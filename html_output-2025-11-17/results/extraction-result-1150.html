<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1150 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1150</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1150</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-25.html">extraction-schema-25</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI agents using adaptive experimental design methods in unknown or partially observable environments, including the specific adaptation strategies, environment characteristics, and performance results.</div>
                <p><strong>Paper ID:</strong> paper-211069585</p>
                <p><strong>Paper Title:</strong> <a href="https://arxiv.org/pdf/1909.04568v3.pdf" target="_blank">BINOCULARS for Efficient, Nonmyopic Sequential Experimental Design</a></p>
                <p><strong>Paper Abstract:</strong> Finite-horizon sequential experimental design (SED) arises naturally in many contexts, including hyperparameter tuning in machine learning among more traditional settings. Computing the optimal policy for such problems requires solving Bellman equations, which are generally intractable. Most existing work resorts to severely myopic approximations by limiting the decision horizon to only a single time-step, which can underweight exploration in favor of exploitation. We present BINOCULARS: Batch-Informed NOnmyopic Choices, Using Long-horizons for Adaptive, Rapid SED, a general framework for deriving efficient, nonmyopic approximations to the optimal experimental policy. Our key idea is simple and surprisingly effective: we first compute a one-step optimal batch of experiments, then select a single point from this batch to evaluate. We realize BINOCULARS for Bayesian optimization and Bayesian quadrature -- two notable SED problems with radically different objectives -- and demonstrate that BINOCULARS significantly outperforms myopic alternatives in real-world scenarios.</p>
                <p><strong>Cost:</strong> 0.021</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1150.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1150.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI agents using adaptive experimental design methods in unknown or partially observable environments, including the specific adaptation strategies, environment characteristics, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BINOCULARS</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>BINOCULARS: Batch-Informed NOnmyopic Choices, Using Long-horizons for Adaptive, Rapid Sequential Experimental Design</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A general nonmyopic sequential experimental design framework that computes an optimal non-adaptive batch (q-size) using batch objectives and then selects one experiment from that batch to execute sequentially, applied to Bayesian optimization (q-EI) and Bayesian quadrature (q-DPP).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>BINOCULARS (q.EI.s / q.EI.b for BO; q.DPP.s / q.DPP.b for BQ)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Surrogate-model-based sequential decision agent using Gaussian processes (GPs). Core components: GP posterior (Matérn ARD kernels), hyperparameter re-fitting after each observation, a batch optimizer (q-EI for BO or DPP-mode for BQ) computed via gradient-based optimization + Monte Carlo reparameterization, and a selection rule that picks one point from the optimized batch (either 's'ampling proportional to immediate reward or 'b'est immediate reward).</td>
                        </tr>
                        <tr>
                            <td><strong>adaptive_design_method</strong></td>
                            <td>Bayesian optimization (q-EI) for BO; Bayesian quadrature with DPP-mode batch design for BQ (active sampling / information-entropy reduction).</td>
                        </tr>
                        <tr>
                            <td><strong>adaptation_strategy_description</strong></td>
                            <td>At each iteration: compute an optimal batch X* of remaining budget size q by maximizing a batch expected-utility (q-EI for BO; batch entropy / DPP-mode for BQ). From X* select a single x (either best immediate-utility or sampled proportional to immediate utility), observe y, update GP posterior and hyperparameters, decrement budget and repeat. The batch computation approximates long-horizon utility and thereby induces nonmyopic behavior while only executing one measurement per iteration.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Black-box optimization and integration benchmarks (synthetic multimodal test functions; real hyperparameter tuning problems; synthetic and real integrands for Bayesian quadrature).</td>
                        </tr>
                        <tr>
                            <td><strong>environment_characteristics</strong></td>
                            <td>Unknown (black-box) objective or integrand, continuous input domains, expensive-to-evaluate queries, multimodal in many benchmarks, partially observable via pointwise noisy or noiseless evaluations (modeled probabilistically with a GP), hyperparameters of the GP are learned online (making posterior and optimal design sometimes dependent on observed values).</td>
                        </tr>
                        <tr>
                            <td><strong>environment_complexity</strong></td>
                            <td>Variable-dimensional continuous domains (d varies per benchmark); action/design space X typically continuous and large/unbounded (effectively infinite |X|); finite-horizon budget T evaluations (experiments used 2d initial points + 20d further iterations in BO experiments); batch sizes q tested up to 15 in BO experiments; computational cost dominated by optimizing a q-dimensional continuous batch objective.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_adaptive_design</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_adaptation</strong></td>
                            <td>BO: q.EI.s variants consistently outperform one-step EI; e.g., on the nine 'hard' synthetic functions average GAP at termination: EI = 0.555 vs 12.EI.s = 0.635 (normalized GAP). Real hyperparameter tuning tasks: EI average GAP = 0.779 vs 6.EI.s = 0.831. BQ: median fractional error at termination averaged across BQ benchmarks: UNCT = 0.068 vs 2.DPP.s = 0.037 (fractional error |Z-Ẑ|/Z). Runtime: BINOCULARS variants run only slightly slower than myopic baselines and are substantially faster (orders of magnitude in some cases) than other nonmyopic methods like rollout/GLASSES per-iteration.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_adaptation</strong></td>
                            <td>Baselines reported: EI (myopic BO) — average GAP = 0.555 (synthetic) and 0.779 (real); Random baseline (BO) average GAP = 0.322 (synthetic). For BQ, UNCT (uncertainty sampling) median fractional error = 0.068. BINOCULARS systematically improves on these baselines in the reported experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>sample_efficiency</strong></td>
                            <td>Empirical results show faster final convergence per budget: e.g., BINOCULARS typically overtakes EI after ~20% of the budget on difficult BO problems (i.e., equalizes then surpasses EI by termination). In BQ, 2.DPP.s achieves substantially lower median fractional error at termination using the same budgets as UNCT. Exact sample counts depend on dimension and budget schedule (experiments used budgets of 20d iterations after initialization).</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_tradeoff</strong></td>
                            <td>BINOCULARS reduces myopia by optimizing a batch expected-utility which approximates multi-step lookahead; this yields more spatially distributed candidate points (enhanced exploration) early, and the sequential selection from the batch plus posterior updating causes transition to exploitation later. Selection strategy ('sampling' vs 'best') modulates exploration: sampling increases exploration, choosing best favors exploitation.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_methods</strong></td>
                            <td>Compared against one-step myopic baselines (EI for BO, UNCT for BQ), rollout (approximate DP rollout 2.R.10 and 3.R.3), GLASSES (simulated-batch nonmyopic method), random baseline, and various q.EI.b (best-from-batch) variants.</td>
                        </tr>
                        <tr>
                            <td><strong>key_results</strong></td>
                            <td>1) BINOCULARS yields distinct nonmyopic behavior: initially more exploratory then switches to exploitation, which gives superior final performance on hard BO benchmarks. 2) BINOCULARS (q.EI.s and q.DPP.s) significantly outperforms myopic baselines (EI/UNCT) across synthetic and real tasks. 3) BINOCULARS is competitive with other nonmyopic approaches (GLASSES, rollout) in solution quality while being much faster computationally — placing it on the Pareto frontier of performance vs time. 4) 'Sampling' from optimized batch generally outperforms or equals picking the 'best' immediate point; increasing q helps up to a point but returns diminish.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>1) Planning too far ahead (very large q) can hurt empirical performance due to model misspecification; choice of q matters and is problem-dependent. 2) Uniform sampling from the batch is worse than 'best' or proportional sampling. 3) The method's computational cost grows with q (batch optimization is the primary cost) and with GP hyperparameter tuning. 4) On some synthetic benchmarks rollout or GLASSES implementations (and optimization artifacts like DIRECT starting point) can produce inconsistent comparisons; synthetic-vs-real benchmark behaviors can differ significantly.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'BINOCULARS for Efficient, Nonmyopic Sequential Experimental Design', 'publication_date_yy_mm': '2019-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1150.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e1150.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI agents using adaptive experimental design methods in unknown or partially observable environments, including the specific adaptation strategies, environment characteristics, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BINOCULARS-BO (q.EI.s)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>BINOCULARS instantiated for Bayesian Optimization using q-Expected Improvement (q-EI) batch objective</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>BO agent variant of BINOCULARS that optimizes a q-point batch expected-improvement (q-EI) via reparameterization + Monte Carlo, then samples one point from the batch and updates the GP sequentially.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>BINOCULARS (q.EI.s)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>GP-based Bayesian optimization agent: uses q-EI batch objective optimized by gradient methods (reparameterization trick and Monte Carlo) to propose a batch X*; selects one x from X* (sampling proportional to immediate EI), executes, updates GP and hyperparameters, repeats until budget exhausted.</td>
                        </tr>
                        <tr>
                            <td><strong>adaptive_design_method</strong></td>
                            <td>Bayesian optimization with nonmyopic batch-informed selection (q-EI).</td>
                        </tr>
                        <tr>
                            <td><strong>adaptation_strategy_description</strong></td>
                            <td>Adapts by recomputing GP posterior and re-optimizing q-EI batch after each single observation; the batch objective encodes a lookahead approximation to the remainder of the budget, guiding early exploration and later exploitation.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Synthetic multimodal benchmark functions (31 total, focus on 9 'hard') and real-world hyperparameter tuning functions (SVM, LDA, Logistic Regression, NN Boston/Cancer, robot-pushing 3d/4d).</td>
                        </tr>
                        <tr>
                            <td><strong>environment_characteristics</strong></td>
                            <td>Unknown continuous objective, potentially multimodal, expensive evaluations, partially observable (only sampled outputs at chosen x), GP-modeled with Matérn5/2 ARD kernel; dimensions vary per problem.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_complexity</strong></td>
                            <td>Examples use d-dimensional problems; experiments used 2d initial samples then 20d additional iterations; batch sizes q tested up to 15; continuous action/design space (infinite |X|).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_adaptive_design</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_adaptation</strong></td>
                            <td>On nine hard synthetic functions (average over 100 repeats): EI average GAP = 0.555 vs 12.EI.s = 0.635 (GAP at termination). On real hyperparameter tuning (50 repeats): EI average GAP = 0.779 vs 6.EI.s = 0.831. BINOCULARS variants generally improve with q up to a problem-dependent point.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_adaptation</strong></td>
                            <td>Myopic EI (one-step) baseline: average GAP = 0.555 (synthetic), 0.779 (real). Random baseline for synthetic: GAP = 0.322.</td>
                        </tr>
                        <tr>
                            <td><strong>sample_efficiency</strong></td>
                            <td>Empirically, q.EI.s overtakes EI after roughly 20% of the evaluation budget on hard BO problems and achieves higher final GAP with the same total budget; absolute sample counts follow the standard experimental budgets (20d iterations after initialization).</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_tradeoff</strong></td>
                            <td>The q-EI batch objective produces spatially spread batch candidates that promote exploration; sampling-from-batch selection leads to broader exploration early and later exploitation as posterior concentrates.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_methods</strong></td>
                            <td>EI (myopic), GLASSES (q.G), rollout (q.R.n), random, q.EI.b (best-from-batch) variants.</td>
                        </tr>
                        <tr>
                            <td><strong>key_results</strong></td>
                            <td>q.EI.s variants consistently outperform one-step EI on hard synthetic and real tasks; sampling-from-batch ('s') generally outperforms choosing the immediate-best ('b'); increasing q helps up to intermediate sizes (e.g., q=6..12) but very large q yields diminishing returns.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Performance sensitive to q choice; larger q increases computational cost; model misspecification can make long-horizon planning detrimental; uniform sampling from batch is suboptimal.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'BINOCULARS for Efficient, Nonmyopic Sequential Experimental Design', 'publication_date_yy_mm': '2019-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1150.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e1150.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI agents using adaptive experimental design methods in unknown or partially observable environments, including the specific adaptation strategies, environment characteristics, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BINOCULARS-BQ (q.DPP.s)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>BINOCULARS instantiated for Bayesian Quadrature using Determinantal Point Process (DPP) batch design</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>BQ agent variant of BINOCULARS that optimizes entropy-based batch designs (mode of a DPP defined over q points) to reduce posterior variance of the integral estimate, then samples one point from the batch to evaluate sequentially.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>BINOCULARS (q.DPP.s)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Bayesian quadrature agent: places a GP on (transformed) integrand (log or sqrt transform for nonnegativity), fits GP hyperparameters iteratively, optimizes a q-point batch by maximizing multivariate Gaussian differential entropy (DPP-mode) via gradient optimization, selects one point from the batch (sampling variant), observes integrand value, updates GP and hyperparameters, and repeats.</td>
                        </tr>
                        <tr>
                            <td><strong>adaptive_design_method</strong></td>
                            <td>Bayesian quadrature with batch-informed active sampling (entropy reduction / DPP batch-mode).</td>
                        </tr>
                        <tr>
                            <td><strong>adaptation_strategy_description</strong></td>
                            <td>Uses the GP posterior (including hyperparameters learned after each observation) to compute a q-point batch that minimizes posterior variance / maximizes entropy reduction of the integral; picks one point from this batch and updates posterior, enabling adaptation because the posterior covariance depends on observed values due to transformations and hyperparameter learning.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>BQ benchmark integrands: five standard synthetic functions, one additional multimodal synthetic function, and two real model likelihood functions used in prior work.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_characteristics</strong></td>
                            <td>Unknown nonnegative integrands, continuous domains, may be multimodal or discontinuous (benchmarks include 'MM', 'discont', etc.), partially observable via pointwise evaluations, GP prior on log(f) to enforce nonnegativity, posterior covariance can depend on observed values (due to transform / approximation).</td>
                        </tr>
                        <tr>
                            <td><strong>environment_complexity</strong></td>
                            <td>Various low-to-moderate dimensional integrands; experiments used budgets consistent with BO setup (2d initial points + further iterations); batch sizes q small (2,3,10 reported); evaluation cost varies with integrand.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_adaptive_design</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_adaptation</strong></td>
                            <td>Median fractional error (|Z-Ẑ|/Z) averaged across BQ benchmarks: UNCT = 0.068 (baseline) vs 2.DPP.s = 0.037 (best among reported BINOCULARS variants). Per-benchmark numbers (median fractional error): e.g., 'cont' UNCT 0.004 vs 2.DPP.s 0.003; 'MM' UNCT 0.254 vs 2.DPP.s 0.221; average across benchmarks shows substantial improvement.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_adaptation</strong></td>
                            <td>UNCT (uncertainty sampling) baseline median fractional error = 0.068 (average across reported BQ functions).</td>
                        </tr>
                        <tr>
                            <td><strong>sample_efficiency</strong></td>
                            <td>2.DPP.s reduces fractional error substantially compared to UNCT with the same evaluation budget; 2-point batch variants (q=2) were particularly effective and efficient, often achieving lower error with similar per-iteration time than rollout.</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_tradeoff</strong></td>
                            <td>The DPP-mode batch objective spreads points to reduce posterior entropy (exploration of uncertain regions) while subsequent sequential selection and posterior updates concentrate sampling on regions that most reduce uncertainty of the integral (exploitation for integral estimate accuracy).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_methods</strong></td>
                            <td>UNCT (uncertainty sampling), rollout variants (2.R.10, 3.R.3), q.DPP.b (best-from-batch), and myopic baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>key_results</strong></td>
                            <td>1) BINOCULARS applied to BQ (not previously treated nonmyopically in literature) yields strong nonmyopic behavior and better final integral estimates than UNCT. 2) 2.DPP.s is often the best-performing variant both in error and runtime tradeoff: lower median fractional error than UNCT and much faster than rollout. 3) 'sampling' variants (q.DPP.s) generally outperform 'best' variants (q.DPP.b).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Increasing q does not consistently improve performance for BQ; transforming integrands (e.g., log) and approximate posterior moment-matching introduce dependencies of covariance on observed values which complicate design and may make large lookaheads brittle; computational cost increases with q and hyperparameter re-fitting.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'BINOCULARS for Efficient, Nonmyopic Sequential Experimental Design', 'publication_date_yy_mm': '2019-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1150.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e1150.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI agents using adaptive experimental design methods in unknown or partially observable environments, including the specific adaptation strategies, environment characteristics, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GLASSES</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GLASSES: Relieving the myopia of Bayesian optimisation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A nonmyopic BO approximation that simulates future sequential decisions using a heuristic batch BO policy to construct a batch and estimate its expected improvement, aiming to reduce myopia compared to one-step EI.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>GLASSES: Relieving the myopia of Bayesian optimisation</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>GLASSES (q.G)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Nonmyopic BO method: constructs a simulated batch by greedily adding points via a penalized/sequential EI heuristic and estimates batch expected utility (originally via expectation propagation; in this paper implemented with quasi-Monte Carlo). Used as a baseline comparator.</td>
                        </tr>
                        <tr>
                            <td><strong>adaptive_design_method</strong></td>
                            <td>Nonmyopic Bayesian optimization via simulation of sequential policy (heuristic batch construction).</td>
                        </tr>
                        <tr>
                            <td><strong>adaptation_strategy_description</strong></td>
                            <td>Simulates future decisions adaptively based on sampled function values; constructs batch by adding points sequentially using penalized EI heuristics and uses that batch to approximate lookahead utility.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Same BO benchmarks as BINOCULARS (synthetic hard functions and real hyperparameter tuning tasks).</td>
                        </tr>
                        <tr>
                            <td><strong>environment_characteristics</strong></td>
                            <td>Unknown black-box continuous objectives, multimodal, expensive evaluations, GP surrogate modeling.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_complexity</strong></td>
                            <td>As per BO experiments: continuous domains, varying dimensions, budgets of 20d further iterations after initialization; batch sizes q tested 2 and 3 in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_adaptive_design</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_adaptation</strong></td>
                            <td>GLASSES is competitive with BINOCULARS in solution quality on real-world BO benchmarks (e.g., 2.G average GAP ≈ 0.836 vs 6.EI.s = 0.831 on the reported real tasks) but is computationally more expensive per iteration than BINOCULARS.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_adaptation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>sample_efficiency</strong></td>
                            <td>Comparable to BINOCULARS in many tested cases but with higher computational cost per iteration; does not consistently dominate BINOCULARS on 'hard' synthetic benchmarks.</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_tradeoff</strong></td>
                            <td>Heuristic simulation of future EI decisions implicitly trades off exploration and exploitation; behavior depends on heuristic penalization and simulation fidelity.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_methods</strong></td>
                            <td>Compared against EI, BINOCULARS, rollout, random.</td>
                        </tr>
                        <tr>
                            <td><strong>key_results</strong></td>
                            <td>GLASSES can reduce myopia and improve over EI but is more expensive to compute; BINOCULARS achieves similar or better performance at much lower computational cost in the reported experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Higher computational cost; heuristic batch construction can be suboptimal; experimental artifacts (optimizer initializations) can affect performance comparisons on synthetic benchmarks.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'BINOCULARS for Efficient, Nonmyopic Sequential Experimental Design', 'publication_date_yy_mm': '2019-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1150.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e1150.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI agents using adaptive experimental design methods in unknown or partially observable environments, including the specific adaptation strategies, environment characteristics, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Rollout</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Approximate dynamic programming approach that estimates multi-step expected utility by simulating future decisions using a heuristic policy (used here to compute 2- or 3-step lookahead BO policies), computationally expensive but theoretically principled.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Rollout (q.R.n)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Rollout agent approximates Bellman recursions by sampling possible future observations and then simulating a heuristic policy (e.g., EI) forward for q steps to estimate expected utility; used with quadrature or Monte Carlo sample sizes to estimate expectations.</td>
                        </tr>
                        <tr>
                            <td><strong>adaptive_design_method</strong></td>
                            <td>Approximate dynamic programming / rollout for Bayesian optimization (multi-step lookahead via simulation).</td>
                        </tr>
                        <tr>
                            <td><strong>adaptation_strategy_description</strong></td>
                            <td>At each candidate x, simulate N sampled future observation sequences and apply a heuristic (EI) to pick subsequent actions, average resulting utilities to estimate lookahead Q, and select x maximizing this estimate; expensive due to nested simulation and integration.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>BO benchmarks used in paper (synthetic and real hyperparameter tuning tasks).</td>
                        </tr>
                        <tr>
                            <td><strong>environment_characteristics</strong></td>
                            <td>Unknown black-box continuous objectives, GP-modeled; same partially observable setting as BO experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_complexity</strong></td>
                            <td>Tested rollout horizons q=2 and q=3 with varying numbers of samples (e.g., 2.R.10 uses 10 samples), computationally heavy per iteration (Gauss-Hermite quadrature used for integrals in some implementations).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_adaptive_design</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_adaptation</strong></td>
                            <td>Rollout yields competitive GAP performance on BO benchmarks (e.g., reported 2.R.10 and 3.R.3 achieve GAPs similar to BINOCULARS on several tasks), but incurs much higher time per iteration — experiments show BINOCULARS is considerably faster while achieving similar GAP.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_adaptation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>sample_efficiency</strong></td>
                            <td>High sample computational cost due to nested simulations; sample-efficient in terms of queries in some settings but expensive in wall-clock/time because of simulation overhead.</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_tradeoff</strong></td>
                            <td>Explicitly trades off exploration and exploitation via approximate Bellman lookahead; quality depends on rollout horizon and number of simulation samples.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_methods</strong></td>
                            <td>Compared against BINOCULARS, GLASSES, EI, random.</td>
                        </tr>
                        <tr>
                            <td><strong>key_results</strong></td>
                            <td>Rollout can achieve nonmyopic gains over EI but is computationally costly; small rollout horizons (2) are frequently chosen in adaptive horizon studies and already expensive to compute.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Very high computational cost per iteration; scaling poorly with horizon and dimension; requires substantial MC/quadrature work to estimate expectations accurately.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'BINOCULARS for Efficient, Nonmyopic Sequential Experimental Design', 'publication_date_yy_mm': '2019-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1150.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e1150.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI agents using adaptive experimental design methods in unknown or partially observable environments, including the specific adaptation strategies, environment characteristics, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>EI (Expected Improvement)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Expected Improvement (one-step lookahead acquisition)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The canonical myopic BO acquisition function that selects the next query to maximize one-step expected improvement over the current best observation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Expected Improvement (EI)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>One-step optimal acquisition for improvement utility: computes closed-form expected improvement under GP posterior and selects argmax_x EI(x); computationally cheap per decision and widely used as a myopic baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>adaptive_design_method</strong></td>
                            <td>Myopic Bayesian optimization (one-step lookahead).</td>
                        </tr>
                        <tr>
                            <td><strong>adaptation_strategy_description</strong></td>
                            <td>Adapts by using the current GP posterior (and the current best observed value) to select the single next point maximizing expected immediate improvement; updates posterior after each observation.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Used as baseline on BO benchmark functions (synthetic and real hyperparameter tuning tasks).</td>
                        </tr>
                        <tr>
                            <td><strong>environment_characteristics</strong></td>
                            <td>Unknown continuous black-box objectives, possibly multimodal; partially observable.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_complexity</strong></td>
                            <td>Same problem settings as BINOCULARS/GLASSES/rollout experiments (2d initial + 20d iterations); action space continuous.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_adaptive_design</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_adaptation</strong></td>
                            <td>Reported baseline performance: average GAP = 0.555 on nine hard synthetic BO functions and 0.779 on real hyperparameter tuning tasks (termination metrics reported). EI is efficient to compute and performs well on many problems but suffers myopia leading to premature exploitation on hard multimodal functions.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_adaptation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>sample_efficiency</strong></td>
                            <td>Good per-iteration computational efficiency; sample efficiency can be suboptimal on hard multimodal problems due to myopia.</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_tradeoff</strong></td>
                            <td>Myopic — trades off exploration and exploitation according to one-step expected improvement; tends to over-exploit in some hard tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_methods</strong></td>
                            <td>Compared against BINOCULARS variants, rollout, GLASSES, random.</td>
                        </tr>
                        <tr>
                            <td><strong>key_results</strong></td>
                            <td>EI is a strong baseline for many tasks but is outperformed systematically by BINOCULARS variants on hard benchmarks where nonmyopic planning helps.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Suffers from myopia; can under-explore and miss distant optima (illustrated by synthetic examples in the paper).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'BINOCULARS for Efficient, Nonmyopic Sequential Experimental Design', 'publication_date_yy_mm': '2019-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1150.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e1150.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI agents using adaptive experimental design methods in unknown or partially observable environments, including the specific adaptation strategies, environment characteristics, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>UNCT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Uncertainty Sampling (UNCT)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A myopic active sampling baseline for Bayesian quadrature that picks the next evaluation at the location of largest posterior variance (greedy entropy reduction of integrand).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Uncertainty Sampling (UNCT)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Selects the input with highest marginal posterior variance under the GP surrogate of the integrand; computationally cheap and standard baseline for BQ / active learning of GPs.</td>
                        </tr>
                        <tr>
                            <td><strong>adaptive_design_method</strong></td>
                            <td>Myopic active learning / uncertainty sampling for Bayesian quadrature.</td>
                        </tr>
                        <tr>
                            <td><strong>adaptation_strategy_description</strong></td>
                            <td>At each iteration pick x maximizing posterior variance of integrand (or entropy of f(X)); update GP and hyperparameters after observation, repeat.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Bayesian quadrature benchmark integrands (synthetic and real likelihoods).</td>
                        </tr>
                        <tr>
                            <td><strong>environment_characteristics</strong></td>
                            <td>Unknown integrand (often nonnegative, transformed by log), potentially multimodal or discontinuous; partially observable via pointwise evaluations; GP posterior and hyperparameters updated iteratively.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_complexity</strong></td>
                            <td>Moderate dimensional integrands used in the experiments; budgets similar to BO experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_adaptive_design</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_adaptation</strong></td>
                            <td>Reported median fractional error across BQ benchmarks = 0.068 (baseline). BINOCULARS q.DPP.s reduced this to 0.037 on average.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_adaptation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>sample_efficiency</strong></td>
                            <td>Less sample-efficient than BINOCULARS variants on tested BQ benchmarks (higher median fractional error for same budget).</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_tradeoff</strong></td>
                            <td>Greedy exploration of high-variance regions; does not explicitly consider downstream effect on integral estimate (exploitation for integral accuracy).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_methods</strong></td>
                            <td>Compared against BINOCULARS q.DPP variants and rollout.</td>
                        </tr>
                        <tr>
                            <td><strong>key_results</strong></td>
                            <td>UNCT is a reasonable myopic baseline for BQ but is substantially outperformed by BINOCULARS nonmyopic DPP-based designs in fractional-error metrics in the experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Greedy variance maximization may not minimize error of integral estimates efficiently; inferior performance on many BQ benchmarks compared to nonmyopic BINOCULARS variants.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'BINOCULARS for Efficient, Nonmyopic Sequential Experimental Design', 'publication_date_yy_mm': '2019-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>GLASSES: Relieving the myopia of Bayesian optimisation <em>(Rating: 2)</em></li>
                <li>Efficient nonmyopic batch active search <em>(Rating: 1)</em></li>
                <li>Bayesian optimization with a finite budget: an approximate dynamic programming approach <em>(Rating: 2)</em></li>
                <li>Why non-myopic Bayesian optimization is promising and how far should we lookahead? A study via rollout <em>(Rating: 2)</em></li>
                <li>Sampling for inference in probabilistic models with fast Bayesian quadrature <em>(Rating: 2)</em></li>
                <li>Nonmyopic -Bayes-optimal active learning of Gaussian processes <em>(Rating: 1)</em></li>
                <li>Determinantal point processes for machine learning <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1150",
    "paper_id": "paper-211069585",
    "extraction_schema_id": "extraction-schema-25",
    "extracted_data": [
        {
            "name_short": "BINOCULARS",
            "name_full": "BINOCULARS: Batch-Informed NOnmyopic Choices, Using Long-horizons for Adaptive, Rapid Sequential Experimental Design",
            "brief_description": "A general nonmyopic sequential experimental design framework that computes an optimal non-adaptive batch (q-size) using batch objectives and then selects one experiment from that batch to execute sequentially, applied to Bayesian optimization (q-EI) and Bayesian quadrature (q-DPP).",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "BINOCULARS (q.EI.s / q.EI.b for BO; q.DPP.s / q.DPP.b for BQ)",
            "agent_description": "Surrogate-model-based sequential decision agent using Gaussian processes (GPs). Core components: GP posterior (Matérn ARD kernels), hyperparameter re-fitting after each observation, a batch optimizer (q-EI for BO or DPP-mode for BQ) computed via gradient-based optimization + Monte Carlo reparameterization, and a selection rule that picks one point from the optimized batch (either 's'ampling proportional to immediate reward or 'b'est immediate reward).",
            "adaptive_design_method": "Bayesian optimization (q-EI) for BO; Bayesian quadrature with DPP-mode batch design for BQ (active sampling / information-entropy reduction).",
            "adaptation_strategy_description": "At each iteration: compute an optimal batch X* of remaining budget size q by maximizing a batch expected-utility (q-EI for BO; batch entropy / DPP-mode for BQ). From X* select a single x (either best immediate-utility or sampled proportional to immediate utility), observe y, update GP posterior and hyperparameters, decrement budget and repeat. The batch computation approximates long-horizon utility and thereby induces nonmyopic behavior while only executing one measurement per iteration.",
            "environment_name": "Black-box optimization and integration benchmarks (synthetic multimodal test functions; real hyperparameter tuning problems; synthetic and real integrands for Bayesian quadrature).",
            "environment_characteristics": "Unknown (black-box) objective or integrand, continuous input domains, expensive-to-evaluate queries, multimodal in many benchmarks, partially observable via pointwise noisy or noiseless evaluations (modeled probabilistically with a GP), hyperparameters of the GP are learned online (making posterior and optimal design sometimes dependent on observed values).",
            "environment_complexity": "Variable-dimensional continuous domains (d varies per benchmark); action/design space X typically continuous and large/unbounded (effectively infinite |X|); finite-horizon budget T evaluations (experiments used 2d initial points + 20d further iterations in BO experiments); batch sizes q tested up to 15 in BO experiments; computational cost dominated by optimizing a q-dimensional continuous batch objective.",
            "uses_adaptive_design": true,
            "performance_with_adaptation": "BO: q.EI.s variants consistently outperform one-step EI; e.g., on the nine 'hard' synthetic functions average GAP at termination: EI = 0.555 vs 12.EI.s = 0.635 (normalized GAP). Real hyperparameter tuning tasks: EI average GAP = 0.779 vs 6.EI.s = 0.831. BQ: median fractional error at termination averaged across BQ benchmarks: UNCT = 0.068 vs 2.DPP.s = 0.037 (fractional error |Z-Ẑ|/Z). Runtime: BINOCULARS variants run only slightly slower than myopic baselines and are substantially faster (orders of magnitude in some cases) than other nonmyopic methods like rollout/GLASSES per-iteration.",
            "performance_without_adaptation": "Baselines reported: EI (myopic BO) — average GAP = 0.555 (synthetic) and 0.779 (real); Random baseline (BO) average GAP = 0.322 (synthetic). For BQ, UNCT (uncertainty sampling) median fractional error = 0.068. BINOCULARS systematically improves on these baselines in the reported experiments.",
            "sample_efficiency": "Empirical results show faster final convergence per budget: e.g., BINOCULARS typically overtakes EI after ~20% of the budget on difficult BO problems (i.e., equalizes then surpasses EI by termination). In BQ, 2.DPP.s achieves substantially lower median fractional error at termination using the same budgets as UNCT. Exact sample counts depend on dimension and budget schedule (experiments used budgets of 20d iterations after initialization).",
            "exploration_exploitation_tradeoff": "BINOCULARS reduces myopia by optimizing a batch expected-utility which approximates multi-step lookahead; this yields more spatially distributed candidate points (enhanced exploration) early, and the sequential selection from the batch plus posterior updating causes transition to exploitation later. Selection strategy ('sampling' vs 'best') modulates exploration: sampling increases exploration, choosing best favors exploitation.",
            "comparison_methods": "Compared against one-step myopic baselines (EI for BO, UNCT for BQ), rollout (approximate DP rollout 2.R.10 and 3.R.3), GLASSES (simulated-batch nonmyopic method), random baseline, and various q.EI.b (best-from-batch) variants.",
            "key_results": "1) BINOCULARS yields distinct nonmyopic behavior: initially more exploratory then switches to exploitation, which gives superior final performance on hard BO benchmarks. 2) BINOCULARS (q.EI.s and q.DPP.s) significantly outperforms myopic baselines (EI/UNCT) across synthetic and real tasks. 3) BINOCULARS is competitive with other nonmyopic approaches (GLASSES, rollout) in solution quality while being much faster computationally — placing it on the Pareto frontier of performance vs time. 4) 'Sampling' from optimized batch generally outperforms or equals picking the 'best' immediate point; increasing q helps up to a point but returns diminish.",
            "limitations_or_failures": "1) Planning too far ahead (very large q) can hurt empirical performance due to model misspecification; choice of q matters and is problem-dependent. 2) Uniform sampling from the batch is worse than 'best' or proportional sampling. 3) The method's computational cost grows with q (batch optimization is the primary cost) and with GP hyperparameter tuning. 4) On some synthetic benchmarks rollout or GLASSES implementations (and optimization artifacts like DIRECT starting point) can produce inconsistent comparisons; synthetic-vs-real benchmark behaviors can differ significantly.",
            "uuid": "e1150.0",
            "source_info": {
                "paper_title": "BINOCULARS for Efficient, Nonmyopic Sequential Experimental Design",
                "publication_date_yy_mm": "2019-09"
            }
        },
        {
            "name_short": "BINOCULARS-BO (q.EI.s)",
            "name_full": "BINOCULARS instantiated for Bayesian Optimization using q-Expected Improvement (q-EI) batch objective",
            "brief_description": "BO agent variant of BINOCULARS that optimizes a q-point batch expected-improvement (q-EI) via reparameterization + Monte Carlo, then samples one point from the batch and updates the GP sequentially.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "BINOCULARS (q.EI.s)",
            "agent_description": "GP-based Bayesian optimization agent: uses q-EI batch objective optimized by gradient methods (reparameterization trick and Monte Carlo) to propose a batch X*; selects one x from X* (sampling proportional to immediate EI), executes, updates GP and hyperparameters, repeats until budget exhausted.",
            "adaptive_design_method": "Bayesian optimization with nonmyopic batch-informed selection (q-EI).",
            "adaptation_strategy_description": "Adapts by recomputing GP posterior and re-optimizing q-EI batch after each single observation; the batch objective encodes a lookahead approximation to the remainder of the budget, guiding early exploration and later exploitation.",
            "environment_name": "Synthetic multimodal benchmark functions (31 total, focus on 9 'hard') and real-world hyperparameter tuning functions (SVM, LDA, Logistic Regression, NN Boston/Cancer, robot-pushing 3d/4d).",
            "environment_characteristics": "Unknown continuous objective, potentially multimodal, expensive evaluations, partially observable (only sampled outputs at chosen x), GP-modeled with Matérn5/2 ARD kernel; dimensions vary per problem.",
            "environment_complexity": "Examples use d-dimensional problems; experiments used 2d initial samples then 20d additional iterations; batch sizes q tested up to 15; continuous action/design space (infinite |X|).",
            "uses_adaptive_design": true,
            "performance_with_adaptation": "On nine hard synthetic functions (average over 100 repeats): EI average GAP = 0.555 vs 12.EI.s = 0.635 (GAP at termination). On real hyperparameter tuning (50 repeats): EI average GAP = 0.779 vs 6.EI.s = 0.831. BINOCULARS variants generally improve with q up to a problem-dependent point.",
            "performance_without_adaptation": "Myopic EI (one-step) baseline: average GAP = 0.555 (synthetic), 0.779 (real). Random baseline for synthetic: GAP = 0.322.",
            "sample_efficiency": "Empirically, q.EI.s overtakes EI after roughly 20% of the evaluation budget on hard BO problems and achieves higher final GAP with the same total budget; absolute sample counts follow the standard experimental budgets (20d iterations after initialization).",
            "exploration_exploitation_tradeoff": "The q-EI batch objective produces spatially spread batch candidates that promote exploration; sampling-from-batch selection leads to broader exploration early and later exploitation as posterior concentrates.",
            "comparison_methods": "EI (myopic), GLASSES (q.G), rollout (q.R.n), random, q.EI.b (best-from-batch) variants.",
            "key_results": "q.EI.s variants consistently outperform one-step EI on hard synthetic and real tasks; sampling-from-batch ('s') generally outperforms choosing the immediate-best ('b'); increasing q helps up to intermediate sizes (e.g., q=6..12) but very large q yields diminishing returns.",
            "limitations_or_failures": "Performance sensitive to q choice; larger q increases computational cost; model misspecification can make long-horizon planning detrimental; uniform sampling from batch is suboptimal.",
            "uuid": "e1150.1",
            "source_info": {
                "paper_title": "BINOCULARS for Efficient, Nonmyopic Sequential Experimental Design",
                "publication_date_yy_mm": "2019-09"
            }
        },
        {
            "name_short": "BINOCULARS-BQ (q.DPP.s)",
            "name_full": "BINOCULARS instantiated for Bayesian Quadrature using Determinantal Point Process (DPP) batch design",
            "brief_description": "BQ agent variant of BINOCULARS that optimizes entropy-based batch designs (mode of a DPP defined over q points) to reduce posterior variance of the integral estimate, then samples one point from the batch to evaluate sequentially.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "BINOCULARS (q.DPP.s)",
            "agent_description": "Bayesian quadrature agent: places a GP on (transformed) integrand (log or sqrt transform for nonnegativity), fits GP hyperparameters iteratively, optimizes a q-point batch by maximizing multivariate Gaussian differential entropy (DPP-mode) via gradient optimization, selects one point from the batch (sampling variant), observes integrand value, updates GP and hyperparameters, and repeats.",
            "adaptive_design_method": "Bayesian quadrature with batch-informed active sampling (entropy reduction / DPP batch-mode).",
            "adaptation_strategy_description": "Uses the GP posterior (including hyperparameters learned after each observation) to compute a q-point batch that minimizes posterior variance / maximizes entropy reduction of the integral; picks one point from this batch and updates posterior, enabling adaptation because the posterior covariance depends on observed values due to transformations and hyperparameter learning.",
            "environment_name": "BQ benchmark integrands: five standard synthetic functions, one additional multimodal synthetic function, and two real model likelihood functions used in prior work.",
            "environment_characteristics": "Unknown nonnegative integrands, continuous domains, may be multimodal or discontinuous (benchmarks include 'MM', 'discont', etc.), partially observable via pointwise evaluations, GP prior on log(f) to enforce nonnegativity, posterior covariance can depend on observed values (due to transform / approximation).",
            "environment_complexity": "Various low-to-moderate dimensional integrands; experiments used budgets consistent with BO setup (2d initial points + further iterations); batch sizes q small (2,3,10 reported); evaluation cost varies with integrand.",
            "uses_adaptive_design": true,
            "performance_with_adaptation": "Median fractional error (|Z-Ẑ|/Z) averaged across BQ benchmarks: UNCT = 0.068 (baseline) vs 2.DPP.s = 0.037 (best among reported BINOCULARS variants). Per-benchmark numbers (median fractional error): e.g., 'cont' UNCT 0.004 vs 2.DPP.s 0.003; 'MM' UNCT 0.254 vs 2.DPP.s 0.221; average across benchmarks shows substantial improvement.",
            "performance_without_adaptation": "UNCT (uncertainty sampling) baseline median fractional error = 0.068 (average across reported BQ functions).",
            "sample_efficiency": "2.DPP.s reduces fractional error substantially compared to UNCT with the same evaluation budget; 2-point batch variants (q=2) were particularly effective and efficient, often achieving lower error with similar per-iteration time than rollout.",
            "exploration_exploitation_tradeoff": "The DPP-mode batch objective spreads points to reduce posterior entropy (exploration of uncertain regions) while subsequent sequential selection and posterior updates concentrate sampling on regions that most reduce uncertainty of the integral (exploitation for integral estimate accuracy).",
            "comparison_methods": "UNCT (uncertainty sampling), rollout variants (2.R.10, 3.R.3), q.DPP.b (best-from-batch), and myopic baselines.",
            "key_results": "1) BINOCULARS applied to BQ (not previously treated nonmyopically in literature) yields strong nonmyopic behavior and better final integral estimates than UNCT. 2) 2.DPP.s is often the best-performing variant both in error and runtime tradeoff: lower median fractional error than UNCT and much faster than rollout. 3) 'sampling' variants (q.DPP.s) generally outperform 'best' variants (q.DPP.b).",
            "limitations_or_failures": "Increasing q does not consistently improve performance for BQ; transforming integrands (e.g., log) and approximate posterior moment-matching introduce dependencies of covariance on observed values which complicate design and may make large lookaheads brittle; computational cost increases with q and hyperparameter re-fitting.",
            "uuid": "e1150.2",
            "source_info": {
                "paper_title": "BINOCULARS for Efficient, Nonmyopic Sequential Experimental Design",
                "publication_date_yy_mm": "2019-09"
            }
        },
        {
            "name_short": "GLASSES",
            "name_full": "GLASSES: Relieving the myopia of Bayesian optimisation",
            "brief_description": "A nonmyopic BO approximation that simulates future sequential decisions using a heuristic batch BO policy to construct a batch and estimate its expected improvement, aiming to reduce myopia compared to one-step EI.",
            "citation_title": "GLASSES: Relieving the myopia of Bayesian optimisation",
            "mention_or_use": "use",
            "agent_name": "GLASSES (q.G)",
            "agent_description": "Nonmyopic BO method: constructs a simulated batch by greedily adding points via a penalized/sequential EI heuristic and estimates batch expected utility (originally via expectation propagation; in this paper implemented with quasi-Monte Carlo). Used as a baseline comparator.",
            "adaptive_design_method": "Nonmyopic Bayesian optimization via simulation of sequential policy (heuristic batch construction).",
            "adaptation_strategy_description": "Simulates future decisions adaptively based on sampled function values; constructs batch by adding points sequentially using penalized EI heuristics and uses that batch to approximate lookahead utility.",
            "environment_name": "Same BO benchmarks as BINOCULARS (synthetic hard functions and real hyperparameter tuning tasks).",
            "environment_characteristics": "Unknown black-box continuous objectives, multimodal, expensive evaluations, GP surrogate modeling.",
            "environment_complexity": "As per BO experiments: continuous domains, varying dimensions, budgets of 20d further iterations after initialization; batch sizes q tested 2 and 3 in experiments.",
            "uses_adaptive_design": true,
            "performance_with_adaptation": "GLASSES is competitive with BINOCULARS in solution quality on real-world BO benchmarks (e.g., 2.G average GAP ≈ 0.836 vs 6.EI.s = 0.831 on the reported real tasks) but is computationally more expensive per iteration than BINOCULARS.",
            "performance_without_adaptation": null,
            "sample_efficiency": "Comparable to BINOCULARS in many tested cases but with higher computational cost per iteration; does not consistently dominate BINOCULARS on 'hard' synthetic benchmarks.",
            "exploration_exploitation_tradeoff": "Heuristic simulation of future EI decisions implicitly trades off exploration and exploitation; behavior depends on heuristic penalization and simulation fidelity.",
            "comparison_methods": "Compared against EI, BINOCULARS, rollout, random.",
            "key_results": "GLASSES can reduce myopia and improve over EI but is more expensive to compute; BINOCULARS achieves similar or better performance at much lower computational cost in the reported experiments.",
            "limitations_or_failures": "Higher computational cost; heuristic batch construction can be suboptimal; experimental artifacts (optimizer initializations) can affect performance comparisons on synthetic benchmarks.",
            "uuid": "e1150.3",
            "source_info": {
                "paper_title": "BINOCULARS for Efficient, Nonmyopic Sequential Experimental Design",
                "publication_date_yy_mm": "2019-09"
            }
        },
        {
            "name_short": "Rollout",
            "name_full": "",
            "brief_description": "Approximate dynamic programming approach that estimates multi-step expected utility by simulating future decisions using a heuristic policy (used here to compute 2- or 3-step lookahead BO policies), computationally expensive but theoretically principled.",
            "citation_title": "",
            "mention_or_use": "use",
            "agent_name": "Rollout (q.R.n)",
            "agent_description": "Rollout agent approximates Bellman recursions by sampling possible future observations and then simulating a heuristic policy (e.g., EI) forward for q steps to estimate expected utility; used with quadrature or Monte Carlo sample sizes to estimate expectations.",
            "adaptive_design_method": "Approximate dynamic programming / rollout for Bayesian optimization (multi-step lookahead via simulation).",
            "adaptation_strategy_description": "At each candidate x, simulate N sampled future observation sequences and apply a heuristic (EI) to pick subsequent actions, average resulting utilities to estimate lookahead Q, and select x maximizing this estimate; expensive due to nested simulation and integration.",
            "environment_name": "BO benchmarks used in paper (synthetic and real hyperparameter tuning tasks).",
            "environment_characteristics": "Unknown black-box continuous objectives, GP-modeled; same partially observable setting as BO experiments.",
            "environment_complexity": "Tested rollout horizons q=2 and q=3 with varying numbers of samples (e.g., 2.R.10 uses 10 samples), computationally heavy per iteration (Gauss-Hermite quadrature used for integrals in some implementations).",
            "uses_adaptive_design": true,
            "performance_with_adaptation": "Rollout yields competitive GAP performance on BO benchmarks (e.g., reported 2.R.10 and 3.R.3 achieve GAPs similar to BINOCULARS on several tasks), but incurs much higher time per iteration — experiments show BINOCULARS is considerably faster while achieving similar GAP.",
            "performance_without_adaptation": null,
            "sample_efficiency": "High sample computational cost due to nested simulations; sample-efficient in terms of queries in some settings but expensive in wall-clock/time because of simulation overhead.",
            "exploration_exploitation_tradeoff": "Explicitly trades off exploration and exploitation via approximate Bellman lookahead; quality depends on rollout horizon and number of simulation samples.",
            "comparison_methods": "Compared against BINOCULARS, GLASSES, EI, random.",
            "key_results": "Rollout can achieve nonmyopic gains over EI but is computationally costly; small rollout horizons (2) are frequently chosen in adaptive horizon studies and already expensive to compute.",
            "limitations_or_failures": "Very high computational cost per iteration; scaling poorly with horizon and dimension; requires substantial MC/quadrature work to estimate expectations accurately.",
            "uuid": "e1150.4",
            "source_info": {
                "paper_title": "BINOCULARS for Efficient, Nonmyopic Sequential Experimental Design",
                "publication_date_yy_mm": "2019-09"
            }
        },
        {
            "name_short": "EI (Expected Improvement)",
            "name_full": "Expected Improvement (one-step lookahead acquisition)",
            "brief_description": "The canonical myopic BO acquisition function that selects the next query to maximize one-step expected improvement over the current best observation.",
            "citation_title": "",
            "mention_or_use": "use",
            "agent_name": "Expected Improvement (EI)",
            "agent_description": "One-step optimal acquisition for improvement utility: computes closed-form expected improvement under GP posterior and selects argmax_x EI(x); computationally cheap per decision and widely used as a myopic baseline.",
            "adaptive_design_method": "Myopic Bayesian optimization (one-step lookahead).",
            "adaptation_strategy_description": "Adapts by using the current GP posterior (and the current best observed value) to select the single next point maximizing expected immediate improvement; updates posterior after each observation.",
            "environment_name": "Used as baseline on BO benchmark functions (synthetic and real hyperparameter tuning tasks).",
            "environment_characteristics": "Unknown continuous black-box objectives, possibly multimodal; partially observable.",
            "environment_complexity": "Same problem settings as BINOCULARS/GLASSES/rollout experiments (2d initial + 20d iterations); action space continuous.",
            "uses_adaptive_design": true,
            "performance_with_adaptation": "Reported baseline performance: average GAP = 0.555 on nine hard synthetic BO functions and 0.779 on real hyperparameter tuning tasks (termination metrics reported). EI is efficient to compute and performs well on many problems but suffers myopia leading to premature exploitation on hard multimodal functions.",
            "performance_without_adaptation": null,
            "sample_efficiency": "Good per-iteration computational efficiency; sample efficiency can be suboptimal on hard multimodal problems due to myopia.",
            "exploration_exploitation_tradeoff": "Myopic — trades off exploration and exploitation according to one-step expected improvement; tends to over-exploit in some hard tasks.",
            "comparison_methods": "Compared against BINOCULARS variants, rollout, GLASSES, random.",
            "key_results": "EI is a strong baseline for many tasks but is outperformed systematically by BINOCULARS variants on hard benchmarks where nonmyopic planning helps.",
            "limitations_or_failures": "Suffers from myopia; can under-explore and miss distant optima (illustrated by synthetic examples in the paper).",
            "uuid": "e1150.5",
            "source_info": {
                "paper_title": "BINOCULARS for Efficient, Nonmyopic Sequential Experimental Design",
                "publication_date_yy_mm": "2019-09"
            }
        },
        {
            "name_short": "UNCT",
            "name_full": "Uncertainty Sampling (UNCT)",
            "brief_description": "A myopic active sampling baseline for Bayesian quadrature that picks the next evaluation at the location of largest posterior variance (greedy entropy reduction of integrand).",
            "citation_title": "",
            "mention_or_use": "use",
            "agent_name": "Uncertainty Sampling (UNCT)",
            "agent_description": "Selects the input with highest marginal posterior variance under the GP surrogate of the integrand; computationally cheap and standard baseline for BQ / active learning of GPs.",
            "adaptive_design_method": "Myopic active learning / uncertainty sampling for Bayesian quadrature.",
            "adaptation_strategy_description": "At each iteration pick x maximizing posterior variance of integrand (or entropy of f(X)); update GP and hyperparameters after observation, repeat.",
            "environment_name": "Bayesian quadrature benchmark integrands (synthetic and real likelihoods).",
            "environment_characteristics": "Unknown integrand (often nonnegative, transformed by log), potentially multimodal or discontinuous; partially observable via pointwise evaluations; GP posterior and hyperparameters updated iteratively.",
            "environment_complexity": "Moderate dimensional integrands used in the experiments; budgets similar to BO experiments.",
            "uses_adaptive_design": true,
            "performance_with_adaptation": "Reported median fractional error across BQ benchmarks = 0.068 (baseline). BINOCULARS q.DPP.s reduced this to 0.037 on average.",
            "performance_without_adaptation": null,
            "sample_efficiency": "Less sample-efficient than BINOCULARS variants on tested BQ benchmarks (higher median fractional error for same budget).",
            "exploration_exploitation_tradeoff": "Greedy exploration of high-variance regions; does not explicitly consider downstream effect on integral estimate (exploitation for integral accuracy).",
            "comparison_methods": "Compared against BINOCULARS q.DPP variants and rollout.",
            "key_results": "UNCT is a reasonable myopic baseline for BQ but is substantially outperformed by BINOCULARS nonmyopic DPP-based designs in fractional-error metrics in the experiments.",
            "limitations_or_failures": "Greedy variance maximization may not minimize error of integral estimates efficiently; inferior performance on many BQ benchmarks compared to nonmyopic BINOCULARS variants.",
            "uuid": "e1150.6",
            "source_info": {
                "paper_title": "BINOCULARS for Efficient, Nonmyopic Sequential Experimental Design",
                "publication_date_yy_mm": "2019-09"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "GLASSES: Relieving the myopia of Bayesian optimisation",
            "rating": 2,
            "sanitized_title": "glasses_relieving_the_myopia_of_bayesian_optimisation"
        },
        {
            "paper_title": "Efficient nonmyopic batch active search",
            "rating": 1,
            "sanitized_title": "efficient_nonmyopic_batch_active_search"
        },
        {
            "paper_title": "Bayesian optimization with a finite budget: an approximate dynamic programming approach",
            "rating": 2,
            "sanitized_title": "bayesian_optimization_with_a_finite_budget_an_approximate_dynamic_programming_approach"
        },
        {
            "paper_title": "Why non-myopic Bayesian optimization is promising and how far should we lookahead? A study via rollout",
            "rating": 2,
            "sanitized_title": "why_nonmyopic_bayesian_optimization_is_promising_and_how_far_should_we_lookahead_a_study_via_rollout"
        },
        {
            "paper_title": "Sampling for inference in probabilistic models with fast Bayesian quadrature",
            "rating": 2,
            "sanitized_title": "sampling_for_inference_in_probabilistic_models_with_fast_bayesian_quadrature"
        },
        {
            "paper_title": "Nonmyopic -Bayes-optimal active learning of Gaussian processes",
            "rating": 1,
            "sanitized_title": "nonmyopic_bayesoptimal_active_learning_of_gaussian_processes"
        },
        {
            "paper_title": "Determinantal point processes for machine learning",
            "rating": 1,
            "sanitized_title": "determinantal_point_processes_for_machine_learning"
        }
    ],
    "cost": 0.0208975,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>BINOCULARS for Efficient, Nonmyopic Sequential Experimental Design</p>
<p>Shali Jiang <a href="&#109;&#97;&#105;&#108;&#116;&#111;&#58;&#106;&#105;&#97;&#110;&#103;&#46;&#115;&#64;&#119;&#117;&#115;&#116;&#108;&#46;&#101;&#100;&#117;">&#106;&#105;&#97;&#110;&#103;&#46;&#115;&#64;&#119;&#117;&#115;&#116;&#108;&#46;&#101;&#100;&#117;</a> 
Department of Computer Science and En-gineering
Washington University in Saint Louis
Saint LouisMissouriUSA</p>
<p>Henry Chai <a href="&#109;&#97;&#105;&#108;&#116;&#111;&#58;&#104;&#99;&#104;&#97;&#105;&#64;&#119;&#117;&#115;&#116;&#108;&#46;&#101;&#100;&#117;">&#104;&#99;&#104;&#97;&#105;&#64;&#119;&#117;&#115;&#116;&#108;&#46;&#101;&#100;&#117;</a>. 
Department of Computer Science and En-gineering
Washington University in Saint Louis
Saint LouisMissouriUSA</p>
<p>Javier Gonzalez 
Amazon Research Cambridge
CambridgeUK</p>
<p>Roman Garnett 
Department of Computer Science and En-gineering
Washington University in Saint Louis
Saint LouisMissouriUSA</p>
<p>BINOCULARS for Efficient, Nonmyopic Sequential Experimental Design
6DE4A484161737EAC600BE9144865E6E
Finite-horizon sequential experimental design (SED) arises naturally in many contexts, including hyperparameter tuning in machine learning among more traditional settings.Computing the optimal policy for such problems requires solving Bellman equations, which are generally intractable.Most existing work resorts to severely myopic approximations by limiting the decision horizon to only a single time-step, which can underweight exploration in favor of exploitation.We present BINOCULARS: Batch-Informed NOnmyopic Choices, Using Long-horizons for Adaptive, Rapid SED, a general framework for deriving efficient, nonmyopic approximations to the optimal experimental policy.Our key idea is simple and surprisingly effective: we first compute a one-step optimal batch of experiments, then select a single point from this batch to evaluate.We realize BINOCULARS for Bayesian optimization and Bayesian quadrature -two notable SED problems with radically different objectives -and demonstrate that BINOCULARS significantly outperforms myopic alternatives in real-world scenarios.</p>
<p>Introduction</p>
<p>Many real-world problems can be framed as finite-horizon sequential experimental design (SED), wherein an agent adaptively designs a prespecified number of experiments seeking to maximize some data-dependent utility function.The optimal policy for SED can be formulated as dynamic programming (DP), which balances the inherent tradeoff between exploitation (immediately advancing the goal) and exploration (learning for the future).However, this optimal policy is intractable even for simple problems (Powell, 2010).Common approximation schemes include rollout, In this work, we propose a novel method for efficient and nonmyopic SED, called BINOCULARS: Batch-Informed NOnmyopic Choices, Using Long-horizons for Adaptive, Rapid SED.BINOCULARS is inspired by the fact that the optimal batch (or non-adaptive) design is an approximation to the optimal sequential (or adaptive) design.In fact, the optimal adaptive and non-adaptive designs are exactly the same in some notable cases where the data utility does not depend on the observed outcomes, such as maximizing information gain for a fixed Gaussian process (GP) (Krause and Guestrin, 2007).Even when this is not the case, we show that the optimal batch expected utility is a lower bound of the optimal sequential expected utility.Furthermore, it is tighter than the one-step optimal policy's implied expected utility.Motivated by this insight, BINOCULARS iteratively computes an optimal batch of designs, then chooses one point from this batch.While many existing methods construct batch policies by simulating a sequential policy (Ginsbourger et al., 2010;Desautels et al., 2014;Jiang et al., 2018), BINOCU-LARS goes the other way and "reduces" sequential design to batch design.</p>
<p>BINOCULARS is a general framework applicable to any SED problem.In this paper, we realize this framework on two important yet fundamentally different SED tasks: Bayesian optimization (BO) (Kushner, 1964;Močkus, 1974;Shahriari et al., 2016) and Bayesian quadrature (BQ) (Larkin, 1972;Diaconis, 1988;O'Hagan, 1991).In BO, an agent repeatedly queries an expensive function seeking its global optimum, whereas in BQ the goal is to estimate an intractable integral of the function.</p>
<p>For both problems, many popular policies are myopic: examples include expected improvement (EI) for BO (Močkus, 1974) and uncertainty sampling (UNCT) for BQ (Gunter et al., 2014).These are all one-step optimal for maximizing particular utility functions in expectation.While they are computationally efficient and give reasonably good empirical results, they are liable to suffer from myopia and over-exploitation.Nonmyopic alternatives have recently been applied to BO (González et al., 2016b;Lam et al., 2016;Yue and Al Kontar, 2019), and although results are arXiv:1909.04568v3 [cs.LG] 9 Feb 2020 promising, these are typically costly to compute.</p>
<p>Our contributions can be summarized as follows: (1) We propose a general framework for efficient and nonmyopic SED with finite horizons, inspired by the close connection between optimal sequential and batch designs.(2) We realize the framework on two important SED problems: Bayesian optimization and Bayesian quadrature.This represents the first nonmyopic policy proposed for BQ.(3) We conduct thorough experiments demonstrating that the proposed method significantly outperforms the myopic baselines and is competitive with (if not better than) state-of-the-art nonmyopic alternatives, while being much more efficient.</p>
<p>BINOCULARS</p>
<p>We will first illustrate the intuition behind BINOCULARS and provide explicit mathematical justification.We will then realize BINOCULARS for two specific SED scenarios: BO and BQ.Throughout the rest of this work, we will make extensive use of Gaussian processes (GPs): a Gaussian process defines a probability distribution over functions, where the joint distribution of the function's values at finitely many locations is multivariate normal; for more details, see (Rasmussen and Williams, 2006).</p>
<p>Intuition.Consider the BO example in Fig. 1, where we wish to maximize a one-dimensional objective function over an interval, conditioned on initial observations at the boundary.Suppose we are allowed to design two further function evaluations.The myopic EI policy would greedily pick the middle point first, followed by a point bisecting the left half of the domain.The resulting choices completely ignore the right half, where the maximum happens to lie.Now consider the following alternative for designing the observations: we first construct the optimal batch of size two (2-EI).These points can be determined relatively efficiently as recursion is not required and reflect a better approximation of the remainder of the optimization than just looking one step ahead.We then pick any point from this batch and use EI to choose the final point given the result.This policy results in well-distributed queries and better performance.We can compare these decisions with the optimal (but expensive) policy maximizing the full lookahead expected utility (2-step-EI in Fig. 1(d)): our choices are nearly perfect.</p>
<p>The Optimal Adaptive Policy</p>
<p>Consider a general SED problem with a finite horizon, T .Let the design space be X , response space be Y; for x ∈ X , y ∈ Y and D ⊆ X × Y, let p(y | x, D) be a probabilistic model; and let u(D) be some utility function of observed data D. Define u(y | x, D) = u D ∪(x, y) −u(D) to represent the marginal gain in utility after observing y from experiment x when D has already been observed.Let Q k (x | D) be the expected utility of designing experiment x after observing D when there are k steps remaining, assuming all later decisions are optimal.Q k (x | D) can be expressed in the form of a Bellman equation as follows:
Q k (x | D) = E y [u(y | x, D)] + E y max x Q k−1 x | D ∪ {(x, y)} , (1)
where the expectation is taken with respect to p(y | x, D).The optimal (expected-case) policy is
x * = argmax x Q T −i (x | D i ),(2)
where D i is the observed set at iteration i.The optimal policy is intractable for any moderately large horizon; in general, the complexity is O |X | T |S| T , where S = {D | D ⊆ X × Y}, and in many settings X and/or S are uncountable.Thus, we must find some tractable approximation to proceed.A common solution is to simply limit the horizon to some manageable value , e.g.= 1 or 2. This is called -step lookahead, and is computationally efficient but myopic as we severely limit our view of the future.It does not plan ahead and can thus make suboptimal tradeoffs between exploration and exploitation.</p>
<p>Nonmyopic Approximation via the Optimal Non-Adaptive Policy</p>
<p>Suppose T experiments X = {x 1 , . . ., x T } must be designed simultaneously given current observations D. The expected marginal utility of the resulting observations is
Q(X | D) = E Y [u(Y | X, D)],(3)
where the expectation is taken over the joint distribution of Y = {y 1 , . . ., y T }, p(Y | X, D).Rewriting (3) by decomposing X into x j and X −j where X −j = X \ {x j }, we have (by telescoping sum)
Q(X | D) = E yj [u(y j | x j , D)]+ E yj Q X −j | D ∪ {(x j , y j )} . (4) Let X * ∈ arg max X Q(X | D)
be an optimal batch of experiments.For any x * j ∈ X * , it follows that
E y * j Q X * −j | D ∪ {(x * j , y * j )} = max X−j E y * j Q X −j | D ∪ {(x * j , y * j )} ,(5)
as otherwise we can construct a batch with higher utility than Q(X * | D).Therefore, given that the expected reward of the entire batch can be decomposed using (4), choosing any experiment x * ∈ X * is equivalent to solving the following optimization:
x * ∈ arg max x B(x | D) where B(x | D) = E y [u(y | x, D)] + max X :|X |=T −1 E y Q X | D ∪ {(x, y)} .(6)
Comparing (6) and the Bellman equation (1), we see two differences: 1) the expectation and maximization are exchanged in the future utility term and 2) the adaptive utility is replaced by a non-adaptive counterpart.As such, (6) is clearly a lower bound of the true expected utility: max
X :|X |=T −1 E y Q X | D ∪ {(x, y)} ≤ E y max X :|X |=T −1 Q X | D ∪ {(x, y)} ≤ E y max x Q T −1 x | D ∪ {(x, y)} . (7)
This is illustrated in Fig. 1(d): 2-step-EI corresponds to (1), and 2-EI to ( 6).An interesting open question is the tightness of this bound, closely related to the so-called adaptivity gap (Jiang et al., 2018;Krause and Guestrin, 2007).The similarity between these formulations provides mathematical justification for using (6) to approximate the optimal policy.Note that (6) is exactly equal to (1) if the remaining experiments become conditionally independent given the observed data, in which case there is no advantage to adaptation.</p>
<p>BINOCULARS is summarized in Algorithm 1.The primary computational cost comes from computing the optimal batch, a high-dimensional optimization problem.For the examples considered below (BO and BQ), this optimization can be done using gradient-based methods and we show empirically that BINOCULARS runs much faster than previously proposed nonmyopic methods (see section 6).Note that while we do use a batch method, it is only as a subroutine.Algorithm 1 is for sequential experimental design: in each iteration, we only observe the outcome of one experiment.</p>
<p>BINOCULARS for Bayesian Optimization</p>
<p>Consider the task: x * = arg max x∈X f (x); in this paper, we model f with a GP.Suppose we have a budget of T function evaluations.Once the budget has been expended, we recommend the point with the highest observed value as the maximizer of f .In this setting, our goal is to sequentially select a set X = {x 1 , x 2 , . . ., x T } of T points from X such that max{y j } is maximized, where y j = f (x j ).</p>
<p>Let D 0 be a set of initial observations, and y 0 = max (x,y)∈D0 y is the initial best observed value.We define the utility function as the improvement over y 0 :
u(Y | X, D 0 ) = max xj ∈X y j − y 0 + ,(8)
where c + = max(c, 0).Defining the utility as improvement allows us to write the expected utility as a Bellman equation with the same form as (1) (derivation in the appendix):
EI k (x) = EI 1 (x) + E y [max x EI k−1 (x | x, y)] ,(9)
where EI k (x) is the expected improvement of k adaptive decisions starting from x, and EI k−1 (x | x, y) is an expectation taken over the posterior belief of f after further conditioning on the observation (x, y) and replacing y 0 by max(y 0 , y).Observe that arg max x EI 1 (x) exactly corresponds to the popular expected improvement (EI) policy (Močkus, 1974), which is one-step optimal; EI 2 (x) is already analytically intractable as it requires an expensive numerical integration: the integrand is max x EI 1 (x | x, y) and entails global optimization!</p>
<p>To apply BINOCULARS, we optimize the batch EI objective, also known as q-EI, via the recently developed reparameterization trick and Monte Carlo approximation (Wang et al., 2016).Then we pick a point from the optimal batch; how to pick this point is discussed later.BINOCULARS trivially extends to other utility functions such as knowledge gradient (Wu and Frazier, 2016), probability of improvement (Kushner, 1964) and predictive entropy (Shah and Ghahramani, 2015) by replacing q-EI appropriately.</p>
<p>BINOCULARS for Bayesian Quadrature</p>
<p>Consider a non-analytic integral of the form Z = f (x)π(x) dx, where f (x) is a likelihood function and π(x) is a prior.Such integrals frequently occur in Bayesian inference (e.g., Bayesian model selection and averaging).Bayesian quadrature operates by placing a GP on the integrand and then minimizing the posterior variance of Z:
Var[Z | X] = K X (x, x )π(x)π(x ) dx dx ,(10)
where X = {x 1 , x 2 , . . ., x T } is a set of T points that needs to be optimized, and K X (x, x ) is the posterior covariance after conditioning on observations at X.If the GP hyperparameters are fixed, the optimal design X * = argmin X Var[Z | X] can be precomputed, as the posterior covariance of a GP does not depend on the observed values f (X); this effectively eliminates the need for sequential experimental design in this setting.</p>
<p>However, in general the hyperparameters are not fixed a priori, but are instead learned iteratively in light of new observations.Furthermore, when the integrand is known to be positive (e.g., a likelihood function), it is often a good practice to place a GP on some non-linear transformation of f , such as √ f or log(f ) (Osborne et al., 2012;Gunter et al., 2014;Chai and Garnett, 2019).As a result, the posterior GP must be approximated (e.g., by moment matching), which causes the posterior covariance to depend on the observed values.In these cases adaptive sampling becomes critical.</p>
<p>The adaptive version of Var[Z | X] is computationally expensive to evaluate so Gunter et al. (2014) proposed the use of uncertainty sampling (UNCT) (Lewis and Gale, 1994;Settles, 2010) as a surrogate, i.e. sequentially evaluating the location with the largest variance.This greedily minimizes the entropy of the integrand instead of the integral.</p>
<p>Formally, we use the differential entropy of the multivariate Gaussian f (X) as the utility function:
H(Y | X) = 1 2 log det 2πe K(X, X) . (11)
Using the chain rule for differential entropy, this quantity can be expressed in the same form as (1):
H(Y | X) = H(y j | x j ) + E yj [H(Y −j |X −j , x j , y j )].
(12) Note that arg max xj H(y j | x j ) corresponds to the sequential uncertainty sampling policy.To apply BINOCULARS for BQ, we must find arg max X H(Y | X), which is the mode of a determinantal point process (DPP) (Kulesza and Taskar, 2012) defined over q = |X| points.This can be done using gradient-based optimization.Note that this formulation can be applied to active learning of GPs, where uncertainty sampling is also a common strategy.</p>
<p>Practical Considerations.Some practical issues arise when applying BINOCULARS to real problems.First, given an optimal batch, how should one go about selecting a point from this batch?We considered several options: selecting the point with the highest expected immediate reward or randomly selecting a point, either proportional to their expected immediate reward or simply uniformly.Empirically, we found that "best" and "proportional sampling" perform similarly while "uniform sampling" is worse than the other two methods.</p>
<p>Second, given that BINOCULARS is only an approximation to the optimal policy, it is not necessarily true that setting q to the exact remaining budget is the best.In theory, if the model is perfect, then full lookahead is optimal.However, in practice, the model is always wrong and thus planning too far ahead could hurt the empirical performance (Yue and Al Kontar, 2019).Further, smaller values of q result in more efficient computation.We empirically study the choice of q in section 6.</p>
<p>Related Work</p>
<p>General introductions to approximate dynamic programming (DP) can be found in Bertsekas (2017); Powell (2010).On the subject of nonmyopic BO, Osborne et al. (2009) derived the optimal policy for BO, and demonstrate that it is possible to approximately compute (with great effort) the two-step lookahead policy for low-dimensional functions and that it generally performs better than the one-step policy.Ginsbourger and Le Riche (2010) also derived the optimal policy and gave an explicit example where two-step EI is better than one-step EI in expectation with a desired degree of statistical significance.González et al. (2016b) proposed a nonmyopic approximation of the optimal policy, known as GLASSES, by simulating future decisions using a batch BO method. 1 Jiang et al. (2017; 2018) proposed a nonmyopic policy for (batch) active search, which can be understood as a special case of BO with cumulative reward, using a similar idea.Lam et al. (2016) proposed to use rollout for BO, which is a classic approximate DP method (Bertsekas, 2017).Yue and Al Kontar (2019) presented theoretical justification for rollout, and gave theoretical and practical guidance on how to choose the rollout horizon.Ling et al. ( 2016) proposed a branch-and-bound near-optimal policy for GP planning assuming that the reward function is Lipschitz continuous, and applied it to BO and active learning.Wu and Frazier (2019) proposed a gradient-based optimization of two-step EI, but each evaluation of two-step EI still requires a quadrature subroutine with an expensive integrand: optimization of one-step EI.</p>
<p>Of these, GLASSES and rollout are most related to BINOC-ULARS.GLASSES's acquisition function shares almost the same form as (6), except the future batch X is constructed using a heuristic batch policy, instead of optimized with the q-EI objective.The batch policy adds points one by one by optimizing the sequential EI function penalized at locations already added to the batch (González et al., 2016a), and the expected utility of the chosen batch is estimated using expectation propagation.</p>
<p>Rolling out two steps using EI as the heuristic policy is exactly equivalent to the two-step lookahead policy, up to quadrature error.Mathematically, the rollout acquisition function can also be written in a similar form as (6), except X is adaptively constructed, depending on sampled values of y instead of globally (irrespective of y) constructed or optimized as in GLASSES and BINOCULARS.Both rollout and GLASSES are very expensive to compute.</p>
<p>While we are unaware of any existing work on nonmyopic BQ, there has been some prior work on nonmyopic active learning of GPs.Krause and Guestrin (2007) derived the adaptivity gap for active learning of GPs under two utility functions.They also proposed a nonmyopic method for active learning of GPs which separates the process into an exploration phase and an exploitation phase.They considered different acquisition functions for the exploration phase; notably, the implicit exploration (IE) method is comparable to the uncertainty sampling baseline in subsection 6.2.Hoang et al. (2014) developed a method for active 1 The name BINOCULARS is inspired by GLASSES.learning of GPs that does away with separate exploration and exploitation phases and instead naturally trades off between the two.Their proposed policy, ε-BAL, approximates the solution to the Bellman formulation of the active GP learning problem using a truncated sampling method.They analyzed the theoretical performance of their method and also developed a pruning-based anytime version of their method.</p>
<p>The setting of our BQ work (integration of non-negative integrands) and active learning of GPs appear related yet are fundamentally different.The cited works focus exclusively on learning the hyperparameters of the GP.In our setting, the use of a transformation to model non-negativity introduces adaptivity beyond the GP hyperparameters: even if the true GP hyperparameters are known a priori, the nonlinear transformation causes the approximate GP posterior to depend on the observed values.</p>
<p>Experiments</p>
<p>We designed our experiments to broadly test the performance and computational cost of BINOCULARS relative to notable myopic and nonmyopic baselines for BO and BQ.We also conducted a thorough exploration of the BINOCU-LARS design choices: the number of steps to look ahead and how to select a point from the optimal batch.The primary takeaways of our experimental results are that BINOCULARS outperforms myopic baselines while running only slightly slower and is at least as good as previously proposed nonmyopic methods while running orders of magnitude faster.This places it on the Pareto front of the running time-performance tradeoff in policy design.Furthermore, BINOCULARS clearly demonstrates distinctively nonmyopic behavior on both BO and BQ tasks, two entirely different SED problems.</p>
<p>We use the following nomenclature to describe BINOCU-LARS: our nonmyopic BO method will be denoted as "q.EI.s" or "q.EI.b",where q is the batch size and "s" represents sampling from the batch while "b" means choosing the "best."For BQ, we replace "EI" with "DPP."In addition to the myopic methods, EI and UNCT, we also compare against rollout for both tasks and GLASSES for BO.2Each rollout method is denoted as "q.R.n", where q represents the number of steps to roll out, and n is the number of samples used to estimate the expectations encountered in each step.Each GLASSES method is denoted as "q.G" where q represents the size of the simulated batch.We use DIRECT (Jones, 2009) to optimize the GLASSES and rollout acquisition functions, following González et al. (2016b).For all nonmyopic methods, when the remaining budget r &lt; q, we set q = r.Thus For all experiments, we start with 2d randomly-sampled observations and perform 20d further iterations, where d is the function's dimensionality.Unless otherwise noted, all results presented are aggregated over 100 repeats with different random initializations.For all tabulated results, the best method is indicated in bold and the entries not significantly worse than the best (under a one-sided paired Wilcoxon signed-rank test with α = 0.05) are in blue italics.</p>
<p>BO Results</p>
<p>We implemented our nonmyopic BO policy and all baselines using BoTorch,3 which contains efficient EI and q-EI implementations.We present experiments for two rollout variants: "2.R.10" and "3.R.3."As we will see, rolling out with horizon two is already very expensive even for just ten y samples.Gauss-Hermite quadrature is used for rollout as in Lam et al. (2016).We also present experiments for two GLASSES variants: "2.G" and "3.G". 4e use GPs with a constant mean and a Matérn5 /2 ARD kernel to model the objective function, the default in BoTorch.</p>
<p>We tune hyperparameters every iteration by maximizing the marginal likelihood using L-BFGS-B.We also maximize the q-EI acquisition function with L-BFGS-B.Complete details can be found in our attached code.We use the GAP measure to evaluate the performance: GAP = (y i − y 0 ) / (y * − y 0 ), where y i 's are maximum observed values and y * is the true optimal value; we convert all problems to maximization problems by negating if necessary.</p>
<p>Synthetic Functions.In this section, we focus on demonstrating the superior performance of our method over EI on nine "hard" benchmark functions.These nine functions are  selected by first running experiments on 31 functions 5 with 30 repeats (see Table 4 in appendix).We then select the ones where EI terminates with average GAP &lt; 0.9.We believe nonmyopic methods are more advantageous on challenging functions; by first identifying these hard problems, we will gain more insight into the various policies.To put the BO performance into perspective, we also include a comparison against a random baseline, "Rand."</p>
<p>Table 1 shows the average GAP at termination.We summarize the results as follows: (1) All q.EI.s variants perform significantly better than EI on average, with 12.EI.sbeing the best and outperforming EI by a large margin.(2) The q.EI.s variants are consistently better than the q.EI.b variants (for better spacing we did not show results for 12.EI.band 15.EI.b).(3) The performance of our method generally improves as we increase q, up to 12.</p>
<p>Perhaps more interestingly, we can clearly observe the nonmyopic behavior of 12.EI.sas shown in Figure 2: it is initially outperformed by the myopic EI as it explores the space.However, our method catches up to EI at ∼20% of the bud- get (on average) as it transitions to exploiting its findings until finally, it outperforms EI by a large margin.This behavior indicates that our method seamlessly navigates the exploration/exploitation tradeoff without the need for any external intervention.</p>
<p>Real World Functions.In this section, we compare our method against popular nonmyopic baselines: rollout and GLASSES.We present results on hyperparameter tuning functions used by Snoek et al. (2012); Wang and Jegelka (2017); Malkomes and Garnett (2018).These functions are evaluated on a predefined grid, so we first compute all policies (except EI) using continuous optimization, then pick the closest point from the grid.</p>
<p>Table 2 shows the results averaged over 50 repeats.We only show the "sampling" variants of our method; full results can be found in Table 6 First we see again all q.EI.s variants outperform EI by a large margin, with q = 6 achieving the best results.Comparing 6.EI.s with the nonmyopic baselines, 2.G is the best, but the difference of 0.005 is negligible; the p-value under a one-sided paired signed-rank test for 6.EI.s against 2.G is 0.4257.</p>
<p>We now focus on comparing the time cost of the tested methods.Figure 3 shows the average GAP versus average time per iteration; the average is taken over 350 experiments (seven functions with 50 repeats each); error bars are also plotted.We again see that our methods are not significantly different from rollout and GLASSES in terms of GAP performance, but are considerably faster in terms of average time cost per iteration (note the log scale on the time axis).</p>
<p>Clearly, our method lies on the Pareto front in terms of computational cost and performance.</p>
<p>We also attempted to compare with the recently published practical two-step EI method (Wu and Frazier, 2019), which is intended to be a more efficient version of our 2.R.n.As far as we understand, the difference is first-versus zerothorder optimization of the acquisition function.In fact, our implementation of rollout already supports gradient-based optimization thanks to automatic differentiation.However, we did not find it considerably faster than using DIRECT.</p>
<p>We leave it to future work to optimize the implementation  It is also possible to further improve rollout's performance using an adaptive rolling horizon in light of a recent study (Yue and Al Kontar, 2019), but it would be even more expensive to compute.In fact, Figure 1 in (Yue and Al Kontar, 2019) shows that with their adaptive horizon approach, the most frequently chosen horizon was two.</p>
<p>BQ Results</p>
<p>We implemented our nonmyopic BQ policy and all baselines using the GPML MATLAB package. 6For all BQ experiments, we use the framework of Chai and Garnett (2019): we place GP priors on the log of the integrands as they are all nonnegative.We use GPs with a constant mean and a Matérn 3 /2 ARD kernel to model the integrands.We tune the GP hyperparameters after each observation by maximizing the marginal likelihood using L-BFGS-B.We also use L-BFGS-B to maximize the DPP likelihood.Complete details of our implementation can be found in our attached code.</p>
<p>We perform experiments on five standard benchmark syn-6 http://gaussianprocess.org/gpml/code/matlab  thetic functions7 as well as one additional synthetic benchmark and two real model likelihood functions used by Chai et al. (2019).The additional synthetic benchmark is:
f (x) = d i=1 sin(xi)+ cos(3x i )) 2 /2
x 2 i/4+0.3</p>
<p>; this function was included because of its multi-modal (MM) nature.We evaluate the performance of all methods using their fractional error: |Z − Ẑ|/Z where Ẑ is the estimate of the integral.</p>
<p>Figure 4(a) indicates that 2.DPP.sexhibits the same nonmyopic behavior as 12.EI.s: it initially lags behind but eventually overtakes the myopic UNCT, again suggesting a superior and automatic tradeoff of exploration and exploitation.</p>
<p>Figure 4(c) shows the median fractional error versus average time per iteration; the average is taken over all 800 BQ experiments.Our method, 2.DPP.s,significantly outperforms all other tested methods, is considerably faster than rollout and only slightly slower than UNCT.</p>
<p>Table 3 shows the median fractional error at termination for all BQ experiments.Fig. 4 shows the convergence of the fractional error as a function of both iterations and time (in log scale).These results corroborate many of the findings from our BO experiments: (1) All nonmyopic methods outperform UNCT on average.(2) Our proposed nonmyopic methods are competitive with, if not better than, rollout while running orders of magnitude faster.</p>
<p>We also note that in general, q.DPP.svariants tend to outperform q.DPP.bvariants and increasing the batch size q does not consistently improve the performance.</p>
<p>The primary conclusion here is the same as for BO: BINOC-ULARS significantly and consistently outperforms myopic policies while only slightly increasing computational cost.</p>
<p>Conclusion and Future Work</p>
<p>We proposed BINOCULARS: an efficient, nonmyopic approximation framework for finite-horizon sequential experimental design.BINOCULARS computes an optimal batch, then picks a point from the batch.We gave an intuitive understanding and a mathematical justification for why this is a good approximation.We applied BINOCULARS to Bayesian optimization and Bayesian quadrature, two entirely different problems, and empirically demonstrated that it significantly outperforms commonly used myopic policies while being much more efficient than popular nonmyopic alternatives.</p>
<p>As suggested by Yue and Al Kontar (2019), it would be useful to derive theories to guide the choice of lookahead horizon q for our method.Another interesting theoretical question is whether we can provide explicit bounds for the adaptivity gap for a general class of problems.</p>
<p>Algorithm 1 BINOCULARS Input: design space X , response space Y, model p(y | x, D), utility function u(y | x, D), budget T Output: D, a sequence of experiments and observations for i ← 0 to T − 1 do Compute the optimal batch X * of size T − i Pick an experiment x * ∈ X * and observe response y * Augment D = D ∪ {(x * , y * )}</p>
<p>Figure 2 :
2
Figure 2: Average GAP over nine synthetic functions demonstrating the nonmyopic behavior of 12.EI.s.</p>
<p>Figure 3 :
3
Figure 3: mean GAP with error bars at termination versus time per iteration (in log scale) averaged over the seven real functions.</p>
<p>Figure 4 :
4
Figure 4: Median fractional error over 100 repeats against iterations or time.(a) synthetic functions, (b) real functions, (c) all functions</p>
<p>Table 1 :
1
Average GAP over 100 repeats on "hard" synthetic functions.
Rand EI2.EI.b 2.EI.s 3.EI.b 3.EI.s 4.EI.b 4.EI.s10.EI.b 10.EI.s 12.EI.s 15.EI.seggholder 0.498 0.6130.6140.6330.6040.6570.6460.6940.6220.7040.7380.694dropwave 0.486 0.4390.5070.5310.4730.5520.4670.5140.3970.5910.5980.585shubert0.355 0.4080.3660.4410.3940.5070.3880.4840.3050.4550.4790.465rastrigin4 0.374 0.8010.7690.7750.8170.8210.8400.8050.7970.8040.7930.799ackley20.358 0.8210.8250.8230.8190.8690.8120.8720.8010.8920.8860.888ackley50.145 0.5090.5440.5090.6010.5500.5960.5920.6360.6060.6270.626bukin0.600 0.8490.8560.8550.8720.8590.8640.8650.8780.8500.8290.853shekel50.038 0.2860.3110.3200.3300.3430.3420.3440.3740.3730.3580.395shekel70.045 0.2680.3460.3130.3490.3250.3520.3700.3990.3580.4120.386Average0.322 0.5550.5710.5780.5840.6090.5900.6160.5790.6260.6350.632the final decision is always made (optimally) with one-steplookahead.</p>
<p>Table 2 :
2
Average GAP over 50 repeats on real functions.
EI2.EI.s3.EI.s 4.EI.s 6.EI.s8.EI.s 2.G3.G2.R.10 3.R.3SVM0.7380.9130.9400.9110.9370.8340.8810.8980.9300.928LDA0.9561.0000.9960.9930.9820.9951.0000.9990.9991.000LogReg0.9630.9981.0000.9990.9991.0000.9890.9110.9650.948NN Boston0.4700.4670.4780.4600.5020.4670.4550.5120.5030.482NN Cancer0.6650.6270.6540.6860.7000.6860.8060.7550.7080.698Robot pushing 3d 0.9280.9600.9620.9570.9620.9610.9550.9510.9550.954Robot pushing 4d 0.7300.7260.6950.6950.7360.6970.7650.7860.7700.745Average0.7790.8130.8180.8150.8310.8060.8360.8300.8330.822</p>
<p>Table 3 :
3
Median fractional error values over 100 repeats on all BQ functions.
UNCT 2.DPP.b 3.DPP.b 10.DPP.b 2.DPP.s 3.DPP.s 10.DPP.s 2.R.10 3.R.3cont0.0450.0520.0550.0590.0390.0370.0290.0360.045corner0.2650.2060.1370.0650.0470.0780.1320.0740.063discont0.5230.5110.4880.4460.5720.6100.5900.5370.577Gauss0.0040.0040.0050.0060.0030.0030.0030.0040.003MM0.2540.2070.2030.2070.2210.1610.1770.1100.086prod0.0070.0070.0070.0070.0070.0060.0060.0120.012GP0.2310.0820.0570.0770.0690.0730.1160.2830.248DLA0.0190.0130.0250.0130.0160.0160.0330.0190.011Average 0.0680.0560.0550.0410.0370.0430.0550.0490.0510.1 0.2 0.3 0.5 0.4 fractional errorUNCT 2.DPP.s0.1 0.3 0.2 fractional errorUNCT 2.DPP.b 10.DPP.b 3.R.30.04 0.1 0.08 0.06 fractional error2.DPP.s UNCT 10.DPP.s3.R.30.2 normalized iteration number 0.4 0.6 0.81.00.2 normalized iteration number 0.4 0.6 0.81.00.021s1min 3min 10min log2(time/iter)(a)(b)(c)</p>
<p>Table 4 :
4
Average GAP of 30 repeats on all 31 synthetic functions.EI 2.EI.b 2.EI.s 3.EI.b3.EI.s4.EI.b4.EI.s5.EI.b 5.EI.s 10.EI.b 10.EI.
s</p>
<p>Table 5 :
5
Average GAP of 100 repeats on all the five "hard" synthetic.
Rand EI2.EI.s 3.EI.s 4.EI.s10.EI.s 12.EI.s 2.G3.G2.R.10 3.R.3eggholder 0.498 0.6130.6330.6570.6940.7040.7380.583 0.563 0.5690.518shubert0.355 0.4080.4410.5070.4840.4550.4790.302 0.254 0.2710.297bukin0.600 0.8490.8550.8590.8650.8500.8290.829 0.811 0.7720.762shekel50.038 0.2860.3200.3430.3440.3730.3580.265 0.175 0.3780.350shekel70.045 0.2680.3130.3250.3700.3580.4120.256 0.174 0.3760.361Average0.307 0.4850.5120.5380.5510.5480.5630.447 0.395 0.4730.458</p>
<p>Table 6 :
6
Average GAP of 50 repeats on real functions for all q.EI variants.
EI2.EI.b 2.EI.s 3.EI.b 3.EI.s4.EI.b 4.EI.s 6.EI.b 6.EI.s 8.EI.b 8.EI.sSVM0.7380.9260.9130.9300.9400.9140.9110.8920.9370.9290.834LDA0.9561.0001.0000.9980.9960.9960.9930.9990.9820.9950.995LogReg0.9631.0000.9980.9991.0000.9990.9991.0000.9991.0001.000NN Boston 0.4700.4910.4670.4900.4780.4950.4600.4600.5020.4550.467NN Cancer 0.6650.6520.6270.6250.6540.6400.6860.6250.7000.6090.686Robot3d0.9280.9590.9600.9440.9620.9560.9570.9600.9620.9670.961Robot4d0.7300.7250.7260.7200.6950.7640.6950.7600.7360.7320.697Average0.7790.8210.8130.8150.8180.8230.8150.8130.8310.8120.806
We did not compare against a BQ-equivalent of GLASSES as no such method has been published.
https://github.com/pytorch/botorch
With help from the authors of(González et al., 2016b), we implemented an advanced version of GLASSES in BoTorch, using quasi Monte Carlo instead of expectation propagation to estimate the expected improvement of the batch, a standard practice for computing qEI in state of the art BO packages such as BoTorch.
https://www.sfu.ca/~ssurjano/ optimization.html
https://www.sfu.ca/~ssurjano/ integration.html
AcknowledgementThanks to Eytan Bakshy and Maximilian Balandat for helping with using the BoTorch package before its release.A. Full-Lookahead Expected Improvement as Bellman EquationWhen T = 1, i.e., there is only one evaluation left, the optimal policy degenerates to the simplest case known as expected improvement (EI):x * = arg maxNow consider T = 2. Starting from location x, the improvement of the next two evaluations depends on three random variables: y ≡ f (x), the next evaluation location x , and its value y ≡ f (x ); computing the expected utility of starting from x requires integrating all three variables out:Given (max{y, y } − y 0 ) + = (y − y 0 ) + + (y − max(y 0 , y))+(Ginsbourger et al., 2010), we haveBy Bellman's principle of optimality, we haveand henceIn general, we have the following Bellman equation for k-step expected utilityB. Additional Bayesian Optimization ResultsIn the main paper, we presented BO results for nine synthetic functions.These nine functions are selected from the 31 functions shown in Table4, with GAP of EI less than 0.9.We only run up to 10.EI for all functions, so 12.EI.sand 15.EI.s are not shown.We argue that by identifying this set of "hard" functions, we are able to consistently see the advantage of nonmyopic BO methods.In Table4, we can see all variants of our method perform better than EI on average, but other interesting patterns are weak, possibly because they are averaged out by the "easy" functions.Table5includes results of rollout and GLASSES on five synthetic functions, after removing four from the nine for which the optima are located in the center of the domain.We remove these functions because the DIRECT optimization procedure used in our implementations of rollout and GLASSES always starts evaluating exactly at the center of the domain.Thus the performance of these methods on benchmarks where the global optimum just happens to be in the center is artificially inflated.This artifact was also pointed out inLam et al. (2016);Wu and Frazier (2019)also excluded such results because of this.We surprisingly see rollout and GLASSES perform even worse than EI on average for these five functions.This is an indicator that the synthetic benchmark functions are very different than the real-world functions.Note that Malkomes and Garnett (2018) also observed significantly different results on synthetic and real functions in their unrelated BO experiments.Table6shows the average results of 50 repeats of EI and both "sampling" and "best" variants of q.EI on the real world functions.Different from the results on synthetic functions, we do not see "sampling" being consistently better than "best" or the other way around.
Dynamic programming and optimal control. Dimitri P Bertsekas, Athena scientific. 12017</p>
<p>Improving quadrature for constrained integrands. Henry Chai, Roman Garnett, Proceedings of the 22nd International Conference on Artificial Intelligence and Statistics (AISTATS). the 22nd International Conference on Artificial Intelligence and Statistics (AISTATS)2019</p>
<p>Automated model selection with Bayesian quadrature. Henry Chai, Jean-François Ton, Michael A Osborne, Roman Garnett, Proceedings of the 36th International Conference on Machine Learning (ICML). the 36th International Conference on Machine Learning (ICML)2019</p>
<p>Parallelizing exploration-exploitation tradeoffs in Gaussian process bandit optimization. Thomas Desautels, Andreas Krause, Joel W Burdick, Journal of Machine Learning Research. 152014</p>
<p>Bayesian numerical analysis. Statistical Decision Theory and Related Topics. Persi Diaconis, 19884</p>
<p>Towards Gaussian process-based optimization with finite time horizon. David Ginsbourger, Rodolphe Le Riche, Advances in Model-Oriented Design and Analysis (MODA) 9. 2010</p>
<p>Kriging is well-suited to parallelize optimization. David Ginsbourger, Computational Intelligence in Expensive Optimization Problems. 2010Rodolphe Le Riche, and Laurent Carraro</p>
<p>Batch Bayesian optimization via local penalization. Javier González, Zhenwen Dai, Philipp Hennig, Neil Lawrence, Proceedings of the 19th International Conference on Artificial Intelligence and Statistics (AISTATS). the 19th International Conference on Artificial Intelligence and Statistics (AISTATS)2016a</p>
<p>GLASSES: Relieving the myopia of Bayesian optimisation. Javier González, Michael Osborne, Neil D Lawrence, Proceedings of the 19th International Conference on Artificial Intelligence and Statistics (AISTATS). the 19th International Conference on Artificial Intelligence and Statistics (AISTATS)2016b</p>
<p>Sampling for inference in probabilistic models with fast Bayesian quadrature. Tom Gunter, Michael A Osborne, Roman Garnett, Philipp Hennig, Stephen J Roberts, Advances in Neural Information Processing Systems (NEURIPS). 201427</p>
<p>Nonmyopic -Bayes-optimal active learning of Gaussian processes. Trong Nghia Hoang, Kian Hsiang Low, Patrick Jaillet, Mohan Kankanhalli, Proceedings of the 31st International Conference on Machine Learning (ICML). Alyssa Shofner, Benjamin Moseley, Roman Garnett, the 31st International Conference on Machine Learning (ICML)2014. 2017Proceedings of the 34th International Conference on Machine Learning (ICML)</p>
<p>Efficient nonmyopic batch active search. Shali Jiang, Gustavo Malkomes, Matthew Abbott, Benjamin Moseley, Roman Garnett, Advances in Neural Information Processing Systems (NEURIPS). 201831</p>
<p>Direct global optimization algorithm. R Donald, Jones, Encyclopedia of optimization. 2009</p>
<p>Nonmyopic active learning of Gaussian processes: an explorationexploitation approach. Andreas Krause, Carlos Guestrin, Proceedings of the 24th International Conference on Machine Learning (ICML). the 24th International Conference on Machine Learning (ICML)2007</p>
<p>Determinantal point processes for machine learning. Alex Kulesza, Ben Taskar, Foundations and Trends in Machine Learning. 20125</p>
<p>A new method of locating the maximum point of an arbitrary multipeak curve in the presence of noise. Harold Joseph, Kushner , ASME. J. Basic Eng. 8611964</p>
<p>Bayesian optimization with a finite budget: an approximate dynamic programming approach. Remi Lam, Karen Willcox, David H Wolpert, Advances in Neural Information Processing Systems (NEURIPS). 201629</p>
<p>Gaussian measure in Hilbert space and applications in numerical analysis. F M Larkin, Rocky Mountain Journal of Mathematics. 231972</p>
<p>A sequential algorithm for training text classifiers. David D Lewis, William A Gale, Proceedings of the 17th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval. the 17th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval1994</p>
<p>Gaussian process planning with Lipschitz continuous reward functions: towards unifying Bayesian optimization, active learning, and beyond. Chun Kai, Ling , Kian Hsiang Low, Patrick Jaillet, Thirtieth AAAI Conference on Artificial Intelligence. 2016</p>
<p>Automating Bayesian optimization with Bayesian optimization. Gustavo Malkomes, Roman Garnett, Advances in Neural Information Processing Systems (NEURIPS). 201831</p>
<p>On Bayesian methods for seeking the extremum. Jonas Močkus, Optimization Techniques IFIP Technical Conference. Springer1974</p>
<p>Bayes-Hermite quadrature. O' Anthony, Hagan, Journal of Statistical Planning and Inference. 291991</p>
<p>Gaussian processes for global optimization. Roman Michael A Osborne, Stephen J Garnett, Roberts, The 3rd International Conference on Learning and Intelligent Optimization (LION3). 2009</p>
<p>Active learning of model evidence using Bayesian quadrature. Michael A Osborne, Roman Garnett, Zoubin Ghahramani, David Duvenaud, Stephen J Roberts, Carl E Rasmussen, Advances in Neural Information Processing Systems (NEURIPS). 201225</p>
<p>Approximate Dynamic Programming: Solving the Curses of Dimensionality. Warren B Powell, Wiley Series in Probability and Statistics. John Wiley &amp; Sons20102 edition</p>
<p>Carl E Rasmussen, K I Christopher, Williams, Gaussian Processes for Machine Learning. Press2006</p>
<p>Active learning literature survey. Burr Settles, July 2010Technical report</p>
<p>Parallel predictive entropy search for batch global optimization of expensive objective functions. Amar Shah, Zoubin Ghahramani, Advances in Neural Information Processing Systems (NEURIPS). 201528</p>
<p>Taking the human out of the loop: a review of Bayesian optimization. Proceedings of the IEEE. Bobak Shahriari, Kevin Swersky, Ziyu Wang, Ryan P Adams, Nando De Freitas, Jan 2016104</p>
<p>Practical Bayesian optimization of machine learning algorithms. Jasper Snoek, Hugo Larochelle, Ryan P Adams, Advances in Neural Information Processing Systems (NEURIPS) 25. 2012</p>
<p>Jialei Wang, Scott C Clark, Eric Liu, Peter I Frazier, arXiv:1602.05149Parallel Bayesian global optimization of expensive functions. 2016arXiv preprint</p>
<p>Max-value entropy search for efficient Bayesian optimization. Zi Wang, Stefanie Jegelka, International Conference on Machine Learning (ICML). 2017</p>
<p>The parallel knowledge gradient method for batch Bayesian optimization. Jian Wu, Peter Frazier, Advances in Neural Information Processing Systems (NEURIPS). 201629</p>
<p>Practical two-step lookahead Bayesian optimization. Jian Wu, Peter Frazier, Advances in Neural Information Processing Systems (NEURIPS). 201932</p>
<p>Why non-myopic Bayesian optimization is promising and how far should we lookahead? A study via rollout. arXiv. Xubo Yue, Raed Al Kontar, 2019Accepted to AISTATS 2020</p>            </div>
        </div>

    </div>
</body>
</html>