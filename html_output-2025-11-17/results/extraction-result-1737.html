<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1737 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1737</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1737</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-31.html">extraction-schema-31</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <p><strong>Paper ID:</strong> paper-2b108cfc37f9db2b5ab0b71dcc46c73be698a259</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/2b108cfc37f9db2b5ab0b71dcc46c73be698a259" target="_blank">Learning Behavior Trees with Genetic Programming in Unpredictable Environments</a></p>
                <p><strong>Paper Venue:</strong> IEEE International Conference on Robotics and Automation</p>
                <p><strong>Paper TL;DR:</strong> It is shown that genetic programming can be effectively used to learn the structure of a behavior tree to solve a robotic task in an unpredictable environment, and that the learned BTs can solve the same task in a realistic simulator, converging without the need for task specific heuristics.</p>
                <p><strong>Paper Abstract:</strong> Modern industrial applications require robots to operate in unpredictable environments, and programs to be created with a minimal effort, to accommodate frequent changes to the task. Here, we show that genetic programming can be effectively used to learn the structure of a behavior tree (BT) to solve a robotic task in an unpredictable environment. We propose to use a simple simulator for learning, and demonstrate that the learned BTs can solve the same task in a realistic simulator, converging without the need for task specific heuristics, making our method appealing for real robotic applications.</p>
                <p><strong>Cost:</strong> 0.012</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1737.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1737.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GP-BT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Genetic Programming for Behavior Trees</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A genetic programming system that evolves Behavior Trees (BTs) to produce fault-tolerant, reactive robot policies; individuals are BTs composed from a primitive pool of control nodes (Sequence, Fallback) and leaf nodes (Actions, Conditions).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Genetic Programming for Behavior Trees (GP-BT)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Population-based GP where each individual is a Behavior Tree encoded as a parenthesis-delimited string mapped to a BT; the primitive set contains BT control-node functions (Sequence, Fallback) and terminals (actions and conditions). The GP evolves the population with tournament selection, elitism, subtree crossover and three mutation operators (node mutation, node addition, node deletion). Fitness is computed by simulating each BT in a fast state-machine simulator that models action outcomes (deterministic or probabilistic), then scoring according to a cost function combining task progress, tree size, execution time and estimated failure probability, with explicit rewards for subgoals (pick/place). The goal is to synthesise robust, reactive BTs for mobile-manipulation tasks in unpredictable environments while keeping evaluation computationally tractable via a simplified simulator.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>programs (Behavior Trees)</td>
                        </tr>
                        <tr>
                            <td><strong>crossover_operation</strong></td>
                            <td>Sub-tree swapping: two parent BTs (represented as strings with parentheses marking subtrees) are paired (tournament selection) and a subtree from parent A is swapped with a subtree from parent B to produce two offspring; crossover is repeated twice per parent pair while avoiding producing identical copies in offspring. This preserves BT structure and semantics because subtrees are valid BT fragments.</td>
                        </tr>
                        <tr>
                            <td><strong>mutation_operation</strong></td>
                            <td>Three mutation modes applied to individuals with specified probabilities: (1) Node mutation — replace a selected node with any node from the gene pool; (2) Node addition — insert a node from the gene pool at an arbitrary position/level in the tree; (3) Node deletion — remove a selected node. For node addition/mutation there is a 50% chance to choose a control node (to reflect expected BT composition). Global GP probabilities (from Table I): overall crossover 40%, mutation 60%; within mutation: node mutation 30%, node addition 40%, node deletion 30%.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_literature</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>uses_code</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_metric</strong></td>
                            <td>Fitness/cost function C used as the executability/functionality metric: C = f(s,b) + γ T + δ P, where f(s,b)=α ||s_d - s||^2 + β b (s encodes state distances: cube-goal, robot-cube, localization error; b is BT length), T is execution time, P is estimated cumulative failure probability of executed actions; rewards (negative cost) are added for subtask completion (pick reward = 50, place reward = 100). Task completion (binary success) and successful execution in the Gazebo physical simulator are also used to validate executability.</td>
                        </tr>
                        <tr>
                            <td><strong>executability_results</strong></td>
                            <td>Quantitative experimental outcomes reported include: convergence of GP to successful BTs required approx. 400,000 evaluation episodes (order-of-magnitude estimate reported); experiments averaged over 10 independent runs. Learned BTs from the simplified simulator were validated and executed successfully in the detailed Gazebo simulator. No explicit numeric success rate (%) or distribution of fitness values is reported in the paper text.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_executability_tradeoff</strong></td>
                            <td>The paper demonstrates an explicit tradeoff between risk (estimated failure probability) and execution time via the δ parameter in the fitness cost: increasing δ penalizes actions/paths with high failure probability, steering the GP to choose longer but safer MoveTo* actions. Empirically, setting δ from 0 to 150 caused learned BTs to prefer safer (longer) paths; increasing environmental uncertainty leads GP to produce larger trees with duplicated actions to raise overall success probability. This is presented qualitatively and supported by experiments (Figures 8–9).</td>
                        </tr>
                        <tr>
                            <td><strong>frontier_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_or_domain</strong></td>
                            <td>Robotic mobile-manipulation (pick-and-place) — behavior tree synthesis for navigation and manipulation in stochastic/unpredictable simulated environments.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Internal baselines across experiments: deterministic state-machine simulator vs. four stochastic variants (Stoch.1–Stoch.4 with increasing failure probabilities), noise levels (adding 3 or 27 irrelevant behaviors), and fitness weighting (δ=0 vs δ=150). No external algorithmic baselines (e.g., hand-coded BTs) were used in experiments, though related works (GE/GP variants) are discussed.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Subtree crossover is a natural and safe operator for BT programs, preserving semantics; allowing mutation to change node types (not restricting to same-type swaps) increases exploration/diversity; structural constraints (preventing identical control nodes consecutively, duplicate adjacent conditions, control nodes without children) avoid semantically-irrelevant/invalid trees. Under higher uncertainty GP tends to produce more complex BTs with repeated actions to raise success probability. GP is robust to added irrelevant actions (noise) and excludes unnecessary behaviors early. Penalizing estimated failure probability (via δ) produces safer but slower behaviors, demonstrating an explicit risk-vs-time tradeoff. Using a simplified state-machine simulator speeds up learning by orders of magnitude, making GP practical for this high-level policy search.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Learning Behavior Trees with Genetic Programming in Unpredictable Environments', 'publication_date_yy_mm': '2020-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1737.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e1737.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GE</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Grammatical Evolution</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An evolutionary approach that uses an explicit grammar (context-free grammar) to map genotypes to syntactically constrained programs; used in related work to evolve Behavior Trees for game agents and swarm tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Grammatical Evolution (GE)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>GE evolves integer/genotype sequences which are mapped to programs via a context-free grammar; it enforces syntactic constraints on output programs (e.g., Behavior Trees) but requires grammar engineering and domain knowledge, which can bias or overconstrain solutions.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>programs (Behavior Trees) via grammar mapping</td>
                        </tr>
                        <tr>
                            <td><strong>crossover_operation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>mutation_operation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_literature</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>uses_code</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_executability_tradeoff</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>frontier_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_or_domain</strong></td>
                            <td>Mentioned in the context of evolving BTs for Mario AI and swarm foraging tasks (references [10], [16]).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Discussed qualitatively versus free GP: GE requires grammar design and can lead to complex, hard-to-interpret BTs and risks of overfitting to domain-specific grammars.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Authors note in related work that GE enforces structure via a grammar but increases engineering effort and risk of overfitting; grammars can become complex for large BTs and may require ad hoc repairs to guarantee logical correctness.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Learning Behavior Trees with Genetic Programming in Unpredictable Environments', 'publication_date_yy_mm': '2020-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1737.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e1737.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GA</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Genetic Algorithm (parameter search variant)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A classical evolutionary algorithm using fixed-length genotypes (e.g., vectors of integers) typically used to tune parameters rather than full program structure; mentioned for comparison with GP.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Genetic Algorithm (parameter-based)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>GA variants represent solutions as fixed-length strings (e.g., integers) and evolve them with crossover/mutation operators; in the paper GA is referenced as the approach used when only program parameters are evolved rather than tree/program structure.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>program parameters (fixed-length genotype), not full program trees</td>
                        </tr>
                        <tr>
                            <td><strong>crossover_operation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>mutation_operation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_literature</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>uses_code</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_executability_tradeoff</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>frontier_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_or_domain</strong></td>
                            <td>Mentioned generally as an alternative approach where only parameters change (reference [6]).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared conceptually to GP: GA is suitable when genotype length is fixed and only parameters vary, whereas GP handles variable-sized program (tree) structures.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Paper cites GA as a contrasting method for evolving parameters but emphasizes GP's suitability for evolving the modular tree structure of BTs.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Learning Behavior Trees with Genetic Programming in Unpredictable Environments', 'publication_date_yy_mm': '2020-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1737.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e1737.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Constrained-GP</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Structural-constraint Genetic Programming (constrained GP)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>GP variants that impose structural/dynamic constraints on evolving trees (e.g., preventing invalid trees, protecting recurrent subtrees) to speed up learning and avoid invalid solutions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Constrained Genetic Programming (structural/dynamic constraints)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>GP implementations that apply constraints such as (i) preventing identical control node types on consecutive levels, (ii) enforcing conditions to appear on rightmost positions in subtrees, (iii) protecting recurrent subtrees from change, and (iv) preventing control nodes without children or duplicate adjacent condition nodes; these constraints reduce the generation of semantically meaningless or invalid trees and can improve learning speed.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>programs (Behavior Trees)</td>
                        </tr>
                        <tr>
                            <td><strong>crossover_operation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>mutation_operation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_literature</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>uses_code</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_executability_tradeoff</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>frontier_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_or_domain</strong></td>
                            <td>Referenced in related work on evolving BTs for games and agents (references [12],[13],[14]).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared qualitatively to unconstrained GP: constrained GP speeds up learning and avoids invalid/undesirable BTs but may reduce exploration if overconstrained.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Authors adopt some structural constraints from prior work to avoid semantically irrelevant BT structures, but deliberately do not constrain mutation to same-type node swaps (unlike some prior work) to increase diversity.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Learning Behavior Trees with Genetic Programming in Unpredictable Environments', 'publication_date_yy_mm': '2020-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Learning of Behavior Trees for Autonomous Agents <em>(Rating: 2)</em></li>
                <li>Evolving Behaviour Trees for the Mario AI Competition Using Grammatical Evolution <em>(Rating: 2)</em></li>
                <li>Evolutionary Behavior Tree Approaches for Navigating Platform Games <em>(Rating: 2)</em></li>
                <li>Behavior Modeling for Autonomous Agents Based on Modified Evolving Behavior Trees <em>(Rating: 2)</em></li>
                <li>Learning Behavior Trees using Grammatical Evolution and Behavior Trees <em>(Rating: 1)</em></li>
                <li>Performance analysis of stochastic behavior trees <em>(Rating: 2)</em></li>
                <li>Genetic programming: An introduction and tutorial, with a survey of techniques and applications <em>(Rating: 2)</em></li>
                <li>Evolving Swarm Behaviors using Grammatical Evolution and Behavior Trees <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1737",
    "paper_id": "paper-2b108cfc37f9db2b5ab0b71dcc46c73be698a259",
    "extraction_schema_id": "extraction-schema-31",
    "extracted_data": [
        {
            "name_short": "GP-BT",
            "name_full": "Genetic Programming for Behavior Trees",
            "brief_description": "A genetic programming system that evolves Behavior Trees (BTs) to produce fault-tolerant, reactive robot policies; individuals are BTs composed from a primitive pool of control nodes (Sequence, Fallback) and leaf nodes (Actions, Conditions).",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Genetic Programming for Behavior Trees (GP-BT)",
            "system_description": "Population-based GP where each individual is a Behavior Tree encoded as a parenthesis-delimited string mapped to a BT; the primitive set contains BT control-node functions (Sequence, Fallback) and terminals (actions and conditions). The GP evolves the population with tournament selection, elitism, subtree crossover and three mutation operators (node mutation, node addition, node deletion). Fitness is computed by simulating each BT in a fast state-machine simulator that models action outcomes (deterministic or probabilistic), then scoring according to a cost function combining task progress, tree size, execution time and estimated failure probability, with explicit rewards for subgoals (pick/place). The goal is to synthesise robust, reactive BTs for mobile-manipulation tasks in unpredictable environments while keeping evaluation computationally tractable via a simplified simulator.",
            "input_type": "programs (Behavior Trees)",
            "crossover_operation": "Sub-tree swapping: two parent BTs (represented as strings with parentheses marking subtrees) are paired (tournament selection) and a subtree from parent A is swapped with a subtree from parent B to produce two offspring; crossover is repeated twice per parent pair while avoiding producing identical copies in offspring. This preserves BT structure and semantics because subtrees are valid BT fragments.",
            "mutation_operation": "Three mutation modes applied to individuals with specified probabilities: (1) Node mutation — replace a selected node with any node from the gene pool; (2) Node addition — insert a node from the gene pool at an arbitrary position/level in the tree; (3) Node deletion — remove a selected node. For node addition/mutation there is a 50% chance to choose a control node (to reflect expected BT composition). Global GP probabilities (from Table I): overall crossover 40%, mutation 60%; within mutation: node mutation 30%, node addition 40%, node deletion 30%.",
            "uses_literature": false,
            "uses_code": true,
            "novelty_metric": null,
            "novelty_results": null,
            "executability_metric": "Fitness/cost function C used as the executability/functionality metric: C = f(s,b) + γ T + δ P, where f(s,b)=α ||s_d - s||^2 + β b (s encodes state distances: cube-goal, robot-cube, localization error; b is BT length), T is execution time, P is estimated cumulative failure probability of executed actions; rewards (negative cost) are added for subtask completion (pick reward = 50, place reward = 100). Task completion (binary success) and successful execution in the Gazebo physical simulator are also used to validate executability.",
            "executability_results": "Quantitative experimental outcomes reported include: convergence of GP to successful BTs required approx. 400,000 evaluation episodes (order-of-magnitude estimate reported); experiments averaged over 10 independent runs. Learned BTs from the simplified simulator were validated and executed successfully in the detailed Gazebo simulator. No explicit numeric success rate (%) or distribution of fitness values is reported in the paper text.",
            "diversity_metric": null,
            "diversity_results": null,
            "novelty_executability_tradeoff": "The paper demonstrates an explicit tradeoff between risk (estimated failure probability) and execution time via the δ parameter in the fitness cost: increasing δ penalizes actions/paths with high failure probability, steering the GP to choose longer but safer MoveTo* actions. Empirically, setting δ from 0 to 150 caused learned BTs to prefer safer (longer) paths; increasing environmental uncertainty leads GP to produce larger trees with duplicated actions to raise overall success probability. This is presented qualitatively and supported by experiments (Figures 8–9).",
            "frontier_characterization": null,
            "benchmark_or_domain": "Robotic mobile-manipulation (pick-and-place) — behavior tree synthesis for navigation and manipulation in stochastic/unpredictable simulated environments.",
            "comparison_baseline": "Internal baselines across experiments: deterministic state-machine simulator vs. four stochastic variants (Stoch.1–Stoch.4 with increasing failure probabilities), noise levels (adding 3 or 27 irrelevant behaviors), and fitness weighting (δ=0 vs δ=150). No external algorithmic baselines (e.g., hand-coded BTs) were used in experiments, though related works (GE/GP variants) are discussed.",
            "key_findings": "Subtree crossover is a natural and safe operator for BT programs, preserving semantics; allowing mutation to change node types (not restricting to same-type swaps) increases exploration/diversity; structural constraints (preventing identical control nodes consecutively, duplicate adjacent conditions, control nodes without children) avoid semantically-irrelevant/invalid trees. Under higher uncertainty GP tends to produce more complex BTs with repeated actions to raise success probability. GP is robust to added irrelevant actions (noise) and excludes unnecessary behaviors early. Penalizing estimated failure probability (via δ) produces safer but slower behaviors, demonstrating an explicit risk-vs-time tradeoff. Using a simplified state-machine simulator speeds up learning by orders of magnitude, making GP practical for this high-level policy search.",
            "uuid": "e1737.0",
            "source_info": {
                "paper_title": "Learning Behavior Trees with Genetic Programming in Unpredictable Environments",
                "publication_date_yy_mm": "2020-11"
            }
        },
        {
            "name_short": "GE",
            "name_full": "Grammatical Evolution",
            "brief_description": "An evolutionary approach that uses an explicit grammar (context-free grammar) to map genotypes to syntactically constrained programs; used in related work to evolve Behavior Trees for game agents and swarm tasks.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "Grammatical Evolution (GE)",
            "system_description": "GE evolves integer/genotype sequences which are mapped to programs via a context-free grammar; it enforces syntactic constraints on output programs (e.g., Behavior Trees) but requires grammar engineering and domain knowledge, which can bias or overconstrain solutions.",
            "input_type": "programs (Behavior Trees) via grammar mapping",
            "crossover_operation": null,
            "mutation_operation": null,
            "uses_literature": false,
            "uses_code": true,
            "novelty_metric": null,
            "novelty_results": null,
            "executability_metric": null,
            "executability_results": null,
            "diversity_metric": null,
            "diversity_results": null,
            "novelty_executability_tradeoff": null,
            "frontier_characterization": null,
            "benchmark_or_domain": "Mentioned in the context of evolving BTs for Mario AI and swarm foraging tasks (references [10], [16]).",
            "comparison_baseline": "Discussed qualitatively versus free GP: GE requires grammar design and can lead to complex, hard-to-interpret BTs and risks of overfitting to domain-specific grammars.",
            "key_findings": "Authors note in related work that GE enforces structure via a grammar but increases engineering effort and risk of overfitting; grammars can become complex for large BTs and may require ad hoc repairs to guarantee logical correctness.",
            "uuid": "e1737.1",
            "source_info": {
                "paper_title": "Learning Behavior Trees with Genetic Programming in Unpredictable Environments",
                "publication_date_yy_mm": "2020-11"
            }
        },
        {
            "name_short": "GA",
            "name_full": "Genetic Algorithm (parameter search variant)",
            "brief_description": "A classical evolutionary algorithm using fixed-length genotypes (e.g., vectors of integers) typically used to tune parameters rather than full program structure; mentioned for comparison with GP.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "Genetic Algorithm (parameter-based)",
            "system_description": "GA variants represent solutions as fixed-length strings (e.g., integers) and evolve them with crossover/mutation operators; in the paper GA is referenced as the approach used when only program parameters are evolved rather than tree/program structure.",
            "input_type": "program parameters (fixed-length genotype), not full program trees",
            "crossover_operation": null,
            "mutation_operation": null,
            "uses_literature": false,
            "uses_code": false,
            "novelty_metric": null,
            "novelty_results": null,
            "executability_metric": null,
            "executability_results": null,
            "diversity_metric": null,
            "diversity_results": null,
            "novelty_executability_tradeoff": null,
            "frontier_characterization": null,
            "benchmark_or_domain": "Mentioned generally as an alternative approach where only parameters change (reference [6]).",
            "comparison_baseline": "Compared conceptually to GP: GA is suitable when genotype length is fixed and only parameters vary, whereas GP handles variable-sized program (tree) structures.",
            "key_findings": "Paper cites GA as a contrasting method for evolving parameters but emphasizes GP's suitability for evolving the modular tree structure of BTs.",
            "uuid": "e1737.2",
            "source_info": {
                "paper_title": "Learning Behavior Trees with Genetic Programming in Unpredictable Environments",
                "publication_date_yy_mm": "2020-11"
            }
        },
        {
            "name_short": "Constrained-GP",
            "name_full": "Structural-constraint Genetic Programming (constrained GP)",
            "brief_description": "GP variants that impose structural/dynamic constraints on evolving trees (e.g., preventing invalid trees, protecting recurrent subtrees) to speed up learning and avoid invalid solutions.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "Constrained Genetic Programming (structural/dynamic constraints)",
            "system_description": "GP implementations that apply constraints such as (i) preventing identical control node types on consecutive levels, (ii) enforcing conditions to appear on rightmost positions in subtrees, (iii) protecting recurrent subtrees from change, and (iv) preventing control nodes without children or duplicate adjacent condition nodes; these constraints reduce the generation of semantically meaningless or invalid trees and can improve learning speed.",
            "input_type": "programs (Behavior Trees)",
            "crossover_operation": null,
            "mutation_operation": null,
            "uses_literature": false,
            "uses_code": true,
            "novelty_metric": null,
            "novelty_results": null,
            "executability_metric": null,
            "executability_results": null,
            "diversity_metric": null,
            "diversity_results": null,
            "novelty_executability_tradeoff": null,
            "frontier_characterization": null,
            "benchmark_or_domain": "Referenced in related work on evolving BTs for games and agents (references [12],[13],[14]).",
            "comparison_baseline": "Compared qualitatively to unconstrained GP: constrained GP speeds up learning and avoids invalid/undesirable BTs but may reduce exploration if overconstrained.",
            "key_findings": "Authors adopt some structural constraints from prior work to avoid semantically irrelevant BT structures, but deliberately do not constrain mutation to same-type node swaps (unlike some prior work) to increase diversity.",
            "uuid": "e1737.3",
            "source_info": {
                "paper_title": "Learning Behavior Trees with Genetic Programming in Unpredictable Environments",
                "publication_date_yy_mm": "2020-11"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Learning of Behavior Trees for Autonomous Agents",
            "rating": 2
        },
        {
            "paper_title": "Evolving Behaviour Trees for the Mario AI Competition Using Grammatical Evolution",
            "rating": 2
        },
        {
            "paper_title": "Evolutionary Behavior Tree Approaches for Navigating Platform Games",
            "rating": 2
        },
        {
            "paper_title": "Behavior Modeling for Autonomous Agents Based on Modified Evolving Behavior Trees",
            "rating": 2
        },
        {
            "paper_title": "Learning Behavior Trees using Grammatical Evolution and Behavior Trees",
            "rating": 1
        },
        {
            "paper_title": "Performance analysis of stochastic behavior trees",
            "rating": 2
        },
        {
            "paper_title": "Genetic programming: An introduction and tutorial, with a survey of techniques and applications",
            "rating": 2
        },
        {
            "paper_title": "Evolving Swarm Behaviors using Grammatical Evolution and Behavior Trees",
            "rating": 2
        }
    ],
    "cost": 0.01245,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Learning Behavior Trees with Genetic Programming in Unpredictable Environments</h1>
<p>Matteo Iovino<em> ${ }^{\ddagger}$, Jonathan Styrud ${ }^{\dagger \ddagger}$, Pietro Falco</em> and Christian Smith ${ }^{\ddagger}$</p>
<h4>Abstract</h4>
<p>Modern industrial applications require robots to be able to operate in unpredictable environments, and programs to be created with a minimal effort, as there may be frequent changes to the task. In this paper, we show that genetic programming can be effectively used to learn the structure of a behavior tree (BT) to solve a robotic task in an unpredictable environment. Moreover, we propose to use a simple simulator for the learning and demonstrate that the learned BTs can solve the same task in a realistic simulator, reaching convergence without the need for task specific heuristics. The learned solution is tolerant to faults, making our method appealing for real robotic applications.</p>
<p>Index Terms-Behavior Trees, Genetic Programming, Mobile Manipulation</p>
<h2>I. INTRODUCTION</h2>
<p>Modern industrial applications, with robots sharing environments with humans, require robots to be able to operate in unpredictable environments. This can be achieved by controlling the robot with a policy, rather than a prescribed sequence of actions, to support handling unexpected outcomes of robot actions, or different types of faults and errors. For modern, flexible, manufacturing environments, it is also desirable that new robot policies or programs can be created with a minimum of effort, as changing requirements may require frequent changes to the task the robot should perform.</p>
<p>In this paper, we propose a method to learn a policy to solve a mobile manipulation task in unpredictable environments. We use Behavior Trees (BTs) to represent the policy, due to their reactivity and modularity, and Genetic Programming (GP) for the learning, as it is a good fit for the modularity and the structure of a BT. The first contribution of this paper is to show that GP can be used to learn a BT which is robust to faults, both reactively and proactively, favoring designs that minimize the risk of error. The GP approach, like many other unsupervised learning methods, requires a large amount of evaluations of the policy, making it difficult to run the learning on a physical robot platform, and it can be severely computationally expensive to run in simulation, on an accurate simulator.</p>
<p>This project is financially supported by the Swedish Foundation for Strategic Research and by the Wallenberg AI, Autonomous Systems, and Software Program (WASP) funded by the Knut and Alice Wallenberg Foundation. The authors gratefully acknowledge this support.
*ABB Corporate Research, Västerås, Sweden
$\dagger$ ABB Robotics, Västerås, Sweden
$\ddagger$ Division of Robotics, Perception and Learning, Royal Institute of Technology (KTH), Stockholm, Sweden</p>
<p>In this paper, we also show that for the high-level policy contained in the BT, the detailed physical models of the robot itself, the environment, and the interaction between them may not be necessary, as long as the outcome of different actions is similar enough to the real scenario. We thus propose to learn on a simplified simulator with a low computational cost, and show that the solutions found are still valid for solving the task in a highly detailed simulation.</p>
<p>The paper is organised as follows. Section II introduces Behavior Trees and Genetic Programming and an overview of methods to synthesize BTs. In Section III we present our approach and demonstrate its performance in Section IV.</p>
<h2>II. BACKGROUND AND RELATED WORK</h2>
<p>In this section we provide a background on Behavior Trees and Genetic Programming, and a summary of the related work, and show how our proposed methods addresses shortcomings in the state of the art.</p>
<h2>A. Behavior Trees</h2>
<p>Behavior Trees (BTs) are a policy or controller representation for AI agents originating in the gaming industry, later applied to robotics, seeing use as an alternative to Finite State Machines (FSM) [1]. BTs have natural support for task hierarchy, actions sequencing and reactivity, and improve on FSM especially in terms of modularity and reusability [2].
<img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Fig. 1. Example of BT with the pool of actions.
In a BT internal nodes are called control flow nodes (polygons in Figure 1) and can be of type Sequence, Fallback or Parallel, while the leaves are called execution nodes and can be either Actions or Conditions (ovals in Figure 1). Execution is realised by propagating tick signals from the root at a given frequency. Action nodes are executed when ticked and returns one of the statuses Running, Success or Failure. Condition nodes perform status checks or sensing</p>
<p>and return Success or Failure. Sequence nodes execute its children in sequence, returning when all succeed or one fails. The Fallback (or Selector) node, executes its children in sequence, returning when one succeeds or all fail. The return state Running is crucial for reactivity [1], allowing other actions to preempt non-finished actions.</p>
<p>The modularity of a BT is particularly relevant when using evolutionary algorithms such as GP because any leaf or subtree is a building block that can be added to the gene pool and re-used in following generations. In crossover, parents generate offspring by swapping genes sequences and in BTs this can be naturally done with subtrees, without compromising the logic execution of the tree [3] and the safety guarantees [4]. There is no explicit upper bound on the size of a BT needed to solve a specific task, and this unboundedness of the solution space limits the number of suitable methods to learn new BTs.</p>
<h2>B. Genetic Programming</h2>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Fig. 2. Scheme of GP execution flow
Genetic Programming (GP) is an optimization algorithm that can evolve programs represented as trees [5]. Populations of individuals (computer programs) generate offspring through the functions of crossover and mutation. A selection mechanism decides which part of the population to keep (Figure 2). Types of selection mechanisms are e.g. elitism (keeping the highest ranking), tournament selection (individuals are compared pare-wise), rank selection (the probability to keep an individual is proportional to its rank in the population). The survival selection is based on a fitness function that assigns a score to each individual based on how it performs in solving the task. There are many variations of GP, in which a grammar is defined to enforce a particular structure and constrain the evolution (Grammatical Evolution), or where only programs parameters are allowed to change and the genotype is represented as fixed-length strings of integers (Genetic Algorithm) [6].</p>
<h2>C. Related Work</h2>
<p>The two main types of automatic synthesis of BTs are planning and learning [2]. An outcome of a planning algorithm is often a sequence of actions to achieve task goals. Failing to execute an action requires re-planning, so the more uncertain the environment is, the more time and computational resources are devoted to compute new plans to adapt to the situation. A common way to deal with environment changes is to include pre- and post-conditions, exploiting the natural reactivity and modularity of the BT [7]. This method exploits back-chaining, starting from the goal conditions and subsequently linking the actions that satisfy them and proceeding backwards, iterating until the starting state is reached. Task knowledge is required to include the conditions. Whenever a post-condition is not met, the BT is expanded to include the actions that achieve it, requiring to stop the execution flow. Updating the BT online during task execution makes it more difficult to analyze and evaluate the policy before it is deployed.</p>
<p>Learning from demonstration and evolutionary approaches [2] have also been proposed as synthesis methods. Learning from demonstration allows inexperienced users to teach a robot how to solve a task. In [8], humans teach a house cleaning task to a mobile robot. Primitives are learned from demonstration and incorporated to a Decision Tree, which is translated to a BT. Depending on task complexity, multiple teaching sessions are required to learn the necessary actions. In particular, it is difficult to handle faults that were not encountered during the demonstrations.</p>
<p>Evolutionary approaches have been used to learn BTs in computer game applications [9]. The authors raise the problem of execution time, since all BTs had to be evaluated by playing the game DEFCON, and the total execution time was roughly 41 days. Various methods have been used to learn BTs for the Mario AI Competition [3], [10]-[14]. [10], [11] use Grammatical Evolution (GE). This requires a syntax for all possible solutions in a context-free grammar. This approach requires domain knowledge and an engineering effort to design the grammar, which grows in complexity with the task to solve. Moreover, grammars defining large BTs can become difficult to read and interpret. Grammars can also compromise the logic correctness of the BT structure, requiring ad hoc modifications [15]. In [12], [13], structural and dynamic constraints (i.e. recurrent subtrees are identified during learning and protected from changes) are implemented in the GP, speeding up the learning by preventing the generation of invalid trees. Similar constraints are proven to improve the fitness by not producing undesirable BTs [14]. In [3], a GP is combined with a heuristic that tries all actions until it finds one that improves the reward. If the heuristic fails, then GP is used to combine sequences of actions. The GP operation of mutation is limited to change a node to another of the same type (control or leaf). All available conditions are already included from start and after the</p>
<p>learning process an algorithm is run to reshape the solution. In computer game applications, treating uncertainties is not of importance, since actions have deterministic outcomes.</p>
<p>In [16] GE is used to evolve a BT to solve a foraging task for a robot swarm. A grammar is used to constrain the evolution of the trees but can push the algorithm to find complex structures. Constructing the grammar requires domain knowledge, and risks overfitting. Authors in [17] use GP to evolve BTs to control a swarm of robots. Even though they do not publish the resulting BTs, they detail the simulator used for the experiments: the simple structure and interactions for these robots enable fast simulation, including physics and sensing, with an average time of 6 minutes to evolve a population of 32 individuals for 100 generations.</p>
<p>In our approach, we use some structural constraints from [14], to avoid to have the same type of control node on two consecutive levels of the tree, conditions on the rightmost position of any sub-tree, control nodes without children, or having identical condition nodes to be next to each other, as none of these can affect the outcome of an execution of the BT. Unlike [3], we do not constrain the mutation only to nodes of the same type, thus increasing the diversity. We do not explicitly specify which conditions to use, but leave this to the GP algorithm to find. Conditions always required to perform a specific action (e.g. only attempt to pick objects not already held in hand), are included within the behavior at an atomic level. We do not perform explicit reshaping of the tree, but the size of the tree (in terms of number of nodes) is a factor included in the fitness function.</p>
<p>To conclude, our contribution with respect to the state of the art is that our GP algorithm can reach convergence in a non-deterministic robotic scenario without the need for task specific heuristics. This is achieved by synthesizing BTs which are naturally reactive to failures and including the success probability in the fitness function, driving towards solutions that avoid actions that are more likely to fail.</p>
<h2>III. PROPOSED METHOD</h2>
<p>Synthesising fault tolerant policies for robotics with unsupervised learning requires the agent to attempt to solve the task in the environment in which it operates, which may require many learning episodes. This may require significant time, as it is not possible to speed up the execution of real tasks. Safety plays another important role, because in order to learn not to fail, the robot may have to experience failure, with the risk of causing unwanted damage or hurting humans. Finally, resetting the task environment for subsequent runs may often require expensive human intervention. Thus, it is better to first learn the policy in a simulator and then try the learned policy in the real world. In detailed simulators, both kinematics and dynamics can be modelled, together with collision boxes for contacts computation. This allows to realize complex robotics tasks, including sensing, navigation, manipulation and so on. The more complex the models and the task to solve, the higher the computational cost will be. In this perspective, simulators can solve the safety problem, but time is still an issue. To overcome this limitation, we propose to learn the structure of a BT using a very simplified simulator, that does not take details of sensing, kinematics, and dynamics, into account. With a careful design of the simulator, the high-level decision and the execution flow would be the same. We demonstrate this with a state machine standing in as a simulator, but assume that any simulator that keeps the high-level structure of actions and outcomes of the original task would work.</p>
<h2>A. GP algorithm and operations on BTs</h2>
<p>The gene pool provided to the genetic algorithm, i.e. the primitive set of the GP system, is composed by a set of terminals (the BT leaves: actions and conditions) and a set of functions (the BT control nodes: sequence (s) and fallback (f)). The BT is represented as a string (e.g. [‘s(’ , ‘action1’, ‘action2’, ‘)’]), where the parenthesis are used as subtree identifier. The GP functions operate on the string, which is mapped into a BT for the evaluation. The initial population is composed of $N$ randomly created BTs of length 4 and then it evolves using the following functions:</p>
<p>a) Crossover: this function takes two individuals of the parent generation and performs a sub-tree swapping, returning two offspring individuals, as in [3] (Figure 3).</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Fig. 3. Example of a Crossover operation in BTs. Top: parent generation, bottom: offspring generation.</p>
<p>b) Mutation: this function changes an individual in three different ways with set probabilities, keeping the structure of the BT consistent. For node addition and mutation, there is a 50% chance that a control node will be chosen, since they typically constitute around 50% of the final behavior tree.</p>
<p>1) Node mutation: a node in the individual is mutated to any node in the gene pool.</p>
<p>2) Node addition: a node from the gene pool is added to the individual at any level.</p>
<p>3) Node deletion: a node is removed from the individual.</p>
<p>For the Crossover and Mutation, the parents are chosen by running a Tournament Selection, giving the number of individuals shown in Table I, as a percentage of the population. Tournament Selection runs several single duels in which the most fit individual of the pair survives. For a given generation, the individual with the best score will always survive, while the individual with the worst score will not.</p>
<p>TABLE I: GP PARAMETERS USED IN THE SIMULATIONS</p>
<table>
<thead>
<tr>
<th>GP Parameters</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>individuals in population $(N)$</td>
<td>30</td>
</tr>
<tr>
<td>individual start length</td>
<td>4</td>
</tr>
<tr>
<td>generations</td>
<td>8000</td>
</tr>
<tr>
<td>crossover $\%$</td>
<td>40</td>
</tr>
<tr>
<td>mutation $\%$</td>
<td>60</td>
</tr>
<tr>
<td>elitism $\%$</td>
<td>10</td>
</tr>
<tr>
<td>mutation: node mutation $\%$</td>
<td>30</td>
</tr>
<tr>
<td>mutation: node addition $\%$</td>
<td>40</td>
</tr>
<tr>
<td>mutation: node deletion $\%$</td>
<td>30</td>
</tr>
<tr>
<td>selection method</td>
<td>tournament</td>
</tr>
</tbody>
</table>
<p>For the rest, it depends on the fitness of the individual they are paired with. Tournament Selection generally performs better than Elitism, in terms of convergence [18], because it allows keeping genetic content used in poorly performing individuals, resulting in a better exploration of the search space and in a lower chance of getting stuck in local minima.</p>
<p>Crossover and mutation will generate two different offspring for each parent, to keep the population size low without compromising the learning speed. The crossover function is repeated twice for each pair of parents, while making sure that there are no copies in the offspring. For mutation, a single parent will generate two different offspring according to the mutation function. A percentage of the following generation (‘elitism’ in Table I), is populated by the most fit individuals. The remaining slots are populated by the output from another Tournament Selection run with all the parents and the offspring ( $N+2 N$ individuals).</p>
<h2>B. Simulator design</h2>
<p>The simple simulator we use here is based on a state machine, where the states and the transitions are designed to be as close as possible to the realistic physics simulator, also providing the same kind of feedback: e.g. estimated robot pose from the localization filter, robot configurations, object pose, etc. The transitions depend on the state of the robot and on the outcome of the action being ticked. The transitions can be designed to be deterministic or probabilistic, modelling the simulator as a Markov Chain. To the best of our knowledge, there is no work leveraging this kind of simulator to learn a BT. In the literature, learning of the structure is always studied in a deterministic fashion (e.g. computer games). In GP every individual needs to be scored by the fitness function. Every BT designed by the GP is simulated in the physical simulator, making the problem intractable if the number of individuals in a population or the number of generations is high (in the order of magnitude of hundreds). In our state machine simulator each evaluation is several orders of magnitude faster. Note that the state machine is meant to substitute the physical simulator. Thus, it is seen as a black box by the learning algorithm, taking as input an individual and returning the fitness score. The knowledge required to design the state machine is not incorporated in the learning algorithm. Since the outcome of the actions is uncertain, post-conditions cannot be defined, thus invalidating planning approaches as in [7].</p>
<h2>IV. EXPERIMENTS AND RESULTS</h2>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Fig. 4. Simulation environment in Gazebo.
To evaluate the performance of our approach, we test it on a mobile manipulation task. The task to solve is for a mobile manipulator to pick an object and place it in another position, thus requiring both navigation and manipulation. To navigate the environment, the robot must be localised and its arm needs to be in a tucked configuration, to not collide with the obstacles. The robot has a camera for object recognition located in the head, which has two configurations: Up (to navigate) and Down (to identify and manipulate objects). To complete the task the robot has to place the object in a goal position. The object is assumed to be a cube, and the pick/place positions correspond to two different tables in the environment (Figure 4). The set of action behaviors available to the robot are are Localise, HeadUp, HeadDown, Tuck, Pick, Place and MoveTo, which can then take as input parameter a goal pose (e.g. the pick and the place pose). A condition Have Block? checks if the robot is currently holding the cube. This is the set of the necessary behaviors to complete the task (Figure 1).</p>
<h2>A. Fitness function design</h2>
<p>For the BTs to evolve, a trade off must be made between generalization and domain knowledge in the fitness function. If it is well adapted to the specific task, it will feature a clear gradient that makes the learning faster, however it may be too task specific and difficult to generalize to other tasks. However, using a very generic fitness function, such as a binary "fail/success" might fail due to the lack of gradient, making the problem closer to a random search. Taking this into account, we design the fitness function to include all the elements that are common to mobile manipulation tasks. The fitness function is an objective to maximize:</p>
<p>$$
\mathcal{J}=\arg \max (-\mathcal{C})
$$</p>
<p>The function $\mathcal{C}$ is the cost:</p>
<p>$$
\mathcal{C}=f(s, b)+\gamma T+\delta P
$$</p>
<p>where</p>
<p>$$
f(s, b)=\alpha \mathbf{s}^{2}+\beta b, \text { and } s=\left|\mathbf{s}_{\mathbf{d}}-\mathbf{s}\right|
$$</p>
<p>takes into account the distance of the robot and cube poses (states $s$ ) from the desired goal pose $s_{d}$. In particular, we award the robot being close to the cube, to provide a "hint" that this may help solve the task. It also includes the localization error, measured as the distance between the real pose of the robot in the environment and the estimated one. The vector weight $\alpha$ for the distance factor has components $\alpha_{1}$ for the distance cube-goal, $\alpha_{2}$ for the distance robotcube and $\alpha_{3}$ for the localization error. The term $b$ takes into account the length (the number of nodes) of the tree, $T$ is the execution time and $P$ is the estimated failure probability, obtained by summing the failure probability of the executed actions. [19] provides a tool to compute the prior estimation of the success/failure probability of the whole tree, but here we take into account the estimated failure probability despite the outcomes of the actions. In this way, the cost increases when actions with high probability of failure are executed. Finally, we give a reward when the robot achieves the picking of the cube and when it finally places it. This in particular prevents the robot from stopping with the cube in front of the placing pose but pushes it to complete the task. The fitness function parameters are in Table II.</p>
<p>TABLE II
PARAMETER FOR THE FUNCTIONS IN (2) AND (3).</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Weights</th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">pick reward</td>
<td style="text-align: center;">50</td>
</tr>
<tr>
<td style="text-align: center;">place reward</td>
<td style="text-align: center;">100</td>
</tr>
<tr>
<td style="text-align: center;">$\alpha_{1}$ (distance cube-goal)</td>
<td style="text-align: center;">10</td>
</tr>
<tr>
<td style="text-align: center;">$\alpha_{2}$ (distance robot-cube)</td>
<td style="text-align: center;">2</td>
</tr>
<tr>
<td style="text-align: center;">$\alpha_{3}$ (localization error)</td>
<td style="text-align: center;">1</td>
</tr>
<tr>
<td style="text-align: center;">$\beta$ (BT length)</td>
<td style="text-align: center;">0.5</td>
</tr>
<tr>
<td style="text-align: center;">$\gamma$ (execution time)</td>
<td style="text-align: center;">0.1</td>
</tr>
<tr>
<td style="text-align: center;">$\delta$ (failure probability)</td>
<td style="text-align: center;">0.0</td>
</tr>
</tbody>
</table>
<p>Completing the entire task, or the sub-task of picking the cube are important, and given high weights, while less important goals that are intended to provide gradients for partial solutions are given significantly lower weights. $\delta$ is not used in the first experiment.</p>
<h2>B. Experiments</h2>
<p>The task has been designed in the physical simulator Gazebo, with the robot controlled through ROS (Figure 4). We use this to evaluate the performance of BTs learned using the simple simulator.</p>
<p>We also tried running the GP directly in this simulator, but it takes more than a month of runtime on a powerful gaming computer to converge. The same learning problem, set up to run in the simple state machine simulator, allows both to speed up the learning by several order of magnitudes, down to a few minutes (depending on the GP parameters), and to choose the failure probabilities and outcomes for all actions.</p>
<p>All the experiments are carried out with the GP parameters in Table I. The BT can fail up to 5 times, below this limit, the root is ticked again upon failure, so that the robot can perform again an action that just failed. This approach is logically equivalent to have copies of the same action controlled by a Fallback node, but results in a simpler tree structure. Every learning curve is an average over 10 runs. The learned BT solutions in all the following experiments were verified to also solve the task in the more detailed simulator in Gazebo. (See Figure 5).</p>
<p>In experiment 1, we will show how the failure probability affects the learning of a robust BT. For this we first run a simulation on a deterministic state machine, where the actions do not have a failure probability. Then we run four more simulations with increasing levels of uncertainties, as showed in Table III.
<img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Fig. 5. Pick and Place in Gazebo.</p>
<p>TABLE III
STATE MACHINE VALUES FOR THE FAILURE PROBABILITIES</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Failure Probability</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Probability Type</td>
<td style="text-align: center;">Stoch. 1</td>
<td style="text-align: center;">Stoch. 2</td>
<td style="text-align: center;">Stoch. 3</td>
<td style="text-align: center;">Stoch. 4</td>
</tr>
<tr>
<td style="text-align: center;">localization failure</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0.2</td>
<td style="text-align: center;">0.3</td>
</tr>
<tr>
<td style="text-align: center;">pick failure</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0.2</td>
<td style="text-align: center;">0.4</td>
</tr>
<tr>
<td style="text-align: center;">place failure</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0.1</td>
<td style="text-align: center;">0.2</td>
</tr>
<tr>
<td style="text-align: center;">losing cube</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0.05</td>
<td style="text-align: center;">0.05</td>
<td style="text-align: center;">0.1</td>
</tr>
<tr>
<td style="text-align: center;">losing localization</td>
<td style="text-align: center;">0.1</td>
<td style="text-align: center;">0.1</td>
<td style="text-align: center;">0.1</td>
<td style="text-align: center;">0.2</td>
</tr>
</tbody>
</table>
<p>The 'localization failure' is the probability of failure in the convergence of the particle filter that estimates the robot pose, whereas the 'losing localization' is the probability for the robot to lose the localization during the navigation. 'Losing cube' means dropping the cube when the robot moves. When the cube is dropped, it will respawn to the pick pose, thus requiring the robot to pick it again. The third column will be used as baseline for comparison in the remainder of this section. The results are shown in Figure 6.</p>
<p>The algorithm is able to handle uncertainties and grant the same convergence as in the deterministic case. When the level of uncertainty increases, however, the found solution is generally more complicated and features multiple copies of the same action, to increase the overall success probability.</p>
<p>Note that the number of episodes needed for convergence, approx. 400 000, would be expensive to run on a real robot or on a realistic simulator. An example of the output is Figure 1.</p>
<p>In experiment 2, we compare a setup in which the pool contains just the 9 behaviors necessary to the completion of the task to two noisy setups. In the first comparison we add 3 useless behaviors (low noise in Figure 7), while in the second we add an additional 27 (high noise). This is to emulate the case where the robot has access to a large number of actions, but only a small subset are needed for a particular task.</p>
<p><img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Fig. 6. Effect of failure probabilities on learning, averaged on 10 runs.
<img alt="img-6.jpeg" src="img-6.jpeg" /></p>
<p>Fig. 7. Effects of noise on the learning.</p>
<p>The results shown in Figure 7 show that the GP is robust to added unnecessary actions. The added actions could have led the robot to local minima, being mostly MoveTo type behaviors that drive the robot around the environment and could get either close to the cube or close to the goal position. The GP excludes the meaningless behaviors in early stages.</p>
<p>In experiment 3 we explore how the parameter $\delta$ affects the learned solution. We assume that the robot could take two paths to both the pick and the place positions: a shorter one, but cluttered by human presence, thus with a higher risk of losing the cube or the localization (set to 0.2 and 0.4 respectively), and a longer one without these probabilities but a longer execution time. This is achieved by setting the MoveTo behaviors to take the shorter but more risky path and by adding MoveTo* actions taking the other. The results are reported in Figure 8, where the $\delta$ parameter is set first to 0 and then to 150 , thus penalizing the robot for taking risks.</p>
<p>Figure 9 shows that the same BT structure that solves the task in normal conditions (see Figure 1), now features the
<img alt="img-7.jpeg" src="img-7.jpeg" /></p>
<p>Fig. 8. Effects of the $\delta$ parameter on the Fitness function.
modified MoveTo* behaviors taking the safer path.
<img alt="img-8.jpeg" src="img-8.jpeg" /></p>
<p>Fig. 9. BT taking safer paths to pick and place.</p>
<h2>V. Conclusions and Future Work</h2>
<p>In this paper we showed that GP can be effectively used to learn the structure of a BT to solve a task in an unpredictable environment. Moreover, we proposed to use a state machine model of the simulator, instead of a physical one, to make the problem computationally tractable, without compromising the traits of the solution. The BTs learned in the simple simulator are demonstrated to efficiently solve the same task in a physical simulator.</p>
<p>We showed that the learned solution is tolerant to faults on the manipulation, localization and navigation actions, making our method appealing for real robotic applications. As future work we propose to transfer the solution on a real robot setup and to compare it to hand coded BTs. A natural continuation of this work is to study if learning on a simple simulator can bootstrap the learning in the physical simulator, or real platform for the cases where a solution from the simple simulator does not work directly.</p>
<h2>Acknowledgment</h2>
<p>The authors would like to thank Ignacio Torroba Balmori and Christopher Iliffe Sprague for their contribution on setting up and designing the simulation environment in ROSGazebo.</p>
<h1>REFERENCES</h1>
<p>[1] M. Colledanchise and P. Ögren, Behavior Trees in Robotics and AI : An Introduction. CRC Press, July 2018. KTH.
[2] M. Iovino, E. Scukins, J. Styrud, P. Ögren, and C. Smith, "A survey of behavior trees in robotics and ai," 2020.
[3] M. Colledanchise, R. Parasuraman, and P. Ögren, "Learning of Behavior Trees for Autonomous Agents," IEEE Transactions on Games, vol. 11, pp. 183-189, June 2019.
[4] M. Colledanchise and P. Ögren, "How Behavior Trees Modularize Hybrid Control Systems and Generalize Sequential Behavior Compositions, the Subsumption Architecture, and Decision Trees," IEEE Transactions on Robotics, vol. 33, pp. 372-389, Apr. 2017. KTH.
[5] W. Langdon, R. Poli, N. Mcphee, and J. Koza, "Genetic programming: An introduction and tutorial, with a survey of techniques and applications," Studies in Computational Intelligence, vol. 115, p. 927-1028, 1970.
[6] M. C. Sinclair and S. H. Shami, "Evolving simple software agents: comparing genetic algorithm and genetic programming performance," in Second International Conference On Genetic Algorithms In Engineering Systems: Innovations And Applications, pp. 421-426, 1997.
[7] M. Colledanchise, D. Almeida, and P. Ögren, "Towards Blended Reactive Planning and Acting using Behavior Trees," in IEEE International Conference on Robotics and Automation, (Montreal, Canada), IEEE, May 2019. KTH.
[8] K. French, S. Wu, T. Pan, Z. Zhou, and O. C. Jenkins, "Learning Behavior Trees From Demonstration," in 2019 International Conference on Robotics and Automation (ICRA), pp. 7791-7797, May 2019.
[9] C.-U. Lim, R. Baumgarten, and S. Colton, "Evolving Behaviour Trees for the Commercial Game DEFCON," in Applications of Evolutionary Computation (D. Hutchison, T. Kanade, J. Kittler, J. M. Kleinberg, F. Mattern, J. C. Mitchell, M. Naor, O. Nierstrasz, C. Pandu Rangan, B. Steffen, M. Sudan, D. Terzopoulos, D. Tygar, M. Y. Vardi, G. Weikum, C. Di Chio, S. Cagnoni, C. Cotta, M. Ebner, A. Ekárt, A. I. Esparcia-Alcazar, C.-K. Goh, J. J. Merelo, F. Neri, M. Preuß, J. Togelius, and G. N. Yannakakis, eds.), vol. 6024, pp. 100-110, Berlin, Heidelberg: Springer Berlin Heidelberg, 2010.
[10] D. Perez, M. Nicolau, M. O’Neill, and A. Brabazon, "Evolving Behaviour Trees for the Mario AI Competition Using Grammatical Evolution," in Applications of Evolutionary Computation (C. Di Chio, S. Cagnoni, C. Cotta, M. Ebner, A. Ekárt, A. I. Esparcia-Alcázar, J. J. Merelo, F. Neri, M. Preuss, H. Richter, J. Togelius, and G. N. Yannakakis, eds.), Lecture Notes in Computer Science, pp. 123-132, Springer Berlin Heidelberg, 2011.
[11] M. Nicolau, D. Perez-Liebana, M. O’Neill, and A. Brabazon, "Evolutionary Behavior Tree Approaches for Navigating Platform Games," IEEE Transactions on Computational Intelligence and AI in Games, vol. 9, pp. 227-238, Sept. 2017.
[12] Q. Zhang, K. Xu, P. Jiao, and Q. Yin, "Behavior Modeling for Autonomous Agents Based on Modified Evolving Behavior Trees," in 2018 IEEE 7th Data Driven Control and Learning Systems Conference (DDCLS), pp. 1140-1145, May 2018.
[13] Q. Zhang, J. Yao, Q. Yin, and Y. Zha, "Learning Behavior Trees for Autonomous Agents with Hybrid Constraints Evolution," Applied Sciences, vol. 8, p. 1077, July 2018.
[14] P. McClarron, R. Ollington, and I. Lewis, "Effect of constraints on evolving behavior trees for game ai," 032016.
[15] A. Hallawa, S. Schug, G. Iacca, and G. Ascheid, "Evolving instinctive behaviour in resource-constrained autonomous agents using grammatical evolution," in International Conference on the Applications of Evolutionary Computation (Part of EvoStar), pp. 369-383, Springer, 2020.
[16] A. Neupane and M. Goodrich, "Learning Swarm Behaviors using Grammatical Evolution and Behavior Trees," in Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence, (Macao, China), pp. 513-520, International Joint Conferences on Artificial Intelligence Organization, Aug. 2019.
[17] S. Jones, M. Studley, S. Hauert, and A. Winfield, "A two teraflop swarm," Frontiers Robotics AI, vol. 5, no. FEB, 2018.
[18] A. Shukla, H. M. Pandey, and D. Mehrotra, "Comparative review of selection techniques in genetic algorithm," in 2015 International Conference on Futuristic Trends on Computational Analysis and Knowledge Management (ABLAZE), pp. 515-519, 2015.
[19] M. Colledanchise, A. Marzinotto, and P. Ögren, "Performance analysis of stochastic behavior trees," in 2014 IEEE International Conference on Robotics and Automation (ICRA), pp. 3265-3272, May 2014.</p>            </div>
        </div>

    </div>
</body>
</html>