<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-4769 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-4769</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-4769</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-105.html">extraction-schema-105</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models using diverse versus similar reasoning methods to solve reasoning problems, including descriptions of the reasoning methods, tasks, performance, and any comparisons or findings about the effectiveness of diverse versus similar reasoning.</div>
                <p><strong>Paper ID:</strong> paper-267938465</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2310.07088v2.pdf" target="_blank">Diversity of Thought Improves Reasoning Abilities of LLMs</a></p>
                <p><strong>Paper Abstract:</strong> Large language models (LLMs) are documented to struggle in settings that require complex reasoning. Nevertheless, instructing the model to break down the problem into smaller reasoning steps, or ensembling various generations through modifying decoding steps boosts performance. However, these methods assume that the input prompt is fixed and expect the decoding strategies to introduce the diversity needed for ensembling. In this work, we discuss how one can create and leverage variations of the input prompt as a means of diversity of thought. We propose a method that automatically improves prompt diversity by soliciting feedback from the LLM to ideate approaches that are apt for the problem. We then ensemble the diverse prompts in our method DIVSE (DIVerse reasoning path Self-Ensemble) across multiple inference calls, or use diverse approaches within a single inference call; we call the latter IDIV-SE (In-call DIVerse reasoning path Self-Ensemble). Apart from our approaches outperforming prior work, DIV-SE(in particular) advances state-of-the-art performance on the challenging planning and graph coloring benchmarks. Our results improve the Pareto frontier of the accuracy-cost trade-off.</p>
                <p><strong>Cost:</strong> 0.019</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e4769.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e4769.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models using diverse versus similar reasoning methods to solve reasoning problems, including descriptions of the reasoning methods, tasks, performance, and any comparisons or findings about the effectiveness of diverse versus similar reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DIV-SE (BLOCKSWORLD 3, GPT-4)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>DIVerse reasoning path Self-Ensemble (DIV-SE) on BLOCKSWORLD 3 using GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A prompting method that elicits multiple distinct high-level reasoning approaches from the LLM, runs each approach in separate inference calls, and aggregates outputs (majority vote); applied to Blocksworld planning with GPT-4, achieving state-of-the-art accuracy at higher inference cost.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>OpenAI GPT-4 as used in the paper (instruction-tuned, evaluated with input/output pricing and cost accounting); exact model internals/size not specified in paper.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>DIV-SE (DIVerse reasoning path Self-Ensemble)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>diverse</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_description</strong></td>
                            <td>Solicit multiple distinct high-level problem-solving approaches (via LLM-guided approach extraction), create separate prompts (each with a single approach + persona + augmented few-shot examples), call the model once per approach, then aggregate outputs by majority vote; diversity is achieved via different approaches/personas rather than stochastic decoding.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>BLOCKSWORLD 3 (planning)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Blocksworld planning benchmark testing planning capability (3-block instances); requires generating valid action plans subject to constraints and goal configuration.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>accuracy 94% (GPT-4, DIV-SE, reported state-of-the-art for BLOCKSWORLD 3)</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_method</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>performance_other_method</strong></td>
                            <td>ZS-CoT: 70% (zero-shot chain-of-thought), SC-10: 73% (self-consistency with 10 samples), IDIV-SE: ~82% (IDIV-SE reported as +12 p.p over ZS-CoT)</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Running distinct reasoning approaches in separate calls (DIV-SE) substantially outperforms standard CoT and decoding-based ensembles (SC) on hard planning tasks; DIV-SE produced a state-of-the-art 94% on BLOCKSWORLD 3 compared to 70% (ZS-CoT) and 73% (SC-10).</td>
                        </tr>
                        <tr>
                            <td><strong>counter_examples_or_negative_results</strong></td>
                            <td>DIV-SE is higher cost due to multiple inference calls; for GPT-3.5 the methods did not improve planning because GPT-3.5 often failed to follow constraints, indicating dependence on model instruction-following capability.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Diversity of Thought Improves Reasoning Abilities of LLMs', 'publication_date_yy_mm': '2023-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4769.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e4769.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models using diverse versus similar reasoning methods to solve reasoning problems, including descriptions of the reasoning methods, tasks, performance, and any comparisons or findings about the effectiveness of diverse versus similar reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>IDIV-SE (BLOCKSWORLD 3, GPT-4)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>In-call DIVerse reasoning path Self-Ensemble (IDIV-SE) on BLOCKSWORLD 3 using GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A cost-reducing variant of DIV-SE that places multiple approaches/personas and their augmented few-shot examples inside a single prompt and requests the model to produce multiple solutions in one call, aggregating them afterward.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>OpenAI GPT-4 as used in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>IDIV-SE (In-call DIVerse reasoning path Self-Ensemble)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>diverse</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_description</strong></td>
                            <td>Compose a single prompt that contains multiple distinct approach/persona sections and augmented examples, ask the model to produce multiple solutions in order inside one inference call, then aggregate (majority vote). Diversity arises from distinct approaches in the same contextual prompt rather than multiple external calls or sampling variability.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>BLOCKSWORLD 3 (planning)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Blocksworld planning benchmark (3-block instances).</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>accuracy ~82% (IDIV-SE reported as +12 percentage points over ZS-CoT baseline of 70% -> implied ≈82%)</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_method</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>performance_other_method</strong></td>
                            <td>ZS-CoT: 70%; SC-10: 73%; DIV-SE: 94%</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>IDIV-SE provides a large accuracy improvement over ZS-CoT at substantially lower inference cost than DIV-SE, but it typically underperforms DIV-SE (likely due to error propagation across chained in-prompt approaches); still it improves the cost-accuracy Pareto frontier versus decoding-based ensembles.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_examples_or_negative_results</strong></td>
                            <td>IDIV-SE performed worse than DIV-SE (≈12 p.p lower on BLOCKSWORLD 3) — the paper attributes part of this gap to error propagation when multiple approaches are chained in a single autoregressive generation.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Diversity of Thought Improves Reasoning Abilities of LLMs', 'publication_date_yy_mm': '2023-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4769.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e4769.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models using diverse versus similar reasoning methods to solve reasoning problems, including descriptions of the reasoning methods, tasks, performance, and any comparisons or findings about the effectiveness of diverse versus similar reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DIV-SE (BLOCKSWORLD 4/5, GPT-4)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>DIVerse reasoning path Self-Ensemble (DIV-SE) on BLOCKSWORLD 4/5 using GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>DIV-SE applied to the harder Blocksworld 4/5 benchmark (4–5 blocks), showing large absolute accuracy gains over baselines and achieving state-of-the-art performance.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>OpenAI GPT-4 as used in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>DIV-SE (DIVerse reasoning path Self-Ensemble)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>diverse</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_description</strong></td>
                            <td>Same as above: run distinct approach/persona prompts in separate inference calls and ensemble outputs via majority vote to leverage diversity of thought.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>BLOCKSWORLD 4/5 (planning)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Blocksworld planning benchmark with 4 or 5 blocks, more challenging planning instances needing valid, constraint-respecting plans.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>accuracy 69.6% (GPT-4, DIV-SE reported)</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_method</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>performance_other_method</strong></td>
                            <td>ZS-CoT: 40% (baseline), SC-10: 41.2%, IDIV-SE: ~57% (IDIV-SE reported +17 p.p over ZS-CoT)</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>DIV-SE dramatically increases accuracy on hard planning instances (improving by 29.6 percentage points on BLOCKSWORLD 4/5 versus ZS-CoT) and is Pareto-optimal in accuracy vs inference-cost trade-off.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_examples_or_negative_results</strong></td>
                            <td>High cost from multiple inference calls; GPT-3.5 showed near-zero baseline and did not benefit due to poor instruction following, indicating model-dependent effectiveness.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Diversity of Thought Improves Reasoning Abilities of LLMs', 'publication_date_yy_mm': '2023-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4769.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e4769.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models using diverse versus similar reasoning methods to solve reasoning problems, including descriptions of the reasoning methods, tasks, performance, and any comparisons or findings about the effectiveness of diverse versus similar reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DIV-SE (Graph Coloring, GPT-4)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>DIVerse reasoning path Self-Ensemble (DIV-SE) on GRAPH COLORING using GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>DIV-SE applied to a constraint-satisfaction task (graph coloring) where many valid solutions exist; uses external verifier for correct solution selection and achieves very high accuracy with GPT-4.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>OpenAI GPT-4 as used in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>DIV-SE (DIVerse reasoning path Self-Ensemble)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>diverse</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_description</strong></td>
                            <td>Run multiple prompts each instantiating a distinct approach/persona to produce candidate colorings, then aggregate using an external sound verifier to pick the valid majority solution; diversity is at the reasoning-approach level.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>GRAPH COLORING (constraint satisfaction)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>100-instance graph-coloring benchmark where solutions are color assignments satisfying edge constraints; many valid non-optimal colorings may exist so a verifier is used to identify correct solutions.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>accuracy 97% (GPT-4, DIV-SE reported as state-of-the-art)</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_method</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>performance_other_method</strong></td>
                            <td>ZS-CoT: 15% (baseline), SC-10: 23%, IDIV-SE: ~74% (IDIV-SE reported +59 p.p above ZS-CoT -> implied ≈74%)</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Diverse approach selection (DIV-SE) yields massive gains on constraint-satisfaction tasks: DIV-SE achieved 97% vs 15% for ZS-CoT and 23% for SC-10, showing that approach-level diversity is far more effective than token-level stochastic ensembling for these problems.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_examples_or_negative_results</strong></td>
                            <td>DIV-SE requires external verification when multiple valid solutions exist; IDIV-SE also improves over baselines but remains substantially lower than DIV-SE, suggesting costs vs robustness trade-offs.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Diversity of Thought Improves Reasoning Abilities of LLMs', 'publication_date_yy_mm': '2023-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4769.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e4769.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models using diverse versus similar reasoning methods to solve reasoning problems, including descriptions of the reasoning methods, tasks, performance, and any comparisons or findings about the effectiveness of diverse versus similar reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>IDIV-SE (Graph Coloring, GPT-4)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>In-call DIVerse reasoning path Self-Ensemble (IDIV-SE) on GRAPH COLORING using GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The in-prompt ensemble variant applied to graph coloring: all approaches are combined into a single prompt to reduce calls; achieves large gains over CoT but below DIV-SE.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>OpenAI GPT-4 as used in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>IDIV-SE (In-call DIVerse reasoning path Self-Ensemble)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>diverse</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_description</strong></td>
                            <td>Place multiple approach/persona sections plus augmented few-shot examples into one prompt so the model emits multiple solutions in a single call; aggregate outputs (majority vote) and use an external verifier for validity.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>GRAPH COLORING (constraint satisfaction)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Graph coloring benchmark (100 examples) requiring valid color assignments; verifier employed for correctness.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>accuracy ≈74% (derived from paper text: IDIV-SE improves absolute accuracy by 59 p.p over ZS-CoT 15% -> implied ≈74%)</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_method</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>performance_other_method</strong></td>
                            <td>ZS-CoT: 15%; SC-10: 23%; DIV-SE: 97%</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>IDIV-SE substantially outperforms CoT and SC baselines at lower inference cost than DIV-SE, but DIV-SE still attains the highest accuracy; indicates that in-prompt combination of diverse approaches captures much of the benefit while reducing calls.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_examples_or_negative_results</strong></td>
                            <td>IDIV-SE remains well below DIV-SE on graph coloring (≈74% vs 97%), indicating error propagation or interference from chaining multiple solutions in a single autoregressive generation.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Diversity of Thought Improves Reasoning Abilities of LLMs', 'publication_date_yy_mm': '2023-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4769.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e4769.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models using diverse versus similar reasoning methods to solve reasoning problems, including descriptions of the reasoning methods, tasks, performance, and any comparisons or findings about the effectiveness of diverse versus similar reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DIV-SE / AQUA-RAT (GPT-4)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>DIVerse reasoning path Self-Ensemble (DIV-SE) on AQUA-RAT using GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>DIV-SE applied to the AQuA-RAT algebraic word-problem dataset; produces notable accuracy increases versus CoT baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>OpenAI GPT-4 as used in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>DIV-SE (DIVerse reasoning path Self-Ensemble)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>diverse</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_description</strong></td>
                            <td>Extract multiple high-level approaches and personas, augment few-shot examples per approach, run each approach in separate calls, and ensemble outputs by majority vote to obtain final answers.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>AQUA-RAT (algebraic word problems)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>AQUA-RAT is a suite of algebraic word problems requiring algebraic reasoning and multi-step solution steps; paper uses test split of 254 questions.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>DIV-SE: reported accuracy increases of +9.84 p.p (FS-CoT) and +14.6 p.p (ZS-CoT) over baselines; computed approximate DIV-SE accuracies ≈81.7% (FS-CoT baseline 71.9% +9.84) and ≈85.1% (ZS-CoT baseline 70.47% +14.6).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_method</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>performance_other_method</strong></td>
                            <td>ZS-CoT baseline ≈70.47%; FS-CoT baseline ≈71.9%; IDIV-SE yields nominal gains (e.g., +7.7 p.p in FS-CoT for GPT-4), SC and CoT reported lower accuracies.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Approach-level diversity (DIV-SE) yields consistent accuracy gains on algebraic word problems compared to CoT and decoding-based ensembles; IDIV-SE also helps but with smaller gains and risk of error propagation.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_examples_or_negative_results</strong></td>
                            <td>IDIV-SE improvements on AQUA-RAT are smaller than DIV-SE; for some high-performing models/datasets (e.g., GSM8K with GPT-4) gains are modest or plateauing.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Diversity of Thought Improves Reasoning Abilities of LLMs', 'publication_date_yy_mm': '2023-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4769.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e4769.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models using diverse versus similar reasoning methods to solve reasoning problems, including descriptions of the reasoning methods, tasks, performance, and any comparisons or findings about the effectiveness of diverse versus similar reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>IDIV-SE / AQUA-RAT (GPT-4 & GPT-3.5)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>In-call DIVerse reasoning path Self-Ensemble (IDIV-SE) on AQUA-RAT using GPT-4 and GPT-3.5</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>IDIV-SE applied to AQUA-RAT showing modest improvements; the paper also measures error-propagation rates as a likely cause of IDIV-SE underperformance vs DIV-SE.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4 and GPT-3.5 Turbo</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>OpenAI GPT-4 and GPT-3.5 Turbo models used in experiments; GPT-3.5 generally had weaker instruction-following for some tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>IDIV-SE (In-call DIVerse reasoning path Self-Ensemble)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>diverse</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_description</strong></td>
                            <td>Single-prompt composition of multiple approaches/personas to produce several solutions in a single call, aggregated by majority vote; reduces inference cost compared to DIV-SE but chains reasoning steps in one autoregressive output.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>AQUA-RAT (algebraic word problems)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>AQuA-RAT dataset of algebraic word problems.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>IDIV-SE: modest gains reported — e.g., GPT-4 IDIV-SE achieved +7.7 p.p in FS-CoT setting; GPT-3.5 also saw improvements but smaller than DIV-SE.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_method</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>performance_other_method</strong></td>
                            <td>DIV-SE: larger gains (see DIV-SE entry), CoT and SC lower (baselines ~70–72%).</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>IDIV-SE gives accuracy gains while reducing inference cost, but some of the performance gap vs DIV-SE is attributable to error propagation in the autoregressive in-prompt chaining; the paper quantifies error-propagation rates to analyze this effect.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_examples_or_negative_results</strong></td>
                            <td>Error propagation rates measured on AQUA-RAT were 6.2% (GPT-4) and 5.5% (GPT-3.5), which partially explain IDIV-SE underperformance relative to DIV-SE; in high-performing benchmarks (e.g., GSM8K with GPT-4) IDIV-SE shows little to no gain.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Diversity of Thought Improves Reasoning Abilities of LLMs', 'publication_date_yy_mm': '2023-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4769.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e4769.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models using diverse versus similar reasoning methods to solve reasoning problems, including descriptions of the reasoning methods, tasks, performance, and any comparisons or findings about the effectiveness of diverse versus similar reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Chain-of-Thought (CoT) Baseline</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Chain-of-Thought prompting (CoT) as baseline</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Chain-of-thought prompting elicits step-by-step reasoning by instructing the model to 'think' through intermediate steps; used as a standard baseline in the paper in both zero-shot and few-shot settings.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Chain of thought prompting elicits reasoning in large language models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4, GPT-3.5, LLaMA-2 70B (as baselines across experiments)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Models on which CoT baselines were run in the paper: GPT-4 and GPT-3.5 (OpenAI models) and experiments with LLaMA-2 70B for AQUA-RAT.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Chain-of-Thought (CoT) prompting (zero-shot or few-shot)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>similar</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_description</strong></td>
                            <td>Prompting the model to produce step-by-step reasoning traces (few-shot CoT uses demonstration rationales; zero-shot CoT uses a generic 'think step by step' instruction). Diversity/similarity: single chain-of-thought per prompt (no ensemble).</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Various (AQUA-RAT, GSM8K, BLOCKSWORLD, GRAPH COLORING, COMMONSENSEQA)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Standard reasoning benchmarks used as baselines; CoT provides baseline correctness metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Examples reported: BLOCKSWORLD 3 (GPT-4) ZS-CoT 70%; BLOCKSWORLD 4/5 40%; GRAPH COLORING ZS-CoT 15%; AQUA-RAT baselines ~70–72% depending on setting; GSM8K GPT-4 near plateau (94–95% in some settings).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_method</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>performance_other_method</strong></td>
                            <td>DIV-SE and IDIV-SE generally outperform CoT baselines across many tasks; SC (self-consistency) sometimes provides modest improvements over CoT but is outperformed by DIV-SE.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>CoT is a strong baseline and necessary for few-shot reasoning, but approach-level diversity (DIV-SE/IDIV-SE) yields further improvements on several tasks, particularly planning and constraint satisfaction, where CoT alone is insufficient.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_examples_or_negative_results</strong></td>
                            <td>On very high-performing tasks/models (e.g., GSM8K with GPT-4), CoT baselines are already near ceiling and DIV-SE/IDIV-SE produce only small or no gains (GSM8K with GPT-4 showed plateauing and modest DIV-SE improvement only).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Diversity of Thought Improves Reasoning Abilities of LLMs', 'publication_date_yy_mm': '2023-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4769.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e4769.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models using diverse versus similar reasoning methods to solve reasoning problems, including descriptions of the reasoning methods, tasks, performance, and any comparisons or findings about the effectiveness of diverse versus similar reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Self-Consistency (SC) Baseline</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Self-Consistency (decoding-based ensemble) prompting</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A decoding-time ensembling method that obtains multiple outputs by sampling (temperature-based) and aggregates them (majority vote); used as a baseline in the paper to compare token-level stochastic diversity against approach-level diversity.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Self-consistency improves chain of thought reasoning in language models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4, GPT-3.5</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>OpenAI models used to run self-consistency experiments; SC runs in the paper used temperature T=0.7 and up to s ∈ [1,10] sampled outputs (denoted SC-s).</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Self-Consistency (SC)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>similar</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_description</strong></td>
                            <td>Increase decoding stochasticity (sampling with temperature) to obtain multiple distinct token-level chains of thought, then ensemble outputs (majority vote) to improve robustness; diversity is at the token/sampling level rather than method/approach level.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Various (BLOCKSWORLD, GRAPH COLORING, AQUA-RAT, GSM8K)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Standard reasoning benchmarks used for comparison; SC is a prominent decoding-time ensemble baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Examples reported: BLOCKSWORLD 3 (GPT-4) SC-10 ≈73%; GRAPH COLORING SC-10 23%; many tasks show SC improves over single CoT but is generally outperformed by DIV-SE.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_method</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>performance_other_method</strong></td>
                            <td>DIV-SE: substantially better on many tasks (e.g., Graph Coloring 97% vs SC-10 23%); IDIV-SE often also outperforms SC at comparable or lower cost.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Decoding-based stochastic ensembles (SC) provide gains over single CoT by increasing token-level diversity, but approach-level diversity (DIV-SE/IDIV-SE) yields much larger gains on complex problems; token-level diversity does not reliably induce method-level independence.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_examples_or_negative_results</strong></td>
                            <td>SC remains helpful and increases performance with more samples s, but it is costlier (many sampled runs producing long CoT outputs) and less effective than DIV-SE for tasks demanding qualitatively different solving strategies.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Diversity of Thought Improves Reasoning Abilities of LLMs', 'publication_date_yy_mm': '2023-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4769.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e4769.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models using diverse versus similar reasoning methods to solve reasoning problems, including descriptions of the reasoning methods, tasks, performance, and any comparisons or findings about the effectiveness of diverse versus similar reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Error Propagation (IDIV-SE)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Error propagation measurement for IDIV-SE (AQUA-RAT)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Quantified measurement of how often earlier wrong answers in an in-prompt chain (IDIV-SE) cause later answers to be wrong due to autoregressive generation, evaluated on AQUA-RAT for GPT-4 and GPT-3.5.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4 and GPT-3.5 Turbo</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>OpenAI models used to measure error propagation in IDIV-SE setup.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>IDIV-SE (error propagation analysis)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>diverse</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_description</strong></td>
                            <td>The paper analyzes cases where all five approaches in IDIV-SE produced the same wrong answer and tests whether later approaches would produce the same (independent) result when re-run in a fresh session: if not, they label it as error propagation due to earlier wrong outputs in the same autoregressive chain.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>AQUA-RAT (FS-CoT)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>AQuA-RAT algebraic word problem benchmark; used to measure how often in-prompt chaining causes leakage of errors.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Measured error-propagation rates: GPT-4 = 6.2%; GPT-3.5 = 5.5% (on the subset of cases analyzed).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_method</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>performance_other_method</strong></td>
                            <td>DIV-SE (separate calls) avoids this autoregressive chaining and thus avoids this form of error propagation; DIV-SE generally outperforms IDIV-SE by amounts comparable to measured propagation rates.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Error propagation (6.2% for GPT-4, 5.5% for GPT-3.5 on AQUA-RAT) is a measurable contributing factor to IDIV-SE's inferiority compared to DIV-SE; while IDIV-SE reduces call cost, autoregressive chaining can cause later solutions to be contaminated by earlier incorrect ones.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_examples_or_negative_results</strong></td>
                            <td>Measured propagation rates are modest but comparable to observed performance gaps between DIV-SE and IDIV-SE; reducing propagation remains challenging due to model autoregressiveness.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Diversity of Thought Improves Reasoning Abilities of LLMs', 'publication_date_yy_mm': '2023-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Chain of thought prompting elicits reasoning in large language models <em>(Rating: 2)</em></li>
                <li>Self-consistency improves chain of thought reasoning in language models <em>(Rating: 2)</em></li>
                <li>Making language models better reasoners with step-aware verifier <em>(Rating: 1)</em></li>
                <li>On the planning abilities of large language models - a critical investigation <em>(Rating: 2)</em></li>
                <li>Large language models don't know they're wrong: An analysis of iterative prompting for reasoning problems <em>(Rating: 1)</em></li>
                <li>Diversity through LLM Interactions <em>(Rating: 1)</em></li>
                <li>Batch prompting: Efficient inference with large language model apis <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-4769",
    "paper_id": "paper-267938465",
    "extraction_schema_id": "extraction-schema-105",
    "extracted_data": [
        {
            "name_short": "DIV-SE (BLOCKSWORLD 3, GPT-4)",
            "name_full": "DIVerse reasoning path Self-Ensemble (DIV-SE) on BLOCKSWORLD 3 using GPT-4",
            "brief_description": "A prompting method that elicits multiple distinct high-level reasoning approaches from the LLM, runs each approach in separate inference calls, and aggregates outputs (majority vote); applied to Blocksworld planning with GPT-4, achieving state-of-the-art accuracy at higher inference cost.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-4",
            "model_description": "OpenAI GPT-4 as used in the paper (instruction-tuned, evaluated with input/output pricing and cost accounting); exact model internals/size not specified in paper.",
            "reasoning_method_name": "DIV-SE (DIVerse reasoning path Self-Ensemble)",
            "reasoning_method_type": "diverse",
            "reasoning_method_description": "Solicit multiple distinct high-level problem-solving approaches (via LLM-guided approach extraction), create separate prompts (each with a single approach + persona + augmented few-shot examples), call the model once per approach, then aggregate outputs by majority vote; diversity is achieved via different approaches/personas rather than stochastic decoding.",
            "task_name": "BLOCKSWORLD 3 (planning)",
            "task_description": "Blocksworld planning benchmark testing planning capability (3-block instances); requires generating valid action plans subject to constraints and goal configuration.",
            "performance": "accuracy 94% (GPT-4, DIV-SE, reported state-of-the-art for BLOCKSWORLD 3)",
            "comparison_with_other_method": true,
            "performance_other_method": "ZS-CoT: 70% (zero-shot chain-of-thought), SC-10: 73% (self-consistency with 10 samples), IDIV-SE: ~82% (IDIV-SE reported as +12 p.p over ZS-CoT)",
            "key_findings": "Running distinct reasoning approaches in separate calls (DIV-SE) substantially outperforms standard CoT and decoding-based ensembles (SC) on hard planning tasks; DIV-SE produced a state-of-the-art 94% on BLOCKSWORLD 3 compared to 70% (ZS-CoT) and 73% (SC-10).",
            "counter_examples_or_negative_results": "DIV-SE is higher cost due to multiple inference calls; for GPT-3.5 the methods did not improve planning because GPT-3.5 often failed to follow constraints, indicating dependence on model instruction-following capability.",
            "uuid": "e4769.0",
            "source_info": {
                "paper_title": "Diversity of Thought Improves Reasoning Abilities of LLMs",
                "publication_date_yy_mm": "2023-10"
            }
        },
        {
            "name_short": "IDIV-SE (BLOCKSWORLD 3, GPT-4)",
            "name_full": "In-call DIVerse reasoning path Self-Ensemble (IDIV-SE) on BLOCKSWORLD 3 using GPT-4",
            "brief_description": "A cost-reducing variant of DIV-SE that places multiple approaches/personas and their augmented few-shot examples inside a single prompt and requests the model to produce multiple solutions in one call, aggregating them afterward.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-4",
            "model_description": "OpenAI GPT-4 as used in the paper.",
            "reasoning_method_name": "IDIV-SE (In-call DIVerse reasoning path Self-Ensemble)",
            "reasoning_method_type": "diverse",
            "reasoning_method_description": "Compose a single prompt that contains multiple distinct approach/persona sections and augmented examples, ask the model to produce multiple solutions in order inside one inference call, then aggregate (majority vote). Diversity arises from distinct approaches in the same contextual prompt rather than multiple external calls or sampling variability.",
            "task_name": "BLOCKSWORLD 3 (planning)",
            "task_description": "Blocksworld planning benchmark (3-block instances).",
            "performance": "accuracy ~82% (IDIV-SE reported as +12 percentage points over ZS-CoT baseline of 70% -&gt; implied ≈82%)",
            "comparison_with_other_method": true,
            "performance_other_method": "ZS-CoT: 70%; SC-10: 73%; DIV-SE: 94%",
            "key_findings": "IDIV-SE provides a large accuracy improvement over ZS-CoT at substantially lower inference cost than DIV-SE, but it typically underperforms DIV-SE (likely due to error propagation across chained in-prompt approaches); still it improves the cost-accuracy Pareto frontier versus decoding-based ensembles.",
            "counter_examples_or_negative_results": "IDIV-SE performed worse than DIV-SE (≈12 p.p lower on BLOCKSWORLD 3) — the paper attributes part of this gap to error propagation when multiple approaches are chained in a single autoregressive generation.",
            "uuid": "e4769.1",
            "source_info": {
                "paper_title": "Diversity of Thought Improves Reasoning Abilities of LLMs",
                "publication_date_yy_mm": "2023-10"
            }
        },
        {
            "name_short": "DIV-SE (BLOCKSWORLD 4/5, GPT-4)",
            "name_full": "DIVerse reasoning path Self-Ensemble (DIV-SE) on BLOCKSWORLD 4/5 using GPT-4",
            "brief_description": "DIV-SE applied to the harder Blocksworld 4/5 benchmark (4–5 blocks), showing large absolute accuracy gains over baselines and achieving state-of-the-art performance.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-4",
            "model_description": "OpenAI GPT-4 as used in the paper.",
            "reasoning_method_name": "DIV-SE (DIVerse reasoning path Self-Ensemble)",
            "reasoning_method_type": "diverse",
            "reasoning_method_description": "Same as above: run distinct approach/persona prompts in separate inference calls and ensemble outputs via majority vote to leverage diversity of thought.",
            "task_name": "BLOCKSWORLD 4/5 (planning)",
            "task_description": "Blocksworld planning benchmark with 4 or 5 blocks, more challenging planning instances needing valid, constraint-respecting plans.",
            "performance": "accuracy 69.6% (GPT-4, DIV-SE reported)",
            "comparison_with_other_method": true,
            "performance_other_method": "ZS-CoT: 40% (baseline), SC-10: 41.2%, IDIV-SE: ~57% (IDIV-SE reported +17 p.p over ZS-CoT)",
            "key_findings": "DIV-SE dramatically increases accuracy on hard planning instances (improving by 29.6 percentage points on BLOCKSWORLD 4/5 versus ZS-CoT) and is Pareto-optimal in accuracy vs inference-cost trade-off.",
            "counter_examples_or_negative_results": "High cost from multiple inference calls; GPT-3.5 showed near-zero baseline and did not benefit due to poor instruction following, indicating model-dependent effectiveness.",
            "uuid": "e4769.2",
            "source_info": {
                "paper_title": "Diversity of Thought Improves Reasoning Abilities of LLMs",
                "publication_date_yy_mm": "2023-10"
            }
        },
        {
            "name_short": "DIV-SE (Graph Coloring, GPT-4)",
            "name_full": "DIVerse reasoning path Self-Ensemble (DIV-SE) on GRAPH COLORING using GPT-4",
            "brief_description": "DIV-SE applied to a constraint-satisfaction task (graph coloring) where many valid solutions exist; uses external verifier for correct solution selection and achieves very high accuracy with GPT-4.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-4",
            "model_description": "OpenAI GPT-4 as used in the paper.",
            "reasoning_method_name": "DIV-SE (DIVerse reasoning path Self-Ensemble)",
            "reasoning_method_type": "diverse",
            "reasoning_method_description": "Run multiple prompts each instantiating a distinct approach/persona to produce candidate colorings, then aggregate using an external sound verifier to pick the valid majority solution; diversity is at the reasoning-approach level.",
            "task_name": "GRAPH COLORING (constraint satisfaction)",
            "task_description": "100-instance graph-coloring benchmark where solutions are color assignments satisfying edge constraints; many valid non-optimal colorings may exist so a verifier is used to identify correct solutions.",
            "performance": "accuracy 97% (GPT-4, DIV-SE reported as state-of-the-art)",
            "comparison_with_other_method": true,
            "performance_other_method": "ZS-CoT: 15% (baseline), SC-10: 23%, IDIV-SE: ~74% (IDIV-SE reported +59 p.p above ZS-CoT -&gt; implied ≈74%)",
            "key_findings": "Diverse approach selection (DIV-SE) yields massive gains on constraint-satisfaction tasks: DIV-SE achieved 97% vs 15% for ZS-CoT and 23% for SC-10, showing that approach-level diversity is far more effective than token-level stochastic ensembling for these problems.",
            "counter_examples_or_negative_results": "DIV-SE requires external verification when multiple valid solutions exist; IDIV-SE also improves over baselines but remains substantially lower than DIV-SE, suggesting costs vs robustness trade-offs.",
            "uuid": "e4769.3",
            "source_info": {
                "paper_title": "Diversity of Thought Improves Reasoning Abilities of LLMs",
                "publication_date_yy_mm": "2023-10"
            }
        },
        {
            "name_short": "IDIV-SE (Graph Coloring, GPT-4)",
            "name_full": "In-call DIVerse reasoning path Self-Ensemble (IDIV-SE) on GRAPH COLORING using GPT-4",
            "brief_description": "The in-prompt ensemble variant applied to graph coloring: all approaches are combined into a single prompt to reduce calls; achieves large gains over CoT but below DIV-SE.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-4",
            "model_description": "OpenAI GPT-4 as used in experiments.",
            "reasoning_method_name": "IDIV-SE (In-call DIVerse reasoning path Self-Ensemble)",
            "reasoning_method_type": "diverse",
            "reasoning_method_description": "Place multiple approach/persona sections plus augmented few-shot examples into one prompt so the model emits multiple solutions in a single call; aggregate outputs (majority vote) and use an external verifier for validity.",
            "task_name": "GRAPH COLORING (constraint satisfaction)",
            "task_description": "Graph coloring benchmark (100 examples) requiring valid color assignments; verifier employed for correctness.",
            "performance": "accuracy ≈74% (derived from paper text: IDIV-SE improves absolute accuracy by 59 p.p over ZS-CoT 15% -&gt; implied ≈74%)",
            "comparison_with_other_method": true,
            "performance_other_method": "ZS-CoT: 15%; SC-10: 23%; DIV-SE: 97%",
            "key_findings": "IDIV-SE substantially outperforms CoT and SC baselines at lower inference cost than DIV-SE, but DIV-SE still attains the highest accuracy; indicates that in-prompt combination of diverse approaches captures much of the benefit while reducing calls.",
            "counter_examples_or_negative_results": "IDIV-SE remains well below DIV-SE on graph coloring (≈74% vs 97%), indicating error propagation or interference from chaining multiple solutions in a single autoregressive generation.",
            "uuid": "e4769.4",
            "source_info": {
                "paper_title": "Diversity of Thought Improves Reasoning Abilities of LLMs",
                "publication_date_yy_mm": "2023-10"
            }
        },
        {
            "name_short": "DIV-SE / AQUA-RAT (GPT-4)",
            "name_full": "DIVerse reasoning path Self-Ensemble (DIV-SE) on AQUA-RAT using GPT-4",
            "brief_description": "DIV-SE applied to the AQuA-RAT algebraic word-problem dataset; produces notable accuracy increases versus CoT baselines.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-4",
            "model_description": "OpenAI GPT-4 as used in the paper.",
            "reasoning_method_name": "DIV-SE (DIVerse reasoning path Self-Ensemble)",
            "reasoning_method_type": "diverse",
            "reasoning_method_description": "Extract multiple high-level approaches and personas, augment few-shot examples per approach, run each approach in separate calls, and ensemble outputs by majority vote to obtain final answers.",
            "task_name": "AQUA-RAT (algebraic word problems)",
            "task_description": "AQUA-RAT is a suite of algebraic word problems requiring algebraic reasoning and multi-step solution steps; paper uses test split of 254 questions.",
            "performance": "DIV-SE: reported accuracy increases of +9.84 p.p (FS-CoT) and +14.6 p.p (ZS-CoT) over baselines; computed approximate DIV-SE accuracies ≈81.7% (FS-CoT baseline 71.9% +9.84) and ≈85.1% (ZS-CoT baseline 70.47% +14.6).",
            "comparison_with_other_method": true,
            "performance_other_method": "ZS-CoT baseline ≈70.47%; FS-CoT baseline ≈71.9%; IDIV-SE yields nominal gains (e.g., +7.7 p.p in FS-CoT for GPT-4), SC and CoT reported lower accuracies.",
            "key_findings": "Approach-level diversity (DIV-SE) yields consistent accuracy gains on algebraic word problems compared to CoT and decoding-based ensembles; IDIV-SE also helps but with smaller gains and risk of error propagation.",
            "counter_examples_or_negative_results": "IDIV-SE improvements on AQUA-RAT are smaller than DIV-SE; for some high-performing models/datasets (e.g., GSM8K with GPT-4) gains are modest or plateauing.",
            "uuid": "e4769.5",
            "source_info": {
                "paper_title": "Diversity of Thought Improves Reasoning Abilities of LLMs",
                "publication_date_yy_mm": "2023-10"
            }
        },
        {
            "name_short": "IDIV-SE / AQUA-RAT (GPT-4 & GPT-3.5)",
            "name_full": "In-call DIVerse reasoning path Self-Ensemble (IDIV-SE) on AQUA-RAT using GPT-4 and GPT-3.5",
            "brief_description": "IDIV-SE applied to AQUA-RAT showing modest improvements; the paper also measures error-propagation rates as a likely cause of IDIV-SE underperformance vs DIV-SE.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-4 and GPT-3.5 Turbo",
            "model_description": "OpenAI GPT-4 and GPT-3.5 Turbo models used in experiments; GPT-3.5 generally had weaker instruction-following for some tasks.",
            "reasoning_method_name": "IDIV-SE (In-call DIVerse reasoning path Self-Ensemble)",
            "reasoning_method_type": "diverse",
            "reasoning_method_description": "Single-prompt composition of multiple approaches/personas to produce several solutions in a single call, aggregated by majority vote; reduces inference cost compared to DIV-SE but chains reasoning steps in one autoregressive output.",
            "task_name": "AQUA-RAT (algebraic word problems)",
            "task_description": "AQuA-RAT dataset of algebraic word problems.",
            "performance": "IDIV-SE: modest gains reported — e.g., GPT-4 IDIV-SE achieved +7.7 p.p in FS-CoT setting; GPT-3.5 also saw improvements but smaller than DIV-SE.",
            "comparison_with_other_method": true,
            "performance_other_method": "DIV-SE: larger gains (see DIV-SE entry), CoT and SC lower (baselines ~70–72%).",
            "key_findings": "IDIV-SE gives accuracy gains while reducing inference cost, but some of the performance gap vs DIV-SE is attributable to error propagation in the autoregressive in-prompt chaining; the paper quantifies error-propagation rates to analyze this effect.",
            "counter_examples_or_negative_results": "Error propagation rates measured on AQUA-RAT were 6.2% (GPT-4) and 5.5% (GPT-3.5), which partially explain IDIV-SE underperformance relative to DIV-SE; in high-performing benchmarks (e.g., GSM8K with GPT-4) IDIV-SE shows little to no gain.",
            "uuid": "e4769.6",
            "source_info": {
                "paper_title": "Diversity of Thought Improves Reasoning Abilities of LLMs",
                "publication_date_yy_mm": "2023-10"
            }
        },
        {
            "name_short": "Chain-of-Thought (CoT) Baseline",
            "name_full": "Chain-of-Thought prompting (CoT) as baseline",
            "brief_description": "Chain-of-thought prompting elicits step-by-step reasoning by instructing the model to 'think' through intermediate steps; used as a standard baseline in the paper in both zero-shot and few-shot settings.",
            "citation_title": "Chain of thought prompting elicits reasoning in large language models",
            "mention_or_use": "use",
            "model_name": "GPT-4, GPT-3.5, LLaMA-2 70B (as baselines across experiments)",
            "model_description": "Models on which CoT baselines were run in the paper: GPT-4 and GPT-3.5 (OpenAI models) and experiments with LLaMA-2 70B for AQUA-RAT.",
            "reasoning_method_name": "Chain-of-Thought (CoT) prompting (zero-shot or few-shot)",
            "reasoning_method_type": "similar",
            "reasoning_method_description": "Prompting the model to produce step-by-step reasoning traces (few-shot CoT uses demonstration rationales; zero-shot CoT uses a generic 'think step by step' instruction). Diversity/similarity: single chain-of-thought per prompt (no ensemble).",
            "task_name": "Various (AQUA-RAT, GSM8K, BLOCKSWORLD, GRAPH COLORING, COMMONSENSEQA)",
            "task_description": "Standard reasoning benchmarks used as baselines; CoT provides baseline correctness metrics.",
            "performance": "Examples reported: BLOCKSWORLD 3 (GPT-4) ZS-CoT 70%; BLOCKSWORLD 4/5 40%; GRAPH COLORING ZS-CoT 15%; AQUA-RAT baselines ~70–72% depending on setting; GSM8K GPT-4 near plateau (94–95% in some settings).",
            "comparison_with_other_method": true,
            "performance_other_method": "DIV-SE and IDIV-SE generally outperform CoT baselines across many tasks; SC (self-consistency) sometimes provides modest improvements over CoT but is outperformed by DIV-SE.",
            "key_findings": "CoT is a strong baseline and necessary for few-shot reasoning, but approach-level diversity (DIV-SE/IDIV-SE) yields further improvements on several tasks, particularly planning and constraint satisfaction, where CoT alone is insufficient.",
            "counter_examples_or_negative_results": "On very high-performing tasks/models (e.g., GSM8K with GPT-4), CoT baselines are already near ceiling and DIV-SE/IDIV-SE produce only small or no gains (GSM8K with GPT-4 showed plateauing and modest DIV-SE improvement only).",
            "uuid": "e4769.7",
            "source_info": {
                "paper_title": "Diversity of Thought Improves Reasoning Abilities of LLMs",
                "publication_date_yy_mm": "2023-10"
            }
        },
        {
            "name_short": "Self-Consistency (SC) Baseline",
            "name_full": "Self-Consistency (decoding-based ensemble) prompting",
            "brief_description": "A decoding-time ensembling method that obtains multiple outputs by sampling (temperature-based) and aggregates them (majority vote); used as a baseline in the paper to compare token-level stochastic diversity against approach-level diversity.",
            "citation_title": "Self-consistency improves chain of thought reasoning in language models",
            "mention_or_use": "use",
            "model_name": "GPT-4, GPT-3.5",
            "model_description": "OpenAI models used to run self-consistency experiments; SC runs in the paper used temperature T=0.7 and up to s ∈ [1,10] sampled outputs (denoted SC-s).",
            "reasoning_method_name": "Self-Consistency (SC)",
            "reasoning_method_type": "similar",
            "reasoning_method_description": "Increase decoding stochasticity (sampling with temperature) to obtain multiple distinct token-level chains of thought, then ensemble outputs (majority vote) to improve robustness; diversity is at the token/sampling level rather than method/approach level.",
            "task_name": "Various (BLOCKSWORLD, GRAPH COLORING, AQUA-RAT, GSM8K)",
            "task_description": "Standard reasoning benchmarks used for comparison; SC is a prominent decoding-time ensemble baseline.",
            "performance": "Examples reported: BLOCKSWORLD 3 (GPT-4) SC-10 ≈73%; GRAPH COLORING SC-10 23%; many tasks show SC improves over single CoT but is generally outperformed by DIV-SE.",
            "comparison_with_other_method": true,
            "performance_other_method": "DIV-SE: substantially better on many tasks (e.g., Graph Coloring 97% vs SC-10 23%); IDIV-SE often also outperforms SC at comparable or lower cost.",
            "key_findings": "Decoding-based stochastic ensembles (SC) provide gains over single CoT by increasing token-level diversity, but approach-level diversity (DIV-SE/IDIV-SE) yields much larger gains on complex problems; token-level diversity does not reliably induce method-level independence.",
            "counter_examples_or_negative_results": "SC remains helpful and increases performance with more samples s, but it is costlier (many sampled runs producing long CoT outputs) and less effective than DIV-SE for tasks demanding qualitatively different solving strategies.",
            "uuid": "e4769.8",
            "source_info": {
                "paper_title": "Diversity of Thought Improves Reasoning Abilities of LLMs",
                "publication_date_yy_mm": "2023-10"
            }
        },
        {
            "name_short": "Error Propagation (IDIV-SE)",
            "name_full": "Error propagation measurement for IDIV-SE (AQUA-RAT)",
            "brief_description": "Quantified measurement of how often earlier wrong answers in an in-prompt chain (IDIV-SE) cause later answers to be wrong due to autoregressive generation, evaluated on AQUA-RAT for GPT-4 and GPT-3.5.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-4 and GPT-3.5 Turbo",
            "model_description": "OpenAI models used to measure error propagation in IDIV-SE setup.",
            "reasoning_method_name": "IDIV-SE (error propagation analysis)",
            "reasoning_method_type": "diverse",
            "reasoning_method_description": "The paper analyzes cases where all five approaches in IDIV-SE produced the same wrong answer and tests whether later approaches would produce the same (independent) result when re-run in a fresh session: if not, they label it as error propagation due to earlier wrong outputs in the same autoregressive chain.",
            "task_name": "AQUA-RAT (FS-CoT)",
            "task_description": "AQuA-RAT algebraic word problem benchmark; used to measure how often in-prompt chaining causes leakage of errors.",
            "performance": "Measured error-propagation rates: GPT-4 = 6.2%; GPT-3.5 = 5.5% (on the subset of cases analyzed).",
            "comparison_with_other_method": true,
            "performance_other_method": "DIV-SE (separate calls) avoids this autoregressive chaining and thus avoids this form of error propagation; DIV-SE generally outperforms IDIV-SE by amounts comparable to measured propagation rates.",
            "key_findings": "Error propagation (6.2% for GPT-4, 5.5% for GPT-3.5 on AQUA-RAT) is a measurable contributing factor to IDIV-SE's inferiority compared to DIV-SE; while IDIV-SE reduces call cost, autoregressive chaining can cause later solutions to be contaminated by earlier incorrect ones.",
            "counter_examples_or_negative_results": "Measured propagation rates are modest but comparable to observed performance gaps between DIV-SE and IDIV-SE; reducing propagation remains challenging due to model autoregressiveness.",
            "uuid": "e4769.9",
            "source_info": {
                "paper_title": "Diversity of Thought Improves Reasoning Abilities of LLMs",
                "publication_date_yy_mm": "2023-10"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Chain of thought prompting elicits reasoning in large language models",
            "rating": 2,
            "sanitized_title": "chain_of_thought_prompting_elicits_reasoning_in_large_language_models"
        },
        {
            "paper_title": "Self-consistency improves chain of thought reasoning in language models",
            "rating": 2,
            "sanitized_title": "selfconsistency_improves_chain_of_thought_reasoning_in_language_models"
        },
        {
            "paper_title": "Making language models better reasoners with step-aware verifier",
            "rating": 1,
            "sanitized_title": "making_language_models_better_reasoners_with_stepaware_verifier"
        },
        {
            "paper_title": "On the planning abilities of large language models - a critical investigation",
            "rating": 2,
            "sanitized_title": "on_the_planning_abilities_of_large_language_models_a_critical_investigation"
        },
        {
            "paper_title": "Large language models don't know they're wrong: An analysis of iterative prompting for reasoning problems",
            "rating": 1,
            "sanitized_title": "large_language_models_dont_know_theyre_wrong_an_analysis_of_iterative_prompting_for_reasoning_problems"
        },
        {
            "paper_title": "Diversity through LLM Interactions",
            "rating": 1,
            "sanitized_title": "diversity_through_llm_interactions"
        },
        {
            "paper_title": "Batch prompting: Efficient inference with large language model apis",
            "rating": 1,
            "sanitized_title": "batch_prompting_efficient_inference_with_large_language_model_apis"
        }
    ],
    "cost": 0.01913775,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Diversity of Thought Improves Reasoning Abilities of LLMs</p>
<p>Ranjita Naik 
Microsoft Varun Chandrasekaran 
Mert Yuksekgonul 
Hamid Palangi 
Besmira Nushi </p>
<p>University of Illinois Urbana-Champaign</p>
<p>Stanford University</p>
<p>Microsoft Research</p>
<p>Microsoft Research</p>
<p>Diversity of Thought Improves Reasoning Abilities of LLMs
16B9358A4220165E5604C6398B16DB15
Large language models (LLMs) are documented to struggle in settings that require complex reasoning.Nevertheless, instructing the model to break down the problem into smaller reasoning steps, or ensembling various generations through modifying decoding steps boosts performance.However, these methods assume that the input prompt is fixed and expect the decoding strategies to introduce the diversity needed for ensembling.In this work, we discuss how one can create and leverage variations of the input prompt as a means of diversity of thought.We propose a method that automatically improves prompt diversity by soliciting feedback from the LLM to ideate approaches that are apt for the problem.We then ensemble the diverse prompts in our method DIV-SE (DIVerse reasoning path Self-Ensemble) across multiple inference calls, or use diverse approaches within a single inference call; we call the latter IDIV-SE (In-call DIVerse reasoning path Self-Ensemble).Apart from our approaches outperforming prior work, DIV-SE (in particular) advances state-of-the-art performance on the challenging planning and graph coloring benchmarks.Our results improve the Pareto frontier of the accuracy-cost trade-off.Q: Michael had 58 golf balls.On tuesday, he lost 23 golf balls.On wednesday, he lost 2 more.How many golf balls did he have at the end of wednesday?A: Michael started with 58 golf balls.After losing 23 on tuesday, he had 58 -23 = 35.After losing 2 more, he had 35 -2 = 33 golf balls.The answer is 33.Q: A candle melts by 2 centimeters every hour that it burns.How many centimeters shorter will a candle be after burning from 1:00 PM to 5:00 PM? Input Q: Michael had 58 golf balls.On tuesday, he lost 23 golf balls.On wednesday, he lost 2 more.How many golf balls did he have at the end of wednesday?A: Approach 1 <Using direct calculation>: Subtract the total number of golf balls lost from (…) Therefore, he had 33 golf balls at the end of Wednesday.Approach 2 <Using algebra>: Let x be the number of golf balls Michael had (…) we find that Michael had 33 golf balls at the end of Wednesday.Approach 3 <Using visualization>: Represent the problem using a diagram with three stages: (…) leaving him with 33 golf balls at the end of Wednesday.</p>
<p>Introduction</p>
<p>Large language models (LLMs) exhibit state-ofthe-art performance across a myriad of tasks, but their effectiveness is strongly influenced by prompt design (Anil et al., 2023;OpenAI, 2023a;Nori et al., 2023).For complex reasoning tasks, the right prompt can enable LLMs to capitalize on task structure (Guidance, 2024), such as by facilitating memory (by externalizing thought processes), or through tractable problem decomposition (Zhou et al., 2024).However, existing prompt design either relies on iterative trial-and-error (White et al., 2023), or is expensive (Lester et al., 2021).</p>
<p>Previous works identified two simple, yet general prompting principles to enable complex reasoning: (i) Chain-of-Thought (CoT) prompting, and (ii) ensembling multiple solutions from diverse decoding paths.CoT prompting (Wei et al., 2022) improves performance by guiding the LLM to follow step-by-step reasoning.Selfconsistency (SC) (Wang et al., 2023) instead increases the stochasticity by modifying the decoding process and obtaining multiple completions, which are then ensembled.</p>
<p>However, combining the two principles raises limitations.First, inference is significantly more expensive due to numerous runs, each generating long completions with many reasoning steps.Next, it may be impermissible to modify the decoding process in some settings, such as commercial deployments.Finally, stochasticity-based methods do not directly guide the diversity at the level of thought or method, but rather at the token level.This poses limitations because linguistic token diversity does not always ensure diverse and independent solution approaches.</p>
<p>In this paper, we explore how to explicitly promote the diversity of thought while mitigating the aforementioned issues.Prior work by Li et al. (2023) highlights the importance of prompt diversity, but their notion of diversity is captured through variety in the few-shot examples provided with the prompt; ours focuses on the reasoning approach.We first solicit the LLM to produce multiple-highlevel reasoning approaches for problem-solving (e.g., method of elimination, visualization techniques etc. for math reasoning problems).We then leverage GPT-4 to augment few-shot examples used in prior work (Wei et al., 2022) into the corresponding approaches, whenever applicable.</p>
<p>We propose DIV-SE (DIVerse reasoning path Self-Ensemble) to extract and aggregate responses Graph Coloring, GPT-4</p>
<p>Figure 1: Diversity of Thought enhances the inference cost vs.accuracy trade-off.We compare DIV-SE and IDIV-SE with SC (Wang et al., 2023) and CoT (Wei et al., 2022) across three benchmarks.The x-axis indicates the total inference cost (as defined in § 3) on the benchmark using the given method, while the y-axis represents the LLM's performance.The few-shot-CoT setting is represented by filled gray dots, while the zero-shot-CoT setting is indicated by unfilled dots.Notice that for a fixed cost, our approaches always give better performance.</p>
<p>(via majority vote) across multiple inference calls ( § 2.2).Since distinct approaches introduce diversity at the "thought" level, our methodology results in improved ensemble accuracy.In Fig. 1, we show that it yields more accurate results across multiple reasoning benchmarks at a fixed inference cost, without modifying the decoding procedure.For instance, in the BLOCKSWORLD 4/5 task (Valmeekam et al., 2022), DIV-SE improves the performance by 29.6 percentage points (p.p).However, this method still leverages multiple inference calls, which could be costly.</p>
<p>To reduce inference costs, we build on the observation that the approaches are often mutually independent, and can be combined in a single prompt to solicit multiple solutions (Cheng et al., 2023).Based on this premise, we propose IDIV-SE (Incall DIVerse reasoning path Self-Ensemble; § 2.2), which combines all approaches within the same prompt and aggregates all resulting outputs to leverage diversity with a reduced cost.Fig. 1 demonstrates that this method obtains comparable accuracy to DIV-SE and better performance than prior work with lower inference costs.</p>
<p>We push the pareto frontier of the cost-accuracy trade-off of prompting strategies across multiple reasoning tasks ( § 4), outperforming both CoT and SC prompting on both GPT-3.5 and GPT-4.This is evident from Fig. 1 for the AQUA-RAT (Ling et al., 2017), planning (Valmeekam et al., 2023), and graph coloring (Stechly et al., 2023) benchmarks, where there is a performance improvement of 16.52, 29.6, and 82.5 p.p respectively.These improvements, some of which are state-of-the-art, show the potential of thought diversity to extract complex reasoning abilities from LLMs that were impossible to leverage otherwise.We will open source our code upon publication to encourage further research.</p>
<p>Diversity through LLM Interactions</p>
<p>First, we introduce terms and notations that we use throughout the paper.We use upper case for sets, lower case for variables, and [n] = {1, • • • , n}.Approach: These are reasoning strategies for problem solving, denoted with the variable a.For example, for the GSM8K (Cobbe et al., 2021), a benchmark of grade-school math problems , some of the (generated) approaches can include a 1 ="using visualizations", a 2 ="working backwards", a 3 ="using direct calculation", and a 4 ="method of elimination".Persona: In addition to specifying "how" to solve a reasoning problem, specifying a persona can also influence how the LLM behaves (Salewski et al., 2023).We denote this with the variable p e.g., p 1 ="Thinking like Alan Turing", p 2 ="Thinking like Math Professor" for the GSM8K task.Note that both approaches and personas are dependent on the reasoning problem.</p>
<p>Using the LLM as a guide</p>
<p>Proposed method for creating prompts, which we term DIVERSEPROMPTING is presented in Algorithm 1. Below, we will describe each step in more detail.At a high-level, we solicit feedback from the LLM on how to solve tasks.</p>
<p>Step 1+2.Extracting Approaches &amp; Personas: Note that LLMs trained on internet-scale data encode a significant knowledge from multiple do-Q: A candle melts by 2 centimeters every hour that it burns.How many centimeters shorter will a candle be after burning from 1:00 PM to 5:00 PM?</p>
<p>Approach 1 <using hypothetical numbers> : Assume a starting length for the candle, say 100 centimeters.(…) The candle will be 8 centimeters shorter.The answer is 8 centimeters.</p>
<p>Approach 2 <using stepwise reduction>: Let x be the original length of the candle.After 4 hours(…) the candle will be 2 centimeters shorter at the end of 4 hours.The answer is 2 centimeters.</p>
<p>Approach 3 <using rate and time>: The rate of the candle melting is 2 centimeters per hour.So, if we multiply the rate by the time it burns, we (…)At 5:00 PM, the candle is 8 centimeters shorter than its original length.The answer is 8 centimeters.</p>
<p>Input Output</p>
<p>A: If a candle melts by 2 centimeters every hour and it burns from 1:00 PM to 5:00 PM, we can assume it burns for a total of 4 hours.4 divided by 2 is 2.the candle would be 2 centimeters shorter after burning from 1:00 PM to 5:00 PM.The answer is 2 centimeters.</p>
<p>CoT Prompting</p>
<p>IDIV-SE Prompting</p>
<p>Output</p>
<p>Figure 2: Diversity of Thought.This illustration depicts CoT and IDIV-SE prompting strategies.Notice that both have a single example.However, IDIV-SE presents more diversity in terms of reasoning paths.This enables it to generate diverse completions, yielding more accurate responses.</p>
<p>mains (Liang et al., 2022;Bubeck et al., 2023).While LLMs may not be perfect at solving reasoning tasks, we hypothesize that they are helpful in providing high-quality intermediate feedback.</p>
<p>To extract approaches, we utilize the following methodology: (i) Randomly picking a question from the reasoning dataset D we want to evaluate; and (ii) Creating an instruction prompt where we ask the LLM to generate the names of b ∈ [1, 5] approaches to solve the aforementioned question conforming to a predefined template (for easier post-processing).Refer to Figure 5 for an example of the prompt used.</p>
<p>We extract the part of the response that is compliant with the template and store it.We repeat this process c times (obtaining of c • b candidate approaches), and pick the n most frequent approaches to store in set A1 .This process is abstracted as method det_approaches(.).</p>
<p>One can repeat the above process used to extract relevant personas for a given reasoning task.However, we followed a simpler route and asked the model directly for relevant personas for a given task and then included them in the set of m candidate personas P used.This is abstracted as method det_personas(.).Note that no persona (ϕ) is also part of the persona set.</p>
<p>Step 3. Choosing the Best Persona, Approach Pairs: The choice of persona and approaches introduces a principled way to promote diversity.</p>
<p>If the set of personas is P , and the set of approaches is A, the Cartesian product of P and A yields the total number of prompts.In practice, for each combination (denoted by s i ) of persona and approach, we evaluate the prompt formed using the composition on a small validation set V 1 and choose the best performing "size" elements on the given task2 .</p>
<p>Step 4. Augmenting few-shot examples: Once the (subset of) approach and persona pairs are fixed, we ask the LLM to augment existing few-shot examples (denoted F = {f 1 , • • • }) with the given set of approaches.Specifically, we take the few-shot examples provided by Wei et al. (2022), and ask the LLM to solve them in the style of a chosen approach and persona pair (Fig. 8); we term the DIVERSEPROMPTING: Prompt creation.output augmented few-shot examples.This is abstracted in method augment(.),where Ti,j is the set of augmented few-shot examples corresponding to the approach and persona pair from s i and example f j .An example is visualized in the bottom left of Fig. 2, where the prompt contains different approaches for solving a math problem.</p>
<p>Designing the Prompts</p>
<p>Step 5. Prompt Composition: We create prompts for our approach using the best approach and persona pairs identified in step 3, and augmented fewshot examples from step 4 as shown in Fig. 2 and 4.</p>
<p>We now describe two techniques to generate prompts with the augmented demonstrations (T ) that have been accumulated.Candidate 1. DIV-SE: We first propose DIV-SE (DIVerse reasoning path Self-Ensemble), a method to execute the diverse set of approaches in different inference calls and aggregate their solutions.Apart from the question to be solved and the augmented few-shot examples, the final prompt contains a persona, approach, and additional instructions.One example is visualized in Fig. 4 (please refer to appendix for more examples of prompts: Fig. 9 through 16).Diversity is ensured through running inference with multiple prompts, each with a different approach and persona pairs and augmented few-shot examples.However, since the approaches are executed separately, generating a solution (via aggregation of multiple responses) requires multiple inference calls, which can be costly.</p>
<p>Candidate 2. IDIV-SE:</p>
<p>To further reduce the inference costs while promoting diversity, we propose IDIV-SE (In-call DIVerse reasoning path Self-Ensemble).In IDIV-SE, the final prompt is a composition of all approach and persona pairs and corresponding augmented few-shot examples, and the question to be solved.An example is presented in Fig. 2 (bottom left).More examples of prompts are presented in the appendix in Fig. 9 through 16.This noticeably decreases the number of calls to be made, since all few-shot examples are presented within the same prompt.We note that there might be error propagation due to the autoregressive nature of models.We evaluate this in detail in § 4.3.Practicality.Crucially, DIVERSEPROMPTING finds approaches that are general and reusable across similar reasoning problems.We reused the strategies identified for solving AQUA-RAT and Planning benchmark respectively in the MATH (counting and probability) and Graph Coloring benchmarks.This also reduces the cost of repeated evaluation on a separate evaluation set.Aggregation.We aggregate the responses via majority vote for both prompting strategies.Other aggregation strategies can also be leveraged, such as utilizing the LLM itself to aggregate responses or weighted aggregation.In § 4.4, we consider an aggregation strategy proposed by Yoran et al. (2023) and describe how compatible it is with our prompting approaches.</p>
<p>Experiments</p>
<p>We consider the following reasoning benchmarks.Arithmetic Reasoning: We use: (i) AQUA-RAT (Ling et al., 2017), a suite of algebraic word problems, (ii) GSM8K (Cobbe et al., 2021), a benchmark of grade-school math problems described in natural language (involving elementary arithmetic operations), and (iii) MATH (Counting and Probability) (Hendrycks et al., 2021), a collection of math problems from which we choose only counting and probability as these are not covered by GSM8K and AQUA-RAT.For all datasets, we use the test split for evaluation, containing 254, 1319, and 474 questions respectively.Planning Capabilities: We use the Blocksworld Planning benchmark proposed in Valmeekam et al. (2022Valmeekam et al. ( , 2023)).The benchmark has two datasets: one involves 3 blocks (BLOCKSWORLD 3, 100 We compare DIV-SE and IDIV-SE with SC (Wang et al., 2023) and CoT (Wei et al., 2022) across three benchmarks.The x-axis indicates the total cost (as defined in § 3) of running inference with the LLM on the benchmark using the given method, while the y-axis represents the LLM's performance.The FS-CoT setting is represented by filled gray dots, while the ZS-CoT setting is indicated by unfilled dots.Notice that for BLOCKSWORLD 3, despite being in the ZS-CoT setting, our approaches are more performant than the SC-s (FS-CoT) baseline.</p>
<p>instances), while the other dataset involves 4 or 5 blocks (BLOCKSWORLD 4/5, 500 instances).</p>
<p>Constraint Satisfaction Optimization: We use the GRAPH COLORING benchmark (Stechly et al., 2023) containing 100 examples to test reasoning for constraint satisfaction.Commonsense Reasoning: We use COMMONSENSEQA (Talmor et al., 2019) which consists of generic multiple-choice questions elicited for testing common sense reasoning.We use the validation split containing 1,221 questions.</p>
<p>Language Models.We evaluate our proposed methods on both GPT-3.5 Turbo (OpenAI, 2022) and GPT-4 (OpenAI, 2023b).We also conduct an additional evaluation on LLaMA-2 70B (Touvron et al., 2023) to explore the performance of our technique on open-source LLMs.For the latter, we use meta-llama/Llama-2-70b-chat-hf through the Transformers library (Wolf et al., 2019).</p>
<p>Baselines.</p>
<p>We consider Chain-of-Thought (CoT) (Wei et al., 2022) and Self-Consistency (SC ) (Wang et al., 2023) as our baselines.For CoT, we consider two settings: zero-shot (ZS) CoT (Kojima et al., 2022) (i.e., "Think step by step" is added to the prompt), and few-shot (FS) CoT (i.e., CoT with demonstrations).In our SC runs, we set the temperature T = 0.7 without top-k truncation and sample up to s ∈ [1, 10] outputs (denoted SC-s).For all other approaches, we set T = 0. We use ensembles of size 5 in IDIV-SE and DIV-SE for GSM8K and AQUA-RAT.For the planning, GRAPH COLORING, and COMMON-SENSEQA benchmarks, we use a size of 3. Performance Metrics.We measure the accuracy on the task, and the generation inference cost.To measure the cost, we assume 1000 tokens are about 750 words3 .For GPT-4 (8K) the input and output prices used to estimate inference cost are $0.03/1ktokens and $0.06/1k tokens, respectively.For GPT 3.5 Turbo (16K), the input and output prices used in the cost estimation are $0.003/1k(tokens) and $0.004/1k (tokens) respectively.Results Summary.include: Across most benchmarks we consider, our techniques provide substantial performance gains (e.g., 16.52, 82.5, and 14.3 p.p improvements for AQUA-RAT, GRAPH COLORING, and MATH respectively).They are also Pareto optimal (in terms of the utility vs. cost trade-off).For the challenging planning benchmark (BLOCKSWORLD 4/5), our techniques improve accuracy by 29.6 p.p achieving state-of-the-art performance.Using GPT-4 for BLOCKSWORLD 3, our approach (in the ZS-CoT setting) is substantially more effective than SC-10 (in the FS-CoT setting) at 4× lower cost (Figure 3 (center figure)).</p>
<p>Since prompts are chained together in IDIV-SE, error propagation is possible.Our evaluation on AQUA-RAT in § 4.3 suggests that even though error propagation is estimated as less than 6.5% for both models, these rates are comparable to differences in performance between DIV-SE and IDIV-SE.When combined with aggregation approaches that are capable of reasoning across the diverse generations (Yoran et al., 2023), we observe additional performance gains as shown in § 4.4.For the AQUA-RAT benchmark for instance, we see an accuracy of 67.7% for GPT-3.5 (3.23 p.p improvement to majority voting).</p>
<p>Results</p>
<p>Main Results</p>
<p>We present the summary of results in  , 1998).We use natural language prompts in all the experiments.For the baseline runs, we introduce minor alterations to the prompt originally proposed by Valmeekam et al. (2023).These changes involve incorporating an explicit directive to prevent under-block movement and resolving minor language ambiguities we observed to be problematic during initial investigation.Furthermore, we reposition the initial condition and goal state information to the beginning of the prompt.The modified improved prompt is presented in Fig. 9.We aggregate the plans through majority voting and utilize string matching for comparing the plans.As a result, we optimize the plan by eliminating the redundant "no-op" steps.GPT-4 Results: We note that GPT-4 performs slightly better in a ZS setting, and use this to run all experiments.From Fig. 1, we observe that for BLOCKSWORLD 3, ZS-CoT records an accuracy of 70%, while SC-10 reaches an accuracy level of 73%.IDIV-SE enhances the absolute accuracy by 12 p.p above the ZS-CoT baseline, while DIV-SE produces an impressive state-of-the-art accuracy of 94%.An analysis of the six unsuccessful instances suggests the capacity for further performance improvement by increasing the size of the ensemble, as already two out of five current approaches generate accurate plans.For the BLOCKSWORLD 4/5 case, the ZS-CoT accuracy is 40%, while SC-10 has an accuracy of 41.2%.Here, IDIV-SE results in an absolute gain of 17 p.p above the ZS-CoT baseline, and DIV-SE too enhances performance, leading to 69.6%.As outlined in Fig. 1 and 3, both IDIV-SE and DIV-SE achieve Pareto optimality.GPT-3.5 Results: The baseline performance on BLOCKSWORLD 3 is 6%, and on BLOCKSWORLD 4/5 is 0.6%.We do not see any additional improvement using both IDIV-SE and DIV-SE.Qualitatively, we observe that during plan generation, GPT-3.5 fails to follow the restrictions provided as part of the problem instructions too often, leading to either infeasible or incorrect plans.This shows instruction following capabilities are crucial to the success of the methods proposed here.</p>
<p>Constraint Satisfaction via GRAPH COLORING</p>
<p>There may exist numerous non-optimal yet valid colorings for a given graph.Since exact string matching is not usable for identifying the majority solution from the ensembles of IDIV-SE and DIV-SE, we employ the external, sound verifier (Stechly et al., 2023) to pick the correct solution.</p>
<p>GPT-4 Results: From Fig. 1, it is observed that ZS-CoT achieves an accuracy of 15%, whereas SC-10 attains an accuracy level of 23%.IDIV-SE improves the absolute accuracy by 59 p.p above the ZS-CoT baseline.Remarkably, DIV-SE delivers a state-of-the-art accuracy of 97%.Given that GPT-4's performance plateaus in the ZS setting, we chose to omit conducting the few-shot experiments.Summary: Methods in this work often demonstrate state-of-the-art performance on reasoning tasks.This is most significant in the planning and constraint satisfaction benchmarks, where the corresponding authors claimed immense difficulty for existing LLMs.Our work shows that statusquo prompt design approaches including chain of thought are too generic for these problems, and prompt customization (via DIVERSEPROMPTING) can yield substantial gains by guiding the chain of thought to the general nature of the problem.</p>
<p>Open Source Models</p>
<p>Due to the limited computational budget, we only performed experiments with the AQUA-RAT benchmark.Please refer to Appendix B for further details.</p>
<p>Errors &amp; Prompt Utility</p>
<p>Error Propagation: Due to the autoregressive nature of LLM decoding, early incorrect answers in IDIV-SE may get propagated to the latter ones.</p>
<p>To quantify this, we select examples where the solution is incorrect and all five approaches produce the same erroneous answer.We focus only on these cases to see if e.g., a wrong conclusion in the initial approaches leaks into the following ones.Next, we attempt the last two approaches again in a separate session: if the LLM generates the same outcomes as in the original session (i.e., IDIV-SE setup) within 3 attempts, we consider it as no error propagation.However, if it does not produce the same answer within the 3 attempts, we interpret this as a case of error propagation since the change in answer could be attributed to the initial approaches with wrong answers in the chain.</p>
<p>We measure this phenomenon on AQUA-RAT (FS-CoT) on both GPT-4 and GPT-3.5.We find that GPT-4 and GPT-3.5 have error propagation rates of 6.2% and 5.5% respectively, which are comparable to performance differences between DIV-SE and IDIV-SE, making error propagation one of the main explanatory hypotheses for the differences between the two methods.Reducing these error rates remains a challenging problem given the autoregressive nature of current LLMs.</p>
<p>Beyond Thinking Step by</p>
<p>Step: The diverse approaches and personas we utilize not only enhance the performance in IDIV-SE and IDIV-SE, but are also independently superior to ZS-CoT.Table 4 highlights this effect, which showcases the importance of conditioning the model for solutions via DIVERSEPROMPTING.</p>
<p>Alternative Aggregation Strategies</p>
<p>Our aggregation thus far relies on majority voting.Li et al. (2023), which shows the importance of prompt diversity.However, they rely on selecting few-shot demonstrations from a holdout set (which defines diversity in their method), without explicitly stating reasoning pathways.</p>
<p>Conclusions</p>
<p>In this work, we promoted diversity of thought as a principled prompting strategy and proposed methodologies that leverage the LLM as a guide to design a diverse set of approaches to solve complex reasoning tasks.Extracting solution approaches from LLMs themselves becomes a discovery mechanism that seeds and conditions generative solutions.Reported results on a variety of tasks confirm that there is a large space for improvement in com-plex reasoning by uncovering the necessary skills and knowledge from LLMs through targeted and diverse prompting methods.These results demonstrated how promoting diversity can improve the Pareto frontier of accuracy-cost trade-off for current LLMs and yield state-of-the-art solutions for planning and mathematical reasoning tasks.We hope that future work will expand these results to complex tasks from other real-world applications.</p>
<p>Limitations</p>
<p>Our study mainly experimented with GPT-3.5 and GPT-4 models because of their instructionfollowing capabilities.While current open-source models have shown remarkable improvements to this end, they are still not able to reliably follow instructions relevant to complex reasoning tasks (e.g.state tracking, plan validity, constraint satisfaction).We hope that progress in the field will enable further experimentation in this direction.</p>
<p>In addition, we also observe that error propagation during autoregressive generation may sometimes negatively impact the performance of IDIV-SE, where all approaches are executed in order within the same prompt.Some of this could be addressed by explicitly instructing the model to forget about the previous solution but ultimately as long as previous generation history remains in context and short-term memory, error propagation risks may still need to be tracked and measured.</p>
<p>B Model Details</p>
<p>B.1 Open-Source Models</p>
<p>We perform the Llama-2 70B experiments with a single 80GB A100 GPU.To fit the 70B model to a single A100, we use 8-bit precision through bitsandbytes (Dettmers et al., 2022a,b).Further, Dettmers et al. (2022a) reports no performance drop with this quantization method.</p>
<p>As the system prompt, we use You are a helpful, respectful and honest assistant.We perform inference with greedy decoding, having temperature T = 0.</p>
<p>C Additional Results</p>
<p>In this section, we provide additional results on COMMONSENSEQA and GSM8K benchmarks.</p>
<p>C.1 Common sense via COMMONSENSEQA</p>
<p>Table 2 presents the results of the experiments.Overall, the improvements in accuracy are relatively modest.This is likely because answering questions in COMMONSENSEQA does not demand as much reasoning and thought diversity as is required in some other benchmarks.In addition, the dataset also contains a number of ambiguous questions, which if read verbatim may have many plausible answers but the ground truth contains only one answer.</p>
<p>C.2 Arithmetic reseasoning via GSM8K</p>
<p>GPT-4 Results: As shown in Fig. 6, accuracy on GSM8K have nearly plateaued, with the ZS-CoT and FS-CoT baselines achieving accuracies of 94% and 95% respectively.IDIV-SE does not produce any significant gains in either setting.On the other hand, DIV-SE reaches accuracy of 96.3% in both FS-CoT and ZS-CoT settings, providing a modest improvement.GPT-3.5 Results: Here, the gains are more substantial.Compared to the ZS-CoT baseline of 76.11%, IDIV-SE provides an improvement of 5.31 p.p. DIV-SE goes a step further, enhancing the accuracy by 10.39 p.p.In the FS-CoT setting, DIV-SE posts an accuracy improvement of 7.68 p.p (with a baseline accuracy of 81.4%).</p>
<p>Fig. 3 (rightmost) presents the cost vs.accuracy trade-offs between IDIV-SE, DIV-SE, and SC.While the performance of SC does improve with the expansion of reasoning paths, both IDIV-SE and DIV-SE offer better trade-offs.</p>
<p>D Evaluating Ensemble Sizes</p>
<p>Figure 6 depicts the average accuracy of different ensemble sizes on GSM8K for both ZS-CoT and FS-CoT settings, utilizing GPT-4 and GPT-3.5.Similarly, Figure 7 demonstrates the average accuracy of various ensemble sizes on AquA for both ZS-CoT and FS-CoT settings, using GPT-4 and GPT-3.5.It is noteworthy that in both AQuA and GSM8K, even an ensemble of size three yields significant performance improvements over the baseline, which we attribute to the high diversity and independence of reasoning paths.</p>
<p>E Prompt Templates</p>
<p>The following section provides a comprehensive visual representation of the prompts used in our study.These prompts, depicted in Figures 9 through 16, were used in different settings and for the planning, AQuA, and graph coloring benchmarks, and incorporate various personas and approaches.</p>
<p>Figure 9 illustrates the prompt used in the baseline run, Figure 10 demonstrates the prompt employed when applying a Finite State Machine approach, Figure 11 depicts the prompt used when incorporating the persona of Alan Turing and an Action Rationale approach, and lastly, Figure 12 shows the prompt used when applying the persona of Alan Turing and the Progressive Block Placement approach in the zero-shot setting for the planning benchmark.</p>
<p>Figure 13 illustrates the algebraic approach, while Figure 14 and Figure 15 demonstrate the prompts incorporating the personas of Alan Turing and Dr. Patel, a renowned mathematician, respectively, in the few-shot-CoT setting for the AQuA benchmark.</p>
<p>In Figure 16 we present the IDIV-SE prompt used in the zero-shot setting for the graph coloring benchmark.</p>
<p>Q: Michael had 58 golf balls.On tuesday, he lost 23 golf balls.On wednesday, he lost 2 more.How many golf balls did he have at the end of wednesday?<Using direct calculation>: Subtract the total number of golf balls lost from (…) Therefore, he had 33 golf balls at the end of Wednesday.</p>
<p>Q: A candle melts by 2 centimeters every hour that it burns.How many centimeters shorter will a candle be after burning from 1:00 PM to 5:00 PM? <using direct calculation>: The candle burns for 4 hours from 1:00 PM to 5:00 PM. (…) The candle will be 8 centimeters shorter.The answer is 8 centimeters.</p>
<p>Input 1</p>
<p>Output 1</p>
<p>DIV-SE Prompting</p>
<p>Q: Michael had 58 golf balls.On tuesday, he lost 23 golf balls.On wednesday, he lost 2 more.How many golf balls did he have at the end of wednesday?</p>
<p><Using visualization>: Represent the problem using a diagram with three stages: (….) leaving him with 33 golf balls at the end of Wednesday.</p>
<p>Q: A candle melts by 2 centimeters every hour that it burns.How many centimeters shorter will a candle be after burning from 1:00 PM to 5:00 PM Input 2 <using algebra>: Let x be the original length of the candle.After 4 hours(…) the candle will be 2 centimeters shorter at the end of 4 hours.</p>
<p>The answer is 2 centimeters.</p>
<p>Output 2 Q: Michael had 58 golf balls.On tuesday, he lost 23 golf balls.On wed,lost 2 more.How many golf balls did he have at the end of wednesday?</p>
<p><Using algebra>: Let x be the number of golf balls Michael had …we find that Michael had 33 golf balls at the end of Wednesday.</p>
<p>Q: A candle melts by 2 centimeters every hour that it burns.How many centimeters shorter will a candle be after burning from 1:00 PM to 5:00 PM?</p>
<p><using visualization>: Here's the visual representation: ---| (2 hours later) (…)At 5:00 PM, the candle is 8 centimeters shorter than its original length.The answer is 8 centimeters.
|-----------------| (original length) |--------| (1 hour later) |-</p>
<p>Output 3 Input 3</p>
<p>Figure 4: DIV-SE prompting.</p>
<p>Use five distinct approaches to solve the given problem accurately.there is no exact match choose the closest option.Q: {Question} Use the following output format: Approach 1 &lt; name of the approach &gt; : &lt; Details of Approach 1 &gt; Approach 2 &lt; name of the approach &gt; : &lt; Details of Approach 2 &gt; Approach 3 &lt; name of the approach &gt; : &lt; Details of Approach 3 &gt; Approach 4 &lt; name of the approach &gt; : &lt; Details of Approach 4 &gt; Approach 5 &lt; name of the approach &gt; : &lt; Details of Approach 5 &gt;</p>
<p>Input Prompt</p>
<p>Solve the problem accurately using {approach name}.</p>
<p>Question: John found that the average of 15 numbers is 40.If 10 is added to each number then the mean of the numbers Answer Choices: (A) 50 (B) 45 (C) 65 (D) 78 (E) 64 A: If 10 is added to each number, then the mean of the numbers also increases by 10.So the new mean would be 50.The answer is (A).</p>
<p>Approach <using {approach name} >:
Augmented Few-shot Examples
Approach <using visualization>:</p>
<p>To solve this problem using visualization, let's consider the given information and the effect of adding 10 to each number on the average.1.The average of 15 numbers is 40.This means that the sum of these 15 numbers is 15 * 40 = 600.</p>
<ol>
<li>
<p>Now, we add 10 to each number.Since there are 15 numbers, the total added is 15 * 10 = 150.</p>
</li>
<li>
<p>The new sum of the 15 numbers is 600 + 150 = 750.4. To find the new average, we divide the new sum by the number of values, which is 750 / 15 = 50.So, the mean of the numbers after adding 10 to each number is 50.The answer is: (A) 50</p>
</li>
</ol>
<p>Approach <using logical reasoning>:</p>
<p>We know that adding the same constant to each number in a set will increase the average by that constant.In this case, we are adding 10 to each number, so the average will increase by 10.New average = 40 + 10 = 50 The answer is: (A) 50</p>
<p>Approach <using elimination strategy>:</p>
<p>We know that adding 10 to each number will increase the average by 10.So, we're looking for an answer choice that is 10 more than the original average of 40.I am playing with a set of blocks where I need to arrange the blocks into stacks.</p>
<p>[STATEMENT] As initial conditions I have that, the orange block is clear, the hand is empty, the blue block is on top of the red block, the orange block is on top of the blue block and the red block is on the What is the plan to achieve my goal?Just give the actions in the plan.</p>
<p>[PLAN]  [PLAN]</p>
<p>procedure DIVERSEPROMPT(size, type, F, D, V ) ▷ Step 1: Identify different approaches to be used.A = {a1, . . ., an} ← det_approaches(D) ▷ where A is the set of approaches ▷ Step 2: Identify different personas to be used.P = {ϕ, p1, . . ., pm} ← det_personas(D) ▷ where P is the set of personas ▷ Step 3: Find the best combination.S = {s1, . . .ssize} ← combine(A, P, size, V ) ▷ where S is the set of combined approaches and personas, and si = (p, ai ∈ A) ▷ Step 4: Augment the few-shot examples.T = { Ti,j, . ..} ← augment(S, F ) ▷ where T is the set of augmented examples, and Ti,j is formed using si ∈ S and fj ∈ F ; |T | =size ▷ Step 5: Compose the final prompt.O ← compose(T, S, type) return O ▷ Return the final output.end procedure</p>
<p>Figure 3 :
3
Figure3: Diversity of Thought enhances the inference cost and accuracy trade-off.We compare DIV-SE and IDIV-SE with SC(Wang et al., 2023) and CoT(Wei et al., 2022) across three benchmarks.The x-axis indicates the total cost (as defined in § 3) of running inference with the LLM on the benchmark using the given method, while the y-axis represents the LLM's performance.The FS-CoT setting is represented by filled gray dots, while the ZS-CoT setting is indicated by unfilled dots.Notice that for BLOCKSWORLD 3, despite being in the ZS-CoT setting, our approaches are more performant than the SC-s (FS-CoT) baseline.</p>
<p>Figure 5 :
5
Figure 5: Prompt template for extracting diverse approaches for problem solving.</p>
<p>Figure 6 :
6
Figure 6: Average accuracy for different ensemble sizes on GSM8K for ZS-CoT and FS-CoT settings on GPT-4 and GPT-3.5.Note that all graphs are zoomed in.</p>
<p>Figure 7 :
7
Figure 7: Average accuracy for different ensemble sizes on AQUA-RAT for ZS-CoT and FS-CoT settings on GPT-4 and GPT-3.5.Note that all graphs are zoomed in.</p>
<p>is exactly 10 more than the original average of 40, so that's the correct answer.The other choices can be eliminated because they are not 10 more than the original average.Approach <using algebra>:Let's denote the sum of the 15 numbers as S. Since the average of the 15 numbers is 40, we can write the equation: S / 15 = 40 S = 40 * 15 = 600 Now, we add 10 to each number, so the new sum is S + 15 * 10 = 600 + 150 = 750.The new average is: New average = 750 / 15 = 50 The answer is: (A) 50</p>
<p>Figure 8 :
8
Figure 8: Illustration of Augmentation of few-shot examples -Algorithm 1, Step 4</p>
<p>Figure 9 :
9
Figure 9: Zero-shot prompt used in the baseline run of the Planning -Blocksworld Domain</p>
<p>Figure 12 :
12
Figure 12: The Zero-shot prompt used in the Alan Turing + Progressive Block Placement Approach for solving the Planning -Blocksworld Domain Problem.</p>
<p>Table 1 and 2. Detailed results are available in Appendix C.These also cover results on the impact of ensemble size in Appendix D.
accuracy while maintaining low costs.4.1.2 Counting and probabilistic reasoningvia MATHGPT-4 Results: From Table 2, we see that DIV-SEachieves an accuracy increase of 14.3 and 16.87 p.pin the FS-CoT (baseline of 66.46%) and ZS-CoT(baseline of 62.24%) settings, respectively. Onthe other hand, IDIV-SE achieves a boost of 5.54and 9.76 p.p in the FS-CoT and ZS-CoT settings,respectively, over the baseline.GPT-3.5 Results: From Table 2, we see that DIV-SE yields a gain of 21.84 and 13.04 p.p in the FS-CoT (baseline of 30.38%) and ZS-CoT (baselineof 31.90%) settings, respectively. Likewise IDIV-SE achieves a boost of 13.72 and 10.60 p.p in theFS-CoT and ZS-CoT settings, respectively.4.1.3 Planning via BLOCKSWORLDSettingMethod AQuA MATH CQACoT59.0031.9071.40SC-361.4032.0772.00GPT-3.5 ZSSC-563.3738.1972.80IDIV-SE62.6042.5074.00DIV-SE72.8344.9474.50CoT57.4830.3879.4GPT-3.5 FSIDIV-SE64.5744.1080.00DIV-SE72.8452.2280.40CoT70.4762.2481.60GPT-4 ZSIDIV-SE71.6572.0082.50DIV-SE80.3179.1181.70CoT71.9066.4687.70GPT-4 FSIDIV-SE79.9072.0089.00DIV-SE84.2580.7688.00Table 2: Performance on AQUA-RAT, MATH (Count-ing and Probability), and COMMONSENSEQA for GPT-3.5 Turbo and GPT-4 in the ZS-CoT and few-shot-CoTsettings respectively.4.1.1 Arithmetic reasoning via AQUA-RATGPT-4 Results: In Table 2, we observe that DIV-SEachieves an accuracy increase of 9.84 and 14.6 p.pin the FS-CoT (baseline accuracy of 71.9%) andZS-CoT (baseline of 70.47%) settings, respectively.While the gains from IDIV-SE are nominal in ZS-CoT, it achieves a boost of 7.7 p.p for FS-CoT.GPT-3.5 Results: In Table 2, we see that DIV-SEyields a gain of 14.23 and 16.52 p.p in the FS-CoT (baseline of 57.48%) and ZS-CoT (baselineof 59%) settings, respectively. Within the FS-CoTsetting, IDIV-SE gets an absolute increase of 7 p.p.Note that Fig. 1 also displays the total inferencecost. Both IDIV-SE and DIV-SE are Pareto opti-mal, indicating their capacity to achieve a higher
Setup:The benchmark provides both natural language and Planning Definition and Domain Language prompts(McDermott et al.</p>
<p>Table 3 :
3
We hypothesize that this is partly due to model's lack of capabilities to both follow instructions and the mentioned approach in the absence of examples.Results on AQUA-RAT and LLaMA-2 70B.
Prompting Strategy ZS-CoT (%) FS-CoT (%)CoT31.3229.1IDIV-SE27.0039.7DIV-SE32.0039.9
Table 3 demonstrates the results for LLaMA-2 70B with 8-bit quantization.DIV-SE and IDIV-SE demonstrate an improvement of over 10 p.p over the baseline in the FS-CoT settings.However, the gain in the ZS-CoT setting has been negligible.</p>
<p>Table 4 :
4
Prompts, derived from approaches and personas, boost performance.Blue rows denote ZS-CoT prompts, while black lines denote FS-CoT prompts.∅ denotes absence (of persona or approach respectively).
MethodGPT-4 (%) GPT-3.5 (%)Majority Voting79.9064.47Meta Reasoning79.2467.70</p>
<p>Table 5 :
5
Alternative aggregation strategies.
Observe</p>
<p>table.My goal is to have that the red block on top of the blue block and the orange block on top of the red block.Here are the actions I can do: Pick up a block from the table Unstack a block from on top of another block Put down a block on the table Stack a block on top of another block I have the following restrictions on my actions: I can only pick up or unstack one block at a time.I can only pick up or unstack a block if my hand is empty.I can only pick up a block if the block is on the table and the block is clear.A block is clear if the block has no other blocks on top of it and if the block is not picked up.
I can only unstack a block from on top of another block if the block I am unstacking wasreally on top of the other block.I can only unstack a block from on top of another block if the block I am unstacking isclear.Once I pick up or unstack a block, I am holding the block.I can only put down a block that I am holding.I can only stack a block on top and not under of another block if I am holding the blockbeing stacked.I can only stack a block on top and not under of another block if the block onto which Iam stacking the block is clear.Once I put down or stack a block, my hand becomes empty.Once you stack a block on top of a second block, the second block is no longer clear.</p>
<p>You are playing with a set of blocks where you need to arrange the blocks into stacks.What is the plan to achieve the goal?<Initial State> : As initial conditions you have that, the orange block is clear, the hand is empty, the blue block is on top of the red block, the orange block is on top of the blue block and the red block is on the table.<GoalState>:Your goal is to have that the red block on top of the blue block and the orange block on top of the red block.You can only pick up or unstack one block at a time.2.You can only pick up or unstack a block if your hand is empty.3.You can only pick up a block if the block is on the table and the block is clear.A block is clear if the block has no other blocks on top of it and if the block is not picked up.4.You can only unstack a block from on top of another block if the block you are unstacking was really on top of the other block.5.You can only unstack a block from on top of another block if the block you are unstacking is clear.6.Once you pick up or unstack a block, you are holding the block.7.You can only put down a block that you are holding.8.You can only stack a block on top and not under of another block if you are holding the block being stacked.9.You can only stack a block on top and not under of another block if the block onto which you are stacking the block is clear.10.Once you put down or stack a block, your hand becomes empty.11.Once you stack a block on top of a second block, the second block is no longer clear.Using a finite state machine and a search algorithm what is the plan to achieve the goal?You can model each state of the blocks configuration on the table and the hand as a state.For each action step check that the step follows the rules and that the step brings you closer to the goal.After each action describe the state of the table and hand.Always check whether the final state satisfies the goal mentioned.<GoalState>:Your goal is to have that the red block on top of the blue block and the orange block on top of the red block.You are playing with a set of blocks where you need to arrange the blocks into stacks.<InitialState>:As initial conditions you have that, the orange block is clear, the hand is empty, the blue block is on top of the red block, the orange block is on top of the blue block and the red block is on the table.<GoalState>:Your goal is to have that the red block on top of the blue block and the orange block on top of the red block.You can only pick up or unstack one block at a time.2.You can only pick up or unstack a block if your hand is empty.3.You can only pick up a block if the block is on the table and the block is clear.A block is clear if the block has no other blocks on top of it and if the block is not picked up.4.You can only unstack a block from on top of another block if the block you are unstacking was really on top of the other block.5.You can only unstack a block from on top of another block if the block you are unstacking is clear.6.Once you pick up or unstack a block, you are holding the block.7.You can only put down a block that you are holding.8.You can only stack a block on top and not under of another block if you are holding the block being stacked.9.You can only stack a block on top and not under of another block if the block onto which you are stacking the block is clear.10.Once you put down or stack a block, your hand becomes empty.11.Once you stack a block on top of a second block, the second block is no longer clear.Thinking like Alan Turing starting from the <Initial State> build a plan to get to the <Goal State>.For each action step carefully check that the step follows the rules.<GoalState>: Your goal is to have that the red block on top of the blue block and the orange block on top of the red block.You are playing with a set of blocks where you need to arrange the blocks into stacks.<InitialState> : As initial conditions you have that, the orange block is clear, the hand is empty, the blue block is on top of the red block, the orange block is on top of the blue block and the red block is on the table.<GoalState> : Your goal is to have that the red block on top of the blue block and the orange block on top of the red block.You can only pick up or unstack one block at a time.2.You can only pick up or unstack a block if your hand is empty.3.You can only pick up a block if the block is on the table and the block is clear.A block is clear if the block has no other blocks on top of it and if the block is not picked up.4.You can only unstack a block from on top of another block if the block you are unstacking was really on top of the other block.5.You can only unstack a block from on top of another block if the block you are unstacking is clear.6.Once you pick up or unstack a block, you are holding the block.7.You can only put down a block that you are holding.8.You can only stack a block on top and not under of another block if you are holding the block being stacked.9.You can only stack a block on top and not under of another block if the block onto which you are stacking the block is clear.10.Once you put down or stack a block, your hand becomes empty.11.Once you stack a block on top of a second block, the second block is no longer clear.Thinking like Alan Turing, starting from the <Initial State> build a plan to get to the <Goal State> .For each action step carefully check that the step follows the rules.Divide the task into smaller steps, starting with placing the bottom block first, followed by the middle blocks, and finally the top block.<Goal State> : Your goal is to have that the red block on top of the blue block and the orange block on top of the red block.
Here are the actions you can do: -Pick up a block from the table -Unstack a block from on top of another block -Put down a block on the table -Stack a block on top of another block Rules: <assess the action> : &lt; are we building the stack bottom up, check carefully&gt; 1. [PLAN] Here are the actions you can do: Here are the actions you can do: -Pick up a block from the table -Pick up a block from the table -Unstack a block from on top of another block -Unstack a block from on top of another block -Put down a block on the table -Stack a block on top of another block -Put down a block on the table -Stack a block on top of another block Rules: <action> : &lt; action to be performed in this step &gt; <state> : <state> 1. output format for each step until you reach the goal state: Rules: 1.Figure 10: The Zero-shot prompt using Finite State Machine Approach for solving the Planning -Blocksworld Figure 11: The Zero-shot prompt used with the persona of Alan Turing and Action Rationale approach for solving Domain Problem. the Planning -Blocksworld Domain Problem.
Correspondence to ranjitan@microsoft.com and besmira.nushi@microsoft.com.
In practice, we set c = 100, b = 5, n ∈ {3, 5}, and |V | &lt;
.
For a given reasoning task, we perform this process once (for GPT-3.5 Turbo), and re-use our selection across all LLMs we evaluate.
https://openai.com/pricing
AppendixA Prompt used for DIVERSEPROMPTING Our diverse prompting strategy for IDIV-SE and DIV-SE is showcased in Fig.2and Fig.4respectively.The instrumental prompt template that determines our approaches is presented in Fig.5.Think like Dr. Patel, the mathematician who specializes in algebra and solve the problem.If there is no exact match choose the closest option.To determine the number of keystrokes needed to type the numbers from 1 to 500, let's break down the problem by analyzing the number of digits in each range: For numbers 1-9, there are 9 numbers with 1 digit each, requiring 9 keystrokes.For numbers 10-99, there are 90 numbers with 2 digits each, requiring 90 * 2 = 180 keystrokes.For numbers 100-499, there are 400 numbers with 3 digits each, requiring 400 * 3 = 1200 keystrokes.For the number 500, it has 3 digits, requiring 3 keystrokes.Now, we can sum up the keystrokes for each range: 9 (for 1-9) + 180 (for 10-99) + 1200 (for 100-499) + 3 (for 500) = 1392 keystrokes.The answer is: (b) 1392 As a math professor, use 3 distinct approaches and without using built-in algorithms, write python programs to color the following graph, described as a set of edges, such that no two vertices on the same edge share a color.You may use at most 3 colors.Vertex 0 is connected to vertex 7. Vertex 0 is connected to vertex 8. Vertex 0 is connected to vertex 9. Vertex 0 is connected to vertex 11.Vertex 1 is connected to vertex 13.Vertex 2 is connected to vertex 9. Vertex 3 is connected to vertex 8. Vertex 3 is connected to vertex 11.Vertex 3 is connected to vertex 12. Vertex 4 is connected to vertex 12. Vertex 5 is connected to vertex 11.Vertex 6 is connected to vertex 9. Vertex 7 is connected to vertex 10.Vertex 7 is connected to vertex 13.Vertex 9 is connected to vertex 11.Vertex 10 is connected to vertex 13.Vertex 11 is connected to vertex 13.There are a total of 14 vertices.Please label every vertex, even if it is disconnected from the rest of the graph.Please provide each vertex's color.Do not skip any vertices.Each color must be provided on a new line in the response and should be formatted as "VERTEX NUMBER: VERTEX COLOR ASSIGNMENT (Color n)".Output format: Approach 1 <name of the approach> : &lt; python program from scratch to color the given graph accurately &gt; Approach 2 <name of the approach> : &lt; python program from scratch to color the given graph accurately&gt; Approach 3 <name of the approach> : &lt; python program from scratch to color the given graph accurately&gt;
Rohan Anil, Andrew M Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin, Alexandre Passos, Siamak Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng Chen, arXiv:2305.10403Palm 2 technical report. 2023arXiv preprint</p>
<p>Alec Radford, Ilya Sutskever, and Dario Amodei. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Advances in Neural Information Processing Systems. Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlishCurran Associates Inc202033Language models are few-shot learners</p>
<p>Sébastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg, arXiv:2303.12712Sparks of artificial general intelligence: Early experiments with gpt-4. 2023arXiv preprint</p>
<p>Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks. Wenhu Chen, Xueguang Ma, Xinyi Wang, William W Cohen, 2022</p>
<p>Batch prompting: Efficient inference with large language model apis. Zhoujun Cheng, Jungo Kasai, Tao Yu, 2023</p>
<p>H W Chung, L Hou, S Longpre, B Zoph, Y Tay, W Fedus, E Li, X Wang, M Dehghani, S Brahma, arXiv:2210.11416Scaling instruction-finetuned language models. 2022arXiv preprint</p>
<p>. Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, John Schulman, 2021Training verifiers to solve math word problems</p>
<p>Tim Dettmers, Mike Lewis, Younes Belkada, Luke Zettlemoyer, arXiv:2208.073398-bit matrix multiplication for transformers at scale. 2022aarXiv preprintint8 (</p>
<p>8-bit optimizers via block-wise quantization. Tim Dettmers, Mike Lewis, Sam Shleifer, Luke Zettlemoyer, 9th International Conference on Learning Representations. ICLR2022b</p>
<p>A guidance language for controlling large language models. 2024</p>
<p>Measuring mathematical problem solving with the math dataset. Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song, Jacob Steinhardt, 2021</p>
<p>Erik Jones, Anca Dragan, arXiv:2303.04381Aditi Raghunathan, and Jacob Steinhardt. 2023. Automatically auditing large language models via discrete optimization. arXiv preprint</p>
<p>Large language models are zero-shot reasoners. T Kojima, S S Gu, M Reid, Y Matsuo, Y Iwasawa, Advances in Neural Information Processing Systems. 2022</p>
<p>The power of scale for parameter-efficient prompt tuning. Brian Lester, Rami Al-Rfou, Noah Constant, arXiv:2104.086912021arXiv preprint</p>
<p>Making language models better reasoners with step-aware verifier. Yifei Li, Zeqi Lin, Shizhuo Zhang, Qiang Fu, Bei Chen, Jian-Guang Lou, Weizhu Chen, Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics. Long Papers. the 61st Annual Meeting of the Association for Computational Linguistics20231</p>
<p>Percy Liang, Rishi Bommasani, Tony Lee, Dimitris Tsipras, Dilara Soylu, Michihiro Yasunaga, Yian Zhang, Deepak Narayanan, Yuhuai Wu, arXiv:2211.09110Holistic evaluation of language models. Ananya Kumar, et al. 2022arXiv preprint</p>
<p>Program induction by rationale generation: Learning to solve and explain algebraic word problems. Wang Ling, Dani Yogatama, Chris Dyer, Phil Blunsom, 10.18653/v1/P17-1015Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics. Long Papers. the 55th Annual Meeting of the Association for Computational LinguisticsVancouver, CanadaAssociation for Computational Linguistics20171</p>
<p>Pddl-the planning domain definition language. Drew Mcdermott, Malik Ghallab, Adele E Howe, Craig A Knoblock, Ashwin Ram, Manuela M Veloso, Daniel S Weld, David E Wilkins, 1998</p>
<p>Can generalist foundation models outcompete special-purpose tuning? case study in medicine. Harsha Nori, Yin Tat Lee, Sheng Zhang, Dean Carignan, Richard Edgar, Nicolo Fusi, Nicholas King, Jonathan Larson, Yuanzhi Li, Weishung Liu, arXiv:2311.164522023arXiv preprint</p>
<p>Michael Nye, Anders J Andreassen, Guy Gur-Ari, Henryk Michalewski, Jacob Austin, David Bieber, David Dohan, Aitor Lewkowycz, Marten Bosma, Daan Luan, arXiv:2112.00114Show your work: Scratchpads for intermediate computation with language models. 2021arXiv preprint</p>
<p>Introducing chatgpt. OpenAI. 2023a. Gpt-4 technical report. OpenAI. 2023b. Gpt-4 technical report. 2022OpenAI</p>
<p>Automatic prompt optimization with" gradient descent" and beam search. Reid Pryzant, Dan Iter, Jerry Li, Yin Tat Lee, Chenguang Zhu, Michael Zeng, arXiv:2305.034952023arXiv preprint</p>
<p>Leonard Salewski, Stephan Alaniz, Isabel Rio-Torto, Eric Schulz, Zeynep Akata, arXiv:2305.14930-context impersonation reveals large language models' strengths and biases. 2023arXiv preprint</p>
<p>Gpt-4 doesn't know it's wrong: An analysis of iterative prompting for reasoning problems. Kaya Stechly, Matthew Marquez, Subbarao Kambhampati, arXiv:2310.123972023arXiv preprint</p>
<p>CommonsenseQA: A question answering challenge targeting commonsense knowledge. Alon Talmor, Jonathan Herzig, Nicholas Lourie, Jonathan Berant, 10.18653/v1/N19-1421Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. Long and Short Papers. the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesMinneapolis, MinnesotaAssociation for Computational Linguistics20191</p>
<p>Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, arXiv:2307.09288Llama 2: Open foundation and fine-tuned chat models. 2023arXiv preprint</p>
<p>On the planning abilities of large language models -a critical investigation. Karthik Valmeekam, Matthew Marquez, 2023Sarath Sreedharan, and Subbarao Kambhampati</p>
<p>Large language models still can't plan (a benchmark for llms on planning and reasoning about change). Karthik Valmeekam, Alberto Olmo, Sarath Sreedharan, Subbarao Kambhampati, arXiv:2206.104982022arXiv preprint</p>
<p>Self-consistency improves chain of thought reasoning in language models. Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdhery, Denny Zhou, 2023</p>
<p>Chain of thought prompting elicits reasoning in large language models. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed Chi, Quoc Le, Denny Zhou, Conference on Neural Information Processing Systems (NeurIPS). 2022</p>
<p>Jules White, Quchen Fu, Sam Hays, Michael Sandborn, Carlos Olea, Henry Gilbert, Ashraf Elnashar, Jesse Spencer-Smith, Douglas C Schmidt, arXiv:2302.11382A prompt pattern catalog to enhance prompt engineering with chatgpt. 2023arXiv preprint</p>
<p>Huggingface's transformers: State-ofthe-art natural language processing. Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz, arXiv:1910.037712019arXiv preprint</p>
<p>Answering questions by meta-reasoning over multiple chains of thought. Tomer Ori Yoran, Ben Wolfson, Uri Bogin, Daniel Katz, Jonathan Deutch, Berant, arXiv:2304.130072023arXiv preprint</p>
<p>Denny Zhou, Nathanael Schärli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schuurmans, Claire Cui, Olivier Bousquet, arXiv:2205.10625Least-to-most prompting enables complex reasoning in large language models. Quoc Le, Ed Chi, 2022arXiv preprint</p>
<p>Selfdiscover: Large language models self-compose reasoning structures. Pei Zhou, Jay Pujara, Xiang Ren, Xinyun Chen, Heng-Tze Cheng, Quoc V Le, Ed H Chi, Denny Zhou, Swaroop Mishra, Huaixiu Steven, Zheng , arXiv:2402.036202024arXiv preprint</p>            </div>
        </div>

    </div>
</body>
</html>