<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-984 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-984</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-984</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-20.html">extraction-schema-20</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <p><strong>Paper ID:</strong> paper-e2f2160ad089f3e2632d1e2c322cf1fd530820b4</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/e2f2160ad089f3e2632d1e2c322cf1fd530820b4" target="_blank">ABCD-Strategy: Budgeted Experimental Design for Targeted Causal Structure Discovery</a></p>
                <p><strong>Paper Venue:</strong> International Conference on Artificial Intelligence and Statistics</p>
                <p><strong>Paper TL;DR:</strong> This work proposes a general framework and theory based on optimal Bayesian experimental design to select experiments for targeted causal discovery and provides a tractable implementation with provable guarantees on both approximation and optimization quality based on submodularity.</p>
                <p><strong>Paper Abstract:</strong> Determining the causal structure of a set of variables is critical for both scientific inquiry and decision-making. However, this is often challenging in practice due to limited interventional data. Given that randomized experiments are usually expensive to perform, we propose a general framework and theory based on optimal Bayesian experimental design to select experiments for targeted causal discovery. That is, we assume the experimenter is interested in learning some function of the unknown graph (e.g., all descendants of a target node) subject to design constraints such as limits on the number of samples and rounds of experimentation. While it is in general computationally intractable to select an optimal experimental design strategy, we provide a tractable implementation with provable guarantees on both approximation and optimization quality based on submodularity. We evaluate the efficacy of our proposed method on both synthetic and real datasets, thereby demonstrating that our method realizes considerable performance gains over baseline strategies such as random sampling.</p>
                <p><strong>Cost:</strong> 0.016</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e984.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e984.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ABCD-Strategy</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Active Budgeted Causal Design Strategy (ABCD-Strategy)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A Bayesian experimental design algorithm that selects batched interventions under sample and batch constraints to optimally learn a target function of a causal DAG (e.g., downstream nodes), using mutual-information utility approximated by DAG bootstrap, MLE parameter estimates and greedy submodular optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>ABCD-Strategy (Active Budgeted Causal Design Strategy)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Selects multiset interventions per batch to maximize expected mutual information about a target functional f(G). Approximations used: (1) approximate posterior over DAGs via DAG bootstrap or MCMC to produce a candidate set \hat{G}_T, (2) replace parameter integrals by plug-in MLE estimates (empirical Bayes/Bernstein–von Mises justification), (3) approximate posterior-after-data with importance weights given by the likelihood of hypothetical new data under each sampled DAG and its MLE parameters, (4) greedy sequential selection exploiting DR-submodularity to obtain (1-1/e) guarantees. Algorithm runs in rounds (batches) and can allocate multiple samples to repeated interventions.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Simulated DAG benchmarks and DREAM4 in-silico gene-expression datasets (batched interventional virtual experiments)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Interactive batched experimental setting: the algorithm chooses batches of interventions (possibly repeated) and receives interventional/observational samples; environments used in paper include simulated chain graphs, Erdös–Rényi DAGs (simulation), and DREAM4 synthetic gene-expression data (in-silico perturbation/knockdown experiments). The environment is batched and allows active experimentation (choosing interventions and allocating samples).</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Indirect refutation and reweighting via interventions and likelihood-based importance weights: ABCD uses interventions to collect data that distinguishes DAGs (thereby refuting spurious edges), and reweights sampled candidate DAGs by the likelihood of newly observed interventional data (empirical-Bayes / importance-weighting with plug-in MLEs). DAG-bootstrap frequency information is also used to identify unstable (potentially spurious) edges.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Spurious edge orientations arising from finite samples and Markov equivalence ambiguity; measurement noise implicitly addressed via likelihood models; irrelevant/weak edges manifest as low posterior weight under reweighting.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Detection is implicit: candidate DAGs/edges that are inconsistent with newly observed interventional data receive low importance weights (P(y | G, theta_hat)), and posterior entropy over f(G) is monitored—large posterior uncertainty signals remaining ambiguities possibly due to spurious correlations.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Importance-weighting of sampled DAGs by the likelihood of newly observed interventional data under each DAG's MLE parameters (hat{w}_i = P(y | G_i, xi, theta_hat^{G_i})); empirical-Bayes posterior approximation then downweights DAGs that poorly predict interventional observations.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Active interventions chosen to maximally reduce posterior entropy (mutual information criterion); when interventional data contradicts a candidate DAG, its posterior/weight falls, effectively refuting spurious causal relations. Repeated interventions and allocation of additional samples to informative interventions are allowed to confirm/refute hypotheses.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td>Mutual-information-based acquisition: choose interventions maximizing expected decrease in entropy of f(G) (mutual information), approximated via sampled DAGs and simulated hypothetical outcomes; greedy sequential selection across multiset interventions using DR-submodularity guarantees.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>Reported as significant reduction in posterior entropy vs random or chordal-random baselines in simulated chain graphs and Erdös–Rényi DAGs; on DREAM4 in-silico gene-expression data, modest improvements over random for predicting descendants of central genes. Exact numeric metrics for 'distractor-robust' variants are not provided.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>ABCD significantly reduces posterior entropy over graph/function compared to random baselines in batched settings; by allowing repeated allocation to informative interventions and using likelihood reweighting of sampled DAGs, the method can actively refute incorrect graph hypotheses that arise from spurious finite-sample correlations. The paper also shows mutual-information utility is consistent in budgeted batched single-node intervention settings while some previously proposed utilities (e.g., Ness et al. 2018) are not.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'ABCD-Strategy: Budgeted Experimental Design for Targeted Causal Structure Discovery', 'publication_date_yy_mm': '2019-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e984.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e984.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Mutual-Information Utility</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Mutual-Information-based Utility for Experimental Design</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Utility function that selects experiments/interventions to maximize expected mutual information between the target graph functional f(G) and prospective observations, equivalent to maximizing expected decrease in posterior entropy of f(G).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Active learning for structure in Bayesian networks</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Mutual-information acquisition for causal discovery</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Define utility U_ML^f(y, xi; D) = H(f | D) - H(f | D, y, xi); select interventions xi maximizing expected utility under current posterior. In this paper, mutual information is approximated by sampling DAGs from the posterior and computing entropies under approximate posteriors; in the infinite-sample limit this reduces to selecting interventions that minimize expected log-size of the interventional MEC.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Batched interventional environments (simulated DAGs, in-silico perturbation data)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Used in batched experimental design settings where multiple intervention samples can be collected per batch; supports adaptive selection across batches.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Ambiguity from finite samples and Markov equivalence; implicitly addresses spurious graph hypotheses by choosing experiments that maximally reduce uncertainty.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Not explicit; mutual information drives selection toward experiments that most reduce posterior entropy, which tends to reveal hypotheses that are inconsistent with spurious correlations when such experiments are performed.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>When used with posterior reweighting (as in ABCD), DAGs inconsistent with interventional data are downweighted via their likelihood under new observations.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>By selecting interventions that maximally reduce entropy, the method produces data that can rule out (refute) DAGs that produced spurious correlations under observational data alone.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td>Expected mutual information maximization (possibly batched and multiset-valued), with approximation via posterior samples and simulated outcomes, and greedy selection exploiting submodularity.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Mutual-information utility generalizes earlier single-sample active-learning formulations to batched settings and finite-sample regimes, can select repeat interventions (useful for allocating more samples to particularly informative interventions), and in the infinite-sample limit selects interventions that minimize expected log-size of interventional MECs; it is shown to be budgeted-batch consistent for single-node interventions.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'ABCD-Strategy: Budgeted Experimental Design for Targeted Causal Structure Discovery', 'publication_date_yy_mm': '2019-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e984.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e984.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Importance-weighted empirical-Bayes reweighting</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Likelihood-based importance-weighted empirical-Bayes posterior approximation (plug-in MLE reweighting)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An approximation used to compute posterior-after-hypothetical-data by reweighting sampled DAGs with the likelihood of the hypothetical/new observations under each DAG evaluated at its MLE parameters, yielding tractable importance weights.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Importance-weighted empirical-Bayes reweighting (hat{w}_i)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Given sampled candidate DAGs G_i with parameter MLEs theta_hat^{G_i}, compute hat{w}_i = P(y | G_i, xi, theta_hat^{G_i}) and form an empirical-Bayes approximate posterior proportional to prior(G_i)*P(D | G_i, theta_hat^{G_i}). Use these weights both to approximate H(f | D) and H(f | D, y, xi) when evaluating mutual-information utility. This avoids integrating over theta and enables greedy acquisition.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Batched interventional simulations and in-silico perturbation data</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Used within ABCD to score candidate interventions by simulating hypothetical outcomes and reweighting candidate graphs; applicable to environments that provide likelihood models for interventional outcomes.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Downweights candidate DAGs (and thus spurious edges) that poorly predict observed interventional data through likelihood-based importance weights; effectively prioritizes models consistent with experimental outcomes.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Finite-sample spurious edge orientations and candidate graphs that overfit observational noise; indirectly handles confounding only to extent interventions break incoming edges.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Graphs that fail to predict new interventional data receive low hat{w}_i, revealing spurious hypotheses; divergence between predicted and observed outcomes indicates spuriousness.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Direct multiplicative downweighting of sampled DAGs by their P(y | G, xi, theta_hat) value (importance weight).</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>If hat{w}_i approaches zero over batches, the corresponding DAG (and its edges) are effectively refuted as explanations for the data.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td>Used to evaluate the expected posterior change for hypothetical outcomes in mutual-information acquisition; candidate interventions are chosen to produce outcomes that will most aggressively alter importance weights.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>The importance-weighted empirical-Bayes approximation makes mutual-information-based batched experimental design tractable and provides a principled way to downweight candidate graphs that are inconsistent with interventional outcomes, thereby enabling the method to refute spurious causal relations that arise from observational ambiguity or finite-sample noise.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'ABCD-Strategy: Budgeted Experimental Design for Targeted Causal Structure Discovery', 'publication_date_yy_mm': '2019-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e984.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e984.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DAG-bootstrap</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>DAG bootstrap (bootstrap-based candidate set of DAGs)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A nonparametric procedure to produce a high-probability candidate set of DAGs by resampling the data and applying a DAG-learner to each bootstrap sample, used here to approximate the posterior over graphs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Data analysis with Bayesian networks: A bootstrap approach</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>DAGBootstrap candidate-set sampling</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Repeatedly resample data (with replacement) to create bootstrap datasets, run a DAG learning algorithm (capable of handling interventional and observational data) on each bootstrap dataset to produce T candidate DAGs \hat{G}_T, and weight them by unnormalized posterior scores to approximate P(G | D). This set is used in downstream importance-weighted mutual-information computations.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Simulated DAG data and in-silico gene-expression perturbation datasets</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Used as posterior approximation in batched experimental design; not itself an interactive policy but used to construct the belief state the active learner operates on.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Resampling variability highlights unstable (potentially spurious) edges: edges that frequently disappear across bootstrap samples indicate weak/support-lacking or spurious relationships; bootstrap frequencies can be used as evidence (low frequency => suspect).</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Edges that arise from sampling noise / spurious correlations due to finite data.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Empirical frequency of edge appearance across bootstrap DAGs; low-frequency edges are flagged as unstable/spurious.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Candidate DAGs with low bootstrap support receive lower unnormalized posterior weight w_{G,D} when forming the approximate posterior; combined with importance reweighting further downweights inconsistent DAGs.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Bootstrap evidence combined with interventional likelihoods leads to progressive refutation of edges that do not persist across resamples and interventions.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>DAG bootstrap provides a computationally efficient approximate posterior (candidate set) used by ABCD; bootstrap-derived candidate variability serves as a heuristic signal for unstable/spurious edges that can be targeted by interventions and subsequently downweighted via likelihood reweighting.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'ABCD-Strategy: Budgeted Experimental Design for Targeted Causal Structure Discovery', 'publication_date_yy_mm': '2019-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e984.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e984.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Ness2018 utility (criticized)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Bayesian active learning experimental design for inferring signaling networks (Ness et al., 2018) utility</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A previously proposed batched experimental design utility that scores interventions by the expected number of additional edges that could be oriented relative to the observational MEC; shown in this paper to be computationally expensive and, in some batched/budgeted settings, inconsistent.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>A Bayesian active learning experimental design for inferring signaling networks</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Edge-orientation expected-gain utility (Ness et al., 2018)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Selects interventions to maximize the expected number of edges that become oriented in the interventional Markov equivalence class (relative to observational MEC), assuming possibly infinite samples per intervention; computationally costly (factorial dependence on batch size) and in the paper shown to be non-consistent in certain budgeted settings because it may repeatedly select the same intervention.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Bathed interventional experimental design (signaling network inference)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Designed for batched interventions where the score is evaluated w.r.t. orientations achievable via Meek rules under interventional MECs; the method presumes the MEC is known initially and infinite samples per chosen intervention are feasible.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td>Choose interventions that are expected to orient the largest number of edges (graph-based, Meek-rule propagation), selecting up to K unique interventions per batch.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>The paper demonstrates a counterexample where this utility repeatedly selects the same intervention and fails to be budgeted-batch consistent; ABCD's mutual-information approach fixes this by accounting for posterior updates and allowing sample reallocation rather than only counting orientations relative to the observational MEC.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'ABCD-Strategy: Budgeted Experimental Design for Targeted Causal Structure Discovery', 'publication_date_yy_mm': '2019-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e984.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e984.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Interventional-MEC algorithms / Meek rules</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Interventional Markov Equivalence Class estimation and Meek rules (Hauser & Bühlmann)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Graph-theoretic methods for representing and reasoning about equivalence classes under interventions; Meek rules propagate edge orientations given detected oriented edges to further orient the essential graph.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Characterization and greedy learning of interventional Markov equivalence classes of directed acyclic graphs</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Interventional-MEC estimation and Meek-rule orientation</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Given a family of interventions, compute the interventional essential graph (Ess^I(G)) that represents the reduced equivalence class; Meek orientation rules are used to infer additional directed edges deterministically when certain local patterns exist. These algorithms are used as a target in graph-based design strategies (select interventions that maximize oriented edges).</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Interventional causal discovery on simulated DAGs and real-world interventional datasets</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Offline or active intervention settings where interventions remove incoming edges to targets; Meek rules propagate orientations noniteratively and are used by several design methods to score candidate interventions.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Ambiguity from Markov equivalence and indistinguishable edge orientations under limited interventions; does not directly model measurement noise.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Orientation propagation and checking of consistency across interventional skeleta; ambiguous edges remain undirected until broken by interventions.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Interventions that change the interventional skeleton eliminate candidate DAGs in the equivalence class, thereby refuting spurious orientations consistent with observational data.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td>Graph-based scoring: choose interventions that are expected to orient the most edges (e.g., maximize Meek-rule-induced orientations).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Meek-rule and interventional-MEC computations are the basis of many graph-based experimental-design heuristics; ABCD's mutual-information objective reduces to selecting interventions that produce fine interventional-MECs in the infinite-sample limit, connecting information-theoretic and graph-theoretic design criteria.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'ABCD-Strategy: Budgeted Experimental Design for Targeted Causal Structure Discovery', 'publication_date_yy_mm': '2019-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Budgeted experiment design for causal structure learning <em>(Rating: 2)</em></li>
                <li>A Bayesian active learning experimental design for inferring signaling networks <em>(Rating: 2)</em></li>
                <li>Two optimal strategies for active learning of causal models from interventional data <em>(Rating: 2)</em></li>
                <li>Characterization and greedy learning of interventional Markov equivalence classes of directed acyclic graphs <em>(Rating: 2)</em></li>
                <li>Active learning for structure in Bayesian networks <em>(Rating: 1)</em></li>
                <li>Data analysis with Bayesian networks: A bootstrap approach <em>(Rating: 1)</em></li>
                <li>Permutation-based causal inference algorithms with interventions <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-984",
    "paper_id": "paper-e2f2160ad089f3e2632d1e2c322cf1fd530820b4",
    "extraction_schema_id": "extraction-schema-20",
    "extracted_data": [
        {
            "name_short": "ABCD-Strategy",
            "name_full": "Active Budgeted Causal Design Strategy (ABCD-Strategy)",
            "brief_description": "A Bayesian experimental design algorithm that selects batched interventions under sample and batch constraints to optimally learn a target function of a causal DAG (e.g., downstream nodes), using mutual-information utility approximated by DAG bootstrap, MLE parameter estimates and greedy submodular optimization.",
            "citation_title": "here",
            "mention_or_use": "use",
            "method_name": "ABCD-Strategy (Active Budgeted Causal Design Strategy)",
            "method_description": "Selects multiset interventions per batch to maximize expected mutual information about a target functional f(G). Approximations used: (1) approximate posterior over DAGs via DAG bootstrap or MCMC to produce a candidate set \\hat{G}_T, (2) replace parameter integrals by plug-in MLE estimates (empirical Bayes/Bernstein–von Mises justification), (3) approximate posterior-after-data with importance weights given by the likelihood of hypothetical new data under each sampled DAG and its MLE parameters, (4) greedy sequential selection exploiting DR-submodularity to obtain (1-1/e) guarantees. Algorithm runs in rounds (batches) and can allocate multiple samples to repeated interventions.",
            "environment_name": "Simulated DAG benchmarks and DREAM4 in-silico gene-expression datasets (batched interventional virtual experiments)",
            "environment_description": "Interactive batched experimental setting: the algorithm chooses batches of interventions (possibly repeated) and receives interventional/observational samples; environments used in paper include simulated chain graphs, Erdös–Rényi DAGs (simulation), and DREAM4 synthetic gene-expression data (in-silico perturbation/knockdown experiments). The environment is batched and allows active experimentation (choosing interventions and allocating samples).",
            "handles_distractors": true,
            "distractor_handling_technique": "Indirect refutation and reweighting via interventions and likelihood-based importance weights: ABCD uses interventions to collect data that distinguishes DAGs (thereby refuting spurious edges), and reweights sampled candidate DAGs by the likelihood of newly observed interventional data (empirical-Bayes / importance-weighting with plug-in MLEs). DAG-bootstrap frequency information is also used to identify unstable (potentially spurious) edges.",
            "spurious_signal_types": "Spurious edge orientations arising from finite samples and Markov equivalence ambiguity; measurement noise implicitly addressed via likelihood models; irrelevant/weak edges manifest as low posterior weight under reweighting.",
            "detection_method": "Detection is implicit: candidate DAGs/edges that are inconsistent with newly observed interventional data receive low importance weights (P(y | G, theta_hat)), and posterior entropy over f(G) is monitored—large posterior uncertainty signals remaining ambiguities possibly due to spurious correlations.",
            "downweighting_method": "Importance-weighting of sampled DAGs by the likelihood of newly observed interventional data under each DAG's MLE parameters (hat{w}_i = P(y | G_i, xi, theta_hat^{G_i})); empirical-Bayes posterior approximation then downweights DAGs that poorly predict interventional observations.",
            "refutation_method": "Active interventions chosen to maximally reduce posterior entropy (mutual information criterion); when interventional data contradicts a candidate DAG, its posterior/weight falls, effectively refuting spurious causal relations. Repeated interventions and allocation of additional samples to informative interventions are allowed to confirm/refute hypotheses.",
            "uses_active_learning": true,
            "inquiry_strategy": "Mutual-information-based acquisition: choose interventions maximizing expected decrease in entropy of f(G) (mutual information), approximated via sampled DAGs and simulated hypothetical outcomes; greedy sequential selection across multiset interventions using DR-submodularity guarantees.",
            "performance_with_robustness": "Reported as significant reduction in posterior entropy vs random or chordal-random baselines in simulated chain graphs and Erdös–Rényi DAGs; on DREAM4 in-silico gene-expression data, modest improvements over random for predicting descendants of central genes. Exact numeric metrics for 'distractor-robust' variants are not provided.",
            "performance_without_robustness": null,
            "has_ablation_study": false,
            "number_of_distractors": null,
            "key_findings": "ABCD significantly reduces posterior entropy over graph/function compared to random baselines in batched settings; by allowing repeated allocation to informative interventions and using likelihood reweighting of sampled DAGs, the method can actively refute incorrect graph hypotheses that arise from spurious finite-sample correlations. The paper also shows mutual-information utility is consistent in budgeted batched single-node intervention settings while some previously proposed utilities (e.g., Ness et al. 2018) are not.",
            "uuid": "e984.0",
            "source_info": {
                "paper_title": "ABCD-Strategy: Budgeted Experimental Design for Targeted Causal Structure Discovery",
                "publication_date_yy_mm": "2019-02"
            }
        },
        {
            "name_short": "Mutual-Information Utility",
            "name_full": "Mutual-Information-based Utility for Experimental Design",
            "brief_description": "Utility function that selects experiments/interventions to maximize expected mutual information between the target graph functional f(G) and prospective observations, equivalent to maximizing expected decrease in posterior entropy of f(G).",
            "citation_title": "Active learning for structure in Bayesian networks",
            "mention_or_use": "use",
            "method_name": "Mutual-information acquisition for causal discovery",
            "method_description": "Define utility U_ML^f(y, xi; D) = H(f | D) - H(f | D, y, xi); select interventions xi maximizing expected utility under current posterior. In this paper, mutual information is approximated by sampling DAGs from the posterior and computing entropies under approximate posteriors; in the infinite-sample limit this reduces to selecting interventions that minimize expected log-size of the interventional MEC.",
            "environment_name": "Batched interventional environments (simulated DAGs, in-silico perturbation data)",
            "environment_description": "Used in batched experimental design settings where multiple intervention samples can be collected per batch; supports adaptive selection across batches.",
            "handles_distractors": null,
            "distractor_handling_technique": null,
            "spurious_signal_types": "Ambiguity from finite samples and Markov equivalence; implicitly addresses spurious graph hypotheses by choosing experiments that maximally reduce uncertainty.",
            "detection_method": "Not explicit; mutual information drives selection toward experiments that most reduce posterior entropy, which tends to reveal hypotheses that are inconsistent with spurious correlations when such experiments are performed.",
            "downweighting_method": "When used with posterior reweighting (as in ABCD), DAGs inconsistent with interventional data are downweighted via their likelihood under new observations.",
            "refutation_method": "By selecting interventions that maximally reduce entropy, the method produces data that can rule out (refute) DAGs that produced spurious correlations under observational data alone.",
            "uses_active_learning": true,
            "inquiry_strategy": "Expected mutual information maximization (possibly batched and multiset-valued), with approximation via posterior samples and simulated outcomes, and greedy selection exploiting submodularity.",
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "Mutual-information utility generalizes earlier single-sample active-learning formulations to batched settings and finite-sample regimes, can select repeat interventions (useful for allocating more samples to particularly informative interventions), and in the infinite-sample limit selects interventions that minimize expected log-size of interventional MECs; it is shown to be budgeted-batch consistent for single-node interventions.",
            "uuid": "e984.1",
            "source_info": {
                "paper_title": "ABCD-Strategy: Budgeted Experimental Design for Targeted Causal Structure Discovery",
                "publication_date_yy_mm": "2019-02"
            }
        },
        {
            "name_short": "Importance-weighted empirical-Bayes reweighting",
            "name_full": "Likelihood-based importance-weighted empirical-Bayes posterior approximation (plug-in MLE reweighting)",
            "brief_description": "An approximation used to compute posterior-after-hypothetical-data by reweighting sampled DAGs with the likelihood of the hypothetical/new observations under each DAG evaluated at its MLE parameters, yielding tractable importance weights.",
            "citation_title": "here",
            "mention_or_use": "use",
            "method_name": "Importance-weighted empirical-Bayes reweighting (hat{w}_i)",
            "method_description": "Given sampled candidate DAGs G_i with parameter MLEs theta_hat^{G_i}, compute hat{w}_i = P(y | G_i, xi, theta_hat^{G_i}) and form an empirical-Bayes approximate posterior proportional to prior(G_i)*P(D | G_i, theta_hat^{G_i}). Use these weights both to approximate H(f | D) and H(f | D, y, xi) when evaluating mutual-information utility. This avoids integrating over theta and enables greedy acquisition.",
            "environment_name": "Batched interventional simulations and in-silico perturbation data",
            "environment_description": "Used within ABCD to score candidate interventions by simulating hypothetical outcomes and reweighting candidate graphs; applicable to environments that provide likelihood models for interventional outcomes.",
            "handles_distractors": true,
            "distractor_handling_technique": "Downweights candidate DAGs (and thus spurious edges) that poorly predict observed interventional data through likelihood-based importance weights; effectively prioritizes models consistent with experimental outcomes.",
            "spurious_signal_types": "Finite-sample spurious edge orientations and candidate graphs that overfit observational noise; indirectly handles confounding only to extent interventions break incoming edges.",
            "detection_method": "Graphs that fail to predict new interventional data receive low hat{w}_i, revealing spurious hypotheses; divergence between predicted and observed outcomes indicates spuriousness.",
            "downweighting_method": "Direct multiplicative downweighting of sampled DAGs by their P(y | G, xi, theta_hat) value (importance weight).",
            "refutation_method": "If hat{w}_i approaches zero over batches, the corresponding DAG (and its edges) are effectively refuted as explanations for the data.",
            "uses_active_learning": true,
            "inquiry_strategy": "Used to evaluate the expected posterior change for hypothetical outcomes in mutual-information acquisition; candidate interventions are chosen to produce outcomes that will most aggressively alter importance weights.",
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": false,
            "number_of_distractors": null,
            "key_findings": "The importance-weighted empirical-Bayes approximation makes mutual-information-based batched experimental design tractable and provides a principled way to downweight candidate graphs that are inconsistent with interventional outcomes, thereby enabling the method to refute spurious causal relations that arise from observational ambiguity or finite-sample noise.",
            "uuid": "e984.2",
            "source_info": {
                "paper_title": "ABCD-Strategy: Budgeted Experimental Design for Targeted Causal Structure Discovery",
                "publication_date_yy_mm": "2019-02"
            }
        },
        {
            "name_short": "DAG-bootstrap",
            "name_full": "DAG bootstrap (bootstrap-based candidate set of DAGs)",
            "brief_description": "A nonparametric procedure to produce a high-probability candidate set of DAGs by resampling the data and applying a DAG-learner to each bootstrap sample, used here to approximate the posterior over graphs.",
            "citation_title": "Data analysis with Bayesian networks: A bootstrap approach",
            "mention_or_use": "use",
            "method_name": "DAGBootstrap candidate-set sampling",
            "method_description": "Repeatedly resample data (with replacement) to create bootstrap datasets, run a DAG learning algorithm (capable of handling interventional and observational data) on each bootstrap dataset to produce T candidate DAGs \\hat{G}_T, and weight them by unnormalized posterior scores to approximate P(G | D). This set is used in downstream importance-weighted mutual-information computations.",
            "environment_name": "Simulated DAG data and in-silico gene-expression perturbation datasets",
            "environment_description": "Used as posterior approximation in batched experimental design; not itself an interactive policy but used to construct the belief state the active learner operates on.",
            "handles_distractors": true,
            "distractor_handling_technique": "Resampling variability highlights unstable (potentially spurious) edges: edges that frequently disappear across bootstrap samples indicate weak/support-lacking or spurious relationships; bootstrap frequencies can be used as evidence (low frequency =&gt; suspect).",
            "spurious_signal_types": "Edges that arise from sampling noise / spurious correlations due to finite data.",
            "detection_method": "Empirical frequency of edge appearance across bootstrap DAGs; low-frequency edges are flagged as unstable/spurious.",
            "downweighting_method": "Candidate DAGs with low bootstrap support receive lower unnormalized posterior weight w_{G,D} when forming the approximate posterior; combined with importance reweighting further downweights inconsistent DAGs.",
            "refutation_method": "Bootstrap evidence combined with interventional likelihoods leads to progressive refutation of edges that do not persist across resamples and interventions.",
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": false,
            "number_of_distractors": null,
            "key_findings": "DAG bootstrap provides a computationally efficient approximate posterior (candidate set) used by ABCD; bootstrap-derived candidate variability serves as a heuristic signal for unstable/spurious edges that can be targeted by interventions and subsequently downweighted via likelihood reweighting.",
            "uuid": "e984.3",
            "source_info": {
                "paper_title": "ABCD-Strategy: Budgeted Experimental Design for Targeted Causal Structure Discovery",
                "publication_date_yy_mm": "2019-02"
            }
        },
        {
            "name_short": "Ness2018 utility (criticized)",
            "name_full": "Bayesian active learning experimental design for inferring signaling networks (Ness et al., 2018) utility",
            "brief_description": "A previously proposed batched experimental design utility that scores interventions by the expected number of additional edges that could be oriented relative to the observational MEC; shown in this paper to be computationally expensive and, in some batched/budgeted settings, inconsistent.",
            "citation_title": "A Bayesian active learning experimental design for inferring signaling networks",
            "mention_or_use": "mention",
            "method_name": "Edge-orientation expected-gain utility (Ness et al., 2018)",
            "method_description": "Selects interventions to maximize the expected number of edges that become oriented in the interventional Markov equivalence class (relative to observational MEC), assuming possibly infinite samples per intervention; computationally costly (factorial dependence on batch size) and in the paper shown to be non-consistent in certain budgeted settings because it may repeatedly select the same intervention.",
            "environment_name": "Bathed interventional experimental design (signaling network inference)",
            "environment_description": "Designed for batched interventions where the score is evaluated w.r.t. orientations achievable via Meek rules under interventional MECs; the method presumes the MEC is known initially and infinite samples per chosen intervention are feasible.",
            "handles_distractors": false,
            "distractor_handling_technique": null,
            "spurious_signal_types": null,
            "detection_method": null,
            "downweighting_method": null,
            "refutation_method": null,
            "uses_active_learning": true,
            "inquiry_strategy": "Choose interventions that are expected to orient the largest number of edges (graph-based, Meek-rule propagation), selecting up to K unique interventions per batch.",
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "The paper demonstrates a counterexample where this utility repeatedly selects the same intervention and fails to be budgeted-batch consistent; ABCD's mutual-information approach fixes this by accounting for posterior updates and allowing sample reallocation rather than only counting orientations relative to the observational MEC.",
            "uuid": "e984.4",
            "source_info": {
                "paper_title": "ABCD-Strategy: Budgeted Experimental Design for Targeted Causal Structure Discovery",
                "publication_date_yy_mm": "2019-02"
            }
        },
        {
            "name_short": "Interventional-MEC algorithms / Meek rules",
            "name_full": "Interventional Markov Equivalence Class estimation and Meek rules (Hauser & Bühlmann)",
            "brief_description": "Graph-theoretic methods for representing and reasoning about equivalence classes under interventions; Meek rules propagate edge orientations given detected oriented edges to further orient the essential graph.",
            "citation_title": "Characterization and greedy learning of interventional Markov equivalence classes of directed acyclic graphs",
            "mention_or_use": "use",
            "method_name": "Interventional-MEC estimation and Meek-rule orientation",
            "method_description": "Given a family of interventions, compute the interventional essential graph (Ess^I(G)) that represents the reduced equivalence class; Meek orientation rules are used to infer additional directed edges deterministically when certain local patterns exist. These algorithms are used as a target in graph-based design strategies (select interventions that maximize oriented edges).",
            "environment_name": "Interventional causal discovery on simulated DAGs and real-world interventional datasets",
            "environment_description": "Offline or active intervention settings where interventions remove incoming edges to targets; Meek rules propagate orientations noniteratively and are used by several design methods to score candidate interventions.",
            "handles_distractors": null,
            "distractor_handling_technique": null,
            "spurious_signal_types": "Ambiguity from Markov equivalence and indistinguishable edge orientations under limited interventions; does not directly model measurement noise.",
            "detection_method": "Orientation propagation and checking of consistency across interventional skeleta; ambiguous edges remain undirected until broken by interventions.",
            "downweighting_method": null,
            "refutation_method": "Interventions that change the interventional skeleton eliminate candidate DAGs in the equivalence class, thereby refuting spurious orientations consistent with observational data.",
            "uses_active_learning": null,
            "inquiry_strategy": "Graph-based scoring: choose interventions that are expected to orient the most edges (e.g., maximize Meek-rule-induced orientations).",
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "Meek-rule and interventional-MEC computations are the basis of many graph-based experimental-design heuristics; ABCD's mutual-information objective reduces to selecting interventions that produce fine interventional-MECs in the infinite-sample limit, connecting information-theoretic and graph-theoretic design criteria.",
            "uuid": "e984.5",
            "source_info": {
                "paper_title": "ABCD-Strategy: Budgeted Experimental Design for Targeted Causal Structure Discovery",
                "publication_date_yy_mm": "2019-02"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Budgeted experiment design for causal structure learning",
            "rating": 2
        },
        {
            "paper_title": "A Bayesian active learning experimental design for inferring signaling networks",
            "rating": 2
        },
        {
            "paper_title": "Two optimal strategies for active learning of causal models from interventional data",
            "rating": 2
        },
        {
            "paper_title": "Characterization and greedy learning of interventional Markov equivalence classes of directed acyclic graphs",
            "rating": 2
        },
        {
            "paper_title": "Active learning for structure in Bayesian networks",
            "rating": 1
        },
        {
            "paper_title": "Data analysis with Bayesian networks: A bootstrap approach",
            "rating": 1
        },
        {
            "paper_title": "Permutation-based causal inference algorithms with interventions",
            "rating": 1
        }
    ],
    "cost": 0.01620075,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>ABCD-Strategy: Budgeted Experimental Design for Targeted Causal Structure Discovery</h1>
<p>Raj Agrawal<br>MIT<br>Chandler Squires<br>Karren Yang<br>Karthikeyan Shanmugam<br>Caroline Uhler<br>MIT<br>MIT<br>MIT-IBM Watson AI Lab<br>MIT<br>IBM Research NY</p>
<h2>Abstract</h2>
<p>Determining the causal structure of a set of variables is critical for both scientific inquiry and decision-making. However, this is often challenging in practice due to limited interventional data. Given that randomized experiments are usually expensive to perform, we propose a general framework and theory based on optimal Bayesian experimental design to select experiments for targeted causal discovery. That is, we assume the experimenter is interested in learning some function of the unknown graph (e.g., all descendants of a target node) subject to design constraints such as limits on the number of samples and rounds of experimentation. While it is in general computationally intractable to select an optimal experimental design strategy, we provide a tractable implementation with provable guarantees on both approximation and optimization quality based on submodularity. We evaluate the efficacy of our proposed method on both synthetic and real datasets, thereby demonstrating that our method realizes considerable performance gains over baseline strategies such as random sampling.</p>
<h2>1 Introduction</h2>
<p>Determining the causal structure of a set of variables is a fundamental task in causal inference, with widespread applications not only in artificial intelligence but also in scientific domains such as biology and economics (Friedman et al., 2000; Pearl, 2003; Robins et al., 2000; Spirtes et al., 2000). One of the most common ways of representing causal structure is through a directed acyclic graph (DAG), where a directed edge between two variables in the DAG represents a direct
causal effect and a directed path indicates an indirect causal effect (Spirtes et al., 2000).</p>
<p>Causal structure learning is intrinsically hard, since a DAG is generally only identifiable up to its Markov equivalence class (MEC) (Verma and Pearl, 1991; Andersson et al., 1997). Identifiability can be improved by performing interventions (Hauser and Bühlmann, 2012; Yang et al., 2018), and several algorithms have been proposed for structure learning from a combination of observational and interventional data (Wang et al., 2017; Hauser and Bühlmann, 2012; Yang et al., 2018). Since experiments tend to be costly in practice, a natural question is how principled experimental design (i.e., selection of intervention targets) can be leveraged to maximize the performance of these algorithms under budget constraints.</p>
<p>Seminal works by Tong and Koller (2001) and Murphy (2001) showed that experimental design can improve structure recovery in causal DAG models. However, these methods assume a basic framework in which experiments are performed one sample at a time. In practice, experimenters often perform a batch of interventions and collect samples over multiple rounds of experiments; and they must also factor in budget and feasibility constraints, such as on the number of unique interventions that can be performed in a single experiment, the number of experimental rounds, and the total number of samples to be collected. In genomics, for instance, genome editing technologies have enabled the collection of batches of large-scale interventional gene expression data (Dixit et al., 2016). An imminent problem is understanding how to optimally select a batch of interventions and allocate samples across these interventions, over multiple experimental rounds in a computationally tractable manner.</p>
<p>Since the initial works by Tong and Koller (2001) and Murphy (2001), there have been a number of new experimental design methods under budget constraints (Hauser and Bühlmann, 2014; Ghassami et al., 2018; Ness et al., 2018). These methods suffer from two drawbacks: (1) poor computational scaling (cf.</p>
<p>Ness et al., 2018) or (2) strong assumptions including the availability of infinite observational and/or interventional data from each experiment (cf. Hauser and Bühlmann, 2014; Ghassami et al., 2018). Since it is difficult to learn the correct MEC in a limited sample setting, it is desirable to use interventional samples not only to improve identifiability but also to help distinguish between observational MECs.
Generalizing the frameworks in (Tong and Koller, 2001; Murphy, 2001; Cho et al., 2016; Hauser and Bühlmann, 2014; Ness et al., 2018), we assume the experimenter is interested in learning some function $f(G)$ of the unknown graph $G$. Returning to gene regulation, one might set $f(G)$ to indicate whether some gene $X$ is downstream of some gene $Y$, i.e. if $X$ is a descendant of $Y$ in $G$. Using targeted experimental design, all statistical power is placed in learning the target function rather than being agnostic to recovering all features in the graph. In addition, we also explicitly take into account that only finitely many samples are allowed in each round, and work under various budget constraints such as a limit on the number of rounds of experimentation.</p>
<p>We start by reviewing causal DAGs in Section 2 and then propose an entropy-based score function that generalizes the one by Tong and Koller (2001) and Murphy (2001) in Section 3. Since optimizing this score function is in general computationally intractable, we propose our $A B C D$-Strategy consisting of approximations via weighted importance sampling and greedy optimization in Section 4. We also provide guarantees for this algorithm based on submodularity. Further, in contrast to earlier score functions, we show that our proposed score function is provably consistent. Finally, in Section 5 we demonstrate the empirical gains of the proposed method over random sampling on both synthetic and real datasets.</p>
<h2>2 Preliminaries</h2>
<p>Causal DAGs: Let $G=([p], A)$ be a directed acyclic graph (DAG) with vertices $[p]:={1, \ldots, p}$ and directed edges $A$, where $(i, j) \in A$ represents the arrow $i \rightarrow j$. A linear causal model is specified by a DAG $G$ and a corresponding set of edge weights $\theta \in \mathbb{R}^{|A|}$. Each node $i$ in $G$ is associated with a random variable $X_{i}$. Under the Markov Assumption, each variable $X_{i}$ is conditionally independent of its nondescendants given its parents, which implies that the joint distribution factors as $\prod_{i=1}^{p} \mathbb{P}\left(X_{i} \mid \operatorname{Pa}<em i="i">{G}\left(X</em>}\right)\right)$, where $\mathrm{Pa<em i="i">{G}\left(X</em>$ (Spirtes et al., 2000, Chapter 4). This factorization implies a set of conditional independence (CI) relations; the Markov equivalence class (MEC) of a DAG $G$ consists of all}\right)$ denotes the parents of node $X_{i</p>
<p>DAGs that share the same CI relations (Lauritzen, 1996, Chapter 3). The essential graph $\operatorname{Ess}(G)$ is a partially oriented graph that uniquely represents the MEC of a DAG by placing directed arrows on edges consistent across the equivalence class and leaves the other edges undirected (Andersson et al., 1997).</p>
<p>Learning with Interventions: Let intervention $I \subseteq[p]$ be a set of intervention targets. Intervening on $I$ removes the incoming edges to the random variables $X_{I}:=\left(X_{i}\right)<em I="I">{i \in I}$ in $G$ and sets the joint distribution of $X</em>^{}$ to a new interventional distribution $\mathbb{P}^{I}$. The resulting mutilated graph is denoted by $G^{I}$. A typical choice of $\mathbb{P}^{I}$ is the product distribution $\prod_{i \in I} f_{i}\left(X_{i}\right)$, where each $f_{i}\left(X_{i}\right)$ is the probability density function for the intervention at $X_{i}$. We denote by $\mathcal{I<em>}:=\left{I_{1}, \cdots, I_{K}\right}$ the set of all $K \in \mathbb{N}$ allowed interventions and by $\mathcal{I} \subseteq \mathcal{I}^{</em>}$ the subset of selected interventions. An intervention $I=\emptyset$ indicates observational data. We assume that $\mathcal{I}^{<em>}$ is a conservative family of interventions, i.e., for any $i \in[p]$, there exists some $I_{j} \in \mathcal{I}^{</em>}$ such that $i \notin I_{j}$ (Hauser and Bühlmann, 2012). Given a conservative family of targets $\mathcal{I}$, two DAGs $G_{1}$ and $G_{2}$ are $\mathcal{I}$-Markov equivalent if they are observationally Markov equivalent and for all $I \in \mathcal{I}, G_{1}^{I}$ and $G_{2}^{I}$ have the same skeleta (Hauser and Bühlmann, 2012, 2015). The set of $\mathcal{I}$-Markov equivalent DAGs can be represented by the $\mathcal{I}$-essential graph $\operatorname{Ess}^{I}(G)$, a partially directed graph with at least as many directed arrows as $\operatorname{Ess}(G)$ (Hauser and Bühlmann, 2012, Theorem 10).
Bayesian Inference over DAGs: In various applications, the goal is to recover a function $f(G)$ of the underlying causal DAG $G$ given a mix of $n$ independent observational and interventional samples $D=\left{\left(X_{m i}, I^{(m)}\right): I^{(m)} \in \mathcal{I}^{*}, m \in[n], i \in[p]\right}$. For example, we might ask whether an undirected edge $(i, j)$ is in $A$, or we might wish to discover which nodes are the parents of a node $i$. We can encode our prior structural knowledge about the underlying DAG through a prior $\mathbb{P}(G)$. The likelihood $\mathbb{P}(D \mid G)$ is obtained by marginalizing out $\theta$ :</p>
<p>$$
\begin{aligned}
\mathbb{P}(D \mid G) &amp; =\int_{\theta} \mathbb{P}(D, \theta \mid G) d \theta \
&amp; =\int_{\theta} \mathbb{P}(D \mid \theta, G) \mathbb{P}(\theta \mid G) d \theta
\end{aligned}
$$</p>
<p>and can be computed in closed-form for certain distributions (Geiger and Heckerman, 1999; Kuipers et al., 2014). Applying Bayes' Theorem yields the posterior distribution $\mathbb{P}(G \mid D) \propto \mathbb{P}(D \mid G) \mathbb{P}(G)$, which describes the state of knowledge about $G$ after observing the data $D$. Given the posterior, we can then compute $\mathbb{E}_{\mathbb{P}(G \mid D)} f(G)$, the posterior mean of some target function $f(G)$. Note that when $f$ is an indicator function, this quantity is a posterior probability.</p>
<h2>3 Optimal Bayesian Experimental Design</h2>
<p>Our goal is to learn some feature $f(G)$ of the unknown graph through experimental design under budget constraints such as limited number of experimental rounds. In principle, this question can be answered using optimal Bayesian experimental design, namely by selecting the experiment that maximizes the expected value of some utility function $U$, where the expectation is with respect to hypothetical data generated according to our current beliefs (Chaloner and Verdinelli, 1995). Here, the expected utility function $U$ is a function defined on multisets of $\mathcal{I}^{<em>}$ :
Definition 3.1. The expected utility $U^{f}(\xi ; D)$ of a multiset of interventions $\xi \in \mathbb{Z}^{\mathcal{I}^{</em>}}$ for learning a function $f(G)$ given currently collected data $D$ is given by</p>
<p>$$
\begin{aligned}
U^{f}(\xi ; D) &amp; =\mathbb{E}<em D="D" G_="G," _mid="\mid" _theta="\theta">{y \sim \mathbb{P}(y \mid D, \xi)} U^{f}(y, \xi ; D) \
&amp; =\mathbb{E}</em>
\end{aligned}
$$} \mathbb{E}_{y \mid G, \theta, \xi} U^{f}(y, \xi ; D), \quad y \in \mathbb{R}^{|\xi|</p>
<p>where $U^{f}(y, \xi ; D) \in \mathbb{R}$ is a function measuring the utility of observing additional samples $y$ from a proposed design $\xi$ and $|\xi|:=\sum_{I \in \mathcal{I}^{<em>}} \mid #$ times $I$ in $\xi \mid$. The optimal Bayesian design $\xi^{</em>}$ under a set of design constraints $C$ is given by</p>
<p>$$
\xi^{<em>} \in \underset{\xi \in \mathbb{Z}^{I^{</em>}} \cap C}{\arg \max } U^{f}(\xi ; D)
$$</p>
<p>We denote samples collected from such an optimal strategy $\xi^{<em>}$ by $D_{\xi^{</em>}}$</p>
<p>In Definition 3.1, $y$ is distributed according to our current beliefs $\mathbb{P}(y \mid D, \xi)=\mathbb{E}_{G, \theta \mid D}[\mathbb{P}(y \mid G, \theta, \xi)]$, a mixture distribution over $(G, \theta)$, and the utility function $U^{f}(y, \xi ; D)$ is averaged over this distribution. There are many potential choices for $U^{f}(y, \xi ; D)$, a popular one being mutual information. Tong and Koller (2001), Cho et al. (2016) and Murphy (2001) propose optimizing mutual information for the problem of recovering the full graph. More precisely, they consider the problem where $f(G)=G$ in the active learning setting, where the experimenter can adaptively collect one sample at a time. We here extend their framework to general functions $f(G)$ and the batched setting, where multiple samples are collected at once and the total number of batches is fixed by the experimenter. Hence, $U^{f}$ must be defined on multisets instead of elements of $\mathcal{I}^{*}$ since multiple samples (i.e., interventions of the same type) may be collected in each batch. Note that the difficulty in solving Eq. (2) stems from the constraint set $C$, which renders this optimization problem combinatorial.
Recently, Ness et al. (2018) proposed a Bayesian experimental design method to work in the batched setting.</p>
<p>The authors proposed a utility function based on the expected number of additional edges that could be oriented by performing a particular intervention given the observational MEC. This function is similar to the one proposed by Hauser and Bühlmann (2014) and Ghassami et al. (2018), in which interventions are chosen that fully identify the causal network given the MEC. Unfortunately, the algorithm in Ness et al. (2018) has factorial dependence on the size of the batch; in addition, we prove in Appendix A. 3 that their proposed utility function is, in general, not consistent; see Definition 3.3 for a definition of consistency.</p>
<p>We therefore follow the approach taken by Tong and Koller (2001) and Murphy (2001) and consider the utility function $U^{f}(y, \xi ; D)$ to be given by mutual information. Maximizing the mutual information is equivalent to picking the set of interventions that leads to the greatest expected decrease in entropy of $f(G)$. The mutual information utility function is given by</p>
<p>$$
U_{\mathrm{M} . \mathrm{L}}^{f}(y, \xi ; D):=H(f \mid D)-H(f \mid D, y=y, \xi)
$$</p>
<p>where the entropy $H(f \mid D)$ equals</p>
<p>$$
\begin{gathered}
\sum_{e: f(G)=e}-\mathbb{P}(f(G)=e \mid D) \log \mathbb{P}(f(G)=e \mid D) \
\text { and } \mathbb{P}(f(G)=e \mid D)=\mathbb{E}<em _theta="\theta">{\mathbb{P}(G \mid D)} \mathbb{1}(f(G)=e) \
\mathbb{P}(G \mid D) \propto \int</em>(G)
\end{gathered}
$$} \mathbb{P}(D \mid G, \theta) \mathbb{P}(\theta \mid G) \mathbb{P</p>
<p>To better understand the behavior of $U_{\mathrm{M} . \mathrm{L}}^{f}$, we prove the following proposition, which highlights the behavior of $U_{\mathrm{M} . \mathrm{L}}^{f}$ in the limit of infinite samples per intervention; this is the setting studied by Hauser and Bühlmann (2014) and Ghassami et al. (2018).
Proposition 3.2. Suppose that the Markov equivalence class $\mathcal{G}$ of $G^{<em>}$ is known and the goal is to identify the underlying true $D A G G^{</em>}$. Furthermore, assume a uniform prior over $\mathcal{G}$, infinite samples per intervention $I \in \mathcal{I}$, and at most $K$ unique interventions per batch as in Ghassami et al. (2018). Then, $U_{\text {M.I. }}$ selects the interventions</p>
<p>$$
\mathcal{I}<em G="G" _in="\in" _mathcal_G="\mathcal{G">{M . I .} \in \underset{|\mathcal{I}| \leq K}{\arg \min } \frac{1}{|\mathcal{G}|} \sum</em>(G)\right|
$$}} \log _{2}\left|\operatorname{Ess}^{\mathcal{I}</p>
<p>where $\left|\operatorname{Ess}^{\mathcal{I}}(G)\right|:=\left|\left{G^{\prime} \in \mathcal{G}: G^{\prime} \in E s s^{\mathcal{I}}(G)\right}\right|$.
This result (proof in Appendix) shows that in the limiting case, mutual information selects interventions that lead to the finest expected $\log \mathcal{I}$-MEC sizes. This limiting behavior of mutual information parallels what graph-based score functions do, such as the ones considered by Hauser and Bühlmann (2014), Ghassami et al. (2018) and Ness et al. (2018), that invoke the</p>
<p>Meek Rules (Verma and Pearl, 1992) to select interventions that orient the most number of edges in the $\mathcal{I}$-essential graphs (in expectation).</p>
<p>A score function based on mutual information is particularly appealing since it not only has desirable properties in the infinite sample setting, but also does not require the MEC to be known, naturally handling the case of finite sample sizes. In particular, a score function based solely on Meek rules will not pick the same intervention twice by definition, since repeating the same intervention does not improve identifiability. As a result, adapting graph-based score functions in the finite sample regime requires first constructing an intervention set and then allocating samples instead of jointly picking and allocating samples. Mutual information, on the other hand, can pick the same intervention twice; for example if a particular intervention is very informative, selecting it twice and allocating more samples to it might lead to a greater expected decrease in entropy than a new intervention.</p>
<h3>3.1 Budget Constraints</h3>
<p>So far we have not specified the constraint set $C$ in Eq. (2). To this end, we assume that the experimenter has a total of $N$ samples to allocate across $B$ batches. While one could try to optimize the partition of $N$ samples across batches, in this work we study the simpler case where each batch $b, 1 \leq b \leq B$, receives a pre-specified amount of samples $N_{b}$ with $\sum_{b} N_{b}=N$. For simplifying notation we assume throughout that $N_{b}=\frac{N}{B}$. We leave the study of adaptive batch sizes $N_{b}$ for future work. The constraint set then equals,</p>
<p>$$
C_{N, b}:=\left{\xi \in \mathbb{Z}^{\mathcal{I}^{*}}:|\xi|=N_{b}\right}
$$</p>
<p>where the subscripts on $C$ emphasize the dependence on $N$ and $b$. Then, the optimal design in batch $b$ is obtained by solving the following combinatorial optimization problem:</p>
<p>$$
\xi_{b}^{<em>} \in \underset{\xi \in \mathbb{Z}^{\mathcal{I}^{</em>}} \cap C_{N, b}}{\arg \max } U\left(\xi ; D_{b-1}\right)
$$</p>
<p>where $D_{b-1}:=\left[D_{\xi_{1}^{<em>}}, \cdots, D_{\xi_{b-1}^{</em>}}\right]$ is all the data collected at the start of batch $b$ and $U\left(\xi ; D_{b-1}\right)$ could, for example, be the mutual information defined in Eq. (3). Notice that while a particular form of $U\left(\xi ; D_{b-1}\right)$ is provided in Definition 3.1, $U\left(\xi ; D_{b-1}\right)$ need not necessarily be a Bayesian utility function to fit within the framework of Eq. (5).</p>
<p>We now define a natural notion of consistency for any experimental design method that can be cast as an optimization routine in the form of Eq. (5). Since the consistency of a utility function should not depend on a specific constraint set such as $C_{N, b}$, Definition 3.3
assumes the constraint set is arbitrary and set by the practitioner.
Definition 3.3. Suppose $f(G)$ is identifiable in $\operatorname{Ess}^{\mathcal{I}^{<em>}}\left(G^{</em>}\right)$, where $G^{*}$ is the true unknown DAG. Let $C_{N, b}, 1 \leq b \leq B$ denote the constraints in batch $b$. A utility function $U(\xi)$ is budgeted batch consistent for learning a target feature $f(G)$ if</p>
<p>$$
\mathbb{P}\left(f(G) \mid D_{B}\right) \xrightarrow{\mu^{<em>}, \text { a.s.}} \mathbb{1}\left(f(G)=f\left(G^{</em>}\right)\right)
$$</p>
<p>as $N, B \rightarrow \infty$, where $\mu^{<em>}$ is the law determined by the true unknown causal DAG $\left(G^{</em>}, \theta^{<em>}\right)$
Theorem 3.4. $U_{M, L}^{f}$ is budgeted batch consistent for single-node interventions, i.e., when $\mathcal{I}^{</em>}=$ ${{1}, \cdots,{p}}$.
Remark 1. While Theorem 3.4 may not be surprising (proof in the Appendix), we found that various utility functions that seem natural and have been proposed in earlier work are not consistent in the budgeted setting. In particular, in Appendix A. 3 we show that the utility function proposed by Ness et al. (2018) is not consistent for single-node interventions. The main issue is that there are DAGs and constraint sets for which the same interventions keep getting selected, instead of selecting new interventions to fully identify $f(G)$.</p>
<h2>4 Tractable Algorithm</h2>
<p>While Section 3 provides a general framework for targeted experimental design, there are several computational challenges that we have not yet addressed. The first challenge is computing $U_{\text {M.I. }}^{f}(\xi ; D)$. This objective function requires summing over an exponential number of DAGs and marginalizing out the edge weights $\theta$. In this section, we discuss how to approximate $U_{\text {M.I. }}^{f}(\xi ; D)$ by sampling graphs (either through MCMC or the DAG-bootstrap Friedman et al. (1999)) and using the maximum likelihood estimator of $\theta$ for each graph. Taken together, these approximations not only allow the mutual information score to be computed tractably but also lead to desirable optimization properties. In particular, we prove in Theorem 4.1 that our approximate utility function is submodular. This property enables optimizing the approximate objective in a sequential greedy fashion with provable guarantees on optimization quality.</p>
<h3>4.1 Expectation over $(G, \theta)$</h3>
<p>A serious problem from a computational perspective is the expectation over $(G, \theta)$ in Definition 3.1. Since the number of DAGs grows superexponentially with $p$, enumerating all possible DAGs is intractable. Instead, in each batch $b$, we propose to sample $T$ graphs according to the posterior $\mathbb{P}\left(G \mid D_{b-1}\right)$. This can be</p>
<p>done using a variety of different Markov chain MonteCarlo (MCMC) samplers; see for example Heckerman et al. (1997); Ellis and Wong (2008); Friedman and Koller (2003); Niinimaki et al. (2016); Kuipers and Moffa (2017); Madigan and York (1995); Grzegorczyk and Husmeier (2008); Agrawal et al. (2018). An alternative that is often faster but still achieves good performance, is approximating the posterior via a highprobability candidate set of $T$ DAGs $\hat{\mathcal{G}}<em T="T">{T}$ (Heckerman et al., 1997; Friedman et al., 1999). While there are many ways to build up this set, a popular approach is through the nonparametric DAG bootstrap (Friedman et al., 1999). The main idea is to subsample the data (with replacement) $T$ times and fit a DAG learning algorithm to each of the generated datasets to construct $\hat{\mathcal{G}}</em>$ can then be weighted according to the ratio of unnormalized posterior probabilities,}$. Each $G \in \hat{\mathcal{G}}_{T</p>
<p>$$
w_{G, D}:=\frac{\mathbb{P}(G) \mathbb{P}(D \mid G)}{\sum_{G \in \hat{\mathcal{G}}_{T}} \mathbb{P}(G) \mathbb{P}(D \mid G)}
$$</p>
<p>to form an approximate posterior $\hat{\mathbb{P}}(G):=w_{G, D} \mathbb{1}(G \in$ $\hat{\mathcal{G}}_{T}$ ). The DAG learning algorithm used for this purpose must be able to handle a mix of observational and interventional data. Two recent methods that have been developed for this purpose are given in Hauser and Bühlmann (2012) and Wang et al. (2017). We summarize constructing an approximate posterior via the DAG bootstrap in Algorithm 1.</p>
<div class="codehilite"><pre><span></span><code><span class="nt">Algorithm</span><span class="w"> </span><span class="nt">1</span><span class="w"> </span><span class="nt">DAGBootSample</span>
<span class="w">    </span><span class="nt">Input</span><span class="o">:</span><span class="w"> </span><span class="nt">N</span><span class="w"> </span><span class="nt">datapoints</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="nt">D_</span><span class="p">{</span><span class="err">N</span><span class="p">}</span><span class="err">\</span><span class="o">),</span><span class="w"> </span><span class="nt">number</span><span class="w"> </span><span class="nt">of</span><span class="w"> </span><span class="nt">samples</span><span class="w"> </span><span class="nt">T</span>
<span class="w">    </span><span class="nt">Output</span><span class="o">:</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="nt">T</span><span class="err">\</span><span class="o">)</span><span class="w"> </span><span class="nt">bootstrap</span><span class="w"> </span><span class="nt">DAG</span><span class="w"> </span><span class="nt">samples</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="err">\</span><span class="nt">hat</span><span class="p">{</span><span class="err">\mathcal{G</span><span class="p">}</span><span class="err">}</span><span class="nt">_</span><span class="p">{</span><span class="err">T</span><span class="p">}</span><span class="err">\</span><span class="o">)</span>
<span class="w">    </span><span class="err">\</span><span class="o">(</span><span class="err">\</span><span class="nt">hat</span><span class="p">{</span><span class="err">\mathcal{G</span><span class="p">}</span><span class="err">}</span><span class="nt">_</span><span class="p">{</span><span class="err">T</span><span class="p">}</span><span class="w"> </span><span class="err">\</span><span class="nt">leftarrow</span><span class="w"> </span><span class="err">\</span><span class="nt">emptyset</span><span class="err">\</span><span class="o">)</span>
<span class="w">    </span><span class="nt">for</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="nt">s</span><span class="o">=</span><span class="nt">1</span><span class="o">:</span><span class="w"> </span><span class="nt">T</span><span class="err">\</span><span class="o">)</span><span class="w"> </span><span class="nt">do</span>
<span class="w">        </span><span class="err">\</span><span class="o">(</span><span class="err">\</span><span class="nt">hat</span><span class="p">{</span><span class="err">D</span><span class="p">}</span><span class="nt">_</span><span class="p">{</span><span class="err">N</span><span class="p">}</span><span class="w"> </span><span class="err">\</span><span class="nt">leftarrow</span><span class="w"> </span><span class="nt">N</span><span class="err">\</span><span class="o">)</span><span class="w"> </span><span class="nt">datapoints</span><span class="w"> </span><span class="nt">sampled</span><span class="w"> </span><span class="o">(</span><span class="nt">with</span><span class="w"> </span><span class="nt">replace-</span>
<span class="w">    </span><span class="nt">ment</span><span class="o">)</span><span class="w"> </span><span class="nt">from</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="nt">D_</span><span class="p">{</span><span class="err">N</span><span class="p">}</span><span class="err">\</span><span class="o">)</span>
<span class="w">        </span><span class="err">\</span><span class="o">(</span><span class="nt">G_</span><span class="p">{</span><span class="err">s</span><span class="p">}</span><span class="w"> </span><span class="err">\</span><span class="nt">leftarrow</span><span class="w"> </span><span class="err">\</span><span class="nt">operatorname</span><span class="p">{</span><span class="err">DAGLearner</span><span class="p">}</span><span class="err">\</span><span class="nt">left</span><span class="o">(</span><span class="nt">D_</span><span class="p">{</span><span class="err">N</span><span class="p">}</span><span class="err">\</span><span class="nt">right</span><span class="o">)</span><span class="err">\</span><span class="o">)</span><span class="w"> </span><span class="nt">e</span><span class="p">.</span><span class="nc">g</span><span class="o">.</span><span class="w"> </span><span class="o">(</span><span class="nt">Wang</span><span class="w"> </span><span class="nt">et</span><span class="w"> </span><span class="nt">al</span><span class="o">.,</span>
<span class="w">        </span><span class="nt">2017</span><span class="o">;</span><span class="w"> </span><span class="nt">Hauser</span><span class="w"> </span><span class="nt">and</span><span class="w"> </span><span class="nt">Bühlmann</span><span class="o">,</span><span class="w"> </span><span class="nt">2012</span><span class="o">)</span>
<span class="w">        </span><span class="err">\</span><span class="o">(</span><span class="err">\</span><span class="nt">hat</span><span class="p">{</span><span class="err">\mathcal{G</span><span class="p">}</span><span class="err">}</span><span class="nt">_</span><span class="p">{</span><span class="err">T</span><span class="p">}</span><span class="w"> </span><span class="err">\</span><span class="nt">leftarrow</span><span class="w"> </span><span class="err">\</span><span class="nt">hat</span><span class="p">{</span><span class="err">\mathcal{G</span><span class="p">}</span><span class="err">}</span><span class="nt">_</span><span class="p">{</span><span class="err">T</span><span class="p">}</span><span class="w"> </span><span class="err">\</span><span class="nt">cup</span><span class="w"> </span><span class="nt">G_</span><span class="p">{</span><span class="err">s</span><span class="p">}</span><span class="err">\</span><span class="o">)</span>
<span class="w">        </span><span class="nt">return</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="err">\</span><span class="nt">hat</span><span class="p">{</span><span class="err">\mathcal{G</span><span class="p">}</span><span class="err">}</span><span class="nt">_</span><span class="p">{</span><span class="err">T</span><span class="p">}</span><span class="err">\</span><span class="o">)</span>
</code></pre></div>

<p>Given $\hat{\mathcal{G}}<em _mathrm_M="\mathrm{M">{T}$, which can be constructed from Algorithm 1 or sampled from a Markov chain, we next discuss how to compute the expectation over $\theta$. Recall that $U</em>(\xi ; D)$ is given by} . \mathrm{L}}^{f</p>
<p>$$
\begin{aligned}
&amp; \mathbb{E}<em G_="G," _mid="\mid" _xi="\xi" y="y">{G \mid D}\left[\mathbb{E}</em>(y, \xi ; D)\right] \
&amp; =\mathbb{E}} U_{\mathrm{M} . \mathrm{L}}^{f<em D="D" G_="G," _mid="\mid" _theta="\theta">{G \mid D}\left[\mathbb{E}</em>} \mathbb{E<em _mathrm_M="\mathrm{M">{y \mid G, \theta, \xi} U</em>(y, \xi ; D)\right]
\end{aligned}
$$} . \mathrm{L}}^{f</p>
<p>Instead of carrying out the expensive expectation over $\theta \mid G, D$ in Eq. (7), we use the MLE of $\theta$ for each sampled $G$. This approximation is justified by the</p>
<p>Bernstein-von Mises Theorem, which implies that</p>
<p>$$
\begin{aligned}
\mathbb{P}(\theta \mid G, D) &amp; \rightarrow N\left(\hat{\theta}<em G="G">{\mathrm{MLE}}^{G}, \frac{1}{n} I\left(\theta</em>\right) \
\hat{\theta}_{\mathrm{MLE}}^{G} &amp; :=\underset{\theta}{\arg \max } \mathbb{P}(D \mid G, \theta)
\end{aligned}
$$}\right)^{-1</p>
<p>Here, $n$ is the number of datapoints in $D$, and $I\left(\theta_{G}\right)$ is the Fisher information matrix of the parameter $\theta_{G}$, which is the asymptotic limit of the maximum likelihood estimator $\hat{\theta}<em _mathrm_MLE="\mathrm{MLE">{\mathrm{MLE}}^{G}$ (Van der Vaart, 2000, Chapter 10). Therefore, the posterior distribution $\theta \mid D, G$ concentrates around $\hat{\theta}</em>)$ statistical rate. Hence, for moderate $n$ (e.g., when a moderate amount of observational data is provided at the start of the experimental design), Eq. (8) implies}}^{G}$ at the standard $O(1 / \sqrt{n</p>
<p>$$
\begin{aligned}
&amp; \mathbb{E}<em D="D" G_="G," _mid="\mid" _theta="\theta">{G \mid D} \mathbb{E}</em>}\left[\mathbb{E<em _mathrm_M="\mathrm{M">{y \mid G, \theta, \xi} U</em>(y, \xi ; D)\right] \
&amp; \approx \mathbb{E}} . \mathrm{L}}^{f<em G_="G," _hat_theta="\hat{\theta" _mid="\mid" y="y">{G \mid D}\left[\mathbb{E}</em><em _mathrm_M="\mathrm{M">{\mathrm{MLE}}^{G}, \xi} U</em>(y, \xi ; D)\right]
\end{aligned}
$$} . \mathrm{L}}^{f</p>
<p>In Hauser and Bühlmann (2015, Section 6.1), the authors provide a closed-form expression for $\hat{\theta}<em _mathrm_MLE="\mathrm{MLE">{\mathrm{MLE}}^{G}$ when $y \mid G, \theta$ is multivariate Gaussian. In this case, $\hat{\theta}</em>$ is a simple function of the sample covariance matrix.}}^{G</p>
<h3>4.2 Approximating Mutual Information</h3>
<p>While in the previous subsection we showed how to approximate the expectations in Eq. (9), computing $U_{\mathrm{M} . \mathrm{L}}^{f}(y, \xi)$ even for a fixed $y$ is intractable since we must sum over all possible DAGs. Recall from Eq. (3) that the mutual information utility function is</p>
<p>$$
U_{\mathrm{M} . \mathrm{L}}^{f}(y, \xi ; D)=H(f \mid D)-H(f \mid D, y=y, \xi)
$$</p>
<p>Note that $H(f \mid D)$ is a constant and does not matter in the optimization over $\xi$. More care is required for computing the second term in Eq. (10), since the posterior of $G$ changes as a result of observing $y$, the realizations of the interventions specified by $\xi$. We therefore cannot immediately use the samples in $\hat{\mathcal{G}}<em T="T">{T}$ to approximate this term. To overcome this problem, we propose to use weighted importance sampling and approximate $H(f \mid D, y, \xi)$ by a weighted average of DAGs in $\hat{\mathcal{G}}</em>, 1 \leq i \leq T$, by}$. We define the importance sample weights for DAG $G_{i</p>
<p>$$
w_{i}:=\frac{\mathbb{P}\left(D, y \mid G_{i}, \xi\right)}{\mathbb{P}\left(D \mid G_{i}\right)}
$$</p>
<p>In general, $w_{i}$ is not equal to $\mathbb{P}(y \mid G, \xi)$ since $D$ and $y$ are dependent without conditioning on $\theta$. While $\mathbb{P}(D, y \mid G, \xi)$ can be computed in closed-form if the prior on $\theta \mid G$ belongs to one of the families described in Geiger and Heckerman (1999), the dependence on previous samples in the importance weights makes</p>
<p>greedily building up the intervention set $\xi$ expensive. In particular, since Eq. (11) does not factorize, the importance weights must be recomputed with every new additional intervention, which again requires an integration over all parameters. Motivated by the approximation in Section 4, where the parameters of each sampled $G \in \hat{\mathcal{G}}_{T}$ are not marginalized out, we instead propose using the importance sample weights</p>
<p>$$
\begin{aligned}
\hat{w}<em i="i">{i} &amp; :=\frac{\mathbb{P}\left(D, y \mid G</em>}, \hat{\theta<em i="i">{\mathrm{MLE}}^{G</em>}}, \xi\right)}{\mathbb{P}\left(D \mid G_{i}, \hat{\theta<em i="i">{\mathrm{MLE}}^{G</em> \
&amp; =\mathbb{P}\left(y \mid G_{i}, \xi, \hat{\theta}}}\right)<em i="i">{\mathrm{MLE}}^{G</em>\right)
\end{aligned}
$$}</p>
<p>$\hat{w}<em _mathrm_M="\mathrm{M">{i}$ has the natural interpretation of re-weighting each DAG by the likelihood of the newly observed data $y$.
Recall from Eq. (3), that $U</em>$ translates into approximating the mutual information against a different posterior distribution in Eq. (3), namely} . \mathrm{I}}^{f}(y, \xi ; D)$ is based on weighting each DAG according to its posterior probability $\mathbb{P}(G \mid D) \propto \int_{\theta} \mathbb{P}(D \mid G, \theta) \mathbb{P}(\theta \mid G) \mathbb{P}(G)$. Using the importance sample weights $\hat{w}_{i</p>
<p>$$
\hat{\mathbb{P}}(G \mid D) \propto \mathbb{P}\left(D \mid G, \hat{\theta}_{\mathrm{MLE}}^{G}\right) \mathbb{P}(G)
$$</p>
<p>which is a specific instance of an empirical Bayes approximation. In what follows, we denote the mutual information score based on the posterior in Eq. (13) by $\hat{U}_{\mathrm{M} . \mathrm{I}}^{f}(y, \xi ; D)$.</p>
<h3>4.3 Greedy Optimization</h3>
<p>The cardinality constraint $|\xi|=N_{b}$ makes our optimization problem a difficult integer program. In the following, we show how to overcome this final computational hurdle using a generalized notion of submodularity for multisets (Soma and Yoshida, 2016). In particular, we prove that greedily selecting interventions provides a $\left(1-\frac{1}{e}\right)$ guarantee on optimization quality.</p>
<h2>Algorithm 2 GreedyDesign</h2>
<p>Input: Utility function $U$, number of samples $N_{b}$, intervention family $\mathcal{I}^{*}$</p>
<p>Output: Multiset of interventions $\xi$
1: $\xi \leftarrow \emptyset$
2: for $s=1: N_{b}$ do
$I^{<em>} \in \underset{I \in I^{</em>}}{\arg \max } U(\xi \cup I)$
$4: \quad \xi \leftarrow \xi \cup I^{*}$
return $\xi$</p>
<p>Theorem 4.1. Suppose $f(G)=G$ i.e. the goal is to recover the full graph as in Tong and Koller (2001); Cho et al. (2016); Murphy (2001); Ness et al. (2018). Then the difference between the global optimum</p>
<p>$$
v_{b}^{<em>}=\max _{\xi \in \mathbb{Z}^{I^{</em>}} \cap C_{N, b}} \mathbb{E}<em b-1="b-1">{G \mid D</em>}} \mathbb{E<em _mathrm_MLE="\mathrm{MLE">{y \mid G, \hat{\theta}</em>(y, \xi ; D)
$$}}^{G}, \xi} \hat{U}_{M . I .}^{f</p>
<p>and $\tilde{v}<em I="I" M="M" class="">{b}=$ GreedyDesign $\left(\hat{U}</em>^{}^{f}, N_{b}, \mathcal{I<em>}\right)$, the output of Algorithm 2 in batch $b$, satisfies $\tilde{v}<em b="b">{b} \geq\left(1-\frac{1}{e}\right) v</em>^{</em>}$, where $C_{N, b}$ is defined as in Eq. (4).
Remark. We conjecture that Theorem 4.1 holds for arbitrary functions $f$, but we currently only have a proof (see Appendix) for the case when $f(G)=G$.</p>
<p>We conclude this section by summarizing the developed Active Budgeted Causal Design Strategy (ABCDStrategy) in Algorithm 3 and then summarizing all the proposed approximations.</p>
<h2>Algorithm 3 ABCD-Strategy</h2>
<p>Input: Target functional $f$, interventional data collected $D_{b-1}$, observational data $D_{o b s}$, number of batch samples $N_{b}$, intervention family $\mathcal{I}^{*}$, number of DAGs $T$, number of datasets $M$</p>
<p>Output: Multiset of interventions $\xi$
1: $\xi \leftarrow \emptyset$
2: $G_{T} \leftarrow$ DAGBootSample $\left(\left[D_{o b s}, D_{b-1}\right], T\right)$
3: Compute $\hat{U}<em _mathrm_M="\mathrm{M">{\mathrm{M} . \mathrm{I} .}^{f}$ via Eq. (14)
4: return GreedyDesign $\left(\hat{U}</em>\right)$} . \mathrm{I} .}^{f}, N_{b}, \mathcal{I}^{*</p>
<p>In terms of approximations, Eq. (9) implies</p>
<p>$$
\begin{aligned}
&amp; \mathbb{E}<em G_="G," _mid="\mid" _theta_="\theta," _xi="\xi" y="y">{G, \theta \mid D}\left[\mathbb{E}</em>} \hat{U<em D="D" G_="G," _mid="\mid">{\mathrm{M} . \mathrm{I} .}^{f}(y, \xi ; D)\right] \
&amp; \approx \mathbb{E}</em>}\left[\mathbb{E<em _mathrm_MLE="\mathrm{MLE">{y \mid G, \hat{\theta}</em>}}^{G}, \xi} \hat{U<em t="1">{\mathrm{M} . \mathrm{I} .}(y, \xi ; D)\right] \
&amp; \approx \sum</em>}^{T} \sum_{m=1}^{M} \hat{U<em m="m" t="t">{\mathrm{M} . \mathrm{I} .}^{f}\left(y</em>, \xi ; D\right) \
&amp; \quad \text { s.t. } y_{t m} \stackrel{\text { i.i.d. }}{=} y \mid G_{t}, \hat{\theta}<em t="1">{\mathrm{MLE}}^{G}, \xi \
&amp; \approx \sum</em>}^{T} \sum_{m=1}^{M} \hat{U<em m="m" t="t">{\mathrm{M} . \mathrm{I} .}^{f}\left(y</em> \
&amp; \hat{U}}, \xi ; D\right), \text { where <em m="m" t="t">{\mathrm{M} . \mathrm{I} .}^{f}\left(y</em>(f \mid D) \
&amp; \hat{\mathbb{P}}}, \xi ; D\right):=H_{1}(f \mid D)-H_{2<em D="D" G_="G,">{1}(G \mid D):=w</em>} \mathbb{1}\left(G \in \hat{\mathcal{G}<em 2="2">{T}\right) \
&amp; \hat{\mathbb{P}}</em>}(G \mid D, y, \xi):=\frac{w_{G, D} \mathbb{P}\left(y \mid G, \xi, \hat{\theta<em t="1">{\mathrm{MLE}}^{G}\right)}{\sum</em>}^{T} w_{G_{t}, D} \mathbb{P}\left(y \mid G_{t}, \xi, \hat{\theta<em t="t">{\mathrm{MLE}}^{G</em>
\end{aligned}
$$}}\right)</p>
<p>where $M$ is the number of synthetic datasets generated, $H_{1}$ and $H_{2}$ are the entropies induced by $\hat{\mathbb{P}}<em 2="2">{1}$ and $\hat{\mathbb{P}}</em>}$ respectively, and $w_{G, D}$ is defined in Eq. (6). Note that $\hat{U<em I="I" M="M" class="">{\mathrm{M} . \mathrm{I} .}^{f}$ is based on the importance sample weights given in Eq. (12).
Proposition 4.2. The total runtime of Algorithm 2 with input utility function $\hat{U}</em>$.}^{f}$ is $O\left(p T \kappa^{3}+\right.$ $\left|\mathcal{I}^{*}\left|M T^{2} N_{b} \kappa p\right)\right.$, where $\kappa$ is the maximum indegree of a graph in $\hat{\mathcal{G}}_{T</p>
<p>See Appendix A. 5 for the proof of Proposition 4.2.</p>
<h2>5 Experiments</h2>
<p>We begin by considering a simple case to demonstrate the behavior of our ABCD-strategy under easily interpretable conditions. Consider the chain graph on $2 m-1$ nodes,</p>
<p>$$
1 \rightarrow 2 \rightarrow \ldots \rightarrow m \rightarrow \ldots \rightarrow p=2 m-1
$$</p>
<p>The corresponding essential graph is completely undirected, and the MEC has $2 m-1$ members, one with each node as the source. Assume that sufficient observational data is available to identify the MEC, and we are interested in fully identifying the DAG. Then, our ABCD-strategy selects interventions in order to minimize the expected entropy of the posterior over this MEC. Given a limit of one intervention per batch but infinite samples per batch, Proposition 3.2 implies the expected entropy after intervening at node $i$ or $2 m-i$, $1 \leq i \leq m$, is</p>
<p>$$
\frac{1}{2 m-1}\left(\sum_{j<i} \log (i-2)+\sum_{j>i} \log (m-(i+2))\right)
$$</p>
<p>which is minimized by choosing the midpoint $i=m$. Analogously, we see that the updated ${\emptyset,{m}}$-MEC is of the same form, so in the second batch, the optimal intervention will be halfway through the remaining nodes. This process of bisection is illustrated in Figure 1 and matches the behavior of our algorithm even in the finite-sample regime as described next.</p>
<p>Figure 2 illustrates the performance of our ABCDstrategy on fifty 11-node chain graphs with random edge weights sampled from $[-1,-.25] \cup[.25,1]$. For comparison, we consider a random intervention strategy that uniformly distributes the samples in each batch to $k$ interventions picked uniformly at random, where $k$ is the maximum number of unique interventions allowed per batch. Whereas the medianperforming random strategy barely reduces the entropy, the ABCD-strategy reduces the entropy significantly in all runs. When all $k$ interventions are
<img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: Illustration of active learning on a chain graph, beginning with a known MEC on a simulated dataset with $p=15$ nodes. The brown circles indicate the interventions selected in each batch.
<img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: Box plots for 50 runs of the random strategy versus our ABCD-strategy on the graph in Figure 5 with $p=11$ and $n=30$ samples. The horizontal line indicates the entropy of the prior distribution, i.e. uniform over the MEC. Note that $k=\infty$ corresponds to the case with no constraints on the number of unique interventions.
picked for the same batch, so that ABCD receives no feedback, the median-performing run of active learning still reduces the entropy as much as the bestperforming runs of the random strategy.
Having demonstrated the behavior of ABCD for a simple case, we now analyze the performance of our method on more general DAGs. The skeleton of each graph is sampled from an Erdös-Rényi model with density $\rho=0.25$. The edges of these graphs are directed by sampling a permutation of the nodes uniformly at random and orienting the edges accordingly. To avoid long runtimes when enumerating the MEC, we disposed of graphs with more than 100 members in their MEC. ${ }^{1}$ When the MEC is known, we may define a variant of the random strategy, Chordal-Random, which only intervenes on nodes that are in chordal components of the essential graph, i.e., nodes adjacent to at least one undirected edge. Since the Meek rules can only propagate by intervening within chordal components, Chordal-Random is a more fair baseline strategy for comparison than simple random sampling.
Figure 3a demonstrates the improvement in selecting interventions using the ABCD-strategy as compared to Chordal-Random when the number of unique interventions per batch is bounded by one. The entropy reduction for an interventional data set $D_{\xi}$ is defined as $\frac{H(G)-H(G \mid D_{\xi})}{H(G)}$, and it is used as a metric so that MECs of different sizes are comparable. Since the number of total possible unique interventions is $k B$, an increase in the number of batches also increases the variability of the interventions, reflected in the increase of en-</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3: Performance of intervention strategies for batch sizes $b$ as a function of the total number of samples, computed from 50 Erdös-Rényi DAGs with density $\rho=0.25$.
tropy reduction with batch size. Already with only 192 samples and 3 total batches, our ABCD-strategy is able to learn most graphs with complete certainty. The comparable performance of the Budgeted Experiment Design (BED) strategy (Ghassami et al., 2018) suggests that for the given experimental setup, the interventions that orient the most edges correspond well to those that most reduce entropy as we discussed in Proposition 3.2. Figure 3b shows that the performance of the ABCD-strategy remains strong even when the MEC of the graph is not known. Specifically, up to 3 additional MECs were generated by randomly flipping non-covered edges that did not create cycles, and again only graphs for which the union of these MECs had cardinality less than 100 were kept. Note that we are not able to compare with BED since BED requires that the MEC is known.</p>
<p>DREAM4 Synthetic Dataset. Finally, we applied our experimental design strategy to gene expression data from the DREAM4 10-node in-silico network reconstruction challenge (Schaffter et al., 2011). These data are generated from stochastic differential equations and simulate microarray data of gene regulatory networks. We constructed an observational dataset from the wild-type, multifactorial perturbation, and time 0 time-series samples ( 16 samples in total), and similarly, interventional datasets from the knockdown and knockout samples ( 2 samples each).</p>
<p>Previous work on experimental design applied to bi-
<img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 4: Top: DREAM4 ground truth 10-node network. Bottom: Performance of intervention strategies on predicting the descendants of gene 0 .
ological datasets (Cho et al., 2016) has focused on learning the entire network. In practice, practitioners may be specifically interested in performing experiments to elucidate a functional of the network, such as the pathway or local network surrounding a gene of interest. To emulate this setting, we applied our ABCDstrategy towards learning the downstream genes of select genes from the true network (Figure 4, top). Despite high variations in learning due to the small size of the dataset, we observed an improvement over the random strategy for several central genes (Fig. 4, bottom; Fig. 6). These results illustrate the promise of applying targeted experimental design for applications to genomics.</p>
<h2>6 Concluding Remarks</h2>
<p>We proposed Active Budgeted Causal Design Strategy (ABCD-Strategy), an experimental method based on optimal Bayesian experimental design with provable guarantees on approximation quality. Empirically, we demonstrated that ABCD yields considerable boosts over random sampling for both targeted and full causal structure discovery. Such experimental design strategies are particularly relevant for applications to genomics, where the number of possible experiments is huge due to the possibility of intervening on combinations of genes.</p>
<h2>Acknowledgements</h2>
<p>R. Agrawal was partially supported by IBM. K.D. Yang was supported by an NSF graduate fellowship</p>
<p>and ONR (N00014-18-1-2765). C. Uhler was partially supported by NSF (DMS-1651995), ONR (N00014-17-1-2147 and N00014-18-1-2765), IBM, and a Sloan Fellowship.</p>
<h2>References</h2>
<p>R. Agrawal, T. Broderick, and C. Uhler. Minimal I-MAP MCMC for scalable structure discovery in causal DAG models. In International Conference on Machine Learning, 2018.
S. A. Andersson, D. Madigan, and M. D. Perlman. A characterization of Markov equivalence classes for acyclic digraphs. Annals of Statistics, 25(2):505541, 1997.
K. Chaloner and I. Verdinelli. Bayesian experimental design: A review. Statistical Science, 10:273-304, 1995.
H. Cho, B. Berger, and J. Peng. Reconstructing causal biological networks through active learning. PLoS ONE, 2016.
A. Dixit, O. Parnas, B. Li, J. Chen, C. Fulco, L. JerbyArnon, N. Marjanovic, D. Dionne, T. Burks, R. Raychowdhury, B. Adamson, T. Norman, E. Lander, J. Weissman, N. Friedman, and A. Regev. Perturbseq: dissecting molecular circuits with scalable single-cell RNA profiling of pooled genetic screens. Cell, pages 1853-1866, 2016.
B. Ellis and W. H. Wong. Learning causal Bayesian network structures from experimental data. Journal of the American Statistical Association, 103:778789, 2008.
N. Friedman and D. Koller. Being Bayesian about network structure. A Bayesian approach to structure discovery in Bayesian networks. Machine Learning, $50: 95-125,2003$.
N. Friedman, M. Goldszmidt, and A. J. Wyner. Data analysis with Bayesian networks: A bootstrap approach. In Proceedings of the Fifteenth Conference on Uncertainty in Artificial Intelligence, 1999.
N. Friedman, M. Linial, I. Nachman, and D. Pe'er. Using Bayesian networks to analyze expression data. Journal of Computational Biology, 7(3-4):601-620, 2000 .
D. Geiger and D. Heckerman. Parameter priors for directed acyclic graphical models and the characterization of several probability distributions. In Proceedings of the Fifteenth Conference on Uncertainty in Artificial Intelligence, 1999.
A. Ghassami, S. Salehkaleybar, N. Kiyavash, and E. Bareinboim. Budgeted experiment design for causal structure learning. In International Conference on Machine Learning, 2018.
S. B. Gillispie and M. D. Perlman. Enumerating Markov equivalence classes of acyclic digraph models. In Proceedings of the 17th Conference in Uncertainty in Artificial Intelligence, 2001.
M. Grzegorczyk and D. Husmeier. Improving the structure MCMC sampler for Bayesian networks by introducing a new edge reversal move. Machine Learning, 71:265-305, 2008.
A. Hauser and P. Bühlmann. Characterization and greedy learning of interventional Markov equivalence classes of directed acyclic graphs. Journal of Machine Learning Research, 13(1):2409-2464, 2012.
A. Hauser and P. Bühlmann. Two optimal strategies for active learning of causal models from interventional data. International Journal of Approximate Reasoning, 55:926-939, 2014.
A. Hauser and P. Bühlmann. Jointly interventional and observational data: estimation of interventional Markov equivalence classes of directed acyclic graphs. Journal of the Royal Statistical Society Series B, 77(1):291-318, 2015.
D. Heckerman, C. Meek, and G. Cooper. A Bayesian approach to causal discovery. Technical report, Microsoft Research, 1997.
J. Kuipers and G. Moffa. Partition MCMC for inference on acyclic digraphs. Journal of the American Statistical Association, 112:282-299, 2017.
J. Kuipers, G. Moffa, and D. Heckerman. Addendum on the scoring of Gaussian directed acyclic graphical models. The Annals of Statistics, 42:1689-1691, 2014.
S. Lauritzen. Graphical Models. Oxford University Press, 1996.
D. Madigan and J. York. Bayesian graphical models for discrete data. International Statistical Review, $63: 215-232,1995$.
K. Murphy. Active learning of causal Bayes net structure. Technical report, 2001.
R. O. Ness, K. Sachs, P. Mallick, and O. Vitek. A Bayesian active learning experimental design for inferring signaling networks. Journal of Computational Biology, 25(7):709-725, 2018.
T. Niinimaki, P. Parviainen, and M. Koivisto. Structure discovery in Bayesian networks by sampling partial orders. Journal of Machine Learning Research, 17:2002-2048, 2016.
J. Pearl. Causality: Models, reasoning, and inference. Econometric Theory, 19(675-685):46, 2003.
J. M. Robins, M. A. Hernan, and B. Brumback. Marginal structural models and causal inference in epidemiology, 2000.</p>
<p>T. Schaffter, D. Marbach, and D. Floreano. GeneNetWeaver: in silico benchmark generation and performance profiling of network inference methods. Bioinformatics, 27:2263-2270, 2011.
T. Soma and Y. Yoshida. Maximizing monotone submodular functions over the integer lattice. In International Conference on Integer Programming and Combinatorial Optimization, pages 325-336. Springer, 2016.
T. Soma, N. Kakimura, K. Inaba, and K. Kawarabayashi. Optimal budget allocation: Theoretical guarantee and efficient algorithm. In International Conference on International Conference on Machine Learning, 2014.
P. Spirtes, C. Glymour, and R. Scheines. Causation, Prediction, and Search. MIT press, 2nd edition, 2000 .
S. Tong and D. Koller. Active learning for structure in Bayesian networks. In International Joint Conference on Artificial Intelligence, 2001.
A. W. Van der Vaart. Asymptotic statistics, volume 3. Cambridge university press, 2000.
T. S. Verma and J. Pearl. Equivalence and synthesis of causal models. In Uncertainty in Artificial Intelligence, volume 6, page 255, 1991.
T. S. Verma and J. Pearl. An algorithm for deciding if a set of observed independencies has a causal explanation. In Uncertainty in Artificial Intelligence, 1992 .
Y. Wang, L. Solus, K. Yang, and C. Uhler. Permutation-based causal inference algorithms with interventions. In Advances in Neural Information Processing Systems, pages 5824-5833, 2017.
K. D. Yang, A. Katcoff, and C. Uhler. Characterizing and learning equivalence classes of causal DAGs under interventions. In International Conference on Machine Learning, 2018.</p>
<h2>A Proofs</h2>
<h3>A.1 Proof of Proposition 3.2</h3>
<p>Given infinite samples per intervention $I \in \mathcal{I}, G^{*}$ is recovered up to its $\mathcal{I}$-Markov equivalence class. Hence, the resulting entropy after placing an infinite number of samples at each intervention is equal to $\log <em G="G" _in="\in" _mathcal_G="\mathcal{G">{2}\left|\operatorname{Ess}^{\mathcal{I}}(G)\right|$ when the true DAG is $G$. Since the true DAG is unknown, this entropy must be averaged over our prior distribution on $\mathcal{G}$, which is uniform. Hence, the entropy after observing an infinite number of samples per intervention in $\mathcal{I}$ equals $\frac{1}{\left|\mathcal{G}\right|} \sum</em>(G)\right|$. Minimizing this entropy over all possible interventions sets of size at most $K$ completes the proof.}} \log _{2}\left|\operatorname{Ess}^{\mathcal{I}</p>
<h3>A.2 Proof of Theorem 3.4</h3>
<p>Let</p>
<p>$$
\mathcal{I}^{\infty}:=\left{I \in \mathcal{I}^{<em>}: \sum_{b=1}^{\infty}\left|\tilde{I} \in \xi_{b}: \tilde{I}=I\right|=\infty \mu^{</em>} a . s .\right}
$$</p>
<p>where $\xi_{b}$ denotes the interventions selected at batch $b$ by $U_{\mathrm{M} . \mathrm{I}}^{f}$. Since $\mathcal{I}^{<em>}$ is finite, $\mathcal{I}^{\infty}$ is non-empty. When $\left|\mathcal{I}^{\infty}\right|&gt;1, \mathcal{I}^{\infty}$ is a conservative family of targets since $\mathcal{I}^{</em>}$ is a family of single-node interventions. Hence, we identify the $\mathcal{I}^{\infty}$-MEC of $G^{<em>}$ in the limit of an infinite number of batches and samples (Hauser and Bühlmann, 2012). Assume $\left|\mathcal{I}^{\infty}\right|&gt;1$. If $f(G)$ is identifiable in $\operatorname{Ess}^{\mathcal{I}^{\infty}}\left(G^{</em>}\right)$, then</p>
<p>$$
\mathbb{P}\left(f(G) \mid D_{B}\right) \xrightarrow{\mu^{<em>} \text { a.s.}} \mathbb{1}\left(f(G)=f\left(G^{</em>}\right)\right)
$$</p>
<p>Hence, it suffices to show that the interventions $U_{\mathrm{M} . \mathrm{I}}^{f}$ selects infinitely often identifies $f(G)$ in the limiting interventional essential graph $\operatorname{Ess}^{\mathcal{I}^{\infty}}\left(G^{<em>}\right)$. Suppose towards a contradiction that $f(G)$ were not fully identifiable in $\operatorname{Ess}^{\mathcal{I}^{\infty}}\left(G^{</em>}\right)$. By definition of almost sure convergence, there exists some $b^{<em>}&lt;\infty$ such that any $\tilde{I} \in \mathcal{I}^{</em>} \backslash \mathcal{I}^{\infty}$ is never selected again after batch $b^{<em>}$ with probability one since $\mathcal{I}^{</em>}$ is finite. Maximizing $U_{\mathrm{M} . \mathrm{I} .}^{f}$ is equivalent to minimizing the conditional entropy,</p>
<p>$$
H_{\xi}^{b}\left(f \mid Y_{\xi}\right):=\mathbb{E}<em b="b">{y \sim \mathbb{P}\left(y \mid D</em>, Y=y\right)
$$}, \xi\right)} H\left(f \mid D_{b</p>
<p>If $b&gt;b^{*}$, then</p>
<p>$$
\underset{\xi \in \mathbb{Z}^{\mathcal{I}^{*}} \cap C_{b}}{\arg \min } H_{\xi}^{b}\left(f \mid Y_{\xi}\right)=\underset{\xi \in \mathbb{Z}^{\mathcal{I}^{\infty}} \cap C_{b}}{\arg \min } H_{\xi}^{b}\left(f \mid Y_{\xi}\right)
$$</p>
<p>since any batch $b$ after $b^{<em>}$ never selects an intervention in $\tilde{I} \in \mathcal{I}^{</em>} \backslash \mathcal{I}^{\infty}$. Since $f$ is not identifiable in $\operatorname{Ess}^{\mathcal{I}^{\infty}}\left(G^{*}\right)$, that implies</p>
<p>$$
\lim <em _xi__infty="\xi_{\infty">{b \rightarrow \infty} H</em>\right) \rightarrow L&gt;0
$$}}^{b}\left(f \mid Y_{\xi_{\infty}</p>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Figure 5: Each box represents the members of the interventional Markov equivalence classes. For $G^{*}$ given in the bottom left box, the observational Markov equivalence class has no edges oriented. The top box represents the essential graph of the observational Markov equivalence class. The interventional Markov equivalence class for an intervention at node one consists of two DAGs given in the bottom box.</p>
<p>Since $\mathcal{I}^{<em>}$ consists of all single-node interventions, $\mathcal{I}^{</em>}$ can identify $f(G)$ (Hauser and Bühlmann, 2012). Hence, there must be some $\tilde{I} \in \mathcal{I}^{*} \backslash \mathcal{I}^{\infty}$ and $\epsilon&gt;0$ such that</p>
<p>$$
\lim <em _xi__infty="\xi_{\infty">{b \rightarrow \infty} H</em>(f)&lt;L-\epsilon
$$} \cup \tilde{I}_{\infty}}^{b</p>
<p>where $\tilde{I}_{\infty}$ denotes selecting $\tilde{I}$ infinitely many times. But Eq. (18) implies that there must exist some batch $b&gt;b^{<em>}$ such that the conditional entropy of the design $\tilde{\xi}={\tilde{I}}$ is uniformly smaller than the conditional entropy of any $\xi \in \mathbb{Z}^{\mathcal{I}^{\infty}}$. But this is a contradiction because then $\tilde{I}$ would be selected again after some batch $b&gt;b^{</em>}$ and Eq. (17) would no longer hold.</p>
<p>For $\left|\mathcal{I}^{\infty}\right|=1$, we no longer have a conservative family of targets. However, a nearly identical argument works by noting that, in the limit, we learn the observational equivalence class of the $\mathcal{I}^{\infty}$ mutilated graph of $G^{*}$.</p>
<h2>A. 3 Consistency Counterexample</h2>
<p>Suppose we know the Markov equivalence class of $G^{<em>}$ and the goal is to fully recover $G^{</em>}$. Suppose $C_{b}=\left{\xi:|\xi|<em 0="0">{0}=K\right}$, where $|\cdot|</em>$ counts the number of unique interventions in $\xi$. Since there is no constraint on the number of samples, only on the number of unique interventions, we may allocate an infinite number of samples per intervention within each batch. This constraint is equivalent to the one examined in Ghassami et al. (2018). The scores in both Ness et al. (2018) and Ghassami et al. (2018) select interventions by maximizing the expected number of oriented edges in the interventional Markov equivalence classes. In particular, the utility function in Ness et al. (2018) is</p>
<p>equivalent to maximizing,</p>
<p>$$
U(\mathcal{I} ; D)=\sum_{G \in \mathcal{G}} A\left(\operatorname{Ess}^{\mathcal{I}}(G)\right) \mathbb{P}(G)
$$</p>
<p>where $A\left(\operatorname{Ess}^{\mathcal{I}}(G)\right)$ equals the additional number of edges oriented relative to the observational Markov equivalence class. Suppose $G^{<em>}$ equals the graph in Fig. 5 and that $K=1$ unique interventions are allowed within each batch. Assume that $\mathcal{I}^{</em>}={{1}, \cdots,{4}}$ and that we start with a uniform prior over $\mathcal{G}$. Then, since all arrows are undirected in the observational Markov equivalence class, symmetry implies $U({j} ; \emptyset)=U({j} ; \emptyset)$ for all $i, j \in 1, \cdots, 4$. Without any loss of generality suppose intervention one is selected in batch one. We show that every subsequent batch will select intervention ${1}$. If only ${1}$ were selected, $U(\mathcal{I} ; D)$ would not be consistent since the ${\emptyset,{1}}-\operatorname{MEC}\left(G^{*}\right)$ contains two graphs, as shown at the bottom of Fig. 5. After batch one, the posterior is supported on these two graphs since an infinite number of samples are allocated to the intervention at node one.</p>
<p>The utility function in Eq. (19) scores interventions relative to the observational equivalence class, which causes the consistency issue. In particular, the posterior in batch two is only supported on the two DAGs given in the bottom box of Fig. 5. The score of ${1}$ equals 5 in batch two while the scores of interventions ${2},{3},{4}$ equal $4,3,4$, respectively. Hence, in batch two, intervention ${1}$ will be selected again, but the posterior will remain the same since the ${\emptyset,{1}}$ interventional Markov equivalence class of $G^{*}$ is already known.</p>
<p>An easy way to fix Eq. (19) (for this given counterexample) would be to only select interventions not selected in previous batches. This modification would fix the issue with the counterexample, namely prevent intervention one from being selecting infinitely often. However, when one can only allocate a finite number of samples per batch, this modification would not lead to a consistent estimator. In particular, if a certain intervention is done in some batch, and that intervention must be conducted in order to identify $f$, then only placing finitely many samples to that intervention in that batch and never placing any more samples in subsequent batches will not lead to a consistent method.</p>
<h2>A. 4 Proof of Theorem 4.1</h2>
<p>Definition A.1. (Soma and Yoshida, 2016) Let $E$ be a finite set. A function $f: \mathbb{Z}^{E} \rightarrow \mathbb{R}$ is diminishing returns submodular (DR-submodular) if for $x \leq y$</p>
<p>$$
f\left(x+\chi_{e}\right)-f(x) \geq f\left(y+\chi_{e}\right)-f(y), x, y \in \mathbb{Z}^{E}
$$</p>
<p>where $e \in E$ and $\chi_{e}$ is the ith unit vector.
Lemma A.2. $\hat{U}<em _M.I.="{M.I." _text="\text">{\text {M.I. }}^{I}(\xi ; D)$ is DR-submodular.
Proof. $f(G)=G$ so we omit $f$ in $\hat{U}</em>$ to simplify notation. Since the sum of submodular functions is submodular, it suffices to show}}^{I</p>
<p>$$
\begin{aligned}
\mathbb{E}<em _mathrm_MLE="\mathrm{MLE">{y \mid G, \hat{\theta}</em>}}^{G}, \xi} \hat{U<em _xi="\xi">{\mathrm{M.I} .}(y, \xi ; D) &amp; =H(G)-H\left(G \mid Y</em>\right) \
&amp; =I\left(\left(G, \hat{\theta}<em _xi="\xi">{\mathrm{MLE}}^{G}\right), Y</em>\right)
\end{aligned}
$$</p>
<p>is DR-submodular, where $I$ is the mutual information. Consider an $A \subseteq B \in \mathbb{Z}^{\mathcal{I}^{<em>}}$. Take any $C \in \mathcal{I}^{</em>}$. Since entropy decreases with more conditioning,</p>
<p>$$
\begin{aligned}
H\left(Y_{C} \mid Y_{A}\right) &amp; -H\left(Y_{C} \mid\left(G, \hat{\theta}<em C="C">{\mathrm{MLE}}^{G}\right)\right) \geq \
H\left(Y</em>\right)\right)
\end{aligned}
$$} \mid Y_{B}\right) &amp; -H\left(Y_{C} \mid\left(G, \hat{\theta}_{\mathrm{MLE}}^{G</p>
<p>By conditional independence,</p>
<p>$$
\begin{aligned}
H\left(Y_{C} \mid\left(G, \hat{\theta}<em C="C">{\mathrm{MLE}}^{G}\right)\right) &amp; =H\left(Y</em>} \mid\left(G, \hat{\theta<em A="A">{\mathrm{MLE}}^{G}\right), Y</em>\right) \
&amp; =H\left(Y_{C} \mid\left(G, \hat{\theta}<em B="B">{\mathrm{MLE}}^{G}\right), Y</em>\right)
\end{aligned}
$$</p>
<p>Hence, Eq. (22) may be rewritten as,</p>
<p>$$
\begin{aligned}
I\left(\left(G, \hat{\theta}<em C="C">{\mathrm{MLE}}^{G}\right), Y</em>\right) &amp; = \
H\left(Y_{C} \mid Y_{A}\right)-H\left(Y_{C} \mid\left(G, \hat{\theta}} \mid Y_{A<em A="A">{\mathrm{MLE}}^{G}\right), Y</em>\right) &amp; \geq \
H\left(Y_{C} \mid Y_{B}\right)-H\left(Y_{C} \mid\left(G, \hat{\theta}<em B="B">{\mathrm{MLE}}^{G}\right), Y</em>\right) &amp; = \
I\left(\left(G, \hat{\theta}<em C="C">{\mathrm{MLE}}^{G}\right), Y</em>\right) &amp; .
\end{aligned}
$$} \mid Y_{B</p>
<p>Eq. (24) implies</p>
<p>$$
\begin{aligned}
&amp; I\left(\left(G, \hat{\theta}<em A="A">{\mathrm{MLE}}^{G}\right), Y</em>}+Y_{C}\right)-I\left(\left(G, \hat{\theta<em A="A">{\mathrm{MLE}}^{G}\right), Y</em>\right) \
&amp; \geq I\left(\left(G, \hat{\theta}<em B="B">{\mathrm{MLE}}^{G}\right), Y</em>}+Y_{C}\right)-I\left(\left(G, \hat{\theta<em B="B">{\mathrm{MLE}}^{G}\right), Y</em>\right)
\end{aligned}
$$</p>
<p>as desired.</p>
<p>The proof of Theorem 4.1 then follows directly from Lemma A. 2 and Soma et al. (2014, Theorem 2.4).</p>
<h2>A. 5 Proof of Proposition 4.2</h2>
<p>For each graph $G \in \mathcal{G}<em _mathrm_MLE="\mathrm{MLE">{T}$, compute the associated edge weights $\hat{\theta}</em>}}^{G}$. Computing each $\hat{\theta<em _M.I.="{M.I." _text="\text">{\mathrm{MLE}}^{G}$ takes $O\left(p \kappa^{3}\right)$ time using the formula given in Hauser and Bühlmann (2012, pg. 17). Since there are $T$ DAGs, the total time to compute the MLE estimates of the edge weights of each DAG is $O\left(T p \kappa^{3}\right)$. Sampling from a multivariate Gaussian with bounded indegree with known adjacency matrix takes $O(p \kappa)$ time. $\hat{U}</em>^{}}^{I}$ requires a total of $\left|\mathcal{I<em>}\right| M N_{b} T^{2}$ samples. Hence, the total computation time of sampling all the $y_{m t}$ in Eq. (14) is $O\left(\left|\mathcal{I}^{</em>}\right| M N_{b} \kappa p T^{2}\right)$. Evaluating $\hat{U}<em _M.I.="{M.I." _text="\text">{\text {M.I. }}^{I}$ takes $O\left(M T^{2}\right)$ time using these samples, which is of lower computational complexity than computing $\hat{U}</em>\right)$.}}^{I}$. Hence, the total runtime is $O\left(p \kappa^{3}+\left|\mathcal{I}^{*}\right| M N_{b} \kappa p T^{2</p>
<h1>A. 6 Constraint on the Number of Unique Interventions</h1>
<p>If we are only allowed to allocate at most $K$ unique interventions per batch, we modify Algorithm 3 by allocating $\frac{N_{2}}{K}$ samples per intervention in Algorithm 2. Once an intervention is selected, that intervention is removed from $I^{*}$ and another one is greedily selected from the remaining set. With this strategy, Algorithm 2 will terminate after $K$ iterations. Hence, there will be at most $K$ unique interventions as desired.</p>
<h2>A. 7 DREAM4 Supplementary Figures</h2>
<p>We applied our targeted experimental design strategy towards learning the downstream pathways of select genes from a 10-node network from the DREAM4 challenge. We observed a modest improvement over the random strategy for some central genes in the network (Fig. 6, top). However, the results are subject to high variations (Fig. 6, bottom), which we surmise to be due to the small size of the observational dataset. Nevertheless, these preliminary results illustrate the promise of applying targeted experimental design to real, large-scale biological datasets.</p>
<p><img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Figure 6: Performance of intervention strategies on predicting the descendants of genes 6 (top) and 8 (bottom).</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{1}$ From a sample of 10,000 graphs, only 54 had MEC size greater than 100. Based on the results by Gillispie and Perlman (2001), we expect the MECs to be typically small.&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>