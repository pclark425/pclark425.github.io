<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1310 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1310</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1310</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-29.html">extraction-schema-29</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <p><strong>Paper ID:</strong> paper-259274881</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2306.15864v2.pdf" target="_blank">What Went Wrong? Closing the Sim-to-Real Gap via Differentiable Causal Discovery</a></p>
                <p><strong>Paper Abstract:</strong> Training control policies in simulation is more appealing than on real robots directly, as it allows for exploring diverse states in an efficient manner. Yet, robot simulators inevitably exhibit disparities from the real-world \rebut{dynamics}, yielding inaccuracies that manifest as the dynamical simulation-to-reality (sim-to-real) gap. Existing literature has proposed to close this gap by actively modifying specific simulator parameters to align the simulated data with real-world observations. However, the set of tunable parameters is usually manually selected to reduce the search space in a case-by-case manner, which is hard to scale up for complex systems and requires extensive domain knowledge. To address the scalability issue and automate the parameter-tuning process, we introduce COMPASS, which aligns the simulator with the real world by discovering the causal relationship between the environment parameters and the sim-to-real gap. Concretely, our method learns a differentiable mapping from the environment parameters to the differences between simulated and real-world robot-object trajectories. This mapping is governed by a simultaneously learned causal graph to help prune the search space of parameters, provide better interpretability, and improve generalization on unseen parameters. We perform experiments to achieve both sim-to-sim and sim-to-real transfer, and show that our method has significant improvements in trajectory alignment and task success rate over strong baselines in several challenging manipulation tasks.</p>
                <p><strong>Cost:</strong> 0.018</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1310.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1310.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>robosuite</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>robosuite: A modular simulation framework and benchmark for robot learning</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A modular robotics simulation framework used as the experiment environment API in this paper; provides access to hundreds of tunable environment parameters and integrates with physics engines (used here with MuJoCo) to simulate robotic manipulation and object interactions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>robosuite: A modular simulation framework and benchmark for robot learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_name</strong></td>
                            <td>robosuite (with MuJoCo backend)</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_description</strong></td>
                            <td>Framework that provides environment definitions, sensors and an API to configure many environment parameters; in this work used to instantiate a mini air-hockey environment and other manipulation tasks with MuJoCo as the physics engine.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>mechanics / robotic manipulation / contact dynamics</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_level</strong></td>
                            <td>medium-fidelity (engineered physics approximation via MuJoCo; models rigid-body dynamics, contact and collision approximately)</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_characteristics</strong></td>
                            <td>Parameterizable friction (sliding/rolling/torsional), damping, mass/inertia, restitution-like behavior; discrete simulation timestep reported 0.05 s; contact and collision approximations (MuJoCo contact model), supports per-object/material properties; many higher-order/ stochastic real-world effects (e.g. non-uniform fan-induced floating forces) are not explicitly modeled.</td>
                        </tr>
                        <tr>
                            <td><strong>model_or_agent_name</strong></td>
                            <td>Soft Actor-Critic (SAC) policies; COMPASS difference-prediction causal model paired with an RL agent</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Reinforcement-learning agent trained with Soft Actor-Critic (SAC); COMPASS trains a differentiable causal difference-prediction model (encoder-decoder MLP with a learned causal graph) to map environment parameters to trajectory differences and then backpropagates to update simulator parameters.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task</strong></td>
                            <td>Scientific/physical reasoning in the sense of predicting and aligning dynamical trajectories of multi-body contact interactions — specifically mini air-hockey (pusher-puck interactions), double-bouncing-ball, and Push-I manipulation tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>training_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_target</strong></td>
                            <td>Real-world robot testbed (Kinova Gen3 with top-down camera) and alternative simulated 'target' environments (sim-to-sim experiments where ground-truth parameters are known).</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance</strong></td>
                            <td>Reported real-world improvements when using COMPASS-tuned simulator parameters: (Low fan speed) trajectory difference mean: nominal 0.35 ± 0.04, NPDR 0.18 ± 0.05, COMPASS 0.12 ± 0.03; Puck2 final distance to goal: nominal 3.68 ± 0.07, NPDR 2.81 ± 0.16, COMPASS 2.37 ± 0.10; Success rate: nominal 0.00 ± 0.00, NPDR 0.39 ± 0.33, COMPASS 0.80 ± 0.09. (High fan speed) trajectory difference mean: nominal 0.29 ± 0.09, NPDR 0.15 ± 0.07, COMPASS 0.13 ± 0.02; Success rate: nominal 0.20 ± 0.07, NPDR 0.47 ± 0.41, COMPASS 0.75 ± 0.22.</td>
                        </tr>
                        <tr>
                            <td><strong>compares_fidelity_levels</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>minimal_fidelity_discussion</strong></td>
                            <td>The paper notes contact/collision dynamics and certain surface/actuation properties (friction, damping, inertia, actuation delay/discount) must be modeled sufficiently well for useful transfer; it argues that many unmodeled or inaccurately-specified dynamics (e.g. non-uniform stochastic floating force from a fan) create sim-to-real gaps, but it does not prescribe a strict minimal fidelity specification.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>Reported failures and degraded real-world performance when simulator dynamics are biased: contact and collision approximations and omission of stochastic/non-uniform forces (fan) cause large sim-to-real gaps; vanilla domain randomization can produce overly conservative policies when ranges are broad; several baseline parameter-tuning methods struggled to converge (especially for damping) when many parameters have negligible effect on trajectories.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'What Went Wrong? Closing the Sim-to-Real Gap via Differentiable Causal Discovery', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1310.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e1310.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MuJoCo</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Mujoco: A physics engine for model-based control</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A widely-used physics engine for simulating articulated rigid-body dynamics, contacts, and collisions; used as the physics backend in the experiments reported in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Mujoco: A physics engine for model-based control</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_name</strong></td>
                            <td>MuJoCo physics engine</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_description</strong></td>
                            <td>A continuous-time rigid-body dynamics simulator with analytic contact models; supports configurable damping, friction, inertia, and contact parameters; used here via robosuite to simulate manipulation tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>mechanics / rigid-body dynamics / contact mechanics</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_level</strong></td>
                            <td>medium-fidelity physics simulator: reasonably accurate rigid-body dynamics and simplified contact/collision modeling but not a fully high-fidelity representation of complex contact microphysics or stochastic environmental forces.</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_characteristics</strong></td>
                            <td>Models mass/inertia, damping, sliding/rolling/torsional friction and standard contact forces; negative sign-convention noted for damping in MuJoCo; simulation timestep used in experiments 0.05 s; simplifies many complex real-world effects and stochasticities.</td>
                        </tr>
                        <tr>
                            <td><strong>model_or_agent_name</strong></td>
                            <td>Soft Actor-Critic (SAC) policies; COMPASS causal difference-prediction model</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Reinforcement-learning agent (SAC) and a differentiable MLP-based causal model (encoder-decoder with learned Gumbel-Softmax causal adjacency) mapping environment parameters + action sequences to trajectory differences.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task</strong></td>
                            <td>Predict and minimize sim-to-real trajectory differences for dynamic manipulation tasks (mini air-hockey, double-bouncing-ball, Push-I).</td>
                        </tr>
                        <tr>
                            <td><strong>training_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_target</strong></td>
                            <td>Real-world robotic testbed and other simulated target environments (sim-to-sim experiments).</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance</strong></td>
                            <td>Same numeric transfer results reported for robosuite experiments (see robosuite entry): COMPASS yields substantially better trajectory alignment and success rates in real-world deployments compared to nominal and baseline-tuned simulators (see Table 1 values).</td>
                        </tr>
                        <tr>
                            <td><strong>compares_fidelity_levels</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>minimal_fidelity_discussion</strong></td>
                            <td>Paper emphasizes that accurate modeling of contact, friction, damping and actuation properties is important for transfer but does not provide a strict minimal-fidelity checklist; notes some real-world stochastic forces may be impractical to model precisely.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>MuJoCo's simplified contact/damping models contributed to sim-to-real gaps in experiments; damping in particular was challenging for baselines to identify/optimize, and unmodeled stochastic floating forces (fan) in the real table led to mismatches.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'What Went Wrong? Closing the Sim-to-Real Gap via Differentiable Causal Discovery', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1310.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e1310.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Custom mini air-hockey simulator</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>custom robosuite-based mini air-hockey simulator (this paper)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A task-specific simulator developed by the authors (using robosuite + MuJoCo) to mimic a physical mini air-hockey table for experiments; used to collect simulated rollouts, perform parameter tuning with COMPASS, and train RL agents.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_name</strong></td>
                            <td>custom mini air-hockey simulator (robosuite + MuJoCo)</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_description</strong></td>
                            <td>Custom instantiation of the robosuite environment configured to match the real air-hockey table geometry and object sizes; exposes ~64 tunable environment parameters for system identification and domain randomization experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>mechanics / contact dynamics / fluid-coupled object interactions (approx.)</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_level</strong></td>
                            <td>medium-fidelity task simulator: geometry and many rigid-body/damping/friction parameters matched to the real setup, but certain environmental stochasticities and spatially-varying forces are only approximated or omitted.</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_characteristics</strong></td>
                            <td>Includes per-object friction types (sliding/rolling/torsional), damping, inertia and actuation parameters; camera bias parameters are included for observation noise; simulation timestep 0.05 s; does not model non-uniform fan-induced air flow stochastically as in the real system.</td>
                        </tr>
                        <tr>
                            <td><strong>model_or_agent_name</strong></td>
                            <td>Soft Actor-Critic (SAC) policy; COMPASS causal model used to tune simulator parameters</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>SAC RL agent for action selection; COMPASS learns a differentiable mapping (encoder-decoder MLP with sparse causal graph via Gumbel-Softmax) from simulator parameters to trajectory differences and backpropagates to update environment parameters.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task</strong></td>
                            <td>Learn control for a dynamic manipulation task (pusher-to-puck and puck-to-puck interactions) and align simulated trajectories to real trajectories to reduce sim-to-real gap.</td>
                        </tr>
                        <tr>
                            <td><strong>training_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_target</strong></td>
                            <td>Real Kinova Gen3 testbed (real-world deployment); also used in sim-to-sim experiments where a distinct simulated environment is treated as the target.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance</strong></td>
                            <td>Real-world results (see Table 1): COMPASS-tuned simulator led to success rates increasing from 0.00 to 0.80 (low fan) and from 0.20 to 0.75 (high fan) over nominal; trajectory difference and final puck distance metrics improved similarly (see robosuite entry for numbers).</td>
                        </tr>
                        <tr>
                            <td><strong>compares_fidelity_levels</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>minimal_fidelity_discussion</strong></td>
                            <td>Authors emphasize that modeling of collisions, friction and damping are important; also note that some real effects (non-uniform fan flow) were not modeled and represent sources of residual gap.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>When key dynamics (e.g. damping or non-uniform airflow) are mis-specified or omitted, the trained policy's real-world success can drop drastically; baselines had particular difficulty optimizing damping parameters, illustrating sensitivity to certain fidelity aspects.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'What Went Wrong? Closing the Sim-to-Real Gap via Differentiable Causal Discovery', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1310.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e1310.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AirSim</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Airsim: High-fidelity visual and physical simulation for autonomous vehicles</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A high-fidelity simulation platform for autonomous vehicle research (visual + physical); cited in related work as an example of high-fidelity simulators but not used in this paper's experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Airsim: High-fidelity visual and physical simulation for autonomous vehicles</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_name</strong></td>
                            <td>AirSim</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_description</strong></td>
                            <td>A simulator providing high-fidelity visual rendering and vehicle dynamics for autonomous vehicle research (cited in related work).</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>autonomous vehicles / visual-physical simulation</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_level</strong></td>
                            <td>high-fidelity (visual + physics)</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_characteristics</strong></td>
                            <td>High-quality visual rendering and physically-plausible vehicle dynamics; intended for perception and control research; not used or analysed experimentally in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>model_or_agent_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_target</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>compares_fidelity_levels</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>minimal_fidelity_discussion</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'What Went Wrong? Closing the Sim-to-Real Gap via Differentiable Causal Discovery', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1310.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e1310.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Neuralsim</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Neuralsim: Augmenting differentiable simulators with neural networks</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A referenced work that augments differentiable simulators with learned components; mentioned in related work but not used in experiments here.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Neuralsim: Augmenting differentiable simulators with neural networks</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_name</strong></td>
                            <td>Neuralsim (concept/paper)</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_description</strong></td>
                            <td>Approach to combine analytic differentiable simulators with neural-network components to increase expressivity and fidelity.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>simulation/integrated modelling (robotics/physics)</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_level</strong></td>
                            <td>aims to improve fidelity by hybrid analytic+learned models (paper-level concept)</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_characteristics</strong></td>
                            <td>Augments differentiable simulator components with neural networks to model hard-to-capture dynamics; cited as related work about differentiable simulation.</td>
                        </tr>
                        <tr>
                            <td><strong>model_or_agent_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_target</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>compares_fidelity_levels</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>minimal_fidelity_discussion</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'What Went Wrong? Closing the Sim-to-Real Gap via Differentiable Causal Discovery', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Mujoco: A physics engine for model-based control <em>(Rating: 2)</em></li>
                <li>robosuite: A modular simulation framework and benchmark for robot learning <em>(Rating: 2)</em></li>
                <li>Closing the sim-to-real loop: Adapting simulation randomization with real world experience <em>(Rating: 2)</em></li>
                <li>Neural Posterior Domain Randomization <em>(Rating: 2)</em></li>
                <li>Neuralsim: Augmenting differentiable simulators with neural networks <em>(Rating: 1)</em></li>
                <li>Tunenet: One-shot residual tuning for system identification and sim-to-real robot task transfer <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1310",
    "paper_id": "paper-259274881",
    "extraction_schema_id": "extraction-schema-29",
    "extracted_data": [
        {
            "name_short": "robosuite",
            "name_full": "robosuite: A modular simulation framework and benchmark for robot learning",
            "brief_description": "A modular robotics simulation framework used as the experiment environment API in this paper; provides access to hundreds of tunable environment parameters and integrates with physics engines (used here with MuJoCo) to simulate robotic manipulation and object interactions.",
            "citation_title": "robosuite: A modular simulation framework and benchmark for robot learning",
            "mention_or_use": "use",
            "simulator_name": "robosuite (with MuJoCo backend)",
            "simulator_description": "Framework that provides environment definitions, sensors and an API to configure many environment parameters; in this work used to instantiate a mini air-hockey environment and other manipulation tasks with MuJoCo as the physics engine.",
            "scientific_domain": "mechanics / robotic manipulation / contact dynamics",
            "fidelity_level": "medium-fidelity (engineered physics approximation via MuJoCo; models rigid-body dynamics, contact and collision approximately)",
            "fidelity_characteristics": "Parameterizable friction (sliding/rolling/torsional), damping, mass/inertia, restitution-like behavior; discrete simulation timestep reported 0.05 s; contact and collision approximations (MuJoCo contact model), supports per-object/material properties; many higher-order/ stochastic real-world effects (e.g. non-uniform fan-induced floating forces) are not explicitly modeled.",
            "model_or_agent_name": "Soft Actor-Critic (SAC) policies; COMPASS difference-prediction causal model paired with an RL agent",
            "model_description": "Reinforcement-learning agent trained with Soft Actor-Critic (SAC); COMPASS trains a differentiable causal difference-prediction model (encoder-decoder MLP with a learned causal graph) to map environment parameters to trajectory differences and then backpropagates to update simulator parameters.",
            "reasoning_task": "Scientific/physical reasoning in the sense of predicting and aligning dynamical trajectories of multi-body contact interactions — specifically mini air-hockey (pusher-puck interactions), double-bouncing-ball, and Push-I manipulation tasks.",
            "training_performance": null,
            "transfer_target": "Real-world robot testbed (Kinova Gen3 with top-down camera) and alternative simulated 'target' environments (sim-to-sim experiments where ground-truth parameters are known).",
            "transfer_performance": "Reported real-world improvements when using COMPASS-tuned simulator parameters: (Low fan speed) trajectory difference mean: nominal 0.35 ± 0.04, NPDR 0.18 ± 0.05, COMPASS 0.12 ± 0.03; Puck2 final distance to goal: nominal 3.68 ± 0.07, NPDR 2.81 ± 0.16, COMPASS 2.37 ± 0.10; Success rate: nominal 0.00 ± 0.00, NPDR 0.39 ± 0.33, COMPASS 0.80 ± 0.09. (High fan speed) trajectory difference mean: nominal 0.29 ± 0.09, NPDR 0.15 ± 0.07, COMPASS 0.13 ± 0.02; Success rate: nominal 0.20 ± 0.07, NPDR 0.47 ± 0.41, COMPASS 0.75 ± 0.22.",
            "compares_fidelity_levels": false,
            "fidelity_comparison_results": "",
            "minimal_fidelity_discussion": "The paper notes contact/collision dynamics and certain surface/actuation properties (friction, damping, inertia, actuation delay/discount) must be modeled sufficiently well for useful transfer; it argues that many unmodeled or inaccurately-specified dynamics (e.g. non-uniform stochastic floating force from a fan) create sim-to-real gaps, but it does not prescribe a strict minimal fidelity specification.",
            "failure_cases": "Reported failures and degraded real-world performance when simulator dynamics are biased: contact and collision approximations and omission of stochastic/non-uniform forces (fan) cause large sim-to-real gaps; vanilla domain randomization can produce overly conservative policies when ranges are broad; several baseline parameter-tuning methods struggled to converge (especially for damping) when many parameters have negligible effect on trajectories.",
            "uuid": "e1310.0",
            "source_info": {
                "paper_title": "What Went Wrong? Closing the Sim-to-Real Gap via Differentiable Causal Discovery",
                "publication_date_yy_mm": "2023-06"
            }
        },
        {
            "name_short": "MuJoCo",
            "name_full": "Mujoco: A physics engine for model-based control",
            "brief_description": "A widely-used physics engine for simulating articulated rigid-body dynamics, contacts, and collisions; used as the physics backend in the experiments reported in this paper.",
            "citation_title": "Mujoco: A physics engine for model-based control",
            "mention_or_use": "use",
            "simulator_name": "MuJoCo physics engine",
            "simulator_description": "A continuous-time rigid-body dynamics simulator with analytic contact models; supports configurable damping, friction, inertia, and contact parameters; used here via robosuite to simulate manipulation tasks.",
            "scientific_domain": "mechanics / rigid-body dynamics / contact mechanics",
            "fidelity_level": "medium-fidelity physics simulator: reasonably accurate rigid-body dynamics and simplified contact/collision modeling but not a fully high-fidelity representation of complex contact microphysics or stochastic environmental forces.",
            "fidelity_characteristics": "Models mass/inertia, damping, sliding/rolling/torsional friction and standard contact forces; negative sign-convention noted for damping in MuJoCo; simulation timestep used in experiments 0.05 s; simplifies many complex real-world effects and stochasticities.",
            "model_or_agent_name": "Soft Actor-Critic (SAC) policies; COMPASS causal difference-prediction model",
            "model_description": "Reinforcement-learning agent (SAC) and a differentiable MLP-based causal model (encoder-decoder with learned Gumbel-Softmax causal adjacency) mapping environment parameters + action sequences to trajectory differences.",
            "reasoning_task": "Predict and minimize sim-to-real trajectory differences for dynamic manipulation tasks (mini air-hockey, double-bouncing-ball, Push-I).",
            "training_performance": null,
            "transfer_target": "Real-world robotic testbed and other simulated target environments (sim-to-sim experiments).",
            "transfer_performance": "Same numeric transfer results reported for robosuite experiments (see robosuite entry): COMPASS yields substantially better trajectory alignment and success rates in real-world deployments compared to nominal and baseline-tuned simulators (see Table 1 values).",
            "compares_fidelity_levels": false,
            "fidelity_comparison_results": "",
            "minimal_fidelity_discussion": "Paper emphasizes that accurate modeling of contact, friction, damping and actuation properties is important for transfer but does not provide a strict minimal-fidelity checklist; notes some real-world stochastic forces may be impractical to model precisely.",
            "failure_cases": "MuJoCo's simplified contact/damping models contributed to sim-to-real gaps in experiments; damping in particular was challenging for baselines to identify/optimize, and unmodeled stochastic floating forces (fan) in the real table led to mismatches.",
            "uuid": "e1310.1",
            "source_info": {
                "paper_title": "What Went Wrong? Closing the Sim-to-Real Gap via Differentiable Causal Discovery",
                "publication_date_yy_mm": "2023-06"
            }
        },
        {
            "name_short": "Custom mini air-hockey simulator",
            "name_full": "custom robosuite-based mini air-hockey simulator (this paper)",
            "brief_description": "A task-specific simulator developed by the authors (using robosuite + MuJoCo) to mimic a physical mini air-hockey table for experiments; used to collect simulated rollouts, perform parameter tuning with COMPASS, and train RL agents.",
            "citation_title": "here",
            "mention_or_use": "use",
            "simulator_name": "custom mini air-hockey simulator (robosuite + MuJoCo)",
            "simulator_description": "Custom instantiation of the robosuite environment configured to match the real air-hockey table geometry and object sizes; exposes ~64 tunable environment parameters for system identification and domain randomization experiments.",
            "scientific_domain": "mechanics / contact dynamics / fluid-coupled object interactions (approx.)",
            "fidelity_level": "medium-fidelity task simulator: geometry and many rigid-body/damping/friction parameters matched to the real setup, but certain environmental stochasticities and spatially-varying forces are only approximated or omitted.",
            "fidelity_characteristics": "Includes per-object friction types (sliding/rolling/torsional), damping, inertia and actuation parameters; camera bias parameters are included for observation noise; simulation timestep 0.05 s; does not model non-uniform fan-induced air flow stochastically as in the real system.",
            "model_or_agent_name": "Soft Actor-Critic (SAC) policy; COMPASS causal model used to tune simulator parameters",
            "model_description": "SAC RL agent for action selection; COMPASS learns a differentiable mapping (encoder-decoder MLP with sparse causal graph via Gumbel-Softmax) from simulator parameters to trajectory differences and backpropagates to update environment parameters.",
            "reasoning_task": "Learn control for a dynamic manipulation task (pusher-to-puck and puck-to-puck interactions) and align simulated trajectories to real trajectories to reduce sim-to-real gap.",
            "training_performance": null,
            "transfer_target": "Real Kinova Gen3 testbed (real-world deployment); also used in sim-to-sim experiments where a distinct simulated environment is treated as the target.",
            "transfer_performance": "Real-world results (see Table 1): COMPASS-tuned simulator led to success rates increasing from 0.00 to 0.80 (low fan) and from 0.20 to 0.75 (high fan) over nominal; trajectory difference and final puck distance metrics improved similarly (see robosuite entry for numbers).",
            "compares_fidelity_levels": false,
            "fidelity_comparison_results": "",
            "minimal_fidelity_discussion": "Authors emphasize that modeling of collisions, friction and damping are important; also note that some real effects (non-uniform fan flow) were not modeled and represent sources of residual gap.",
            "failure_cases": "When key dynamics (e.g. damping or non-uniform airflow) are mis-specified or omitted, the trained policy's real-world success can drop drastically; baselines had particular difficulty optimizing damping parameters, illustrating sensitivity to certain fidelity aspects.",
            "uuid": "e1310.2",
            "source_info": {
                "paper_title": "What Went Wrong? Closing the Sim-to-Real Gap via Differentiable Causal Discovery",
                "publication_date_yy_mm": "2023-06"
            }
        },
        {
            "name_short": "AirSim",
            "name_full": "Airsim: High-fidelity visual and physical simulation for autonomous vehicles",
            "brief_description": "A high-fidelity simulation platform for autonomous vehicle research (visual + physical); cited in related work as an example of high-fidelity simulators but not used in this paper's experiments.",
            "citation_title": "Airsim: High-fidelity visual and physical simulation for autonomous vehicles",
            "mention_or_use": "mention",
            "simulator_name": "AirSim",
            "simulator_description": "A simulator providing high-fidelity visual rendering and vehicle dynamics for autonomous vehicle research (cited in related work).",
            "scientific_domain": "autonomous vehicles / visual-physical simulation",
            "fidelity_level": "high-fidelity (visual + physics)",
            "fidelity_characteristics": "High-quality visual rendering and physically-plausible vehicle dynamics; intended for perception and control research; not used or analysed experimentally in this paper.",
            "model_or_agent_name": null,
            "model_description": null,
            "reasoning_task": null,
            "training_performance": null,
            "transfer_target": null,
            "transfer_performance": null,
            "compares_fidelity_levels": null,
            "fidelity_comparison_results": "",
            "minimal_fidelity_discussion": "",
            "failure_cases": "",
            "uuid": "e1310.3",
            "source_info": {
                "paper_title": "What Went Wrong? Closing the Sim-to-Real Gap via Differentiable Causal Discovery",
                "publication_date_yy_mm": "2023-06"
            }
        },
        {
            "name_short": "Neuralsim",
            "name_full": "Neuralsim: Augmenting differentiable simulators with neural networks",
            "brief_description": "A referenced work that augments differentiable simulators with learned components; mentioned in related work but not used in experiments here.",
            "citation_title": "Neuralsim: Augmenting differentiable simulators with neural networks",
            "mention_or_use": "mention",
            "simulator_name": "Neuralsim (concept/paper)",
            "simulator_description": "Approach to combine analytic differentiable simulators with neural-network components to increase expressivity and fidelity.",
            "scientific_domain": "simulation/integrated modelling (robotics/physics)",
            "fidelity_level": "aims to improve fidelity by hybrid analytic+learned models (paper-level concept)",
            "fidelity_characteristics": "Augments differentiable simulator components with neural networks to model hard-to-capture dynamics; cited as related work about differentiable simulation.",
            "model_or_agent_name": null,
            "model_description": null,
            "reasoning_task": null,
            "training_performance": null,
            "transfer_target": null,
            "transfer_performance": null,
            "compares_fidelity_levels": null,
            "fidelity_comparison_results": "",
            "minimal_fidelity_discussion": "",
            "failure_cases": "",
            "uuid": "e1310.4",
            "source_info": {
                "paper_title": "What Went Wrong? Closing the Sim-to-Real Gap via Differentiable Causal Discovery",
                "publication_date_yy_mm": "2023-06"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Mujoco: A physics engine for model-based control",
            "rating": 2,
            "sanitized_title": "mujoco_a_physics_engine_for_modelbased_control"
        },
        {
            "paper_title": "robosuite: A modular simulation framework and benchmark for robot learning",
            "rating": 2,
            "sanitized_title": "robosuite_a_modular_simulation_framework_and_benchmark_for_robot_learning"
        },
        {
            "paper_title": "Closing the sim-to-real loop: Adapting simulation randomization with real world experience",
            "rating": 2,
            "sanitized_title": "closing_the_simtoreal_loop_adapting_simulation_randomization_with_real_world_experience"
        },
        {
            "paper_title": "Neural Posterior Domain Randomization",
            "rating": 2,
            "sanitized_title": "neural_posterior_domain_randomization"
        },
        {
            "paper_title": "Neuralsim: Augmenting differentiable simulators with neural networks",
            "rating": 1,
            "sanitized_title": "neuralsim_augmenting_differentiable_simulators_with_neural_networks"
        },
        {
            "paper_title": "Tunenet: One-shot residual tuning for system identification and sim-to-real robot task transfer",
            "rating": 2,
            "sanitized_title": "tunenet_oneshot_residual_tuning_for_system_identification_and_simtoreal_robot_task_transfer"
        }
    ],
    "cost": 0.018026,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>What Went Wrong? Closing the Sim-to-Real Gap via Differentiable Causal Discovery
19 Oct 2023</p>
<p>Peide Huang peideh@andrew.cmu.edu 
Carnegie Mellon University</p>
<p>Xilun Zhang xilunz@andrew.cmu.edu 
Carnegie Mellon University</p>
<p>Equal contribution</p>
<p>Ziang Cao ziangc@andrew.cmu.edu 
Carnegie Mellon University</p>
<p>Equal contribution</p>
<p>Shiqi Liu shiqiliu@andrew.cmu.edu 
Carnegie Mellon University</p>
<p>Equal contribution</p>
<p>Mengdi Xu mengdixu@andrew.cmu.edu 
Carnegie Mellon University</p>
<p>Wenhao Ding wenhaod@andrew.cmu.edu 
Carnegie Mellon University</p>
<p>Jonathan Francis jon.francis@us.bosch.com 
Bosch Center for Artificial Intelligence</p>
<p>Bingqing Chen bingqing.chen@us.bosch.com 
Bosch Center for Artificial Intelligence</p>
<p>Ding Zhao dingzhao@andrew.cmu.edu 
Carnegie Mellon University</p>
<p>What Went Wrong? Closing the Sim-to-Real Gap via Differentiable Causal Discovery
19 Oct 2023B91B63F71838383DA69801D6673E2558arXiv:2306.15864v2[cs.RO]sim-to-real gapreinforcement learningcausal discovery
Training control policies in simulation is more appealing than on real robots directly, as it allows for exploring diverse states in an efficient manner.Yet, robot simulators inevitably exhibit disparities from the real-world dynamics, yielding inaccuracies that manifest as the dynamical simulation-to-reality (sim-toreal) gap.Existing literature has proposed to close this gap by actively modifying specific simulator parameters to align the simulated data with real-world observations.However, the set of tunable parameters is usually manually selected to reduce the search space in a case-by-case manner, which is hard to scale up for complex systems and requires extensive domain knowledge.To address the scalability issue and automate the parameter-tuning process, we introduce COMPASS, which aligns the simulator with the real world by discovering the causal relationship between the environment parameters and the sim-to-real gap.Concretely, our method learns a differentiable mapping from the environment parameters to the differences between simulated and real-world robot-object trajectories.This mapping is governed by a simultaneously learned causal graph to help prune the search space of parameters, provide better interpretability, and improve generalization on unseen parameters.We perform experiments to achieve both sim-tosim and sim-to-real transfer, and show that our method has significant improvements in trajectory alignment and task success rate over strong baselines in several challenging manipulation tasks.Demos are available on our project website: https://sites.google.com/view/sim2real-compass.</p>
<p>Introduction</p>
<p>Training control policies directly on real robots poses challenges due to the sample complexity of deep reinforcement learning (RL) algorithms.Therefore, training in simulation is often necessary to perform diverse exploration of the state-action space in an efficient manner [1,2,3,4,5,6,7].However, robot simulators are constructed based on simplified models and are thus approximations of the real world.For example, dynamics such as contact and collision are notoriously difficult to simulate with simplified physics [8,9].Even if the dynamics could be simulated accurately, not all physical parameters can be precisely measured in the real world and specified in simulation, e.g., friction coefficients, actuation delay, etc.As a result, a robot that is trained in a biased simulator could have catastrophic performance degradation in the real world [10,11,12,13].It is, therefore, critical to use simulators that closely mimic real-world dynamics to reduce this sim-to-real gap [14,15,16,17].</p>
<p>Existing literature has proposed to close the sim-to-real gap by adjusting the parameters of the simulator to align the simulated data with the observed real data.To facilitate this, robot simulators such 7th Conference on Robot Learning (CoRL 2023), Atlanta, USA.A h E n K q u B h p B D J F V f M 1 f u i q i q F 2 u + h U X S O W p Y J 4 3 j a 6 v e v A I F y m A f 1 M A h s M A p a I J L 0 A J t g E A K n s A z e N E e t F f t T X s v R k v a d K c K Z q B 9 / A J y x K H j &lt; / l a t e x i t &gt; d⌧ puck2 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " w 4 a t x o S 4 o R p d K j Z 9 W E s / b b v l w Y g = " &gt; A A A C D 3 i c b V C 7 T s M w F H X K q 5 R X o C N L 1 A q J q U o Q A s Y i F i Z U J P q Q m i h y H K e 1 6 j i R 7 S C i q J / A w M j E C l / A h l j A h E n K q u B h p B D J F V f M 1 f u i q i q F 2 u + h U X S O W p Y J 4 3 j a 6 v e v A I F y m A f 1 M A h s M A p a I J L 0 A J t g E A K n s A z e N E e t F f t T X s v R k v a d K c K Z q B 9 / A J y x K H j &lt; / l a t e x i t &gt; d⌧ puck1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " w 4 a t x o S 4 o R p d K j Z 9 W E s / b b v l w Y g = " &gt; A A A C D 3 i c b V C 7 T s M w F H X K q 5 R X o C N L 1 A q J q U o Q A s Y i F i Z U J P q Q m i h y H K e 1 6 j i R 7 S C i q J / A w M j E C l / A h l j A h E n K q u B h p B D J F V f M 1 f u i q i q F 2 u + h U X S O W p Y J 4 3 j a 6 v e v A I F y m A f 1 M A h s M A p a I J L 0 A J t g E A K n s A z e N E e t F f t T X s v R k v a d K c K Z q B 9 / A J y x K H j &lt; / l a t e x i t &gt;     as robosuite [18] provide APIs to modify over 400 different environment parameters.Unfortunately, the search space grows exponentially with the dimension of the environment parameters.To mitigate this issue, various existing methods attempt to modify the parameters more efficiently, using gradient-based or gradient-free sampling-based techniques [19,20].For example, in quasi-static manipulation tasks, such as sorting pegs or opening drawers, Chebotar et al. [19] chose to modify parameters related to the size, positions, and compliance; in dynamic manipulation tasks, Muratore et al. [20] chose to modify mass, friction, and restitution coefficients, etc.
w Y g = " &gt; A A A C D 3 i c b V C 7 T s M w F H X K q 5 R X o C N L 1 A q J q U o Q A s Y i F i Z U J P q Q m i h y H K e 1 6 j i R 7 S C i q J / A w M j E C l / Ai L k j E b m Q a Y y e E A 0 Y C g q B U k q t X b S + i v k h D 9 W W + a 0 u Y j F 2 9 b j b M C Y x F Y k 1 J v V l 7 v P 8 5 H 3 2 1 X P 3 b 9 i O U h J h J R K E Q f c u M p Z N B L g m i e F y x E 4 F j i E Z w g P u K M h h i 4 W S T 8 G P j Q C m + E U R c P S a N i f p 3 I 4 O h y P O p y R D K o Z j 3 c v E / r 5 / I 4 M z J C I s T i R k q D g U J N W R k 5 E 0 Y P u E Y S Z o q A h E n K q u B h p B D J F V f M 1 f u i q i q F 2 u + h U X S O W p Y J 4 3 j a 6 v e v A I F y m A f 1 M A h s M A p a I J L 0 A J t g E A K n s A z e N E e t F f t T X s v R k v a d K c K Z q B 9 / A J y x K H j &lt; / l a t e x i t &gt; d⌧ Sim-to-real traj. diff. &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " D M 9 j k X / g b Q K Q z Q j h o r D R f Z H d U O 8 = " &gt; A A A C R n i c d V B N S x x B E K 3 Z f K n 5 c K N H L 0 O W k J y W G U m i g o e F g I g k Q c F V Y W d Z e n p q 1 s a e 7 q G 7 J r g M 8 5 8 E / 4 S / Q P C k F 6 9 7 C 7 m m Z 1 f E T c x r m n 6 8 q u p 6 v D i X w l I Q X H m N J 0 + f P X 8 x N 7 / w 8 t X r N 4 v N t 0 s H V h e G Y 5 d r q c 1 R z C x K o b B L g i Q e 5 Q Z Z F k s 8 j E + + 1 v X D n 2 i s 0 G q f R j n 2 M z Z U I h W c k Z M G z Z 0 o w d T N T n 4 q t W F q i F W 5 v f / 9 W 1 W u b d W n W o g I T 2 m 2 I Y q 1 T O w o c 0 + Z D C J i R V U N m q 2 g v V H j s x + 2 g w n + J a 3 O h / F 4 c f P 8 d n f Q v I 0 S z Y s M F X H J r O 2 F Q U 7 9 k h k S X K L b W 1 j M G T 9 h Q + w 5 q l i G t l 9 O j F T + e 6 c k f q q N u 4 r 8 i f p w o m S Z r Q 2 6 z o z R s f 2 7 V o u P 1 X o F p e vE P w F f W 1 n E 4 X E 6 o F h D u f c y 7 1 z J i s 4 M z a K f j S C h c V H j 5 e W V 1 a f P H 2 2 t t 5 8 v n F q V K k J 7 R H F l T 7 P w F D O J O 1 Z Z j k 9 L z Q F k X F 6 l l 1 9 r P 2 z r 1 Q b p u R n O y 7 o Q M C l Z E N G w H o p b X 5 J B N g R A e 4 O K 3 y A E 7 e T Z I r n Z i z 8 5 R J a G M a V r C 7 E G z x r w A M l 9 0 r q Z h S c W C i r 1 0 m V O n E Q V x f H a b M V h b v t t x / 2 9 v F D E o f R B K 1 O e FI = " &gt; A A A C H 3 i c d V D L T h s x F P V Q o C n P U J b d W I 2 Q W E U z 4 V H Y o E h s E A s U p C Z B y o T I 4 7 k J F h 5 7 Z N 9 B h N F 8 A J / R L + i 2 X b N g V 3 X L n v 5 H n Q Q k n l e y f H T O v b r n n i i V w q L v 3 3 l T H 6 Z n Z j + W P s 3 N L y w u L Z d X P r e s z g y H J t d S m 5 O I W Z B C Q R M F S j h J D b A k k t C O z v d H e v s C j B V a f c d h C t 2 E D Z T o C 8 7 Q U b 1 y J Y y 0 j O 0 w c V 8 e Q m q F 1 K o 4 T X p 5 i H C J e W y K w n X 5 1 c 3 a x u 7 W N n 0 N g q o / r k o 9 O L w v b q 7 2 G r 3 y v z D W P E t A I Z f M 2 k 7 g p 9 j N m U H B J R R z Y W Y h Z f y c D a D j o G I J 2 G 4 + P q a g a 4 6 J a V 8 b 9 x T S M f t 0 I m e J H f l 1 n Q n D M / t S G 5 F v a Z 0 M + z v d X K g 0 Q 1 B 8 s q i f S Y q a j p K h s T D A U Q 4 d Y N w I 5 5 X y M 2 Y Y R 5 f f s y 2 X E 6 s u l 8 f j 6 f u g V a s G
However, this parameter selection process is typically carried out on a case-by-case basis, necessitating substantial domain knowledge to restrict the scope of environment parameters.This becomes challenging when dealing with simulations involving multiple interacting objects [21].Furthermore, most existing methods lack the capability to offer explicit insights that can effectively guide the future deployment of more complex systems.They fail to offer direct answers to the question "What went wrong with my simulator" or, more specifically, "What simulator parameters should I tune to reduce the sim-to-real gap" without post hoc analysis of the final parameters.In contrast, humans are good at analyzing complex events, identifying and eliminating irrelevant factors, and uncovering crucial cause-and-effect relationships.Such causal discovery capability enables an efficient and interpretable search [22,23,24] for differences between two systems, providing a promising direction to bridge the gap between simulation and reality.</p>
<p>In this work, we propose a method that aims to align the simulator with the real world by discovering the causality between environment parameters and the sim-to-real gap (COMPASS) as illustrated in Figure 1.COMPASS learns a differentiable mapping, from the simulation environment parameters to the differences between simulated and real-world trajectories of dynamic robot-object interactions, governed by a simultaneously-learned causal graph.With the differentiable causal model fixed, COMPASS back-propagates gradients to optimize the simulation environment parameters in an endto-end manner to reduce the domain gaps.Beyond the interpretability, the causal graph also helps to prune the parameter search space, thus improving the efficiency of domain randomization as well as the scalability.We summarize our contributions as follows:</p>
<p>that vanilla DR may result in overly conservative policies when the range of randomization is broad [32,33].As an alternative approach for achieving sim-to-real transfer, system identification aims to estimate the parameters of the environment through limited interactions with real environments [20,34,21,35,36,37] and has been combined with DR methods.We draw inspiration from this line of work in developing our parameter estimation framework, which learns causal relationships from dynamic robot-object interactions in order to facilitate the sim-to-real transfer.</p>
<p>Gradient-free Parameter Estimation for Sim-to-Real Transfer.Gradient-free parameter estimation methods typically utilize sampling-based methods to update the simulation environment parameters.Chebotar et al. [19] propose the SimOpt framework, which iteratively alters the distribution of environment parameters in simulation to mirror real environment rollouts via the cross-entropy method.Moving away from the assumption that the distribution of environment parameters follows a Gaussian distribution, as adopted in [19], Ramos et al. [38] develop BayesSim, which uses a Gaussian mixture model and optimizes the parameter distribution from a Bayesian perspective.Muratore et al. [20] propose Neural Posterior Domain Randomization (NPDR) which further removes assumptions on the environment parameter distribution by utilizing neural likelihood-free inference methods and could handle correlated parameters.It is worth noting that scaling up sampling-based methods becomes challenging when dealing with a large number of parameters.In contrast, COMPASS learns a difference-prediction model, leverages gradients to adjust the simulation parameters, and further improves scalability with learned causal structures.</p>
<p>Gradient-based Parameter Estimation for Sim-to-Real Transfer.Gradient-based methods typically employ a neural network to encapsulate the gradient landscape of parameter differences [34,21,35] or to model environment dynamics [36].TuneNet [34] uses a neural network to predict the discrepancies in parameters based on the observations derived from two distinct environments.The Search Parameter Model (SPM) [35] is a binary classifier, with rollouts and parameters as input, which predicts whether a set of parameters is higher or lower than the target ones.Unlike TuneNet or SPM, we opt to predict observation differences using environment parameters as inputs.Allevato et al. [21] further expand the capabilities of TuneNet from handling a single parameter to managing a model with 5 parameters.In contrast, we demonstrate COMPASS is able to scale up to a 64-parameter system, a capacity notably larger than existing works.EXI-Net [36] implements a dynamics predictive model, conditioned on environment parameters, and identifies the most suitable parameters via back-propagation.While EXI-Net strives to model a broad spectrum of environments by separately modeling the known/explicit and implicit dynamics parameters, we aim to enhance sim-to-real transfer efficiency by capitalizing on the progressively discovered causal structure.</p>
<p>Methodology</p>
<p>Problem formulation: Markov Decision Processes and sim-to-real gap</p>
<p>A finite-horizon Markov Decision Process (MDP) is defined by M = (S, A, P, R, p 0 , γ, T ), where S and A are state and action spaces, P : S ×A×S → R + is a state-transition probability function or probabilistic system dynamics, R : S × A → R is a reward function, p 0 : S → R + is an initial state distribution, γ is a reward discount factor, and T is a fixed horizon.Let τ = (s 0 , a 0 , . . ., s T , a T ) be a trajectory of states and actions and R(τ ) = T t=0 γ t R (s t , a t ) is the trajectory reward.The objective of RL is to find parameters θ of a policy π θ (a|s) that maximize the expected discounted reward over trajectories induced by the policy: E π θ [R(τ )], where s 0 ∼ p 0 , s t+1 ∼ P (s t+1 |s t , a t ), and a t ∼ π θ (a t |s t ).</p>
<p>In our work, we assume that the simulator's system dynamics are conditioned on environment parameters ϵ ∈ R |E| , i.e., P : S × A × S × R |E| → R + , where E is the set of all tunable environment parameters and | • | measures the cardinality of the set.Given a simulator parameterized by ϵ, the agent is optimizing E π θ ,ϵ [R(τ )].When the simulation dynamics are very close to the real-world dynamics, one can expect the trajectory rollouts in the simulator to be close to that in the real world as well.Hence, an optimal agent trained in the simulator would expect near-optimal performance in the real world [39].However, due to unmodeled dynamics and inaccurate environment parameters, the simulation dynamics are different from the real world (i.e., there exists a sim-to-real gap), resulting in different trajectory rollouts and thus degradation in real-world performance [1,2,10,11,15].</p>
<p>For better interpretability, we assume a factorized state space, i.e., S = {S 1 × • • • × S K }, with s k,t ∈ S k representing the k-th factorized state at time t.Each component usually has explicit semantic meanings (i.e., an event or object's property) [23], which holds through state and action abstraction in general [40,41,42].For example, in the case of pick-and-place, the state space can be factorized to the 3D position and orientation of the object and end effector.Similar to Chebotar et al. [19], we then define a factorized trajectory difference function:
d k (τ sim , τ real ) := T t=0 ∥s k,t,sim − s k,t,real ∥ 2 , for k = 1, 2, . . . , K(1)
The trajectory difference function is then d := [d 1 , . . ., d K ], and the trajectory difference d τ is the output of d to measure the sim-to-real gap between of a pair of trajectories, (τ sim , τ real ).In this work, we aim to find a simulation environment parameter ϵ that minimizes the expectation of trajectory differences d τ under the same policy.</p>
<p>Learning causality between environment parameters and trajectory differences</p>
<p>To model the causality, COMPASS learns a causal model f ϕ (ϵ, a; G) mapping the environment parameter ϵ and action sequence a = [a 0 , . . ., a T ] to the trajectory difference d τ .This model contains a causal graph G, whose nodes represent the variables to be considered and the edges represent the causal influence from one node to another node.We jointly learn the model parameter ϕ and discover the underlying causal graph G in a fully differentiable manner.</p>
<p>Causal Graph.The causal graph G plays a crucial role in the model by providing interpretability, pruning the search space of parameters, and improving the generalization on unseen parameters.Since we focus on the influence of environment parameter ϵ to the trajectory difference d τ , we can represent the graph with a binary adjacency matrix of size |E| × K, where 1/0 indicates the existence/absence of an edge from the environment parameter to the trajectory difference.Motivated by previous works [43,44,45] that formulate the combinatorial graph learning into a continuous optimization problem, we design a sample-efficient pipeline by making the optimization of G differentiable.We sample elements of the graph G from a Gumbel-Softmax distribution [46], parametrized by ψ
∈ [0, 1] |E|×K , i.e., G ij ∼ GumbelSoftmax(ψ ij ; T = 1)
, where T is the softmax temperature.We denote the parameterized causal graph as G ψ .All elements (i, j) are initialized to ones to ensure the causal graph is fully connected at the beginning.</p>
<p>Structural Causal Model.Since the causal graph only describes the connection between variables, we also need a parameterized model to precisely represent how the causes influence the effects.</p>
<p>We design an encoder-decoder structure in f , with G as a linear transformation applied to the intermediate features.First, the encoder operates on each dimension of ϵ independently to generate features z ϵ ∈ R |E|×dz .Then the causal graph is multiplied by the features to generate the inputs for the decoder, i.e., g ϵ = z T ϵ G ∈ R dz×K , where d z is the dimension of the feature.Similarly, the action sequence a is passed through the encoder and transformation to produce the feature of the action sequence g a ∈ R dz×K .Finally, g ϵ + g a is passed through the decoder to output the prediction dτ .Differentiable Causal Discovery.Given a dataset D := {ϵ m , a m , d m τ } m=1,...,M , the optimization objective to discover the underlying causal model consists of two terms:
L ϕ,ψ := 1 M M m=1 ∥f ϕ (ϵ m , a m ; G ψ ) − d m τ ∥ 2 2 + λ∥ψ∥ p p ,(2)
where the first term is the mean squared error between the predicted trajectory differences and the real differences, and the second is a regularization term that encourages the sparsity of G (∥ψ∥ p is the entry-wise p-norm of ψ) with a positive scalar λ to eliminate the influence of irrelevant environment parameters.The detailed architecture of this causal model can be found in Appendix A.</p>
<p>Algorithm 1 Causality between envirOnMent PArameterS and the Sim-to-real gap (COMPASS) Train π θ in Sim(ϵ i ) 10:</p>
<p>{τ n sim } n=1,...,N ← Rollout N trajectories using π θ in Sim(ϵ i )</p>
<p>11:</p>
<p>{τ n real } n=1,...,N ← Rollout N trajectories using π θ in the real environment 12:
Stop the iterations if AVERAGE(d(τ 1 sim , τ 1 real ), . . . , d(τ N sim , τ N real )) ≤ ζ 13: D ← ∅ 14:
for n ∈ {1, . . ., N } do ▷ This loop can run in parallel 15:
{ϵ m dr } m=1,...,M ← CAUSALITYGUIDEDDOMAINRANDOMIZATION(ϵ i , ψ) 16:
for m ∈ {1, . . ., M } do 17:
τ m sim ← Rollout π θ in Sim(ϵ m dr )
18:
d m τ ← d(τ m sim , τ n real ) 19: D ← D ∪ {ϵ m dr , τ n real , d m τ } 20:
Jointly optimize model parameter ϕ and causal graph parameter ψ of f ϕ (ϵ, a; G ψ ) ▷ Eq. 2 21:
ϵ i+1 ← UPDATEENVPARAM(ϵ i , f ϕ (ϵ i , a; G ψ )) ▷ Eq. 3 Algorithm 2 Causality-Guided Domain Randomization 1: function CAUSALITYGUIDEDDOMAINRANDOMIZATION(ϵ, ψ) 2: for r = 1, 2, . . . , |E| do 3: if max(ψ r ) &gt; Threshold then ▷ ψ r is the r-th row of ψ 4: {ϵ m r } m=1,...,M ← UNIFORM(ϵ r − δ r , ϵ r + δ r ) ▷ ϵ r is the r-th dimension of ϵ 5:
return {ϵ m } m=1,...,M</p>
<p>Closing the sim-to-real gap via differentiable causal discovery</p>
<p>The main algorithm is shown in Algorithm 1.We highlight two parts of the algorithm here.</p>
<p>Causality-guided Domain Randomization.The learned causal graph is used to prune the search space.Since each element of the causal graph parameter ψ indicates the probability of an edge from the environment parameter to the trajectory difference, we can use ψ to determine whether to randomize a particular environment parameter or not.For instance, if the learned ψ indicates that there is no causal relationship between the torsional friction and the trajectory difference, the torsional friction will be excluded from randomization in the subsequent iteration, which enhances the efficiency of DR.The randomized environment parameters are sampled uniformly from certain ranges according to the current environment parameters.In this way, COMPASS automatically reduces the search space by orders of magnitude without human supervision or domain knowledge.The detail of causality-guided domain randomization is shown in Algorithm 2.</p>
<p>Environment Parameter Optimization.Owing to the full differentiability of our model, we can back-propagate the gradient information directly to the environment parameters to minimize the predicted sim-to-real gap:
J = 1 K K k=1 f ϕ,k (ϵ, a; G ψ ), ϵ ← ϵ − η∇ ϵ J(3)
where f ϕ,k is the k-th dimension of the output.We use the real action sequences and apply Eq. 3 multiple times until convergence or reaching the maximum step.The sparse causal graph G could improve the robustness against noisy trajectory data and generalization on unseen environment parameter values during parameter optimization.Mini-Air-Hockey with Obstacle.We design a challenging task of playing air hockey with a robot arm.To reach the goal, the agent needs to consider pusher-to-puck, puck-to-puck, puck-to-wall collisions, and surface properties of the hockey table.The task is to manipulate the pusher to hit the first puck, colliding with the second, which in turn needs to avoid the obstacle to reach the goal position by bouncing against the wall.Similar to Evans et al. [47], the action space includes the starting position of the pusher, hitting angle, and velocity.The state space includes the position of the two pucks (K = 2).The pusher, puck, and goal have a radius of 3cm, 2.55cm, and 15cm, respectively.This task requires precise actuation since objects interact multiple times, propagating and compounding simto-real mismatches such that the agent can experience a significant drop in success rate.Additionally, methods need to be robust against noisy and unmodeled dynamics.For instance, the floating force, in reality, is generated by a fan placed at the center of the table, and thus is non-uniform and stochastic.There are 64 tunable environment parameters in our experiments (|E| = 64), and we use parameter notations in the format of object@param type@param.We use the Kinova Gen 3 robot arm in the real-world test bench and simulate in the robosuite [18] environment with MuJoCo physics engine [8].Experimental details and two supplementary experiments, Double-Bouncing-Ball and Push-I, are available in Appendix B, E and F, respectively.</p>
<p>Baselines.As baselines, we select the state-of-the-art gradient-free sampling baselines NPDR [20], and two gradient-based baselines, TuneNet [34] and EXI-Net [36], as discussed in Section 2.</p>
<p>Sim-to-sim trajectory alignment with known target environment parameters</p>
<p>In this experiment, we verify whether COMPASS can align trajectories between two different environments.We conduct experiments in simulation so that the ground truth environment parameters are known to us.Among the two environments, one is treated as the "real" (target) environment we want to align with, the other is the simulation environment we will fine-tune.We collect rollouts with a scripted stochastic policy.For each method except Tune-Net, we use MaxIter = 10, N = 10, M = 64.For Tune-Net, we collect a dataset of size MaxIter × N × M = 6400 to train the regression model.More implement details and ablation study are presented in Appendix C and D.</p>
<p>The learned causal graph parameters ψ after 2 iterations (i = 0, 1, 2) are shown in Figure .3. We observe that the learned causal graph is very sparse, reducing the search space by orders of magnitude without extensive domain knowledge.Our method is able to automatically discover different types of relevant environment parameters such as actuation, sensing, and dynamics.It is worth noting that only the damping of the right wall out of 4 sides has causality discovered with the trajectory puck1 puck2 Iter 0 puck1 puck2 Iter 1 env@light@pos_x env@light@pos_z env@light@pos_y env@air@density env@air@viscosity env@camera@bias_x env@camera@bias_y env@light@ambient_b env@light@ambient_g env@light@ambient_r pusher@dyna@inertia_ixx pusher@dyna@damping pusher@actuation@vel_discount pusher@dyna@inertia_iyy pusher@dyna@inertia_izz puck1@dyna@friction_torsional puck1@dyna@inertia_ixx puck1@dyna@friction_rolling puck1@dyna@damping puck1@dyna@inertia_iyy puck1@dyna@inertia_izz puck1@dyna@friction_sliding puck2@dyna@friction_torsional puck2@dyna@inertia_ixx puck2@dyna@inertia_iyy puck2@dyna@inertia_izz puck2@dyna@friction_rolling puck2@dyna@damping puck2@dyna@friction_sliding front_wall@dyna@inertia_izz front_wall@dyna@friction_rolling front_wall@dyna@inertia_iyy front_wall@dyna@inertia_ixx front_wall@dyna@friction_torsional front_wall@dyna@friction_sliding front_wall@dyna@damping back_wall@dyna@friction_rolling back_wall@dyna@friction_sliding back_wall@dyna@friction_torsional back_wall@dyna@inertia_ixx back_wall@dyna@inertia_iyy back_wall@dyna@damping back_wall@dyna@inertia_izz right_wall@dyna@damping right_wall@dyna@inertia_ixx right_wall@dyna@friction_torsional right_wall@dyna@friction_sliding right_wall@dyna@friction_rolling right_wall@dyna@inertia_izz right_wall@dyna@inertia_iyy left_wall@dyna@inertia_izz left_wall@dyna@inertia_iyy left_wall@dyna@inertia_ixx left_wall@dyna@friction_torsional left_wall@dyna@friction_sliding left_wall@dyna@friction_rolling left_wall@dyna@damping obstacle@dyna@inertia_iyy obstacle@dyna@inertia_ixx obstacle@dyna@friction_torsional obstacle@dyna@friction_sliding obstacle@dyna@friction_rolling obstacle@dyna@inertia_izz obstacle@dyna@damping puck1 puck2 Iter 2    The overlapping of trajectories and the obstacle are due to the camera bias.(c) shows the mean trajectory differences throughout 10 iterations, evaluated with 5 random seeds and 10 pairs of rollouts per seed.</p>
<p>difference because we initialized the position of puck1 and puck2 in such a way that they almost only collided with the right wall.Though occasionally pucks did collide with the front wall or the obstacle, the speed at contacting is usually low and has minimal effects on the trajectory; therefore COMPASS placed low attention to such causality.Compared with the baseline methods, our proposed method provides unique interpretability that could guide the sim-to-real transfer in other systems.</p>
<p>The optimization process of 8 environment parameters with discovered causality is shown in Figure 4. We observe that COMPASS optimizes the environment parameters to approach the ground truth gradually, while baseline methods struggle to converge, especially for damping.Since Tune-Net trains a regression model to predict the difference between the current and the target set of environment parameters given trajectories, it does not work well when most of the environment parameters have negligible effects on the trajectories.Note that our method does NOT necessarily converge to the ground-truth environment parameters; rather, it aims to find a combination of environmental parameters to minimize the trajectory difference (more discussion in Section 5).The trajectoryaligning results are shown in Figure .5(a)(b).It is observed that our method outperforms all the baselines in terms of the trajectory difference using the same number of "real" and simulation rollouts.</p>
<p>Sim-to-real with policy optimization in the loop</p>
<p>In this experiment, we first trained the agent in the initial simulation environment parameters with Soft Actor-Critic (SAC) [48].Then, we applied COMPASS and the best-performing baseline in the sim-to-sim experiment, NPDR, to update the environment parameters and retrained the agent in the new simulation environment parameters.Finally, we deployed the agent in the real environment and reported the evaluation statistics.We used a fixed set of real trajectories instead of collecting new ones in every iteration.We effectively set up two real environments by powering the electric fan at different speeds, referred to as low fan speed and high fan speed.</p>
<p>Upon inspecting Table .1, we first observe that (i) COMPASS consistently outperforms the nominal simulator and the NPDR baseline in terms of trajectory difference and success rate.Notably, COMPASS improved success rate by 105.1% and 59.6% compared with NPDR in the low and high fan speed settings, respectively.We hypothesize that COMPASS is more robust to the noisy and unmodeled dynamics in the real environment owing to the sparse causal model learned during the model learning and parameter optimization process.We also observe that (ii) the agent's real-world performance positively correlates with the trajectory alignment performance.This is as expected given that previous works have proved that the policy performance degradation is bounded by the difference in transition distributions between two systems [39].Similar patterns are observed in the supplementary experiments as well (Appendix E).</p>
<p>Discussion and Conclusion</p>
<p>In conclusion, COMPASS is a novel causality-guided framework to identify simulation environment parameters that minimize the sim-to-real gap.It has three salient features.Firstly, COMPASS requires less domain knowledge of the randomized environment parameters, enabling a more automated process for sim-to-real transfer.Secondly, COMPASS learns an interpretable causal structure, providing better generalization during environment parameter optimization and robustness against observational noise in real rollouts.Lastly, COMPASS employs a fully differentiable model to update the environment parameters, which mitigates the efficiency issue of the existing sampling-based methods.Through both simulation and real-world experiments, we verify that our proposed method outperforms the existing gradient-free and gradient-based parameter estimation methods in terms of trajectory alignment accuracy and the agent's success rate, while offering interpretability.</p>
<p>Limitations.With all the advantages of COMPASS discussed, some limitations of our method also suggest directions for future work.Similar to the existing gradient-based methods [34,36,35,21], COMPASS could converge to local minima since the identifiable set of parameters may be coupled [49,50], which would result in multiple local minima in the parameter space.Indeed, if the purpose is to find a specific combination of parameters that minimize the sim-to-real gap, it becomes less important whether it converges to the global optimum or not [34].In addition, COMPASS finds a single combination of environment parameters rather than a distribution of them.Nevertheless, our method can maintain several particles of environment parameters as an empirical distribution [51,52,53,54,55] without extensive modifications to the core algorithm.</p>
<p>A Model details</p>
<p>In a standard fully-connected multilayer perceptron (MLP), the input is treated as a whole and input into the first linear layer.It blends all information into the feature of subsequent layers, making it difficult to separate the cause and effects.To highlight the difference between our model and traditional MLP, we plot the detailed model architecture of the COMPASS in Figure .6.</p>
<p>More specifically, we design an encoder-decoder structure in f , with G as a linear transformation applied to the intermediate features.First, the encoder operates on each dimension of ϵ independently to generate features z ϵ ∈ R |E|×dz .Then the causal graph is multiplied by the features to generate the inputs for the decoder, i.e., g ϵ = z T ϵ G ∈ R dz×K , where d z is the dimension of the feature.Similarly, the action sequence a is passed through the encoder and transformation to produce the feature of the action sequence g a ∈ R dz×K .Finally, g ϵ + g a is passed through the decoder to output the prediction dτ .
= " &gt; A A A C B X i c b V D L S g M x F M 3 U V 6 2 v V j e C m 2 A p u C o z I u q y 4 E J X U s E + Y D q U T J p p Q z P J k G T E M n S t a 8 G t f o E 7 c e t 3 + A F + g H 9 g p t O F b T 0 Q O J x z L / f k + B G j S t v 2 l 5 V b W l 5 Z X c u v F z Y 2 t 7 Z 3 i q X d p h K x x K S B B R O y 7 S N F G O W k o a l m p B 1 J g k K f k Z Y / v E j 9 1 h 2 R i g p + q 0 c R 8 U L U 5 z S g G G k j u Z 0 Q 6 Q F G L L k c d 4 t l u 2 p P A B e J M y X l 2 v 7 j U 8 U p / d S 7 x e 9 O T + A 4 J F x j h p R y H T v S X o K k p p i R c a E T K x I h P E R 9 4 h r K U U i U l 0 w i j 2 H F K D 0 Y C G k e 1 3 C i / t 1 I U K j U K P T N Z B p R z X u p + J / n x j o 4 9 x L K o 1 g T j r N D Q c y g F j D 9 P + x R S b B m I 0 M Q l t R k h X i A J M L a t D R z 5 T 6 L a n p x 5 l t Y J M 3 j q n N a P b l x y r V r k C E P D s A h O A I O O A M 1 c A X q o A E w E O A Z v I B X 6 8</p>
<p>B Experimental Details B.1 Experimental Configurations for Robot Simulation Setup</p>
<p>A simulator was developed to mimic a simulated air hockey table with dimensions matching the real-world setup using robosuite [18].This allowed us to gather rollout trajectories and training data within the simulated environment.The specific dimensions of the objects within the simulation, such as the table size, are detailed in Table 2. Additionally, for the sim-to-sim experiment configuration, default simulation parameters and the ground-truth simulated real environment parameters are presented in Table 3.</p>
<p>State and action space.The observation space for the RL agent comprises 6 dimensions.It includes the initial position of puck1 (3D), and the initial position of puck2 (3D).The RL agent's action space consists of 4 dimensions: the initial position of the pusher in the x-direction, the initial position of the pusher in the y-direction, the shooting angle of the pusher, and the pushing velocity of the pusher.We fixed the initial position of puck1 and puck2.Note that the shooting angle is relative to the line connecting the center of the pusher and puck1.</p>
<p>Reward function.</p>
<p>The reward is calculated as −10 × ∥[x puck1 , y puck1 , z puck1 ] − [x goal , y goal , z goal ]∥ 2 .To provide additional incentive for reaching the goal, the distance penalty term is divided by 2. Furthermore, a terminal reward is given if the hockey stays within the success region at the last time step.It is important to mention that the reward is not accumulated throughout the horizon.Instead, it only considers the final Euclidean distance between puck2 and the goal center.For further numerical details and specifications, please refer to Table 4.  Simulated "Real" Env Parameters pusher@actuation@vel discount 0.75 0.85 pusher@dyna@damping -10.0 -6.0 puck1@dyna@damping -10.0 -6.0 puck1@dyna@friction sliding 0.05 0.04 puck2@dyna@damping -10.0 -6.0 puck2@dyna@friction sliding 0.05 0.03 front wall, back wall, left wall, right wall, obstacle@dyna@damping -10.0 -6.0 env@camera@bias x 0.0 +0.03 env@camera@bias y 0.0 -0.02This is a top-down view of the mini air hockey table we used to collect real trajectories.The dimensional attributes of each component are annotated in Figure 7, while green dashed lines distinctly demarcate the designated goal area.We used Kinova Gen 3 robot platform and installed a top-down Intel RealSense D345f RGB camera to track the position of puck1 and puck2.</p>
<p>B.2 Experimental Configurations for Real Robot Setup</p>
<p>C Implementation Details</p>
<p>We reproduced the baseline implementation EXI-Net [36], NPDR [20] and Tune-Net [34] based on the papers and released code base.We utilized software packages such as PyTorch [56], sbi [57], StableBaseline3 [58], and OpenCV [59].We report the hyperparameters used for all algorithms, We investigated the effect of the real rollout size N and simulation rollout size M by testing values of N = 5, 10, 20 at M = 64 and M = 32, 64, 128 at N = 10.The optimization processes for environment parameters, given these sizes, are illustrated in Figure 8 and 9. Notably, for a given N, M , COMPASS demonstrates superior convergence in comparison to NPDR.</p>
<p>Further insights are offered in Figure 10a and 10c, which depicts the trajectory differences iterative steps, and Figure 10b and 10d, showing the final trajectory discrepancies for different N, M values.These visualizations highlight that as the rollout budget N, M diminishes, the performance gap between COMPASS and other benchmark methods widens.This can be attributed to the fullydifferentiable nature of COMPASS.Reinforcing our key contributions, COMPASS consistently outperforms the baselines, maintaining superiority under identical counts of real and simulation rollouts.with discovered causality (as shown in Figure 3).The solid lines represent the mean value across 3 random seeds, and the shaded area represents the standard deviation.with discovered causality (as shown in Figure 3).The solid lines represent the mean value across 3 random seeds, and the shaded area represents the standard deviation.To investigate the sensitivity of COMPASS to initialization, we conducted experiments with randomly initialized environment parameters.The environment parameter optimization processes are illustrated in Figure .12,while Figure .11presents the trajectory discrepancies.</p>
<p>A key observation from both figures is that the starting point-i.e., the parameter initialization-does influence the complexity of aligning the trajectories.Despite these variances in initialization, COMPASS consistently demonstrates its capability to minimize the trajectory difference across different initial conditions.</p>
<p>D.3 Different Sparsity Weight λ</p>
<p>The learned causal graph parameters, denoted as ψ, are illustrated in Figure .13 across various sparsity weights: λ = 0.001, 0.005, 0.01.In the absence of regularization (specifically when λ = 0), the graph tends to be denser, devoid of any constraints to minimize edge count.As λ increases, the env@light@pos_x env@light@pos_z env@light@pos_y env@air@density env@air@viscosity env@camera@bias_x env@camera@bias_y env@light@ambient_b env@light@ambient_g env@light@ambient_r pusher@dyna@inertia_ixx pusher@dyna@damping pusher@actuation@vel_discount pusher@dyna@inertia_iyy pusher@dyna@inertia_izz puck1@dyna@friction_torsional puck1@dyna@inertia_ixx puck1@dyna@friction_rolling puck1@dyna@damping puck1@dyna@inertia_iyy puck1@dyna@inertia_izz puck1@dyna@friction_sliding puck2@dyna@friction_torsional puck2@dyna@inertia_ixx puck2@dyna@inertia_iyy puck2@dyna@inertia_izz puck2@dyna@friction_rolling puck2@dyna@damping puck2@dyna@friction_sliding front_wall@dyna@inertia_izz front_wall@dyna@friction_rolling front_wall@dyna@inertia_iyy front_wall@dyna@inertia_ixx front_wall@dyna@friction_torsional front_wall@dyna@friction_sliding front_wall@dyna@damping back_wall@dyna@friction_rolling back_wall@dyna@friction_sliding back_wall@dyna@friction_torsional back_wall@dyna@inertia_ixx back_wall@dyna@inertia_iyy back_wall@dyna@damping back_wall@dyna@inertia_izz right_wall@dyna@damping right_wall@dyna@inertia_ixx right_wall@dyna@friction_torsional right_wall@dyna@friction_sliding right_wall@dyna@friction_rolling right_wall@dyna@inertia_izz right_wall@dyna@inertia_iyy left_wall@dyna@inertia_izz left_wall@dyna@inertia_iyy left_wall@dyna@inertia_ixx left_wall@dyna@friction_torsional left_wall@dyna@friction_sliding left_wall@dyna@friction_rolling left_wall@dyna@damping obstacle@dyna@inertia_iyy obstacle@dyna@inertia_ixx obstacle@dyna@friction_torsional obstacle@dyna@friction_sliding obstacle@dyna@friction_rolling obstacle@dyna@inertia_izz obstacle@dyna@damping puck1 puck2 Iter 2 (a) λ = 0.001 puck1 puck2 Iter 0 puck1 puck2 Iter 1 env@light@pos_x env@light@pos_z env@light@pos_y env@air@density env@air@viscosity env@camera@bias_x env@camera@bias_y env@light@ambient_b env@light@ambient_g env@light@ambient_r pusher@dyna@inertia_ixx pusher@dyna@damping pusher@actuation@vel_discount pusher@dyna@inertia_iyy pusher@dyna@inertia_izz puck1@dyna@friction_torsional puck1@dyna@inertia_ixx puck1@dyna@friction_rolling puck1@dyna@damping puck1@dyna@inertia_iyy puck1@dyna@inertia_izz puck1@dyna@friction_sliding puck2@dyna@friction_torsional puck2@dyna@inertia_ixx puck2@dyna@inertia_iyy puck2@dyna@inertia_izz puck2@dyna@friction_rolling puck2@dyna@damping puck2@dyna@friction_sliding front_wall@dyna@inertia_izz front_wall@dyna@friction_rolling front_wall@dyna@inertia_iyy front_wall@dyna@inertia_ixx front_wall@dyna@friction_torsional front_wall@dyna@friction_sliding front_wall@dyna@damping back_wall@dyna@friction_rolling back_wall@dyna@friction_sliding back_wall@dyna@friction_torsional back_wall@dyna@inertia_ixx back_wall@dyna@inertia_iyy back_wall@dyna@damping back_wall@dyna@inertia_izz right_wall@dyna@damping right_wall@dyna@inertia_ixx right_wall@dyna@friction_torsional right_wall@dyna@friction_sliding right_wall@dyna@friction_rolling right_wall@dyna@inertia_izz right_wall@dyna@inertia_iyy left_wall@dyna@inertia_izz left_wall@dyna@inertia_iyy left_wall@dyna@inertia_ixx left_wall@dyna@friction_torsional left_wall@dyna@friction_sliding left_wall@dyna@friction_rolling left_wall@dyna@damping obstacle@dyna@inertia_iyy obstacle@dyna@inertia_ixx obstacle@dyna@friction_torsional obstacle@dyna@friction_sliding obstacle@dyna@friction_rolling obstacle@dyna@inertia_izz obstacle@dyna@damping puck1 puck2 Iter 2 (b) λ = 0.005 puck1 puck2 Iter 0 puck1 puck2 Iter 1 env@light@pos_x env@light@pos_z env@light@pos_y env@air@density env@air@viscosity env@camera@bias_x env@camera@bias_y env@light@ambient_b env@light@ambient_g env@light@ambient_r pusher@dyna@inertia_ixx pusher@dyna@damping pusher@actuation@vel_discount pusher@dyna@inertia_iyy pusher@dyna@inertia_izz puck1@dyna@friction_torsional puck1@dyna@inertia_ixx puck1@dyna@friction_rolling puck1@dyna@damping puck1@dyna@inertia_iyy puck1@dyna@inertia_izz puck1@dyna@friction_sliding puck2@dyna@friction_torsional puck2@dyna@inertia_ixx puck2@dyna@inertia_iyy puck2@dyna@inertia_izz puck2@dyna@friction_rolling puck2@dyna@damping puck2@dyna@friction_sliding front_wall@dyna@inertia_izz front_wall@dyna@friction_rolling front_wall@dyna@inertia_iyy front_wall@dyna@inertia_ixx front_wall@dyna@friction_torsional front_wall@dyna@friction_sliding front_wall@dyna@damping back_wall@dyna@friction_rolling back_wall@dyna@friction_sliding back_wall@dyna@friction_torsional back_wall@dyna@inertia_ixx back_wall@dyna@inertia_iyy back_wall@dyna@damping back_wall@dyna@inertia_izz right_wall@dyna@damping right_wall@dyna@inertia_ixx right_wall@dyna@friction_torsional right_wall@dyna@friction_sliding right_wall@dyna@friction_rolling right_wall@dyna@inertia_izz right_wall@dyna@inertia_iyy left_wall@dyna@inertia_izz left_wall@dyna@inertia_iyy left_wall@dyna@inertia_ixx left_wall@dyna@friction_torsional left_wall@dyna@friction_sliding left_wall@dyna@friction_rolling left_wall@dyna@damping obstacle@dyna@inertia_iyy obstacle@dyna@inertia_ixx obstacle@dyna@friction_torsional obstacle@dyna@friction_sliding obstacle@dyna@friction_rolling obstacle@dyna@inertia_izz obstacle@dyna@damping puck1 puck2 Iter 2 (c) λ = 0.01 graph becomes progressively sparser.However, it still maintains the most influential edges; omitting them would significantly elevate the prediction error.</p>
<p>E Sim-to-Real Double-Bouncing-Ball Experiment E.1 Double-bouncing-ball experimental setup Figure 14 illustrates the experimental setup.Building upon the experimental design presented by Allevato et al. [34], we've raised the bar by allowing the ball to bounce twice, rather than just once, before landing in the goal basket.The goal basket has a diameter of 13.0 cm, and the ball measures 6.8 cm in diameter.Successful task completion is characterized by the ball's accurate entry into the hoop from above.The task's intricacy hinges on achieving a seamless alignment between the real-world dynamics and the simulation.By releasing the ball at a specific height, it needs to bounce first off inclined plate 1, followed by plate 2, and finally enter into the goal basket.The ball's motion is constrained within a 2-D plane with properly aligned plates.As such, the action space is represented by a scalarthe ball's release height.Simultaneously, the state space corresponds to the ball's 2-D positional coordinates within this plane (K = 1).This experiment encompasses 82 environment parameters (|E| = 82).</p>
<p>E.2 Learned causal graph</p>
<p>Figure 15 depicts the learned causal graph parameter, denoted as ψ.Starting from a fully-connected causal graph, COMPASS efficiently narrows down the parameter search space from 82 dimensions to a mere 4 dimensions.Specifically, these are ball@dyna@damping, ball@dyna@mass, plate1@dyna@damping, and plate2@dyna@damping.Remarkably, this refinement is achieved within just two iterations.</p>
<p>E.3 Sim-to-real trajectory alignment results</p>
<p>As depicted in Figure 16, it's evident that COMPASS effectively aligns simulated trajectories closely with their real-world counterparts.Given the extensive scale of environment parameters in this conball Iter 0 ball Iter 1 env@light@pos_x env@light@pos_z env@light@pos_y env@light@ambient_r env@light@ambient_g env@light@ambient_b env@light@active env@air@viscosity env@air@density ball@vis@material_specular ball@vis@material_shininess ball@dyna@damping ball@vis@geom_r ball@vis@material_reflectance ball@dyna@friction_sliding ball@dyna@friction_torsional ball@dyna@inertia_ixx ball@dyna@friction_rolling ball@dyna@inertia_izz ball@dyna@mass ball@vis@geom_b ball@vis@geom_g ball@dyna@inertia_iyy plate1@vis@geom_r plate1@dyna@friction_torsional plate1@vis@geom_g plate1@vis@geom_b plate1@dyna@mass plate1@dyna@inertia_izz plate1@dyna@inertia_iyy plate1@dyna@damping plate1@dyna@friction_rolling plate1@dyna@friction_sliding plate1@dyna@inertia_ixx plate2@dyna@mass plate2@dyna@inertia_izz plate2@vis@geom_b plate2@vis@geom_g plate2@vis@geom_r plate2@dyna@inertia_ixx plate2@dyna@inertia_iyy plate2@dyna@friction_torsional plate2@dyna@damping plate2@dyna@friction_rolling plate2@dyna@friction_sliding table@vis@material_reflectance table@vis@geom_r table@vis@geom_g table@vis@geom_b table@vis@material_specular table@vis@material_shininess table@dyna_collision@damping table@dyna@mass table@dyna@inertia_izz table@dyna@inertia_iyy table@dyna@inertia_ixx floor@vis@geom_b floor@vis@material_specular floor@vis@material_shininess floor@vis@material_reflectance floor@vis@geom_r floor@vis@geom_g robot@dyna_shoulder_link@mass robot@dyna_shoulder_link@inertia_izz robot@dyna_shoulder_link@inertia_iyy robot@dyna_shoulder_link@inertia_ixx robot@dyna_forearm_link@inertia_izz robot@dyna_forearm_link@inertia_iyy robot@dyna_forearm_link@inertia_ixx robot@dyna_base@inertia_izz robot@dyna_base@inertia_iyy robot@dyna_base@inertia_ixx robot@dyna_HalfArm2_Link@mass robot@dyna_HalfArm2_Link@inertia_izz robot@dyna_HalfArm2_Link@inertia_iyy robot@dyna_HalfArm2_Link@inertia_ixx robot@dyna_HalfArm1_Link@mass robot@dyna_HalfArm1_Link@inertia_izz robot@dyna_HalfArm1_Link@inertia_iyy robot@dyna_HalfArm1_Link@inertia_ixx robot@dyna_forearm_link@mass robot@dyna_base@mass ball Iter 2</p>
<p>E.4 Real-world agent performance</p>
<p>Table 10 presents the real-world performance of agents after policy optimization in the adjusted compared with nominal agents (those trained in the original environments).Consistent with the trajectory alignment outcomes, agents trained using COMPASS demonstrate superior success rates compared to those trained using NPDR and the nominal approach.Table 10: Agents' performance in the real environment."±" represents the standard deviation.We evaluate the results using 5 policies generated from independent runs and collect 10 trajectories for each run.</p>
<p>F.2 Learned causal graph</p>
<p>The learned causal graph parameter is shown in Figure .19. Starting from a fully-connected causal graph, COMPASS efficiently narrows down the parameter search space from 67 dimensions to only 3 dimensions within 2 iterations.Specifically, they are cube@dyna@mass, cube@dyna@damping, cube@dyna@friction sliding.</p>
<p>pos roll pitch yaw</p>
<p>Iter 0 pos roll pitch yaw Iter 1 dynamic@env@density dynamic@env@viscosity lighting@light@pos_x lighting@light@pos_y lighting@light@pos_z lighting@light@ambient_r lighting@light@ambient_g lighting@light@ambient_b lighting@light@active dynamic@table@inertia_ixx dynamic@table@inertia_iyy dynamic@table@inertia_izz dynamic@table@mass texture@table_visual@geom_r texture@table_visual@geom_g texture@table_visual@geom_b texture@table_visual@material_reflectance texture@table_visual@material_shininess texture@table_visual@material_specular dynamic@cube_main@inertia_ixx dynamic@cube_main@inertia_iyy dynamic@cube_main@inertia_izz dynamic@cube_main@mass dynamic@cube_g0@friction_sliding dynamic@cube_g0@friction_torsional dynamic@cube_g0@friction_rolling dynamic@cube_g0@damping_ratio texture@cube_g0_vis@geom_r texture@cube_g0_vis@geom_g texture@cube_g0_vis@geom_b texture@gripper0_hand_visual@geom_r texture@gripper0_hand_visual@geom_g texture@gripper0_hand_visual@geom_b dynamic@gripper0_hand_collision@damping_ratio dynamic@gripper0_hand_collision@friction_sliding dynamic@gripper0_hand_collision@friction_torsional dynamic@gripper0_hand_collision@friction_rolling dynamic@gripper0_left_outer_knuckle@inertia_ixx dynamic@gripper0_left_outer_knuckle@inertia_iyy dynamic@gripper0_left_outer_knuckle@inertia_izz dynamic@gripper0_left_outer_knuckle@mass dynamic@gripper0_left_outer_knuckle_collision@friction_sliding dynamic@gripper0_left_outer_knuckle_collision@friction_torsional dynamic@gripper0_left_outer_knuckle_collision@friction_rolling dynamic@gripper0_left_outer_knuckle_collision@damping_ratio dynamic@gripper0_left_inner_knuckle@inertia_ixx dynamic@gripper0_left_inner_knuckle@inertia_iyy dynamic@gripper0_left_inner_knuckle@inertia_izz dynamic@gripper0_left_inner_knuckle@mass dynamic@gripper0_left_inner_knuckle_collision@friction_sliding dynamic@gripper0_left_inner_knuckle_collision@friction_torsional dynamic@gripper0_left_inner_knuckle_collision@friction_rolling dynamic@gripper0_left_inner_knuckle_collision@damping_ratio dynamic@gripper0_left_outer_finger_collision@friction_sliding dynamic@gripper0_left_outer_finger_collision@friction_torsional dynamic@gripper0_left_outer_finger_collision@friction_rolling dynamic@gripper0_left_outer_finger_collision@damping_ratio texture@gripper0_right_outer_finger_visual@geom_r texture@gripper0_right_outer_finger_visual@geom_g texture@gripper0_right_outer_finger_visual@geom_b dynamic@gripper0_right_inner_finger@inertia_ixx dynamic@gripper0_right_inner_finger@inertia_iyy dynamic@gripper0_right_inner_finger@inertia_izz dynamic@gripper0_right_inner_finger@mass texture@gripper0_right_inner_finger_visual@geom_r texture@gripper0_right_inner_finger_visual@geom_g texture@gripper0_right_inner_finger_visual@geom_b pos roll pitch yaw Iter 2</p>
<p>F.4 Sim-to-sim agent performance</p>
<p>Table 10 presents the "real" performance of agents after policy optimization in the adjusted environment, compared with nominal agents (those trained in the original environments).Consistent with the trajectory alignment outcomes, agents trained using COMPASS demonstrate higher success rates compared to those trained using NPDR and the nominal approach.</p>
<p>Table 11: Agents' performance in the "real" environment."±" represents the standard deviation.We evaluate the results using 3 policies generated from independent runs and collect 10 trajectories for each run.</p>
<p>G Additional Literature Review</p>
<p>Adaptive Policy in Locomotion and Manipulation.The challenge of sim-to-real transfer has been central to the field of locomotion tasks, and it has recently demonstrated remarkable success [61,62,63,64,65].Rapid Motor Adaptation (RMA) [62] proposed a solution to bridge the sim-toreal gap by effectively learning the relationship between dynamic-affecting parameters and historical contexts.More recently, Kumar et al. [63] introduced Adapting-RMA (A-RMA) to further refine the base policy of RMA using model-free reinforcement learning (RL) techniques.Typically, RMAbased methods approach the sim-to-real challenge as a generalization problem.They tend to assume an appropriate range and set of parameters that influence testing performance, along with a sizable randomized training budget, to ensure successful operation.These assumptions present inherent challenges due to the requisite domain expertise and training time.In manipulation, Liu et al. [66] approached the adaptive policy from a continual RL perspective, cultivating a policy for each group of tasks rather than an individual task to solve unseen tasks in seen groups in a zero-shot manner.In contrast, this paper focuses on aligning simulators with real-world dynamics.Our approach involves the automated identification of simulation environment parameters that minimize the simto-real dynamics gap.While there are similar studies, such as the work by Mozian et al. [65], which on searching for the environment parameter distributions that are challenging yet not excessively adversarial to learn, our emphasis is on sim-to-real applications with novel causality-based system identification.</p>
<p>t e x i t s h a 1 _ b a s e 6 4 = " q 7 u B + C 3 8 X n k y 7 f c a C N / F L B b / I M E = " &gt; A A A C B n i c b V C 7 S g N B F J 3 1 G e M r a m k z J A h W Y V d E L S M 2 V h L B P C C 7 h N n J b D J k d n e Y u S u G J b 2 N r W C l X 2 A n t v 6 G W F v 7 C 0 6 y K U z i g Q u H c + 7 l H o 4 v B d d g 2 5 / W w u L S 8 s p q bi 2 / v r G 5 t V 3 Y 2 a 3 r O F G U 1 W g s Y t X 0 i W a C R 6 w G H A R r S s V I 6 A v W 8 P s X I 7 9 x y 5 T m c X Q D A 8 m 8 k H Q j H n B K w E i u K 3 k 7 d a H H g A z b h Z J d t s f A 8 8 S Z k F K l + P T w c 9 7 / q r Y L 3 2 4 n p k n I I q C C a N 1 y b A l e S h R w K t g w 7 y a a S U L 7 p M t a h k Y k Z N p L x 5 m H + M A o H R z E y k w E e K z + v U h J q P U g 9 M 1 m S K C n Z 7 2 R + J / X S i A 4 8 1 I e y Q R Y R L N H Q S I w x H h U A O 5 w x S i I g S G E K m 6 y Y t o j i l A w N U 1 9 u c u i m l 6 c 2 R b m S f 2 o 7 J y U j 6 + d U u U K Z c i h f V R E h 8 h B p 6 i C L l E V 1 R B F E j 2 i Z / R i 3 V u v 1 p v 1 n q 0 u W J O b P T Q F 6 + M X E5 W e d g = = &lt; / l a t e x i t &gt; ⇡ ✓ &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " t 8 L P 9 I x G h 3 5 f x 4 5 i U K s i c r 0 F C + Y = " &gt; A A A C E X i c b V D L S g M x F M 3 4 r P U 1 K q 7 c B I v g q s y o q D s L b l x J B f u A z l A y m b Q N z S R D k h H L 0 K / w C 9 z q F 7 g T t y 5 d + Q H + h 5 m Z L m z r g Z D D O f d y D y e I G V X a c b 6 t h c W l 5 Z X V 0 l p 5 f W N z a 9 v e 2 W 0 q k U h M G l g w I d s B U o R R T h q a a k b a s S Q o C h h p B c P r z G 8 9 E K m o 4 P d 6 F B M / Q n 1 O e x Q j b a S u v e 8 F g o V q F J k v 9 U i s K B N 8 3 L U r T t X J A e e J O y G V q 6 / T H P W u / e O F A i c R 4 R o z p F T H d W L t p 0 h q i h k Z l 7 1 E k R j h I e q T j q E c R U T 5 a R 5 / D I + M E s K e k O Z x D X P 1 7 0 a K I p U l N J M R 0 g M 1 6 2 X i f 1 4 n 0 b 1 L P 6 U 8 T j T h u D j U S x j U A m Z d w J B K g j U b G Y K w p C Y r x A M k E d a m s a k r j 0 V U 0 4 s 7 2 8 I 8 a Z 5 U 3 f P q 2 Z 1 b q d 2 C A i V w A A 7 B M X D B B a i B G 1 A H D Y B B C p 7 B C 3 i 1 n q w 3 6 9 3 6 K E Y X r M n O H p i C 9 f k L 1 z O h K g = = &lt; / l a t e x i t &gt; ✏ Causality Gradient backprop puck1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " w 4 a t x o S 4 o R p d K j Z 9 W E s / b b v l w Y g = " &gt; A A A C D 3 i c bV C 7 T s M w F H X K q 5 R X o C N L 1 A q J q U o Q A s Y i F i Z U J P q Q m i hy H K e 1 6 j i R 7 S C i q J / A w M j E C l / A h l j 5 B M T M z C / g N B 1 o y 5 E s H 5 1 z r + 7 R 8 W J K h D T N T 6 2 0 t L y y u l Z e r 2 x s b m 3 v 6 L t 7 H R E l H O E 2 i m j E e x 4 U m B K G 2 5 J I i n s x x z D 0 K O 5 6 o 4 v c 7 9 5 i L k j E b m Q a Y y e E A 0 Y C g q B U k q t X b S + i v k h D 9 W W + a 0 u Y j F 2 9 b j b M C Y x F Y k 1 J v V l 7 v P 8 5 H 3 2 1 X P 3 b 9 i O U h J h J R K E Q f c u M p Z N B L g m i e F y x E 4 F j i E Z w g P u K M h h i 4 W S T 8 G P j Q C m + E U R c P S a N i f p 3 I 4 O h y P O p y R D K o Z j 3 c v E / r 5 / I 4 M z J C I s T i R k q D g U J N W R k 5 E 0 Y P u E Y S Z o q</p>
<p>5 B M T M z C / g N B 1 o y 5 E s H 5 1 z r + 7 R 8 W J K h D T N T 6 2 0 t L y y u l Z e r 2 x s b m 3 v 6 L t 7 H R E l H O E 2 i m j E e x 4 U m B K G 2 5 J I i n s x x z D 0 K O 5 6 o 4 v c 7 9 5 i L k j E b m Q a Y y e E A 0 Y C g q B U k q t X b S + i v k h D 9 W W + a 0 u Y j F 2 9 b j b M C Y x F Y k 1 J v V l 7 v P 8 5 H 3 2 1 X P 3 b 9 i O U h J h J R K E Q f c u M p Z N B L g m i e F y x E 4 F j i E Z w g P u K M h h i 4 W S T 8 G P j Q C m + E U R c P S a N i f p 3 I 4 O h y P O p y R D K o Z j 3 c v E / r 5 / I 4 M z J C I s T i R k q D g U J N W R k 5 E 0 Y P u E Y S Z o q</p>
<p>5 B M T M z C / g N B 1 o y 5 E s H 5 1 z r + 7 R 8 W J K h D T N T 6 2 0 t L y y u l Z e r 2 x s b m 3 v 6 L t 7 H R E l H O E 2 i m j E e x 4 U m B K G 2 5 J I i n s x x z D 0 K O 5 6 o 4 v c 7 9 5 i L k j E b m Q a Y y e E A 0 Y C g q B U k q t X b S + i v k h D 9 W W + a 0 u Y j F 2 9 b j b M C Y x F Y k 1 J v V l 7 v P 8 5 H 3 2 1 X P 3 b 9 i O U h J h J R K E Q f c u M p Z N B L g m i e F y x E 4 F j i E Z w g P u K M h h i 4 W S T 8 G P j Q C m + E U R c P S a N i f p 3 I 4 O h y P O p y R D K o Z j 3 c v E / r 5 / I 4 M z J C I s T i R k q D g U J N W R k 5 E 0 Y P u E Y S Z o q</p>
<p>d⌧ puck2 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " w 4 a t x o S 4 o R p d K j Z 9 W E s / b b v l</p>
<p>h l j 5 B M T M z C / g N B 1 o y 5 E s H 5 1 z r + 7 R 8 W J K h D T N T 6 2 0 t L y y u l Z e r 2 x s b m 3 v 6 L t 7 H R E l H O E 2 i m j E e x 4 U m B K G 2 5 J I i n s x x z D 0 K O 5 6 o 4 v c 7 9 5</p>
<p>9 U q i 8 I F R 8 u i g t p E / a r w P 0 E 2 G Q k x w 5 w r g R z q v P j 5 l h n F z M M 1 t O p 1 Z d L v + P 45 4 c r L b D L + 1 P e 2 G r 8 w O m m I M V e A c f I Y Q 1 6 M A 2 7 E I X O J z B J V z D j X f h j b 1 f 3 u 9 p a 8 O 7 m 1 m G G T T g D 1 w Y u R I = &lt; / l a t e x i t &gt; d⌧ Env parameter &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 4 O c E a 2 U k M 6 t l P g O O f Z 2 9 V k e 6 G T 8 = " &gt; A A A C S H i c d V B d S x t B F J 1 N 6 0 f 9 j P W x L 0 u D 6 F P Y F V s V f A g I k g c t F o w K 2 R B m Z + 8 m g 7 M z y 8 x d S V j 2 T + m / 8 B e 0 j y 3 4 K r 4 V 3 5 x N i h g / z j D M 4 d x 7 5 x 5 O m A p u 0 P N + O 5 U P H 6 e m Z 2 Y / z c 0 v L C 4 t V 1 c + n x q V a Q Y t p o T S 5 y E 1 I L i E F n I U c J 5 q o E k o 4 C y 8 2 C / r Z 5 e g D V f y B I c p d B L a k z z m j K K V u t X D I I L Y z o 5 + y p W m s g d F 3 j w 5 O i z y 7 Y P y F H M B w g A n G 4 J Q i c g M E / v k A a S G C y W L o l u t e f X d E t 9 c v + 6 N 8 J r U G u t 3 d 8 t 7 1 7 f H 3 e p t E C m W J S C R C W p M 2 / d S 7 O R U I 2 c C 7 O b M Q E r Z B e 1 B 2 1 J J E z C d f G S l c N e s E r m x 0 v Z K d E f q 8 4 m c J q a 0 a D s T i n 3 z s l a K b 9 X a G c Y 7 n Z z L N E O Q b L w o z o S L y i 0 j d C O u g a E Y W k K Z 5 t a r y / p U U 4 Y 2 6 I k t g 7 F V m 8 v 7 c T y R 0 8 2 6 / 7 2 + 9 d O v N X 6 Q M W b J F / K V b B C f b J M G a Z J j 0 i K M X J F f 5 A / 5 6 9 w 4 9 8 4 / 5 2 H c W n H + z 6 y S C V Q q j 1 w 6 u h M = &lt; / l a t e x i t &gt; ✏ &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " x 7 / U J U v Z I I 8 8 Q t 5 w W m + P S A p J a R Q = " &gt; A A A C Z n i c d V F d a x N B F J 1 s q / 1 Q 2 9 g i f e j L Y B A q y L I b 2 6 o P h Y B 9 6 E t L B N M W s u l y d 3 b S j J 2 P Z W Z W D M P + k P q r + u o P</p>
<p>3 j e z d t / k x y R U p B p S U c j O n H U W E H D r R l h N N q N S k N L Y B c w S X t e y p B U D N w k 0 w q / M o r O R 4 q 7 Y + 0 e K L O d j g Q p l 7 U V 9 Y J m L + 9 W v y X 1 y / t 8 P 3 A M V m U l k o y H T Q s O b Y K 1 w H j n G l K L B 9 7 A k Q z v y s m I 9 B A r P + G u S n f p q v 6 X P 4 8 H v + f n L b D e D / c / R S 3 O i d o i m W 0 j V 6 i H R S j d 6 i D j l A X 9 R B B N + g W 3 T V Q 4 1 e w F r w I t q a l Q e N 3 z y a a Q 4 D v A T L p w e o = &lt; / l a t e x i t &gt; D = {(✏ m , a m , d m ⌧ )} M m=1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " y l / Q e 0 A i 2 D J F l R H r / 7 6 r f z B m k J</p>
<p>drFigure 1 :
1
Figure 1: Overview of the COMPASS framework.</p>
<p>Figure 2 :
2
Figure 2: Experimental setup.</p>
<p>Figure 3 :
3
Figure 3: Learned causal graph parameters ψ.Darker colors present values closer to 1.We use parameter notations in the format of object@param type@param.</p>
<p>Figure 4 :
4
Figure4: Environment parameters optimization.We show 8 parameters with discovered causality (as shown in Figure3).The final mean absolute percentage errors (MAPE) are 0.22, 0.95, 0.29, 3.85 for COMPASS, EXI-Net, NPDR, Tune-Net, respectively.The solid lines represent the mean value across 5 random seeds, and the shaded area represents the standard deviation.The damping is negative due to the sign convention in MuJoCo.</p>
<p>Figure 5 :
5
Figure 5: (a) and (b) visualize sampled trajectory-aligning results using NPDR and COMPASS, respectively.</p>
<p>t e x i t s h a 1 _ b a s e 6 4 = " V O / s W D 3 m I n 6 8 U 9 K F S y Q d r r 6 A z 6 4</p>
<p>Figure 6 :
6
Figure 6: COMPASS model architecture.</p>
<p>Figure 7 :
7
Figure 7: Top-Down View ofTable Air Hockey.</p>
<p>Figure 8 :
8
Figure 8: Environment parameters optimization with different real rollout sizes N .We show 8 parameters</p>
<p>Figure 9 :
9
Figure 9: Environment parameters optimization with different sim rollout sizes M .We show 8 parameters</p>
<p>Figure 10 :Figure 11 :
1011
Figure 10: (a)(b) Trajectory difference for different real rollout size N .(c)(d) Trajectory difference different sim rollout size M .</p>
<p>Figure 12 :
12
Figure 12: Environment parameters optimization with randomized initialization.We only show one run per initialization.</p>
<p>Figure 13 :
13
Figure 13: Learned causal graph parameters ψ with different sparsity weight λ.Darker colors present values closer to 1.We use parameter notations in the format of object@param type@param.</p>
<p>Figure 14 :
14
Figure 14: Double-bouncing-ball setup.</p>
<p>Figure 15 :
15
Figure 15: Learned causal graph parameters ψ for double-bouncing-ball experiments.Darker colors present values closer to 1.We use parameter notations in the format of object@param type@param.</p>
<p>Figure 16 :
16
Figure 16: Visualization of sim-to-real trajectory alignment.</p>
<p>Figure 17 :
17
Figure 17: Real-world policy rollouts.</p>
<p>10 FF. 1
101
Success rate (↑) 0.30 ± 0.14 0.58 ± 0.15 0.86 ± 0.Sim-to-Sim Push-I Experiment Experimental setup We conducted further evaluations using an experiment inspired by the Push-T experiment described by Chi et al.[60].In this experiment, illustrated in Figure.18, the agent controls the robot arm to strategically move a slender I-shaped cube towards a specific position and alignment.The task spans a horizon of T = 30.The state space comprises the 3-D coordinates and orientation of the cube, the target, and the end effector.The action space is defined by the 3-D velocity of the end effector and the gripper's action (either open or close).The states of interest are factorized into the position, roll, pitch, and yaw of the cube (K = 4).This setup involves 67 environment parameters (|E| = 67).</p>
<p>Figure 18 :
18
Figure 18: Push-I task.The green cube represents the target.</p>
<p>Figure 19 :
19
Figure 19: Learned causal graph parameters ψ for Push-I experiments.</p>
<p>Figure 20 :Figure 21 :F. 3
20213
Figure 20: Environment parameters optimization.The solid lines represent the mean value across 3 random seeds, and the shaded area represents the standard deviation.</p>
<p>Figure 22 :
22
Figure 22: Trajectory alignment results of EXI-Net, NPDR, and COMPASS.</p>
<p>Figure 23 :
23
Figure 23: Trajectory alignment results of EXI-Net, NPDR, and COMPASS.</p>
<p>Figure 24 :
24
Figure 24: Trajectory alignment results of EXI-Net, NPDR, and COMPASS.</p>
<p>Figure 25 :
25
Figure 25: Trajectory alignment results of EXI-Net, NPDR, and COMPASS.</p>
<p>22, 0.95, 0.29, 3.85 for COMPASS, EXI-Net, NPDR, Tune-Net, respectively.The solid lines represent the mean value across 5 random seeds, and the shaded area represents the standard deviation.The damping is negative due to the sign convention in MuJoCo.
0.30.30.30.20.20.20.10.10.10.00.00.00.10.10.1"real" puck1iter 1 puck1"real" puck1iter 1 puck1"real" puck1iter 1 puck10.2"real" puck2 iter 2 puck1iter 1 puck2 iter 0 puck10.2"real" puck2 iter 2 puck1iter 1 puck2 iter 0 puck10.2"real" puck2 iter 2 puck1iter 1 puck2 iter 0 puck10.3iter 2 puck2iter 0 puck20.3iter 2 puck2iter 0 puck20.3iter 2 puck2iter 0 puck20.10.00.10.20.30.40.10.00.10.20.30.40.10.00.10.20.30.4(a) NPDR0.30.30.30.20.20.20.10.10.10.00.00.00.10.10.1"real" puck1iter 1 puck1"real" puck1iter 1 puck1"real" puck1iter 1 puck10.2"real" puck2 iter 2 puck1iter 1 puck2 iter 0 puck10.2"real" puck2 iter 2 puck1iter 1 puck2 iter 0 puck10.2"real" puck2 iter 2 puck1iter 1 puck2 iter 0 puck10.3iter 2 puck2iter 0 puck20.3iter 2 puck2iter 0 puck20.3iter 2 puck2iter 0 puck20.10.00.10.20.30.40.10.00.10.20.30.40.10.00.10.20.30.4</p>
<p>Table 1 :
1
Trajectory difference (averaged between Puck1 and Puck2) and agents' performance in the real environment."±" represents the standard deviation.We evaluate the results using 5 policies generated from independent runs and collect 10 trajectories for each run.
Low fan speedHigh fan speedNominalNPDRCOMPASSNominalNPDRCOMPASSTrajectory difference min (↓) Trajectory difference max (↓) Trajectory difference mean (↓) Puck2 final dist. to goal center (↓) 0.35 ± 0.04 0.18 ± 0.05 0.12 ± 0.03 0.29 ± 0.09 0.15 ± 0.07 0.13 ± 0.02 3.68 ± 0.07 2.81 ± 0.16 2.37 ± 0.10 2.23 ± 0.37 3.05 ± 0.46 1.41 ± 0.25 10.77 ± 0.05 7.34 ± 1.41 5.71 ± 0.23 9.84 ± 0.56 10.36 ± 0.82 8.17 ± 1.34 7.60 ± 0.03 5.18 ± 0.77 4.02 ± 0.07 6.07 ± 0.40 5.63 ± 0.5 3.97 ± 0.45 Success rate (↑) 0.00 ± 0.00 0.39 ± 0.33 0.80 ± 0.09 0.20 ± 0.07 0.47 ± 0.41 0.75 ± 0.22</p>
<p>Table 2 :
2
Mujoco Simulation Environment Setup
X (m) Y (m) Z (m)Radius(m)Air hockey table0.00.00.8[0.45, 0.9, 0.035]Puck1-0.150.00.80.0255Puck2-0.075 -0.0750.80.0255Goal point0.430.00.80.15Obstacle bar0.10.00.8[0.025, 0.18, 0.025]</p>
<p>Table 3 :
3
Sim-to-Sim Env Parameters
Env paramDefault Simulation Env Parameters</p>
<p>Table 4 :
4
Simulation Environment Setup
Simulation ParametersAction spacelow: [-0.24, 0.065, -0.157, 0.3] high: [-0.21, 0.085, 0.157, 0.5]Observation spacelow: [-inf] -high:[inf]Terminal reward2.25Simulation horizon50 time stepsSimulation timestep0.05 s</p>
<p>Table 5 :
5
Soft Actor-Critic Hyperparameters
Parameters NameValueslearning rate3e-4gradient steps32batch size32train freq8ent coef0.005net arch[32, 32]policy"MlpPolicy"env number64buffer size1,000,000learning starts100tau0.005gamma0.99action noiseNonestats window size100
[58]uding the proposed COMPASS method, in Table6, 7, 8, and 9, which provide a comprehensive list of the parameters we utilized to reproduce the results.Soft Actor-Critic hyperparameters.We use SAC implementation in StableBaseline3[58]to train the RL agents.The training hyperparameter is shown in Table5.</p>
<p>Table 6 :
6
COMPASS hyperparameters
Descriptionvaluevariable nameShared HyperparametersNumber of iterations10n roundRetrain in each iteration (if False, keep using the model trained in the first iteration)Trueretrain from scratchNumber of rollouts in each iteration640n samples per roundNumber of command actions in each iteration10n cmd actionNumber of epochs4000n epochsBatch size64batch sizeLearning rate0.001learning rateAlgorithm-Specific HyperparametersNetwork encoder dimension32emb dimNetwork hidden dimension[256, 256]hidden dimCausal dimension32causal dimSparsity weight of the loss function0.003sparse weightSparsity weight discount0.5sw discountLoss functionMSE + Sparsity loss functionOptimizerAdamoptimizer</p>
<p>Table 7 :
7
EXI-Net hyperparameters
Descriptionvaluevariable nameShared HyperparametersNumber of iterations10n roundRetrain in each iteration (if False, keep using the model trained in the first iteration)Trueretrain from scratchNumber of rollouts in each iteration640n samples per roundNumber of command actions in each iteration10n cmd actionNumber of epochs4000n epochsBatch size64batch sizeLearning rate0.001learning rateAlgorithm-Specific HyperparametersNetwork hidden dimension[256, 256] hidden dimLoss functionMSEloss functionOptimizerAdamoptimizer</p>
<p>Table 8 :
8
NPDR hyperparameters
Descriptionvaluevariable nameShared HyperparametersNumber of iterations10n roundRetrain in each iteration (if False, keep using the model trained in the first iteration)Trueretrain from scratchNumber of rollouts in each iteration640n samples per roundNumber of command actions in each iteration10n cmd actionAlgorithm-Specific HyperparametersPrior distribution typeUniform priorInference model typemafinf modelEmbedding net typeLSTMembedding structEmbedding downsampling factor2downsampling factorPosterior hidden features100hidden featuresPosterior number of transforms10num transformsNormalize posteriorFalsenormalize posteriorDensity estimator training epochs50num epochsDensity estimator training rate3e-4learning rateEarly stop epochs once posterior converge20stop after epochsUse combined loss for posterior trainingTrueuse combined lossDiscard prior samplesFalsediscard prior samplesSampling methodMCMCsample withMCMC thinning factor2thin</p>
<p>Table 9 :
9
Tune-Net hyperparameters
Descriptionvaluevariable nameShared HyperparametersNumber of iterations1n roundRetrain in each iteration (if False, keep using the model trained in the first iteration)Falseretrain from scratchNumber of rollouts in each iteration6400n samples per roundNumber of command actions in each iteration10n cmd actionNumber of epochs4000n epochsBatch size64batch sizeLearning rate0.001learning rateAlgorithm-Specific HyperparametersNetwork input dimension (Pair of Trajectory and Action dimension)(2, 304)(dim pair, dim state)Network output dimension (Tunable env param dimension)64dim zetaEnv param update iteration10KNetwork hidden dimension[256, 256] hidden dimLoss functionMSEloss fnOptimizerAdamoptimizer
D.1 Different Real Rollout Size N and Sim Rollout Size M</p>
<p>text, sampling-based techniques like NPDR become notably inefficient.This is primarily because they necessitate an immense sample size to learn a posterior distribution accurately.
realiter 3realiter 3realiter 3realiter 31.6iter 6iter 01.6iter 6iter 01.6iter 6iter 01.6iter 6iter 01.41.41.41.41.21.21.21.21.01.01.01.00.80.80.80.80.40.20.00.20.40.40.20.00.20.40.40.20.00.20.40.40.20.00.20.4(a) NPDRrealiter 3realiter 3realiter 3realiter 31.6iter 6iter 01.6iter 6iter 01.6iter 6iter 01.6iter 6iter 01.41.41.41.41.21.21.21.21.01.01.01.00.80.80.80.80.40.20.00.20.40.40.20.00.20.40.40.20.00.20.40.40.20.00.20.4(b) COMPASS
. We propose a novel causality-guided parameter estimation framework to close the sim-to-real gap and improve agent performance in the real world.
. We design a fully-differentiable model that explicitly embeds the causal structure to provide better interpretability, prune the search space of parameters, and improve generalization.
. We empirically evaluate our method in both the simulation and the real world, which outperforms baselines in terms of trajectory alignment and task success rate with the same sample size.2 Related WorkClosing the sim-to-real gap in robotic control tasks is often approached through domain randomization (DR)[10,25,26,27,28,29,30,31]. Although DR proves successful in numerous applications, particularly when access to real environments or data collected therein is unavailable, it is recognized
AcknowledgmentsThe authors gratefully acknowledge the support from the National Science Foundation under grants CNS-2047454.
Sim-to-real transfer of robotic control with dynamics randomization. X B Peng, M Andrychowicz, W Zaremba, P Abbeel, IEEE international conference on robotics and automation (ICRA). 2018. 2018IEEE</p>
<p>Learning dexterous in-hand manipulation. O M Andrychowicz, B Baker, M Chociej, R Jozefowicz, B Mcgrew, J Pachocki, A Petron, M Plappert, G Powell, A Ray, The International Journal of Robotics Research. 3912020</p>
<p>Learn-to-race challenge 2022: Benchmarking safe learning and cross-domain generalisation in autonomous racing. J Francis, B Chen, S Ganju, S Kathpal, J Poonganam, A Shivani, S Genc, I Zhukov, M Kumskoy, A Koul, arXiv:2205.029532022arXiv preprint</p>
<p>Diverse and admissible trajectory forecasting through multimodal context understanding. S H Park, G Lee, J Seo, M Bhat, M Kang, J Francis, A Jadhav, P P Liang, L.-P Morency, Computer Vision-ECCV 2020: 16th European Conference. Glasgow, UKSpringerAugust 23-28, 2020. 2020Proceedings, Part XI 16</p>
<p>Knowledge-driven scene priors for semantic audio-visual embodied navigation. G Tatiya, J Francis, L Bondi, I Navarro, E Nyberg, J Sinapov, J Oh, arXiv:2212.113452022arXiv preprint</p>
<p>Distribution-aware goal prediction and conformant model-based planning for safe autonomous driving. J Francis, B Chen, W Yao, E Nyberg, J Oh, arXiv:2212.087292022arXiv preprint</p>
<p>Learn-to-race: A multimodal control environment for autonomous racing. J Herman, J Francis, S Ganju, B Chen, A Koul, A Gupta, A Skabelkin, I Zhukov, M Kumskoy, E Nyberg, Proceedings of the IEEE/CVF International Conference on Computer Vision. the IEEE/CVF International Conference on Computer Vision2021</p>
<p>Mujoco: A physics engine for model-based control. E Todorov, T Erez, Y Tassa, 2012 IEEE/RSJ international conference on intelligent robots and systems. IEEE2012</p>
<p>. B Ellenberger, 2018-2019Pybullet gymperium</p>
<p>Domain randomization for transferring deep neural networks from simulation to the real world. J Tobin, R Fong, A Ray, J Schneider, W Zaremba, P Abbeel, 2017 IEEE/RSJ international conference on intelligent robots and systems (IROS). IEEE2017</p>
<p>Sim2real predictivity: Does evaluation in simulation predict real-world performance?. A Kadian, J Truong, A Gokaslan, A Clegg, E Wijmans, S Lee, M Savva, S Chernova, D Batra, IEEE Robotics and Automation Letters. 542020</p>
<p>Scalable safety-critical policy evaluation with accelerated rare event sampling. M Xu, P Huang, F Li, J Zhu, X Qi, K Oguchi, Z Huang, H Lam, D Zhao, 2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE2022</p>
<p>Trustworthy reinforcement learning against intrinsic vulnerabilities: Robustness, safety, and generalizability. M Xu, Z Liu, P Huang, W Ding, Z Cen, B Li, D Zhao, arXiv:2209.080252022arXiv preprint</p>
<p>Airsim: High-fidelity visual and physical simulation for autonomous vehicles. S Shah, D Dey, C Lovett, A Kapoor, Field and Service Robotics: Results of the 11th International Conference. Springer2018</p>
<p>Core challenges in embodied vision-language planning. J Francis, N Kitamura, F Labelle, X Lu, I Navarro, J Oh, Journal of Artificial Intelligence Research. 742022</p>
<p>High fidelity tools for rescue robotics: results and perspectives. S Carpin, J Wang, M Lewis, A Birk, A Jacoff, RoboCup 2005: Robot Soccer World Cup IX 9. Springer2006</p>
<p>Neuralsim: Augmenting differentiable simulators with neural networks. E Heiden, D Millard, E Coumans, Y Sheng, G S Sukhatme, 2021 IEEE International Conference on Robotics and Automation (ICRA). IEEE2021</p>
<p>robosuite: A modular simulation framework and benchmark for robot learning. Y Zhu, J Wong, A Mandlekar, R Martín-Martín, A Joshi, S Nasiriany, Y Zhu, arXivpreprintarXiv:2009.122932020</p>
<p>Closing the sim-to-real loop: Adapting simulation randomization with real world experience. Y Chebotar, A Handa, V Makoviychuk, M Macklin, J Issac, N Ratliff, D Fox, 2019 International Conference on Robotics and Automation (ICRA). IEEE2019</p>
<p>Neural posterior domain randomization. F Muratore, T Gruner, F Wiese, B Belousov, M Gienger, J Peters, Conference on Robot Learning. PMLR2022</p>
<p>Multiparameter real-world system identification using iterative residual tuning. A Allevato, M Pryor, A L Thomaz, Journal of Mechanisms and Robotics. 1332021</p>
<p>Seeing is not believing: Robust reinforcement learning against spurious correlation. W Ding, L Shi, Y Chi, D Zhao, arXiv:2307.079072023arXiv preprint</p>
<p>Generalizing goal-conditioned reinforcement learning with variational causal reasoning. W Ding, H Lin, B Li, D Zhao, arXiv:2207.090812022arXiv preprint</p>
<p>Causalaf: causal autoregressive flow for safety-critical driving scenario generation. W Ding, H Lin, B Li, D Zhao, Conference on Robot Learning. PMLR2023</p>
<p>Active domain randomization. B Mehta, M Diaz, F Golemo, C J Pal, L Paull, Conference on Robot Learning. PMLR2020</p>
<p>Understanding domain randomization for sim-toreal transfer. X Chen, J Hu, C Jin, L Li, L Wang, arXiv:2110.032392021arXiv preprint</p>
<p>How to pick the domain randomization parameters for sim-to-real transfer of reinforcement learning policies?. Q Vuong, S Vikram, H Su, S Gao, H I Christensen, arXiv:1903.117742019arXiv preprint</p>
<p>Data-efficient domain randomization with bayesian optimization. F Muratore, C Eilers, M Gienger, J Peters, IEEE Robotics and Automation Letters. 622021</p>
<p>Deep drone racing: From simulation to reality with domain randomization. A Loquercio, E Kaufmann, R Ranftl, A Dosovitskiy, V Koltun, D Scaramuzza, IEEE Transactions on Robotics. 3612019</p>
<p>Domain randomization and generative models for robotic grasping. J Tobin, L Biewald, R Duan, M Andrychowicz, A Handa, V Kumar, B Mcgrew, A Ray, J Schneider, P Welinder, 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE2018</p>
<p>Robust reinforcement learning as a stackelberg game via adaptively-regularized adversarial training. P Huang, M Xu, F Fang, D Zhao, arXiv:2202.095142022arXiv preprint</p>
<p>Multi-agent manipulation via locomotion using hierarchical sim2real. O Nachum, M Ahn, H Ponte, S Gu, V Kumar, arXiv:1908.052242019arXiv preprint</p>
<p>Group distributionally robust reinforcement learning with hierarchical latent variables. M Xu, P Huang, Y Niu, V Kumar, J Qiu, C Fang, K.-H Lee, X Qi, H Lam, B Li, International Conference on Artificial Intelligence and Statistics. PMLR2023</p>
<p>Tunenet: One-shot residual tuning for system identification and sim-to-real robot task transfer. A Allevato, E S Short, M Pryor, A Thomaz, Conference on Robot Learning. PMLR2020</p>
<p>Auto-tuned sim-to-real transfer. Y Du, O Watkins, T Darrell, P Abbeel, D Pathak, 2021 IEEE International Conference on Robotics and Automation (ICRA). IEEE2021</p>
<p>Exi-net: Explicitly/implicitly conditioned network for multiple environment sim-to-real transfer. T Murooka, M Hamaya, F Drigalski, K Tanaka, Y Ijiri, Conference on Robot Learning. PMLR2021</p>
<p>Sim-to-real transfer for biped locomotion. W Yu, V C Kumar, G Turk, C K Liu, 2019 ieee/rsj international conference on intelligent robots and systems (iros). IEEE2019</p>
<p>Bayessim: adaptive domain randomization via probabilistic inference for robotics simulators. F Ramos, R C Possas, D Fox, arXiv:1906.017282019arXiv preprint</p>
<p>When to trust your model: Model-based policy optimization. M Janner, J Fu, M Zhang, S Levine, Advances in neural information processing systems. 201932</p>
<p>D Abel, arXiv:2203.00397A theory of abstraction in reinforcement learning. 2022arXiv preprint</p>
<p>M Shanahan, M Mitchell, arXiv:2202.05839Abstraction for deep reinforcement learning. 2022arXiv preprint</p>
<p>State abstractions for lifelong reinforcement learning. D Abel, D Arumugam, L Lehnert, M Littman, International Conference on Machine Learning. PMLR2018</p>
<p>Differentiable causal discovery from interventional data. P Brouillard, S Lachapelle, A Lacoste, S Lacoste-Julien, A Drouin, Advances in Neural Information Processing Systems. 202033</p>
<p>Dag-gnn: Dag structure learning with graph neural networks. Y Yu, J Chen, T Gao, M Yu, International Conference on Machine Learning. PMLR2019</p>
<p>S Lachapelle, P Brouillard, T Deleu, S Lacoste-Julien, arXiv:1906.02226Gradient-based neural dag learning. 2019arXiv preprint</p>
<p>E Jang, S Gu, B Poole, arXiv:1611.01144Categorical reparameterization with gumbel-softmax. 2016arXiv preprint</p>
<p>Context is everything: Implicit identification for dynamics adaptation. B Evans, A Thankaraj, L Pinto, 2022 International Conference on Robotics and Automation (ICRA). IEEE2022</p>
<p>Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor. T Haarnoja, A Zhou, P Abbeel, S Levine, International conference on machine learning. PMLR2018</p>
<p>Parameter identification of robot dynamics. P K Khosla, T Kanade, 24th IEEE conference on decision and control. IEEE1985. 1985</p>
<p>Identifiability analysis of planar rigid-body frictional contact. N Fazeli, R Tedrake, A Rodriguez, Robotics Research. 22018</p>
<p>Active domain randomization. B Mehta, M Diaz, F Golemo, C J Pal, L Paull, Proceedings of the Conference on Robot Learning. L P Kaelbling, D Kragic, K Sugiura, the Conference on Robot LearningPMLR10030of Proceedings of Machine Learning Research</p>
<p>Curriculum reinforcement learning using optimal transport via gradual domain adaptation. P Huang, M Xu, J Zhu, L Shi, F Fang, D Zhao, Advances in Neural Information Processing Systems. 202235</p>
<p>On the benefit of optimal transport for curriculum reinforcement learning. P Klink, C D'eramo, J Peters, J Pajarinen, arXiv:2309.140912023arXiv preprint</p>
<p>Outcome-directed reinforcement learning by uncertainty &amp; temporal distance-aware curriculum goal generation. D Cho, S Lee, H J Kim, arXiv:2301.117412023arXiv preprint</p>
<p>free autonomous reinforcement learning via implicit and bidirectional curriculum. J Kim, D Cho, H J Kim, arXiv:2305.099432023arXiv preprint</p>
<p>Pytorch: An imperative style, high-performance deep learning library. A Paszke, S Gross, F Massa, A Lerer, J Bradbury, G Chanan, T Killeen, Z Lin, N Gimelshein, L Antiga, Advances in neural information processing systems. 201932</p>
<p>Sbi -a toolkit for simulation-based inference. A Tejero-Cantero, J Boelts, M Deistler, J.-M Lueckmann, C Durkan, P J Gonc ¸alves, D S Greenberg, J H Macke, 2020</p>
<p>A Hill, A Raffin, M Ernestus, A Gleave, A Kanervisto, R Traore, P Dhariwal, C Hesse, O Klimov, A Nichol, M Plappert, A Radford, J Schulman, S Sidor, Y Wu, Stable baselines. 2018</p>
<p>G Bradski, The OpenCV Library. Dr. Dobb's Journal of Software Tools. 2000</p>
<p>Diffusion policy: Visuomotor policy learning via action diffusion. C Chi, S Feng, Y Du, Z Xu, E Cousineau, B Burchfiel, S Song, Robotics: Science and Systems. 2023</p>
<p>Learning agile and dynamic motor skills for legged robots. J Hwangbo, J Lee, A Dosovitskiy, D Bellicoso, V Tsounis, V Koltun, M Hutter, Science Robotics. 42658722019</p>
<p>A Kumar, Z Fu, D Pathak, J Malik, arXiv:2107.04034Rma: Rapid motor adaptation for legged robots. 2021arXiv preprint</p>
<p>Adapting rapid motor adaptation for bipedal robots. A Kumar, Z Li, J Zeng, D Pathak, K Sreenath, J Malik, 2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE2022</p>
<p>Legged robots that keep on learning: Fine-tuning locomotion policies in the real world. L Smith, J C Kew, X B Peng, S Ha, J Tan, S Levine, 2022 International Conference on Robotics and Automation (ICRA). IEEE2022</p>
<p>Learning domain randomization distributions for training robust locomotion policies. M Mozian, J C G Higuera, D Meger, G Dudek, 2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE2020</p>
<p>Continual vision-based reinforcement learning with group symmetries. S Liu, M Xu, P Huang, X Zhang, Y Liu, K Oguchi, D Zhao, 7th Annual Conference on Robot Learning. 2023</p>            </div>
        </div>

    </div>
</body>
</html>