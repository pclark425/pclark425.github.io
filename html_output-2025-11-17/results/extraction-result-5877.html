<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-5877 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-5877</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-5877</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-119.html">extraction-schema-119</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) or AI systems being used to extract, discover, or distill quantitative laws, mathematical relationships, or empirical equations from large collections of scientific or scholarly papers.</div>
                <p><strong>Paper ID:</strong> paper-270737876</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2406.17809v1.pdf" target="_blank">Towards a Science Exocortex</a></p>
                <p><strong>Paper Abstract:</strong> Artificial intelligence (AI) methods are poised to revolutionize intellectual work, with generative AI enabling automation of text analysis, text generation, and simple decision making or reasoning. The impact to science is only just beginning, but the opportunity is significant since scientific research relies fundamentally on extended chains of cognitive work. Here, we review the state of the art in agentic AI systems, and discuss how these methods could be extended to have even greater impact on science. We propose the development of an exocortex, a synthetic extension of a person's cognition. A science exocortex could be designed as a swarm of AI agents, with each agent individually streamlining specific researcher tasks, and whose inter-communication leads to emergent behavior that greatly extend the researcher's cognition and volition.</p>
                <p><strong>Cost:</strong> 0.016</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e5877.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e5877.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) or AI systems being used to extract, discover, or distill quantitative laws, mathematical relationships, or empirical equations from large collections of scientific or scholarly papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLM (x,y) function distillation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Large language model trained on paired (x,y) data to articulate underlying function f(x)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The paper cites recent work showing that an LLM trained on paired (x,y) examples can infer and verbalize the underlying mapping f(x) (including producing code for it or inverting it), suggesting LLMs can recover mathematical relationships from data pairs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Not specified in this paper beyond 'an LLM trained on (x,y) pairs'; no architecture, size, or training regimen is given here.</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>General scientific data / cross-domain function discovery (paper-level claim, not a specific domain)</td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_description</strong></td>
                            <td>Described only as training on (x,y) pairs; the paper does not provide counts, sources, or preprocessing details.</td>
                        </tr>
                        <tr>
                            <td><strong>distillation_method</strong></td>
                            <td>Supervised training on (x,y) pairs with prompting to produce an explicit functional form (ability to express the function in code and invert it is noted); the paper references this result but gives no implementation details.</td>
                        </tr>
                        <tr>
                            <td><strong>quantitative_law_type</strong></td>
                            <td>Explicit mathematical function (mapping f(x)) inferred from data pairs</td>
                        </tr>
                        <tr>
                            <td><strong>example_law_extracted</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>The paper reports (via citation) that an LLM can articulate underlying functions from (x,y) pairs (including generating code and inverses), but provides no quantitative metrics or experimental details in this review.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>Details are sparse in this paper — generalization, noise robustness, dataset size/coverage, and evaluation procedures are not provided here; the claim is reported as promising but preliminary.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baselines</strong></td>
                            <td>No direct comparisons are provided in this paper; the citation is presented as an existence proof rather than a benchmarked result.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Towards a Science Exocortex', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5877.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e5877.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) or AI systems being used to extract, discover, or distill quantitative laws, mathematical relationships, or empirical equations from large collections of scientific or scholarly papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLM literature value extraction (RAG)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Retrieval-augmented LLM pipelines for systematic extraction and tabulation of quantitative values from the scientific literature</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The paper explicitly identifies an obvious use-case: using LLMs (often combined with retrieval-augmentation) to search corpora and extract/tabulate numeric values and quantities of interest from heterogeneous scientific publications.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Described generically as retrieval-augmented generation (RAG) style LLMs connected to document retrieval; specific LLM architectures or sizes are not given in this paper for this use-case.</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>Scientific literature across domains (examples and emphasis on materials science and other physical sciences are discussed elsewhere in the paper)</td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_description</strong></td>
                            <td>Large corpora of scientific publications / sections thereof (no paper-specific counts or filters provided here); the paper notes heterogeneity in terminology, units, and definitions as a practical challenge.</td>
                        </tr>
                        <tr>
                            <td><strong>distillation_method</strong></td>
                            <td>Document retrieval (RAG) combined with LLM-based extraction and normalization (handling synonyms, unit conversion, and heterogenous reporting); suggested workflows include grounding outputs via retrieved documents to reduce hallucination.</td>
                        </tr>
                        <tr>
                            <td><strong>quantitative_law_type</strong></td>
                            <td>Empirical measurements, tabulated constants, and potentially empirical relationships derived by aggregating tabulated values across publications</td>
                        </tr>
                        <tr>
                            <td><strong>example_law_extracted</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Not specified in this review — the paper suggests human curation/verification and grounding via retrieval as mitigation against errors, but gives no formal evaluation protocol or metrics here.</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>Stated as an established and valuable use-case; the review cites relevant works and notes that domain-specific RAG chatbots and extraction pipelines have been built, but provides no numerical performance figures in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>Heterogeneity of reporting (units, definitions), incomplete machine-readable access to literature, risk of hallucinations, and the need for provenance and high-reliability sourcing for scientific use.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baselines</strong></td>
                            <td>The paper argues conceptually that RAG + LLM extraction is more flexible than simple keyword search or manual curation for handling heterogeneity, but it gives no quantitative baseline comparisons in this review.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Towards a Science Exocortex', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5877.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e5877.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) or AI systems being used to extract, discover, or distill quantitative laws, mathematical relationships, or empirical equations from large collections of scientific or scholarly papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLaMP</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLaMP: Large Language Model Made Powerful for High-fidelity Materials Knowledge Retrieval and Distillation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A referenced work (title appears in the paper's bibliography) that, by its title, targets application of LLM techniques to high-fidelity retrieval and distillation of materials knowledge from literature and data.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>LLaMP: Large Language Model Made Powerful for High-fidelity Materials Knowledge Retrieval and Distillation</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLaMP</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Not described within this review beyond the paper title; the host paper cites it as an example of work on materials knowledge retrieval and distillation but does not provide architecture/size or method details.</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>Materials science (materials knowledge retrieval and distillation)</td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_description</strong></td>
                            <td>Implied to be materials literature / data (the review does not provide corpus size or preprocessing details for the referenced work).</td>
                        </tr>
                        <tr>
                            <td><strong>distillation_method</strong></td>
                            <td>Inferred from the title to involve LLM-based retrieval and distillation workflows for materials knowledge; the review does not give methodological details.</td>
                        </tr>
                        <tr>
                            <td><strong>quantitative_law_type</strong></td>
                            <td>Presumably materials property extraction, tabulation, and distilled empirical knowledge (title implies high-fidelity distillation), but specifics are not given in this review.</td>
                        </tr>
                        <tr>
                            <td><strong>example_law_extracted</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>Referenced as a relevant example; no results or performance metrics are reported in this review.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>Not discussed in the review — any limitations of LLaMP would need to be read from the original referenced work.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baselines</strong></td>
                            <td>Not discussed in this review.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Towards a Science Exocortex', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>LLaMP: Large Language Model Made Powerful for High-fidelity Materials Knowledge Retrieval and Distillation <em>(Rating: 2)</em></li>
                <li>Retrieval-Augmented Generation for Large Language Models: A Survey <em>(Rating: 2)</em></li>
                <li>Learning to Generate Novel Scientific Directions with Contextualized Literature-based Discovery <em>(Rating: 1)</em></li>
                <li>Can large language models provide useful feedback on research papers? A large-scale empirical analysis <em>(Rating: 1)</em></li>
                <li>Connecting the Dots: LLMs can Infer and Verbalize Latent Structure from Disparate Training Data <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-5877",
    "paper_id": "paper-270737876",
    "extraction_schema_id": "extraction-schema-119",
    "extracted_data": [
        {
            "name_short": "LLM (x,y) function distillation",
            "name_full": "Large language model trained on paired (x,y) data to articulate underlying function f(x)",
            "brief_description": "The paper cites recent work showing that an LLM trained on paired (x,y) examples can infer and verbalize the underlying mapping f(x) (including producing code for it or inverting it), suggesting LLMs can recover mathematical relationships from data pairs.",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": null,
            "model_description": "Not specified in this paper beyond 'an LLM trained on (x,y) pairs'; no architecture, size, or training regimen is given here.",
            "task_domain": "General scientific data / cross-domain function discovery (paper-level claim, not a specific domain)",
            "input_corpus_description": "Described only as training on (x,y) pairs; the paper does not provide counts, sources, or preprocessing details.",
            "distillation_method": "Supervised training on (x,y) pairs with prompting to produce an explicit functional form (ability to express the function in code and invert it is noted); the paper references this result but gives no implementation details.",
            "quantitative_law_type": "Explicit mathematical function (mapping f(x)) inferred from data pairs",
            "example_law_extracted": null,
            "evaluation_method": null,
            "results_summary": "The paper reports (via citation) that an LLM can articulate underlying functions from (x,y) pairs (including generating code and inverses), but provides no quantitative metrics or experimental details in this review.",
            "limitations_challenges": "Details are sparse in this paper — generalization, noise robustness, dataset size/coverage, and evaluation procedures are not provided here; the claim is reported as promising but preliminary.",
            "comparison_to_baselines": "No direct comparisons are provided in this paper; the citation is presented as an existence proof rather than a benchmarked result.",
            "uuid": "e5877.0",
            "source_info": {
                "paper_title": "Towards a Science Exocortex",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "LLM literature value extraction (RAG)",
            "name_full": "Retrieval-augmented LLM pipelines for systematic extraction and tabulation of quantitative values from the scientific literature",
            "brief_description": "The paper explicitly identifies an obvious use-case: using LLMs (often combined with retrieval-augmentation) to search corpora and extract/tabulate numeric values and quantities of interest from heterogeneous scientific publications.",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": null,
            "model_description": "Described generically as retrieval-augmented generation (RAG) style LLMs connected to document retrieval; specific LLM architectures or sizes are not given in this paper for this use-case.",
            "task_domain": "Scientific literature across domains (examples and emphasis on materials science and other physical sciences are discussed elsewhere in the paper)",
            "input_corpus_description": "Large corpora of scientific publications / sections thereof (no paper-specific counts or filters provided here); the paper notes heterogeneity in terminology, units, and definitions as a practical challenge.",
            "distillation_method": "Document retrieval (RAG) combined with LLM-based extraction and normalization (handling synonyms, unit conversion, and heterogenous reporting); suggested workflows include grounding outputs via retrieved documents to reduce hallucination.",
            "quantitative_law_type": "Empirical measurements, tabulated constants, and potentially empirical relationships derived by aggregating tabulated values across publications",
            "example_law_extracted": null,
            "evaluation_method": "Not specified in this review — the paper suggests human curation/verification and grounding via retrieval as mitigation against errors, but gives no formal evaluation protocol or metrics here.",
            "results_summary": "Stated as an established and valuable use-case; the review cites relevant works and notes that domain-specific RAG chatbots and extraction pipelines have been built, but provides no numerical performance figures in this paper.",
            "limitations_challenges": "Heterogeneity of reporting (units, definitions), incomplete machine-readable access to literature, risk of hallucinations, and the need for provenance and high-reliability sourcing for scientific use.",
            "comparison_to_baselines": "The paper argues conceptually that RAG + LLM extraction is more flexible than simple keyword search or manual curation for handling heterogeneity, but it gives no quantitative baseline comparisons in this review.",
            "uuid": "e5877.1",
            "source_info": {
                "paper_title": "Towards a Science Exocortex",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "LLaMP",
            "name_full": "LLaMP: Large Language Model Made Powerful for High-fidelity Materials Knowledge Retrieval and Distillation",
            "brief_description": "A referenced work (title appears in the paper's bibliography) that, by its title, targets application of LLM techniques to high-fidelity retrieval and distillation of materials knowledge from literature and data.",
            "citation_title": "LLaMP: Large Language Model Made Powerful for High-fidelity Materials Knowledge Retrieval and Distillation",
            "mention_or_use": "mention",
            "model_name": "LLaMP",
            "model_description": "Not described within this review beyond the paper title; the host paper cites it as an example of work on materials knowledge retrieval and distillation but does not provide architecture/size or method details.",
            "task_domain": "Materials science (materials knowledge retrieval and distillation)",
            "input_corpus_description": "Implied to be materials literature / data (the review does not provide corpus size or preprocessing details for the referenced work).",
            "distillation_method": "Inferred from the title to involve LLM-based retrieval and distillation workflows for materials knowledge; the review does not give methodological details.",
            "quantitative_law_type": "Presumably materials property extraction, tabulation, and distilled empirical knowledge (title implies high-fidelity distillation), but specifics are not given in this review.",
            "example_law_extracted": null,
            "evaluation_method": null,
            "results_summary": "Referenced as a relevant example; no results or performance metrics are reported in this review.",
            "limitations_challenges": "Not discussed in the review — any limitations of LLaMP would need to be read from the original referenced work.",
            "comparison_to_baselines": "Not discussed in this review.",
            "uuid": "e5877.2",
            "source_info": {
                "paper_title": "Towards a Science Exocortex",
                "publication_date_yy_mm": "2024-06"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "LLaMP: Large Language Model Made Powerful for High-fidelity Materials Knowledge Retrieval and Distillation",
            "rating": 2,
            "sanitized_title": "llamp_large_language_model_made_powerful_for_highfidelity_materials_knowledge_retrieval_and_distillation"
        },
        {
            "paper_title": "Retrieval-Augmented Generation for Large Language Models: A Survey",
            "rating": 2,
            "sanitized_title": "retrievalaugmented_generation_for_large_language_models_a_survey"
        },
        {
            "paper_title": "Learning to Generate Novel Scientific Directions with Contextualized Literature-based Discovery",
            "rating": 1,
            "sanitized_title": "learning_to_generate_novel_scientific_directions_with_contextualized_literaturebased_discovery"
        },
        {
            "paper_title": "Can large language models provide useful feedback on research papers? A large-scale empirical analysis",
            "rating": 1,
            "sanitized_title": "can_large_language_models_provide_useful_feedback_on_research_papers_a_largescale_empirical_analysis"
        },
        {
            "paper_title": "Connecting the Dots: LLMs can Infer and Verbalize Latent Structure from Disparate Training Data",
            "rating": 2,
            "sanitized_title": "connecting_the_dots_llms_can_infer_and_verbalize_latent_structure_from_disparate_training_data"
        }
    ],
    "cost": 0.016233499999999998,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Towards a Science Exocortex
24 Jun 2024</p>
<p>Kevin G Yager 
Center for Functional Nanomaterials
Brookhaven National Laboratory
11973UptonNew YorkUnited States</p>
<p>Towards a Science Exocortex
24 Jun 20241841B1CB5C99F8EDB3AA5FC8A636468EarXiv:2406.17809v1[cs.AI]
Artificial intelligence (AI) methods are poised to revolutionize intellectual work, with generative AI enabling automation of text analysis, text generation, and simple decision making or reasoning.The impact to science is only just beginning, but the opportunity is significant since scientific research relies fundamentally on extended chains of cognitive work.Here, we review the state of the art in agentic AI systems, and discuss how these methods could be extended to have even greater impact on science.We propose the development of an exocortex, a synthetic extension of a person's cognition.A science exocortex could be designed as a swarm of AI agents, with each agent individually streamlining specific researcher tasks, and whose inter-communication leads to emergent behavior that greatly extend the researcher's cognition and volition.</p>
<p>Introduction</p>
<p>Artificial intelligence and machine-learning (AI/ML) methods are having growing impact across a wide range of field, including the physical sciences.[1][2][3][4][5][6] Generative foundation models, in particular, are displacing a swath of other methods.Foundation models involve extensive training of deep neural networks on enormous datasets in a task-agnostic manner.[7,8] Generative methods (genAI), often employing the transformer architecture, [9] seek to create novel outputs that conform to the statistical structure of training data, [10,11] enabling (e.g.) image synthesis [12][13][14] or text generation.[15] Large language models (LLMs) are generative models trained on text completion, but which can be adapted to a variety of tasks, including text classification, sentiment analysis, code or document generation, or interactive chatbots that respond to users in natural language.[7,[16][17][18] The performance of LLMs increases with the scale of the training data, network size, and training time.[19][20][21] There is growing evidence that LLMs do not merely reproduce surface statistics, but learn a meaningful world model; [22][23][24][25][26][27] one correspondingly observes sudden leaps in capabilities during training, suggesting the emergent learning of generalized concepts.[25,[28][29][30][31] LLMs can be tailored via reinforcement learning using human feedback (RLHF), [32][33][34][35] so that particular behaviors (e.g.helpful and truthful) are emphasized during generation.Generation quality can be improved by connecting to a corpus of trusted documents, which allows production of replies that are sourced and grounded (so-called retrieval augmented generation, RAG).[36][37][38][39] While LLMs are often viewed purely as text-generators (e.g. for chat interactions), they have transformative potential owing to their ability to generate decisions and plans.For instance, LLMs can trigger software tools Figure 1: An exocortex seeks to augment human intelligence by connecting computation systems to a person.A science exocortex could be implemented as a swarm of specialized AI agents, operating on behalf of the human researcher, including agents for controlling experimental systems, for exploring data and synthesizing it into knowledge, and for exploring literature and ideation.The AI agents would connect to science components (instruments, databases, software, etc.) and streamline access.Crucially, the AI agents communicate with one another, working on tasks on behalf of the user and only surfacing the most important decisions and outputs for human consideration.If successful, such a system would allow researchers to handle the enormity of modern scientific knowledge, and accelerate discovery and dissemination of new science.Karpathy).While LLMs perform text generation, Karpathy has proposed to view them instead as kernels-orchestration agents-of a new kind of operating system.[40,41] In this paradigm, the LLM is responsible for accessing resources (e.g.documents) or triggering actions (calculations, web browsing, etc.), and feeding results to a desired interface (e.g.chatbot dialog).The ability of LLMs to perform (rudimentary) decision-making can thus be exploited to coordinate more complex activity in response to relatively vague commands (which may come from a human or another LLM system).by providing them access to application programming interfaces (APIs).[42][43][44][45][46][47][48][49][50] Generations can be improved by inducing self-critique of output quality, [51,52] or creating chains of thought through iterative self-prompting.[53][54][55] These systems can be turned into task-oriented autonomous agents by allowing them to iteratively propose and execute solutions.[46,[56][57][58][59] The impressive capabilities of LLMs presage a paradigm shift in the way intellectual work is performed, as they empower humans to delegate many tasks to the LLM and instead focus on the highest-level deliberation and planning.However, there remain many outstanding questions about what system architecture and humancomputer interactions (HCI) will best leverage these capabilities.Adaptation of these methods to scientific domains requires even deeper consideration, as science and engineering tasks are extremely technical and require high reliability and sourcing for both information and arguments.</p>
<p>Here, we explore the concept of an exocortex-an artificial extension to the human brain that provides additional cognitive capabilities.While future implementations of this concept might employ brain-computer interfaces (BCIs), [60] we argue that progress can be made by leveraging existing HCI methods to connect the human to a swarm of inter-communicating AI agents.If the individual agents are sufficiently capable, and their interactions sufficiently coherent, then the emergent activity could feel, to the human operator, as an empowering expansion to their mental capabilities.</p>
<p>We focus in particular on the concept of a science exocortex-meant to expand a researcher's intelligence and scientific reasoning-and propose some concrete architectural ideas.We propose an implementation (Figure 1) using a swarm of AI agents that operate on behalf of the human user, and which-importantly-communicate with one another and thereby reserve human interaction only for high-value ideas and important decisions.We define specific categories of required agents, including some focused on orchestrating experiments, others on data and software, and others on scientific literature.Although highly speculative, we hope the ideas presented herein stimulate further research on AI agents optimized for science, and their integration into systems that empower human researchers.</p>
<p>Discussion</p>
<p>LLMs natively output streams of tokens, and are by default used to generate text for humans to read, as in the canonical use as chatbots.However, a narrow interpretation of LLMs would miss their most significant capability: their outputs can be used as decisions, allowing one to automate (simple) cognitive tasks.Karpathy provides a provocative vision for the future of LLMs, wherein they act as kernels (orchestration agents) of a diverse set of capabilities (Figure 2).[40,41] In a conventional operating system (OS), the kernel is a privileged software process that manages resource distribution and inter-process communication, allowing the end-user to access software systems, files on disk, network resources, and other services.By analogy, one can imagine a sort of AI OS, where the orchestration abilities of the LLM are leveraged to intelligently trigger the appropriate tool (via APIs, [42][43][44][45][46][47][48][49][50] code execution, etc.), retrieve relevant content (via RAG [36][37][38][39], web browsing, etc.), and reformulate it into a form suitable for human consumption (text, images, audio, etc.).The crucial insight is that the LLM enables orchestration of tasks and resources, and aggregation of data sources, in a much more abstracted and high-level manner than is traditionally thought of as possible for software systems.</p>
<p>The exocortex concept takes this idea seriously, and expands upon it to propose that a swarm of agents could handle complex tasks.Each agent would operate in the manner depicted in Figure 2, optimized for a particular task (by tailoring the available tools/documents, the prompting and scaffolding that dictate its input/output behavior, etc.).The interaction of agents, each acting as a sort of primitive cognitive module, could then lead to emergent capabilities in the whole.</p>
<p>Achieving this vision will be difficult, requiring solving a cascade of research challenges.Research is required to determine how best to exploit LLMs to generate agentic modules that can perform tasks autonomously (over short timescales) by iterating on a problem.Specialization of these agents to scientific problems will require additional consideration.The software infrastructure to have agents run over longer time periods, and intercommunicate productively, will need to be developed.The correct inter-agent organizational and communication structure will need to be identified.And, finally, the appropriate interface between the ecosystem of AI agents, and the human operator, will need to be developed.Below we provide initial thoughts on these various challenges.are possible using an architecture where task plans and status are captured in an explicit tree structure, which provides a flexible way to organize complex hierarchies.[59] Tree structures can be efficiently searched (e.g.Monte Carlo tree search) for reasoning and planning, yielding improvements in many tasks including math.[69][70][71][72][73] Additional research will be required to adapt agentic LLM approaches to scientific problems.Straightforward improvements would arise from training or fine-tuning LLMs on scientific documents, to ensure understanding of the relevant topics.Document retrieval can also easily improve LLM performance on scientific tasks.[37] Additional LLM specializations for science should also be considered.Golkar et al. proposed xVal, a specialized token encoding for numbers (scaling a dedicated embedding vector) which improves LLM handling of numerical tasks.[74] McLeish et al. used special positional embeddings (relative to start of number) and demonstrated vastly improved performance and generalization on simple arithmetic (addition and multiplication) tasks.[75] Xu et al. integrated symbolic expressions and logic rules into a chain-of-thought prompting strategy, demonstrating improved reasoning on logical tasks since the LLM was invoking formal logic and symbol manipulation during the solution.[55] Trinh et al. combined a language model with a symbolic solver to handle geometry theorems.[76] These kinds of approaches appear promising, suggesting that LLMs with slight adaptations could yield vastly improved reasoning for science and engineering tasks.</p>
<p>An advantage of the exocortex architecture is that it can easily integrate more advanced AI agents as they are developed by others.In other words, we propose to separate the design/function of agents from their intercommunication, so that new agents can be added to the exocortex easily (by simply building a wrapper that supports the expected messaging between agents).The goal is to be able to leverage the growing ecosystem of AI modules being developed for science, including for simulating complex systems, [77] fluid dynamics, [78] crystallography, [79], chemistry tools, [80] protein representation [81] and design, [82] and pathology images.[83,84]</p>
<p>Autonomous Experimentation</p>
<p>Autonomous experimentation (AE) is an emerging paradigm for accelerating scientific discovery, leveraging AI/ML to automate the entire experimental loop, notably the decision-making step.[85,86] AE aims not to merely quantitatively accelerate, but also to qualitatively improve experiment execution by having an algorithm adaptively select optimal experiments.It seeks not to replace the human researcher, but to liberate them to operate at a higher level of abstraction where they can focus on scientific meaning instead of micro-managing experimental details.[86,87] Progress in AE has grown rapidly over the last few years, transitioning from proof-of-principle to true discovery of new science.[88][89][90][91][92][93][94][95][96][97][98][99][100][101][102][103][104][105][106] The AI control module may exploit reinforcement learning, [100,107] though a highly popular approach is to exploit Bayesian methods [108] (such as a Gaussian process, [97,109] GP) since this provides rigorous modeling of a data surrogate and associated uncertainty.AE methods are increasing in sophistication, including demonstration of multi-modal autonomous experiments integrating multiple measurement systems.[110] Instead of treating the AE system as an autonomous loop initiated and monitored by the human researcher, one can envision it as a module in the exocortex, which can be activated and monitored by other AI agents.Enabling this capability would require relatively little change to existing AE architectures.Primarily, one would need to define a simple software API or natural-language interface for AE parameters and actions.Doing so would increase the power of AE systems, as they could more easily integrate physics-informed priors arising from literature or preexisting datasets.</p>
<p>Experimental Assistant</p>
<p>A highly consequential type of AI agent for science is one that negotiates control of some experimental tool on behalf of the researcher.Building such an agent requires the experimental system to already be highly automated, such that the agent can trigger operations (synthesis, measurement, etc.) and retrieve generated data.However, as more and more platforms naturally shift towards higher levels of automation, the prospects for AI control improve.Many high-end measurement tools provide highly software-driven interfaces, including electron microscopes, [98,99] scanning probe instruments, [98,111,112] and synchrotron [104,113] or free electron laser (FEL) [114][115][116] beamlines.Recent work has also demonstrated automated workflows [105,[117][118][119][120] or modular platforms [121][122][123] for lab experiments.The rapidly advancing capabilities of AI robotic control [124][125][126][127][128][129][130] suggest that broader ranges of manual laboratory tasks will soon be amenable to automation.</p>
<p>The next step is thus to design AI agents that can access the capabilities of these automated systems.Preliminary work has already demonstrated the viability of LLM-based agents for controlling scientific instruments.[80,[131][132][133] AI experimental assistants can allow the human to phrase commands in natural-language, whereupon the LLM can convert this into action through API calls or code generation.[5] The assistant can help to integrate experimental and data analysis steps, making it easier to see the consequences of measurements and to iterate more quickly on the problem being studied.Experimental assistants can also act as tutors, e.g.generating initial control code for a user unfamiliar with a particular instrument.The approach is flexible, and can easily be adapted to changing instrument conditions by updating documentation that is added to the LLM's context during operation.</p>
<p>Data Exploration</p>
<p>Scientific discovery involves collecting, processing, and analyzing datasets of many types.In answering a scientific problem, researchers will integrate a wide variety of data sources, including lab notes, instrument outputs (images, spectra, etc.), simulation results, and a succession of derivative data products created through analysis.Tracking, organizing, and visualizing these datasets is extremely challenging.An acute challenge for a modern researcher is the interdisciplinary nature of many frontier topics, which correspondingly means dealing with a heterogeneity of datasets coming from different sources, and following different conventions for formatting and meta-data.</p>
<p>AI assistants could play an important role in alleviating this burden, by automating many routine tasks in data triage and reformatting, and by automatically triggering the required pipeline for automated data processing.The heterogeneity of data can possibly be handled using foundation models.[8] Whereas in the past application of machine-learning to science required training bespoke models on carefully-labelled datasets specific that science topic, foundation models trained on vast quantities of unlabelled data should be able to learn generic representations that are useful.For instance, it was found that the Contrastive Language-Image Pre-training (CLIP) model [134] trained on generic Internet image data could be used to assess similarity for scanning electron microscopy and x-ray scattering datasets, without any retraining or fine-tuning.[37] Many scientific datasets are images, or can be converted into images.Thus a powerful approach for AI data assistants is to exploit multi-modal language/vision models.[84,[134][135][136][137] Indeed, humans generally consume data as images, in the form of graphs and plots; this visual formulation of the data has the advantage of being ready-to-deploy, human-readable, and already well-represented in existing training sources (publications).Exploiting multi-modal models as data assistants is still in its infancy, but early systems [83,[138][139][140][141][142] show promise.</p>
<p>Knowledge Mapping</p>
<p>A grand challenge in data science is to integrate data from disparate sources into a single model.Human scientists excel at this task, as they integrate insights provided from experimental data, calculations, literature they recall, and intuitions informed by years of scientific practice.When thinking about or discussing a complex topic, human scientists will naturally jump between different levels of abstraction and thus different scientific models.This combination of models (some highly quantitative, others heuristic) allows human scientists to compensate for the deficiencies in one model/reasoning by leveraging another.Approximating this efficient behavior in a synthetic knowledge system is challenging.</p>
<p>A core challenge is to align disparate observations of the same physical signal; that is, to account for the unknown disparity between models arising from systematic errors, different underlying assumptions, mismatched definitions, etc.Consider a simple signal for a material system (e.g.crystalline grain size) as a function of a physical parameter (e.g.temperature).Despite the independent/dependent variables being well-defined within one model (observation), matching between models may not be trivial.For instance, a physical measurement might use absolute real-world temperature (in Kelvin units) while an associated coarse-grained simulation might rely on a unitless abstracted temperature variable.(Obviously the two quantities are closely related; but the mapping function between them is typically not known.)The measurement of grain size by different techniques may not match owing to different definitions (e.g.volumetric vs. aerial averaging).[143] Thus, it can be challenging to merge datasets relevant to the same physical problem, even when they are individually trustworthy and robust.The problem becomes harder still as input data sources become more heterogeneous and ill-defined (heuristic classifications, text descriptions, scientist intuitions, etc.).</p>
<p>The simplest approach to this problem might be to exploit contrastive learning.For instance, the CLIP[134] model uses two encoder pathways: one for text and one for images.The method also computes a similarity matrix between the two latent spaces (cosine similarity for text/image pairs), where part of the training loss seeks to maximize the diagonal and minimize the off-diagonal elements.In this way, the text and image latent spaces align, allowing cross-modal learning and applications.In principle, a similar approach could be used for scientific data.Datasets and their associated text descriptions could be used as training pairs, or different observations of the same physical phenomenon (e.g.experimental measurements and corresponding simulations) could be combined if some pairwise associations were manually identified.Recent work increasing the number of modalities appears promising.[144,145] Nevertheless, it may be challenging to scale this approach by itself, to handle the heterogeneity, complexity, and sparsity of realistic laboratory datasets.</p>
<p>A more sophisticated approach to this problem is to train multi-modal foundation models on scientific datasets.[6] The Polymathic AI effort is proposing to train AI models for science on a breadth of data, [146] which can then be specialized for any particular application by exploiting the latent representations or via Figure 3: Knowledge mapping is an attempt to align and aggregate a variety of data sources about a particular scientific problem into a single model.One architecture for accomplishing this is shown.Available data is organized into signals of interest (such as physical measurables, material properties, or functional metrics).One typically has a variety of estimates or observations for a given signal, arising from different experiments, calculations, or theories.In principle these observations already map into a common space; in practice there are complex and often unknown disparities between the observations, owing to measurement errors, disparate definitions, or different assumptions.Thus, some non-linear transformation (e.g.accomplished using neural networks) is required to combine them into a single predictive model.Models for distinct signals can be crosscorrelated to identify inter-relations; this can effectively combine the models into a single multi-modal model.problem-specific fine-tuning.Cranmer argues that doing otherwise (e.g.training an ML model for science using random initialization) is inefficient as it ignores the wealth of well-understood scientific priors.[147] Initial results for this approach are promising, [148,149] with (e.g.) multi-physics pretraining on system dynamics improving subsequent predictions on new systems.The approach involves projecting the fields for different kinds of physical systems into a shared embedding space.The central generative model (based on transformers) thus learns meaningful physics, while the dataset-specific embedding/normalization schemes capture the differences between the physical systems.</p>
<p>A closely-related approach would be to train multi-modal foundation models on science data, so that these models could be queried to explore trends in the data.Recent work [150] has shown that an LLM trained on (x, y) pairs can articulate the function f (x) that underlies the transformation (can define it in code, can invert it, etc.).If this result generalizes, it implies that LLMs trained on raw science data could coherently describe the data, make predictions based on the underlying functions, and so on.</p>
<p>A different way to formulate this task (Figure 3) is to focus on integrated modeling of all the signals defined in physical parameter spaces for a given problem (e.g.class of materials).For a given signal, a variety of different observations might be available (from experiments, simulation, theory, etc.), with tradeoffs between signals (in terms of sampling density, error bars, validity in different parts of parameter space, etc.).Signals could be combined into a merged model by learning a non-linear transformation that maps them into a common space and maximizes their overlap (using, e.g., variants of the methods described above).The combined datasets could be interpolated using a Gaussian process or other nonparametric method, [97,109] leveraging physics-informed constraints to further improve the model (e.g. via tailored kernel design [103,151]) and acceleration methods to reduce computation cost.[152,153] The set of models could also be cross-correlated, to identify connections and scientific trends between signals (or establishing lack thereof).GP modeling of correlated signals would also allow interpolation of signals into parts of spaces where they were not explicitly measured (effectively using a correlated measurement as a sort of proxy signal).Conceptually, the set of signals (and covariance matrix between them) represents a final rich multi-modal model of full system behavior.This unified model could be used for predictions, searching for trends and novel physics, or as a guide for future discovery (identifying under-sampled regions, suggesting high-performing materials, etc.).</p>
<p>An even more speculative approach would be to attempt to adapt methods of generative world synthesis to scientific data.There has been enormous progress in generative synthesis of images (2D data), [12][13][14] objects (3D), [154,[154][155][156][157][158][159][160][161][162][163] and video (3D).[164][165][166][167][168][169] Neural radiance fields [170] and Gaussian splatting [171] have emerged as efficient methods for reconstructing and representing 3D scenes (where input images act as projective constraints).These methods have been extended to capture [172][173][174] or synthesize [175][176][177][178][179] changes over time (4D).These methods are efficient, [180,181] scalable, [182] and amenable to in/out-painting.[183,184] In addition to obvious applications in content generation, these methods are seeing adoption for autonomous driving [185] and robotics.[186][187][188][189] The trajectory of these development suggests neural synthesis of virtual world, [169] wherein immersive 3D environments are generated and animated/evolved, using real-world reconstructions and/or user text commands as inputs.We suggest that this approach could be applied, in higher-dimensional spaces, to scientific datasets.The partial measurements made in scientific experiments can act as constraints (conceptually a projective view of the full higher-dimensional space), where the objective is to reconstruct a consolidated model consistent with all the data (i.e.merge datasets and modalities) and to generatively fill unmeasured parts of the space using an informed model (i.e.interpolate and extrapolate in a physics-aware manner).Considerable work would be required to recast existing methods to handle the dimensionality and different constraints of scientific data in physical parameter spaces; but the efficient representations being developed for simulating the real world may well hold useful insights for representing other kinds of coherent data-spaces.</p>
<p>Literature Discovery</p>
<p>The scale of the research literature is continually growing, making it increasingly difficult for researchers to maintain awareness of important trends or singular results.Conversely, this enormous scientific corpus is a trove of insights that should be more fully leveraged.Literature Based Discovery (LBD) [190][191][192] has a long history of increasingly sophisticated methods and software being developed for mining the literature, identifying connections across domains, and otherwise streamlining literature research.AI methods, and LLMs in particular, are well-positioned to greatly accelerate these processes, automating knowledge extraction from publications.[193] An obvious use-case is to systematically search through a corpus in order to extract and tabulate values for quantities of interest.[194][195][196] Here, the flexibility of LLMs can enable extraction that handles the heterogeneity arising from synonyms, different definitions or units of measure, and so on.</p>
<p>LLMs can be combined with document retrieval (RAG) to allow users to rapidly identify relevant documents (or sub-sections thereof) and immediately incorporate them into reasoning or question-answering.RAG LLMs have been used to build domain-specific chatbots for science, [37] and to provide an interface to vast materials data that can be distilled as requested by the user.[196] More generally, the AI model can be exploited as a copilot to help the user exploit specialized knowledge or tools, as has been demonstrated for catalyst research, [197] chemistry experiments, [58] and chemistry tools.[80] A valid concern is that the reasoning of LLMs-being well below human scientists-would be insufficient to be useful.However, when designed as a co-pilot, such systems can offer substantial value.LLMs can exploit the systematic compositionality of language (and thus ideas), which enables them to generalize in useful ways.[198] Evidence shows that dialoging with LLMs can indeed help researchers.[2,199] LLMs can also be exploited to automate tedious tasks.For instance, they can be used for ranking [37,200] or classifying [37] scientific documents.This opens up a new possibility for researcher engagement with the literature, beyond the conventional activities of periodically searching for articles of interest and keeping a watch for relevant articles through networks (peers or automated).LLMs could be used to search, organize, rank, triage, and summarize papers, and thereby identify the most pertinent publications for human consideration.</p>
<p>LBD has a strong history of exploiting network analysis to understand the science corpus, including using predictive knowledge networks.[201,202] An interesting possibility would be to exploit modern foundation models as another form of network analysis.The semantic embedding provided by these models could offer a rich means of identifying connections (or lack thereof) in the literature.For instance, clusters of publications that are semantically similar but not cross-citing one other could represent inefficiency (duplicative efforts unaware of each other), while clusters that are highly correlated in a subset of embedding dimensions (but divergent in others) could represent opportunities for collaboration.</p>
<p>Autonomous Ideation</p>
<p>A novel use for LLMs would be to help automate the task of generating and evaluating scientific ideas, including research plans, testable hypotheses, experimental plans, and predictive theories.These cognitive tasks are among the most high-level performed by human scientists, and as such least likely to be fully automated by LLMs in the foreseeable future.On the other hand, the process of human ideation involves many secondary cognitive activities that could be automated.[203] Thus, autonomous ideation seeks to generation loops of machine-driven brainstorming and evaluation, bringing high-value ideas to the human's attention for further consideration.</p>
<p>Existing work in LBD has begun to tackle the question of how to use natural language processing and LLMs for hypothesis generation or other scientific ideation tasks.A central question is whether LLMs can be creative at all.LLMs are trained statistically on a large document corpus, and can be viewed as generating novel text that are interpolations in a semantic space.Such generations can be factual (correctly composing Figure 4: Autonomous ideation aims for the AI agent to develop new scientific ideas (novel research directions, testable hypotheses, actionable research plans).One possible system design is to treat the task simialr to an autonomous experimentation loop, wherein one is exploring a multi-dimensional parameter space.In ideation, one can define the space of ideas using embedding vectors to position each idea.Each idea can be scored using an LLM ranking procedure.The loop consists of selecting a region for exploration (e.g. based on some combination of local sparsity, model error, and quality-maximization), generating ideas in that region (e.g. using an LLM provided with documents/ideas from the local neighborhood), and ranking the resultant ideas.As the loop proceeds, the space becomes populated with ideas.The top generations can eventually be presented to the human for consideration.ideas in the training data) or erroneous "hallucinations" (or confabulations).Hallucinations can be partially mitigated by detecting them through generation uncertainty, [204] or by grounding responses using RAG.[36][37][38][39] Although hallucinations are generally undesirable, their existence is intrinsic [205] and there is a tradeoff between hallucinations and creativity.[206] In other words, some amount of hallucination is desirable, to enhance creativity and communication.[207] More broadly, evaluations of LLM creativity suggest that they can generate outputs that are non-trivially novel and useful to humans.[208][209][210][211][212] Language models have demonstrated utility for hypothesis generation, [213,214] or as generators for novel ideas.[203,215,216] The most direct way to use LLMs for ideation is as a chatbot assistant to a human researcher.A more automated design would leverage agentic AI operating in loops, so that a group of LLMs propose and critique ideas, and then rank [37,200] these ideas in order to identify the most promising.A more structured (but speculative) approach is to treat the task of autonomous ideation as being analogous to autonomous experimentation, [86] wherein an ML decision-making algorithm selects points in a physical parameter space for measurement.In autonomous ideation, one could analogously select points in the semantic "space of ideas" for exploration (Figure 4).More specifically, the search space is defined using a semantic vector (e.g.text embedding) and the target signal in that space is defined using LLM ranking of the ideas.On each loop, a new region is selected for exploration, using a modeling process that can consider both idea ranking (bias towards high-quality regions), and uncertainty (explore under-sampled or high-error regions).This modeling can exploit Gaussian process methods to naturally capture uncertainty and learn hyper-parameters that describe the semantics being explored.Once a point is selected, an LLM generates new ideas at that position by (e.g.) sampling a local neighborhood [216] of ideas or documents in order to generate new content.This generation is ranked to quantify it as a signal, which is fed back into the loop.As this procedure continues, it will naturally fill the semantic space of ideas, balancing between exploration and exploitation, and providing a surrogate model for idea quality in the subspace selected for search.It is an open question whether Bayesian modeling can meaningfully be applied to the inherently vague space and signals associated with ideation.But the AE framework provides a robust starting point for rigorously testing various idea exploration schemes.</p>
<p>A different ideation design would be to leverage ongoing work in visualizing and interpreting the internal state of the LLM.While neural networks are often described as inscrutable black boxes, there has been enormous progress in interpreting their structure and the latent spaces in which they operate.In vision models, the role of neurons and circuits can be interpreted by visualizing strong activation patterns.[217] In language models, tasks learned in-context can be understood as a simple function vector that capture the relevant input-output behavior.[218,219] A particular direction in the model's internal state can be associated with specific behavior, such as refusal to respond [220] (allowing that behavior to be selectively amplified or weakened).Identifying internal circuits associated with particular concepts allows one to build "circuit breakers" to suppress undesired output.[221] Natural hierarchies of concepts-which occur throughout natural language and especially in scientific ontologies-are represented in the model's internal vectorial space as polytopes that can be decomposed into simplexes of mutually-exclusive categories.[222,223] Model activations can be interpreted using human concepts, if they are projected into a higher-dimensional space to disentangle them.[224][225][226] These interpretability insights are often exploited for alignment, [227] to elicit safe and desirable model behavior.However, they could also be used to directly explore the landscape of ideas.For instance, visualizing the internal ontology for a scientific sub-space might allow researchers to identify regions of unexplored concepts, or to see fruitful crossconnections between ideas that are typically considered unrelated.Searching the structure of this space for common patterns could further reveal new connections or universal motifs.Being able to directly alter the activation or geometry of the semantic space, and observing LLM output, provides another avenue for generating novel ideas in a highly directed way.This research thrust would require researchers building new intuitions about how to understand and navigate the complex spaces internal to LLMs.</p>
<p>More generally, strategies originally intended for model tuning or alignment could all be co-opted for ideation.For instance, one could block off exploration of ideas known to be fruitless, or conversely emphasize desired modes-of-thought.Viable strategies include fine-tuning, [228][229][230] RLHF [32][33][34] (including AI-assisted [35]), constitutional adherence, [231] preference ranking, [232], instruction backtranslation, [233] principle-driven selfalignment, [234] or eliciting latent knowledge.[235][236][237]</p>
<p>Exocortex System</p>
<p>The proposed exocortex design will behave as a system of interconnected AI agents, some of which can also communicate directly with the human researcher.The correct design for this system is an open research and engineering challenge.Nevertheless, we can begin to propose and test designs.One of the simplest implementations would be for each researcher to build a personalized network by selecting among pre-existing AI agents, and defining connections between them based on desired workflows.Communication between agents could thus be managed with point-to-point message queues.This approach is not very scalable, however.An alternative would be to establish a central database where inter-agent messages are accumulated, and build code that manages communications, using user-defined heuristics to decide when incoming messages require returning to the same agent for revision, launching a new agent, passing to a running agent, or bringing to the human's attention.Likely there are yet better designs possible if one treats the agent-interaction problem as a large machine-learning task.By selecting a flexible design (e.g. based on graph neural networks), an automated optimization process could create/eliminate connections in order to build dynamic workflows.Much of the work on within-agent iteration and looping can be exploited to improve inter-agent workflows.</p>
<p>In all these schemes, signals between agents can take the form of plaintext messages.This has the advantage of being highly legible to the human operators, [238] allowing them to understand commands, make improvements, and even extract scientific value from intermediate products.As the number of agent types increases, the diversity of possible inter-agent cooperations increases quadratically, while the space of possible workflows grows exponentially.Example messages that might be sent between agents are shown in Table 1.Legible inter-agent messages will allow the human operator to inspect, at will, operation of the system, including editing an agent's message before it is executed by another agent.</p>
<p>The complexity of interconnected agents, and the non-standardized (text-based) messaging between them poses a problem for automated monitoring, analysis, and optimization of these systems.On the other hand, it is possible that existing approaches for systems engineering can be recast to the context of AI swarms.For instance, machine-learning has benefiting enormously from gradient backpropagation, [239] which has essentially automated the process of optimizing complex neural network and AI models.By analogy, Yuksekgonul et al. proposed TextGrad as a text-based "differentiation" of AI systems.[240] Natural language feedback (e.g.criticism) of system outputs can be used as scores (analogous to loss), the variation in score as a function of changes in prompt can be used as a gradient, and gradients can be propagated across the system with knowledge of architecture.This allows automated optimization of LLM-interaction networks.Further developing techniques such as this may be crucial to properly optimzing exocortex-like systems.</p>
<p>The goal of the exocortex is to augment a human scientist's intelligence.This objective is predicated on the assumption of emergence at two levels: one, that the swarm of AI agents will, through coordination, exhibit intelligence greater than the naive summation of their respective abilities; and two, that the combination of exocortex agents and human thinking will enable greater effective intelligence.To succeed, the exocortex architecture must thus enable this outcome.The correct design remains an open research question.However, we propose that analogies to human cognition can aid in the design.</p>
<p>AI-AI Interactions</p>
<p>LLMs generate ideas and decisions, but they are quite primitive in the sense that the ideas are reflexive rather than resulting from deep introspection.[238] The repeated waves of processing that occur within an LLM as it proceeds through tokens provides an opportunity to build-up more complex assessments, with the current understanding represented as updates to the residual stream.Improved behavior can thus be elicited by inducing the model to explicitly output reasoning steps.[241,242] Interestingly, introducing even meaningless filler tokens into the output provides improved performance, [243] presumably owing to the additional computation cycles    that are invoked.And yet, LLMs implement a relatively primitive and unidirectional method of thinking, as they are unable to revise the serialized output.Multiple research efforts aim to improve this by introducing a sort of deliberation cycle, such as by triggering self-critique of output, [51,52] or generating chains of thought through iterative self-prompting.[53][54][55] Exploiting tree search (e.g.Monte Carlo) can further improve quality, especially on math problems.[69][70][71][72] For scientific applications, versions of these methods that explicitly invoke formal logic are especially attractive.[55] One can also provide pre-designed thought-templates to improve reasoning on selected tasks; [244] building a catalog of templates for scientific tasks would be beneficial.</p>
<p>Another means of generating improved output is to construct "societies" of semi-specialized AI agents, and allow them to communicate and cooperate on a task.The hope is that specialization improves diversity and allows task-specific targeting, and that the emergent quality of collective output is higher than for any individual agent.Although this approach is only nascent, [57,[245][246][247][248][249][250][251] there are early suggestions that it can improve task performance in contrived contexts (e.g.games [252,253]) and applications (e.g.code generation [254] and translation [255]).One can also use synthetic analogs of cultural transmission to improve learning of AI swarms.[256,257] Interaction between agents can be [250] cooperative, debating, or competitive.Agents can be organized into flat structures, where each agent is equivalent (e.g.voting on answers/decisions), or hierarchically, where top-level agents assign tasks to workers, and aggregate outputs.Different tasks will, of course, call for different organizational structures.However, there are often clear advantages to establishing hierarchies and workflows, [248] especially where one can draw inspiration from human organizational structures.</p>
<p>Instead of emulating human social structures, an alternate architecture is mixture-of-agents, [251] which organizes AI blocks into layers reminiscent of neural networks (where each node is an LLM instead of a synapse).The input prompt is fed into a layer of models that propose independent responses, an aggregator synthesizes the responses into an improved output, and this is is fed into the next layer.Thus, response quality progressively improves across layers, as more reconsideration is performed.By including different LLMs within a layer, one can improve diversity and allow for models to compensate for each other's weaknesses.Performance can also be optimized by correct selection of models within layers.The architecture is rationalized and organized, and amenable to rescaling (changing number of agents per layer, number of layers, etc.) to optimize for a particular task.This work demonstrated significantly improved outputs, compared to single-shot use of any underlying model, and demonstrated that a final aggregation LLM call (rather than ranking and selecting the best output so far) improves generation.This supports the idea that agent interactions can lead to emergent capabilities greater than any individual agent.The iterative processing may also make multi-agent setups amenable to longer-horizon tasks (e.g.longer text analysis or generation).</p>
<p>The optimal architecture for providing LLMs with deliberative capabilities remains an open and exciting research question.[238] Current scaling suggests that LLMs have untapped potential that could be unlocked with appropriate designs.In parallel with algorithmic research, we propose that scientific researchers can make progress by simply expending compute to compensate for architectural weaknesses.For instance, consider tasking an agent-swarm with a problem, whereupon the agents generate ideas, ask each other questions, generate random permutations by combining ideas, rank all ideas, and only present the best ideas to the human.This workflow is highly wasteful in the sense that the majority of the generated content is never seen and indeed low-quality.Yet this invisible content can be viewed as the system's internal deliberation.Even if this process is inefficient, its automated and unobtrusive nature can make the outputs sought-after by humans.In the context of science expenditures, the associated costs could be small relative to the value.There are tentative reports that this kind of extended search can yield substantial results.[258][259][260] We thus propose increasing investigation by physical scientists of such brute-force workflows, for generating content useful to researchers.</p>
<p>Human-AI Interactions</p>
<p>Human thinking involves a combination of effortless intuition and deliberative reasoning [261][262][263][264] (often referred to as "implicit" vs. "explicit" or as "system 1" vs. "system 2").A cluster of low-level brain modules generate reflexive actions, intuitive assessments, and creative ideas.A higher-level deliberative process engages in discrimination, iterative refinement, and selection; using the low-level generators as inputs and assessors.A synthetic exocortex can be designed similarly.The swarm of AI agents act as low-level generators, introducing ideas and providing reflexive assessments.The human deliberative consciousness remains the core, doing the highest-level discrimination and decision-making, and is thus ultimately the locus of volition.</p>
<p>The exocortex interface should ideally make the AI-generated inputs feel much like the human's own low-level modules.When actively working on a task, the exocortex should provide contextual assessments and ideas that feel like spontaneous intuition that the human can trust (but will also verify).When returning to a dormant task, accumulated background AI-swarm processing should feel like the mental incubation known to occur in humans, [265] wherein returning to a problem after a diversion often yields new insights and perspective owing to subconscious consideration.</p>
<p>Obviously, efficient coupling between reflexive and deliberative processes is required in humans for effective creativity and problem-solving.[266] A legitimate concern is that traditional peripheral-based user interfaces (using keyboards, screens, etc.) represents too much friction for strong coupling, and brain-computer interfaces will be required.[60] However, there is ample evidence of human tool use becoming overlearned [267] to the point that the tool is considered an extension of the person's body and volition.[268] We can view the evolution of cognitive technology as precedent for humans externalizing aspects of their cognition, with a succession of tools (writing, calculators, the Internet, smartphones) being exploited as external memories, processing extensions, or task-activation schemes.Thus, we posit that fast and responsive interaction through existing computer interfaces may be sufficient for the desired interaction.Indeed, humans are known to be able to enter so-called "flow states" (immersed and focused) [269,270] during computer-oriented tasks such as programming.[271]</p>
<p>Human-Computer Interface</p>
<p>The purpose of the exocortex is to offer the human additional cognitive power that feels-as much as possibleas a natural extension to their own mind.One can imagine a future where brain-computer interfaces are used to provide and ideal interface; [60] we posit that in the short term much value can be realized by providing researchers with AI agents through traditional computer interfaces.Research in human use of autonomous tools suggest that the person must ultimately feel that they are in control of processes.[87] Correspondingly, we propose that initial exocortex interfaces will involve humans reviewing and verifying LLM plans before they are executed (by other AI agents).There is evidence that humans observing the output of LLMs debating each other helps the human identify the best ideas.[272,273] This suggests that, more generally, providing researchers with access to exocortex inter-communications (critique, debate, refinement, etc.) could provide them with valuable information.As system robustness improves, and user confidence in the tools increases, more and more workflows can be automated and unattended.</p>
<p>With respect to human interaction with the software tools, we can define several modalities:</p>
<p>• Push: Where alerts are used to capture the user's attention (operating system notifications, text messages, etc.).</p>
<p>• Pull: Which require the user to actively check on status (visiting web page, opening a program, etc.).</p>
<p>• Ambient: Where information is displayed peripherally to the user, or where contextually relevant.</p>
<p>Different aspects of exocortex operation might imply a different notification mode.For instance, humandirected dialogue is inherently pull, while operationally-critical and time-sensitive statuses that require human resolution will be push.However, the ambient modality is the most well-aligned to the ethos of the exocortex, where information generated by AI agents is contextually but unobtrusively presented, available to subconscious consideration by the human, and thus appears to the user as a seamless extension of their ongoing planning.</p>
<p>In the short term, we can envision useful interfaces being developed by exploiting HCI best-practices for ambient information display, and by integrating exocortex outputs into existing visualization tools and workflows.Extended reality (virtual reality, augmented reality) tools may be natural peripherals for exocortex software.Leveraging improving systems for voice transcription and voice synthesis provides another avenue for natural interaction with these tools.We note that as LLMs increase in capability, they are beginning to develop a primitive theory of mind.[24,25,274,275] This can be taken advantage of by using the LLM to roughly model human behavior, and thereby providing suggestions in ways that are most beneficial and least disruptive.</p>
<p>Infrastructure</p>
<p>In addition to novel AI developments, the success of the exocortex requires continued progress in several pragmatic infrastructure components (left side of Figure 1).In general, science infrastructure must be made increasingly automated and software-accessible, so that AI agents will be able to leverage these systems as tools.Importantly, even if the exocortex concept is flawed, the proposed improvements in science infrastructure will be of great value to the community.</p>
<p>Automated Instruments</p>
<p>As previously discussed, scientific instruments are becoming increasingly automated.This trend is driven by the increasing complexity of these tools (there are too many layers of control for them all to be manually managed), and researcher desires for speed and efficiency.Automated tools are in principle amenable for activation by AI agents.The primary limiting factor is the availability of an external API for both triggering actions (synthesis or measurement), and retrieving results (raw or analyzed data).We encourage researchers and tool vendors to push aggressively towards a world wherein every piece of laboratory equipment has an API, and is thus amenable for AI automation.LLM technology may in fact be a crucial enabler for such a transition, since their ability to handle arbitrary and heterogeneous APIs (as long as documentation is provided) liberates researchers and manufacturers from having to agree on and follow a single standard for laboratory automation.</p>
<p>Open Science Databases</p>
<p>There is growing appreciation that the data underlying scientific publications should be open and freely available to others.Open data practices increase the realized value of a research effort, as datasets can be used by others in ways not originally envisioned.[86,276] For example, datasets can be used for meta-analysis, to identify broader trends, and as inputs to machine-learning training.The FAIR data principle emphasizes that all datasets should be Findable, Accessible, Interoperable, and Reusable.[277] In practice, this means data must be retained and archived, that archives should be open for download and indexing, and that data should be correctly labelled and have corresponding meta-data to contextualize and associate it (with people, groups, publications, and related datasets).</p>
<p>The exocortex is closely tied to open data efforts.To function most effectively, it requires that AI agents be able to identify and operate on vast datasets.Thus, the exocortex is empowered by the greater availability of research data of all types.Obviously, the exocortex also improves as more domain-specific AI modules are trained; this will typically require aggregating openly available domain datasets.</p>
<p>The exocortex concept can also potentially improve data release.One key limiter in data release is researchers being unable to provide sufficiently detailed meta-data, because common tools lack meta-data features and because of the time burden associated with manually adding human annotations to vast datasets.AI agents can help here, as they are better able to handle the ambiguity of sparse meta-data labelling.AI agents may also be able to help automate the collection of meta-data and annotation of datasets when they are first produced, which should increase the richness of meta-data captured.The lesson for the community to learn is that data release is valuable even if the dataset is imperfectly organized and annotated.Future tools will make it possible to organize and extract value even from heterogeneous and unlabelled data.</p>
<p>Software</p>
<p>Software underlies an enormous amount of scientific research, and its importance is further growing as more machine-learning methods are integrated into science.LLMs can play an important role in scientific software, for code generation [5] and code execution by calling APIs [42][43][44][45][46][47][48][49][50] or interacting with graphic user interfaces (GUIs).[278][279][280][281] LLMs could also play a role in user education, since they provide a way for scientists to learn new software systems via chatbot assistance or LLM generation of code exemplars.</p>
<p>Greater integration of scientific software tools into AI agent workflows will require these tools to be made readily available.Fortunately, the prevailing trend in scientific software is to release code as open source, and make it available via repositories; these make it possible for automated systems such as AI agents to take advantage of them.AI agents may well be able to handle the some of the heterogeneity of modern software deployments; that is, they may be able to automatically download code, set up an appropriate containerized environment, generate wrapper code for interacting with that container, and then activate the system.However, it may well be preferable for the community to begin developing and adopting flexible but standardized methods of containerizing scientific software so that it can be more easily shared and launched.For instance, the MLExchange effort is developing a web platform for working with containerized ML models.[282] We also note a substantial software infrastructure challenge.Running a large number of AI agent instances, and enabling coordination between them, is a substantial technical challenge.Integrating these resources into existing scientific software workflows is also challenging.[6] The expertise of the high-performance computing (HPC) community can be leveraged, as existing know-how with respecting to scaling and deployment of largescale science software systems should be transferable to AI swarm architectures.</p>
<p>Publications</p>
<p>As with data, publications should ideally be broadly open in order for an exocortex to leverage them.It must be possible for the exocortex to identify relevant documents, retrieve them, and read them.Currently, the vast majority of the scientific literature is not easily available for machine indexing, retrieval, and AI/ML training.Researchers will generally not be able to negotiate the required licenses with publishers in order to easily obtain access to the required.Luckily, scientific practices have been increasingly moving towards open access, where the publication (or at least a preprint version of it) is freely available.We encourage researchers and publishers to continue pushing in this direction, since it both benefits traditional scientific practices, and helps enable future AI-driven workflows.</p>
<p>In addition to policy questions, there are engineering tasks required in order to make the scientific literature readily available to AI agents.In the short term, researchers may need to manage these activities themselves, building a curated local corpus of documents for their agents to interact with.In the medium term, AI agents will likely be able to access publications through tools or APIs.In the long term, the community would ideally build a common AI database on top of the existing literature.For instance, a community database that kept track of embeddings for every published paper (and sub-sections thereof) would avoid the wasted cost of researchers recomputing embeddings when their own agent ingests publications.Such a database could also store AI-generated secondary products associated with papers (summaries, classifications, connections to other literature, proposed research directions, etc.).Sharing such a database would allow each researcher's exocortex to leverage the work of all other researchers exocortices.</p>
<p>Facilities</p>
<p>Scientific research tools are often organized into coherent facilities that offer multiple related capabilities, or multiple versions of a particular measurement tool (as in the case of electron microscopy centers, synchrotrons, FELs, etc.).As more synthesis, processing, and measurement tools become individually automated and collectively organized into facilities, we can begin to imagine the impact that agentic AI will have on them.In particular, agentic AI will enable a transition of scientific facilities away from individual tools that are selected and micro-managed by scientists, and into a discovery ecosystem, wherein users can phrase their high-level scientific goals, and rely upon a swarm of AI agents to correctly select tools, launch experiments, and aggregate results.A possible architecture is depicted in Figure 5.Each researcher's exocortex, which knows about that researcher's scientific goals and problem-specific science constraints, can negotiate with AI agents operated by the facilities.This allows researchers to conceive of science goals, and leverage agents to convert this into actionable plans.The scientific facilities design and operate AI agents responsible with providing access to a variety of systems, and correctly coordinating between these systems.For instance, a particular research goal might require launching a set of measurement tools and corresponding simulations, and then aggregating the results to compare.This coordination could be executed by a a combination of AI agents and traditional software Figure 5: A possible architecture for AI agents aggregating access to scientific facilities.Each researcher's exocortex could negotiate control by dialoging with a set of AI agents provided by the facilities.That layer of agents would be optimized to launch tasks using traditional software APIs.The underlying resources (measurement instruments, compute resources, databases) would be triggered and queried, with the outputs integrated first by the facility AI agents, and then by the researcher's exocortex.infrastructure.This vision inherently requires ubiquitous and reliable automation of individual systems.It also requires novel developments in research infrastructure, to more efficiently cross-connect between components.We postulate that agentic AI will be an enabling technology for accomplishing this interconnection, as it will bypass the need for every sub-component to adhere to a single standard for meta-data and communication.As long as each component provides a documented software interface, the layer of AI agents should be able to productively access it.The productivity gain from this architecture could be transformative, as it would allow researchers to conduct experiments of a complexity previously impossible.</p>
<p>Perspectives</p>
<p>We have presented an admittedly speculative vision for the future of science, wherein each scientist has a personalized exocortex-a swarm of AI agents working together to automate research and expand researcher cognition.While this vision currently seems far-fetched, it is now within reach owing to recent developments in LLMs; and it becomes increasingly realistic as LLM technology improves.Indeed, the exocortex is envisioned in such a way that it automatically leverages improvements in the technology of AI agents, as more powerful models can be swapped in progressively as they become available.We propose that the science community should work together, and aggressively pursue the creation of systems like this.</p>
<p>We suggest that physical scientists focus on applications of AI agents, and learning how best to connect agents into coherent workflows.In fact, science is an ideal proving ground for agentic AI, since scientists can articulate precise goals, assess rigor of reasoning, and evaluate success.Thus, AI/ML researchers will hopefully view the physical sciences as an ideal environment in which to research agents and agent swarms.</p>
<p>We emphasize that the proposed work is valuable even if the exocortex concept turns out not to be the right framing.The proposed improvements to science infrastructure-making it increasingly robust, automated, software-accessible, and auditable-has value even if AI agents are not successful.The proposed AI agentsstreamlining access to publications, data, software, and instruments-are valuable even if their interconnection into an exocortex proves fruitless.</p>
<p>The science exocortex has enormous potential impact.There is growing evidence that generative AI methods exhibit various forms of emergence, including world modeling, [22][23][24][25] concept generalization, [25,[28][29][30][31] and pattern aggregation that is more capable than the inputs.[283] The exocortex architecture would enable and leverage additional layers of emergence.Interactions between AI agents should lead to more reliable, coherent, and capable output than single-shot generation by a lone LLM.And, crucially, interaction between a swarm of AI agents-each responsible for intelligently mediating access to a suite of research capabilities-and a human researcher should lead to the emergence of enhanced human capabilities.By expanding the researcher's intelligence into the exocortex, the researcher can accomplish more, as they are able to intuitively and seamlessly weave myriad physical, computational, and cognititve systems into their intellectual work.</p>
<p>Figure 2 :
2
Figure 2: Diagram of a large language model (LLM) acting as a kernel (image based on social media post by Andrej Karpathy).While LLMs perform text generation, Karpathy has proposed to view them instead as kernels-orchestration agents-of a new kind of operating system.[40,41]In this paradigm, the LLM is responsible for accessing resources (e.g.documents) or triggering actions (calculations, web browsing, etc.), and feeding results to a desired interface (e.g.chatbot dialog).The ability of LLMs to perform (rudimentary) decision-making can thus be exploited to coordinate more complex activity in response to relatively vague commands (which may come from a human or another LLM system).</p>
<p>Table 1 :
1
Examples of command messages that various AI agents could send to other agents.The diagonal elements (grey text) are commands sent from an agent to another instance of the same type.</p>
<p>AcknowledgementsThis research was carried out by the Center for Functional Nanomaterials, which is a U.S. DOE Office of Science Facility, at Brookhaven National Laboratory under Contract No. DE-SC0012704.We thank Dr. Charles T. Black for fruitful discussions.Author ContributionsKGY reviewed the literature, developed the concepts, and wrote the manuscript.Conflicts of interest
. J Qiu, Q Wu, G Ding, Y Xu, S Feng, EURASIP Journal on Advances in Signal Processing. 672016. 2016</p>
<p>The Impact of Large Language Models on Scientific Discovery: a Preliminary Study using GPT-4. M R Ai4science, M A Quantum, 2023</p>
<p>. H Wang, T Fu, Y Du, W Gao, K Huang, Z Liu, P Chandak, S Liu, P Van Katwyk, A Deac, A Anandkumar, K Bergen, C P Gomes, S Ho, P Kohli, J Lasenby, J Leskovec, T.-Y Liu, A Manrai, D Marks, B Ramsundar, L Song, J Sun, J Tang, P Veličković, M Welling, L Zhang, C W Coley, Y Bengio, M Zitnik, Nature. 6202023</p>
<p>T R Society, Science in the Age of AI: How artificial intelligence is changing the nature and method of scientific research. 2024</p>
<p>. K M Jablonka, Q Ai, A Al-Feghali, S Badhwar, J D Bocarsly, A M Bran, S Bringuier, L C Brinson, K Choudhary, D Circi, S Cox, W A Jong, M L Evans, N Gastellu, J Genzling, M V Gil, A K Gupta, Z Hong, A Imran, S Kruschwitz, A Labarre, J Lála, T Liu, S Ma, S Majumdar, G W Merz, N Moitessier, E Moubarak, B Mouriño, B Pelkie, M Pieler, M C Ramos, B Ranković, S G Rodriques, J N Sanders, P Schwaller, M Schwarting, J Shi, B Smit, B E Smith, J Van Herck, C Völker, L Ward, S Warren, B Weiser, S Zhang, X Zhang, G A Zia, A Scourtas, K J Schmidt, I Foster, A D White, B Blaiszik, Digital Discovery. 22023</p>
<p>N C Hudson, J G Pauloski, M Baughman, A Kamatar, M Sakarvadia, L Ward, R Chard, A Bauer, M Levental, W Wang, W Engler, O Price Skelly, B Blaiszik, R Stevens, K Chard, I Foster, Proceedings of the IEEE/ACM 10th International Conference on Big Data Computing. the IEEE/ACM 10th International Conference on Big Data ComputingNew York, NY, USAApplications and Technologies2024</p>
<p>. T Brown, B Mann, N Ryder, M Subbiah, J D Kaplan, P Dhariwal, A Neelakantan, P Shyam, G Sastry, A Askell, S Agarwal, A Herbert-Voss, G Krueger, T Henighan, R Child, A Ramesh, D Ziegler, J Wu, C Winter, C Hesse, M Chen, E Sigler, M Litwin, S Gray, B Chess, J Clark, C Berner, S Mccandlish, A Radford, I Sutskever, D Amodei, Advances in Neural Information Processing Systems. 2020</p>
<p>R Bommasani, D A Hudson, E Adeli, R Altman, S Arora, S Arx, M S Bernstein, J Bohg, A Bosselut, E Brunskill, E Brynjolfsson, S Buch, D Card, R Castellon, N Chatterji, A Chen, K Creel, J Q Davis, D Demszky, C Donahue, M Doumbouya, E Durmus, S Ermon, J Etchemendy, K Ethayarajh, L Fei-Fei, C Finn, T Gale, L Gillespie, K Goel, N Goodman, S Grossman, N Guha, T Hashimoto, P Henderson, J Hewitt, D E Ho, J Hong, K Hsu, J Huang, T Icard, S Jain, D Jurafsky, P Kalluri, S Karamcheti, G Keeling, F Khani, O Khattab, P W Koh, M Krass, R Krishna, R Kuditipudi, A Kumar, F Ladhak, M Lee, T Lee, J Leskovec, I Levent, X L Li, X Li, T Ma, A Malik, C D Manning, S Mirchandani, E Mitchell, Z Munyikwa, S Nair, A Narayan, D Narayanan, B Newman, A Nie, J C Niebles, H Nilforoshan, J Nyarko, G Ogut, L Orr, I Papadimitriou, J S Park, C Piech, E Portelance, C Potts, A Raghunathan, R Reich, H Ren, F Rong, Y Roohani, C Ruiz, J Ryan, C Ré, D Sadigh, S Sagawa, K Santhanam, A Shih, K Srinivasan, A Tamkin, R Taori, A W Thomas, F Tramèr, R E Wang, W Wang, B Wu, J Wu, Y Wu, S M Xie, M Yasunaga, J You, M Zaharia, M Zhang, T Zhang, X Zhang, Y Zhang, L Zheng, K Zhou, P Liang, On the Opportunities and Risks of Foundation Models. 2021</p>
<p>Attention Is All You Need. A Vaswani, N Shazeer, N Parmar, J Uszkoreit, L Jones, A N Gomez, L Kaiser, I Polosukhin, 2017</p>
<p>. M Jovanovic, M Campbell, Computer. 552022</p>
<p>ChatGPT is not all you need. A State of the Art Review of large Generative AI models. R Gozalo-Brizuela, E C Garrido-Merchan, 2023</p>
<p>Hierarchical Text-Conditional Image Generation with CLIP Latents. A Ramesh, P Dhariwal, A Nichol, C Chu, M Chen, 2022</p>
<p>High-Resolution Image Synthesis with Latent Diffusion Models. R Rombach, A Blattmann, D Lorenz, P Esser, B Ommer, 2021</p>
<p>J Oppenlaender, Proceedings of the 25th International Academic Mindtrek Conference. the 25th International Academic Mindtrek ConferenceNew York, NY, USA2022</p>
<p>Improving Language Understanding by Generative Pre-Training. A Radford, K Narasimhan, T Salimans, I Sutskever, Openai technical report. 2018</p>
<p>J Yang, H Jin, R Tang, X Han, Q Feng, H Jiang, B Yin, X Hu, Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond. 2023</p>
<p>Y Liu, H He, T Han, X Zhang, M Liu, J Tian, Y Zhang, J Wang, X Gao, T Zhong, Y Pan, S Xu, Z Wu, Z Liu, X Zhang, S Zhang, X Hu, T Zhang, N Qiang, T Liu, B Ge, Understanding LLMs: A Comprehensive Overview from Training to Inference. 2024</p>
<p>Large Language Models: A Survey. S Minaee, T Mikolov, N Nikzad, M Chenaghlu, R Socher, X Amatriain, J Gao, 2024</p>
<p>J Hestness, S Narang, N Ardalani, G Diamos, H Jun, H Kianinejad, M M A Patwary, Y Yang, Y Zhou, Deep Learning Scaling is Predictable. 2017</p>
<p>Scaling Laws for Autoregressive Generative Modeling. T Henighan, J Kaplan, M Katz, M Chen, C Hesse, J Jackson, H Jun, T B Brown, P Dhariwal, S Gray, C Hallacy, B Mann, A Radford, A Ramesh, N Ryder, D M Ziegler, J Schulman, D Amodei, S Mccandlish, 2020</p>
<p>. J Hoffmann, S Borgeaud, A Mensch, E Buchatskaya, T Cai, E Rutherford, D De Las Casas, L A Hendricks, J Welbl, A Clark, T Hennigan, E Noland, K Millican, G Van Den Driessche, B Damoc, A Guy, S Osindero, K Simonyan, E Elsen, J W Rae, O Vinyals, L Sifre, Training Compute-Optimal Large Language Models. 2022</p>
<p>K Li, A K Hopkins, D Bau, F Viégas, H Pfister, M Wattenberg, Emergent World Representations: Exploring a Sequence Model Trained on a Synthetic Task. 2023</p>
<p>What learning algorithm is in-context learning? Investigations with linear models. E Akyürek, D Schuurmans, J Andreas, T Ma, D Zhou, 2023</p>
<p>Evaluating Large Language Models in Theory of Mind Tasks. M Kosinski, 2023</p>
<p>. T Webb, K J Holyoak, H Lu, Nature Human Behaviour. 2023</p>
<p>W Gurnee, M Tegmark, Language Models Represent Space and Time. 2024</p>
<p>K Vafa, J Y Chen, J Kleinberg, S Mullainathan, A Rambachan, Evaluating the World Model Implicit in a Generative Model. 2024</p>
<p>. D Ganguli, D Hernandez, L Lovitt, A Askell, Y Bai, A Chen, T Conerly, N Dassarma, D Drain, N Elhage, S E Showk, S Fort, Z Hatfield-Dodds, T Henighan, S Johnston, A Jones, N Joseph, J Kernian, S Kravec, B Mann, N Nanda, K Ndousse, C Olsson, D Amodei, T Brown, J Kaplan, S Mccandlish, C Olah, D Amodei, J Clark, ACM Conference on Fairness, Accountability, and Transparency. 2022. 2022</p>
<p>J Wei, Y Tay, R Bommasani, C Raffel, B Zoph, S Borgeaud, D Yogatama, M Bosma, D Zhou, D Metzler, E H Chi, T Hashimoto, O Vinyals, P Liang, J Dean, W Fedus, Emergent Abilities of Large Language Models. 2022</p>
<p>Progress measures for grokking via mechanistic interpretability. N Nanda, L Chan, T Lieberum, J Smith, J Steinhardt, 2023</p>
<p>S Bubeck, V Chandrasekaran, R Eldan, J Gehrke, E Horvitz, E Kamar, P Lee, Y T Lee, Y Li, S Lundberg, H Nori, H Palangi, M T Ribeiro, Y Zhang, Sparks of Artificial General Intelligence: Early experiments with GPT-4. 2023</p>
<p>Fine-Tuning Language Models from Human Preferences. D M Ziegler, N Stiennon, J Wu, T B Brown, A Radford, D Amodei, P Christiano, G Irving, 2020</p>
<p>Training language models to follow instructions with human feedback. L Ouyang, J Wu, X Jiang, D Almeida, C L Wainwright, P Mishkin, C Zhang, S Agarwal, K Slama, A Ray, J Schulman, J Hilton, F Kelton, L Miller, M Simens, A Askell, P Welinder, P Christiano, J Leike, R Lowe, 2022</p>
<p>. N Lambert, L Castricato, L Werra, A Havrilla, Hugging Face Blog. 2022</p>
<p>RLAIF: Scaling Reinforcement Learning from Human Feedback with AI Feedback. H Lee, S Phatale, H Mansoor, T Mesnard, J Ferret, K Lu, C Bishop, E Hall, V Carbune, A Rastogi, S Prakash, 2023</p>
<p>P Lewis, E Perez, A Piktus, F Petroni, V Karpukhin, N Goyal, H Küttler, M Lewis, W -T. Yih, T Rocktäschel, S Riedel, D Kiela, Proceedings of the 34th International Conference on Neural Information Processing Systems. the 34th International Conference on Neural Information Processing SystemsRed Hook, NY, USA2020</p>
<p>. K G Yager, Digital Discovery. 22023</p>
<p>Retrieval-Augmented Generation for Large Language Models: A Survey. Y Gao, Y Xiong, X Gao, K Jia, J Pan, Y Bi, Y Dai, J Sun, M Wang, H Wang, 2024</p>
<p>Evaluation of Retrieval-Augmented Generation: A Survey. H Yu, A Gan, K Zhang, S Tong, Q Liu, Z Liu, 2024</p>
<p>. A Karpathy, Karpathy -Windows, X Os, Linux , Posted on Threads.net, 11/10/2023</p>
<p>. A Karpathy, @karpathy -Llm Os, 11/10/2023</p>
<p>S Yao, J Zhao, D Yu, N Du, I Shafran, K Narasimhan, Y Cao, ReAct: Synergizing Reasoning and Acting in Language Models. 2023</p>
<p>Toolformer: Language Models Can Teach Themselves to Use Tools. T Schick, J Dwivedi-Yu, R Dessì, R Raileanu, M Lomeli, L Zettlemoyer, N Cancedda, T Scialom, 2023</p>
<p>PAL: Program-aided Language Models. L Gao, A Madaan, S Zhou, U Alon, P Liu, Y Yang, J Callan, G Neubig, 2023</p>
<p>Y Liang, C Wu, T Song, W Wu, Y Xia, Y Liu, Y Ou, S Lu, L Ji, S Mao, Y Wang, L Shou, M Gong, N Duan, TaskMatrix.AI: Completing Tasks by Connecting Foundation Models with Millions of APIs. 2023</p>
<p>HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face. Y Shen, K Song, X Tan, D Li, W Lu, Y Zhuang, 2023</p>
<p>T Cai, X Wang, T Ma, X Chen, D Zhou, Large Language Models as Tool Makers. 2023</p>
<p>Check Your Facts and Try Again: Improving Large Language Models with External Knowledge and Automated Feedback. B Peng, M Galley, P He, H Cheng, Y Xie, Y Hu, Q Huang, L Liden, Z Yu, W Chen, J Gao, 2023</p>
<p>ReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models. B Xu, Z Peng, B Lei, S Mukherjee, Y Liu, D Xu, 2023</p>
<p>C.-Y Hsieh, S.-A Chen, C.-L Li, Y Fujii, A Ratner, C.-Y Lee, R Krishna, T Pfister, Tool Documentation Enables Zero-Shot Tool-Usage with Large Language Models. 2023</p>
<p>Reflexion: Language Agents with Verbal Reinforcement Learning. N Shinn, F Cassano, B Labash, A Gopinath, K Narasimhan, S Yao, 2023</p>
<p>Let's Verify Step by Step. H Lightman, V Kosaraju, Y Burda, H Edwards, B Baker, T Lee, J Leike, J Schulman, I Sutskever, K Cobbe, 2023</p>
<p>Reprompting: Automated Chain-of-Thought Prompt Inference Through Gibbs Sampling. W Xu, A Banburski-Fahey, N Jojic, 2023</p>
<p>Tree of Thoughts: Deliberate Problem Solving with Large Language Models. S Yao, D Yu, J Zhao, I Shafran, T L Griffiths, Y Cao, K Narasimhan, 2023</p>
<p>J Xu, H Fei, L Pan, Q Liu, M.-L Lee, W Hsu, Faithful Logical Reasoning via Symbolic Chain-of-Thought. 2024</p>
<p>Voyager: An Open-Ended Embodied Agent with Large Language Models. G Wang, Y Xie, Y Jiang, A Mandlekar, C Xiao, Y Zhu, L Fan, A Anandkumar, 2023</p>
<p>CAMEL: Communicative Agents for. G Li, H A A K Hammoud, H Itani, D Khizbullin, B Ghanem, Exploration of Large Scale Language Model Society. 2023</p>
<p>. D A Boiko, R Macknight, B Kline, G Gomes, Nature. 6242023</p>
<p>R Yang, J Chen, Y Zhang, S Yuan, A Chen, K Richardson, Y Xiao, D Yang, SelfGoal: Your Language Agents Already Know How to Achieve High-level Goals. 2024</p>
<p>T Bonaci, J Herron, C Matlack, H J Chizeck, IEEE Conference on Norbert Wiener in the 21st Century (21CW). 2014. 2014</p>
<p>Z Xi, W Chen, X Guo, W He, Y Ding, B Hong, M Zhang, J Wang, S Jin, E Zhou, R Zheng, X Fan, X Wang, L Xiong, Y Zhou, W Wang, C Jiang, Y Zou, X Liu, Z Yin, S Dou, R Weng, W Cheng, Q Zhang, W Qin, Y Zheng, X Qiu, X Huang, T Gui, The Rise and Potential of Large Language Model Based Agents: A Survey. 2023</p>
<p>. L Wang, C Ma, X Feng, Z Zhang, H Yang, J Zhang, Z Chen, J Tang, X Chen, Y Lin, W X Zhao, Z Wei, J Wen, Frontiers of Computer Science. 182024</p>
<p>W Zhong, L Guo, Q Gao, H Ye, Y Wang, MemoryBank: Enhancing Large Language Models with Long-Term Memory. 2023</p>
<p>Augmenting Language Models with Long-Term Memory. W Wang, L Dong, H Cheng, X Liu, X Yan, J Gao, F Wei, 2023</p>
<p>. P Das, S Chaudhury, E Nelson, I Melnyk, S Swaminathan, S Dai, A Lozano, G Kollias, V Chenthamarakshan, Jiří, S Navrátil, P.-Y Dan, Chen, Larimar: Large Language Models with Episodic Memory Control. 2024</p>
<p>Banishing LLM Hallucinations Requires Rethinking Generalization, github. J Li, S Consul, E Zhou, J Wong, N Farooqui, N Manohar, Z N Wei, T Wu, B Echols, S Zhou, G Diamos, 2024</p>
<p>Quiet-STaR: Language Models Can Teach Themselves to Think Before Speaking. E Zelikman, G Harik, Y Shao, V Jayasiri, N Haber, N D Goodman, 2024</p>
<p>W Bounsi, B Ibarz, A Dudzik, J B Hamrick, L Markeeva, A Vitvitskyi, R Pascanu, P Veličković, Transformers meet Neural Algorithmic Reasoners. 2024</p>
<p>Improve Mathematical Reasoning in Language Models by Automated Process Supervision. L Luo, Y Liu, R Liu, S Phatale, H Lara, Y Li, L Shu, Y Zhu, L Meng, J Sun, A Rastogi, 2024</p>
<p>AlphaMath Almost Zero: process Supervision without process. G Chen, M Liao, C Li, K Fan, 2024</p>
<p>D Zhang, S Zhoubian, Y Yue, Y Dong, J Tang, ReST-MCTS*: LLM Self-Training via Process Reward Guided Tree Search. 2024</p>
<p>Accessing GPT-4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self-refine with LLaMa-3 8B. D Zhang, J Li, X Huang, D Zhou, Y Li, W Ouyang, 2024</p>
<p>. J Y Koh, S Mcaleer, D Fried, R Salakhutdinov, 2024arXiv preprint</p>
<p>S Golkar, M Pettee, M Eickenberg, A Bietti, M Cranmer, G Krawezik, F Lanusse, M Mccabe, R Ohana, L Parker, B R .-S. Blancard, T Tesileanu, K Cho, S Ho, xVal: A Continuous Number Encoding for Large Language Models. 2023</p>
<p>Transformers Can Do Arithmetic with the Right Embeddings. S Mcleish, A Bansal, A Stein, N Jain, J Kirchenbauer, B R Bartoldson, B Kailkhura, A Bhatele, J Geiping, A Schwarzschild, T Goldstein, 2024</p>
<p>. T H Trinh, Y Wu, Q V Le, H He, T Luong, Nature. 6252024</p>
<p>SysCaps: Language Interfaces for Simulation Surrogates of Complex Systems. P Emami, Z Li, S Sinha, T Nguyen, 2024</p>
<p>. V Kumar, L Gleyzer, A Kahana, K Shukla, G E Karniadakis, Journal of Machine Learning for Modeling and Computing. 42023</p>
<p>. P M Maffettone, L Banko, P Cui, Y Lysogorskiy, M A Little, D Olds, A Ludwig, A I Cooper, Nature Computational Science. 12021</p>
<p>A M Bran, S Cox, O Schilter, C Baldassari, A D White, P Schwaller, ChemCrow: Augmenting large-language models with chemistry tools. 2023</p>
<p>ProtST: Multi-Modality Learning of Protein Sequences and Biomedical Texts. M Xu, X Yuan, S Miret, J Tang, 2023</p>
<p>S Liu, Y Li, Z Li, A Gitter, Y Zhu, J Lu, Z Xu, W Nie, A Ramanathan, C Xiao, J Tang, H Guo, A Anandkumar, A Text-guided Protein Design Framework. 2023</p>
<p>. M Y Lu, B Chen, D F K Williamson, R J Chen, M Zhao, A K Chow, K Ikemura, A Kim, D Pouli, A Patel, A Soliman, C Chen, T Ding, J J Wang, G Gerber, I Liang, L P Le, A V Parwani, L L Weishaupt, F Mahmood, Nature. 2024</p>
<p>. L A Royer, Nature Methods. 2024</p>
<p>K G Yager, Online Resource for Big Data and Extreme-Scale Computing Workshop. 2018</p>
<p>Methods and Applications of Autonomous Experimentation. K G Yager, 2023Chapman and Hall/CRC211st edn</p>
<p>. L Hung, J A Yager, D Monteverde, D Baiocchi, H.-K Kwon, S Sun, S Suram, Digital Discovery. 2024</p>
<p>. R D King, K E Whelan, F M Jones, P G K Reiser, C H Bryant, S H Muggleton, D B Kell, S G Oliver, Nature. 4272004</p>
<p>. A G Kusne, T Gao, A Mehta, L Ke, M C Nguyen, K.-M Ho, V Antropov, C.-Z Wang, M J Kramer, C Long, I Takeuchi, Scientific Reports. 2014, 4, 6367</p>
<p>. P Nikolaev, D Hooper, N Perea-López, M Terrones, B Maruyama, ACS Nano. 82014</p>
<p>. D Xue, P V Balachandran, R Yuan, T Hu, X Qian, E R Dougherty, T Lookman, Proceedings of the National Academy of Sciences. 1132016</p>
<p>. F Ren, L Ward, T Williams, K J Laws, C Wolverton, J Hattrick-Simpers, A Mehta, Science Advances. 2018, 4, eaaq1566</p>
<p>. H S Stein, J M Gregoire, Chem. Sci. 102019</p>
<p>. M M Noack, K G Yager, M Fukuto, G S Doerk, R Li, J A Sethian, Scientific Reports. 2019, 9, 11809</p>
<p>. M M Noack, G S Doerk, R Li, M Fukuto, K G Yager, Scientific Reports. 1013252020</p>
<p>. M M Noack, G S Doerk, R Li, J K Streit, R A Vaia, K G Yager, M Fukuto, Scientific Reports. 10176632020</p>
<p>. M M Noack, P H Zwart, D M Ushizima, M Fukuto, K G Yager, K C Elbert, C B Murray, A Stein, G S Doerk, E H R Tsai, R Li, G Freychet, M Zhernenkov, H.-Y N Holman, S Lee, L Chen, E Rotenberg, T Weber, Y L Goc, M Boehm, P Steffens, P Mutti, J A Sethian, Nature Reviews Physics. 32021</p>
<p>. S V Kalinin, M Ziatdinov, J Hinkle, S Jesse, A Ghosh, K P Kelley, A R Lupini, B G Sumpter, R K Vasudevan, ACS Nano. 152021</p>
<p>. E Stach, B Decost, A G Kusne, J Hattrick-Simpers, K A Brown, K G Reyes, J Schrier, S Billinge, T Buonassisi, I Foster, C P Gomes, J M Gregoire, A Mehta, J Montoya, E Olivetti, C Park, E Rotenberg, S K Saikin, S Smullin, V Stanev, B Maruyama, Matter, 20214</p>
<p>. I.-J Chen, M Aapro, A Kipnis, A Ilin, P Liljeroth, A S Foster, Nature Communications. 1374992022</p>
<p>. C Zhao, C.-C Chung, S Jiang, M M Noack, J.-H Chen, K Manandhar, J Lynch, H Zhong, W Zhu, P Maffettone, D Olds, M Fukuto, I Takeuchi, S Ghose, T Caswell, K G Yager, Y.-C K Chen-Wiegart, Communications Materials. 3862022</p>
<p>. G S Doerk, A Stein, S Bae, M M Noack, M Fukuto, K G Yager, Science Advances. 936872023</p>
<p>. S Bae, M M Noack, K G Yager, Nanoscale. 152023</p>
<p>. K G Yager, P W Majewski, M M Noack, M Fukuto, Nanotechnology. 343220012023</p>
<p>. A A Volk, R W Epps, D T Yonemoto, B S Masters, F N Castellano, K G Reyes, M Abolhasani, Nature Communications. 1414032023</p>
<p>. N J Szymanski, B Rendy, Y Fei, R E Kumar, T He, D Milsted, M J Mcdermott, M Gallant, E D Cubuk, A Merchant, H Kim, A Jain, C J Bartel, K Persson, Y Zeng, G Ceder, Nature. 6242023</p>
<p>. F J Alexander, J Ang, J A Bilbrey, J Balewski, T Casey, R Chard, J Choi, S Choudhury, B Debusschere, A M Degennaro, N Dryden, J A Ellis, I Foster, C G Cardona, S Ghosh, P Harrington, Y Huang, S Jha, T Johnston, A Kagawa, R Kannan, N Kumar, Z Liu, N Maruyama, S Matsuoka, E Mccarthy, J Mohd-Yusof, P Nugent, Y Oyama, T Proffen, D Pugmire, S Rajamanickam, V Ramakrishniah, M Schram, S K Seal, G Sivaraman, C Sweeney, L Tan, R Thakur, B V Essen, L Ward, P Welch, M Wolf, S S Xantheas, K G Yager, S Yoo, B.-J Yoon, The International Journal of High Performance Computing Applications. 352021</p>
<p>T Rainforth, A Foster, D R Ivanova, F B Smith, Modern Bayesian Experimental Design. 2023Accepted for publication in Statistical Science</p>
<p>Methods and Applications of Autonomous Experimentation. M M Noack, 2023Chapman and Hall/CRC161st edn</p>
<p>P M Maffettone, D B Allan, S I Campbell, M R Carbone, T A Caswell, B L Decost, D Gavrilov, M D Hanwell, H Joress, J Lynch, B Ravel, S B Wilkins, J Wlodek, D Olds, Self-driving Multimodal Studies at User Facilities. 2023</p>
<p>. P Zahl, T Wagner, R Möller, A Klust, Journal of Vacuum Science and Technology B. 282010</p>
<p>. Y Liu, K P Kelley, R K Vasudevan, H Funakubo, M A Ziatdinov, S V Kalinin, Nature Machine Intelligence. 42022</p>
<p>. J Hill, S Campbell, G Carini, Y.-C K Chen-Wiegart, Y Chu, A Fluerasu, M Fukuto, M Idir, J Jakoncic, I Jarrige, P Siddons, T Tanabe, K G Yager, Journal of Physics: Condensed Matter. 3740082020</p>
<p>. C Bostedt, S Boutet, D M Fritz, Z Huang, H J Lee, H T Lemke, A Robert, W F Schlotter, J J Turner, G J Williams, Rev. Mod. Phys. 150072016</p>
<p>. C Bostedt, H N Chapman, J T Costello, J R Crespo López-Urrutia, S Düsterer, S W Epp, J Feldhaus, A Föhlisch, M Meyer, T Möller, R Moshammer, M Richter, K Sokolowski-Tinten, A Sorokin, K Tiedtke, J Ullrich, W Wurth, Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment. 6012009</p>
<p>. E Allaria, R Appio, L Badano, W A Barletta, S Bassanese, S G Biedron, A Borga, E Busetto, D Castronovo, P Cinquegrana, S Cleva, D Cocco, M Cornacchia, P Craievich, I Cudin, G D'auria, M Forno, M B Danailov, R De Monte, G De Ninno, P Delgiusto, A Demidovich, S Di Mitri, B Diviacco, A Fabris, R Fabris, W Fawley, M Ferianis, E Ferrari, S Ferry, L Froehlich, P Furlan, G Gaio, F Gelmetti, L Giannessi, M Giannini, R Gobessi, R Ivanov, E Karantzoulis, M Lonza, A Lutman, B Mahieu, M Milloch, S V Milton, M Musardo, I Nikolov, S Noe, F Parmigiani, G Penco, M Petronio, L Pivetta, M Predonzani, F Rossi, L Rumiz, A Salom, C Scafuri, C Serpico, P Sigalotti, S Spampinati, C Spezzani, M Svandrlik, C Svetina, S Tazzari, M Trovo, R Umer, A Vascotto, M Veronese, R Visintini, M Zaccaria, D Zangrando, M Zangrando, Nature Photonics. 62012</p>
<p>. E M Chan, C Xu, A W Mao, G Han, J S Owen, B E Cohen, D J Milliron, Nano Letters. 102010</p>
<p>. B Li, S S Kaye, C Riley, D Greenberg, D Galang, M S Bailey, ACS Combinatorial Science. 142012</p>
<p>. Q Yan, J Yu, S K Suram, L Zhou, A Shinde, P F Newhouse, W Chen, G Li, K A Persson, J M Gregoire, J B Neaton, 2017114Proceedings of the National Academy of Sciences</p>
<p>. J M Granda, L Donina, V Dragone, D.-L Long, L Cronin, Nature. 5592018</p>
<p>. R Vescovi, T Ginsburg, K Hippe, D Ozgulbas, C Stone, A Stroka, R Butler, B Blaiszik, T Brettin, K Chard, M Hereld, A Ramanathan, R Stevens, A Vriza, J Xu, Q Zhang, I Foster, Digital Discovery. 22023</p>
<p>. R Shimizu, S Kobayashi, Y Watanabe, Y Ando, T Hitosugi, APL Materials. 2020, 8, 111110</p>
<p>. M Abolhasani, E Kumacheva, Nature Synthesis. 2023</p>
<p>. A Brohan, N Brown, J Carbajal, Y Chebotar, X Chen, K Choromanski, T Ding, D Driess, A Dubey, C Finn, P Florence, C Fu, M G Arenas, K Gopalakrishnan, K Han, K Hausman, A Herzog, J Hsu, B Ichter, A Irpan, N Joshi, R Julian, D Kalashnikov, Y Kuang, I Leal, L Lee, T.-W E Lee, S Levine, Y Lu, H Michalewski, I Mordatch, K Pertsch, K Rao, K Reymann, M Ryoo, G Salazar, P Sanketi, P Sermanet, J Singh, A Singh, R Soricut, H Tran, V Vanhoucke, Q Vuong, A Wahid, S Welker, P Wohlhart, J Wu, F Xia, T Xiao, P Xu, S Xu, T Yu, B Zitkovich, arXiv:2307.158182023arXiv preprint</p>
<p>C Chi, S Feng, Y Du, Z Xu, E Cousineau, B Burchfiel, S Song, Proceedings of Robotics: Science and Systems (RSS). Robotics: Science and Systems (RSS)2023</p>
<p>A Avetisyan, C Xie, H Howard-Jenkins, T.-Y Yang, S Aroudj, S Patra, F Zhang, D Frost, L Holland, C Orme, J Engel, E Miller, R Newcombe, V Balntas, SceneScript: Reconstructing Scenes With An Autoregressive Structured Language Model. 2024</p>
<p>I Radosavovic, B Zhang, B Shi, J Rajasegaran, S Kamat, T Darrell, K Sreenath, J Malik, Humanoid Locomotion as Next Token Prediction. 2024</p>
<p>AutoRT: Embodied Foundation Models for Large Scale Orchestration of Robotic Agents. M Ahn, D Dwibedi, C Finn, M G Arenas, K Gopalakrishnan, K Hausman, B Ichter, A Irpan, N Joshi, R Julian, S Kirmani, I Leal, E Lee, S Levine, Y Lu, I Leal, S Maddineni, K Rao, D Sadigh, P Sanketi, P Sermanet, Q Vuong, S Welker, F Xia, T Xiao, P Xu, S Xu, Z Xu, 2024</p>
<p>. D Aldarondo, J Merel, J D Marshall, L Hasenclever, U Klibaite, A Gellis, Y Tassa, G Wayne, M Botvinick, B P Ölveczky, Nature. 2024</p>
<p>. Z Fu, Q Zhao, Q Wu, G Wetzstein, C Finn, arXiv2024</p>
<p>M H Prince, H Chan, A Vriza, T Zhou, V K Sastry, M T Dearing, R J Harder, R K Vasudevan, M J Cherukara, Opportunities for Retrieval and Tool Augmented Large Language Models in Scientific Facilities. 2023</p>
<p>D Potemkin, C Soto, R Li, K Yager, E Tsai, Virtual Scientific Companion for Synchrotron Beamlines: A Prototype. 2023</p>
<p>Synergizing Human Expertise and AI Efficiency with Language Model for Microscopy Operation and Automated Experiment Design. Y Liu, M Checa, R K Vasudevan, 2024</p>
<p>Learning Transferable Visual Models From Natural Language Supervision. A Radford, J W Kim, C Hallacy, A Ramesh, G Goh, S Agarwal, G Sastry, A Askell, P Mishkin, J Clark, G Krueger, I Sutskever, 2021</p>
<p>ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks. J Lu, D Batra, D Parikh, S Lee, 2019</p>
<p>Z Yang, L Li, K Lin, J Wang, C.-C Lin, Z Liu, L Wang, The Dawn of LMMs: Preliminary Explorations with GPT-4V(ision). 2023</p>
<p>A Review of Multi-Modal Large Language and Vision Models. K Carolan, L Fennelly, A F Smeaton, 2024</p>
<p>W Gao, Z Deng, Z Niu, F Rong, C Chen, Z Gong, W Zhang, D Xiao, F Li, Z Cao, Z Ma, W Wei, L Ma, OphGLM: Training an Ophthalmology Large Language-and-Vision Assistant based on Instructions and Dialogue. 2023</p>
<p>C Li, C Wong, S Zhang, N Usuyama, H Liu, J Yang, T Naumann, H Poon, J Gao, Advances in Neural Information Processing Systems. 2023</p>
<p>. Y Wang, W Zhang, S Lin, M S Farruggio, A Wang, bioRxiv. 2024</p>
<p>LLaGA: Large Language and Graph Assistant. R Chen, T Zhao, A Jaiswal, N Shah, Z Wang, 2024</p>
<p>Z Song, Y Li, M Fang, Z Chen, Z Shi, Y Huang, L Chen, MMAC-Copilot: Multi-modal Agent Collaboration Operating System Copilot. 2024</p>
<p>. P W Majewski, K G Yager, Journal of Physics: Condensed Matter. 4030022016</p>
<p>D Mizrahi, R Bachmann, O F Kar, T Yeo, M Gao, A Dehghan, A Zamir, Thirty-seventh Conference on Neural Information Processing Systems. 2023</p>
<p>4M-21: An Any-to-Any Vision Model for Tens of Tasks and Modalities. R Bachmann, O F Kar, D Mizrahi, A Garjani, M Gao, D Griffiths, J Hu, A Dehghan, A Zamir, 2024</p>
<p>A I Polymathic, Advancing Science through Multi-Disciplinary AI. </p>
<p>. M , </p>
<p>F Lanusse, L Parker, S Golkar, M Cranmer, A Bietti, M Eickenberg, G Krawezik, M Mccabe, R Ohana, M Pettee, B R .-S. Blancard, T Tesileanu, K Cho, S Ho, AstroCLIP: Cross-Modal Pre-Training for Astronomical Foundation Models. 2023</p>
<p>M Mccabe, B R .-S. Blancard, L Parker, R Ohana, M Cranmer, A Bietti, M Eickenberg, S Golkar, G Krawezik, F Lanusse, M Pettee, T Tesileanu, K Cho, S Ho, NeurIPS 2023 AI for Science Workshop. 2023</p>
<p>J Treutlein, D Choi, J Betley, C Anil, S Marks, R B Grosse, O Evans, Connecting the Dots: LLMs can Infer and Verbalize Latent Structure from Disparate Training Data. 2024</p>
<p>. M M Noack, J A Sethian, Communications in Applied Mathematics and Computational Science. 172021</p>
<p>M M Noack, D Perryman, H Krishnan, P H Zwart, 2021 3rd Annual Workshop on Extreme-scale Experiment-in-the-Loop Computing (XLOOP). 2021</p>
<p>. M M Noack, H Krishnan, M D Risser, K G Reyes, Scientific Reports. 1331552023</p>
<p>B Poole, A Jain, J T Barron, B Mildenhall, DreamFusion: Text-to-3D using 2D Diffusion. 2022</p>
<p>ProlificDreamer: High-Fidelity and Diverse Text-to-3D Generation with Variational Score Distillation. Z Wang, C Lu, Y Wang, F Bao, C Li, H Su, J Zhu, 2023</p>
<p>C.-H Lin, J Gao, L Tang, T Takikawa, X Zeng, X Huang, K Kreis, S Fidler, M.-Y Liu, T.-Y Lin, Magic3D: High-Resolution Text-to-3D Content Creation. 2023</p>
<p>G Metzer, E Richardson, O Patashnik, R Giryes, D Cohen-Or, Latent-NeRF for Shape-Guided Generation of 3D Shapes and Textures. 2022</p>
<p>Fantasia3D: Disentangling Geometry and Appearance for Highquality Text-to-3D Content Creation. R Chen, Y Chen, N Jiao, K Jia, 2023</p>
<p>TextMesh: Generation of Realistic 3D Meshes From Text Prompts. C Tsalicoglou, F Manhardt, A Tonioni, M Niemeyer, F Tombari, 2023</p>
<p>Zero-1-to-3: Zero-shot One Image to 3D Object. R Liu, R Wu, B V Hoorick, P Tokmakov, S Zakharov, C Vondrick, 2023</p>
<p>G Qian, J Mai, A Hamdi, J Ren, A Siarohin, B Li, H.-Y Lee, I Skorokhodov, P Wonka, S Tulyakov, B Ghanem, Magic123: One Image to High-Quality 3D Object Generation Using Both 2D and 3D Diffusion Priors. 2023</p>
<p>A Haque, M Tancik, A A Efros, A Holynski, A Kanazawa, Instruct-NeRF2NeRF: Editing 3D Scenes with Instructions. 2023</p>
<p>R Gao, A Holynski, P Henzler, A Brussee, R Martin-Brualla, P Srinivasan, J T Barron, B Poole, CAT3D: Create Anything in 3D with Multi-View Diffusion Models. 2024</p>
<p>Make-A-Video: Text-to-Video Generation without Text-Video Data. U Singer, A Polyak, T Hayes, X Yin, J An, S Zhang, Q Hu, H Yang, O Ashual, O Gafni, D Parikh, S Gupta, Y Taigman, 2022</p>
<p>Imagen Video: High Definition Video Generation with Diffusion Models. J Ho, W Chan, C Saharia, J Whang, R Gao, A Gritsenko, D P Kingma, B Poole, M Norouzi, D J Fleet, T Salimans, 2022</p>
<p>Align your Latents: High-Resolution Video Synthesis with Latent Diffusion Models. A Blattmann, R Rombach, H Ling, T Dockhorn, S W Kim, S Fidler, K Kreis, 2023</p>
<p>Photorealistic Video Generation with Diffusion Models. A Gupta, L Yu, K Sohn, X Gu, M Hahn, L Fei-Fei, I Essa, L Jiang, J Lezama, 2023</p>
<p>VideoPoet: A Large Language Model for Zero-Shot Video Generation. D Kondratyuk, L Yu, X Gu, J Lezama, J Huang, G Schindler, R Hornung, V Birodkar, J Yan, M.-C Chiu, K Somandepalli, H Akbari, Y Alon, Y Cheng, J Dillon, A Gupta, M Hahn, A Hauth, D Hendon, A Martinez, D Minnen, M Sirotenko, K Sohn, X Yang, H Adam, M.-H Yang, I Essa, H Wang, D A Ross, B Seybold, L Jiang, 2024</p>
<p>. T Brooks, B Peebles, C Holmes, W Depue, Y Guo, L Jing, D Schnurr, J Taylor, T Luhman, E Luhman, C Ng, R Wang, A Ramesh, 2024</p>
<p>B Mildenhall, P P Srinivasan, M Tancik, J T Barron, R Ramamoorthi, R Ng, Computer Vision -ECCV 2020. Cham2020</p>
<p>B Kerbl, G Kopanas, T Leimkühler, G Drettakis, 3D Gaussian Splatting for Real-Time Radiance Field Rendering. 2023</p>
<p>G Wu, T Yi, J Fang, L Xie, X Zhang, W Wei, W Liu, Q Tian, X Wang, 4D Gaussian Splatting for Real-Time Dynamic Scene Rendering. 2023</p>
<p>Z Li, Z Chen, Z Li, Y Xu, Spacetime Gaussian Feature Splatting for Real-Time Dynamic View Synthesis. 2024</p>
<p>J Ren, K Xie, A Mirzaei, H Liang, X Zeng, K Kreis, Z Liu, A Torralba, S Fidler, S W Kim, H Ling, L4GM: Large 4D Gaussian Reconstruction Model. 2024</p>
<p>R Shao, J Sun, C Peng, Z Zheng, B Zhou, H Zhang, Y Liu, Control4D: Efficient 4D Portrait Editing with Text. 2023</p>
<p>S Peng, Y Zhang, K Li, PAPR in Motion: Seamless Point-level 3D Scene Interpolation. 2024</p>
<p>H Yu, C Wang, P Zhuang, W Menapace, A Siarohin, J Cao, L A Jeni, S Tulyakov, H.-Y Lee, 4Real: Towards Photorealistic 4D Scene Generation via Video Diffusion Models. 2024</p>
<p>Vidu4D: Single Generated Video to High-Fidelity 4D Reconstruction with Dynamic Gaussian Surfels. Y Wang, X Wang, Z Chen, Z Wang, F Sun, J Zhu, 2024</p>
<p>ASH: Animatable Gaussian Splats for Efficient and Photoreal Human Rendering. H Pang, H Zhu, A Kortylewski, C Theobalt, M Habermann, 2024</p>
<p>D Duckworth, P Hedman, C Reiser, P Zhizhin, J.-F Thibert, M Lučić, R Szeliski, J T Barron, SMERF: Streamable Memory Efficient Radiance Fields for Real-Time Large-Scene Exploration. 2024</p>
<p>. Z Peng, T Shao, L Yong, J Zhou, Y Yang, J Wang, K Zhou, 2024</p>
<p>J Lin, Z Li, X Tang, J Liu, S Liu, J Liu, Y Lu, X Wu, S Xu, Y Yan, W Yang, VastGaussian: Vast 3D Gaussians for Large Scene Reconstruction. 2024</p>
<p>E Weber, A Hołyński, V Jampani, S Saxena, N Snavely, A Kar, A Kanazawa, NeRFiller: Completing Scenes via Generative 3D Inpainting. 2023</p>
<p>J Seo, K Fukuda, T Shibuya, T Narihira, N Murata, S Hu, C.-H Lai, S Kim, Y Mitsufuji, GenWarp: Single Image to Novel Views with Semantic-Preserving Generative Warping. 2024</p>
<p>Introducing PRISM-1: Photorealistic reconstruction in static and dynamic scenes. W Ai, </p>
<p>3D-Aware Manipulation with Object-Centric Gaussian Splatting. </p>
<p>Physically Embodied Gaussian Splatting: A Realtime Correctable World Model for Robotics. </p>
<p>Y Li, D Pathak, ICRA 2024 Workshop on 3D Visual Representations for Robot Manipulation. 2024</p>
<p>S Xue, J Dill, P Mathur, F Dellaert, P Tsiotras, D Xu, Neural Visibility Field for Uncertainty-Driven Active Mapping. 2024</p>
<p>. N R Smalheiser, Journal of the American Society for Information Science and Technology. 632012</p>
<p>. S Henry, B T Mcinnes, Journal of Biomedical Informatics. 742017</p>
<p>. M Thilakaratne, K Falkner, T Atapattu, ACM Comput. Surv. 522019</p>
<p>. M Krenn, R Pollice, S Y Guo, M Aldeghi, A Cervera-Lierta, P Friederich, G Dos Passos, F Gomes, A Häse, A Jinich, Z Nigam, A Yao, Aspuru-Guzik, Nature Reviews Physics. 42022</p>
<p>. S R Young, A Maksov, M Ziatdinov, Y Cao, M Burch, J Balachandran, L Li, S Somnath, R M Patton, S V Kalinin, R K Vasudevan, Journal of Applied Physics. 1153032018</p>
<p>. R Kumar, A Joshi, S A Khan, S Misra, Digital Discovery. 32024</p>
<p>LLaMP: Large Language Model Made Powerful for High-fidelity Materials Knowledge Retrieval and Distillation. Y Chiang, E Hsieh, C.-H Chou, J Riebesell, 2024</p>
<p>Bayesian Optimization of Catalysts With In-context Learning. M C Ramos, S S Michtavy, M D Porosoff, A D White, 2023</p>
<p>. B M Lake, M Baroni, Nature. 6232023</p>
<p>Can large language models provide useful feedback on research papers? A large-scale empirical analysis. W Liang, Y Zhang, H Cao, B Wang, D Ding, X Yang, K Vodrahalli, S He, D Smith, Y Yin, D Mcfarland, J Zou, 2023</p>
<p>Large Language Models are Effective Text Rankers with Pairwise Ranking Prompting. Z Qin, R Jagerman, K Hui, H Zhuang, J Wu, J Shen, T Liu, J Liu, D Metzler, X Wang, M Bendersky, 2023</p>
<p>D Paranyushkin, The World Wide Web Conference. New York, NY, USA2019</p>
<p>. M Krenn, L Buffoni, B Coutinho, S Eppel, J G Foster, A Gritsevskiy, H Lee, Y Lu, J P Moutinho, N Sanjabi, R Sonthalia, N M Tran, F Valente, Y Xie, R Yu, M Kopp, Nature Machine Intelligence. 52023</p>
<p>S Kambhampati, K Valmeekam, L Guan, M Verma, K Stechly, S Bhambri, L Saldyt, A Murthy, LLMs Can't Plan, But Can Help Planning in LLM-Modulo Frameworks. 2024</p>
<p>. S Farquhar, J Kossen, L Kuhn, Y Gal, Nature. 6302024</p>
<p>Calibrated Language Models Must Hallucinate. A T Kalai, S S Vempala, 2024</p>
<p>Creativity Has Left the Chat: The Price of Debiasing Language Models. B Mohammadi, 2024</p>
<p>Confabulation: The Surprising Value of Large Language Model Hallucinations. P Sui, E Duede, S Wu, R J So, 2024</p>
<p>M Koivisto, S Grassini, Scientific Reports. 20231313601</p>
<p>J Haase, P H P Hanel, Artificial muses: Generative Artificial Intelligence Chatbots Have Risen to Human-Level Creativity. 2023</p>
<p>. K Girotra, L Meincke, C Terwiesch, K T Ulrich, Ssrn, 2023</p>
<p>. L Boussioux, J N Lane, M Zhang, V Jacimovic, K R Lakhani, Harvard Business School Technology &amp; Operations Mgt. Unit Working Paper. 2023</p>
<p>. A R Doshi, O Hauser, Ssrn, 2023</p>
<p>B S Manning, K Zhu, J J Horton, Automated Social Science: Language Models as Scientist and Subjects. 2024</p>
<p>Y J Ma, W Liang, H.-J Wang, S Wang, Y Zhu, L Fan, O Bastani, D Jayaraman, DrEureka: Language Model Guided Sim-To-Real Transfer. 2024</p>
<p>Learning to Generate Novel Scientific Directions with Contextualized Literature-based Discovery. Q Wang, D Downey, H Ji, T Hope, 2023</p>
<p>Q Wang, D Downey, H Ji, T Hope, SciMON: Scientific Inspiration Machines Optimized for Novelty. 2024</p>
<p>. C Olah, A Mordvintsev, L Schubert, Distill , 2017</p>
<p>In-Context Learning Creates Task Vectors. R Hendel, M Geva, A Globerson, 2023</p>
<p>Function Vectors in Large Language Models. E Todd, M L Li, A S Sharma, A Mueller, B C Wallace, D Bau, 2024</p>
<p>Refusal in LLMs is mediated by a single direction. A Arditi, O Obeso, N Aaquib111, Nanda, LessWrong. 2024</p>
<p>Improving Alignment and Robustness with Circuit Breakers. A Zou, L Phan, J Wang, D Duenas, M Lin, M Andriushchenko, R Wang, Z Kolter, M Fredrikson, D Hendrycks, 2024</p>
<p>The Linear Representation Hypothesis and the Geometry of Large Language Models. K Park, Y J Choe, V Veitch, 2023</p>
<p>The Geometry of Categorical and Hierarchical Concepts in Large Language Models. K Park, Y J Choe, Y Jiang, V Veitch, 2024</p>
<p>T Bricken, A Templeton, J Batson, B Chen, A Jermyn, T Conerly, N Turner, C Anil, C Denison, A Askell, R Lasenby, Y Wu, S Kravec, N Schiefer, T Maxwell, N Joseph, Z Hatfield-Dodds, A Tamkin, K Nguyen, B Mclean, J E Burke, T Hume, S Carter, T Henighan, C Olah, Transformer Circuits Thread. 2023</p>
<p>A Templeton, T Conerly, J Marcus, J Lindsey, T Bricken, B Chen, A Pearce, C Citro, E Ameisen, A Jones, H Cunningham, N L Turner, C Mcdougall, M Macdiarmid, C D Freeman, T R Sumers, E Rees, J Batson, A Jermyn, S Carter, C Olah, T Henighan, Transformer Circuits Thread. 2024</p>
<p>Scaling and evaluating sparse autoencoders. L Gao, T D Tour, H Tillman, G Goh, R Troll, A Radford, I Sutskever, J Leike, J Wu, 2024</p>
<p>Aligning Large Language Models with Human: A Survey. Y Wang, W Zhong, L Li, F Mi, X Zeng, W Huang, L Shang, X Jiang, Q Liu, 2023</p>
<p>LoRA: Low-Rank Adaptation of Large Language Models. E J Hu, Y Shen, P Wallis, Z Allen-Zhu, Y Li, S Wang, L Wang, W Chen, 2021</p>
<p>QLoRA: Efficient Finetuning of Quantized LLMs. T Dettmers, A Pagnoni, A Holtzman, L Zettlemoyer, 2023</p>
<p>DoRA: Weight-Decomposed Low-Rank Adaptation. S.-Y Liu, C.-Y Wang, H Yin, P Molchanov, Y.-C F Wang, K.-T Cheng, M.-H Chen, 2024</p>
<p>Y Bai, S Kadavath, S Kundu, A Askell, J Kernion, A Jones, A Chen, A Goldie, A Mirhoseini, C Mckinnon, C Chen, C Olsson, C Olah, D Hernandez, D Drain, D Ganguli, D Li, E Tran-Johnson, E Perez, J Kerr, J Mueller, J Ladish, J Landau, K Ndousse, K Lukosuite, L Lovitt, M Sellitto, N Elhage, N Schiefer, N Mercado, N Dassarma, R Lasenby, R Larson, S Ringer, S Johnston, S Kravec, S E Showk, S Fort, T Lanham, T Telleen-Lawton, T Conerly, T Henighan, T Hume, S R Bowman, Z Hatfield-Dodds, B Mann, D Amodei, N Joseph, S Mccandlish, T Brown, J Kaplan, Constitutional AI: Harmlessness from AI Feedback. 2022</p>
<p>Preference Ranking Optimization for Human Alignment. F Song, B Yu, M Li, H Yu, F Huang, Y Li, H Wang, 2024</p>
<p>Self-Alignment with Instruction Backtranslation. X Li, P Yu, C Zhou, T Schick, O Levy, L Zettlemoyer, J Weston, M Lewis, 2024</p>
<p>Principle-Driven Self-Alignment of Language Models from Scratch with Minimal Human Supervision. Z Sun, Y Shen, Q Zhou, H Zhang, Z Chen, D Cox, Y Yang, C Gan, 2023</p>
<p>J Pfau, A Infanger, A Sheshadri, A Panda, J Michael, C Huebner, Socially Responsible Language Modelling Research. 2023</p>
<p>LEACE: Perfect linear concept erasure in closed form. N Belrose, D Schneider-Joseph, S Ravfogel, R Cotterell, E Raff, S Biderman, 2023</p>
<p>Eliciting Latent Predictions from Transformers with the Tuned Lens. N Belrose, Z Furman, L Smith, D Halawi, I Ostrovsky, L Mckinney, S Biderman, J Steinhardt, 2023</p>
<p>L Aschenbrenner, Situational Awareness: The Decade Ahead. 2024</p>
<p>. D E Rumelhart, G E Hinton, R J Williams, Nature. 3231986</p>
<p>M Yuksekgonul, F Bianchi, J Boen, S Liu, Z Huang, C Guestrin, J Zou, TextGrad: Automatic "Differentiation" via Text. 2024</p>
<p>Chain-of-Thought Prompting Elicits Reasoning in Large Language Models. J Wei, X Wang, D Schuurmans, M Bosma, B Ichter, F Xia, E Chi, Q Le, D Zhou, 2023</p>
<p>Large Language Models are Zero-Shot Reasoners. T Kojima, S S Gu, M Reid, Y Matsuo, Y Iwasawa, 2023</p>
<p>Let's Think Dot by Dot: Hidden Computation in Transformer Language Models. J Pfau, W Merrill, S R Bowman, 2024</p>
<p>Buffer of Thoughts: Thought-Augmented Reasoning with Large Language Models. L Yang, Z Yu, T Zhang, S Cao, M Xu, W Zhang, J E Gonzalez, B Cui, 2024</p>
<p>W Chen, Y Su, J Zuo, C Yang, C Yuan, C.-M Chan, H Yu, Y Lu, Y.-H Hung, C Qian, Y Qin, X Cong, R Xie, Z Liu, M Sun, J Zhou, AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors. 2023</p>
<p>MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework. S Hong, M Zhuge, J Chen, X Zheng, Y Cheng, C Zhang, J Wang, Z Wang, S K S Yau, Z Lin, L Zhou, C Ran, L Xiao, C Wu, J Schmidhuber, 2023</p>
<p>J S Park, J C O'brien, C J Cai, M R Morris, P Liang, M S Bernstein, Generative Agents: Interactive Simulacra of Human Behavior. 2023</p>
<p>M Zhuge, H Liu, F Faccio, D R Ashley, R Csordás, A Gopalakrishnan, A Hamdi, H A A K Hammoud, V Herrmann, K Irie, L Kirsch, B Li, G Li, S Liu, J Mai, P Piękos, A Ramesh, I Schlag, W Shi, A Stanić, W Wang, Y Wang, M Xu, D.-P Fan, B Ghanem, J Schmidhuber, Mindstorms in Natural Language-Based Societies of Mind. 2023</p>
<p>I Frisch, M Giulianelli, LLM Agents in Interaction: Measuring Personality Consistency and Linguistic Alignment in Interacting Populations of Large Language Models. 2024</p>
<p>T Guo, X Chen, Y Wang, R Chang, S Pei, N V Chawla, O Wiest, X Zhang, Large Language Model based Multi-Agents: A Survey of Progress and Challenges. 2024</p>
<p>Mixture-of-Agents Enhances Large Language Model Capabilities. J Wang, J Wang, B Athiwaratkun, C Zhang, J Zou, 2024</p>
<p>Describe, Explain, Plan and Select: Interactive Planning with Large Language Models Enables Open-World Multi-Task Agents. Z Wang, S Cai, G Chen, A Liu, X Ma, Y Liang, 2023</p>
<p>S Abdelnabi, A Gomaa, S Sivaprasad, L Schönherr, M Fritz, LLM-Deliberation: Evaluating LLMs with Interactive Multi-Agent Negotiation Games. 2023</p>
<p>Self-collaboration Code Generation via ChatGPT. Y Dong, X Jiang, Z Jin, G Li, 2024</p>
<p>Beyond Human Translation: Harnessing Multi-Agent Collaboration for Translating Ultra-Long Literary Texts. M Wu, Y Yuan, G Haffari, L Wang, 2024</p>
<p>. A Bhoopchand, B Brownfield, A Collister, A Lago, A Edwards, R Everett, A Frechette, Y G Oliveira, E Hughes, K W Mathewson, P Mendolicchio, J Pawar, M Pislar, A Platonov, E Senter, S Singh, A Zacherl, L M Zhang, Nature Communications. 75362023</p>
<p>J Perez, C Léger, M Ovando-Tellez, C Foulon, J Dussauld, P.-Y Oudeyer, C Moulin-Frier, Cultural evolution in populations of Large Language Models. 2024</p>
<p>Scaling Scaling Laws with Board Games. A L Jones, 2021</p>
<p>R Agarwal, A Singh, L M Zhang, B Bohnet, L Rosias, S Chan, B Zhang, A Anand, Z Abbas, A Nova, J D Co-Reyes, E Chu, F Behbahani, A Faust, H Larochelle, Many-Shot In-Context Learning. 2024</p>
<p>R Greenblatt, Getting 50% (SoTA) on ARC-AGI with GPT-4o. 2024</p>
<p>D Kahneman, P Slovic, A Tversky, Judgment Under Uncertainty: Heuristics and Biases. CambridgeCambridge University Press1982</p>
<p>. K E Stanovich, R F West, Behavioral and Brain Sciences. 232000</p>
<p>. D Kahneman, American Psychologist. 582003</p>
<p>. J S Evans, Trends in Cognitive Sciences. 72003</p>
<p>. U N Sio, T C Ormerod, Psychological Bulletin. 1352009</p>
<p>. R E Beaty, M Benedek, S Barry Kaufman, P J Silvia, Scientific Reports. 2015, 5, 10964</p>
<p>. J E Driskell, R P Willis, C Copper, Journal of Applied Psychology. 771992</p>
<p>. A Maravita, A Iriki, Trends in Cognitive Sciences. 82004</p>
<p>FLOW: The Psychology of Optimal Experience. M Csikszentmihalyi, 1990Harper and Row</p>
<p>. J E V Gary, D Ellis, C Morris, Journal of Leisure Research. 261994</p>
<p>. J Gold, J Ciorciari, Behavioral Sciences (Basel). 1372020</p>
<p>J Michael, S Mahdi, D Rein, J Petty, J Dirani, V Padmakumar, S R Bowman, Debate Helps Supervise Unreliable Experts. 2023</p>
<p>A Khan, J Hughes, D Valentine, L Ruis, K Sachan, A Radhakrishnan, E Grefenstette, S R Bowman, T Rocktäschel, E Perez, Debating with More Persuasive LLMs Leads to More Truthful Answers. 2024</p>
<p>. J W A Strachan, D Albergo, G Borghini, O Pansardi, E Scaliti, S Gupta, K Saxena, A Rufo, S Panzeri, G Manzi, M S A Graziano, C Becchio, Nature Human Behaviour. 2024</p>
<p>W Street, J O Siy, G Keeling, A Baranes, B Barnett, M Mckibben, T Kanyere, A Lentz, B A Arcas, R I M Dunbar, LLMs achieve adult human performance on higher-order theory of mind tasks. 2024</p>
<p>National Labs Should Be World-Leaders in Data Management. J Connolly, F Poli, P Nugent, W J Shaw, K G Yager, Oppenheimer Science &amp; Energy Leadership Program Think Pieces. 2021</p>
<p>M D Wilkinson, M Dumontier, I J Aalbersberg, G Appleton, M Axton, A Baak, N Blomberg, J.-W Boiten, L B Da Silva Santos, P E Bourne, J Bouwman, A J Brookes, T Clark, M Crosas, I Dillo, O Dumon, S Edmunds, C T Evelo, R Finkers, A Gonzalez-Beltran, A J Gray, P Groth, C Goble, J S Grethe, J Heringa, P A . 't Hoen, R Hooft, T Kuhn, R Kok, J Kok, S J Lusher, M E Martone, A Mons, A L Packer, B Persson, P Rocca-Serra, M Roos, R Van Schaik, S.-A Sansone, E Schultes, T Sengstag, T Slater, G Strawn, M A Swertz, M Thompson, J Van Der Lei, E Van Mulligen, J Velterop, A Waagmeester, P Wittenburg, K Wolstencroft, J Zhao, B Mons, Scientific Data. 2016, 3, 160018</p>
<p>H Lai, X Liu, I L Iong, S Yao, Y Chen, P Shen, H Yu, H Zhang, X Zhang, Y Dong, J Tang, AutoWebGLM: Bootstrap And Reinforce A Large Language Model-based Web Navigating Agent. 2024</p>
<p>Autonomous Evaluation and Refinement of Digital Agents. J Pan, Y Zhang, N Tomlin, Y Zhou, S Levine, A Suhr, 2024</p>
<p>T Xie, D Zhang, J Chen, X Li, S Zhao, R Cao, T J Hua, Z Cheng, D Shin, F Lei, Y Liu, Y Xu, S Zhou, S Savarese, C Xiong, V Zhong, T Yu, OSWorld: Benchmarking Multimodal Agents for Open-Ended Tasks in Real Computer Environments. 2024</p>
<p>DigiRL: Training In-The-Wild Device-Control Agents with Autonomous Reinforcement Learning. H Bai, Y Zhou, M Cemri, J Pan, A Suhr, S Levine, A Kumar, 2024</p>
<p>Z Zhao, T Chavez, E A Holman, G Hao, A Green, H Krishnan, D Mcreynolds, R J Pandolfi, E J Roberts, P H Zwart, H Yanxon, N Schwarz, S Sankaranarayanan, S V Kalinin, A Mehta, S I Campbell, A Hexemer, 4th Annual Workshop on Extreme-scale Experiment-in-the-Loop Computing. 2022. 2022</p>
<p>Transcendence: Generative Models Can Outperform The Experts That Train Them. E Zhang, V Zhu, N Saphra, A Kleiman, B L Edelman, M Tambe, S M Kakade, E Malach, 2024</p>            </div>
        </div>

    </div>
</body>
</html>