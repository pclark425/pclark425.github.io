<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2514 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2514</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2514</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-68.html">extraction-schema-68</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <p><strong>Paper ID:</strong> paper-211096951</p>
                <p><strong>Paper Title:</strong> <a href="https://arxiv.org/pdf/2002.05635v1.pdf" target="_blank">AGATHA: Automatic Graph-mining And Transformer based Hypothesis generation Approach</a></p>
                <p><strong>Paper Abstract:</strong> Medical research is risky and expensive. Drug discovery, as an example, requires that researchers efficiently winnow thousands of potential targets to a small candidate set for more thorough evaluation. However, research groups spend significant time and money to perform the experiments necessary to determine this candidate set long before seeing intermediate results. Hypothesis generation systems address this challenge by mining the wealth of publicly available scientific information to predict plausible research directions. We present AGATHA, a deep-learning hypothesis generation system that can introduce data-driven insights earlier in the discovery process. Through a learned ranking criteria, this system quickly prioritizes plausible term-pairs among entity sets, allowing us to recommend new research directions. We massively validate our system with a temporal holdout wherein we predict connections first introduced after 2015 using data published beforehand. We additionally explore biomedical sub-domains, and demonstrate AGATHA's predictive capacity across the twenty most popular relationship types. This system achieves best-in-class performance on an established benchmark, and demonstrates high recommendation scores across subdomains. Reproducibility: All code, experimental data, and pre-trained models are available online: sybrandt.com/2020/agatha</p>
                <p><strong>Cost:</strong> 0.024</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2514.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2514.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AGATHA</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Automatic Graph-mining And Transformer based Hypothesis generation Approach</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A large-scale biomedical hypothesis generation system that constructs a multi-layer semantic graph of MEDLINE sentences, embeds it with a distributed graph embedding, and uses a transformer-encoder ranking model to score plausibility of candidate term-term hypotheses.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>AGATHA</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Builds a semantic multi-layer graph (sentences, predicates, lemmas, entities, n-grams, UMLS/MeSH/coded terms) from MEDLINE (pre-2015 for validation). Embeds the heterogeneous graph with PyTorch-BigGraph (PTBG) into 256/512-d vectors using typed translations and dot-product scoring. For hypothesis ranking, AGATHA forms input sets combining a candidate subject-object pair and neighborhood predicate samples, encodes each element via the graph embedding and a feed-forward layer, passes the sequence through a 4-layer transformer encoder (multi-head self-attention, no positional encoding), averages encoder outputs, projects to a scalar with a sigmoid to produce a plausibility score H(X). Training uses positive SemRep predicates and two negative-sampling schemes (scrambles and swaps), a margin ranking loss (m=0.1), LAMB optimizer, large batches across multiple GPUs, and temporal holdout evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>knowledge-graph-based + transformer ranking (hybrid neural graph + encoder)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>biomedicine / biomedical literature mining (drug discovery, gene-disease, molecular biology, clinical research)</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Generates candidate hypotheses by enumerating candidate term-pairs (UMLS-coded terms) and scoring them with a learned transformer ranking model that takes as input the pair plus sampled neighborhood predicates; candidates come from the semantic graph built from sentence adjacency, approximate nearest-neighbors of SciBERT sentence embeddings (FAISS + PQ), and SemRep predicate nodes.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td>Temporal holdout: treats connections first appearing after the cutoff date (post-2015) as novel positives; selects positive validation predicates by rapid growth in post-cutoff popularity within subdomains. No explicit novelty-scoring beyond ranking and temporal validation.</td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Learned ranking function H(X): transformer-encoder over PTBG graph embeddings producing sigmoid plausibility scores; trained to rank published SemRep predicates above negative samples using margin ranking loss. Also uses downstream recommendation metrics (ROC AUC, PR AUC, top-k precision, AP.@k, RR, MAP, MRR) to quantify plausibility performance.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td>Implicit via training and validation on published predicates and negative-sampling (scrambles/swaps) plus temporal-holdout: model is optimized to place published (plausible) predicates above negatives, and novelty is operationalized by temporal holdout (post-cutoff appearance). No explicit optimization trade-off parameter reported between novelty and plausibility.</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td>ROC AUC (receiver-operating-characteristic area), PR AUC (precision-recall area), top-k precision (P.@k), average precision at k (AP.@k), reciprocal rank (RR), mean average precision (MAP.@k), mean reciprocal rank (MRR.@k).</td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Large-scale computational validation via temporal holdout: train on pre-2015 data, predict connections first published after 2015; benchmark against a previously published validation set and perform many-to-many recommendation evaluation across 20 biomedical subdomains. Metrics computed include ROC AUC, PR AUC, and recommendation metrics. No new wet-lab experimental validation is reported for AGATHA in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td>Code, experimental data, and pre-trained models released online; detailed training hyperparameters reported (embedding dims 256/512, negative sampling 100 per edge for PTBG, neighborhood subsample s=15, margin m=0.1, LAMB optimizer, learning rate 0.01 with warmup, cross-validation on 1% holdout), and hardware resources (clusters, GPUs) described.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td>Mitigations include training on published SemRep predicates (so model learns from published links), using swap negative samples to force finer semantic discrimination, and providing an interpretable topic-modeling path (LDA topic models and sentence-paths) for human inspection; no explicit algorithmic hallucination-filtering or factual grounding module is reported.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td>Not explicitly provided; detection is left to human-in-the-loop interpretability tools (topic-model outputs, returned sentence paths) and validation against temporal ground truth. No automated hallucination classifier reported.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td>Model outputs a sigmoid score in [0,1] as a plausibility score; ranking margin loss and validation metrics quantify separation between positives and negatives. No Bayesian uncertainty estimation, calibration statistics, confidence intervals, or ensemble uncertainty methods are reported.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td>SemMedDB predicates (SemRep extracted predicates) from MEDLINE pre-2015 for training; a 2015 temporal holdout benchmark and the prior Moliere benchmark (as reported in [38]) used for comparison. Subdomain-specific evaluation used top-100 post-2015 growing predicates per semantic-type pair.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>AGATHA-512: ROC AUC = 0.901, PR AUC = 0.936. AGATHA-256: ROC AUC = 0.826, PR AUC = 0.895. Subdomain metrics reported (examples): (Gene→Cell Function) top-10 average precision 0.83 and mean-reciprocal-rank 0.61; many-to-many recommendation P.@10 and MAP/MRR reported per subdomain (detailed per-table in paper). Wall-time per-query reduced from minutes (Moliere topic-modeling pipeline) to milliseconds.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>Compared to Moliere (Medline): AGATHA-512 improves ROC AUC from 0.718 to 0.901 (~25% relative increase). Compared to Moliere (Full Text): AGATHA-512 improves ROC AUC from 0.795 to 0.901 (~13% relative increase). AGATHA also offers large speedups (ms per query vs minutes).</td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Relies on SemRep predicates which are noisy and restricted to UMLS-coded entities; no direct method to incorporate arbitrary experimental data (only network-convertible experimental results are straightforward to add); interpretability is limited for large-scale queries requiring switch to topic-modeling and human inspection; no explicit hallucination-detection, uncertainty calibration, or experimental wet-lab validation reported for AGATHA in this work.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'AGATHA: Automatic Graph-mining And Transformer based Hypothesis generation Approach', 'publication_date_yy_mm': '2020-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2514.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2514.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Moliere</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Moliere (prior automatic biomedical hypothesis generation system)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An earlier system by the authors that finds short paths in a semantic graph and generates LDA topic models over the sentences near those paths, combined with heuristic plausibility ranking measures to recommend hypotheses.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Moliere</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Constructs semantic heterogeneous graphs of biomedical entities and finds short paths connecting query terms. Produces LDA topic models from sentences around returned paths for human interpretability. Uses heuristic metrics (embedding-based keyword-topic similarity, network-analytic measures on topic-nearest-neighbors) combined into a meta-measure to quantify plausibility of candidate hypotheses.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>knowledge-graph-based + topic-model interpretability</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>biomedicine (literature-based discovery)</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>ABC-style or path-based literature-based discovery: find intermediary terms/paths (A−B−C) and summarize associated texts via LDA to present candidate B terms or topics that connect A and C.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td>Heuristic ranking that prioritized topic-model signals and network measures; temporal validation used in later benchmarking but no formal novelty scoring beyond heuristics.</td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Heuristic plausibility metrics: embedding similarity between keywords and topics, and network-analytic measures on topic-nearest-neighbors aggregated into a meta-score.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td>Relies on heuristics which tended to bias toward incremental discoveries; no explicit formal trade-off between novelty and plausibility reported.</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td>Used the same benchmarking metrics in follow-up evaluation (ROC AUC, PR AUC, top-k precision, AP, RR) when compared to AGATHA; original internal metrics were heuristic meta-scores derived from topic/embedding measures.</td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Computational validation and human-in-the-loop case studies (e.g., previously reported discovery of DDX3 inhibition related to HIV-associated neurodegenerative disease).</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td>Open-source prior implementation and published heuristics in prior work; not detailed in this paper beyond references.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td>Human oversight / scientist-in-the-loop via topic-model inspection and path inspection; heuristics to rank plausible topics helped reduce false leads.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td>Manual expert review of topic-model outputs and path sentences; no automated hallucination detector reported.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td>Heuristic meta-scores produce scalar plausibility values; no probabilistic uncertainty quantification reported.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td>MEDLINE, and in some runs PubMed Central full text (used in prior comparisons).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Reported baseline ROC AUC (Moliere: Medline) = 0.718, PR AUC = 0.820; (Moliere: Full Text) ROC AUC = 0.795, PR AUC = 0.778 (as reported in the benchmark compared by AGATHA).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td>Previously reported discovery (via Moliere) of DDX3 inhibition as a candidate treatment target for HIV-associated neurodegenerative disease that led to follow-up experimental work (referenced in paper).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Requires significant human oversight, computationally expensive (topic-modeling, shortest-path computations), biased toward incremental/ABC-style discoveries, and slower per-query runtime (minutes) especially when using full text.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'AGATHA: Automatic Graph-mining And Transformer based Hypothesis generation Approach', 'publication_date_yy_mm': '2020-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2514.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2514.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ARROWSMITH</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ARROWSMITH (Swanson's hypothesis generation system)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A foundational literature-based discovery (LBD) system that applied the ABC model to identify implicit connections by mining co-occurring keywords across MEDLINE titles, famously discovering the fish oil–Raynaud's syndrome link.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>ARROWSMITH</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Implements the ABC model: given terms A and C, finds intermediate B-terms appearing with A and with C separately (co-occurrence analysis) to suggest A−B−C hypotheses based on shared keywords across literature.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>co-occurrence / ABC-model literature-based discovery</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>biomedicine (literature mining)</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Mining title/keyword co-occurrences to produce intermediary terms that connect two otherwise unlinked concepts.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td>Implicit (novelty via lack of explicit prior A–C co-occurrence); no formal novelty scoring beyond bibliographic absence.</td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Heuristic plausibility via co-occurrence counts and domain knowledge; no statistical ranking model reported in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Historical case studies (e.g., fish oil → Raynaud's).</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td>MEDLINE titles / keywords (historical)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td>Fish oil — Raynaud's syndrome connection (historical demonstration).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>ABC co-occurrence approach scales poorly, biases toward incremental discoveries, and depends heavily on heuristically determined term-lists and manual validation.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'AGATHA: Automatic Graph-mining And Transformer based Hypothesis generation Approach', 'publication_date_yy_mm': '2020-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2514.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2514.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>IBM Watson (Watson for Drug Discovery)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Watson for Drug Discovery (IBM Watson application)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A commercial cognitive/computational system that applies NLP and curated knowledge to help identify potential therapeutic hypotheses and associations; cited as an example of visual/interpretability-driven hypothesis discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Watson for Drug Discovery</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Closed-source cognitive computing platform combining text mining, knowledge graphing, and visualization to surface candidate biomedical insights to domain experts (as cited historically for case studies).</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>commercial cognitive NLP + knowledge-based system</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>biomedicine / drug discovery</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Text mining + knowledge graph traversal + expert-in-the-loop interpretation (details not provided in this paper).</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Cited case studies in literature (no details in this paper).</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td>Cited example: Watson's reported discovery related to ALS treatments in prior work (referenced).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Closed-source; requires human oversight for interpretation; not directly compared experimentally in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'AGATHA: Automatic Graph-mining And Transformer based Hypothesis generation Approach', 'publication_date_yy_mm': '2020-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2514.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2514.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GrEDeL</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GrEDeL (knowledge-graph-embedding based hypothesis generator)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A recent deep-learning approach that uses paths in a predicate knowledge graph and an LSTM model to evaluate drug–disease association paths; cited and contrasted in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>GrEDeL</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Constructs a knowledge graph from SemRep predicates, enumerates paths between entities (e.g., drug and disease), and scores those paths using an LSTM trained on features of the path; embeddings used were TransE in that work.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>knowledge-graph-embedding + LSTM path-scoring</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>biomedicine (drug-disease discovery)</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Enumerate graph paths that connect query pairs and evaluate them with an LSTM classifier to propose plausible associations.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>LSTM path classifier trained to rank drug-disease associations.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Computational evaluation on drug–disease associations but limited generalization beyond that subdomain (per paper's critique).</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td>SemRep predicate graph (used by authors of GrEDeL)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Relies on noisy SemRep path sequences, needs manual filtering of false positives, is specialized to drug–disease discovery, and used TransE embeddings which may under-represent variance across many relation types (per AGATHA paper critique).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'AGATHA: Automatic Graph-mining And Transformer based Hypothesis generation Approach', 'publication_date_yy_mm': '2020-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2514.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e2514.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SemRep / SemMedDB</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>SemRep (predicate extraction) and SemMedDB (predicate database)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>SemRep extracts subject-verb-object predicates from MEDLINE and maps components to UMLS coded terms; SemMedDB is the collection of SemRep-extracted predicates used as training and validation data.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>SemRep / SemMedDB</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>SemRep performs predicate extraction (subject-verb-object) from biomedical text and maps predicates' components to UMLS semantic types and coded terms; SemMedDB aggregates these predicates across MEDLINE and is used here as the source of positive training examples (19M+ pre-2015 predicates).</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>information extraction / knowledge-base construction</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>biomedicine / biomedical NLP</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Not a generator itself, but provides published predicate triples used as positive exemplars for supervised ranking and as graph nodes in the semantic graph.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Used as ground-truth positives for temporal holdout validation: predicates first appearing after cutoff are treated as novel positives.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td>SemMedDB is a public resource; used here as a reproducible training/validation set though authors note it contains noise.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td>SemMedDB (SemRep predicates) extracted from MEDLINE; >19M predicates pre-2015 used for training.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Predicate set is noisy, may contain incorrect/obsolete algorithmic extractions; restricted to entities coded in UMLS which limits coverage.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'AGATHA: Automatic Graph-mining And Transformer based Hypothesis generation Approach', 'publication_date_yy_mm': '2020-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2514.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e2514.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SciBERT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>SciBERT (pretrained contextualized embeddings for scientific text)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A BERT-family transformer model pre-trained on a large corpus of scientific text; used to produce 768-d context-sensitive sentence embeddings (averaging final hidden layer) for nearest-neighbor sentence similarity in AGATHA.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>SciBERT</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Pretrained transformer-based language model adapted to scientific text (vocabulary and corpora), used here to derive 768-dimensional contextualized embeddings per sentence by averaging the final hidden layer outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>LLM-based contextual embedding model</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>scientific / biomedical NLP</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Not a hypothesis generator; supplies sentence-level contextual embeddings used to construct a sentence similarity graph (via FAISS) which contributes edges to the AGATHA semantic graph.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td>Pretrained 'scibert-scivocab-uncased' model specified (trained on ~1.14M full-text papers).</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td>SciBERT pretraining corpora (cited), used to produce embeddings for FAISS nearest-neighbor graph construction.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Sentence embeddings are averaged across tokens to obtain sentence vectors; approximate nearest-neighbors (FAISS + PQ) are used for scalability which introduces approximation error.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'AGATHA: Automatic Graph-mining And Transformer based Hypothesis generation Approach', 'publication_date_yy_mm': '2020-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2514.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e2514.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ScispaCy</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ScispaCy (scientific text processing library)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A spaCy-based library with models and pipelines optimized for scientific/biomedical text (POS, dependency parsing, NER); used to process MEDLINE sentences and extract lemmas, entities and syntactic annotations for graph construction.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>ScispaCy</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Provides efficient, high-quality part-of-speech tagging, dependency parsing, and named-entity recognition tailored to scientific text; applied per-sentence over MEDLINE to extract entities, lemmas, and annotations that become nodes/edges in the semantic graph.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>scientific NLP preprocessing toolkit</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>biomedical NLP / literature mining</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Not a hypothesis generator; supplies structured annotations (entities, lemmas, POS) used in semantic graph construction.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Entity recognition and parsing quality depend on model capacity and domain coverage; residual annotation noise contributes to downstream graph noise.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'AGATHA: Automatic Graph-mining And Transformer based Hypothesis generation Approach', 'publication_date_yy_mm': '2020-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2514.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e2514.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PTBG</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>PyTorch-BigGraph (PTBG)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A distributed large-scale graph embedding system used to embed AGATHA's 184M-node heterogeneous semantic graph into 256/512-dimensional vectors with typed relation translations and negative sampling.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>PyTorch-BigGraph (PTBG)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Distributed embedding system for very large heterogeneous graphs; learns typed node embeddings with per-relation translation vectors, uses dot-product scoring with softmax loss, and high-rate negative sampling (100 negatives per edge) across partitions to produce embeddings used by AGATHA's transformer ranking.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>large-scale graph embedding</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>graph representation learning applied to biomedicine</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Provides node embeddings that encode semantic/structural context used by the transformer ranking model to score hypotheses.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td>Embedding dimensions reported, negative sampling regimen (100 negatives), training passes described (10 passes for 256-d, 5 passes for 512-d within 72h), and cluster specs reported.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td>AGATHA semantic graph (184M nodes, 12.3B edges) constructed from MEDLINE pre-2015.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Requires large distributed compute cluster; embedding quality depends on partitioning and negative-sampling strategies; dot-product + translation model has inductive biases.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'AGATHA: Automatic Graph-mining And Transformer based Hypothesis generation Approach', 'publication_date_yy_mm': '2020-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2514.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e2514.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Transformer ranking encoder</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Transformer encoder-based ranking model (multi-head self-attention)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The supervised ranking module in AGATHA: a 4-layer transformer encoder (multi-head attention, feed-forward layers, layer-norm) that processes sets of neighborhood predicates and term embeddings to output a sigmoid plausibility score.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Transformer encoder ranking model</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Processes an input set X (subject, object, and s=15 sampled neighbor predicates per term) by applying a feed-forward projection to each element's PTBG embedding, running the sequence through N=4 encoder layers (multi-head attention, FFN, LayerNorm, ReLU activations, dropout), averaging encoder outputs, and projecting to a scalar with a linear layer followed by sigmoid to produce H(X). Training uses margin ranking loss with negative scrambles and swaps and LAMB optimizer.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>transformer encoder (set-input) supervised ranking</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>biomedical literature mining</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Scores candidate hypotheses by learned pattern recognition across neighborhoods of graph predicates rather than explicit path enumeration.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Direct output scalar plausibility score trained to separate published predicates from negatives; uses swaps to require fine semantic discrimination.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td>Rank-based metrics (ROC AUC, PR AUC, P.@k, AP.@k, RR, MAP, MRR) used to evaluate model performance on temporal holdout.</td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Cross-validated on a 1% holdout for early stopping; evaluated on temporal holdout benchmark and subdomain recommendation tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td>Architecture details (layer counts, dimensions, parameter tables) and training regimen (batch sizes, optimizer, learning rate schedule) reported in paper and supplementary information.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td>Training with swaps and scrambles helps reduce spurious associations; interpretable topic-model fallback for manual review.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td>Sigmoid output score used as plausibility value; no formal calibration or predictive uncertainty quantification.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td>SemRep-derived positive predicates and generated negative samples; temporal holdout set for evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>No positional encoding (set-input) may limit modeling of ordered evidence; outputs uncalibrated scalar plausibility without reported confidence intervals or Bayesian uncertainty measures.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'AGATHA: Automatic Graph-mining And Transformer based Hypothesis generation Approach', 'publication_date_yy_mm': '2020-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2514.10">
                <h3 class="extraction-instance">Extracted Data Instance 10 (e2514.10)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>FAISS + PQ</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>FAISS approximate nearest neighbors with product quantization</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A scalable ANN system (FAISS) with product quantization (PQ) and k-means bucketing used to build an approximate sentence-similarity graph over 155M sentences for AGATHA's semantic graph.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>FAISS + PQ nearest-neighbors</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>FAISS is used to perform distributed approximate nearest-neighbor search on 768-d SciBERT-derived sentence embeddings. AGATHA uses 96 PQ quantizers (each on disjoint 8-d chunks), k-means partitioning into 2048 buckets, and per-point search across the 16 most-similar buckets to retrieve ~25 nearest neighbors per sentence at scale.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>approximate nearest-neighbor search / indexing</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>biomedical NLP / scalable similarity search</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Provides sentence-similarity edges in the semantic graph that connect contentually similar sentences across abstracts, enabling cross-document evidence aggregation for hypothesis scoring.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td>FAISS configuration parameters (PQ quantizers, partitions, buckets searched) described for reproducibility.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td>SciBERT-derived sentence embeddings from MEDLINE (155M sentences in 2015 validation instance).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Approximation reduces complexity; the pipeline retrieves 25 approximate nearest neighbors per sentence. Specific recall/precision of ANN not reported.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Approximate search introduces retrieval approximations; PQ and bucket selection parameters trade off recall and speed.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'AGATHA: Automatic Graph-mining And Transformer based Hypothesis generation Approach', 'publication_date_yy_mm': '2020-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2514.11">
                <h3 class="extraction-instance">Extracted Data Instance 11 (e2514.11)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LDA topic-model fallback</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Latent Dirichlet Allocation (LDA) topic-modeling interpretability module</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An interpretable topic-modeling component (used previously in Moliere and retained as an optional explainability tool) that summarizes sentences near a graph path to provide human-interpretable evidence supporting suggested hypotheses.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>LDA topic-model interpretability</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>For candidate hypotheses that need interpretation, the system finds a short path within the semantic network between terms and constructs an LDA topic model over sentences near that path; outputs path sentences and topics for human inspection to support or refute model-suggested hypotheses.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>probabilistic topic modeling for interpretability</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>biomedical literature interpretation / human-in-the-loop validation</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Not used for high-throughput generation here, but used to provide interpretable support for a smaller set of candidate hypotheses.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Provides human-interpretable textual evidence to judge plausibility; previously used heuristics (embedding-topic similarity) to quantify plausibility.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Human expert review of returned path sentences and topic summaries.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td>Used as an interpretability/verification tool so human users can detect unsupported or spurious claims.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Topic-modeling is computationally expensive (hence used post-hoc for smaller candidate sets) and provides fuzzy, non-probabilistic explanations that still require expert interpretation.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'AGATHA: Automatic Graph-mining And Transformer based Hypothesis generation Approach', 'publication_date_yy_mm': '2020-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2514.12">
                <h3 class="extraction-instance">Extracted Data Instance 12 (e2514.12)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Temporal holdout validation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Temporal holdout / historical validation method</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A large-scale evaluation protocol that treats connections first appearing after a cutoff date as novel positives, enabling computational validation of hypothesis generation systems without wet-lab experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Temporal holdout validation</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Split dataset by time (train on pre-cutoff publications, validate on connections/predicates that first appear post-cutoff). Use SemMedDB to identify predicates, and evaluate model's ability to rank those future-occurring connections above negatives. Also used for subdomain-specific recommendations (top-100 growing predicates per semantic-type pair).</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>evaluation protocol / retrospective validation</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>biomedical literature-mining evaluation</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td>Operationalizes novelty as first appearance after a temporal cutoff; selects growing post-cutoff predicates to define novel positives.</td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Evaluates plausibility via rank-based metrics (ROC AUC, PR AUC, top-k precision, AP, RR, MAP, MRR) computed on temporal holdout positives vs negatives.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td>Balances novelty by choosing post-cutoff positives while plausibility is measured by ranking quality; no explicit trade-off algorithm beyond selection and metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td>ROC AUC, PR AUC, top-k precision, AP.@k, RR, MAP.@k, MRR.@k.</td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Used to validate AGATHA at scale and compare to prior systems; allows subdomain analyses and many-to-many recommendation evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td>Cutoff date (Jan 1, 2015) and data sources (MEDLINE, SemMedDB) specified; subdomain selection method described (semantic types, top-100 growth predicates).</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td>SemMedDB-derived predicates and MEDLINE abstracts split at Jan 1, 2015 for the validation instance used in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Temporal holdout measures retrospective predictive capacity but cannot substitute for prospective wet-lab validation; may be affected by noise in SemRep extractions and publication biases.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'AGATHA: Automatic Graph-mining And Transformer based Hypothesis generation Approach', 'publication_date_yy_mm': '2020-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Fish oil, raynaud's syndrome, and undiscovered public knowledge <em>(Rating: 2)</em></li>
                <li>Moliere: Automatic biomedical hypothesis generation system <em>(Rating: 2)</em></li>
                <li>Scibert: Pretrained contextualized embeddings for scientific text <em>(Rating: 2)</em></li>
                <li>Scispacy: Fast and robust models for biomedical natural language processing <em>(Rating: 2)</em></li>
                <li>PyTorch-BigGraph: A Large-scale Graph Embedding System <em>(Rating: 2)</em></li>
                <li>Gredel: A knowledge graph embedding based method for drug discovery from biomedical literatures <em>(Rating: 2)</em></li>
                <li>Automated hypothesis generation based on mining scientific literature <em>(Rating: 1)</em></li>
                <li>Attention is all you need <em>(Rating: 1)</em></li>
                <li>Product quantization for nearest neighbor search <em>(Rating: 1)</em></li>
                <li>Semrep: A repository for semantic mapping <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2514",
    "paper_id": "paper-211096951",
    "extraction_schema_id": "extraction-schema-68",
    "extracted_data": [
        {
            "name_short": "AGATHA",
            "name_full": "Automatic Graph-mining And Transformer based Hypothesis generation Approach",
            "brief_description": "A large-scale biomedical hypothesis generation system that constructs a multi-layer semantic graph of MEDLINE sentences, embeds it with a distributed graph embedding, and uses a transformer-encoder ranking model to score plausibility of candidate term-term hypotheses.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "AGATHA",
            "system_description": "Builds a semantic multi-layer graph (sentences, predicates, lemmas, entities, n-grams, UMLS/MeSH/coded terms) from MEDLINE (pre-2015 for validation). Embeds the heterogeneous graph with PyTorch-BigGraph (PTBG) into 256/512-d vectors using typed translations and dot-product scoring. For hypothesis ranking, AGATHA forms input sets combining a candidate subject-object pair and neighborhood predicate samples, encodes each element via the graph embedding and a feed-forward layer, passes the sequence through a 4-layer transformer encoder (multi-head self-attention, no positional encoding), averages encoder outputs, projects to a scalar with a sigmoid to produce a plausibility score H(X). Training uses positive SemRep predicates and two negative-sampling schemes (scrambles and swaps), a margin ranking loss (m=0.1), LAMB optimizer, large batches across multiple GPUs, and temporal holdout evaluation.",
            "system_type": "knowledge-graph-based + transformer ranking (hybrid neural graph + encoder)",
            "scientific_domain": "biomedicine / biomedical literature mining (drug discovery, gene-disease, molecular biology, clinical research)",
            "hypothesis_generation_method": "Generates candidate hypotheses by enumerating candidate term-pairs (UMLS-coded terms) and scoring them with a learned transformer ranking model that takes as input the pair plus sampled neighborhood predicates; candidates come from the semantic graph built from sentence adjacency, approximate nearest-neighbors of SciBERT sentence embeddings (FAISS + PQ), and SemRep predicate nodes.",
            "novelty_assessment_method": "Temporal holdout: treats connections first appearing after the cutoff date (post-2015) as novel positives; selects positive validation predicates by rapid growth in post-cutoff popularity within subdomains. No explicit novelty-scoring beyond ranking and temporal validation.",
            "plausibility_assessment_method": "Learned ranking function H(X): transformer-encoder over PTBG graph embeddings producing sigmoid plausibility scores; trained to rank published SemRep predicates above negative samples using margin ranking loss. Also uses downstream recommendation metrics (ROC AUC, PR AUC, top-k precision, AP.@k, RR, MAP, MRR) to quantify plausibility performance.",
            "novelty_plausibility_balance": "Implicit via training and validation on published predicates and negative-sampling (scrambles/swaps) plus temporal-holdout: model is optimized to place published (plausible) predicates above negatives, and novelty is operationalized by temporal holdout (post-cutoff appearance). No explicit optimization trade-off parameter reported between novelty and plausibility.",
            "hypothesis_quality_metrics": "ROC AUC (receiver-operating-characteristic area), PR AUC (precision-recall area), top-k precision (P.@k), average precision at k (AP.@k), reciprocal rank (RR), mean average precision (MAP.@k), mean reciprocal rank (MRR.@k).",
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Large-scale computational validation via temporal holdout: train on pre-2015 data, predict connections first published after 2015; benchmark against a previously published validation set and perform many-to-many recommendation evaluation across 20 biomedical subdomains. Metrics computed include ROC AUC, PR AUC, and recommendation metrics. No new wet-lab experimental validation is reported for AGATHA in this paper.",
            "reproducibility_measures": "Code, experimental data, and pre-trained models released online; detailed training hyperparameters reported (embedding dims 256/512, negative sampling 100 per edge for PTBG, neighborhood subsample s=15, margin m=0.1, LAMB optimizer, learning rate 0.01 with warmup, cross-validation on 1% holdout), and hardware resources (clusters, GPUs) described.",
            "hallucination_prevention_method": "Mitigations include training on published SemRep predicates (so model learns from published links), using swap negative samples to force finer semantic discrimination, and providing an interpretable topic-modeling path (LDA topic models and sentence-paths) for human inspection; no explicit algorithmic hallucination-filtering or factual grounding module is reported.",
            "hallucination_detection_method": "Not explicitly provided; detection is left to human-in-the-loop interpretability tools (topic-model outputs, returned sentence paths) and validation against temporal ground truth. No automated hallucination classifier reported.",
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": "Model outputs a sigmoid score in [0,1] as a plausibility score; ranking margin loss and validation metrics quantify separation between positives and negatives. No Bayesian uncertainty estimation, calibration statistics, confidence intervals, or ensemble uncertainty methods are reported.",
            "benchmark_dataset": "SemMedDB predicates (SemRep extracted predicates) from MEDLINE pre-2015 for training; a 2015 temporal holdout benchmark and the prior Moliere benchmark (as reported in [38]) used for comparison. Subdomain-specific evaluation used top-100 post-2015 growing predicates per semantic-type pair.",
            "performance_metrics": "AGATHA-512: ROC AUC = 0.901, PR AUC = 0.936. AGATHA-256: ROC AUC = 0.826, PR AUC = 0.895. Subdomain metrics reported (examples): (Gene→Cell Function) top-10 average precision 0.83 and mean-reciprocal-rank 0.61; many-to-many recommendation P.@10 and MAP/MRR reported per subdomain (detailed per-table in paper). Wall-time per-query reduced from minutes (Moliere topic-modeling pipeline) to milliseconds.",
            "comparison_with_baseline": "Compared to Moliere (Medline): AGATHA-512 improves ROC AUC from 0.718 to 0.901 (~25% relative increase). Compared to Moliere (Full Text): AGATHA-512 improves ROC AUC from 0.795 to 0.901 (~13% relative increase). AGATHA also offers large speedups (ms per query vs minutes).",
            "validated_on_real_science": false,
            "novel_discoveries": null,
            "limitations": "Relies on SemRep predicates which are noisy and restricted to UMLS-coded entities; no direct method to incorporate arbitrary experimental data (only network-convertible experimental results are straightforward to add); interpretability is limited for large-scale queries requiring switch to topic-modeling and human inspection; no explicit hallucination-detection, uncertainty calibration, or experimental wet-lab validation reported for AGATHA in this work.",
            "uuid": "e2514.0",
            "source_info": {
                "paper_title": "AGATHA: Automatic Graph-mining And Transformer based Hypothesis generation Approach",
                "publication_date_yy_mm": "2020-02"
            }
        },
        {
            "name_short": "Moliere",
            "name_full": "Moliere (prior automatic biomedical hypothesis generation system)",
            "brief_description": "An earlier system by the authors that finds short paths in a semantic graph and generates LDA topic models over the sentences near those paths, combined with heuristic plausibility ranking measures to recommend hypotheses.",
            "citation_title": "here",
            "mention_or_use": "mention",
            "system_name": "Moliere",
            "system_description": "Constructs semantic heterogeneous graphs of biomedical entities and finds short paths connecting query terms. Produces LDA topic models from sentences around returned paths for human interpretability. Uses heuristic metrics (embedding-based keyword-topic similarity, network-analytic measures on topic-nearest-neighbors) combined into a meta-measure to quantify plausibility of candidate hypotheses.",
            "system_type": "knowledge-graph-based + topic-model interpretability",
            "scientific_domain": "biomedicine (literature-based discovery)",
            "hypothesis_generation_method": "ABC-style or path-based literature-based discovery: find intermediary terms/paths (A−B−C) and summarize associated texts via LDA to present candidate B terms or topics that connect A and C.",
            "novelty_assessment_method": "Heuristic ranking that prioritized topic-model signals and network measures; temporal validation used in later benchmarking but no formal novelty scoring beyond heuristics.",
            "plausibility_assessment_method": "Heuristic plausibility metrics: embedding similarity between keywords and topics, and network-analytic measures on topic-nearest-neighbors aggregated into a meta-score.",
            "novelty_plausibility_balance": "Relies on heuristics which tended to bias toward incremental discoveries; no explicit formal trade-off between novelty and plausibility reported.",
            "hypothesis_quality_metrics": "Used the same benchmarking metrics in follow-up evaluation (ROC AUC, PR AUC, top-k precision, AP, RR) when compared to AGATHA; original internal metrics were heuristic meta-scores derived from topic/embedding measures.",
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Computational validation and human-in-the-loop case studies (e.g., previously reported discovery of DDX3 inhibition related to HIV-associated neurodegenerative disease).",
            "reproducibility_measures": "Open-source prior implementation and published heuristics in prior work; not detailed in this paper beyond references.",
            "hallucination_prevention_method": "Human oversight / scientist-in-the-loop via topic-model inspection and path inspection; heuristics to rank plausible topics helped reduce false leads.",
            "hallucination_detection_method": "Manual expert review of topic-model outputs and path sentences; no automated hallucination detector reported.",
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": "Heuristic meta-scores produce scalar plausibility values; no probabilistic uncertainty quantification reported.",
            "benchmark_dataset": "MEDLINE, and in some runs PubMed Central full text (used in prior comparisons).",
            "performance_metrics": "Reported baseline ROC AUC (Moliere: Medline) = 0.718, PR AUC = 0.820; (Moliere: Full Text) ROC AUC = 0.795, PR AUC = 0.778 (as reported in the benchmark compared by AGATHA).",
            "comparison_with_baseline": null,
            "validated_on_real_science": true,
            "novel_discoveries": "Previously reported discovery (via Moliere) of DDX3 inhibition as a candidate treatment target for HIV-associated neurodegenerative disease that led to follow-up experimental work (referenced in paper).",
            "limitations": "Requires significant human oversight, computationally expensive (topic-modeling, shortest-path computations), biased toward incremental/ABC-style discoveries, and slower per-query runtime (minutes) especially when using full text.",
            "uuid": "e2514.1",
            "source_info": {
                "paper_title": "AGATHA: Automatic Graph-mining And Transformer based Hypothesis generation Approach",
                "publication_date_yy_mm": "2020-02"
            }
        },
        {
            "name_short": "ARROWSMITH",
            "name_full": "ARROWSMITH (Swanson's hypothesis generation system)",
            "brief_description": "A foundational literature-based discovery (LBD) system that applied the ABC model to identify implicit connections by mining co-occurring keywords across MEDLINE titles, famously discovering the fish oil–Raynaud's syndrome link.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "ARROWSMITH",
            "system_description": "Implements the ABC model: given terms A and C, finds intermediate B-terms appearing with A and with C separately (co-occurrence analysis) to suggest A−B−C hypotheses based on shared keywords across literature.",
            "system_type": "co-occurrence / ABC-model literature-based discovery",
            "scientific_domain": "biomedicine (literature mining)",
            "hypothesis_generation_method": "Mining title/keyword co-occurrences to produce intermediary terms that connect two otherwise unlinked concepts.",
            "novelty_assessment_method": "Implicit (novelty via lack of explicit prior A–C co-occurrence); no formal novelty scoring beyond bibliographic absence.",
            "plausibility_assessment_method": "Heuristic plausibility via co-occurrence counts and domain knowledge; no statistical ranking model reported in this paper.",
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": null,
            "pre_experiment_evaluation": null,
            "validation_mechanism": "Historical case studies (e.g., fish oil → Raynaud's).",
            "reproducibility_measures": null,
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": null,
            "benchmark_dataset": "MEDLINE titles / keywords (historical)",
            "performance_metrics": null,
            "comparison_with_baseline": null,
            "validated_on_real_science": true,
            "novel_discoveries": "Fish oil — Raynaud's syndrome connection (historical demonstration).",
            "limitations": "ABC co-occurrence approach scales poorly, biases toward incremental discoveries, and depends heavily on heuristically determined term-lists and manual validation.",
            "uuid": "e2514.2",
            "source_info": {
                "paper_title": "AGATHA: Automatic Graph-mining And Transformer based Hypothesis generation Approach",
                "publication_date_yy_mm": "2020-02"
            }
        },
        {
            "name_short": "IBM Watson (Watson for Drug Discovery)",
            "name_full": "Watson for Drug Discovery (IBM Watson application)",
            "brief_description": "A commercial cognitive/computational system that applies NLP and curated knowledge to help identify potential therapeutic hypotheses and associations; cited as an example of visual/interpretability-driven hypothesis discovery.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "Watson for Drug Discovery",
            "system_description": "Closed-source cognitive computing platform combining text mining, knowledge graphing, and visualization to surface candidate biomedical insights to domain experts (as cited historically for case studies).",
            "system_type": "commercial cognitive NLP + knowledge-based system",
            "scientific_domain": "biomedicine / drug discovery",
            "hypothesis_generation_method": "Text mining + knowledge graph traversal + expert-in-the-loop interpretation (details not provided in this paper).",
            "novelty_assessment_method": null,
            "plausibility_assessment_method": null,
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": null,
            "pre_experiment_evaluation": null,
            "validation_mechanism": "Cited case studies in literature (no details in this paper).",
            "reproducibility_measures": null,
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": null,
            "benchmark_dataset": null,
            "performance_metrics": null,
            "comparison_with_baseline": null,
            "validated_on_real_science": true,
            "novel_discoveries": "Cited example: Watson's reported discovery related to ALS treatments in prior work (referenced).",
            "limitations": "Closed-source; requires human oversight for interpretation; not directly compared experimentally in this paper.",
            "uuid": "e2514.3",
            "source_info": {
                "paper_title": "AGATHA: Automatic Graph-mining And Transformer based Hypothesis generation Approach",
                "publication_date_yy_mm": "2020-02"
            }
        },
        {
            "name_short": "GrEDeL",
            "name_full": "GrEDeL (knowledge-graph-embedding based hypothesis generator)",
            "brief_description": "A recent deep-learning approach that uses paths in a predicate knowledge graph and an LSTM model to evaluate drug–disease association paths; cited and contrasted in the paper.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "GrEDeL",
            "system_description": "Constructs a knowledge graph from SemRep predicates, enumerates paths between entities (e.g., drug and disease), and scores those paths using an LSTM trained on features of the path; embeddings used were TransE in that work.",
            "system_type": "knowledge-graph-embedding + LSTM path-scoring",
            "scientific_domain": "biomedicine (drug-disease discovery)",
            "hypothesis_generation_method": "Enumerate graph paths that connect query pairs and evaluate them with an LSTM classifier to propose plausible associations.",
            "novelty_assessment_method": null,
            "plausibility_assessment_method": "LSTM path classifier trained to rank drug-disease associations.",
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": null,
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Computational evaluation on drug–disease associations but limited generalization beyond that subdomain (per paper's critique).",
            "reproducibility_measures": null,
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": null,
            "benchmark_dataset": "SemRep predicate graph (used by authors of GrEDeL)",
            "performance_metrics": null,
            "comparison_with_baseline": null,
            "validated_on_real_science": true,
            "novel_discoveries": null,
            "limitations": "Relies on noisy SemRep path sequences, needs manual filtering of false positives, is specialized to drug–disease discovery, and used TransE embeddings which may under-represent variance across many relation types (per AGATHA paper critique).",
            "uuid": "e2514.4",
            "source_info": {
                "paper_title": "AGATHA: Automatic Graph-mining And Transformer based Hypothesis generation Approach",
                "publication_date_yy_mm": "2020-02"
            }
        },
        {
            "name_short": "SemRep / SemMedDB",
            "name_full": "SemRep (predicate extraction) and SemMedDB (predicate database)",
            "brief_description": "SemRep extracts subject-verb-object predicates from MEDLINE and maps components to UMLS coded terms; SemMedDB is the collection of SemRep-extracted predicates used as training and validation data.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "SemRep / SemMedDB",
            "system_description": "SemRep performs predicate extraction (subject-verb-object) from biomedical text and maps predicates' components to UMLS semantic types and coded terms; SemMedDB aggregates these predicates across MEDLINE and is used here as the source of positive training examples (19M+ pre-2015 predicates).",
            "system_type": "information extraction / knowledge-base construction",
            "scientific_domain": "biomedicine / biomedical NLP",
            "hypothesis_generation_method": "Not a generator itself, but provides published predicate triples used as positive exemplars for supervised ranking and as graph nodes in the semantic graph.",
            "novelty_assessment_method": null,
            "plausibility_assessment_method": null,
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": null,
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Used as ground-truth positives for temporal holdout validation: predicates first appearing after cutoff are treated as novel positives.",
            "reproducibility_measures": "SemMedDB is a public resource; used here as a reproducible training/validation set though authors note it contains noise.",
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": null,
            "benchmark_dataset": "SemMedDB (SemRep predicates) extracted from MEDLINE; &gt;19M predicates pre-2015 used for training.",
            "performance_metrics": null,
            "comparison_with_baseline": null,
            "validated_on_real_science": null,
            "novel_discoveries": null,
            "limitations": "Predicate set is noisy, may contain incorrect/obsolete algorithmic extractions; restricted to entities coded in UMLS which limits coverage.",
            "uuid": "e2514.5",
            "source_info": {
                "paper_title": "AGATHA: Automatic Graph-mining And Transformer based Hypothesis generation Approach",
                "publication_date_yy_mm": "2020-02"
            }
        },
        {
            "name_short": "SciBERT",
            "name_full": "SciBERT (pretrained contextualized embeddings for scientific text)",
            "brief_description": "A BERT-family transformer model pre-trained on a large corpus of scientific text; used to produce 768-d context-sensitive sentence embeddings (averaging final hidden layer) for nearest-neighbor sentence similarity in AGATHA.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "SciBERT",
            "system_description": "Pretrained transformer-based language model adapted to scientific text (vocabulary and corpora), used here to derive 768-dimensional contextualized embeddings per sentence by averaging the final hidden layer outputs.",
            "system_type": "LLM-based contextual embedding model",
            "scientific_domain": "scientific / biomedical NLP",
            "hypothesis_generation_method": "Not a hypothesis generator; supplies sentence-level contextual embeddings used to construct a sentence similarity graph (via FAISS) which contributes edges to the AGATHA semantic graph.",
            "novelty_assessment_method": null,
            "plausibility_assessment_method": null,
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": null,
            "pre_experiment_evaluation": null,
            "validation_mechanism": null,
            "reproducibility_measures": "Pretrained 'scibert-scivocab-uncased' model specified (trained on ~1.14M full-text papers).",
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": null,
            "benchmark_dataset": "SciBERT pretraining corpora (cited), used to produce embeddings for FAISS nearest-neighbor graph construction.",
            "performance_metrics": null,
            "comparison_with_baseline": null,
            "validated_on_real_science": null,
            "novel_discoveries": null,
            "limitations": "Sentence embeddings are averaged across tokens to obtain sentence vectors; approximate nearest-neighbors (FAISS + PQ) are used for scalability which introduces approximation error.",
            "uuid": "e2514.6",
            "source_info": {
                "paper_title": "AGATHA: Automatic Graph-mining And Transformer based Hypothesis generation Approach",
                "publication_date_yy_mm": "2020-02"
            }
        },
        {
            "name_short": "ScispaCy",
            "name_full": "ScispaCy (scientific text processing library)",
            "brief_description": "A spaCy-based library with models and pipelines optimized for scientific/biomedical text (POS, dependency parsing, NER); used to process MEDLINE sentences and extract lemmas, entities and syntactic annotations for graph construction.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "ScispaCy",
            "system_description": "Provides efficient, high-quality part-of-speech tagging, dependency parsing, and named-entity recognition tailored to scientific text; applied per-sentence over MEDLINE to extract entities, lemmas, and annotations that become nodes/edges in the semantic graph.",
            "system_type": "scientific NLP preprocessing toolkit",
            "scientific_domain": "biomedical NLP / literature mining",
            "hypothesis_generation_method": "Not a hypothesis generator; supplies structured annotations (entities, lemmas, POS) used in semantic graph construction.",
            "novelty_assessment_method": null,
            "plausibility_assessment_method": null,
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": null,
            "pre_experiment_evaluation": null,
            "validation_mechanism": null,
            "reproducibility_measures": null,
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": null,
            "benchmark_dataset": null,
            "performance_metrics": null,
            "comparison_with_baseline": null,
            "validated_on_real_science": null,
            "novel_discoveries": null,
            "limitations": "Entity recognition and parsing quality depend on model capacity and domain coverage; residual annotation noise contributes to downstream graph noise.",
            "uuid": "e2514.7",
            "source_info": {
                "paper_title": "AGATHA: Automatic Graph-mining And Transformer based Hypothesis generation Approach",
                "publication_date_yy_mm": "2020-02"
            }
        },
        {
            "name_short": "PTBG",
            "name_full": "PyTorch-BigGraph (PTBG)",
            "brief_description": "A distributed large-scale graph embedding system used to embed AGATHA's 184M-node heterogeneous semantic graph into 256/512-dimensional vectors with typed relation translations and negative sampling.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "PyTorch-BigGraph (PTBG)",
            "system_description": "Distributed embedding system for very large heterogeneous graphs; learns typed node embeddings with per-relation translation vectors, uses dot-product scoring with softmax loss, and high-rate negative sampling (100 negatives per edge) across partitions to produce embeddings used by AGATHA's transformer ranking.",
            "system_type": "large-scale graph embedding",
            "scientific_domain": "graph representation learning applied to biomedicine",
            "hypothesis_generation_method": "Provides node embeddings that encode semantic/structural context used by the transformer ranking model to score hypotheses.",
            "novelty_assessment_method": null,
            "plausibility_assessment_method": null,
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": null,
            "pre_experiment_evaluation": null,
            "validation_mechanism": null,
            "reproducibility_measures": "Embedding dimensions reported, negative sampling regimen (100 negatives), training passes described (10 passes for 256-d, 5 passes for 512-d within 72h), and cluster specs reported.",
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": null,
            "benchmark_dataset": "AGATHA semantic graph (184M nodes, 12.3B edges) constructed from MEDLINE pre-2015.",
            "performance_metrics": null,
            "comparison_with_baseline": null,
            "validated_on_real_science": null,
            "novel_discoveries": null,
            "limitations": "Requires large distributed compute cluster; embedding quality depends on partitioning and negative-sampling strategies; dot-product + translation model has inductive biases.",
            "uuid": "e2514.8",
            "source_info": {
                "paper_title": "AGATHA: Automatic Graph-mining And Transformer based Hypothesis generation Approach",
                "publication_date_yy_mm": "2020-02"
            }
        },
        {
            "name_short": "Transformer ranking encoder",
            "name_full": "Transformer encoder-based ranking model (multi-head self-attention)",
            "brief_description": "The supervised ranking module in AGATHA: a 4-layer transformer encoder (multi-head attention, feed-forward layers, layer-norm) that processes sets of neighborhood predicates and term embeddings to output a sigmoid plausibility score.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Transformer encoder ranking model",
            "system_description": "Processes an input set X (subject, object, and s=15 sampled neighbor predicates per term) by applying a feed-forward projection to each element's PTBG embedding, running the sequence through N=4 encoder layers (multi-head attention, FFN, LayerNorm, ReLU activations, dropout), averaging encoder outputs, and projecting to a scalar with a linear layer followed by sigmoid to produce H(X). Training uses margin ranking loss with negative scrambles and swaps and LAMB optimizer.",
            "system_type": "transformer encoder (set-input) supervised ranking",
            "scientific_domain": "biomedical literature mining",
            "hypothesis_generation_method": "Scores candidate hypotheses by learned pattern recognition across neighborhoods of graph predicates rather than explicit path enumeration.",
            "novelty_assessment_method": null,
            "plausibility_assessment_method": "Direct output scalar plausibility score trained to separate published predicates from negatives; uses swaps to require fine semantic discrimination.",
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": "Rank-based metrics (ROC AUC, PR AUC, P.@k, AP.@k, RR, MAP, MRR) used to evaluate model performance on temporal holdout.",
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Cross-validated on a 1% holdout for early stopping; evaluated on temporal holdout benchmark and subdomain recommendation tasks.",
            "reproducibility_measures": "Architecture details (layer counts, dimensions, parameter tables) and training regimen (batch sizes, optimizer, learning rate schedule) reported in paper and supplementary information.",
            "hallucination_prevention_method": "Training with swaps and scrambles helps reduce spurious associations; interpretable topic-model fallback for manual review.",
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": "Sigmoid output score used as plausibility value; no formal calibration or predictive uncertainty quantification.",
            "benchmark_dataset": "SemRep-derived positive predicates and generated negative samples; temporal holdout set for evaluation.",
            "performance_metrics": null,
            "comparison_with_baseline": null,
            "validated_on_real_science": false,
            "novel_discoveries": null,
            "limitations": "No positional encoding (set-input) may limit modeling of ordered evidence; outputs uncalibrated scalar plausibility without reported confidence intervals or Bayesian uncertainty measures.",
            "uuid": "e2514.9",
            "source_info": {
                "paper_title": "AGATHA: Automatic Graph-mining And Transformer based Hypothesis generation Approach",
                "publication_date_yy_mm": "2020-02"
            }
        },
        {
            "name_short": "FAISS + PQ",
            "name_full": "FAISS approximate nearest neighbors with product quantization",
            "brief_description": "A scalable ANN system (FAISS) with product quantization (PQ) and k-means bucketing used to build an approximate sentence-similarity graph over 155M sentences for AGATHA's semantic graph.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "FAISS + PQ nearest-neighbors",
            "system_description": "FAISS is used to perform distributed approximate nearest-neighbor search on 768-d SciBERT-derived sentence embeddings. AGATHA uses 96 PQ quantizers (each on disjoint 8-d chunks), k-means partitioning into 2048 buckets, and per-point search across the 16 most-similar buckets to retrieve ~25 nearest neighbors per sentence at scale.",
            "system_type": "approximate nearest-neighbor search / indexing",
            "scientific_domain": "biomedical NLP / scalable similarity search",
            "hypothesis_generation_method": "Provides sentence-similarity edges in the semantic graph that connect contentually similar sentences across abstracts, enabling cross-document evidence aggregation for hypothesis scoring.",
            "novelty_assessment_method": null,
            "plausibility_assessment_method": null,
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": null,
            "pre_experiment_evaluation": null,
            "validation_mechanism": null,
            "reproducibility_measures": "FAISS configuration parameters (PQ quantizers, partitions, buckets searched) described for reproducibility.",
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": null,
            "benchmark_dataset": "SciBERT-derived sentence embeddings from MEDLINE (155M sentences in 2015 validation instance).",
            "performance_metrics": "Approximation reduces complexity; the pipeline retrieves 25 approximate nearest neighbors per sentence. Specific recall/precision of ANN not reported.",
            "comparison_with_baseline": null,
            "validated_on_real_science": null,
            "novel_discoveries": null,
            "limitations": "Approximate search introduces retrieval approximations; PQ and bucket selection parameters trade off recall and speed.",
            "uuid": "e2514.10",
            "source_info": {
                "paper_title": "AGATHA: Automatic Graph-mining And Transformer based Hypothesis generation Approach",
                "publication_date_yy_mm": "2020-02"
            }
        },
        {
            "name_short": "LDA topic-model fallback",
            "name_full": "Latent Dirichlet Allocation (LDA) topic-modeling interpretability module",
            "brief_description": "An interpretable topic-modeling component (used previously in Moliere and retained as an optional explainability tool) that summarizes sentences near a graph path to provide human-interpretable evidence supporting suggested hypotheses.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "LDA topic-model interpretability",
            "system_description": "For candidate hypotheses that need interpretation, the system finds a short path within the semantic network between terms and constructs an LDA topic model over sentences near that path; outputs path sentences and topics for human inspection to support or refute model-suggested hypotheses.",
            "system_type": "probabilistic topic modeling for interpretability",
            "scientific_domain": "biomedical literature interpretation / human-in-the-loop validation",
            "hypothesis_generation_method": "Not used for high-throughput generation here, but used to provide interpretable support for a smaller set of candidate hypotheses.",
            "novelty_assessment_method": null,
            "plausibility_assessment_method": "Provides human-interpretable textual evidence to judge plausibility; previously used heuristics (embedding-topic similarity) to quantify plausibility.",
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": null,
            "pre_experiment_evaluation": null,
            "validation_mechanism": "Human expert review of returned path sentences and topic summaries.",
            "reproducibility_measures": null,
            "hallucination_prevention_method": "Used as an interpretability/verification tool so human users can detect unsupported or spurious claims.",
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": null,
            "benchmark_dataset": null,
            "performance_metrics": null,
            "comparison_with_baseline": null,
            "validated_on_real_science": null,
            "novel_discoveries": null,
            "limitations": "Topic-modeling is computationally expensive (hence used post-hoc for smaller candidate sets) and provides fuzzy, non-probabilistic explanations that still require expert interpretation.",
            "uuid": "e2514.11",
            "source_info": {
                "paper_title": "AGATHA: Automatic Graph-mining And Transformer based Hypothesis generation Approach",
                "publication_date_yy_mm": "2020-02"
            }
        },
        {
            "name_short": "Temporal holdout validation",
            "name_full": "Temporal holdout / historical validation method",
            "brief_description": "A large-scale evaluation protocol that treats connections first appearing after a cutoff date as novel positives, enabling computational validation of hypothesis generation systems without wet-lab experiments.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "Temporal holdout validation",
            "system_description": "Split dataset by time (train on pre-cutoff publications, validate on connections/predicates that first appear post-cutoff). Use SemMedDB to identify predicates, and evaluate model's ability to rank those future-occurring connections above negatives. Also used for subdomain-specific recommendations (top-100 growing predicates per semantic-type pair).",
            "system_type": "evaluation protocol / retrospective validation",
            "scientific_domain": "biomedical literature-mining evaluation",
            "hypothesis_generation_method": null,
            "novelty_assessment_method": "Operationalizes novelty as first appearance after a temporal cutoff; selects growing post-cutoff predicates to define novel positives.",
            "plausibility_assessment_method": "Evaluates plausibility via rank-based metrics (ROC AUC, PR AUC, top-k precision, AP, RR, MAP, MRR) computed on temporal holdout positives vs negatives.",
            "novelty_plausibility_balance": "Balances novelty by choosing post-cutoff positives while plausibility is measured by ranking quality; no explicit trade-off algorithm beyond selection and metrics.",
            "hypothesis_quality_metrics": "ROC AUC, PR AUC, top-k precision, AP.@k, RR, MAP.@k, MRR.@k.",
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Used to validate AGATHA at scale and compare to prior systems; allows subdomain analyses and many-to-many recommendation evaluation.",
            "reproducibility_measures": "Cutoff date (Jan 1, 2015) and data sources (MEDLINE, SemMedDB) specified; subdomain selection method described (semantic types, top-100 growth predicates).",
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": null,
            "benchmark_dataset": "SemMedDB-derived predicates and MEDLINE abstracts split at Jan 1, 2015 for the validation instance used in the paper.",
            "performance_metrics": null,
            "comparison_with_baseline": null,
            "validated_on_real_science": false,
            "novel_discoveries": null,
            "limitations": "Temporal holdout measures retrospective predictive capacity but cannot substitute for prospective wet-lab validation; may be affected by noise in SemRep extractions and publication biases.",
            "uuid": "e2514.12",
            "source_info": {
                "paper_title": "AGATHA: Automatic Graph-mining And Transformer based Hypothesis generation Approach",
                "publication_date_yy_mm": "2020-02"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Fish oil, raynaud's syndrome, and undiscovered public knowledge",
            "rating": 2,
            "sanitized_title": "fish_oil_raynauds_syndrome_and_undiscovered_public_knowledge"
        },
        {
            "paper_title": "Moliere: Automatic biomedical hypothesis generation system",
            "rating": 2,
            "sanitized_title": "moliere_automatic_biomedical_hypothesis_generation_system"
        },
        {
            "paper_title": "Scibert: Pretrained contextualized embeddings for scientific text",
            "rating": 2,
            "sanitized_title": "scibert_pretrained_contextualized_embeddings_for_scientific_text"
        },
        {
            "paper_title": "Scispacy: Fast and robust models for biomedical natural language processing",
            "rating": 2,
            "sanitized_title": "scispacy_fast_and_robust_models_for_biomedical_natural_language_processing"
        },
        {
            "paper_title": "PyTorch-BigGraph: A Large-scale Graph Embedding System",
            "rating": 2,
            "sanitized_title": "pytorchbiggraph_a_largescale_graph_embedding_system"
        },
        {
            "paper_title": "Gredel: A knowledge graph embedding based method for drug discovery from biomedical literatures",
            "rating": 2,
            "sanitized_title": "gredel_a_knowledge_graph_embedding_based_method_for_drug_discovery_from_biomedical_literatures"
        },
        {
            "paper_title": "Automated hypothesis generation based on mining scientific literature",
            "rating": 1,
            "sanitized_title": "automated_hypothesis_generation_based_on_mining_scientific_literature"
        },
        {
            "paper_title": "Attention is all you need",
            "rating": 1,
            "sanitized_title": "attention_is_all_you_need"
        },
        {
            "paper_title": "Product quantization for nearest neighbor search",
            "rating": 1,
            "sanitized_title": "product_quantization_for_nearest_neighbor_search"
        },
        {
            "paper_title": "Semrep: A repository for semantic mapping",
            "rating": 2,
            "sanitized_title": "semrep_a_repository_for_semantic_mapping"
        }
    ],
    "cost": 0.02427275,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>AGATHA: Automatic Graph-mining And Transformer based Hypothesis generation Approach</p>
<p>Justin Sybrandt 
School of Computing
Clemson University</p>
<p>Ilya Tyagin 
School of Computing
Clemson University</p>
<p>Michael Shtutman 
Drug Discovery and Biomedical Sciences
University of South Carolina</p>
<p>Ilya Safro 
School of Computing
Clemson University</p>
<p>AGATHA: Automatic Graph-mining And Transformer based Hypothesis generation Approach</p>
<p>Medical research is risky and expensive. Drug discovery, as an example, requires that researchers efficiently winnow thousands of potential targets to a small candidate set for more thorough evaluation. However, research groups spend significant time and money to perform the experiments necessary to determine this candidate set long before seeing intermediate results. Hypothesis generation systems address this challenge by mining the wealth of publicly available scientific information to predict plausible research directions. We present AGATHA, a deep-learning hypothesis generation system that can introduce data-driven insights earlier in the discovery process. Through a learned ranking criteria, this system quickly prioritizes plausible term-pairs among entity sets, allowing us to recommend new research directions. We massively validate our system with a temporal holdout wherein we predict connections first introduced after 2015 using data published beforehand. We additionally explore biomedical subdomains, and demonstrate AGATHA's predictive capacity across the twenty most popular relationship types. This system achieves best-in-class performance on an established benchmark, and demonstrates high recommendation scores across subdomains. Reproducibility: All code, experimental data, and pre-trained models are available online:</p>
<p>Introduction</p>
<p>As the rate of global scientific output continues to climb [41], an increasing portion of the biomedical discovery process is becoming a "big data" problem. For instance, the US National Library of Medicine's (NLM) database of biomedical abstracts, MEDLINE, has steadily increased the number of papers added per-year, and has added significantly over 800,000 papers every year since 2015 [1]. This wealth of scientific knowledge comes with the overhead cost payed by practitioners who often struggle to keep up with the state-of-the-art.</p>
<p>Buried within the large and growing MEDLINE database are many undiscovered implicit connectionsthose relationships that are implicitly discoverable, yet have not been identified by the research community. One connection of this type was first proposed and subsequently discovered by Swanson and Smalheiser in the mid-to-late 1980's [37]. Their landmark finding, using only the co-occurrences of keywords across MEDLINE titles, was to establish a connection between fish oil and Raynaud's Syndrome [36]. At that time, it was known that fish oil modified various bodily properties, such as blood viscosity, which were key factors pertaining to Raynaud's syndrome. However, while each explicit relationship was known, the implicit relationship was not discovered before Swanson's ARROWSMITH hypothesis generation system identified the connection algorithmically.</p>
<p>Modern advances in machine learning, specifically in the realms of text and graph mining, enable contemporary hypothesis generation systems to identify fruitful new research directions while taking far more than title co-occurrence rates into account. Modern systems predict missing links on domain specific graphs, such as BioGraph on gene-disease network [26] or MeTeOR on the term-co-occurrence graph [44]. Other systems focus on identifying relevant key terms, similar to Swanson's work, but using modern techniques. For instance, Jha et al. study the evolution of word embedding spaces over time to learn contemporary trends relevant to particular queries [20]. Further work by Jha et al. continues to study the joint evolution of corpora and ontologies within biomedical research [21]. Another approach is to produce visualizations for interpretation by domain scientists [34], such as the closed-source Watson for Drug Discovery [9]. Moliere, our prior hypothesis generation system [39], produces data for scientific interpretation in the form of LDA topic models [7]. Additional work produced heuristically-backed ranking criteria to help automate the analysis process [40].</p>
<p>While prior hypothesis generation systems have been valuable in real-world explorations, such as Swanson's fish-old and Raynaud's syndom finding [36], Watson's discovery of ALS treatments [9], or Moliere's discovery of DDX3 inhibition as a treatment for HIV-associated neurodegenerative disease [5], there remains significant drawbacks to the state of the art. Most systems require significant human oversight to produce useful results [35,9,39], or are only tested on very small evaluation sets [20,21,15,30]. Systems still using the "ABC" model of discovery [20,21,23], posed by Swanson in 1986 [36], face many known limitations such as reduced scalabiltiy and a bias towards incremental discoveries [32].</p>
<p>To overcome these limitations, we present a new hypothesis generation system that scales to the entirety of biomedical literature, and is backed by efficient deep-learning techniques to enable thousands of queries a minute, enabling new types of queries. This system constructs a new semantic multi-layered graph, and places its millions of nodes into a shared embedding. From there, we use a transformer encoder architecture [42] to learn a ranking criteria between regions of our semantic graph and the plausibility of new research connections. Because our graph spans all of MEDLINE, we are able to generate hypotheses from a large range of biomedical subdomains. Other than our prior work [39], we are unaware of any system that is capable of the same breadth of cross-domain discovery that is also open source, or even just publicly available for comparison. Because we efficiently pre-process our graph and its embeddings, we can perform hundreds of queries per-second on GPU, which enables new many-to-many recommendation queries that were not previously feasible. Because we replace our heuristically determined ranking criteria from our prior work [40] with a learned ranking criteria, we achieve significantly improved performance, as demonstrated by an increase in benchmark performance using the same training and validation from and ROC AUC of 0.718 [38] to 0.901. Our contribution:</p>
<p>(1) We introduce a novel approach to construct large semantic graphs that use the granularity of sentences to represent documents. These graphs are constructed using a pipeline of state of the art NLP techniques that have been customized for understanding scientific text, including SciBERT [6] and ScispaCy [28].</p>
<p>(2) We deploy our deep-learning transformer-based model that trained to predict likely connections between term-pairs at scale. This is done by embedding our proposed semantic graph to encode all sentences, entities, n-grams, lemmas, UMLS terms, MeSH terms, chemical identifiers, and SemRep predicates [4] in a common space using the PyTorch-BigGraph embedding [25].</p>
<p>(3) We validate our system using the massive validation techniques presented in [40], and also demonstrate the ability of AGATHA to generalize across biomedical subdomains. For instance, in the scope of "Gene -Cell Function" relationships, our system has a top-10 average precision of 0.83, and a mean-reciprocal-rank of 0.61.</p>
<p>This system is open-source, easily installed, and all prepared data and trained models are available to perform hypothesis queries at sybrandt.com/2020/agatha .</p>
<p>Background</p>
<p>Hypothesis Generation Systems. Swanson posited that undiscovered public knowledge, those facts that are implicitly available but not explicitly known, would accelerate scientific discovery if an automated system were capable of returning them [37]. His work established what is now known as the "A-B-C" model of literature-based discovery [33]. This formulation follow that a hypothesis generation system, given two terms A and C, should uncover some likely B-terms that explain the quality of a potential A − B − C connection. This technique fueled Swanson's own system, ARROWSMITH [36], and still forms the backbone of some contemporary successors [23].</p>
<p>Our former approach to address these challenges is posed by the Moliere system [39], and its accompanying plausibility ranking criteria [40]. This system expands on the A − B − C model by describing a range of connection patterns, as represented by an LDA topic model [7], when receiving an A, C query. To do so, the Moliere system first finds a short-path of interactions bridging the A − C connection from within a large semantic graph. This structure includes nodes that correspond to different entity types that are both textual and biomedical, such as abstracts, predicate statements, genes, diseases, proteins, etc. Edges between entities indicate similarity. For instance, an edge may exist between an abstract and all genes discussed within it, or between two proteins that are discussed in similar contexts. Using the short-path discovered within the semantic network between A and C, the Moliere system also reports an LDA topic model [7]. This model summarizes popular areas of conversation pertaining to abstracts identified near to the returned path. As a result, the user can view various fuzzy clusters of entities and the importance of interesting concepts across documents.</p>
<p>To reduce the burden of topic-model analysis on biomedical researchers, the Moliere system is augmented by a range of techniques that automatically quantify the plausibility of the query based on its resulting topic models. Our measures, such as the embedding-based similarity between keywords and topics, as well as network analytic measures based on the topic-nearest-neighbors network, were heuristically backed, and were combined into a meta-measure to best understand potential hypotheses. Using this technique, we both validated the overall performance of the Moliere system, and used it to identify a new gene-treatment target for HIV-associated neurodegenerative disease through the inhibition of DDX3X [3]. Related and Incorporated Technologies. SemRep [4] is a utility that extracts predicate statements in the form of "subject-verb-object" from the entirety of Medline. This utility further classifies its predicate components into the set coded keywords provided by the Unified Medical Language System (UMLS), and a small set of coded verb-types. These UMLS terms provide a way to unify synonyms and acronyms from across medicine. Additionally, all content extracted by SemRep is provided in the Semantic Medical Database (SemMedDB) for direct use. ScispaCy [28], a version of the popular spaCy text processing library provided by AllenNLP, is designed to properly handle scientific text. Using a deep-learning approach for its part-of-speech tagging, dependency parsing, and entity recognition, this tool achieves state-of-the-art performance on a range of scientific and biomedical linguistic benchmarks. Additionally, this software is optimized sufficiently to operate on each sentence of MEDLINE, which numbers over 188 million as of 2020. SciBert [6] is a version of the BERT transformer model for scientific language. This model learns representations for each word part in a given sentence. The resulting embeddings for each word part are determined by its relationship to all other word parts. As a result, the output word-part embeddings are highly content-dependent, and homographs, words with the same spelling but different meanings, receive significantly different representations. FAISS [22], the open-source similarity-search utility, is capable of computing an approximate nearestneighbors network for huge point clouds. This technique scales to various graph sizes by its modular component set, and we choose PQ-quantization and k-means bucketing to reduce the dimensionality of our sentences, and reduce the search space per-query. PyTorch-BigGraph (PTBG) [25] is an open-source, large-scale, distributed graph-embedding technique aimed at heterogeneous information networks [31]. These graphs consist of nodes of various types, connected by typed edges. We define each node and relationship type contained in our semantic graph as input to this embedding technique. PTBG distributes edges such that all machines compute on disjoint node-sets. We choose to encode edges through the dot product of transformed embeddings, which we explain in more detail in Section 3. The Transformer [42] model is built with multi-headed attention. Conceptually, this mechanism works by learning weighted averages per-element of the input sequence, over the entire input sequence. Specifically, this includes three projections of each element's embedding, represented as packed matrices: Q, K, and V . The specific mechanism is defined as follows, with d k representing the dimensionality of each Q and K embedding:
Attention(Q, K, V ) = softmax QK √ d k V
(1) Figure 1: System Diagram of the AGATHA process. Figure 2: AGATHA multi-layered graph schema. The "multi-headed" aspect of the transformer indicates that the attention mechanism is applied multiple times per-layer, and recombined to form a joint representation. If W (x) indicates a matrix of learned weights, then this operation is defined as:
MultiHead(X) = [h 1 ; . . . ; h k ]W (4) where h i = Attention XW (1) i , XW (2) i , XW (3) i (2)
By using only the encoder half of the transformer model, and by omitting any positional mask or encoding, we apply the self-attention mechanism to understand input sets while reducing the effect of the arbitrary ordering imposed by a sequence model. One encoder layer is defined as:
E(X) = LayerNorm(F F (α) + α)
where F F (α) = max 0, αW (5) W (6) and α = LayerNorm(MultiHead(X) + X)
(3)</p>
<p>Data Preparation</p>
<p>We propose a significant data processing pipeline ( Fig. 1), to convert raw-text sources into a semantic graph (Fig. 2). An embedding of this graph enables our learned ranking criteria. Text Pre-Processing. We begin with raw MEDLINE XML files 1 . We attempt to extract the paper id (PMID), version, title, abstract text, date of first occurrence, keywords, and publication language. Next, we filter out non-English documents. In order to validate our system, we additionally discard any document that is dated after January 1 st , 2015.</p>
<p>We split the text of each abstract into sentences. For each sentence, we identify parts-of-speech, dependency tags, and named entities using ScispaCy [28]. The result of this process is a record per-sentence, including the title, that contains all metadata associated with the original abstract, as well as all algorithmically identified annotations.</p>
<p>Using the lemma information of each sentence, we perform n-gram mining in order to identify common phrases that may not have been picked up by entity detection. First, we provide a set of part-of-speech tags we mark as "interesting" from the perspective of n-gram mining. These are: nouns, verbs, adjectives, proper nouns, adverbs, interjections, and "other." We additionally supply a short stopword list, and assert that stop words are uninteresting. Then, for each sentence, we produce the set of n-grams of length two-to-four that both start and end with an interesting lemma. We record any n-gram that achieves an overall support of at least 100. However, we find it necessary to introduce an approximation factor, that an n-gram must have a minimum support of five within a datafile for those occurrences to count. Semantic Graph Construction. After splitting sentences, while simultaneously identifying lemmas, entities and n-grams, we can begin constructing the semantic graph. We begin this process by creating edges between similar sentences. The simplest edge we add is that between two adjacent sentences from the same abstract. For instance, sentence i in abstract A will produce edges to A i−1 and A i+1 , with the paper title serving as A 0 .</p>
<p>To capture edges between similar sentences in different abstracts, we compute an approximate-nearestneighbors network on the set of sentence embeddings. We derive these embeddings from the average of the final hidden layer of the SciBert 2 NLP model for scientific text [6]. This 768-dimensional embedding captures context-sensitive content regarding each word in each sentence.</p>
<p>However, we have over 155-million sentences in the 2015 validation instance of AGATHA, which makes performing a nearest-neighbors search per-sentence (typically O(n 2 d)) computationally difficult. Therefore, we leverage FAISS to perform dimensionality reduction, as well as approximate-nearest neighbors, in a distributed setting. First, we collect a one-percent sample of all embeddings on a single machine, wherein we perform product quantization (PQ) [18]. This technique learns an efficient bit representation of each embedding. We use 96-quantizers, and each considers a disjoint an 8-dimensional chunk of the 768-dimensional SciBert embeddings. Each quantizer then learns to map its input real-valued chunk into output 8-bit codes, such that similar input chunks receive output codes with low hamming distance.</p>
<p>Still using the 1% sample on one machine, FAISS performs k-Means over PQ codes in order to partition the reduced space into self-similar buckets. By storing the centroid of each bucket, we can later select a relevant sub-space pertaining to each input query, dramatically reducing the search space. We select 2048 partitions to divide the space, and when performing a query, each input embedding is compared to all embeddings residing in the 16 most-similar buckets.</p>
<p>Once the PQ quantizers and k-means buckets are determined, the initial parameters are distributed to each machine in the cluster. Every sentence can be added to the FAISS nearest-neighbors index structure in parallel, and then the reduced codes and buckets can be merged in-memory on one machine. We again distributed the nearest-neighbors index, now containing all 155-million sentence codes, to each machine in the cluster. In parallel, these machines can identify relevant buckets per-point, and record their 25 approximate nearest-neighbors. If we have m machines, each with p cores, and search q = 16 of the b = 2048 buckets-per-query, we reduce complexity for identifying all nearest-neighbors from O(dn 2 ) to O qdn 2 /32bpm . We additionally add simpler sentence-occurrence edges for lemmas, n-grams and entities. In each case, we produce an edge between s and x provided that lemma, entity, n-gram, or metadata-keyword x occurs in sentence s. The last node type is SemRep predicates [4]. Each has associated metadata, such as the sentence in which it occurred, its raw text, and its relevant UMLS coded terms. For each unique subjectverb-object triple, we create a node in the semantic graph. We then create edges from that node to each relevant sentence, keyword, lemma, entity, and n-gram. Our overall graph consists of 184-million nodes and 12.3-billion edges. Graph Embedding. We utilize the PyTorch-BigGraph (PTBG) embedding utility to perform a distributed embedding of the entire network [25]. PTBG learns typed embeddings, and we define node types corresponding to each presented in our semantic graph schema. Each undirected edge in our graph schema is also coded as two directional edges of types x → y and y → x.</p>
<p>We explore two different embedding dimensionalities: 256 and 512. When computing both embeddings, we specify for edges to be encoded via the dot-product of nodes, and for relationship types to be encoded using a learned translation per-type. We generate a total of 100 negative samples per edge, 50 chosen from nodes within each batch, and 50 chosen from nodes within the corresponding partitions. Dot products between embeddings are learned using the supplied softmax loss, with the first dimension of every embedding acting as a bias unit.</p>
<p>Formally, if an edge ij exists between nodes i and j of types t i and t j respectively, then we learn an embedding function e(·) that is used to create a score for ij by projecting each node into R N where N Figure 3: AGATHA ranking transformer encoder. is a predetermined embedding dimensionality. In our experiments we consider N = 256 and 512. This embedding function uses the typed translation vector T (titj ) ∈ R N that is shared for all edges of the same type as ij. This score is defined as:
s(ij) = e(i) 1 + e(j) 1 + T (titj ) 1 + N k=2 e(i) k e(j) k + T (titj ) k(4)
Then, for each edge ij, we generate 100 negative samples in the form x
(ij) n y (ij)
n . Their scores are compared to that of the positive sample using the following loss function, which indicates the component of overall loss corresponding to edge ij:
GraphLoss ij = −s(ij) + log 100 n=0 exp s x (ij) n y (ij) n(5)
Training Data. In order to learn what makes a plausible biomedical connection, we collect the set of published connections present in our pre-2015 training set. For this, we turn to the Semantic Medical Database (SemMedDB), which contains over 19-million pre-2015 SemRep [4] predicates parsed from all of MEDLINE. A SemRep predicate is a published subject-verb-object triple that is identified algorithmically. In lieu of a true data set of attempted hypotheses, we can train our model on these published connections. However, this approach comes with some drawbacks. Firstly, SemRep predicates are defined on the set of UMLS terms, which will restrict our system to only those entities that have been coded. This limitation is acceptable given size size of UMLS, and presence of existing benchmarks defined among UMLS terms [40]. Secondly, the predicate set is noisy, and may contain entries that are incorrect or obsolete, as well as algorithmically introduced inaccuracies. However, we find at scale that these sources of noise do not overwhelm the useful signal present within SemMedDB.</p>
<p>Ranking Plausible Connections</p>
<p>We train a model to rank published SemRep [4] predicates above noisy negative samples using the transformer architecture [42]. To do so we first formulate a predicate with subject α and object β for input into the model. Those predicates that are collected from SemRep are "positive samples" (PS). The function Γ(·) indicates the set of neighbor predicates that include a term as either a subject or object. We represent the αβ predicate as a set with elements that include both terms, as well as a fixed-size sample with-replacement of size s = 15 of each node's non-shared predicates:
PS αβ = α, β, γ (α) 1 , . . . , γ (α) s , γ (β) 1 , . . . , γ (β) s where γ (α) i ∼ {Γ(α) − Γ(β)}, and γ (β) i ∼ {Γ(β) − Γ(α)}(6)
Negative Samples We cannot learn to rank positive training examples in isolation. Instead, we first generate negative samples to accompany each published predicate. This include two types of samples: scrambles and swaps. Both are necessary, as we find during training that the easier-to-distinguish scrambles aid early convergence, while the swaps require the model to understand the biomedical concepts encoded by the semantic graph embedding. The negative scramble (NScr) selects two arbitrary terms x and y, as well as 2s arbitrary predicates from the set of training data. While we enforce that x and y do not share a predicate, we do not enforce any relationship between the sampled predicates and these terms. Therefore these samples are easy to distinguish from positive examples. If T denote all positive-set terms, and P denotes all predicates, then a negative scramble associated with positive sample αβ is notated as:
NScr αβ = {x, y, γ 1 , . . . , γ 2s } where x, y ∼ T , and γ i ∼ P s.t. Γ(x) ∩ Γ(y) = ∅(7)
The negative swap (NSwp) selects two arbitrary terms, but samples the associated predicates in the same manner as the positive sample. Therefore, the observed term-predicate relationship will be the same for each half of this negative sample (α and γ (α) i ). This sample requires the model to learn that some αβ pairs should not go together, and this will require an understanding of the relationships between biomedical terms. A negative scramble associated with αβ is notated as: 
NSwp αβ = x, y, γ (x) 1 , . . . , γ (x) s , γ(y)
Here n = 10 denotes the number of negative scrambles, n = 30 is the number of negative swaps, m = 0.1 is the desired margin between positive and negative samples, and H is the learned function that produces a ranking criteria given two terms and a sample of predicates. Model. Using the transformer encoder summarized in Section 2, as well as the semantic graph embedding, we construct our model. If e(x) represents the semantic graph embedding of x, FF represents a feed-forward layer, and E represents an encoder layer, then our model H is defined as:
H(X) = sigmoid(MW ) M = 1 |X| xi∈X E N (F F (e(x i ))) E i+1 (x) = E(E i (x)), and E 0 (x) = x(10)
Here N = 4 represents the number of encoder layers, and W indicates the learned weights associated with the final ranking projection. By averaging the transformer output over the input sequence X, then projecting that result down to a single real value with W , and applying the sigmoid function, we produce an output per-predicate in the unit interval. This function is depicted in Figure 4. The supplemental information containing training parameters and additional model detail.</p>
<p>Validation</p>
<p>Testing hypothesis generation, in contrast to information retrieval, is difficult as ultimately these systems are intended to discover information that is unknown to even those designing them [45]. A thorough evaluation would require a costly process wherein scientists explore automatically posed hypotheses. Instead, we perform a historical validation, in a manner similar to that performed in [40,38]. This method enables large-scale evaluation of many biomedical subdomains almost instantly, but cannot truly tell us how our system will perform in a laboratory environment. Comparison with Heuristic-Based Ranking. We begin by comparing the performance numbers obtained through our proposed learned ranking criteria with other ranking methods posed in [40]. Specifically, the Moliere system presents experimental numbers for various training-data scenarios for the same 2015 temporal holdout as used in this work [38]. For a direct comparison, we use our proposed method to rank the same set of positive and negative validation examples. Comparison by Subdomain Recommendation. As mentioned in [16], the Moliere validation set has limitations. We improve this set by expanding both the quantity and diversity of considered term pairs, as well as evaluating AGATHA through the use of all-pairs recommendation queries within popular biomedical subdomains. As a result, this comparison effectively uses subdomain-specific negative examples, which makes for a harder benchmark than that presented in the Moliere work. It is worth nothing that these all-pairs searches are made possible by the very efficient neural-network inference within AGATHA, and would not be as computationally efficient in the Moliere shortest-path and topic-modeling approach.</p>
<p>This analysis begins by extracting semantic types [2], which categorize each UMLS term per-predicate into one of 134 categories, including "Lipid," "Plant," or "Enzyme." From there, we can group αβ predicate-term pairs by types t α and t β . We select the twenty predicate type pairs with the most popularity in the post-2015 dataset, and within each type we identify the top-100 predicates with the most rapid non-decreasing growth of popularity determined by the number of abstracts containing each term-pair per year. These predicates form the positive class of the validation set. We form the rest of the subdomain's validation set by recording all possible undiscovered pairs of type t α t β from among the UMLS terms in the top-100 predicates. We then rank the resulting set by the learned ranking criteria, and evaluate these results using a range of metrics. Metrics. The first metrics we consider are typical for determining a classification threshold: the area under the receiver-operating-characteristic curve (AUC ROC) and the area under the precision-recall curve (AUC PR). We additionally provide recommendation system metrics, such as top-k precision (P.@k), average precision (AP.@k), and overall reciprocal rank (RR). Top-k precision is simply the number of published term-pairs appearing in the first k elements of the ranked list, divided by k. Top-k average precision weights each published result by its location in the front of the ranked list. The reciprocal rank is the inverse of the rank of the first published term pair. The above recommender system metrics all consider the single many-to-many query within a biomedical subdomain. However, this same result can be interpreted as a set of one-to-many recommendation queries. Doing so enables us to compute the mean average precision(MAP.@k), and mean-reciprocal rank(MRR.@k) for the set of recommendations. A high MRR within a domain indicates that the researcher should expect to see a useful result within the first few results. A high MAP indicates that out of the top k results, more of them are useful. These metrics, taken together, should influence biomedical researchers when exploring the results of a one-to-many query.</p>
<p>Results</p>
<p>We compare the performance of AGATHA against Moliere, as presented in [38]. In that work, multiple trained instances of Moliere rank a benchmark set of positive and negative potential connections using a range of criteria defined in [40]. These Moliere instances each use different datasets published prior to 2015 in order to perform hypothesis queries, of which we focus on two: all of MEDLINE (Moliere: MEDLINE), and all of PubMedCentral (Moliere: Full Text). The former instance represents a system trained on the same raw data as the AGATHA system presented here, while the latter represents a system trained on all publicly available full-text papers provided by the NLM released in the same date range.</p>
<p>The prior work establishes that the Moliere topic-modeling approach is improved by the additional information made available by full-text papers, but at a overwhelming 45x runtime penalty. These quality    Table 2, and we include additional results for the AGATHA system when evaluated on only abstracts, and exactly the same set of predicates. We observe that the AGATHA system, when trained with 512-dimensional graph embeddings, improves upon Moliere: Medline by 25% and Moliere: Full Text by 13%. Importantly, this increase in quality comes at an overwhelming decrease in runtime, with the wall time per-query dropping from minutes to milliseconds, due to the introduction of the deep-learning approach.</p>
<p>To extend the validation beyond the above results, provided that we can now generate thousands of hypothesis per-minute, we explore the capacity of our deep-learning ranking criteria to perform hypothesis recommendation within various many-to-many queries across different biomedical sub-domains. These results, displayed in Table 1, list the 20 predicate types with the most popularity following 2015. Due to space limitations, we present predicate types using NLM semantic type codes [2]. All numbers are reported from the AGATHA-512 model.</p>
<p>We observe that the (Gene)→(Cell Function)(gngm, celf) predicate type, is the easiest predicate type for AGATHA-512 to recommend, even though connections of this type only account for 0.29% of the training data. Of the top-10 recommendations the highest ranked is a valid connection and half are valuable. When performing a one-to-many query within this type of connection, we observe 85% of all top-10 suggestions to be useful on average, and that a useful result occurs typically within the first two recommendations. We see similar performance in the (Gene)→(Neoplastic Process) (gngm, neop) and (Amino Acid, Peptide, or Protein)→(Neoplastic Process) (aapp, neop) sub-domains. Interestingly, there appears to be little correlation between the popularity of a predicate type in the training data and the quality of the resulting recommendations. This result enforces the idea of AGATHA as a general-purpose biomedical hypothesis generation system.</p>
<p>Of the 20-most-popular predicate subdomains considered, AGATHA-512 has the most difficulty with the (Therapeutic or Preventive Procedure)→(Disease or Syndrome)(topp, dsyn). In this subdomain, the the highest ranked positive predicate is ranked tenth, and only twelve of the top-100 suggestions are useful. Still, in a one-to-many query, we expect about one-in-ten recommended predicates to be useful, and for the top-3 predicates to contain a useful result. While the lower-performing subdomains are significantly harder for AGATHA-512 than the top few, we note that even a low-precision tool can be useful for aiding the biomedical discovery process. Furthermore, these difficult subdomains are still ranked significantly better than random chance, and even better than many of the classical ranking measures presented in [40]. Using this information, future work may wish to fine-tune the AGATHA method to a specific subdomain for improved performance.</p>
<p>Lessons Learned and Open Problems</p>
<p>Result Interpretability. While deep-learning models are notoriously hard for human decision makers to interpret, we find that biomedical researchers still need to understand how a result was produced in order to act on model predictions. However, we cannot leave the entire analysis up for human judgement, as this drastically reduces the benefits of "automatic" hypothesis generation. To walk the narrow edge between these conflicting objectives, we implement both an automatic ranking component, as well as a more interpretable topic-model query system. We find that these tools serve different functions during different times of the discovery process.</p>
<p>At first, a researcher may be considering a wide range of potential research directions, such as during the candidate selection phase of the drug-discovery process. This often requires assembling hundreds (or thousands) of target ingredients, compounds, genes, or deceases, and determining whether elements of this large set have a relationship to an item of interest. For instance, when we evaluated HIV-associated Neurodegenerative Disease, we explored over 40,000 potential human genes [3]. This component of the discovery process fits nicely into the deep-learning ranking and recommendation system proposed here, especially when the target set is so large that a manual literature review may prove costly.</p>
<p>Once a candidate set of targets has been winnowed from the large target set, the researcher will prioritize interpretability. However, the candidate set is typically orders of magnitude smaller than the target set. Therefore, we can afford to run more costly-yet-interpretable routines, even if these routines do not provide any form of "automatic" analysis. At this stage, we switch from our deep-learning ranking method to the topic-modeling approach similar to that presented in Moliere [39]. This process finds a path within our semantic network containing the textual information necessary to describe a potential connection. We present that path along with the set of relevant sentences, as well as a visualization of the topic model built from those sentences. Researchers can explore the sets of entities that are frequently mentioned together in order to expand their mental models of each hypothesis's quality.</p>
<p>Datasets and Expandability. When discussing hypothesis generation systems with prospective adopters in the biomedical community, we often are asked to include specific datasets that has domainrelevance to an individual's research direction. For instance, the set of clinical trials, internal experimental findings, or a database of chemicals.</p>
<p>We designed AGATHA to be easily extendable. Domain scientists can easily supply new graph datasets as a collection of TSV files and by making minor changes to the PTBG configuration. Furthermore, new textual sources can be merged into the pipeline with straightforward modification to the python dataprocessing pipeline. In contrast to the graph and text sources, it is not currently clear how to incorporate experimental data into the AGATHA system. This challenge arises from the many forms experimental data can take. In the case where an experiment can be reformulated as a network, such as converting the geneexpression matrix into a gene-to-gene network, these results can trivially be introduced as new edges. Other experimental results, such as many clinical trials, include a thorough summary of that trial's findings. These may be introduced as a combination of textual and graph-based sources, including both the description text, as well as any links to known publications that reference the trial. Importantly, we do not find a "one size fits all" solution for experimental data, and more work should explore the costs and benefit associated with various datasets.</p>
<p>Related Work</p>
<p>Foster et al. [13] identify a series of common successful research strategies often used by scientists. In doing so they demonstrate that high-risk and innovative strategies are uncommon among the scientific community in general. It follows that the field of hypotheses generation obeys similar rules. Many systems have found success using algorithmic techniques that approximate these common research strategies by studying term co-occurrences [19,17,43], or predicting links with a graph of biomedical entities [29,11]. While the Foster's model of research strategies has proven to be useful, the mechanisms involved in complex scientific discoveries remain unexplored.</p>
<p>Unsurprisingly, we find that hypothesis generation systems utilize algorithmic techniques in a range of complexity that is analogous to these human research strategies. The first hypothesis generation system, ARROWSMITH, presents the ABC model of automatic discovery [36]. This technique identifies a list of terms that are anticipated to help explain a connection between two terms of interest. This basic algorithm remains in some modern systems, such as [23]. However, ABC-based techniques have significant limitations [32], including their similarity metrics defined on heuristically determined term lists, as well as their reliance on manual validation processes. As a result, ABC systems are know to be biased towards finding incremental discoveries [24].</p>
<p>A completely different strategy of performing LBD is proposed by Spangler et al. in [35]. To explore the p53 kinase, the authors use neighborhood graphs constructed from entity co-occurrence rates. The approach relies on domain experts and requires manual oversight to provide MEDLINE search queries, and to prune redundant terms, but produces promising results. In [10] the authors demonstrate that this technique can identify kinase NEK2 as an inhibitor of p53, and in [5] a similar scientist-in-the-loop technique identifies a number of RNA-binding proteins associated with ALS. A significant step beyond ABC and human-assisted techniques is to incorporate a domain specific datasets. Bipartite graphs, such as the gene-disease [27] or the term-document [14] networks, are frequent choices. These systems usually aim to perform a number of graph traversals between node-pairs in order to rank the most viable options. However, the number of generated paths may be prohibitively large, which reduces ranking quality [15] To address this problem, Gopalakrishnan proposes two-stage filtering through a "singleclass classifier" which is able to prune up to 90% hypotheses prior to the ranking scheme [14] One recent approach is to use deep learning models to help extract viable biomedical hypotheses. Sang et al. [30] describe GrEDeL, a way to generate new hypotheses using knowledge graphs obtained from predicate triples in the form of subject, verb, object. This approach finds all possible paths between a given drug and decease, provided those paths include a particular target entity. Then these paths are evaluated using a LSTM model that captures features related to drug-disease associations. While the GrEDeL system is successful at identifying some novel drug-disease relationships, this approach has some important trade-offs: (1) Their proposed model is trained using SemRep graph traversals as a sequence, which the authors note is a highly noisy dataset. Furthermore, multiple redundant and similar paths exist within their dataset, which decrease the quality of their validation holdout set. The AGATHA system overcomes this limitation by leveraging node neighborhoods in place of paths. (2) Their knowledge graph is constructed exclusively from predicates mined from MEDLINE abstracts using SemRep. This process affects the model quality significantly and, being the only resource of knowledge, it requires careful manual filtering of false positive and isolated predicates. (3) The GrEDeL LSTM model is trained to only discover drug-disease associations, and does not generalize to other biomedical subdomains. (4) This approach embeds their predicate knowledge graph using the TransE method [8], which supposes that relationships can be modeled as direct linear transformations. When using the large number of relationship types present in SemRep, this assumption greatly reduces the useful variance in the resulting node embeddings.</p>
<p>Conclusions</p>
<p>This work presents AGATHA, a deep-learning biomedical hypothesis generation system, which can accelerate discovery by learning to detect useful new research ideas from existing literature. This technique enables domain scientists to keep pace with the accelerating rate of publications, and to efficiently extract implicit connections from the breadth of biomedical research. By constructing a large semantic network, embedding that network, and then training a transformer-encoder deep-learning model, we can learn a ranking criteria that prioritizes plausible connections. We validate this ranking technique by constructing an instance of the AGATHA system using only data published prior to January 1 st 2015. This system then evaluates both a benchmark of predicates established from prior work [38], and performs recommendation in twenty popular biomedical subdomains. The result is state-of-the art prediction quality on the 2015 benchmark, as well as strong performance across a range of subdomains. The AGATHA system is open-source and written entirely in Python and PyTorch, which enable to be easily used or adapted anywhere. We release both the 2015 validation system, as well as an up-to-date 2019 system to accelerate the broader community of biomedical sciences.</p>
<p>Reproducability Details</p>
<p>Training Graph Embedding When optimizing our semantic graph embedding, we find that maximal performance is achieved using a compute cluster of twenty twenty-four-core machines. Within the 72h time restriction of the Palmetto super computing cluster, we have enough time to see every edge in the graph 10 times, in the case of the 256-dim embedding, and 5 times in the case of the 512-dim embedding. Once complete, we are ready to begin training the AGATHA deep learning hypothesis generation model. Training Ranking Model We minimize the ranking loss over all published predicates using the LAMB optimizer [46]. This allows us to efficiently train using very large batch sizes, which is necessary as we leverage 10 NVIDIA V100 GPUs to effectively process 600 positive samples (and therefore 2,400 total samples) per batch. In terms of hyperparameters, we select a learning rate of η = 0.01 with a linear warm up of 1,000 batches, a margin of m = 0.1, a neighborhood sub-sampling rate of s = 15, and we perform cross-validation on a 1% random holdout to provide early stopping and to select the best model with respect to validation loss. Due to the large size of training data, one epoch consists of only 10% of the overall training data. This process is made easier through the helpful Pytorch-Lightning library [12].   </p>
<p>L
We minimize the margin ranking loss between each positive sample and all associated negative samples. The contribution of positive sample αβ to the overall loss is defined as: PS αβ , Nswp (j) αβ where L(p, n) = max (0, m − H(p) + H(n))</p>
<p>Table 1 :
1AGATHA-512. Above are hypothesis prediction results on biomedical sub-domains. Indicated along with performance numbers are the percentage of training data (pre-2015 predates) as well as the training-data popularity rank out of 6396, with 1 being most popular. Metrics described in detail in Section 5.System Instance 
ROC AUC PR AUC </p>
<p>Moliere: Medline 
0.718 
0.820 
Moliere: Full Text 
0.795 
0.778 
AGATHA-256 
0.826 
0.895 
AGATHA-512 
0.901 
0.936 </p>
<p>Table 2 :
2Benchmark comparison between Moliere and AGATHA on the same benchmark. results are reproduced in</p>
<p>Layer NameInput Dim. Output Dim. Num. ParamsLinear (ReLU) 
512 
512 
262656 
Enc. M.H.Att. 
512 
512 
1050624 
Enc. Dropout(0.1) 
512 
512 
0 
Enc. LayerNorm 
512 
512 
1024 
Enc. Linear (ReLU) 
512 
1024 
524800 
Enc. Dropout(0.1) 
512 
512 
0 
Enc. Linear (ReLU) 
1024 
512 
525312 
Enc. Dropout(0.1) 
512 
512 
0 
Enc. LayerNorm 
512 
512 
1024 
Encoder 2 
512 
512 
2102272 
Encoder 3 
512 
512 
2102272 
Encoder 4 
512 
512 
2102272 
Linear (sigmoid) 
512 
1 
513 </p>
<p>Table 3 :
3Layers and parameter counts for the AGATHA transformer model.Node Type 
Count </p>
<p>Sentence 
140,913,505 
Predicate 
19,268,319 
Lemma 
12,718,832 
Entity 
10,240,635 
Coded Term 
488,923 
n-Grams 
333,862 </p>
<p>Total Nodes 
183,964,076 
Total Edges 12,362,325,167 </p>
<p>Table 4 :
4Graph Size of 2015 Validation Dataset
At the time of writing, the bulk release at the end of 2019 contained 1,014 files, containing nearly 30-million documents
We specifically use the pre-trained "scibert-scivocab-uncased" model, which was trained on over 1.14-million full-text papers.</p>
<p>Inhibition of the dead box rna helicase 3 prevents hiv-1 tat and cocaine-induced neurotoxicity by targeting microglia activation. Marina Aksenova, Justin Sybrandt, Biyun Cui, Vitali Sikirzhytski, Hao Ji, Diana Odhiambo, D Matthew, Jill R Lucius, Eugenia Turner, Edsel Broude, Peña, Journal of Neuroimmune Pharmacology. Marina Aksenova, Justin Sybrandt, Biyun Cui, Vitali Sikirzhytski, Hao Ji, Diana Odhiambo, Matthew D Lucius, Jill R Turner, Eugenia Broude, Edsel Peña, et al. Inhibition of the dead box rna helicase 3 prevents hiv-1 tat and cocaine-induced neurotoxicity by targeting microglia activation. Journal of Neuroimmune Pharmacology, pages 1-15, 2019.</p>
<p>Semrep: A repository for semantic mapping. Datenbanksysteme für Business. Patrick Arnold, Erhard Rahm, BTWPatrick Arnold and Erhard Rahm. Semrep: A repository for semantic mapping. Datenbanksysteme für Business, Technologie und Web (BTW 2015), 2015.</p>
<p>Artificial intelligence in neurodegenerative disease research: use of ibm watson to identify additional rna-binding proteins altered in amyotrophic lateral sclerosis. Nadine Bakkar, Tina Kovalik, Ileana Lorenzini, Scott Spangler, Alix Lacoste, Kyle Sponaugle, Philip Ferrante, Elenee Argentinis, Rita Sattler, Robert Bowser, Acta neuropathologica. 1352Nadine Bakkar, Tina Kovalik, Ileana Lorenzini, Scott Spangler, Alix Lacoste, Kyle Sponaugle, Philip Ferrante, Elenee Argentinis, Rita Sattler, and Robert Bowser. Artificial intelligence in neurodegenerative disease research: use of ibm watson to identify additional rna-binding proteins altered in amyotrophic lateral sclerosis. Acta neuropathologica, 135(2):227-247, 2018.</p>
<p>Iz Beltagy, Arman Cohan, Kyle Lo, arXiv:1903.10676Scibert: Pretrained contextualized embeddings for scientific text. arXiv preprintIz Beltagy, Arman Cohan, and Kyle Lo. Scibert: Pretrained contextualized embeddings for scientific text. arXiv preprint arXiv:1903.10676, 2019.</p>
<p>Probabilistic topic models. M David, Blei, Communications of the ACM. 554David M Blei. Probabilistic topic models. Communications of the ACM, 55(4):77-84, 2012.</p>
<p>Translating embeddings for modeling multi-relational data. Antoine Bordes, Nicolas Usunier, Alberto Garcia-Duran, Jason Weston, Oksana Yakhnenko, Advances in neural information processing systems. Antoine Bordes, Nicolas Usunier, Alberto Garcia-Duran, Jason Weston, and Oksana Yakhnenko. Trans- lating embeddings for modeling multi-relational data. In Advances in neural information processing systems, pages 2787-2795, 2013.</p>
<p>Ibm watson: how cognitive computing can be applied to big data challenges in life sciences research. Ying Chen, Griff Jd Elenee Argentinis, Weber, Clinical therapeutics. 384Ying Chen, JD Elenee Argentinis, and Griff Weber. Ibm watson: how cognitive computing can be applied to big data challenges in life sciences research. Clinical therapeutics, 38(4):688-701, 2016.</p>
<p>Literature-based automated discovery of tumor suppressor p53 phosphorylation and inhibition by nek2. Byung-Kwon, Tajhal Choi, Neha Dayaram, Angela D Parikh, Meena Wilkins, Nagarajan, B Ilya, Novikov, J Benjamin, Sung Yun Bachman, Jung, J Peter, Jacques L Haas, Labrie, Proceedings of the National Academy of Sciences. 11542Byung-Kwon Choi, Tajhal Dayaram, Neha Parikh, Angela D Wilkins, Meena Nagarajan, Ilya B Novikov, Benjamin J Bachman, Sung Yun Jung, Peter J Haas, Jacques L Labrie, et al. Literature-based auto- mated discovery of tumor suppressor p53 phosphorylation and inhibition by nek2. Proceedings of the National Academy of Sciences, 115(42):10666-10671, 2018.</p>
<p>Biomine: predicting links between biological entities using network models of heterogeneous databases. Lauri Eronen, Hannu Toivonen, BMC bioinformatics. 131119Lauri Eronen and Hannu Toivonen. Biomine: predicting links between biological entities using network models of heterogeneous databases. BMC bioinformatics, 13(1):119, 2012.</p>
<p>Pytorch lightning. W A , W.A. et al. Falcon. Pytorch lightning. https://github.com/PytorchLightning/pytorch-lightning, 2019.</p>
<p>Tradition and innovation in scientists research strategies. G Jacob, Andrey Foster, James A Rzhetsky, Evans, American Sociological Review. 805Jacob G Foster, Andrey Rzhetsky, and James A Evans. Tradition and innovation in scientists research strategies. American Sociological Review, 80(5):875-908, 2015.</p>
<p>Towards selflearning based hypotheses generation in biomedical text domain. Kishlay Vishrawas Gopalakrishnan, Guangxu Jha, Xun, Q Hung, Aidong Ngo, Zhang, Bioinformatics. 3412Vishrawas Gopalakrishnan, Kishlay Jha, Guangxu Xun, Hung Q Ngo, and Aidong Zhang. Towards self- learning based hypotheses generation in biomedical text domain. Bioinformatics, 34(12):2103-2115, 2018.</p>
<p>Generating hypothesis: Using global and local features in graph to discover new knowledge from medical literature. Kishlay Vishrawas Gopalakrishnan, Aidong Jha, Wei Zhang, Jin, Proceedings of the 8th International Conference on Bioinformatics and Computational Biology. the 8th International Conference on Bioinformatics and Computational BiologyVishrawas Gopalakrishnan, Kishlay Jha, Aidong Zhang, and Wei Jin. Generating hypothesis: Using global and local features in graph to discover new knowledge from medical literature. In Proceedings of the 8th International Conference on Bioinformatics and Computational Biology, BICOB, pages 23-30, 2016.</p>
<p>Indirect relatedness, evaluation, and visualization for literature based discovery. Sam Henry, Sam Henry. Indirect relatedness, evaluation, and visualization for literature based discovery. 2019.</p>
<p>Exploiting semantic relations for literature-based discovery. Dimitar Hristovski, Carol Friedman, C Thomas, Borut Rindflesch, Peterlin, AMIA annual symposium proceedings. 349Dimitar Hristovski, Carol Friedman, Thomas C Rindflesch, and Borut Peterlin. Exploiting semantic relations for literature-based discovery. In AMIA annual symposium proceedings, volume 2006, page 349. American Medical Informatics Association, 2006.</p>
<p>Product quantization for nearest neighbor search. Herve Jegou, Matthijs Douze, Cordelia Schmid, IEEE transactions on pattern analysis and machine intelligence. 33Herve Jegou, Matthijs Douze, and Cordelia Schmid. Product quantization for nearest neighbor search. IEEE transactions on pattern analysis and machine intelligence, 33(1):117-128, 2010.</p>
<p>Anni 2.0: a multipurpose text-mining tool for the life sciences. Rob Jelier, J Martijn, Antoine Schuemie, Veldhoven, C J Lambert, Guido Dorssers, Jan A Jenster, Kors, Genome biology. 9696Rob Jelier, Martijn J Schuemie, Antoine Veldhoven, Lambert CJ Dorssers, Guido Jenster, and Jan A Kors. Anni 2.0: a multipurpose text-mining tool for the life sciences. Genome biology, 9(6):R96, 2008.</p>
<p>Conceptsbridges: Uncovering conceptual bridges based on biomedical concept evolution. Kishlay Jha, Guangxu Xun, Yaqing Wang, Vishrawas Gopalakrishnan, Aidong Zhang, Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining. the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data MiningKishlay Jha, Guangxu Xun, Yaqing Wang, Vishrawas Gopalakrishnan, and Aidong Zhang. Concepts- bridges: Uncovering conceptual bridges based on biomedical concept evolution. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining, pages 1599- 1607, 2018.</p>
<p>Hypothesis generation from text based on co-evolution of biomedical concepts. Kishlay Jha, Guangxu Xun, Yaqing Wang, Aidong Zhang, Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining. the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data MiningKishlay Jha, Guangxu Xun, Yaqing Wang, and Aidong Zhang. Hypothesis generation from text based on co-evolution of biomedical concepts. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining, pages 843-851, 2019.</p>
<p>Billion-scale similarity search with gpus. Jeff Johnson, Matthijs Douze, Hervé Jégou, arXiv:1702.08734arXiv preprintJeff Johnson, Matthijs Douze, and Hervé Jégou. Billion-scale similarity search with gpus. arXiv preprint arXiv:1702.08734, 2017.</p>
<p>A context-based abc model for literature-based discovery. Kim Yong Hwan, Min Song, PloS one. 144Yong Hwan Kim and Min Song. A context-based abc model for literature-based discovery. PloS one, 14(4), 2019.</p>
<p>Literature-related discovery. Annual review of information science and technology. Joel A Ronald N Kostoff, Jeffrey L Block, Solka, B Michael, Robert L Briggs, Jesse A Rushenberg, Dustin Stump, Terence J Johnson, Jeffrey R Lyons, Wyatt, 43Ronald N Kostoff, Joel A Block, Jeffrey L Solka, Michael B Briggs, Robert L Rushenberg, Jesse A Stump, Dustin Johnson, Terence J Lyons, and Jeffrey R Wyatt. Literature-related discovery. Annual review of information science and technology, 43(1):1-71, 2009.</p>
<p>PyTorch-BigGraph: A Large-scale Graph Embedding System. Adam Lerer, Ledell Wu, Jiajun Shen, Timothee Lacroix, Luca Wehrstedt, Abhijit Bose, Alex Peysakhovich, Proceedings of the 2nd SysML Conference. the 2nd SysML ConferencePalo Alto, CA, USAAdam Lerer, Ledell Wu, Jiajun Shen, Timothee Lacroix, Luca Wehrstedt, Abhijit Bose, and Alex Peysakhovich. PyTorch-BigGraph: A Large-scale Graph Embedding System. In Proceedings of the 2nd SysML Conference, Palo Alto, CA, USA, 2019.</p>
<p>Biograph: unsupervised biomedical knowledge discovery via automated hypothesis generation. M L Anthony, Jeroen Liekens, Walter De Knijf, Bart Daelemans, Goethals, Jurgen Peter De Rijk, Del-Favero, Genome biology. 12657Anthony ML Liekens, Jeroen De Knijf, Walter Daelemans, Bart Goethals, Peter De Rijk, and Jur- gen Del-Favero. Biograph: unsupervised biomedical knowledge discovery via automated hypothesis generation. Genome biology, 12(6):R57, 2011.</p>
<p>Diseaseconnect: a comprehensive web server for mechanism-based disease-disease connections. Chun-Chi Liu, Yu-Ting Tseng, Wenyuan Li, Chia-Yu Wu, Ilya Mayzus, Andrey Rzhetsky, Fengzhu Sun, Michael Waterman, J W Jeremy, Chen, M Preet, Chaudhary, Nucleic acids research. 42W1Chun-Chi Liu, Yu-Ting Tseng, Wenyuan Li, Chia-Yu Wu, Ilya Mayzus, Andrey Rzhetsky, Fengzhu Sun, Michael Waterman, Jeremy JW Chen, Preet M Chaudhary, et al. Diseaseconnect: a comprehensive web server for mechanism-based disease-disease connections. Nucleic acids research, 42(W1):W137-W146, 2014.</p>
<p>Mark Neumann, Daniel King, arXiv:1902.07669Iz Beltagy, and Waleed Ammar. Scispacy: Fast and robust models for biomedical natural language processing. arXiv preprintMark Neumann, Daniel King, Iz Beltagy, and Waleed Ammar. Scispacy: Fast and robust models for biomedical natural language processing. arXiv preprint arXiv:1902.07669, 2019.</p>
<p>Supervised approach to rank predicted links using interestingness measures. K Murali, Pusala, G Ryan, Benton, Raju N Vijay V Raghavan, Gottumukkala, 2017 IEEE International Conference on Bioinformatics and Biomedicine (BIBM). IEEEMurali K Pusala, Ryan G Benton, Vijay V Raghavan, and Raju N Gottumukkala. Supervised approach to rank predicted links using interestingness measures. In 2017 IEEE International Conference on Bioinformatics and Biomedicine (BIBM), pages 1085-1092. IEEE, 2017.</p>
<p>Gredel: A knowledge graph embedding based method for drug discovery from biomedical literatures. Shengtian Sang, Zhihao Yang, Xiaoxia Liu, Lei Wang, Hongfei Lin, Jian Wang, Michel Dumontier, IEEE Access. 7Shengtian Sang, Zhihao Yang, Xiaoxia Liu, Lei Wang, Hongfei Lin, Jian Wang, and Michel Dumontier. Gredel: A knowledge graph embedding based method for drug discovery from biomedical literatures. IEEE Access, 7:8404-8415, 2018.</p>
<p>A survey of heterogeneous information network analysis. Chuan Shi, Yitong Li, Jiawei Zhang, Yizhou Sun, S Yu Philip, IEEE Transactions on Knowledge and Data Engineering. 291Chuan Shi, Yitong Li, Jiawei Zhang, Yizhou Sun, and S Yu Philip. A survey of heterogeneous informa- tion network analysis. IEEE Transactions on Knowledge and Data Engineering, 29(1):17-37, 2016.</p>
<p>Literature-based discovery: Beyond the abcs. R Neil, Smalheiser, Journal of the American Society for Information Science and Technology. 632Neil R Smalheiser. Literature-based discovery: Beyond the abcs. Journal of the American Society for Information Science and Technology, 63(2):218-224, 2012.</p>
<p>Rediscovering don swanson: The past, present and future of literature-based discovery. R Neil, Smalheiser, Journal of Data and Information Science. 24Neil R Smalheiser. Rediscovering don swanson: The past, present and future of literature-based discov- ery. Journal of Data and Information Science, 2(4):43-64, 2017.</p>
<p>Accelerating Discovery: Mining Unstructured Information for Hypothesis Generation. Scott Spangler, Chapman and Hall/CRCScott Spangler. Accelerating Discovery: Mining Unstructured Information for Hypothesis Generation. Chapman and Hall/CRC, 2015.</p>
<p>Automated hypothesis generation based on mining scientific literature. Scott Spangler, Angela D Wilkins, J Benjamin, Meena Bachman, Tajhal Nagarajan, Peter Dayaram, Sam Haas, Regenbogen, R Curtis, Austin Pickering, Jeffrey N Comer, Myers, Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining. the 20th ACM SIGKDD international conference on Knowledge discovery and data miningScott Spangler, Angela D Wilkins, Benjamin J Bachman, Meena Nagarajan, Tajhal Dayaram, Peter Haas, Sam Regenbogen, Curtis R Pickering, Austin Comer, Jeffrey N Myers, et al. Automated hy- pothesis generation based on mining scientific literature. In Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 1877-1886, 2014.</p>
<p>Fish oil, raynaud's syndrome, and undiscovered public knowledge. Perspectives in biology and medicine. Don R Swanson, 30Don R Swanson. Fish oil, raynaud's syndrome, and undiscovered public knowledge. Perspectives in biology and medicine, 30(1):7-18, 1986.</p>
<p>Undiscovered public knowledge. The Library Quarterly. Don R Swanson, 56Don R Swanson. Undiscovered public knowledge. The Library Quarterly, 56(2):103-118, 1986.</p>
<p>Are abstracts enough for hypothesis generation?. Justin Sybrandt, Angelo Carrabba, Alexander Herzog, Ilya Safro, 2018 IEEE International Conference on Big Data (Big Data). Justin Sybrandt, Angelo Carrabba, Alexander Herzog, and Ilya Safro. Are abstracts enough for hypoth- esis generation? In 2018 IEEE International Conference on Big Data (Big Data), pages 1504-1513, 2018.</p>
<p>Moliere: Automatic biomedical hypothesis generation system. Justin Sybrandt, Michael Shtutman, Ilya Safro, Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD '17. the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD '17New York, NY, USAACMJustin Sybrandt, Michael Shtutman, and Ilya Safro. Moliere: Automatic biomedical hypothesis gen- eration system. In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD '17, pages 1633-1642, New York, NY, USA, 2017. ACM.</p>
<p>Large-scale validation of hypothesis generation systems via candidate ranking. Justin Sybrandt, Micheal Shtutman, Ilya Safro, 2018 IEEE International Conference on Big Data (Big Data). Justin Sybrandt, Micheal Shtutman, and Ilya Safro. Large-scale validation of hypothesis generation systems via candidate ranking. In 2018 IEEE International Conference on Big Data (Big Data), pages 1494-1503, 2018.</p>
<p>Global scientific output doubles every nine years. Richard Van Noorden, Nature news blog. Richard Van Noorden. Global scientific output doubles every nine years. Nature news blog, 2014.</p>
<p>Attention is all you need. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, Illia Polosukhin, Advances in neural information processing systems. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention is all you need. In Advances in neural information processing systems, pages 5998-6008, 2017.</p>
<p>Text-based discovery in biomedicine: the architecture of the dad-system. Marc Weeber, Henny Klein, Alan R Aronson, James G Mork, Lt De Jong-Van Den, Rein Berg, Vos, Proceedings of the AMIA Symposium, page 903. American Medical Informatics Association. the AMIA Symposium, page 903. American Medical Informatics AssociationMarc Weeber, Henny Klein, Alan R Aronson, James G Mork, LT De Jong-van Den Berg, and Rein Vos. Text-based discovery in biomedicine: the architecture of the dad-system. In Proceedings of the AMIA Symposium, page 903. American Medical Informatics Association, 2000.</p>
<p>Automated literature mining and hypothesis generation through a network of medical subject headings. Stephen Wilson, Angela Dawn Wilkins, V Matthew, Holt, Byung Kwon, Daniel Choi, Chih-Hsu Konecki, Amanda Lin, Yue Koire, Seon-Young Chen, Yi Kim, Wang, BioRxiv. 403667Stephen Wilson, Angela Dawn Wilkins, Matthew V Holt, Byung Kwon Choi, Daniel Konecki, Chih-Hsu Lin, Amanda Koire, Yue Chen, Seon-Young Kim, Yi Wang, et al. Automated literature mining and hypothesis generation through a network of medical subject headings. BioRxiv, page 403667, 2018.</p>
<p>Evaluation of literature-based discovery systems. - Meliha Yetisgen, Wanda Yildiz, Pratt, Literature-based discovery. SpringerMeliha Yetisgen-Yildiz and Wanda Pratt. Evaluation of literature-based discovery systems. In Literature-based discovery, pages 101-113. Springer, 2008.</p>
<p>Yang You, Jing Li, Sashank Reddi, Jonathan Hseu, Sanjiv Kumar, Srinadh Bhojanapalli, Xiaodan Song, James Demmel, Cho-Jui Hsieh, arXiv:1904.00962Large batch optimization for deep learning: Training bert in 76 minutes. 1arXiv preprintYang You, Jing Li, Sashank Reddi, Jonathan Hseu, Sanjiv Kumar, Srinadh Bhojanapalli, Xiaodan Song, James Demmel, and Cho-Jui Hsieh. Large batch optimization for deep learning: Training bert in 76 minutes. arXiv preprint arXiv:1904.00962, 1(5), 2019.</p>            </div>
        </div>

    </div>
</body>
</html>