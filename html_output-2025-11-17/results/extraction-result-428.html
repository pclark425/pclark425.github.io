<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-428 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-428</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-428</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-17.html">extraction-schema-17</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <p><strong>Paper ID:</strong> paper-269772868</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2405.09521v3.pdf" target="_blank">Declarative Design of Neural Predicates in Neuro-Symbolic Systems</a></p>
                <p><strong>Paper Abstract:</strong> Neuro-symbolic systems (NeSy), which claim to combine the best of both learning and reasoning capabilities of artificial intelligence, are missing a core property of reasoning systems: Declarativeness. The lack of declarativeness is caused by the functional nature of neural predicates inherited from neural networks. We propose and implement a general framework for fully declarative neural predicates, which hence extends to fully declarative NeSy frameworks. We first show that the declarative extension preserves the learning and reasoning capabilities while being able to answer arbitrary queries while only being trained on a single query type.</p>
                <p><strong>Cost:</strong> 0.015</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e428.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e428.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DeclDeepProblog</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Declarative DeepProblog (prototype-based neural predicates)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A neuro-symbolic extension of DeepProblog that makes neural predicates declarative by structuring them around learned prototypes (mixture components in a latent space) and adding sampling/decoding relations so that variables standing for non-symbolic arguments can be unified by sampling from prototypes.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Declarative DeepProblog (DeclDeepProblog)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>An extension of DeepProblog where neural predicates are redesigned as prototype-based probabilistic relations: each symbolic class is associated with a learned prototype (a Gaussian in latent space) and encoder/decoder networks map between raw inputs (images) and prototype latent codes. Prototype membership is encoded as annotated disjunctions (mixture components) so the Problog inference machinery can (1) compute likelihoods of (image, label) pairs, (2) infer labels given images, and (3) generate images for a label or for variables by sampling from prototypes and decoding. The approach preserves DeepProblog's inference engine without internal changes by changing the semantics of neural predicates to be relational (prototype match/3, encode/3, decode/3) rather than purely functional.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Probabilistic logic programming using (Deep)Problog / Problog clauses and annotated disjunctions; facts and rules are standard Problog/Prolog style with probabilistic facts represented as annotated disjunctions.</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Neural encoder and decoder networks (implemented as a variational autoencoder in the paper) and prototype parameter tables (Gaussian means and variances). The encoder q(z|X) and decoder p(X|z) are deep neural networks; prototypes are multivariate Gaussian priors p(z|d).</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Modular integration inside DeepProblog: neural components provide probabilistic facts via neural annotated disjunctions (nADs) reinterpreted as prototype mixture likelihoods; relational predicates prototype_match/3, encode/3, decode/3 connect symbolic variables and non-symbolic data. Training uses VAE-style variational objectives (reconstruction loss + KL between prototype priors and encoder posteriors) while inference reuses DeepProblog's resolution and probabilistic summation; unification over continuous domains is handled by sampling from prototypes and decoding to instantiate variables during resolution.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Regains declarativeness: the system can answer arbitrary queries involving neural predicates (e.g., classify image->digit, produce image for a digit, generate all groundings, and answer complex composed queries involving variables in any argument position). Enables generative queries without retraining (sampling from prototypes allows generation/inpainting), separation of knowledge base and inference (knowledge can be changed without retraining networks), and compositional reasoning across neural predicates (e.g., multi-digit addition with some variables).</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>MNIST digit classification and MNIST addition tasks (single-digit classification digit/2, addition add/3, and multi-digit addition generalization queries).</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td>Direct supervision (digit/2): 98.4% classification accuracy; Distant supervision (add/3): 94.2% classification accuracy; Generative/unseen queries: digit/2 generative accuracy 88.1%; add/3 generative accuracy 81.5%; multi-digit addition (4-digit composed queries) generative accuracy 62.2%. (Metrics: accuracy, percent).</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Shows improved generalization in the sense of answering query types not seen at training: a model trained on conditional classification queries can answer generative queries (produce images for labels) and complex composed queries (multi-digit addition with variables). Performance on unseen compositional queries degrades (error accumulation across digits), but the system typically selects the correct prototype even when generated samples visually resemble another digit.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Maintains symbolic interpretability from the logic layer (rules and proofs are available via Problog resolution); prototypes provide an explicit, inspectable latent representation per class (Gaussian means/variances) that can be decoded to visualize canonical instances, offering an interpretable bridge between symbols and sensory data. The probabilistic semantics (p(X,d)=p(X|z)p(z|d)p(d)) gives interpretable likelihoods.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Scalability concerns: training iterations take ~2x longer; distant supervision (weak labels) is harder because multiple prototype assignments may explain a label (ambiguity); prototypes sometimes generate images that look more like another class, reducing generative accuracy; assumes a fixed number of prototypes (user-specified) and exclusive assignment to prototypes; sampling from continuous infinite domains is limited by returning a single sample per variable during unification.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>A probabilistic generative model: joint p(X,d)=∫ p(X|z)p(z|d)p(d) dz with p(z|d) modeled as Gaussians (prototypes) and p(X|z) as a neural decoder; variational posterior q(z|X) (encoder) approximates inference. The paper provides semantics mapping these distributions into DeepProblog's probabilistic facts and shows how VAE-style lower bounds and likelihood approximations enable the required inference queries.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Declarative Design of Neural Predicates in Neuro-Symbolic Systems', 'publication_date_yy_mm': '2024-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e428.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e428.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DeepProblog</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>DeepProblog (neural probabilistic logic programming)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A hybrid neuro-symbolic system that embeds neural networks as neural predicates inside the ProbLog probabilistic logic programming framework, where neural predicates provide conditional label probabilities used in logical-probabilistic inference.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Deepproblog: Neural probabilistic logic programming.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>DeepProblog</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>ProbLog-based probabilistic logic programming augmented with neural predicates (neural annotated disjunctions, nADs). Neural networks act as discriminative functions that map non-symbolic inputs (e.g., images) to label distributions; these outputs are injected as probabilities into the logic program enabling joint probabilistic inference over symbolic structure and perceptual inputs.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>ProbLog (probabilistic logic programming) clauses, annotated disjunctions, and logical rules providing symbolic reasoning and probabilistic inference.</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Neural classifiers (discriminative neural networks) used as functional neural predicates producing conditional label probabilities p(label|input).</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Neural networks produce probabilistic facts via neural annotated disjunctions (nADs) which are consumed by the Problog inference engine; training typically optimizes neural components (via gradient descent) with the logic layer providing supervision/constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Combines perception (neural) with symbolic probabilistic reasoning enabling tasks like reasoning over noisy perceptual inputs, learning from structured supervision, and probabilistic relational inference; however, neural predicates are functional so the system cannot generatively instantiate non-symbolic variables or answer arbitrary queries requiring inverted mappings without retraining.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>MNIST digit classification and MNIST addition tasks (as used in comparisons in this paper).</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td>Reported in this paper on baseline tasks: digit/2 classification accuracy 98.7%; add/3 classification accuracy 95.6% (percent).</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Effective at conditional tasks mapping inputs to labels; limited declarativeness — cannot generally answer queries that require generating inputs from labels or unifying variables in non-symbolic argument positions without specialized generative training.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Symbolic logic layer provides explainable reasoning traces; neural predicates themselves are functional and less interpretable, though their outputs are explicit probabilities.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Neural predicates are functional discriminators (p(label|input)) and thus break unification in logic resolution when variables appear in non-symbolic positions; lacks generative/declarative capabilities for arbitrary queries involving non-symbolic domains.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Probabilistic logical semantics via Problog: facts as independent Bernoulli variables and possible-world semantics where neural predicates supply conditional probabilities; no explicit generative latent-prototype semantics by default.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Declarative Design of Neural Predicates in Neuro-Symbolic Systems', 'publication_date_yy_mm': '2024-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e428.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e428.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SLASH</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>SLASH</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A recent neuro-symbolic system demonstrating generative capabilities by combining neural modules with symbolic reasoning, but in a functional design that requires explicit training for each generative task and does not achieve full declarativeness.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>SLASH</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A neuro-symbolic integration that enables some generative tasks by combining neural components and symbolic constraints; referenced as demonstrating the ability to answer queries requiring image generation but remaining inherently functional (task-specific training required).</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Symbolic reasoning / programmatic constraints (as described in cited work), likely logic-based rules that interact with neural outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Neural generative or discriminative components (details not specified in this paper).</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Modular combination where neural modules produce artifacts used by symbolic reasoning; cited as not being declarative because it must be trained on the specific generative task.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Can perform some generative tasks (image generation for constrained queries) when explicitly trained for them, but lacks the universal query-answering declarativeness the present paper targets.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Generative queries involving images (reference in related work).</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Limited: requires explicit training per generative task and cannot answer arbitrary unseen query types without retraining.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Not detailed in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Inherently functional design — cannot answer arbitrary queries and must be trained for specific generative tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Not detailed in this paper; treated as related work illustrating functional (non-declarative) neuro-symbolic designs.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Declarative Design of Neural Predicates in Neuro-Symbolic Systems', 'publication_date_yy_mm': '2024-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e428.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e428.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>VAEL</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>VAEL</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A neuro-symbolic extension demonstrating generative abilities (cited as related work) but retaining a functional design requiring task-specific training, therefore not achieving full declarativeness.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>VAEL</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Referenced as a DeepProblog extension that can achieve generative capabilities (e.g., image generation) but does not provide declarativeness: it remains functional and requires explicit training for particular generative tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Problog-style symbolic logic (as part of DeepProblog ecosystem) referenced, but specifics not provided here.</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Neural generative models (details not provided in this paper).</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Functional integration of neural generative models with symbolic reasoning; task-specific training required.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Enables some generative tasks but lacks universal, query-agnostic declarativeness.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Generative image queries (related work context).</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Limited generalization to unseen query types without retraining.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Not described in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Functional design; not declarative.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Declarative Design of Neural Predicates in Neuro-Symbolic Systems', 'publication_date_yy_mm': '2024-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e428.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e428.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DeepSeaProblog</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>DeepSeaProblog</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An extension of DeepProblog that supports continuous distributions and provides language features useful for modeling declarative neural predicates (e.g., auto-encoding components), but which does not itself address full declarativeness of neural predicates.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>DeepSeaProblog</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>DeepProblog variant that adds support for continuous distributions and provides constructs suitable for modeling generative/autoencoding behaviors inside a probabilistic logic programming setting; contains demonstrations similar to encoder-decoder structures but stops short of turning neural predicates into fully declarative relations.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Problog-like probabilistic logic programming with extensions for continuous distributions.</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Neural generative components (used for autoencoding/density modeling).</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Extends DeepProblog semantics to handle continuous latent variables and decoding, enabling tighter integration of generative networks with Problog probabilistic facts; however, does not propose prototype-based relational semantics for neural predicates.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Enables modeling of continuous latent generative processes within the probabilistic logic framework, facilitating some generation tasks inside logic programs.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Demonstrations involving continuous generative models (cited in related work).</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Provides tools for generative modeling in logic programs but not shown to enable full declarative query generalization.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Not the focus; primarily provides modeling flexibility for continuous distributions.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Does not establish a basis for turning arbitrary neural predicates into declarative relations; remains limited relative to the prototype-based approach proposed in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Declarative Design of Neural Predicates in Neuro-Symbolic Systems', 'publication_date_yy_mm': '2024-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e428.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e428.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DeepStochlog</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>DeepStochlog</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A neuro-symbolic system (cited in experiments and related work) combining stochastic logic programming with neural perception modules, used as a comparative reference for MNIST-based tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>DeepStochlog</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A system that integrates stochastic logic programming with neural networks to address perception + reasoning tasks (e.g., MNIST addition), mentioned as part of the experimental lineage for the tasks used in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Stochastic logic programming (a probabilistic logic programming formalism).</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Neural perception modules for image-to-label mappings.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Neural outputs feed into stochastic logic program probabilities; specifics not detailed in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Enables combining perception and probabilistic logical reasoning for tasks like digit addition.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>MNIST addition tasks (contextual mention).</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Not described here.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Not detailed in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Not discussed here; cited for context.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Declarative Design of Neural Predicates in Neuro-Symbolic Systems', 'publication_date_yy_mm': '2024-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e428.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e428.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Scallop / NeurASP / LTNs / NeuPSL</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Scallop, NeurASP, Logic Tensor Networks (LTN), NeuPSL (mentioned group)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A set of representative neuro-symbolic or differentiable reasoning systems cited in related work: Scallop (scalable differentiable reasoning over probabilistic deductive DBs), NeurASP (neural + ASP), Logic Tensor Networks (differentiable logical constraints), and NeuPSL — each mixes symbolic and neural components but none are described here as fully declarative with prototype-based neural predicates.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Various neuro-symbolic systems (Scallop, NeurASP, Logic Tensor Networks, NeuPSL)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Related neuro-symbolic systems that integrate symbolic reasoning (probabilistic deductive databases, answer set programming, differentiable logical frameworks) with neural components for perception or differentiable constraint enforcement; cited to position the present work within the broader field.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Varies per system: probabilistic deductive databases (Scallop), Answer Set Programming (NeurASP), logical constraints/tensorized logic (LTN), probabilistic logic DSLs (NeuPSL).</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Neural networks used for perception, constraints, or differentiable components (varies by system).</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Differentiable reasoning, modular integration, or embedding neural outputs as probabilistic facts; specifics are system-dependent and not detailed in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Each system aims to combine symbolic and subsymbolic strengths (structured reasoning + learning), but none are claimed here to solve the declarativeness problem addressed by prototype-based neural predicates.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Various (not specified in this paper).</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Not described in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Symbolic components generally support interpretability; specifics not given here.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Not discussed in detail in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Declarative Design of Neural Predicates in Neuro-Symbolic Systems', 'publication_date_yy_mm': '2024-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Deepproblog: Neural probabilistic logic programming. <em>(Rating: 2)</em></li>
                <li>SLASH <em>(Rating: 2)</em></li>
                <li>VAEL <em>(Rating: 2)</em></li>
                <li>DeepSeaProblog <em>(Rating: 2)</em></li>
                <li>DeepStochlog <em>(Rating: 2)</em></li>
                <li>Scallop: From probabilistic deductive databases to scalable differentiable reasoning. <em>(Rating: 1)</em></li>
                <li>NeurASP <em>(Rating: 1)</em></li>
                <li>Logic tensor networks <em>(Rating: 1)</em></li>
                <li>NeuPSL <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-428",
    "paper_id": "paper-269772868",
    "extraction_schema_id": "extraction-schema-17",
    "extracted_data": [
        {
            "name_short": "DeclDeepProblog",
            "name_full": "Declarative DeepProblog (prototype-based neural predicates)",
            "brief_description": "A neuro-symbolic extension of DeepProblog that makes neural predicates declarative by structuring them around learned prototypes (mixture components in a latent space) and adding sampling/decoding relations so that variables standing for non-symbolic arguments can be unified by sampling from prototypes.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Declarative DeepProblog (DeclDeepProblog)",
            "system_description": "An extension of DeepProblog where neural predicates are redesigned as prototype-based probabilistic relations: each symbolic class is associated with a learned prototype (a Gaussian in latent space) and encoder/decoder networks map between raw inputs (images) and prototype latent codes. Prototype membership is encoded as annotated disjunctions (mixture components) so the Problog inference machinery can (1) compute likelihoods of (image, label) pairs, (2) infer labels given images, and (3) generate images for a label or for variables by sampling from prototypes and decoding. The approach preserves DeepProblog's inference engine without internal changes by changing the semantics of neural predicates to be relational (prototype match/3, encode/3, decode/3) rather than purely functional.",
            "declarative_component": "Probabilistic logic programming using (Deep)Problog / Problog clauses and annotated disjunctions; facts and rules are standard Problog/Prolog style with probabilistic facts represented as annotated disjunctions.",
            "imperative_component": "Neural encoder and decoder networks (implemented as a variational autoencoder in the paper) and prototype parameter tables (Gaussian means and variances). The encoder q(z|X) and decoder p(X|z) are deep neural networks; prototypes are multivariate Gaussian priors p(z|d).",
            "integration_method": "Modular integration inside DeepProblog: neural components provide probabilistic facts via neural annotated disjunctions (nADs) reinterpreted as prototype mixture likelihoods; relational predicates prototype_match/3, encode/3, decode/3 connect symbolic variables and non-symbolic data. Training uses VAE-style variational objectives (reconstruction loss + KL between prototype priors and encoder posteriors) while inference reuses DeepProblog's resolution and probabilistic summation; unification over continuous domains is handled by sampling from prototypes and decoding to instantiate variables during resolution.",
            "emergent_properties": "Regains declarativeness: the system can answer arbitrary queries involving neural predicates (e.g., classify image-&gt;digit, produce image for a digit, generate all groundings, and answer complex composed queries involving variables in any argument position). Enables generative queries without retraining (sampling from prototypes allows generation/inpainting), separation of knowledge base and inference (knowledge can be changed without retraining networks), and compositional reasoning across neural predicates (e.g., multi-digit addition with some variables).",
            "task_or_benchmark": "MNIST digit classification and MNIST addition tasks (single-digit classification digit/2, addition add/3, and multi-digit addition generalization queries).",
            "hybrid_performance": "Direct supervision (digit/2): 98.4% classification accuracy; Distant supervision (add/3): 94.2% classification accuracy; Generative/unseen queries: digit/2 generative accuracy 88.1%; add/3 generative accuracy 81.5%; multi-digit addition (4-digit composed queries) generative accuracy 62.2%. (Metrics: accuracy, percent).",
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": true,
            "generalization_properties": "Shows improved generalization in the sense of answering query types not seen at training: a model trained on conditional classification queries can answer generative queries (produce images for labels) and complex composed queries (multi-digit addition with variables). Performance on unseen compositional queries degrades (error accumulation across digits), but the system typically selects the correct prototype even when generated samples visually resemble another digit.",
            "interpretability_properties": "Maintains symbolic interpretability from the logic layer (rules and proofs are available via Problog resolution); prototypes provide an explicit, inspectable latent representation per class (Gaussian means/variances) that can be decoded to visualize canonical instances, offering an interpretable bridge between symbols and sensory data. The probabilistic semantics (p(X,d)=p(X|z)p(z|d)p(d)) gives interpretable likelihoods.",
            "limitations_or_failures": "Scalability concerns: training iterations take ~2x longer; distant supervision (weak labels) is harder because multiple prototype assignments may explain a label (ambiguity); prototypes sometimes generate images that look more like another class, reducing generative accuracy; assumes a fixed number of prototypes (user-specified) and exclusive assignment to prototypes; sampling from continuous infinite domains is limited by returning a single sample per variable during unification.",
            "theoretical_framework": "A probabilistic generative model: joint p(X,d)=∫ p(X|z)p(z|d)p(d) dz with p(z|d) modeled as Gaussians (prototypes) and p(X|z) as a neural decoder; variational posterior q(z|X) (encoder) approximates inference. The paper provides semantics mapping these distributions into DeepProblog's probabilistic facts and shows how VAE-style lower bounds and likelihood approximations enable the required inference queries.",
            "uuid": "e428.0",
            "source_info": {
                "paper_title": "Declarative Design of Neural Predicates in Neuro-Symbolic Systems",
                "publication_date_yy_mm": "2024-05"
            }
        },
        {
            "name_short": "DeepProblog",
            "name_full": "DeepProblog (neural probabilistic logic programming)",
            "brief_description": "A hybrid neuro-symbolic system that embeds neural networks as neural predicates inside the ProbLog probabilistic logic programming framework, where neural predicates provide conditional label probabilities used in logical-probabilistic inference.",
            "citation_title": "Deepproblog: Neural probabilistic logic programming.",
            "mention_or_use": "use",
            "system_name": "DeepProblog",
            "system_description": "ProbLog-based probabilistic logic programming augmented with neural predicates (neural annotated disjunctions, nADs). Neural networks act as discriminative functions that map non-symbolic inputs (e.g., images) to label distributions; these outputs are injected as probabilities into the logic program enabling joint probabilistic inference over symbolic structure and perceptual inputs.",
            "declarative_component": "ProbLog (probabilistic logic programming) clauses, annotated disjunctions, and logical rules providing symbolic reasoning and probabilistic inference.",
            "imperative_component": "Neural classifiers (discriminative neural networks) used as functional neural predicates producing conditional label probabilities p(label|input).",
            "integration_method": "Neural networks produce probabilistic facts via neural annotated disjunctions (nADs) which are consumed by the Problog inference engine; training typically optimizes neural components (via gradient descent) with the logic layer providing supervision/constraints.",
            "emergent_properties": "Combines perception (neural) with symbolic probabilistic reasoning enabling tasks like reasoning over noisy perceptual inputs, learning from structured supervision, and probabilistic relational inference; however, neural predicates are functional so the system cannot generatively instantiate non-symbolic variables or answer arbitrary queries requiring inverted mappings without retraining.",
            "task_or_benchmark": "MNIST digit classification and MNIST addition tasks (as used in comparisons in this paper).",
            "hybrid_performance": "Reported in this paper on baseline tasks: digit/2 classification accuracy 98.7%; add/3 classification accuracy 95.6% (percent).",
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": true,
            "generalization_properties": "Effective at conditional tasks mapping inputs to labels; limited declarativeness — cannot generally answer queries that require generating inputs from labels or unifying variables in non-symbolic argument positions without specialized generative training.",
            "interpretability_properties": "Symbolic logic layer provides explainable reasoning traces; neural predicates themselves are functional and less interpretable, though their outputs are explicit probabilities.",
            "limitations_or_failures": "Neural predicates are functional discriminators (p(label|input)) and thus break unification in logic resolution when variables appear in non-symbolic positions; lacks generative/declarative capabilities for arbitrary queries involving non-symbolic domains.",
            "theoretical_framework": "Probabilistic logical semantics via Problog: facts as independent Bernoulli variables and possible-world semantics where neural predicates supply conditional probabilities; no explicit generative latent-prototype semantics by default.",
            "uuid": "e428.1",
            "source_info": {
                "paper_title": "Declarative Design of Neural Predicates in Neuro-Symbolic Systems",
                "publication_date_yy_mm": "2024-05"
            }
        },
        {
            "name_short": "SLASH",
            "name_full": "SLASH",
            "brief_description": "A recent neuro-symbolic system demonstrating generative capabilities by combining neural modules with symbolic reasoning, but in a functional design that requires explicit training for each generative task and does not achieve full declarativeness.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "SLASH",
            "system_description": "A neuro-symbolic integration that enables some generative tasks by combining neural components and symbolic constraints; referenced as demonstrating the ability to answer queries requiring image generation but remaining inherently functional (task-specific training required).",
            "declarative_component": "Symbolic reasoning / programmatic constraints (as described in cited work), likely logic-based rules that interact with neural outputs.",
            "imperative_component": "Neural generative or discriminative components (details not specified in this paper).",
            "integration_method": "Modular combination where neural modules produce artifacts used by symbolic reasoning; cited as not being declarative because it must be trained on the specific generative task.",
            "emergent_properties": "Can perform some generative tasks (image generation for constrained queries) when explicitly trained for them, but lacks the universal query-answering declarativeness the present paper targets.",
            "task_or_benchmark": "Generative queries involving images (reference in related work).",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Limited: requires explicit training per generative task and cannot answer arbitrary unseen query types without retraining.",
            "interpretability_properties": "Not detailed in this paper.",
            "limitations_or_failures": "Inherently functional design — cannot answer arbitrary queries and must be trained for specific generative tasks.",
            "theoretical_framework": "Not detailed in this paper; treated as related work illustrating functional (non-declarative) neuro-symbolic designs.",
            "uuid": "e428.2",
            "source_info": {
                "paper_title": "Declarative Design of Neural Predicates in Neuro-Symbolic Systems",
                "publication_date_yy_mm": "2024-05"
            }
        },
        {
            "name_short": "VAEL",
            "name_full": "VAEL",
            "brief_description": "A neuro-symbolic extension demonstrating generative abilities (cited as related work) but retaining a functional design requiring task-specific training, therefore not achieving full declarativeness.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "VAEL",
            "system_description": "Referenced as a DeepProblog extension that can achieve generative capabilities (e.g., image generation) but does not provide declarativeness: it remains functional and requires explicit training for particular generative tasks.",
            "declarative_component": "Problog-style symbolic logic (as part of DeepProblog ecosystem) referenced, but specifics not provided here.",
            "imperative_component": "Neural generative models (details not provided in this paper).",
            "integration_method": "Functional integration of neural generative models with symbolic reasoning; task-specific training required.",
            "emergent_properties": "Enables some generative tasks but lacks universal, query-agnostic declarativeness.",
            "task_or_benchmark": "Generative image queries (related work context).",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Limited generalization to unseen query types without retraining.",
            "interpretability_properties": "Not described in this paper.",
            "limitations_or_failures": "Functional design; not declarative.",
            "theoretical_framework": "",
            "uuid": "e428.3",
            "source_info": {
                "paper_title": "Declarative Design of Neural Predicates in Neuro-Symbolic Systems",
                "publication_date_yy_mm": "2024-05"
            }
        },
        {
            "name_short": "DeepSeaProblog",
            "name_full": "DeepSeaProblog",
            "brief_description": "An extension of DeepProblog that supports continuous distributions and provides language features useful for modeling declarative neural predicates (e.g., auto-encoding components), but which does not itself address full declarativeness of neural predicates.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "DeepSeaProblog",
            "system_description": "DeepProblog variant that adds support for continuous distributions and provides constructs suitable for modeling generative/autoencoding behaviors inside a probabilistic logic programming setting; contains demonstrations similar to encoder-decoder structures but stops short of turning neural predicates into fully declarative relations.",
            "declarative_component": "Problog-like probabilistic logic programming with extensions for continuous distributions.",
            "imperative_component": "Neural generative components (used for autoencoding/density modeling).",
            "integration_method": "Extends DeepProblog semantics to handle continuous latent variables and decoding, enabling tighter integration of generative networks with Problog probabilistic facts; however, does not propose prototype-based relational semantics for neural predicates.",
            "emergent_properties": "Enables modeling of continuous latent generative processes within the probabilistic logic framework, facilitating some generation tasks inside logic programs.",
            "task_or_benchmark": "Demonstrations involving continuous generative models (cited in related work).",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Provides tools for generative modeling in logic programs but not shown to enable full declarative query generalization.",
            "interpretability_properties": "Not the focus; primarily provides modeling flexibility for continuous distributions.",
            "limitations_or_failures": "Does not establish a basis for turning arbitrary neural predicates into declarative relations; remains limited relative to the prototype-based approach proposed in this paper.",
            "theoretical_framework": "",
            "uuid": "e428.4",
            "source_info": {
                "paper_title": "Declarative Design of Neural Predicates in Neuro-Symbolic Systems",
                "publication_date_yy_mm": "2024-05"
            }
        },
        {
            "name_short": "DeepStochlog",
            "name_full": "DeepStochlog",
            "brief_description": "A neuro-symbolic system (cited in experiments and related work) combining stochastic logic programming with neural perception modules, used as a comparative reference for MNIST-based tasks.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "DeepStochlog",
            "system_description": "A system that integrates stochastic logic programming with neural networks to address perception + reasoning tasks (e.g., MNIST addition), mentioned as part of the experimental lineage for the tasks used in the paper.",
            "declarative_component": "Stochastic logic programming (a probabilistic logic programming formalism).",
            "imperative_component": "Neural perception modules for image-to-label mappings.",
            "integration_method": "Neural outputs feed into stochastic logic program probabilities; specifics not detailed in this paper.",
            "emergent_properties": "Enables combining perception and probabilistic logical reasoning for tasks like digit addition.",
            "task_or_benchmark": "MNIST addition tasks (contextual mention).",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Not described here.",
            "interpretability_properties": "Not detailed in this paper.",
            "limitations_or_failures": "Not discussed here; cited for context.",
            "uuid": "e428.5",
            "source_info": {
                "paper_title": "Declarative Design of Neural Predicates in Neuro-Symbolic Systems",
                "publication_date_yy_mm": "2024-05"
            }
        },
        {
            "name_short": "Scallop / NeurASP / LTNs / NeuPSL",
            "name_full": "Scallop, NeurASP, Logic Tensor Networks (LTN), NeuPSL (mentioned group)",
            "brief_description": "A set of representative neuro-symbolic or differentiable reasoning systems cited in related work: Scallop (scalable differentiable reasoning over probabilistic deductive DBs), NeurASP (neural + ASP), Logic Tensor Networks (differentiable logical constraints), and NeuPSL — each mixes symbolic and neural components but none are described here as fully declarative with prototype-based neural predicates.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "Various neuro-symbolic systems (Scallop, NeurASP, Logic Tensor Networks, NeuPSL)",
            "system_description": "Related neuro-symbolic systems that integrate symbolic reasoning (probabilistic deductive databases, answer set programming, differentiable logical frameworks) with neural components for perception or differentiable constraint enforcement; cited to position the present work within the broader field.",
            "declarative_component": "Varies per system: probabilistic deductive databases (Scallop), Answer Set Programming (NeurASP), logical constraints/tensorized logic (LTN), probabilistic logic DSLs (NeuPSL).",
            "imperative_component": "Neural networks used for perception, constraints, or differentiable components (varies by system).",
            "integration_method": "Differentiable reasoning, modular integration, or embedding neural outputs as probabilistic facts; specifics are system-dependent and not detailed in this paper.",
            "emergent_properties": "Each system aims to combine symbolic and subsymbolic strengths (structured reasoning + learning), but none are claimed here to solve the declarativeness problem addressed by prototype-based neural predicates.",
            "task_or_benchmark": "Various (not specified in this paper).",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Not described in this paper.",
            "interpretability_properties": "Symbolic components generally support interpretability; specifics not given here.",
            "limitations_or_failures": "Not discussed in detail in this paper.",
            "uuid": "e428.6",
            "source_info": {
                "paper_title": "Declarative Design of Neural Predicates in Neuro-Symbolic Systems",
                "publication_date_yy_mm": "2024-05"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Deepproblog: Neural probabilistic logic programming.",
            "rating": 2,
            "sanitized_title": "deepproblog_neural_probabilistic_logic_programming"
        },
        {
            "paper_title": "SLASH",
            "rating": 2
        },
        {
            "paper_title": "VAEL",
            "rating": 2
        },
        {
            "paper_title": "DeepSeaProblog",
            "rating": 2,
            "sanitized_title": "deepseaproblog"
        },
        {
            "paper_title": "DeepStochlog",
            "rating": 2,
            "sanitized_title": "deepstochlog"
        },
        {
            "paper_title": "Scallop: From probabilistic deductive databases to scalable differentiable reasoning.",
            "rating": 1,
            "sanitized_title": "scallop_from_probabilistic_deductive_databases_to_scalable_differentiable_reasoning"
        },
        {
            "paper_title": "NeurASP",
            "rating": 1
        },
        {
            "paper_title": "Logic tensor networks",
            "rating": 1,
            "sanitized_title": "logic_tensor_networks"
        },
        {
            "paper_title": "NeuPSL",
            "rating": 1
        }
    ],
    "cost": 0.014932999999999998,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Declarative Design of Neural Predicates in Neuro-Symbolic Systems
30 Jan 2025</p>
<p>Tilman Hinnerichs t.r.hinnerichs@tudelft.nl 
Robin Manhaeve robin.manhaeve@cs.kuleuven.be 
Giuseppe Marra giuseppe.marra@cs.kuleuven.be 
Sebastijan Dumančić s.dumancic@tudelft.nl 
T U Delft 
K U Leuven 
Declarative Design of Neural Predicates in Neuro-Symbolic Systems
30 Jan 202555873297487B1A30BF63196876DE58D9arXiv:2405.09521v3[cs.AI]
Neuro-symbolic systems (NeSy), which claim to combine the best of both learning and reasoning capabilities of artificial intelligence, are missing a core property of reasoning systems: Declarativeness.The lack of declarativeness is caused by the functional nature of neural predicates inherited from neural networks.We propose and implement a general framework for fully declarative neural predicates, which hence extends to fully declarative NeSy frameworks.We first show that the declarative extension preserves the learning and reasoning capabilities while being able to answer arbitrary queries while only being trained on a single query type.</p>
<p>Introduction</p>
<p>The existing neuro-symbolic systems [Marra et al., 2024;Hitzler et al., 2022], which aim to unify the learning and reasoning capabilities of artificial intelligence (AI), lack one of the fundamental properties of reasoning systems -their declarativeness.Declarativeness is the property that makes reasoning systems universal question-answering engines.That is, reasoning systems are procedures for computing answers to arbitrary queries over arbitrary knowledge bases where both are specified in a formal language.For instance, logical reasoning systems, such as Prolog [Sterling and Shapiro, 1986] and Answer Set Programming [Lifschitz, 2019], can answer arbitrary queries over a given knowledge graph (Who is a daughter of Lord Byron?, Who is the father of Ada Lovelace?, and even aggregate queries such as How many presidents did USA have in the past 100 years?).Similarly, probabilistic inference procedures can provide posteriors of arbitrary combinations of variables and evidence in a given Bayesian Network.</p>
<p>The capabilities of neuro-symbolic systems would significantly increase if they become declarative.Most existing neuro-symbolic methods focus on problems that require reasoning about visual input; they use neural models to extract symbols from images and symbolic reasoning to reason about the content of the images.If they become declarative, the same neuro-symbolic model could reason about the content of images but also inpaint an image while remaining logically consistent, create an image based on the logical description, provide a logical description of an image, and complete a partial logical description of an image, without a specialized model for each of these tasks.Moreover, as the knowledge base is separated from the inference procedure, the knowledge base can be modified without compromising the capabilities of an AI agent.That means that new symbolic knowledge about the images can be added without having to do any retraining.</p>
<p>The existing state-of-the-art systems, such as Deep-Problog [Manhaeve et al., 2018] and SLASH [Skryagin et al., 2022], support declarativeness to a large extent.However, the declarativity breaks down with neural predicates, the key abstraction of neuro-symbolic systems, which essentially evaluate the truthfulness of facts with neural networks.For instance, a classic DeepProblog example uses neural predicates to map MNIST images to corresponding digits, digit ( ,3).DeepProblog can answer any query that requires computation involving mapping a given image to a digit.If a query requires mapping a given digit to an image, DeepProblog would not be able to answer such a query (while it would not struggle to answer such a query if the predicate in question is a logical predicate).Recent DeepProblog extensions, VAEL [Misino et al., 2022], SLASH [Skryagin et al., 2022], andDeepSeaProblog [De Smet et al., 2023], show that such generative capabilities can be achieved, but without declarativeness.</p>
<p>The lack of declarativeness is caused by the functional nature of neural networks integrated into reasoning frameworks.First, neural networks are functions, not relations, with clearly defined inputs and outputs that cannot be exchanged.Reasoning systems are instead based on relations, where arguments can take arbitrary roles of inputs and outputs.Second, neural networks are discriminators, meaning that they learn a conditional distribution of labels given features but do not model properties of the feature space.Even the generative architectures, such as variational auto-encoder [Kingma and Welling, 2019] and diffusion models [Yang et al., 2024], operate as functions, generating, e.g., images from noise or latent representations, despite not performing a classification task.For instance, a perfect MNIST digit classified does not model a particular digit's distribution of valid images.</p>
<p>The main consequence of this is that neural predicates addition(Im1,Im2,Z) :-digit(Im1,X2), digit(Im2,Y2), Z is X2+Y2.nn(mnist_net,[X],Y,[0,..,9])::digit(X,Y).In this paper, we introduce a general framework for designing declarative neural predicates.In essence, our two contributions focus on enabling unification to operate over infinite domains that are difficult to characterize precisely, such as sensory input in the form of images or sounds.First, the central idea behind our approach is to design neural predicates around prototypes and prototype networks [Xu et al., 2020].Designing neural predicates around prototypes forces them to learn concepts instead of mapping from sensory input to labels, avoiding the issues with unification.Second, we demonstrate how a relational interpretation of the encodingdecoding scheme, relating instances to their prototypes, resolves the relations-vs-functions dichotomy.Because prototypes effectively learn a domain, any argument of the corresponding predicate can be sampled from the prototype and thus unified with a variable.We design the declarative neural predicates in such a way that our proposed framework does not require new special machinery, but it reuses the inference procedures of DeepProblog.</p>
<p>We implemented our framework within DeepProblog and evaluated it on the subset of DeepProblog [Manhaeve et al., 2018] problems for which prototype interpretation makes sense.We demonstrate that our declarative neural predicates learn prototypical instances from data, achieve comparable performance to DeepProblog despite solving a more complex task, and expand DeepProblog's capabilities by answering arbitrary queries involving neural predicates.</p>
<p>Background 2.1 Declarative problem solving</p>
<p>We start by recapping the idea of declarative problem-solving for an uninitiated reader, illustrating the types of behaviour we want to recover for neuro-symbolic systems.We focus on logic programs [Sterling and Shapiro, 1986] as they are the basis for this work and DeepProblog.</p>
<p>Logic programs reason over knowledge bases, which state things we know.The knowledge bases contain facts, the logical statements we know are true.For example, they could state the relative sizes of certain animals.</p>
<p>bigger(elephant, horse).bigger(horse, donkey).bigger(donkey, dog).bigger(donkey, monkey).</p>
<p>Knowledge bases also contain rules we can use to deduce further facts.For example, the following rule allows us to combine the previously stated facts towards their relative close.</p>
<p>is_bigger(X, Y) :-bigger(X, Y). is_bigger(X, Y) :-bigger(X, Z), is_bigger(Z, Y).</p>
<p>Logic programs can answer different queries with these facts and rules in the knowledge base.</p>
<p>We can query the entire knowledge base for the facts directly.</p>
<p>For instance, whether an elephant is bigger than a horse, which would correspond to the following query ?-is bigger(elephant,horse). 1 We could also ask which animal is bigger than a dog, ?-is bigger(X,dog).2 , or which animal is smaller than a donkey, ?-is bigger(donkey,X).We could even ask for all pairs of animals such that the first one is bigger than the second one, ?-is bigger(X,Y)..These kinds of queries can be posed about any predicate in the knowledge base, not prespecified ones.The ability to do all of these is referred to as declarative behaviour.</p>
<p>An essential consequence of declarativeness is that the knowledge base can be modified freely.For instance, if we add the fact bigger(whale,elephant), a logic programming engine would immediately produce correct answers.Similarly, if we add a new predicate, for instance, swims(whale), the engine would immediately be able to answer queries involving the swims/1 predicate.</p>
<p>We want to unlock this kind of behaviour in neurosymbolic systems.</p>
<p>DeepProblog</p>
<p>We briefly summarise the basics of DeepProblog, which we use as a basis for our contributions.</p>
<p>DeepProblog extends Problog [De Raedt et al., 2007;Kimmig et al., 2011], the probabilistic extension of Prolog, enriching facts with probabilities of being true.A Problog program consists of (1) a set of ground probabilistic facts F written as p :: f for fact f with probability p of being true, and a set of clauses R.</p>
<p>Probabilistic facts and rules jointly (with their entailments) define possible worlds.The probability of a possible world w F is described by a subset of facts F ⊆ F and is defined as w F = F ∪ {f θ |R ∪ F |= f θ and f θ is ground}, where each fact f ∈ F corresponds to an independent Boolean random variable with probability p f .The probability of a world P (w F ) is defined by
P (w F ) = f ∈F p f f ∈F \F (1 − p f ) (1)
The probability of a query q is then defined by the sum of probabilities where q holds, i.e.
P (q) = F ⊆F :q∈w F P (w F ) (2)
DeepProblog [Manhaeve et al., 2018] extendProblog with neural predicates {q} which determine the probability of a probabilistic fact dynamically.This makes it possible to conveniently model probabilistic facts defined over technically infinite spaces, like images or sounds.Neural predicates are modeled using ground annotated disjunctions (nADs) of the form nn(m q , ⃗ t, ⃗ u) :: q( ⃗ t, u 1 ); ...; q( ⃗ t, u n ) :
−b 1 , ..., b m (3)
where b i are the atoms, ⃗ t = t 1 , . . ., t k is a vector of inputs of the neural network, u 1 to u n are the network's possible output values and m q is the identifier of the used network.This means that neural predicates effectively model a conditional distribution of labels given an image.</p>
<p>Prototype networks</p>
<p>Prototypes make the representation of each category or class of data explicit.Prototype networks [Snell et al., 2017] represent each possible concept using a prototype in a latent space.</p>
<p>To classify, they learn an embedding function that maps inputs to the same latent space.An input is assigned to a class by applying the embedding function and computing the distance to the class' prototype.</p>
<p>3 Related work  et al., 2023] and many others.These systems predominantly use neural predicates to process sensory data, such as images, into a symbolic interpretation suitable for reasoning.None of these systems are fully declarative.However, our contributions can be directly incorporated into any of these systems.</p>
<p>Generative capabilities in neuro-symbolic systems.Several recent systems are directly related to our work.SLASH [Skryagin et al., 2022] and VAEL [Misino et al., 2022] demonstrate the ability to answer queries requiring image generation.However, their design remains inherently functional.They must be explicitly trained to solve the particular generative task and cannot answer arbitrary queries without retraining.Vieira [Li et al., 2024] is a system for programming with (generative) language models that focuses on combining them, but any declarative properties are prescribed, not learned from data.</p>
<p>DeepSeaProblog [De Smet et al., 2023] is the work most closely related to ours.DeepSeaProblog extends Deep-Problog with support for continuous distributions.Though DeepSeaProblog does not tackle the issue of declarative neuro-symbolic systems, it provides a suitable language for modeling declarative neural predicates.One of the demonstrations presented in the paper uses an auto-encoding structure similar to our proposal.However, DeepSeaProblog does not establish a basis for turning any neural predicate into a declarative one.</p>
<p>Methodology</p>
<p>We now explain our framework for declarative neural predicates.We will use the digit/2 predicate from the MNIST example as a running example, where digits are matched with their images.</p>
<p>Our framework is based on two key ideas.First, to answer arbitrary queries that involve neural predicates, there exists a set of canonical queries to which other queries can be reduced.In our example, the canonical set of queries that we want to be able to answer without (re)training is • digit( ,3): is this an image of the digit 3?;</p>
<p>• digit( ,?): what is the digit in this image?;</p>
<p>• digit( ?,3): what is an image associated with the digit 3?; and</p>
<p>• digit( ?,?): what are valid groundings of this predicate?</p>
<p>More complex queries involving more neural predicates and combinations thereof would reduce to combining this set of queries.Our framework contributes inference procedures to answer all these queries.Second, the main challenge in answering canonical queries is that the non-symbolic arguments of neural predicates do not come with concretely defined domains.However, if a user poses a query involving a domain of images, the reasoning engine needs to know which values can appear in that place.We overcome this problem by structuring predicates around prototypes, which learn the domains of non-symbolic arguments from data.</p>
<p>We present a framework rather than a fully automatable process; the user must still decide how to structure the neural predicates around prototypes.However, the construction can be done automatically under some fairly general assumptions.Our framework is designed to avoid changes to the internal mechanisms in (Deep)Problog.The proposed framework changes the semantics of DeepProblog programs but preserves the inference procedure.</p>
<p>We first explain the design principles behind declarative neural predicates and operations over them.The formal definition of their semantics is in appendix A.</p>
<p>Neural predicates with prototypes</p>
<p>Instead of treating neural predicates as mappings from images to symbols, we task neural predicates with capturing prototypes and relating images to them.The goal of a prototype is to learn true groundings of a neural predicate.All images of digit 1 should be associated with the prototype, but no other images.We impose five modelling assumptions on neural predicates.Assumption 1.We assume a fixed number of prototypes.In our example, we assume ten prototypes corresponding to one of the digits each.We assume that the user gives the number of prototypes and leave the problem of automatically finding them for future work.</p>
<p>While we assume a fixed number of prototypes, the prototypes themselves are learned from data with prototype networks [Xu et al., 2020].Prototypes are usually captured in latent space, not the same representation spaces as the original inputs; we follow the same principle.Assumption 2. The prototypes are responsible for grounding non-symbolic arguments of the predicate, that is, the arguments that are not expressed as logical symbols, such as images, sound, or any other sensory input.Considering our MNIST example, as each prototype is associated with one of the ten digits, the role of the prototypes is to produce groundings of images related to it, i.e., the images of a particular digit.Assumption 3. One neural predicate models exactly one non-symbolic argument.A predicate involving two or more non-symbolic arguments can be modeled through a clause combining several neural predicates.For instance, assume we want to have a predicate visual addition/3 which takes three arguments, all being images, such that the third image is the sum of the digits in the first images.This assumption means that we will not model such a predicate as a single neural predicate operating on one or three prototypes but rather as a composition of three neural predicates focusing on individual images: visual_addition(Im1, Im2, Im3):digit(Im1,D1), digit(Im2,D2) digit(Im3,D3), D3 is D1 + D2 Assumption 4. Symbolic arguments of neural predicates are associated with prototypes and can be determined from them.In our MNIST example, each prototype has a digit associated with it; therefore, by knowing the prototype an instance belongs to, we can determine the second argument of the digit/2 predicate, i.e., the corresponding digit.n-ary predicates can be handled similarly.</p>
<p>We do not assume that there has to be a 1-to-1 mapping between a prototype and symbolic arguments of a predicate.One prototype can map to more than one combination of symbolic arguments.</p>
<p>Assumption 5. We assume that prototypes are mutually exclusive, i.e., every non-symbolic instance can belong to only one prototype.In DeepProblog terms, the prototype membership is an annotated disjunction.This assumption is not restrictive: the original formulation of neural predicates also assumes that neural predicates declare annotated disjunction, meaning that one image can have only one label attached to it.In our case, an MNIST image can only belong to one prototype, and it is up to the DeepProblog engine to decide which one.</p>
<p>We model prototype membership as an annotated disjunction where the probability of assignment to a particular prototype is proportional to the distance from the learned prototype (fig.3, lines 1-5).The prototypes form a mixture model, and the annotated disjunction ensures that a particular nonsymbolic instance belongs to one component of the mixture (one prototype) at a time.This formulation closely follows the standard Gaussian mixture model [Reynolds, 2009].</p>
<p>Relational operations on prototypes</p>
<p>By design, prototypes are learned from data and, therefore, realize the domain of valid instances.An important consequence is that we can now sample instances from a prototype.By doing so, we overcome the previously outlined problem of unification.If we have to unify a variable standing in for a non-symbolic argument, we can sample from the corresponding prototype.</p>
<p>This ability to sample instances from a prototype allows us to answer the four canonical queries (see fig. 2):</p>
<p>• digit( ,3): to answer this query, we map the given image to the latent space and compute the distance of the mapping to the prototype associated with digit 3; • digit( ,?): to answer this query, we map the image to the latent space, find the closest prototype, and determine the corresponding digit;</p>
<p>• digit( ?,3): to answer this query, we determine the prototype associated with the digit 3, sample an instance for the prototype, and unify it with the image variable,</p>
<p>• digit( ?,?): to answer this query, we iterate over all prototypes and sample an instance from them.The instance is then decoded into an image.The inference procedures for the canonical set of queries demonstrate that we must move flexibly between nonsymbolic instances and the prototypes.To do so, we introduce a relation prototype match/3 which relates the image, a prototype, and the probability that the image is associated with the prototype.This can be seen as a relation interpretation of the encoding-decoding scheme standard in (variational) autoencoders.</p>
<p>The relation defined in line 7 of fig. 3 first states the obvious: the given images embed into the prototype, and the prototype decodes the image.The interesting part is in these two inner relations.The relation encode(Im,Prot,P) states that an image Im belongs to a prototype Prot with probability P: encode(Image, Prot, P):ground(Image),nn_encoder(Image, Lat), lat_similar(Prot,Lat, P). encode(Image, Prot, P) :-var(Image), sample(Prot, Sample), nn_decoder(Sample, Image), lat_similar(Prot, Sample, P).If an image is given, it is mapped to the prototype space through the prototype network nn encoder/2.The probability is determined by the similarity of the encoding to the prototype.If the image is not given, we sample from the given prototype to generate an image.
p 3 p 2 p 1 digit( 3 ,3) (a) p 3 p 2 p 1 digit( 3 ,?) (b) p 3 p 2 p 1 digit( ? ,3) (c) p 3 p 2 p 1 digit( ? ,?)(d
The decode/3 relation relates prototypes to images from their domain and is defined similarly to the encode/3 relation: decode(Prot, Image, P) :-ground(Prot), sample(Prot, Sample), nn_decoder(Sample, Image2), im_similar(Image, Image2, P). decode(Prot,Image,1.0):var(Prot), nn_encoder(Prot,Image).Training objective.The im similar/2 predicate measures the similarity between the given image and the one generated from a prototype.This predicate essentially defines a reconstruction loss, pushing the decoder to learn to generate images similar to the ones in the data.This predicate is unnecessary during inference, and we remove it from the program.</p>
<p>3 Prototype membership probabilities.The missing part of the framework is the probabilities of probabilistic facts that associate instances with prototypes.To do so, we design prototypes as multivariate Gaussian distributions parametrised by a mean and standard derivation, following the design of variational auto-encoders [Kingma and Welling, 2014].This design allows a prototype to capture the variance present in images that should be associated with it.The probability of an instance belonging to a prototype is then defined as a normalised likelihood of an instance being sampled from a Gaussian distribution captured by the prototype.</p>
<p>Implementing encoder and decoder.The framework presented so far does not depend on the exact structure of encoders and decoders.While in this work, we rely on a variational auto-encoder, any generative network can be used as a decoder.For instance, to use diffusion models [Yang et al., 2024] or generative adversarial networks [Goodfellow et al., 2014], the prototypes can be interpreted as capturing a distribution of input noise to be fed into these models.Unification over infinite spaces.An attentive reader might have noticed the prototypes described so far do not reduce the domain.They learn what typical instances look like, but the domain remains continuous and infinite.This remains a problem for unification because if it encounters a variable corresponding to an image, it would try to fill it with infinite possibilities.The way we have structured declarative neural predicates helps to avoid this issue: a possible image is sampled from a prototype, and we limit our framework to retrieving a single sample.</p>
<p>Experimental evaluation</p>
<p>The experimental evaluation of our framework focuses on verifying that prototype-based neural predicates can be effectively learned from data and that they extend the capabilities of neuro-symbolic systems with declarative reasoning.We separate the evaluation into the following research questions:</p>
<p>RQ1: Can prototype-based neural predicates be learned from direct supervision?RQ2: Can prototype-based neural predicates be learned from distance supervision?RQ3: Can prototype-based DeepProblog answer arbitrary queries?</p>
<p>Methodology</p>
<p>Tasks.To evaluate our framework, we use a classical problem of MNIST addition introduced in DeepProblog [ Manhaeve et al., 2018] and DeepStochlog [Winters et al., 2022].These tasks allow for a meaningful interpretation of prototypes, which capture the digits images represent.More specifically, we use the following tasks:     It relates it to each prototype through prototype match/3.The predicate prototype/2 relates a particular prototype to its latent representation.The prototype match/3 is essentially a probability fact capturing the likelihood that an image belongs to the prototype.This is achieved by comparing the latent projection of an image to the prototype space and the prototypes themselves.The prototypes are modeled as Gaussian distributions; the similarity to a prototype is computed as the likelihood of sampling a latent representation of an image from the distribution defined by the prototype.The predicates im similar/2 and lat similar/2 compute similarities in the image space (as 1 -mean squared error between the images) and the probability of a latent vector being sampled from the Gaussian distribution defined by the prototype, respectively.(b) During inference, the snippet marked in red is substituted by the green code snippet.As the decoder is trained already, we can shorten the decode rule and remove im similar.</p>
<p>• Direct supervision (digit/2): we learn prototypebased neural predicates from examples such as digit( ,3).This is essentially a sanity check to assess the performance of our new neural predicates, which have more complex tasks to solve than the original DeepProblog.</p>
<p>• Distant supervision (add/3): we learn neural predicates from examples such as addition( , ,6), matching the DeepProblog setup.</p>
<p>• Unseen queries -simple (digit/2 and add/3): we use the model from RQ1 and query it with queries it has not been trained to answer.More precisely, we use queries ?-digit( ?,?). (return images for all possible digits), and ?-addition( ?, ?,7) (return images of all combinations of digits that sum to 7).</p>
<p>No other system can answer these queries without being explicitly trained to do so.</p>
<p>• Unseen queries -complex (multi add/3): starting from the model trained in RQ1, we prompt it to solve 4-digit addition.We randomly substitute 4 images with variables to sample n = 100 declarative queries (see Appendix C for an example).Again, no other system is able to solve this task.We train our declarative and original DeepProblog version on 60000 examples fordigit/2 and 30000 examples for add/3 and test on a separate test set of 10000 samples.Performance metrics.For the first two tasks, we use classification accuracy to measure success.For the two tasks involving unseen queries, we calculate the accuracy of answers in the following way.For every image our system returns as an answer, we find the most similar image from the training set (using the mean squared error as a distance) and retrieve the corresponding label.We then use these labels to calculate the accuracy of the answers, denoted as generative accuracy.We opt for this measure rather than the choice of prototypes, as the system's performance is judged based on the final output it generates, not the want it intends to generate.Implementation details.Our implementation uses a neural architecture similar to DeepProblog, except that the last layer of the encoder maps to a prototype rather than a label.We use a fully connected network as a decoder.Similar to DeepProblog, we use binary cross-entropy as the loss function.One of our framework's hyperparameters is the similarity measure choice, comparing instances to prototypes.For our variational autoencoder (VAE) setup, we use likelihood to describe similarity in latent space, i.e., between prediction and respective prototypes.To measure similarity in image space, we use the inverted mean squared error (mse), that is 1-mse(Im1,Im2).Digit classification and addition tasks were repeated 5 and 3 times, respectively, and average measures were reported.</p>
<p>Results</p>
<p>RQ1: Learning prototypes from direct supervision When learned from direct supervision, prototype-based neural predicates are as effective as their functional counterpart (table 1).This result demonstrates that declarative neural predicates do not necessarily sacrifice performance and can be effectively learned, despite solving a more challenging task by capturing domains through prototypes.</p>
<p>RQ2: Learning prototypes from distant supervision</p>
<p>Similarly to the previous experiment, our declarative neural predicates perform comparatively to their functional counterpart when trained on distant supervision.This result is especially interesting because distant supervision arguably provides a less clear signal to learn the domains of instances.</p>
<p>RQ3: Declarative queries</p>
<p>The most interesting aspect of our evaluation is the unseen queries.The results (table 2) demonstrate that our declarative DeepProblog can successfully answer the simple queries, digit/2 and add/3, obtaining high generative accuracy.Interestingly, while the generative accuracy is imperfect, our system always picks the correct prototype.The generated images, sampled from the selected prototype, look more similar to those generated from another prototype.This issue might be overcome by using a more powerful generative model or training longer.fig. 4 shows the images sampled from each prototype when querying ?-digit( ?,?)..The prototypes pick up on the distinguishing features of digits rather than their whole appearance.This could result from using mean squared error as the reconstruction loss or not having a sufficiently powerful sampling architecture.</p>
<p>Our system also performs well on the multi-digit addition problem table 2, having the generative accuracy well above random guessing.The actual performance is much lower than in the previous cases, but this is to be expected as the error accumulates with more digits.However, similar to the previous  case, most errors are caused not by selecting a wrong prototype but by generating an image that looks more similar to another digit.Again, we note that no other system is able to answer all of these queries simultaneously.</p>
<p>Conclusion</p>
<p>This work tackles an open problem within neuro-symbolic systems: How can we make them fully declarative?Focusing on the DeepProblog family of neuro-symbolic systems, we outline challenges that prevent these systems from being fully declarative, all arising from the functional nature of neural networks.To overcome these limitations, we introduce a framework for making any neural predicate, the key abstraction in DeepProblog, fully declarative.Our framework introduces a specific design of neural predicates around prototypes; this design allows them to regain declarativeness.Our initial experiments demonstrate the potential of the proposed framework: our neural predicates demonstrate similar performance to a functional one while being able to answer arbitrary queries.</p>
<p>Many open challenges remain if we are to reach the goal of fully declarative neuro-symbolic systems.One of the biggest challenges is the scalability.We have noticed that incorporating exclusive membership to prototypes ensures fast convergence; however, each training iteration takes twice as much time.Furthermore, distant supervision makes learning more challenging.We suppose this is the case because distant supervision does not provide a 1-to-1 assignment between images and prototypes; the example addition( ?, ?,5) does not give a unique assignment to the first two arguments but several options are possible: 0+5=5, 5+0=5, 1+4=5, 4+1=5, 2+3=5, 3+2=5.Finally, we have assumed a fixed number of prototypes; automatically learning the number of necessary prototypes would make the entire framework more usable.</p>
<p>Figure 1 :
1
Figure 1: Unification in DeepProblog breaks when tasked to generate an image.DeepProblog iteratively tries to match either the current facts with rules from the program in (a) or variables with values.After digit( ?,4) is generated it cannot assign a value to ? , breaking the resolution algorithm.</p>
<p>Neuro-symbolic systems.Many neuro-symbolic systems have been introduced over the years: DeepProblog [Manhaeve et al., 2018], Scallop [Huang et al., 2021], NeurASP [Yang et al., 2023], Logic Tensor Networks [Badreddine et al., 2022], and NeuPSL [Pryor</p>
<p>Figure 2 :
2
Figure 2: Procedures to answer the four canonical queries.Each prototype is shown in latent space and consists of a mean pi and a distribution illustrated in a darker shade.The arrows represent different computations, as shown in the legend.(a) Both image and prototype are mapped to the latent space.The probability is their distance in latent space.(b) The image is encoded, compared to all prototypes, and the closest is used to answer the query.(c) The prototype is mapped to the latent space, an instance is sampled and decoded back to image space.(d) All possible groundings are generated.The prototype is fetched for each possible grounding, and an instance gets sampled and decoded back to image space.</p>
<p>, Image, P) :-ground(Prot), sample(Prot, Sample), 16 nn_decoder(Sample, Image2), im_similar(Image, Image2, P).</p>
<p>17</p>
<p>, Lat2, P) :-Lat1 \= Lat2, likelihood(Lat1, Lat2, P).</p>
<p>, Image, 1.0) :-ground(Prot).(b)Substitution used during inference.</p>
<p>Figure 3 :
3
Figure 3: Declarative neural predicate for the MNIST digit example with three digits only.(a) The first clause is an annotated disjunction modeling prototype membership of an image I.It relates it to each prototype through prototype match/3.The predicate prototype/2 relates a particular prototype to its latent representation.The prototype match/3 is essentially a probability fact capturing the likelihood that an image belongs to the prototype.This is achieved by comparing the latent projection of an image to the prototype space and the prototypes themselves.The prototypes are modeled as Gaussian distributions; the similarity to a prototype is computed as the likelihood of sampling a latent representation of an image from the distribution defined by the prototype.The predicates im similar/2 and lat similar/2 compute similarities in the image space (as 1 -mean squared error between the images) and the probability of a latent vector being sampled from the Gaussian distribution defined by the prototype, respectively.(b) During inference, the snippet marked in red is substituted by the green code snippet.As the decoder is trained already, we can shorten the decode rule and remove im similar.</p>
<p>Figure 4 :
4
Figure 4: Images learned by prototypes, sorted from 0 to 9.They resemble key distinguishing features of digits but not their full appearance.</p>
<p>Table 1 :
1
Declarative neural predicates achieve comparable performance when trained on direct supervision and perform well but noticeably worse when trained on distant supervision.
ModelAccuracydigit/2 add/3DeepProblog98.7%95.6%DeclDeepProblog98.4%94.2%</p>
<p>Table 2 :
2
Declarative DeepProblog accurately generates images for queries it has not been trained on.
ModelAccuracydigit/2 add/3 multi add/9DeclDeepProblog88.1%81.5%62.2%
the character ?-is a Prolog convention indicating that we are interested in establishing the truth value of a logical statement following the character
2 capitalized symbols like X stand for variable, while lowercase symbols stand for entities like dog stand for entities in the knowledge base
It is possible to include reconstruction loss outside of the Deep-Problog program; this is a simple and easy way to achieve this.
A SemanticsWe show the semantics of the neural predicate in the MNIST case, but the explanation holds beyond it.The neural predicate p(X, d) is a joint probability distribution: p(X, d) = p(X|z)p(z|d)p(d)dz where X is an image, z is a latent embedding and d is a digit.Here:• p(d) is a prior over digits; we model it as a uniform categorical distribution over the digits;• p(z|d) is a multivariate gaussian distribution ; it is parameterized by a simple table mapping d to the mean and standard deviation of the Gaussian; this is the prototype associated with d.• p(X|d) is a set of independent Gaussian distributions of pixel intensities parameterized by a deep neural decoder.Given the model, we will now show how to perform different inference tasks on this model.Generative query.The purely generative query digit( ?,?) can be answered by sampling from the distribution p(X, d) following the conditional factorization.Conditional query on digits.The conditional query digit( ?,3) can be answered as the previous one but starting from the provided digit.Conditional query on image.To answer such a query, we need to introduce two approximations to the intractable posterior distributions p(z|X) and p(d|z).We introduce a variational Gaussian approximation q(z|X), parameterized by a neural network encoder, and a categorical digit distribution:where d is a distance function in embedding space and Z = δ e − d(z,z δ ) T is a normalization factor.Therefore, p(d|X) ≈ q(d|z)q(z|X)dzThe corresponding query can thus be answered by sampling from q(z|X) and q(d|z).Notice that q(d|z) shares the same parameters (prototypes) z d with p(z|d), thus making the most probable digit d the one whose prototype z d in p(z, d) is the closest.Likelihood query.The final query digit( ,3) is a likelihood of a (image, digit) pair for our model.Answering this query corresponds to computing the probability that the model generates the corresponding pair.Using standard variational inference arguments (Appendix A), we can provide a lower bound to the log probability of the pair, i.e.:where:• E z [log p(X|z)] is the likelihood of independent Gaussians (maps to an MSE, standard in VAE); • KL(p(z|d)||q(z|X)) is the KL between the prior p(z|d)and the posterior q(z|X).B Likelihood LowerboundWe want to compute a lower bound to the log-likelihood of a training pair p(X, d):Let's multiply and divide for the approximate posterior q(z|X) (i.e., the encoder).For Jensen's inequality: C ExperimentsWe provide an example for the declarative queries over multi add/3.As described, we randomly generate two 4digit numbers represented by a list of digit images.These numbers have to add up to the last element of the query.We randomly substitute 4 digits with variables to re-generate them.As the generated MNIST digits are hard to distinguish in this small format, we use boxed digits to represent them.The original queryis masked to multi add([ ?, 4 , ? , ?],[ ? , 5 , 2 , 5 ], 4963.(5)And prompted to our model.For each answer, which is a list of generated images, we compute the labels of the closest image in the image space.If those labels satisfy the underlying addition, we denote a query as successfully answered.D Implementation DetailsThe implementation provided within the main body is great for educational purposes but is tedious to maintain once we want to change parameters.We use a slightly different formulation for the experiments that grounds out to the same implementation but requires more Prolog knowledge.As described, we change the probability of decode between training and inference.The full training program used is shown in fig.5. Here, we treat all prototypes at the same time using a map list.As in this formulation Image is only bound once, we have to make the list of images explicit to generate images for all possible prototypes.prototype(X, tensor(prototype(X))) :-between(0,9,X).9 10 P0::digit(I0,0) ; P1::digit(I1,1); P2::digit(I2,2); P3::digit(I3,3); 11 P4::digit(I4,4); P5::digit(I5,5); P6::digit(I6,6); P7::digit(I7,7);[0,1,2,3,4,5,6,7,8,9],14 [P0, P1, P2, P3, P4, P5, P6, P7, P8, P9]).(b) Substitutions for the program used during inference, not using im similar anymore.The brief decode is feasible, as the image is either given or already generated during encode.
Logic tensor networks. Badreddine, Artificial Intelligence. 3031036492022. 2022</p>
<p>Problog: A probabilistic prolog and its application in link discovery. De Raedt, IJCAI 2007, Proceedings of the 20th international joint conference on artificial intelligence. 2007. 2007Luc De Raedt, Angelika Kimmig, and Hannu Toivonen</p>
<p>Scallop: From probabilistic deductive databases to scalable differentiable reasoning. De Smet, ICLR 2014Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence. Conference Track Proceedings. Angelika Kimmig, Bart Demoen, Luc De Raedt, Santos Vitor, Ricardo Costa, Rocha, the Thirty-Ninth Conference on Uncertainty in Artificial IntelligenceAhn; Banff, AB, CanadaKingma and Welling2023. 31 Jul-04 Aug 2023. 2014. 2014. 2022. June 2022. 2021. 2021. 2020. 2020. 2011. 2011. 2014. April 14-16, 2014. 2014. 20192162nd International Conference on Learning Representations. Kingma and Welling, 2019] Diederik P. Kingma and Max Welling. An introduction to variational autoencoders. CoRR, abs/1906.02691</p>
<p>Rajeev Alur, and Mayur Naik. Relational programming with foundational models. Li, Proceedings of the AAAI Conference on Artificial Intelligence. Vladimir Lifschitz. Answer Set Programming. the AAAI Conference on Artificial IntelligenceSpringer Publishing Company2024. Mar. 2024. 2019. 201938Incorporated, 1st edition</p>
<p>Deepproblog: Neural probabilistic logic programming. Manhaeve, Advances in neural information processing systems. 2018. 201831</p>
<p>From statistical relational to neurosymbolic artificial intelligence: A survey. Marra, ICML Workshop on Knowledge and Logical Reasoning in the Era of Data-Driven Learning (KLR). Connor Pryor, Charles Dickens, Lise Getoor, 2024. 2024. 2022. 20223282023Advances in Neural Information Processing Systems</p>
<p>Neural-probabilistic answer set programming. Reynolds ; , Douglas Reynolds, ; Springer, U S Boston, M A Skryagin, Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017. Isabelle Guyon, Samy Ulrike Von Luxburg, Hanna M Bengio, Rob Wallach, S V N Fergus, Roman Vishwanathan, Garnett, Long Beach, CA, USA; Cambridge, MAAAAI Press2009. 2009. 2022. 2022. 2017. December 4-9, 2017. 2017. 1986. 1986. 202219AAAI</p>
<p>Attribute prototype network for zero-shot learning. Xu, Advances in Neural Information Processing Systems. 2020. 202033</p>
<p>Diffusion models: A comprehensive survey of methods and applications. Yang , arXiv:2307.07700Neurasp: Embracing neural networks into answer set programming. 2023. 2023. 2024. 20245639arXiv preprint</p>            </div>
        </div>

    </div>
</body>
</html>