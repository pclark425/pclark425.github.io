<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-3451 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-3451</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-3451</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-80.html">extraction-schema-80</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <p><strong>Paper ID:</strong> paper-18949530</p>
                <p><strong>Paper Title:</strong> Compositional Reasoning in Early Childhood</p>
                <p><strong>Paper Abstract:</strong> Compositional “language of thought” models have recently been proposed to account for a wide range of children’s conceptual and linguistic learning. The present work aims to evaluate one of the most basic assumptions of these models: children should have an ability to represent and compose functions. We show that 3.5–4.5 year olds are able to predictively compose two novel functions at significantly above chance levels, even without any explicit training or feedback on the composition itself. We take this as evidence that children at this age possess some capacity for compositionality, consistent with models that make this ability explicit, and providing an empirical challenge to those that do not.</p>
                <p><strong>Cost:</strong> 0.011</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e3451.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e3451.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Prototype theory</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Prototype theory</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Concepts are represented as prototypical feature averages or idealized exemplars; category membership and compositional combinations are derived from similarity to these prototypes.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Compositional Reasoning in Early Childhood</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>prototype theory</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Conceptual categories are represented by a prototype (an averaged, idealized feature vector) and membership/judgments are determined by similarity to that prototype.</td>
                        </tr>
                        <tr>
                            <td><strong>level_of_analysis</strong></td>
                            <td>functional</td>
                        </tr>
                        <tr>
                            <td><strong>supporting_evidence</strong></td>
                            <td>Classical literature (cited) shows typicality effects and graded category membership that prototype representations capture (Rosch & Mervis style typicality and family resemblance effects referenced).</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence_or_challenges</strong></td>
                            <td>Prototype representations have been argued (cited work such as Fodor & Lepore) to inadequately account for compositionality and some structured concept phenomena; the present paper notes that pure prototype accounts may struggle to implement the kinds of systematic compositional operations LOT-style models posit.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_theories</strong></td>
                            <td>Paper contrasts prototype-style formats with symbolic/compositional LOT approaches, noting that compositionality could either be built 'on top' of prototypes or be intrinsic to core representations as in LOT; prototypes are presented as an alternative but potentially insufficient for compositional learning.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_limitations_or_open_questions</strong></td>
                            <td>Unclear how prototype models would naturalistically implement the rapid formation of novel composed operations without additional machinery; the present experiment does not adjudicate whether compositionality is implemented on top of prototypes or as part of core representations.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3451.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e3451.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Exemplar theory</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Exemplar theory</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Concepts are represented as sets of stored instances (exemplars), and classification or composition is performed by comparing new stimuli to remembered exemplars.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Compositional Reasoning in Early Childhood</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>exemplar theory</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Conceptual knowledge consists of memory for individual exemplars; judgments arise from similarity-weighted retrieval of these exemplars.</td>
                        </tr>
                        <tr>
                            <td><strong>level_of_analysis</strong></td>
                            <td>functional</td>
                        </tr>
                        <tr>
                            <td><strong>supporting_evidence</strong></td>
                            <td>Referenced as an established account in the literature that explains many categorization phenomena via exemplar memory and similarity-based inference.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence_or_challenges</strong></td>
                            <td>Like prototype accounts, exemplar models are not obviously compositional and may have difficulty explaining systematic productivity or rapid construction of novel composed functions; the paper implies exemplar models are an alternative but does not provide direct empirical support for composition within exemplar frameworks.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_theories</strong></td>
                            <td>Positioned alongside prototype and LOT theories in the introduction as alternative representational formats; contrasted implicitly with symbolic/compositional LOT approaches which more directly encode combinatorial structure.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_limitations_or_open_questions</strong></td>
                            <td>How exemplar representations could produce the observed ability to compose novel functions without explicit composition training is left unresolved; the experiment does not directly test exemplar-based mechanistic accounts.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3451.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e3451.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Language of Thought (LOT)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Language of Thought / symbolic compositional representation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Concepts are structured, symbolic expressions built compositionally from primitive functions and operators (e.g., logical forms); complex concepts arise by composing simpler functions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Compositional Reasoning in Early Childhood</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>language of thought (LOT) / symbolic compositional representation</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Conceptual knowledge is represented as symbolic/compositional expressions (functions and operators) that can be composed (e.g., f2(f1(x)) or f2 ∘ f1) to form complex thoughts; primitives ground out in a small set of operations.</td>
                        </tr>
                        <tr>
                            <td><strong>level_of_analysis</strong></td>
                            <td>functional</td>
                        </tr>
                        <tr>
                            <td><strong>supporting_evidence</strong></td>
                            <td>The paper's critical empirical finding: 3.5–4.5 year-olds can predictively compose two novel transformations (functions) above chance without feedback on compositions, indicating children can represent functions and combine them—consistent with LOT's prediction that learners can compose operations.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence_or_challenges</strong></td>
                            <td>Observed systematic failure on within-dimension change/change sequences (e.g., color then color) challenges the purest form of compositionality: a mechanism that composes arbitrarily should handle within-dimension compositions as well; the experiment cannot distinguish between explicit symbolic chunking (f2 ∘ f1) and weaker successive application f2(f1(x)).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_theories</strong></td>
                            <td>Directly contrasted with prototype and exemplar models (as an account that makes compositionality intrinsic), and with connectionist/PDP approaches (questioning whether such distributed models can account for compositional learning without presupposing compositionality). Bayesian/rational variants of LOT are described as modern incarnations that add statistical inference to symbolic primitives.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_limitations_or_open_questions</strong></td>
                            <td>Does not resolve whether children form explicit composed symbols (chunking) versus only performing sequential updates; fails in within-dimension rapid sequential updates possibly due to memory/race conditions; leaves open how LOT-like composition is implemented neurally and whether connectionist systems can emulate it without built-in compositional primitives.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3451.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e3451.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Bayesian/rational LOT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Rational/Bayesian models of compositional learning (LOT variants)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Structured symbolic hypothesis spaces (a LOT) combined with Bayesian inference to select between composed hypotheses and learn primitives/compositions from data.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Compositional Reasoning in Early Childhood</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Bayesian / rational LOT models</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Learners entertain structured, compositional hypotheses (expressions in a LOT) and perform probabilistic (Bayesian) inference to choose among hypotheses and learn which compositions explain observed data.</td>
                        </tr>
                        <tr>
                            <td><strong>level_of_analysis</strong></td>
                            <td>functional</td>
                        </tr>
                        <tr>
                            <td><strong>supporting_evidence</strong></td>
                            <td>Cited modeling work (Goodman et al., Piantadosi et al., Feldman) shows rational/L0T models can explain diverse learning phenomena; the present behavioral results (children composing unseen combinations) are qualitatively consistent with learners possessing compositional hypothesis spaces amenable to Bayesian inference.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence_or_challenges</strong></td>
                            <td>Empirical failures (within-dimension CH/CH breakdown) suggest that Bayesian/L0T models must incorporate processing limitations (e.g., memory constraints) to match behavior; the paper does not present formal Bayesian model fits to these data.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_theories</strong></td>
                            <td>Presented as a refinement of LOT theories (adding statistical decision mechanisms) and contrasted with non-symbolic connectionist accounts; paper frames Bayesian LOT as a prominent contemporary approach.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_limitations_or_open_questions</strong></td>
                            <td>Whether Bayesian LOT accounts can capture the specific within-dimension failures without ad hoc resource limits, and whether neural/connectionist implementations approximating Bayesian LOT exist, remain open.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3451.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e3451.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Connectionism / PDP</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Connectionist / Parallel Distributed Processing (PDP) models</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Concepts are encoded in distributed patterns across networks of units; compositional behavior must be learned by network weights rather than via explicit symbolic composition.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Compositional Reasoning in Early Childhood</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>connectionist / parallel distributed processing (PDP)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Representations are distributed activation patterns in networks; generalization and composition emerge from learned weight structures and distributed transformations rather than explicit symbolic function composition.</td>
                        </tr>
                        <tr>
                            <td><strong>level_of_analysis</strong></td>
                            <td>functional</td>
                        </tr>
                        <tr>
                            <td><strong>supporting_evidence</strong></td>
                            <td>Connectionist frameworks have historically accounted for graded generalization and learning phenomena; the paper cites the connectionist vs symbolic debate and acknowledges PDP as a competing framework.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence_or_challenges</strong></td>
                            <td>The paper highlights the challenge: can connectionist systems learn separate functions and then compose them on the fly for novel combinations without additional composition training? This is posed as an open empirical/theoretical question and a potential weakness if such systems require extra training to compose.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_theories</strong></td>
                            <td>Contrasted with LOT/symbolic accounts which build compositionality in as primitives; cites the Fodor & Pylyshyn debate (connectionism vs symbolic) and asks whether PDP implementations can be interpreted without presupposing compositionality.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_limitations_or_open_questions</strong></td>
                            <td>Unclear how to construct a connectionist model that captures children's ability to compose novel functions immediately; the paper raises this as a topic for future work rather than providing data against connectionism.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3451.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e3451.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Constraint-combination account</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Constraint combination (non-compositional alternative)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Children may predict outcomes by combining constraints imposed by each screen on possible outcomes, rather than by composing functions symbolically.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Compositional Reasoning in Early Childhood</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>constraint combination (non-compositional)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Rather than representing and composing functions, learners represent constraints on possible outputs from each transformation and combine these constraints to infer the final outcome.</td>
                        </tr>
                        <tr>
                            <td><strong>level_of_analysis</strong></td>
                            <td>functional</td>
                        </tr>
                        <tr>
                            <td><strong>supporting_evidence</strong></td>
                            <td>The paper notes this as an alternative that could, in principle, capture the observed ability to infer outcomes without explicit composition; constraint combination can explain success in many two-screen cases by intersecting allowed outcomes.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence_or_challenges</strong></td>
                            <td>Authors argue constraint models would struggle to naturally explain the specific failure on within-dimension CH/CH trials and the detailed above-chance pattern across conditions unless they include operations that effectively emulate function composition; thus constraint accounts face empirical challenges matching the pattern.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_theories</strong></td>
                            <td>Framed as an alternative to compositional (LOT) accounts; contrasted in explanatory power for the present data—constraint combination must replicate compositional predictions to be viable.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_limitations_or_open_questions</strong></td>
                            <td>Requires formalization to determine whether constraint-combination can reproduce the full pattern of successes and failures; the present study does not formally test such models.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3451.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e3451.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Lambda/combinatory logic</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Lambda-calculus / combinatory logic (formal composition systems)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Formal minimal systems where computation is built purely by function abstraction and composition, demonstrating that composition alone can express arbitrary computation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Compositional Reasoning in Early Childhood</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>lambda-calculus / combinatory logic (formal composition)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Mathematical formalisms in which functions and their composition (plus abstraction) are the primitive operations; they show that arbitrary computations can be constructed from composition alone.</td>
                        </tr>
                        <tr>
                            <td><strong>level_of_analysis</strong></td>
                            <td>functional</td>
                        </tr>
                        <tr>
                            <td><strong>supporting_evidence</strong></td>
                            <td>Cited formal results (Church, Schönfinkel, Hindley & Seldin, Smullyan) that function composition suffices for Turing-complete computation, motivating the claim that compositional primitives can support rich learning.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence_or_challenges</strong></td>
                            <td>Formal sufficiency does not imply cognitive or neural plausibility; the paper acknowledges the gap between formal systems and implementational/processing limitations observed in children (e.g., within-dimension failures).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_theories</strong></td>
                            <td>Used to motivate the conceptual power of compositional primitives (LOT) relative to non-compositional representations; not presented as an empirical cognitive model but as theoretical grounding.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_limitations_or_open_questions</strong></td>
                            <td>How (and whether) children implement compositional primitives analogous to lambda-calculus in neural substrate is unresolved; formal systems do not address resource or memory constraints evident in behavior.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3451.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e3451.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Memory / race-condition account</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Working memory / race-condition explanation for within-dimension failures</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Processing-level account attributing failures in within-dimension compositions to interference or slow 'write' operations in memory leading to loss/overwriting of the first transformation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Compositional Reasoning in Early Childhood</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>working memory / race-condition account</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Compositional operations are represented and applied, but rapid sequential updates to the same feature can interfere (a race condition), causing the first update to be lost or overwritten in working memory.</td>
                        </tr>
                        <tr>
                            <td><strong>level_of_analysis</strong></td>
                            <td>functional</td>
                        </tr>
                        <tr>
                            <td><strong>supporting_evidence</strong></td>
                            <td>Paper's error analysis shows incorrect responses tend to reflect correct application of the second screen more often than the first, supporting an explanation where the first transformation is overwritten or not encoded robustly.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence_or_challenges</strong></td>
                            <td>Because overall two-screen performance is below 50% in within-dimension CH/CH, simple forgetting of one screen (which would predict ~50%) is insufficient to explain the breakdown—suggesting interference can be more destructive than simple memory lapses.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_theories</strong></td>
                            <td>Positioned as a processing/mechanistic complement to representational theories: LOT-style composition could still be true at representational level but constrained by working-memory dynamics; contrasts with pure representational failure accounts.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_limitations_or_open_questions</strong></td>
                            <td>Paper cannot determine whether the failure is due to encoding, storage, retrieval, or representational format; further work is needed to identify the exact cognitive bottleneck and its interaction with representational format.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>The language of thought <em>(Rating: 2)</em></li>
                <li>Parallel distributed processing <em>(Rating: 2)</em></li>
                <li>Minimization of Boolean complexity in human concept learning <em>(Rating: 2)</em></li>
                <li>Bootstrapping in a language of thought: a formal model of numerical concept learning <em>(Rating: 2)</em></li>
                <li>A Rational Analysis of Rule-Based Concept Learning <em>(Rating: 2)</em></li>
                <li>A Computational Study of Cross-Situational Techniques for Learning Word-to-Meaning Mappings <em>(Rating: 2)</em></li>
                <li>Connectionism and cognitive architecture: a critical analysis, Connections and symbols <em>(Rating: 2)</em></li>
                <li>Introduction to Combinators and λ-calculus <em>(Rating: 1)</em></li>
                <li>To Mock a Mockingbird: and other logic puzzles including an amazing adventure in combinatory logic <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-3451",
    "paper_id": "paper-18949530",
    "extraction_schema_id": "extraction-schema-80",
    "extracted_data": [
        {
            "name_short": "Prototype theory",
            "name_full": "Prototype theory",
            "brief_description": "Concepts are represented as prototypical feature averages or idealized exemplars; category membership and compositional combinations are derived from similarity to these prototypes.",
            "citation_title": "Compositional Reasoning in Early Childhood",
            "mention_or_use": "mention",
            "theory_name": "prototype theory",
            "theory_description": "Conceptual categories are represented by a prototype (an averaged, idealized feature vector) and membership/judgments are determined by similarity to that prototype.",
            "level_of_analysis": "functional",
            "supporting_evidence": "Classical literature (cited) shows typicality effects and graded category membership that prototype representations capture (Rosch & Mervis style typicality and family resemblance effects referenced).",
            "counter_evidence_or_challenges": "Prototype representations have been argued (cited work such as Fodor & Lepore) to inadequately account for compositionality and some structured concept phenomena; the present paper notes that pure prototype accounts may struggle to implement the kinds of systematic compositional operations LOT-style models posit.",
            "comparison_to_other_theories": "Paper contrasts prototype-style formats with symbolic/compositional LOT approaches, noting that compositionality could either be built 'on top' of prototypes or be intrinsic to core representations as in LOT; prototypes are presented as an alternative but potentially insufficient for compositional learning.",
            "notable_limitations_or_open_questions": "Unclear how prototype models would naturalistically implement the rapid formation of novel composed operations without additional machinery; the present experiment does not adjudicate whether compositionality is implemented on top of prototypes or as part of core representations.",
            "uuid": "e3451.0"
        },
        {
            "name_short": "Exemplar theory",
            "name_full": "Exemplar theory",
            "brief_description": "Concepts are represented as sets of stored instances (exemplars), and classification or composition is performed by comparing new stimuli to remembered exemplars.",
            "citation_title": "Compositional Reasoning in Early Childhood",
            "mention_or_use": "mention",
            "theory_name": "exemplar theory",
            "theory_description": "Conceptual knowledge consists of memory for individual exemplars; judgments arise from similarity-weighted retrieval of these exemplars.",
            "level_of_analysis": "functional",
            "supporting_evidence": "Referenced as an established account in the literature that explains many categorization phenomena via exemplar memory and similarity-based inference.",
            "counter_evidence_or_challenges": "Like prototype accounts, exemplar models are not obviously compositional and may have difficulty explaining systematic productivity or rapid construction of novel composed functions; the paper implies exemplar models are an alternative but does not provide direct empirical support for composition within exemplar frameworks.",
            "comparison_to_other_theories": "Positioned alongside prototype and LOT theories in the introduction as alternative representational formats; contrasted implicitly with symbolic/compositional LOT approaches which more directly encode combinatorial structure.",
            "notable_limitations_or_open_questions": "How exemplar representations could produce the observed ability to compose novel functions without explicit composition training is left unresolved; the experiment does not directly test exemplar-based mechanistic accounts.",
            "uuid": "e3451.1"
        },
        {
            "name_short": "Language of Thought (LOT)",
            "name_full": "Language of Thought / symbolic compositional representation",
            "brief_description": "Concepts are structured, symbolic expressions built compositionally from primitive functions and operators (e.g., logical forms); complex concepts arise by composing simpler functions.",
            "citation_title": "Compositional Reasoning in Early Childhood",
            "mention_or_use": "use",
            "theory_name": "language of thought (LOT) / symbolic compositional representation",
            "theory_description": "Conceptual knowledge is represented as symbolic/compositional expressions (functions and operators) that can be composed (e.g., f2(f1(x)) or f2 ∘ f1) to form complex thoughts; primitives ground out in a small set of operations.",
            "level_of_analysis": "functional",
            "supporting_evidence": "The paper's critical empirical finding: 3.5–4.5 year-olds can predictively compose two novel transformations (functions) above chance without feedback on compositions, indicating children can represent functions and combine them—consistent with LOT's prediction that learners can compose operations.",
            "counter_evidence_or_challenges": "Observed systematic failure on within-dimension change/change sequences (e.g., color then color) challenges the purest form of compositionality: a mechanism that composes arbitrarily should handle within-dimension compositions as well; the experiment cannot distinguish between explicit symbolic chunking (f2 ∘ f1) and weaker successive application f2(f1(x)).",
            "comparison_to_other_theories": "Directly contrasted with prototype and exemplar models (as an account that makes compositionality intrinsic), and with connectionist/PDP approaches (questioning whether such distributed models can account for compositional learning without presupposing compositionality). Bayesian/rational variants of LOT are described as modern incarnations that add statistical inference to symbolic primitives.",
            "notable_limitations_or_open_questions": "Does not resolve whether children form explicit composed symbols (chunking) versus only performing sequential updates; fails in within-dimension rapid sequential updates possibly due to memory/race conditions; leaves open how LOT-like composition is implemented neurally and whether connectionist systems can emulate it without built-in compositional primitives.",
            "uuid": "e3451.2"
        },
        {
            "name_short": "Bayesian/rational LOT",
            "name_full": "Rational/Bayesian models of compositional learning (LOT variants)",
            "brief_description": "Structured symbolic hypothesis spaces (a LOT) combined with Bayesian inference to select between composed hypotheses and learn primitives/compositions from data.",
            "citation_title": "Compositional Reasoning in Early Childhood",
            "mention_or_use": "mention",
            "theory_name": "Bayesian / rational LOT models",
            "theory_description": "Learners entertain structured, compositional hypotheses (expressions in a LOT) and perform probabilistic (Bayesian) inference to choose among hypotheses and learn which compositions explain observed data.",
            "level_of_analysis": "functional",
            "supporting_evidence": "Cited modeling work (Goodman et al., Piantadosi et al., Feldman) shows rational/L0T models can explain diverse learning phenomena; the present behavioral results (children composing unseen combinations) are qualitatively consistent with learners possessing compositional hypothesis spaces amenable to Bayesian inference.",
            "counter_evidence_or_challenges": "Empirical failures (within-dimension CH/CH breakdown) suggest that Bayesian/L0T models must incorporate processing limitations (e.g., memory constraints) to match behavior; the paper does not present formal Bayesian model fits to these data.",
            "comparison_to_other_theories": "Presented as a refinement of LOT theories (adding statistical decision mechanisms) and contrasted with non-symbolic connectionist accounts; paper frames Bayesian LOT as a prominent contemporary approach.",
            "notable_limitations_or_open_questions": "Whether Bayesian LOT accounts can capture the specific within-dimension failures without ad hoc resource limits, and whether neural/connectionist implementations approximating Bayesian LOT exist, remain open.",
            "uuid": "e3451.3"
        },
        {
            "name_short": "Connectionism / PDP",
            "name_full": "Connectionist / Parallel Distributed Processing (PDP) models",
            "brief_description": "Concepts are encoded in distributed patterns across networks of units; compositional behavior must be learned by network weights rather than via explicit symbolic composition.",
            "citation_title": "Compositional Reasoning in Early Childhood",
            "mention_or_use": "mention",
            "theory_name": "connectionist / parallel distributed processing (PDP)",
            "theory_description": "Representations are distributed activation patterns in networks; generalization and composition emerge from learned weight structures and distributed transformations rather than explicit symbolic function composition.",
            "level_of_analysis": "functional",
            "supporting_evidence": "Connectionist frameworks have historically accounted for graded generalization and learning phenomena; the paper cites the connectionist vs symbolic debate and acknowledges PDP as a competing framework.",
            "counter_evidence_or_challenges": "The paper highlights the challenge: can connectionist systems learn separate functions and then compose them on the fly for novel combinations without additional composition training? This is posed as an open empirical/theoretical question and a potential weakness if such systems require extra training to compose.",
            "comparison_to_other_theories": "Contrasted with LOT/symbolic accounts which build compositionality in as primitives; cites the Fodor & Pylyshyn debate (connectionism vs symbolic) and asks whether PDP implementations can be interpreted without presupposing compositionality.",
            "notable_limitations_or_open_questions": "Unclear how to construct a connectionist model that captures children's ability to compose novel functions immediately; the paper raises this as a topic for future work rather than providing data against connectionism.",
            "uuid": "e3451.4"
        },
        {
            "name_short": "Constraint-combination account",
            "name_full": "Constraint combination (non-compositional alternative)",
            "brief_description": "Children may predict outcomes by combining constraints imposed by each screen on possible outcomes, rather than by composing functions symbolically.",
            "citation_title": "Compositional Reasoning in Early Childhood",
            "mention_or_use": "mention",
            "theory_name": "constraint combination (non-compositional)",
            "theory_description": "Rather than representing and composing functions, learners represent constraints on possible outputs from each transformation and combine these constraints to infer the final outcome.",
            "level_of_analysis": "functional",
            "supporting_evidence": "The paper notes this as an alternative that could, in principle, capture the observed ability to infer outcomes without explicit composition; constraint combination can explain success in many two-screen cases by intersecting allowed outcomes.",
            "counter_evidence_or_challenges": "Authors argue constraint models would struggle to naturally explain the specific failure on within-dimension CH/CH trials and the detailed above-chance pattern across conditions unless they include operations that effectively emulate function composition; thus constraint accounts face empirical challenges matching the pattern.",
            "comparison_to_other_theories": "Framed as an alternative to compositional (LOT) accounts; contrasted in explanatory power for the present data—constraint combination must replicate compositional predictions to be viable.",
            "notable_limitations_or_open_questions": "Requires formalization to determine whether constraint-combination can reproduce the full pattern of successes and failures; the present study does not formally test such models.",
            "uuid": "e3451.5"
        },
        {
            "name_short": "Lambda/combinatory logic",
            "name_full": "Lambda-calculus / combinatory logic (formal composition systems)",
            "brief_description": "Formal minimal systems where computation is built purely by function abstraction and composition, demonstrating that composition alone can express arbitrary computation.",
            "citation_title": "Compositional Reasoning in Early Childhood",
            "mention_or_use": "mention",
            "theory_name": "lambda-calculus / combinatory logic (formal composition)",
            "theory_description": "Mathematical formalisms in which functions and their composition (plus abstraction) are the primitive operations; they show that arbitrary computations can be constructed from composition alone.",
            "level_of_analysis": "functional",
            "supporting_evidence": "Cited formal results (Church, Schönfinkel, Hindley & Seldin, Smullyan) that function composition suffices for Turing-complete computation, motivating the claim that compositional primitives can support rich learning.",
            "counter_evidence_or_challenges": "Formal sufficiency does not imply cognitive or neural plausibility; the paper acknowledges the gap between formal systems and implementational/processing limitations observed in children (e.g., within-dimension failures).",
            "comparison_to_other_theories": "Used to motivate the conceptual power of compositional primitives (LOT) relative to non-compositional representations; not presented as an empirical cognitive model but as theoretical grounding.",
            "notable_limitations_or_open_questions": "How (and whether) children implement compositional primitives analogous to lambda-calculus in neural substrate is unresolved; formal systems do not address resource or memory constraints evident in behavior.",
            "uuid": "e3451.6"
        },
        {
            "name_short": "Memory / race-condition account",
            "name_full": "Working memory / race-condition explanation for within-dimension failures",
            "brief_description": "Processing-level account attributing failures in within-dimension compositions to interference or slow 'write' operations in memory leading to loss/overwriting of the first transformation.",
            "citation_title": "Compositional Reasoning in Early Childhood",
            "mention_or_use": "use",
            "theory_name": "working memory / race-condition account",
            "theory_description": "Compositional operations are represented and applied, but rapid sequential updates to the same feature can interfere (a race condition), causing the first update to be lost or overwritten in working memory.",
            "level_of_analysis": "functional",
            "supporting_evidence": "Paper's error analysis shows incorrect responses tend to reflect correct application of the second screen more often than the first, supporting an explanation where the first transformation is overwritten or not encoded robustly.",
            "counter_evidence_or_challenges": "Because overall two-screen performance is below 50% in within-dimension CH/CH, simple forgetting of one screen (which would predict ~50%) is insufficient to explain the breakdown—suggesting interference can be more destructive than simple memory lapses.",
            "comparison_to_other_theories": "Positioned as a processing/mechanistic complement to representational theories: LOT-style composition could still be true at representational level but constrained by working-memory dynamics; contrasts with pure representational failure accounts.",
            "notable_limitations_or_open_questions": "Paper cannot determine whether the failure is due to encoding, storage, retrieval, or representational format; further work is needed to identify the exact cognitive bottleneck and its interaction with representational format.",
            "uuid": "e3451.7"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "The language of thought",
            "rating": 2,
            "sanitized_title": "the_language_of_thought"
        },
        {
            "paper_title": "Parallel distributed processing",
            "rating": 2,
            "sanitized_title": "parallel_distributed_processing"
        },
        {
            "paper_title": "Minimization of Boolean complexity in human concept learning",
            "rating": 2,
            "sanitized_title": "minimization_of_boolean_complexity_in_human_concept_learning"
        },
        {
            "paper_title": "Bootstrapping in a language of thought: a formal model of numerical concept learning",
            "rating": 2,
            "sanitized_title": "bootstrapping_in_a_language_of_thought_a_formal_model_of_numerical_concept_learning"
        },
        {
            "paper_title": "A Rational Analysis of Rule-Based Concept Learning",
            "rating": 2,
            "sanitized_title": "a_rational_analysis_of_rulebased_concept_learning"
        },
        {
            "paper_title": "A Computational Study of Cross-Situational Techniques for Learning Word-to-Meaning Mappings",
            "rating": 2,
            "sanitized_title": "a_computational_study_of_crosssituational_techniques_for_learning_wordtomeaning_mappings"
        },
        {
            "paper_title": "Connectionism and cognitive architecture: a critical analysis, Connections and symbols",
            "rating": 2,
            "sanitized_title": "connectionism_and_cognitive_architecture_a_critical_analysis_connections_and_symbols"
        },
        {
            "paper_title": "Introduction to Combinators and λ-calculus",
            "rating": 1,
            "sanitized_title": "introduction_to_combinators_and_λcalculus"
        },
        {
            "paper_title": "To Mock a Mockingbird: and other logic puzzles including an amazing adventure in combinatory logic",
            "rating": 1,
            "sanitized_title": "to_mock_a_mockingbird_and_other_logic_puzzles_including_an_amazing_adventure_in_combinatory_logic"
        }
    ],
    "cost": 0.01149875,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Compositional Reasoning in Early Childhood</p>
<p>Steven Piantadosi *spiantado@gmail.com 
Department of Brain and Cognitive Sciences
University of Rochester
RochesterNYUnited States of America</p>
<p>Richard Aslin 
Department of Brain and Cognitive Sciences
University of Rochester
RochesterNYUnited States of America</p>
<p>Compositional Reasoning in Early Childhood
RESEARCH ARTICLE
Compositional "language of thought" models have recently been proposed to account for a wide range of children's conceptual and linguistic learning. The present work aims to evaluate one of the most basic assumptions of these models: children should have an ability to represent and compose functions. We show that 3.5-4.5 year olds are able to predictively compose two novel functions at significantly above chance levels, even without any explicit training or feedback on the composition itself. We take this as evidence that children at this age possess some capacity for compositionality, consistent with models that make this ability explicit, and providing an empirical challenge to those that do not.</p>
<p>Introduction</p>
<p>One of the basic goals of cognitive science is to understand the nature of conceptual representations. Proposals for the format and structure of concepts range through theories based on prototypes [1], exemplars [2,3], language-like representations [4], and others [5]. A central issue for all approaches is that of compositionality-how to handle the combination of individual concepts into more complex representations (e.g. "beautiful" composed with "accordions" yields a composite concept, "beautiful accordions") [6][7][8][9]. This ability may be built "on top" of a representational format like prototypes [10] or it may be intrinsically a part of the core conceptual representation itself, as is hypothesized in language of thought (LOT) theories. According to LOT theories, the formation of a complex thought like "all sailboats are heavy" occurs when thinkers construct the corresponding compositional structure built out of simpler operations. For instance, such a conceptual format may be similar to standard logic: 8x.sailboat(x)! heavy(x). Here, 8, sailboat and heavy are functions that are composed in one particular way to express the composite idea "all sailboats are heavy." These functions may themselves be built out of simpler operations, but in LOT theories eventually this process grounds out in primitive functions from which all other thoughts and representations are derived.</p>
<p>LOT theories are motivated in part by the rich structure human concepts appear to easily represent, as well as by factors like the systematicity, productivity, and compositionality of cognition [11]. Indeed, the LOT has a rich history in cognitive science, dating back at least to Boole [12] and later Frege [13]. Boole sought to characterize the "laws of thought" and did so by postulating the formal logical system of Boolean logic, which builds logical representations (formulas) out of the logical primitives and, or, and not. More recent incarnations of LOT theories have argued specifically for compositional, symbolic representations as fuller cognitive theories encompassing a wider range of semantic and logical operations [4]. A structured LOT has also been argued to explain developmental change in concept and language learning [14][15][16][17][18][19][20][21], providing a convenient formalism to express both what learners bring to learning tasks (primitive functions), and what exactly they acquire (compositions of those functions to explain observed data). For instance, Piantadosi et al. [21] suggest that children may know about simple functions on sets (e.g. union, intersection, etc.) and build more complex representations of cardinality and counting by appropriately composing these operations. This type of general approach builds on work of Feldman [22] who used a compositional system to explain patterns in Boolean concept learning, and Siskind [14] who first developed a compositional account of learning semantics. Following Goodman et al. [16], many recent theories posit rational (Bayesian) statistical models as the core inductive mechanism that decides between possible combinations of primitives in the face of data. In all cases-dating back to Boole-the core claim is that composition of simple primitive functions is what allows for the creation of complex cognitive representations.</p>
<p>While learning studies and modeling work have established LOT-based models as plausible in principle, no experimental work has examined LOT models' most basic assumptions: learners should be able to represent functions and combine them through composition. This ability should be present without any explicit instruction on either the fact that functions can be composed, or what happens when they are composed. This ability is not trivial. Functions may perform many kinds of operations and in principle function combination can be used to express arbitrary computation [23][24][25].</p>
<p>To be clear, we focus here on conceptual compositionality (combinations of concepts), not linguistic compositionality (combinations of words in sentences), which has been studied previously [26][27][28][29]. The reason for this is that acquisition models have so far focused on learning either individual word meanings by composing simpler conceptual elements [14] or using compositional LOT systems to learn non-linguistic systems of concepts like magnetism [19]. In these cases, the learning models therefore make the strong prediction that children should be able to compose operations outside of the domain of language. Note that an ability to compose linguistic expressions does not establish that children will be able to compose conceptual operations; the compositionality of linguistics may or may not be encapsulated within language processing. The present work takes a first step towards investigating non-linguistic conceptual combination in children.</p>
<p>Of course, it is important to note that many tasks can be interpreted as compositional, depending on how they are formalized. Even, for instance, Sally-Ann [30] or simple numerical tasks with infants [31] require multiple updates to a representation, and therefore can be phrased as compositions of functions. Here, however, we approach compositionality from a more directed stance, constructing an experiment that is difficult to interpret in any way but compositional. The general logic of our experiment is to teach children that certain "screens" (occluders) cause specific feature changes (color or pattern) to an occluded object. The critical test conditions occur when two such screens are adjacent and children observe an object go behind both screens but they do not observe it between screens. Prediction of the correct outcome in this case requires them to apply both object transformations. Children receive no feedback on their responses to the compositional (two-screen) trials, meaning that success is indicative of automatic compositional reasoning without instruction or encouragement.</p>
<p>This experiment tests whether children can compute a composition of functions like f 2 (f 1 (x)), where f 2 is the second screen and f 1 is the first. However, there is a stronger sense in which learners might "know" compositionality: they might be able to form an explicit symbol h = f 2 (f 1 (x)) for the composition itself. Creating such a symbol is not a necessary ability for success on our task. In a linguistic analogy, the strong form of compositionality is tantamount to knowing that the term (symbol) "pit stop" refers to "refueling" and "changing tires." The weaker form corresponds to being able to refuel and then change tires, without knowing that there is a term or symbol that refers to the combination of both operations. Because we are just beginning to explore the type of compositional reasoning in a non-linguistic task, we start by investigating the developmental origins of the weaker sense: can preschoolers predictively compose novel operations? Or, do they show catastrophic failures when attempting to combine multiple functions, perhaps reminiscent of younger children's limitations with multiple updates to representations of objects or numerosity [32][33][34]?</p>
<p>Methods</p>
<p>In the experiment, preschoolers were shown displays on a touchscreen monitor in which a car with a colored pattern appeared. Cars had one of two patterns (dots/stars) occurring in one of two colors (red/blue). A car with one choice of these features drove on-screen and children were required to select which pattern it matched from a menu with all four possible options (Fig 1a). This ensured that they attended to the features of the cars and knew them at the start of each trial. For this response, children were required to respond until they answered correctly, with incorrect responses penalized by a buzzing noise and correct responses rewarded by a trumpet sound. The car then drove behind a single screen, making its pattern (but not wheels) occluded (Fig 1b). It jiggled behind the screen to indicate that a transformation was taking place. Children then responded with what they expected the car to look like when the screen lifted.</p>
<p>The experiment began with 6 explicit training trials in which children were provided with verbal feedback and instruction on the operation provided by each of the screens. Participants then entered an second training phase in which they received no verbal feedback from the experimenter, but were required to answer single-screen trials until correct, at which time the screen lifted to reveal the correct outcome (Fig 1c). Presentation of operations in this phase was in blocks of 6 single operations (red, blue, dots, stars, and two with no changes, in random order).</p>
<p>Children stayed in the training phase until they answered 5 out of 6 correct in a block. After meeting this criterion, the experiment progressed to a test phase. Here, children were shown blocks containing 2 single screen displays with feedback, and 4 two-screen displays without feedback (Fig 1d). In these critical trials, children observed the car pass behind one screen, then the next, without seeing it in between. As in training, they were required to answer correctly to the first question on the car's initial pattern, but crucially received no feedback on their selected outcome after the car had passed behind both screens. The screens never lifted to reveal the car after selection and the experiment simply progressed to the next trial.</p>
<p>Screens were chosen to be iconic of the color and pattern transformations because we are primarily interested in how children combine these operations when they know them, not how hard it is for children to learn each individual function. However, sometimes the screen would not cause a change-for instance, if a car with blue dots drove behind a blue screen. These trials were included in order to ensure that children really paid attention to the pattern on the screens and did not just "flip" the relevant dimension. We refer to transformations in which a feature changed (e.g. red car behind blue screen) as change (CH) screens, and transformations which did not change a feature (e.g. blue car behind blue screen) as identity (ID) screens.</p>
<p>Children were run in the experiment for a maximum of approximately 30 minutes, and were shown a short "reward" animation every three responses in order to keep the experiment interesting. Stimuli were presented using Kelpy, the Kid Experimental Library in Python, which is available under the GNU Public License from the first author [35]. This study was approved by the University of Rochester Research Subjects Review Board. Written informed consent was gathered from parents/guardians of the children involved.</p>
<p>Participants</p>
<p>Twenty-one children (10 females and 11 males) aged approximately 3.5-4.5 years (mean: 50.9 months; range: 42.9 to 53.9 months) were recruited to the Rochester Baby Lab. In order to assess overall levels of performance, all subjects were included in the following analysis, although two did not progress out of training.  subject intercepts and slopes by function type [36]. This type of analysis is well-suited to unbalanced designs where children have been run for varying amounts of test and training items. The red line corresponds to a chance rate of 25%, for guessing at random from the four possible choices. This figure shows that in each condition children are substantially above chance on single screen displays. They thus learned the operations performed by each iconic screen. However, children are not very good at this task-their overall accuracy is near 50%. This likely results from the fact that the task is somewhat complex, requiring tracking of multiple values of multiple dimensions.</p>
<p>Results</p>
<p>Critical two-screen test trials are shown in Fig 3. Again, error bars were computed via a mixed effect logistic regression with subject intercepts by function type (a model with random slopes did not converge). First, this figure shows that the overall mean response (teal bar) is substantially higher than the chance rate of 25%. The overall accuracy is also only slightly worse than the overall accuracy on single screen displays, meaning that knowledge of compositions is available to learners after training on single screens despite the fact that feedback was never provided on these two-screen trials. The other bars in this plot show performance broken down by the type of function performed by each of the two screens. Despite above chance performance overall, children are at chance in conditions involving feature changes within the same dimension (e.g. CH-Color/ CH-Color). In such a condition, a red circle car would go behind a blue screen (changing its color) and then behind a red screen (changing its color again). This requires keeping track of several different values within the same dimension, and-because the features are binary-realizing that a feature changes and then reverts back to its original value. Note that children are not just having difficulty in this condition in tracking the order in which the functions applied: that would predict 50% performance in these conditions (since children would have the other dimension right). Instead, it appears that children's performance breaks down completely in this case, not unlike total breakdowns seen in object tracking [32][33][34].</p>
<p>These detailed patterns of responses also rule out several other hypotheses about children's performance. First, it is clear that children are not above chance by merely applying one of the two screens. Such a tactic would predict 0% accuracy on conditions with two changes (e.g. CH-Color-CH-Pattern and CH-Pattern-CH-Shape) since application of only one screen would always give the wrong answer. Instead, children performed particularly well in these two conditions, with a mean accuracy of nearly 50%, trending above even the overall experiment mean. Responses in these conditions are each individually significantly above the 25% chance level (CH-Color-CH-Pattern accuracy is 50%, p = 0.003 when compared to chance; CH-Pattern-  CH-Color is 55%, p = 0.002 when compared to chance). Children's success in these conditions provides strong evidence that they do not simply choose one box to apply.</p>
<p>Moreover, children's performance surpasses their expected performance based on their ability to apply single screens. The blue dots in Fig 3 show the performance that would be expected if children's accuracy was determined by independent application of each function, with individual function accuracies determined by the performance on single boxes. Thus, the blue dot for CH-Color/CH-Pattern corresponds to the probability of success on a CH-Color operation followed by the probability of success on a CH-Pattern operation, according to Fig 2. Because the accuracies in Fig 2 are near 50% for each function type, application of two of these correctly is near 25%(= 0.5 Á 0.5). Across nearly all function types other than changes within the same dimension, children are substantially above this performance level. This suggests that their failures are not due to independent failures on each screen. This pattern could occur if, for instance, children's low accuracy in Fig 2 was driven by not paying attention on all trials, rather than not knowing the right answer.</p>
<p>Responses were also analyzed using a mixed-effect logistic regression [36] with intercepts by subject (a model with random slopes did not converge). This analysis lets us simultaneously evaluate the influence of multiple factors of children's response accuracies, and determine their mean accuracy while controlling these factors. Fig 4 shows estimated coefficients and standard errors. The coefficients here correspond to whether the first function is an identity function (Identity F1), the second is an identity (Identity F2; this is computed as whether the second function is an identity function on the output of the first function), the first change is a color dimension (IsColor F1), the second is the same feature dimension as the first (SameDimension), children's age, whether the child is male, the child's training accuracy, the number of items it took the child to progress on to testing, and the number of test items seen so far. The binary predictors here (Identity F1, Identity F2, IsColor F1, SameDimension, IsMale) are all negative sum coded and the continuous predictors are all standardized, meaning that the intercept can be interpreted as the mean response accuracy across all predictors. In this figure, coefficients far from the zero line indicate significant influences on response accuracy. This shows that there are three significant predictors: children are substantially worse when both boxes operate on the same dimension (SameDimension) (β = −0.50,z = −4.23,p &lt; 0.001). This means that when the first box changes a color, children are worse when the second box also changes a color, and analogously when both boxes change pattern. Children are worse when they take longer to reach testing (β = −0.25, z = 2.14, p = 0.03). Children with better training accuracy also perform better on testing (β = 0.54, z = 4.40, p &lt; 0.001). Importantly, the intercept here represents the mean accuracy controlling for all other effects. This shows that the intercept (β = −0.19) is significantly higher than the chance rate logit(0.25) shown by the red dot in the graph (p &lt; 0.001), indicating that children are substantially above the chance guessing rate. They are not, however, significantly different from 50% accuracy (p = 0.15). These results revealed no significant effect of age, indicating that we have no evidence older children are better at this task. This might suggest that such compositional reasoning is attained earlier than about 3.5 years of age so that children in the range 3.5 * 4.5 are not differentially capable of dealing with composition.</p>
<p>We additionally analyzed the pattern of errors children made in their responses. To do this, we looked only at incorrect responses and tried to predict which components of an incorrect response children were likely to get correct. In a mixed effect regression, we found that these responses were substantially more likely to provide a response with the second screen correctly applied rather than the first (β = 1.15, z = 4.946, p &lt; 0.001). This effect was independent of whether the first and second screens were colors or not (|β|&lt;0.1, z &lt; 0.5, p &gt; 0.65). This suggests that children's difficulty with composition may be in tracking or encoding the features of the car and the first screen while focusing on the second, temporally more recent, screen.</p>
<p>Discussion</p>
<p>These results provide evidence that preschoolers spontaneously infer the outcome of combinations of function applications after receiving training on only the individual pieces. Their performance on two screen displays-though not perfect-is comparable to their performance on single screen displays. These results suggest that knowledge of composition does not require training for preschoolers beyond learning the individual pieces: children at this age have already learned how to predictively combine operations. This does not mean that children have never required instruction (or data) for learning about composition, but it does mean that whatever they have learned before the experiment began is abstract enough to apply to novel functions.</p>
<p>It is worth noting that while our experiments were motivated by compositionality, there are likely non-compositional models that could capture these results. For instance, children may learn that each screen constrains the possible outcomes, and combine constraints in order to predict the outcome. The challenge for these theories would be to state combination in a way that cannot be viewed (or perhaps cannot be viewed naturally) as function composition. There are also challenging data points for such theories even in this simple experiment: for instance, they would have a difficult time explaining why children are below 50% on within-dimension CH/CH trials, a fact that almost certainly depends on the details of how constraints may be combined. Stronger results could likely be provided by displays with more features and operations in order to fully probe the extent of children's ability and distinguish alternative models. We therefore take our results as a first step that provides suggestive-not definitive-evidence for compositionality.</p>
<p>Our analysis revealed some subtle facts about which compositions are easy and difficult for young learners. Changes within the same feature dimension are difficult, but two changes across dimensions are as easy as one. The limitation within dimensions presents a challenge to the purest form of compositional theories: what type of mechanism could correctly compose, but only when the composed functions operate on separate feature dimensions? One theory is that setting a feature value in memory is slow. Thus, when the value of two features change rapidly, children may get confused about what the resulting value is. On the other hand, if one feature changes and then a different feature changes, both "write" processes can occur in parallel and not interfere with each other. Difficulties dealing with rapidly sequential updates to a variable are common in parallel programming in computer science, (resulting in a so-called race condition). This view is consistent with the pattern of children's errors, where it appears that the transformation of the first screen is most likely to get overwritten or lost.</p>
<p>Interestingly, however, children's performance is also below 50%, indicating that their failure is perhaps more than a problem with remembering both screens. It is more likely to be a complete breakdown, because forgetting a single screen would still give 50% performance in the two-screen trials (since half the time, one will be an identity screen). This may indicate that memory mechanisms are fundamentally incapable of tracking multiple updates to the same feature dimension, perhaps because two rapid updates interfere in a particularly destructive way.</p>
<p>In the introduction, we discussed two forms of compositionality corresponding to whether learners explicitly represent a combination of functions f 2 ⚬ f 1 or whether they merely have the capacity to successively apply them to a representation f 2 (f 1 (x)). The present experiment does not strongly distinguish between these possibilities; it is possible that children only track the object moving behind the screens, successively updating its visual features (corresponding to f 2 (f 1 (x))). It is also possible that children could explicitly know that two screens together can be chunked into a single unit, the function f 2 ⚬ f 1 . These possibilities might be disentangled by future work where children's ability to treat compositional functions as single units (e.g. in other compositions) could be evaluated.</p>
<p>In addition to demonstrating compositional ability, these results also suggest that children aged 3.5 * 4.5 are able to represent functions, not itself a trivial capacity. In particular, to perform above chance children must be able to represent the fact that each of four screens performs a particular change to an object's features, and that that change occurs even if the outcome is not directly observed. Such an ability to represent functions themselves might be viewed as an even more basic ability than compositionality. However, fluency with functions can only yield more complex computations if those functions can be combined to form novel combinations-which our results indicate preschoolers are likely able to do.</p>
<p>We consider this capacity for representing functions themselves as potentially a basic fact about the organization of cognitive computation. In modern computer systems, encapsulated functions play a critical role by allowing complex computations to efficiently and easily be built from simpler components. For instance, programs are constructed only out of simpler elementary operations (e.g. +, −, Á, /, for, if, etc.) which are eventually directly interpretable by the computer's hardware. Using only these kinds of primitive functions, one can create a structure implementing a more complex computation, like f(x) = x Á x Á x+x − (x+1)/x. The capacity to combine such elementary operations in arbitrary ways is extremely powerful, and an ability to manipulate functions themselves potentially allows a huge range of computations to be executed using very little "built in" knowledge (ie. few primitives). Indeed, the simplest computational systems like lambda calculus [23,25] and combinatory logic [24,37] "build in" almost nothing, essentially only the rules of function composition. A striking result in formal logic holds that arbitrary (ie. Turing-complete) computational processes can then be built out of nothing more than this capacity for composition [23]. This means that the ability of children to represent, manipulate, and compose functions may point to how they are able to acquire operations of substantial computational complexity, while requiring only very simple cognitive machinery. In this sense, compositionality may be the key component of LOT theories that allows arbitrarily complex computations to be represented by learners.</p>
<p>Our study was in large part motivated by LOT learning models, but it is also interesting to consider how to interpret these results in the context of larger theoretical divides in cognitive science. It may be productive, for example, to determine how such learning might be captured in connectionist or parallel distribution processing [38] approaches: how might one capture learning of separate functions which can be composed, without requiring any additional training on composition? Is it possible to set up such a system in a way that cannot be interpreted as presupposing compositionality itself? Or, it may be that compositionality is basic enough that, as in LOT theories, it should be assumed as a core computational primitive.</p>
<p>Conclusion</p>
<p>These results are an early step in linking contemporary structured learning models with infant and early childhood experimental studies. An ability to combine novel functions appears to be robustly present by three or four years of age, with children requiring no explicit training on combination once they have learned individual functions. This suggests that learning theories based around assuming compositionality are behaviorally plausible and that a capacity for combining mental operations may be one of the mechanisms that supports children's creation of rich conceptual systems.</p>
<p>Fig 2
2shows mean first response accuracies to single screen trials, broken down by each type of function: change (CH) color, change pattern, identity (ID) color, identity pattern. Means and standard errors were computed using a mixed effect logistic regression, taking into account</p>
<p>Fig 1 .
1The four phases of the experiment. First, a truck is observed (a) and children are required to touch which pattern of the four possible patterns in the box matches the car. The response of the first pattern on the car stays on the screen (right box in (b)) and the car moves behind a screen with an iconic representation of its operation. Children are then asked to predict the outcome with a new set of four choices on the left (b). In training trials (b), children answer until they are correct and then see the screen lift to reveal the car with the new pattern (c). The critical response in test trials is shown in (d), with the car occluded after passing behind two screens. No feedback is provided on these trials. doi:10.1371/journal.pone.0147734.g001</p>
<p>Fig 2 .
2Mean response accuracies to single screens which performed change (CH) or identity (ID) operations. A chance rate of 25% is shown by the dotted red line. doi:10.1371/journal.pone.0147734.g002</p>
<p>Fig 3 .
3Mean response accuracies to double screens, each of which performed change (CH) or identity (ID) operations. Error bars show confidence intervals. A chance rate of 25% is shown by the dotted red line. The blue dots correspond to the accuracy predicted under independent application of the single function accuracies in Fig 2.</p>
<p>doi:10.1371/journal.pone.0147734.g003</p>
<p>Fig 4 .
4Coefficients in a mixed-effect logistic regression predicting accuracy on test (two-screen) trials from a number of predictors. There intercept here, representing the mean accuracy, should be compared to the chance rate of 1/4 (red dot, at logit(0.25) on this scale), the overall chance guessing rate for 4 options. All other coefficients should be compared to the x = 0 line, showing whether they had a statistically significant influence on response accuracy. Effects significant at p &lt; 0.05) are shown with gray bars. doi:10.1371/journal.pone.0147734.g004
PLOS ONE | DOI:10.1371/journal.pone.0147734 September 2, 2016
AcknowledgmentsThis work benefited greatly from discussions with Roman Feiman, Celeste Kidd, Noah Goodman, and members of AKlab. Children were run with the help of Holly Palmeri and the Rochester Babylab RAs. Research reported in this publication was supported by the Eunice Kennedy Shriver National Institute Of Child Health &amp; Human Development of the National Institutes of Health under Award Number F32HD070544 and an NIH research grant to R. Aslin and E. Newport (HD-037082). The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Institutes of Health.
Family resemblances: Studies in the internal structure of categories. E Rosch, C B Mervis, 10.1016/0010-0285(75)90024-9Cognitive psychology. 74Rosch E, Mervis CB. Family resemblances: Studies in the internal structure of categories. Cognitive psychology. 1975; 7(4):573-605. doi: 10.1016/0010-0285(75)90024-9</p>
<p>Context theory of classification learning. D L Medin, M M Schaffer, 10.1037/0033-295X.85.3.207Psychological review. 853Medin DL, Schaffer MM. Context theory of classification learning. Psychological review. 1978; 85 (3):207-238. doi: 10.1037/0033-295X.85.3.207</p>
<p>The exemplar view. Foundations of cognitive psychology: Core readings. E E Smith, D L Medin, Smith EE, Medin DL. The exemplar view. Foundations of cognitive psychology: Core readings. 2002; p. 277-292.</p>
<p>The language of thought. J A Fodor, Harvard University PressCambridge, MAFodor JA. The language of thought. Cambridge, MA: Harvard University Press; 1975.</p>
<p>Concepts: Core Readings. E Margolis, S Laurence, The MIT PressCambridge, MAMargolis E., Laurence S. Concepts: Core Readings. Cambridge, MA: The MIT Press; 1999.</p>
<p>On the adequacy of prototype theory as a theory of concepts. D N Osherson, E E Smith, 10.1016/0010-0277(81)90013-5Cognition. 91Osherson DN, Smith EE. On the adequacy of prototype theory as a theory of concepts. Cognition. 1981; 9(1):35-58. doi: 10.1016/0010-0277(81)90013-5 PMID: 7196818</p>
<p>Conceptual combination with prototype concepts. E E Smith, D N Osherson, 10.1207/s15516709cog0804_2Cognitive Science. 84Smith EE, Osherson DN. Conceptual combination with prototype concepts. Cognitive Science. 1984; 8 (4):337-361. doi: 10.1207/s15516709cog0804_2</p>
<p>Prototype theory and compositionality. H Kamp, B Partee, 10.1016/0010-0277(94)00659-98556840Cognition. 572Kamp H, Partee B. Prototype theory and compositionality. Cognition. 1995; 57(2):129-191. doi: 10. 1016/0010-0277(94)00659-9 PMID: 8556840</p>
<p>The red herring and the pet fish: Why concepts still can't be prototypes. J Fodor, E Lepore, 10.1016/0010-0277(95)00694-XCognition. 582Fodor J, Lepore E. The red herring and the pet fish: Why concepts still can't be prototypes. Cognition. 1996; 58(2):253-270. doi: 10.1016/0010-0277(95)00694-X PMID: 8820389</p>
<p>Combining prototypes: A selective modification model. Cognitive Science. E E Smith, D N Osherson, L Rips, M Keane, 10.1207/s15516709cog1204_112Smith EE, Osherson DN, Rips L, Keane M. Combining prototypes: A selective modification model. Cog- nitive Science. 1988; 12(4):485-527. doi: 10.1207/s15516709cog1204_1</p>
<p>Connectionism and cognitive architecture: a critical analysis, Connections and symbols. A Cognition Special Issue. J Fodor, Z W Pylyshyn, Pinker S and Mehler JFodor J, Pylyshyn ZW. Connectionism and cognitive architecture: a critical analysis, Connections and symbols. A Cognition Special Issue, Pinker S and Mehler J (eds). 1988; p. 3-71.</p>
<p>An investigation of the laws of thought: on which are founded the mathematical theories of logic and probabilities. G Boole, Walton and MaberlyLondon, UKBoole G. An investigation of the laws of thought: on which are founded the mathematical theories of logic and probabilities. London, UK: Walton and Maberly; 1854.</p>
<p>Über sinn und bedeutung. G Frege, Wittgenstein Studien. 18921Frege G. Über sinn und bedeutung. Wittgenstein Studien. 1892; 1(1).</p>
<p>A Computational Study of Cross-Situational Techniques for Learning Word-to-Meaning Mappings. J M Siskind, 10.1016/S0010-0277(96)00728-7Cognition. 61Siskind JM. A Computational Study of Cross-Situational Techniques for Learning Word-to-Meaning Mappings. Cognition. 1996; 61:31-91. doi: 10.1016/S0010-0277(96)00728-7</p>
<p>Modeling semantic cognition as logical dimensionality reduction. Y Katz, N D Goodman, K Kersting, C Kemp, J B Tenenbaum, Proceedings of Thirtieth Annual Meeting of the Cognitive Science Society. Thirtieth Annual Meeting of the Cognitive Science SocietyKatz Y, Goodman ND, Kersting K, Kemp C, Tenenbaum JB. Modeling semantic cognition as logical dimensionality reduction. In: Proceedings of Thirtieth Annual Meeting of the Cognitive Science Society; 2008.</p>
<p>A Rational Analysis of Rule-Based Concept Learning. N D Goodman, J B Tenenbaum, J Feldman, T L Griffiths, 10.1080/0364021070180207121635333Cognitive Science. 321Goodman ND, Tenenbaum JB, Feldman J, Griffiths TL. A Rational Analysis of Rule-Based Concept Learning. Cognitive Science. 2008; 32(1):108-154. doi: 10.1080/03640210701802071 PMID: 21635333</p>
<p>Advances in neural information processing systems. C Kemp, N D Goodman, J B Tenenbaum, 20Learning and using relational theoriesKemp C, Goodman ND, Tenenbaum JB. Learning and using relational theories. Advances in neural information processing systems. 2008; 20:753-760.</p>
<p>Learning a theory of causality. N D Goodman, T D Ullman, J B Tenenbaum, Proceedings of the 31st annual conference of the cognitive science society. the 31st annual conference of the cognitive science societyGoodman ND, Ullman TD, Tenenbaum JB. Learning a theory of causality. In: Proceedings of the 31st annual conference of the cognitive science society; 2009. p. 2188-2193.</p>
<p>Theory Acquisition as Stochastic Search. T D Ullman, N D Goodman, J B Tenenbaum, Proceedings of thirty second annual meeting of the cognitive science society. thirty second annual meeting of the cognitive science societyUllman TD, Goodman ND, Tenenbaum JB. Theory Acquisition as Stochastic Search. In: Proceedings of thirty second annual meeting of the cognitive science society; 2010.</p>
<p>Learning and the language of thought. MIT. S T Piantadosi, Piantadosi ST. Learning and the language of thought. MIT; 2011. Available from: http://colala.bcs. rochester.edu/papers/piantadosi_thesis.pdf.</p>
<p>Bootstrapping in a language of thought: a formal model of numerical concept learning. S T Piantadosi, J B Tenenbaum, N D Goodman, 10.1016/j.cognition.2011.11.00522284806Cognition. 123Piantadosi ST, Tenenbaum JB, Goodman ND. Bootstrapping in a language of thought: a formal model of numerical concept learning. Cognition. 2012; 123:199-217. doi: 10.1016/j.cognition.2011.11.005 PMID: 22284806</p>
<p>Minimization of Boolean complexity in human concept learning. J Feldman, 10.1038/3503658611034211Nature. 4076804Feldman J. Minimization of Boolean complexity in human concept learning. Nature. 2000; 407 (6804):630-633. doi: 10.1038/35036586 PMID: 11034211</p>
<p>An unsolvable problem of elementary number theory. A Church, 10.2307/2371045American journal of mathematics. 582Church A. An unsolvable problem of elementary number theory. American journal of mathematics. 1936; 58(2):345-363. doi: 10.2307/2371045</p>
<p>On the building blocks of mathematical logic. From Frege to Gödel. M Schönfinkel, Schönfinkel M. On the building blocks of mathematical logic. From Frege to Gödel. 1967; p. 355-366.</p>
<p>Introduction to Combinators and λ-calculus. J R Hindley, J P Seldin, Cambridge, UKPress Syndicate of the University of CambridgeHindley JR, Seldin JP. Introduction to Combinators and λ-calculus. Cambridge, UK: Press Syndicate of the University of Cambridge; 1986.</p>
<p>The acquisition of prenominal modifier sequences. E H Matthei, 10.1016/0010-0277(82)90018-XCognition. 113Matthei EH. The acquisition of prenominal modifier sequences. Cognition. 1982; 11(3):301-332. doi: 10.1016/0010-0277(82)90018-X PMID: 7199414</p>
<p>Compositionality and Statistics in Adjective Acquisition: 4-Year-Olds Interpret Tall and Short Based on the Size Distributions of Novel Noun Referents. Child development. D Barner, J Snedeker, 10.1111/j.1467-8624.2008.01145.x1848941579Barner D, Snedeker J. Compositionality and Statistics in Adjective Acquisition: 4-Year-Olds Interpret Tall and Short Based on the Size Distributions of Novel Noun Referents. Child development. 2008; 79 (3):594-608. doi: 10.1111/j.1467-8624.2008.01145.x PMID: 18489415</p>
<p>Blue car, red car: Developing efficiency in online interpretation of adjective-noun phrases. A Fernald, K Thorpe, V A Marchman, 10.1016/j.cogpsych.2009.12.00220189552Cognitive psychology. 603Fernald A, Thorpe K, Marchman VA. Blue car, red car: Developing efficiency in online interpretation of adjective-noun phrases. Cognitive psychology. 2010; 60(3):190-217. doi: 10.1016/j.cogpsych.2009. 12.002 PMID: 20189552</p>
<p>30-month-olds use the distribution and meaning of adverbs to interpret novel adjectives. K Syrett, J Lidz, 10.1080/15475440903507905Language Learning and Development. 64Syrett K, Lidz J. 30-month-olds use the distribution and meaning of adverbs to interpret novel adjec- tives. Language Learning and Development. 2010; 6(4):258-282. doi: 10.1080/15475440903507905</p>
<p>Beliefs about beliefs: Representation and constraining function of wrong beliefs in young children's understanding of deception. H Wimmer, J Perner, 10.1016/0010-0277(83)90004-56681741Cognition. 131Wimmer H, Perner J. Beliefs about beliefs: Representation and constraining function of wrong beliefs in young children's understanding of deception. Cognition. 1983; 13(1):103-128. doi: 10.1016/0010-0277 (83)90004-5 PMID: 6681741</p>
<p>Addition and subtraction by human infants. K Wynn, 10.1038/358749a01508269Nature. 3586389Wynn K. Addition and subtraction by human infants. Nature. 1992; 358(6389):749-750. doi: 10.1038/ 358749a0 PMID: 1508269</p>
<p>Ten-month-old infants' intuitions about addition. Unpublished manuscript. R Baillargeon, K Miller, J Constantino, Urbana, Champaign, IL.University of Illinois atBaillargeon R, Miller K, Constantino J. Ten-month-old infants' intuitions about addition. Unpublished manuscript, University of Illinois at Urbana, Champaign, IL. 1994;.</p>
<p>On the limits of infants' quantification of small object arrays. L Feigenson, S Carey, 10.1016/j.cognition.2004.09.01016260263Cognition. 973Feigenson L, Carey S. On the limits of infants' quantification of small object arrays. Cognition. 2005; 97 (3):295-313. doi: 10.1016/j.cognition.2004.09.010 PMID: 16260263</p>
<p>Seven-month old infants chunk items in working memory. M Moher, A S Tuerk, L Feigenson, 10.1016/j.jecp.2012.03.00722575845Journal of Experimental Child Psychology. 112Moher M, Tuerk AS, Feigenson L. Seven-month old infants chunk items in working memory. Journal of Experimental Child Psychology. 2012; 112:361-377. doi: 10.1016/j.jecp.2012.03.007 PMID: 22575845</p>
<p>Kelpy: a free library for child experimentation in python. S T Piantadosi, Piantadosi ST. Kelpy: a free library for child experimentation in python; 2012. available from https:// github.com/piantado/kelpy/.</p>
<p>Data Analysis Using Regression and Multilevel/Hierarchical Models. A Gelman, J Hill, Cambridge University PressCambridge, UKGelman A, Hill J. Data Analysis Using Regression and Multilevel/Hierarchical Models. Cambridge, UK: Cambridge University Press; 2007.</p>
<p>To Mock a Mockingbird: and other logic puzzles including an amazing adventure in combinatory logic. R M Smullyan, Oxford University PressSmullyan RM. To Mock a Mockingbird: and other logic puzzles including an amazing adventure in com- binatory logic. Oxford University Press; 1985.</p>
<p>Parallel distributed processing. D E Rumelhart, J L Mcclelland, MIT PressCambridge, MARumelhart DE, McClelland JL. Parallel distributed processing. Cambridge, MA: MIT Press; 1986.</p>            </div>
        </div>

    </div>
</body>
</html>