<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2306 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2306</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2306</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-63.html">extraction-schema-63</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <p><strong>Paper ID:</strong> paper-271475890</p>
                <p><strong>Paper Title:</strong> Machine Learning Methods for Geotechnical Site Characterization and Scour Assessment</p>
                <p><strong>Paper Abstract:</strong> Reliable geotechnical site characterization and geohazard assessment are critical for bridge foundation design and management. This paper explores existing and emerging artificial intelligence-machine learning methods (AI-ML) transforming geotechnical site characterization and scour assessment for bridge foundation design and maintenance. The prevalent ML techniques applied for subsurface characterization are reviewed, and step-by-step methodologies for stratigraphy classification, borehole interpretation, geomaterial characterization, and ground modeling are provided. The ML techniques for maximum scour depth prediction are reviewed, and a simple ML methodology is proposed to provide a more reliable tool for scour depth estimation for implementation in practice. Also, a novel deep learning approach, with a detailed implementation description, is recommended for real-time scour monitoring and assessment of existing bridges. The challenges with database design and data processing for ML modeling, model optimization, training and validation, and uncertainty assessments are discussed, and innovative techniques for addressing them are reviewed.</p>
                <p><strong>Cost:</strong> 0.024</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2306.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2306.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>FFNN/MLP (scour)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Feed-Forward Neural Network / Multilayer Perceptron for maximum scour depth prediction</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A classical fully-connected neural network (MLP/FFNN) used as a regression model to predict maximum (design) scour depth from engineered and environmental input features; recommended as a 'simple enough' model with ensemble and transfer learning for improved reliability.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Bridge scour / hydraulic geohazard prediction</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Predict maximum (equilibrium or observed) scour depth around bridge piers/abutments as a function of river/flow conditions, sediment properties and bridge geometry for design and safety assessment.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Limited to moderate; global databases such as the USGS National Bridge Scour Database exist but contain stitched heterogeneous records with statistical/design deficiencies; reliable local/site-specific databases are recommended and often scarce.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Structured tabular data (engineered features: sediment type, bed condition, median grain size D50, flow depth/velocity, scour type), heterogeneous across datasets; mixed categorical and numerical features.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>High nonlinearity and multi-factor dependence (many interacting physical variables); moderate-to-high input dimensionality but datasets often small relative to complexity; extrapolation (out-of-convex-hull) is unreliable.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Applied engineering domain with well-known empirical formulae; ML application is emerging but lacks a single established best model; practical deployment requires engineering oversight.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Medium-high — engineering design requires interpretability, uncertainty bounds and conservative judgment (paper recommends engineering due diligence and using lower bounds where risk is critical); purely black-box predictions are insufficient for final design without validation.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Feed-forward neural network (multilayer perceptron) with ensemble and transfer learning</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>A three-layer MLP (input, one hidden layer with sigmoid activation, output) trained for regression (scour depth). Training uses MSE loss, early stopping (patience), cross-validation (K-fold or Monte Carlo) and ensembles formed by repeated random initializations (+50 runs). Transfer learning: initialize local site model weights from a 'global' model trained on a larger database then fine-tune on local data. Hyperparameters tuned via grid/random search; uncertainty estimated from ensemble spread and confidence bounds.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Supervised learning (regression); ensemble methods; transfer learning</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Applicable and appropriate when a statistically representative local database is available; limited when target inputs lie outside the convex hull of training data; requires careful database statistical design and normalization.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>ML/FFNN approaches show superior fit/accuracy relative to traditional empirical equations on the same training datasets but suffer from poor generalization/extrapolation; ensemble and transfer learning improve reliability when local data are included.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Potential to improve site-specific scour depth estimation and provide uncertainty bounds for design and maintenance decision-making if databases are well-designed and local data are available; could reduce conservative over-design or missed vulnerabilities if validated.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared qualitatively to traditional empirical scour equations: ML yields better accuracy on training data but worse extrapolation; ensemble plus transfer learning recommended to overcome some limitations. No consistent single best ML algorithm for this task reported.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Quality and statistical design of the database (coverage across feature ranges), local data for transfer learning, ensembles and cross-validation, careful preprocessing and feature selection, and engineering validation.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>FFNNs can model the nonlinear, multi-factor scour process more accurately than empirical formulas within the training domain, but their practical reliability depends critically on representative local data, ensemble uncertainty quantification, and transfer learning.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Machine Learning Methods for Geotechnical Site Characterization and Scour Assessment', 'publication_date_yy_mm': '2025-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2306.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2306.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LSTM (scour timeseries)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Long Short-Term Memory recurrent neural network for real-time scour forecasting</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An RNN variant (LSTM) applied to multivariate time-series monitoring data (scour depth, flow stage, velocity) to forecast future scour depth (e.g., seven days ahead) for realtime risk assessment.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Real-time scour monitoring and early-warning for bridge foundations</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Forecast short-to-medium horizon future scour depth at monitored bridges using historical continuous sensor data to enable early warning and operational responses.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Site-specific historical sensor timeseries; typically limited to single-bridge records; sensors produce continuous but noisy data with common missing intervals; monitoring programs exist (USGS, state DOTs) but many bridges lack long histories.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Multivariate time series (regularly sampled): sonar/sonic scour depth, flow stage (water level), flow velocity; may include exogenous inputs (meteorological/flood forecasts).</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Temporal dependencies with multiple time scales (hours to days); noise, missing data, and occasional sensor failure; nonlinear temporal dynamics influenced by boundary conditions (floods) making forecasting challenging.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Monitoring networks and physical understanding of scour are established; application of DL (LSTM) to operational forecasting is emerging and promising with demonstrated case studies.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Medium — forecasts are used for operational decisions; interpretability less critical than reliability and uncertainty quantification, but model outputs must be judged alongside physical/flood forecasts and historical trends.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>LSTM RNN (timeseries forecasting)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>LSTM networks trained on sliding-window data slices (input sequence and label/forecast segment). Preprocessing includes denoising (MAD), imputation for missing data (linear interpolation or Gaussian process), smoothing/low-pass filtering, and normalization. Training uses batches of sequences, hyperparameter tuning (input/label width, layers, units, learning rate), sequential K-fold cross-validation with transfer learning, and ensemble/overlap-based uncertainty estimation.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Supervised learning — sequence forecasting (deep learning, recurrent networks)</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Highly applicable for bridges instrumented with continuous monitoring sensors and adequate historic records; powerful for site-specific forecasting but limited where monitoring data are unavailable.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td>Reported case studies on Alaskan bridges: LSTM variants provided 7-day-ahead scour forecasts with average error between 0.20 and 0.35 m.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>LSTMs produced accurate short-term forecasts in case studies and outperformed empirical equations in those site-specific scenarios; sensitivity to sensor noise and missing data requires careful preprocessing and validation.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>High for operational risk management: provides early warnings, helps prioritize inspections/closures, and enables data-driven mitigation; transfers well to other monitored bridges in similar regions.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared to empirical scour models — LSTM outperforms in site-specific forecasting; compared to CNN temporal models — CNNs showed competitive accuracy with substantially lower computational cost.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Availability of continuous, quality sensor data; robust preprocessing (outlier detection, imputation, filtering); appropriate sliding-window configuration; ensemble and cross-validation strategies; combining forecasts with engineering/flood information.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>When adequate site-specific monitoring data exist, LSTMs can reliably forecast scour several days ahead with actionable accuracy, but success depends on careful data preprocessing and explicit uncertainty estimation.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Machine Learning Methods for Geotechnical Site Characterization and Scour Assessment', 'publication_date_yy_mm': '2025-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2306.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2306.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Temporal CNN (scour)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Convolutional Neural Network applied to temporal (timeseries) scour forecasting</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A temporal CNN architecture applied to timeseries sonar and stage data for computationally efficient real-time scour forecasting with competitive accuracy to LSTM in case studies.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Real-time scour forecasting / timeseries prediction</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Forecast scour depth from multivariate time-series sensor data with lower computational cost than RNN-based approaches.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Same as LSTM: site-specific continuous monitoring records, often limited length and noisy.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Multivariate time series (regularly sampled) — input and label windows formed via sliding window.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Temporal dependencies that can be learned by causal convolutions; similar challenges to LSTM (noise, missing data).</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Emerging — temporal CNNs have been trialed and show promise as a lighter-weight alternative to LSTM for operational forecasting.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Medium — operational reliability and uncertainty estimation required; interpretability secondary.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Temporal convolutional neural network (CNN) for sequence forecasting</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>CNNs operate on data slices created by sliding window; architecture uses temporal convolutional layers to learn patterns across time steps; trained with supervised regression loss and validated via sequential cross-validation; hyperparameters tuned similarly to LSTM.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Supervised learning — deep learning (convolutional sequence models)</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Applicable where low-latency, lower-compute forecasting is required; competitive with LSTM in Alaskan case studies per the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Temporal CNNs achieved competitive performance to LSTM on Alaskan bridge data with a substantially lower computational cost, making them attractive for real-time deployment.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Enables scalable, lower-cost operational forecasting on embedded or constrained systems while maintaining forecast accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared qualitatively to LSTM: similar predictive performance but lower computational cost; both outperform empirical equations in monitored, site-specific contexts.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Good quality timeseries slices, careful hyperparameter tuning, and robust preprocessing (outlier detection, imputation).</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Temporal CNNs can match LSTM forecast accuracy on monitored scour timeseries while being more computationally efficient, making them attractive for real-time systems.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Machine Learning Methods for Geotechnical Site Characterization and Scour Assessment', 'publication_date_yy_mm': '2025-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2306.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2306.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>IC-XGBoost2D</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Iterative Convolution XGBoost 2D (stochastic image-based stratigraphy simulation)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An image-based stochastic simulation algorithm that leverages training images (TIs) and iterative convolutional XGBoost to generate 2-D conditional realizations of subsurface stratigraphy and quantify stratigraphic uncertainty.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Subsurface stratigraphic modeling / geological cross-section simulation</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Interpolate and predict discrete stratigraphic classes across a target area from scarce site-specific measurements by learning patterns from training images and conditioning on borehole/outcrop data to produce multiple realizations and uncertainty measures.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Scarce site-specific measurements (few boreholes); supplemented by training images compiled from nearby projects, conceptual models, simulations or experiments — TIs provide prior patterns when data are limited.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>2-D image-like spatial patterns (training images) and sparse conditioning data (borehole logs); categorical stratigraphic classes (discrete labels).</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>High spatial heterogeneity and connectivity constraints; discrete, multimodal patterns; heavy reliance on prior pattern representation (TI); computational complexity arises from conditional sampling across 2-D fields.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Emerging; builds on multiple-point statistics and image-based geostatistics; TI-based stochastic simulations are established in geosciences but their ML hybrids (IC-XGBoost2D) are recent developments.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Medium — geological plausibility of realizations is essential; TI must encode prior geological process knowledge; interpretability of pattern selection important for acceptance by practitioners.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Iterative convolutional XGBoost stochastic simulation</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Uses a data-event template (sliding window) to search compatible patterns from a TI database and constructs empirical CDFs used to sample soil types at unsampled locations; XGBoost (gradient-boosted trees) is applied iteratively with convolutional-like sampling to build 2-D cross-sections conditioned on site data. Ensemble of TIs can be used to represent prior uncertainty.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Hybrid of supervised ML (gradient boosting) and stochastic simulation / generative conditional sampling (image-based geostatistics)</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Appropriate when training images exist to represent expected stratigraphic patterns and site-specific data are sparse; sensitive to TI selection and can produce poor realizations if TI mismatched to site.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Provides a way to leverage prior geological patterns to overcome sparse data, enabling multiple realizations and stratigraphic uncertainty quantification; performance depends greatly on the appropriateness of training images.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Enables probabilistic subsurface models and uncertainty-aware design/analysis when borehole data are limited, improving risk-informed engineering decisions.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared conceptually to multiple-point statistics (MPS): both are image-based; IC-XGBoost2D integrates ML (XGBoost) with convolutional-like pattern retrieval; TI influence diminishes as more site-specific data are available.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Quality and relevance of the training image database, ensemble of TIs to capture alternative geological scenarios, and sufficient conditioning data to reduce TI dominance where possible.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Image-based ML-stochastic hybrids can effectively transfer prior geological patterns (via training images) to conditionally simulate stratigraphy from sparse data, but their reliability hinges on correct TI selection and ensemble approaches to capture prior uncertainty.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Machine Learning Methods for Geotechnical Site Characterization and Scour Assessment', 'publication_date_yy_mm': '2025-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2306.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2306.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BCS (Bayesian Compressive Sampling)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Bayesian Compressive Sampling for spatial interpolation of geo-properties</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A nonparametric compressive-sensing-based machine learning method to reconstruct high-resolution spatial fields (e.g., cone tip resistance) from sparse measurements by representing signals over a limited number of basis functions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Spatial interpolation of geotechnical properties / ground model construction</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Interpolate spatially varying geo-properties (e.g., CPT tip resistance) across a 2-D/3-D cross-section from sparse CPT/borehole measurements to produce high-resolution maps for ground models.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Sparse CPT/borehole measurements typical for engineering sites; geophysical data may supplement but are of differing types/resolutions.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Spatial fields (2-D/3-D) represented as signals that can be approximated with a sparse set of basis functions (e.g., discrete cosine transform coefficients).</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>High-dimensional spatial interpolation with limited samples; requires selection of basis set and regularization; nontrivial inverse reconstruction under noise.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Novel but grounded in compressive sensing and Bayesian inference; applied in recent geotechnical contexts as a promising interpolation approach.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Low-to-medium — outputs are used as inputs to mechanistic analyses, so they must be physically plausible; method itself is more data-driven and probabilistic than mechanistic.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Bayesian compressive sampling (BCS)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Assumes the spatial field can be represented as a sparse linear combination of pre-specified basis functions; Bayesian sparse inference recovers coefficients from sparse noisy measurements, yielding posterior distributions for reconstructed fields; used sequentially with stratigraphic realizations to map property variability per soil unit.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Bayesian nonparametric / compressive-sensing (unsupervised or semi-supervised spatial reconstruction)</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Suited for reconstructing spatially varying geotechnical properties from sparse measurements and for producing multiple realizations for uncertainty quantification in ground models.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Promising for generating high-resolution estimates from limited CPT data and for propagating uncertainty; effectiveness depends on suitability of chosen basis functions and noise levels.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Enables richer, uncertainty-aware ground models that integrate sparse geotechnical measurements into practical engineering workflows, improving design robustness.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Alternative geostatistical interpolation often relies on spatial correlation estimates; BCS bypasses explicit correlation modeling by leveraging sparsity in a basis domain, which can be advantageous with very sparse samples.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Appropriate basis selection, good noise modeling, integration with stratigraphic realizations, and sufficient computational implementation.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>BCS provides a principled Bayesian way to reconstruct spatial geotechnical fields from sparse data by exploiting sparsity in an appropriate basis, enabling uncertainty-aware ground models when conventional geostatistics struggle with limited samples.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Machine Learning Methods for Geotechnical Site Characterization and Scour Assessment', 'publication_date_yy_mm': '2025-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2306.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e2306.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DANN-KHMD + MRF (PyMRF)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Discriminant Adaptive Nearest Neighbor-based K-harmonic Mean Distance classifier combined with Markov Random Field and Gibbs sampling (PyMRF implementation)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A Bayesian framework for automated stratigraphic interpolation and uncertainty quantification that generates initial stratigraphic fields using DANN-KHMD and refines them with Gibbs sampling under a Markov random field contextual model, implemented as 'PyMRF'.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Borehole-based subsurface stratigraphic interpolation and uncertainty quantification</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Infer stratigraphic cross-sections and associated uncertainties automatically from borehole stratigraphy data without relying on training images, suitable for cases with variable stratigraphic complexity.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Relies on borehole stratigraphies collected at site; data requirement (number of boreholes) scales with stratigraphic complexity (more boreholes for complex folded structures).</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Spatial grid elements with categorical stratigraphic labels at borehole locations and unlabeled elsewhere; operates on discrete class labels.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Handling discrete spatial classification with contextual constraints and limited observations; requires sampling from posterior distributions over high-dimensional discrete fields.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Recent methodological development reported by Wei & Wang; implemented in Python (PyMRF) and aimed at practical unsupervised stratigraphic inference.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Medium — aims to provide plausible stratigraphic fields with quantified uncertainty; geological plausibility and contextual constraints are built into the MRF prior.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>DANN-KHMD classifier + Markov Random Field Gibbs sampling (Bayesian machine learning)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Step 1: collect and label borehole stratigraphy. Step 2: generate multiple initial fields using the DANN-KHMD classifier that probabilistically labels unknown elements based on long-range spatial patterns learned from known elements. Step 3: perform Gibbs sampling to update stratigraphic configuration and MRF model parameters iteratively, sampling conditional distributions and updating parameters until convergence. Step 4: generate multiple simulations to quantify stratigraphic uncertainty (information entropy). Implemented in Python as PyMRF.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Bayesian / probabilistic machine learning; unsupervised/semi-supervised spatial classification</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Appropriate for stratigraphic inference when training images are not desired or available; automates initial labeling and accounts for model and stratigraphic uncertainty.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Provides automatic, unsupervised inference of stratigraphic profiles with consideration of both stratigraphic and model uncertainty; advantages include lower computational cost for reasonable initial fields and avoidance of TI reliance.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Can standardize and automate stratigraphic inference workflows, reduce subjectivity, and provide uncertainty quantification for engineering design and risk assessments.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared to TI-based image simulation methods: does not require training images and explicitly models both stratigraphic and model uncertainty; may require adequate borehole density for reliable inference.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Quality and representativeness of borehole data, proper setting of MRF contextual priors, multiple initial fields and convergence criteria, and ability to sample adequate posterior realizations.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Combining a discriminant nearest-neighbor initial labeling with Bayesian MRF Gibbs sampling yields an automated workflow that infers stratigraphy and quantifies uncertainty without the need for external training images, making it valuable where borehole data exist but TIs are unavailable.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Machine Learning Methods for Geotechnical Site Characterization and Scour Assessment', 'publication_date_yy_mm': '2025-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2306.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e2306.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Bayesian NN / MCD / VI</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Bayesian Neural Networks with Variational Inference and Monte Carlo Dropout for uncertainty quantification</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Approaches that integrate Bayesian treatments into neural networks (variational inference or Monte Carlo dropout) to provide predictive distributions (uncertainty estimates) for soil property prediction tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Prediction of geomaterial properties (e.g., compression index, undrained shear strength) with uncertainty quantification</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Provide both point estimates and uncertainty bounds for geotechnical properties predicted from in-situ and laboratory data, enabling reliability assessment of ML-derived predictions.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Moderate-size databases reported in the literature (examples: 241 triaxial tests, 61 block samples in one cited study); overall, geotechnical datasets are often limited and heterogeneous.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Structured tabular data combining CPTU and laboratory measurements; input features include pressures, stresses, CPT measurements, and sample descriptors.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Nonlinear regression under limited/heterogeneous data and measurement noise; need to propagate uncertainty for engineering reliability.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Emerging practice in geotechnical ML; Bayesian NN approaches reported in recent studies to address deterministic ML limitations.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>High — engineering decisions require error bounds and reliability measures; Bayesian approaches provide probabilistic outputs that support safer decisions.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Bayesian neural networks (BNN) with variational inference (VI) and Monte Carlo dropout (MCD)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>BNNs trained using variational inference approximate posterior distributions over weights, producing predictive distributions for outputs; Monte Carlo dropout applied during inference approximates Bayesian model uncertainty by sampling multiple dropout realizations; used to predict compression index and undrained shear strength and to estimate predictive standard deviation.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Bayesian supervised learning / uncertainty-aware deep learning</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Well-suited to geotechnical regression tasks where uncertainty quantification is necessary for engineering risk assessment; requires careful training and appropriate data quality.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Provides reliability estimates and standard deviation of predictions enabling risk-aware use of ML outputs; addresses major limitation of deterministic ML models by allowing reliability evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Improves safety and trust in ML-based geotechnical predictions by supplying uncertainty bounds, thereby supporting engineering decisions and possibly wider adoption.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Improves over deterministic ANN approaches by quantifying prediction uncertainty; Monte Carlo dropout offers a practical approximation when full Bayesian training is expensive.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>High-quality labeled data, correct probabilistic model specification, adequate computational resources for sampling/ensemble inference, and careful validation against unseen data.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>In geotechnical regression tasks where data are limited and safety critical, Bayesian NN methods using VI or MCD provide essential uncertainty estimates that deterministic ML lacks, increasing the method's practical utility.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Machine Learning Methods for Geotechnical Site Characterization and Scour Assessment', 'publication_date_yy_mm': '2025-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2306.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e2306.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ANN + seismic attributes (ground model)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Artificial Neural Network multi-attribute regression mapping seismic attributes to geotechnical properties</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Use of ANNs to map quantitative seismic attributes (e.g., acoustic impedance and derived attributes) into geotechnical properties such as CPT tip resistance to produce 3-D integrated ground models.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Integrated ground/soil model construction combining geophysical and geotechnical data</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Predict geotechnical property distributions (e.g., cone tip resistance) across areas covered by seismic surveys by learning relationships between seismic attributes and point geotechnical measurements.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Joint datasets: seismic reflection volumes (abundant high-resolution data) and sparse calibration sites with CPTU measurements (limited); requires down-sampling and depth conversion steps.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Multimodal: continuous seismic attribute volumes (images/3D grids) plus structured tabular CPTU point measurements; requires mapping from time-domain seismic to depth-domain geotechnical measurements.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>High spatial resolution inference combining different measurement modalities and scales; feature selection and time-depth conversion add complexity.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Applied and maturing; various approaches (geometrical, geostatistical, ML) exist; paper cites ML as most accurate per comparative studies.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Medium — outputs are used for design; geological plausibility and validation against boreholes required.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Artificial Neural Network multi-attribute regression (with genetic algorithm optimization for attribute selection)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Derive quantitative seismic attributes (optimized by genetic algorithms for feature selection), convert time-domain seismic to depth domain, down-sample CPTU data to seismic sample interval, train ANN to regress CPTU q_c from seismic attributes at calibration sites; then predict across seismic volume.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Supervised learning — multimodal regression</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Applicable and effective for large projects where seismic coverage exists and a few calibration CPTs are available; ML approach shown to outperform geometrical and geostatistical approaches in referenced study.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Reported to be the most accurate method among geometric and geostatistical approaches in cited comparative work, enabling more consistent and higher-resolution ground models.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Significant for offshore and large onshore projects: enables mapping of geotechnical properties at site-wide scales, improving foundation design and reducing need for dense borehole campaigns.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared to geometrical and geostatistical approaches: ML/ANN provided most accurate predictions in the cited comparative study (Sauvin et al.).</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Availability of representative seismic attributes, good depth conversion, calibration sites with reliable CPTU data, and robust feature selection (genetic algorithm).</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Integrating abundant seismic attributes with sparse geotechnical measurements via ANNs can yield more accurate, higher-resolution ground models than traditional geometrical or geostatistical methods when properly calibrated.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Machine Learning Methods for Geotechnical Site Characterization and Scour Assessment', 'publication_date_yy_mm': '2025-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2306.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e2306.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Classical ML vs DL (general)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Classical machine learning versus deep learning considerations in geotechnical problems</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A domain-level insight: conventional ML methods (SVM, RF, XGBoost, shallow NN) are generally better suited to small-sample geotechnical tasks, while deep learning (CNNs, RNNs, LSTMs, GNNs) requires large labeled datasets but can capture more complex patterns when data are sufficient.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>General geotechnical / subsurface characterization and geohazard modeling</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Choosing appropriate ML/DL approaches depending on dataset size, data type and task complexity across many geotechnical subproblems (stratigraphy, property prediction, forecasting).</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Geotechnical data are often scarce (from several hundred to ~1000 samples at most) and heterogeneous; benchmark/global datasets exist but are limited.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Varies: structured tabular data, images (training images), time series, graphs (e.g., GNN inputs), and multimodal combinations.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Varies from low-dimensional empirical correlations to complex spatial-temporal processes requiring high-capacity models; data sparsity constrains model choice.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Geotechnical engineering is mature but ML/DL adoption is recent and rapidly growing; no consensus on optimal ML/DL algorithm.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Often medium to high for engineering acceptance; interpretability and uncertainty quantification are important for deployment.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Conventional ML (SVM, RF, XGBoost, GP) vs Deep Learning (CNN, RNN/LSTM, GNN, GAN)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Paper summarizes that classical ML (tree-based, kernel methods, shallow NNs) suits small-sample problems and tabular tasks; DL architectures (CNNs for images, LSTMs for sequences, GNNs for structural data, GANs for generative training images) require larger labeled datasets and often more compute; hybrid strategies (transfer learning, ensembles, TI-based priors) are recommended to mitigate data scarcity.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Supervised/unsupervised deep learning and classical supervised learning; hybrid approaches</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Classical ML is broadly applicable to small datasets common in geotechnics; DL is applicable when large datasets or continuous monitoring data are available (or via transfer learning), or for image/time-series tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Empirical observation: DL dominated by neural networks generally requires large amounts of training data to outperform classical methods; classical ML performs well in small-sample settings.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Guides appropriate method selection in geotechnical applications and motivates database development, transfer learning and hybrid approaches to leverage DL strengths even with limited data.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Paper reports that no single 'optimal' ML/DL algorithm exists; choice depends on data quantity/type and preference for explicit analytical expressions versus black-box modeling.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Matching model capacity to dataset size, using transfer learning and ensembles, careful preprocessing/feature selection, and development of benchmark datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>The effectiveness of ML vs DL in geotechnics is driven primarily by data availability and structure: classical ML is preferable for small, tabular datasets, while DL is advantageous for large image/time-series datasets or when transfer learning can be applied.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Machine Learning Methods for Geotechnical Site Characterization and Scour Assessment', 'publication_date_yy_mm': '2025-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Machine Learning Solutions for Bridge Scour Forecast based on Monitoring Data <em>(Rating: 2)</em></li>
                <li>Towards an AI-Based Early Warning System for Bridge Scour <em>(Rating: 2)</em></li>
                <li>Development of Subsurface Geological Cross-Section from Limited Site-Specific Boreholes and Prior Geological Knowledge Using Iterative Convolution XGBoost <em>(Rating: 2)</em></li>
                <li>Stochastic Stratigraphic Modeling Using Bayesian Machine Learning <em>(Rating: 2)</em></li>
                <li>Prediction of Undrained Shear Strength Using Extreme Gradient Boosting and Random Forest Based on Bayesian Optimization <em>(Rating: 1)</em></li>
                <li>Machine Learning and Landslide Studies: Recent Advances and Applications <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2306",
    "paper_id": "paper-271475890",
    "extraction_schema_id": "extraction-schema-63",
    "extracted_data": [
        {
            "name_short": "FFNN/MLP (scour)",
            "name_full": "Feed-Forward Neural Network / Multilayer Perceptron for maximum scour depth prediction",
            "brief_description": "A classical fully-connected neural network (MLP/FFNN) used as a regression model to predict maximum (design) scour depth from engineered and environmental input features; recommended as a 'simple enough' model with ensemble and transfer learning for improved reliability.",
            "citation_title": "",
            "mention_or_use": "mention",
            "scientific_problem_domain": "Bridge scour / hydraulic geohazard prediction",
            "problem_description": "Predict maximum (equilibrium or observed) scour depth around bridge piers/abutments as a function of river/flow conditions, sediment properties and bridge geometry for design and safety assessment.",
            "data_availability": "Limited to moderate; global databases such as the USGS National Bridge Scour Database exist but contain stitched heterogeneous records with statistical/design deficiencies; reliable local/site-specific databases are recommended and often scarce.",
            "data_structure": "Structured tabular data (engineered features: sediment type, bed condition, median grain size D50, flow depth/velocity, scour type), heterogeneous across datasets; mixed categorical and numerical features.",
            "problem_complexity": "High nonlinearity and multi-factor dependence (many interacting physical variables); moderate-to-high input dimensionality but datasets often small relative to complexity; extrapolation (out-of-convex-hull) is unreliable.",
            "domain_maturity": "Applied engineering domain with well-known empirical formulae; ML application is emerging but lacks a single established best model; practical deployment requires engineering oversight.",
            "mechanistic_understanding_requirements": "Medium-high — engineering design requires interpretability, uncertainty bounds and conservative judgment (paper recommends engineering due diligence and using lower bounds where risk is critical); purely black-box predictions are insufficient for final design without validation.",
            "ai_methodology_name": "Feed-forward neural network (multilayer perceptron) with ensemble and transfer learning",
            "ai_methodology_description": "A three-layer MLP (input, one hidden layer with sigmoid activation, output) trained for regression (scour depth). Training uses MSE loss, early stopping (patience), cross-validation (K-fold or Monte Carlo) and ensembles formed by repeated random initializations (+50 runs). Transfer learning: initialize local site model weights from a 'global' model trained on a larger database then fine-tune on local data. Hyperparameters tuned via grid/random search; uncertainty estimated from ensemble spread and confidence bounds.",
            "ai_methodology_category": "Supervised learning (regression); ensemble methods; transfer learning",
            "applicability": "Applicable and appropriate when a statistically representative local database is available; limited when target inputs lie outside the convex hull of training data; requires careful database statistical design and normalization.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "ML/FFNN approaches show superior fit/accuracy relative to traditional empirical equations on the same training datasets but suffer from poor generalization/extrapolation; ensemble and transfer learning improve reliability when local data are included.",
            "impact_potential": "Potential to improve site-specific scour depth estimation and provide uncertainty bounds for design and maintenance decision-making if databases are well-designed and local data are available; could reduce conservative over-design or missed vulnerabilities if validated.",
            "comparison_to_alternatives": "Compared qualitatively to traditional empirical scour equations: ML yields better accuracy on training data but worse extrapolation; ensemble plus transfer learning recommended to overcome some limitations. No consistent single best ML algorithm for this task reported.",
            "success_factors": "Quality and statistical design of the database (coverage across feature ranges), local data for transfer learning, ensembles and cross-validation, careful preprocessing and feature selection, and engineering validation.",
            "key_insight": "FFNNs can model the nonlinear, multi-factor scour process more accurately than empirical formulas within the training domain, but their practical reliability depends critically on representative local data, ensemble uncertainty quantification, and transfer learning.",
            "uuid": "e2306.0",
            "source_info": {
                "paper_title": "Machine Learning Methods for Geotechnical Site Characterization and Scour Assessment",
                "publication_date_yy_mm": "2025-01"
            }
        },
        {
            "name_short": "LSTM (scour timeseries)",
            "name_full": "Long Short-Term Memory recurrent neural network for real-time scour forecasting",
            "brief_description": "An RNN variant (LSTM) applied to multivariate time-series monitoring data (scour depth, flow stage, velocity) to forecast future scour depth (e.g., seven days ahead) for realtime risk assessment.",
            "citation_title": "",
            "mention_or_use": "mention",
            "scientific_problem_domain": "Real-time scour monitoring and early-warning for bridge foundations",
            "problem_description": "Forecast short-to-medium horizon future scour depth at monitored bridges using historical continuous sensor data to enable early warning and operational responses.",
            "data_availability": "Site-specific historical sensor timeseries; typically limited to single-bridge records; sensors produce continuous but noisy data with common missing intervals; monitoring programs exist (USGS, state DOTs) but many bridges lack long histories.",
            "data_structure": "Multivariate time series (regularly sampled): sonar/sonic scour depth, flow stage (water level), flow velocity; may include exogenous inputs (meteorological/flood forecasts).",
            "problem_complexity": "Temporal dependencies with multiple time scales (hours to days); noise, missing data, and occasional sensor failure; nonlinear temporal dynamics influenced by boundary conditions (floods) making forecasting challenging.",
            "domain_maturity": "Monitoring networks and physical understanding of scour are established; application of DL (LSTM) to operational forecasting is emerging and promising with demonstrated case studies.",
            "mechanistic_understanding_requirements": "Medium — forecasts are used for operational decisions; interpretability less critical than reliability and uncertainty quantification, but model outputs must be judged alongside physical/flood forecasts and historical trends.",
            "ai_methodology_name": "LSTM RNN (timeseries forecasting)",
            "ai_methodology_description": "LSTM networks trained on sliding-window data slices (input sequence and label/forecast segment). Preprocessing includes denoising (MAD), imputation for missing data (linear interpolation or Gaussian process), smoothing/low-pass filtering, and normalization. Training uses batches of sequences, hyperparameter tuning (input/label width, layers, units, learning rate), sequential K-fold cross-validation with transfer learning, and ensemble/overlap-based uncertainty estimation.",
            "ai_methodology_category": "Supervised learning — sequence forecasting (deep learning, recurrent networks)",
            "applicability": "Highly applicable for bridges instrumented with continuous monitoring sensors and adequate historic records; powerful for site-specific forecasting but limited where monitoring data are unavailable.",
            "effectiveness_quantitative": "Reported case studies on Alaskan bridges: LSTM variants provided 7-day-ahead scour forecasts with average error between 0.20 and 0.35 m.",
            "effectiveness_qualitative": "LSTMs produced accurate short-term forecasts in case studies and outperformed empirical equations in those site-specific scenarios; sensitivity to sensor noise and missing data requires careful preprocessing and validation.",
            "impact_potential": "High for operational risk management: provides early warnings, helps prioritize inspections/closures, and enables data-driven mitigation; transfers well to other monitored bridges in similar regions.",
            "comparison_to_alternatives": "Compared to empirical scour models — LSTM outperforms in site-specific forecasting; compared to CNN temporal models — CNNs showed competitive accuracy with substantially lower computational cost.",
            "success_factors": "Availability of continuous, quality sensor data; robust preprocessing (outlier detection, imputation, filtering); appropriate sliding-window configuration; ensemble and cross-validation strategies; combining forecasts with engineering/flood information.",
            "key_insight": "When adequate site-specific monitoring data exist, LSTMs can reliably forecast scour several days ahead with actionable accuracy, but success depends on careful data preprocessing and explicit uncertainty estimation.",
            "uuid": "e2306.1",
            "source_info": {
                "paper_title": "Machine Learning Methods for Geotechnical Site Characterization and Scour Assessment",
                "publication_date_yy_mm": "2025-01"
            }
        },
        {
            "name_short": "Temporal CNN (scour)",
            "name_full": "Convolutional Neural Network applied to temporal (timeseries) scour forecasting",
            "brief_description": "A temporal CNN architecture applied to timeseries sonar and stage data for computationally efficient real-time scour forecasting with competitive accuracy to LSTM in case studies.",
            "citation_title": "",
            "mention_or_use": "mention",
            "scientific_problem_domain": "Real-time scour forecasting / timeseries prediction",
            "problem_description": "Forecast scour depth from multivariate time-series sensor data with lower computational cost than RNN-based approaches.",
            "data_availability": "Same as LSTM: site-specific continuous monitoring records, often limited length and noisy.",
            "data_structure": "Multivariate time series (regularly sampled) — input and label windows formed via sliding window.",
            "problem_complexity": "Temporal dependencies that can be learned by causal convolutions; similar challenges to LSTM (noise, missing data).",
            "domain_maturity": "Emerging — temporal CNNs have been trialed and show promise as a lighter-weight alternative to LSTM for operational forecasting.",
            "mechanistic_understanding_requirements": "Medium — operational reliability and uncertainty estimation required; interpretability secondary.",
            "ai_methodology_name": "Temporal convolutional neural network (CNN) for sequence forecasting",
            "ai_methodology_description": "CNNs operate on data slices created by sliding window; architecture uses temporal convolutional layers to learn patterns across time steps; trained with supervised regression loss and validated via sequential cross-validation; hyperparameters tuned similarly to LSTM.",
            "ai_methodology_category": "Supervised learning — deep learning (convolutional sequence models)",
            "applicability": "Applicable where low-latency, lower-compute forecasting is required; competitive with LSTM in Alaskan case studies per the paper.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "Temporal CNNs achieved competitive performance to LSTM on Alaskan bridge data with a substantially lower computational cost, making them attractive for real-time deployment.",
            "impact_potential": "Enables scalable, lower-cost operational forecasting on embedded or constrained systems while maintaining forecast accuracy.",
            "comparison_to_alternatives": "Compared qualitatively to LSTM: similar predictive performance but lower computational cost; both outperform empirical equations in monitored, site-specific contexts.",
            "success_factors": "Good quality timeseries slices, careful hyperparameter tuning, and robust preprocessing (outlier detection, imputation).",
            "key_insight": "Temporal CNNs can match LSTM forecast accuracy on monitored scour timeseries while being more computationally efficient, making them attractive for real-time systems.",
            "uuid": "e2306.2",
            "source_info": {
                "paper_title": "Machine Learning Methods for Geotechnical Site Characterization and Scour Assessment",
                "publication_date_yy_mm": "2025-01"
            }
        },
        {
            "name_short": "IC-XGBoost2D",
            "name_full": "Iterative Convolution XGBoost 2D (stochastic image-based stratigraphy simulation)",
            "brief_description": "An image-based stochastic simulation algorithm that leverages training images (TIs) and iterative convolutional XGBoost to generate 2-D conditional realizations of subsurface stratigraphy and quantify stratigraphic uncertainty.",
            "citation_title": "",
            "mention_or_use": "mention",
            "scientific_problem_domain": "Subsurface stratigraphic modeling / geological cross-section simulation",
            "problem_description": "Interpolate and predict discrete stratigraphic classes across a target area from scarce site-specific measurements by learning patterns from training images and conditioning on borehole/outcrop data to produce multiple realizations and uncertainty measures.",
            "data_availability": "Scarce site-specific measurements (few boreholes); supplemented by training images compiled from nearby projects, conceptual models, simulations or experiments — TIs provide prior patterns when data are limited.",
            "data_structure": "2-D image-like spatial patterns (training images) and sparse conditioning data (borehole logs); categorical stratigraphic classes (discrete labels).",
            "problem_complexity": "High spatial heterogeneity and connectivity constraints; discrete, multimodal patterns; heavy reliance on prior pattern representation (TI); computational complexity arises from conditional sampling across 2-D fields.",
            "domain_maturity": "Emerging; builds on multiple-point statistics and image-based geostatistics; TI-based stochastic simulations are established in geosciences but their ML hybrids (IC-XGBoost2D) are recent developments.",
            "mechanistic_understanding_requirements": "Medium — geological plausibility of realizations is essential; TI must encode prior geological process knowledge; interpretability of pattern selection important for acceptance by practitioners.",
            "ai_methodology_name": "Iterative convolutional XGBoost stochastic simulation",
            "ai_methodology_description": "Uses a data-event template (sliding window) to search compatible patterns from a TI database and constructs empirical CDFs used to sample soil types at unsampled locations; XGBoost (gradient-boosted trees) is applied iteratively with convolutional-like sampling to build 2-D cross-sections conditioned on site data. Ensemble of TIs can be used to represent prior uncertainty.",
            "ai_methodology_category": "Hybrid of supervised ML (gradient boosting) and stochastic simulation / generative conditional sampling (image-based geostatistics)",
            "applicability": "Appropriate when training images exist to represent expected stratigraphic patterns and site-specific data are sparse; sensitive to TI selection and can produce poor realizations if TI mismatched to site.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "Provides a way to leverage prior geological patterns to overcome sparse data, enabling multiple realizations and stratigraphic uncertainty quantification; performance depends greatly on the appropriateness of training images.",
            "impact_potential": "Enables probabilistic subsurface models and uncertainty-aware design/analysis when borehole data are limited, improving risk-informed engineering decisions.",
            "comparison_to_alternatives": "Compared conceptually to multiple-point statistics (MPS): both are image-based; IC-XGBoost2D integrates ML (XGBoost) with convolutional-like pattern retrieval; TI influence diminishes as more site-specific data are available.",
            "success_factors": "Quality and relevance of the training image database, ensemble of TIs to capture alternative geological scenarios, and sufficient conditioning data to reduce TI dominance where possible.",
            "key_insight": "Image-based ML-stochastic hybrids can effectively transfer prior geological patterns (via training images) to conditionally simulate stratigraphy from sparse data, but their reliability hinges on correct TI selection and ensemble approaches to capture prior uncertainty.",
            "uuid": "e2306.3",
            "source_info": {
                "paper_title": "Machine Learning Methods for Geotechnical Site Characterization and Scour Assessment",
                "publication_date_yy_mm": "2025-01"
            }
        },
        {
            "name_short": "BCS (Bayesian Compressive Sampling)",
            "name_full": "Bayesian Compressive Sampling for spatial interpolation of geo-properties",
            "brief_description": "A nonparametric compressive-sensing-based machine learning method to reconstruct high-resolution spatial fields (e.g., cone tip resistance) from sparse measurements by representing signals over a limited number of basis functions.",
            "citation_title": "",
            "mention_or_use": "mention",
            "scientific_problem_domain": "Spatial interpolation of geotechnical properties / ground model construction",
            "problem_description": "Interpolate spatially varying geo-properties (e.g., CPT tip resistance) across a 2-D/3-D cross-section from sparse CPT/borehole measurements to produce high-resolution maps for ground models.",
            "data_availability": "Sparse CPT/borehole measurements typical for engineering sites; geophysical data may supplement but are of differing types/resolutions.",
            "data_structure": "Spatial fields (2-D/3-D) represented as signals that can be approximated with a sparse set of basis functions (e.g., discrete cosine transform coefficients).",
            "problem_complexity": "High-dimensional spatial interpolation with limited samples; requires selection of basis set and regularization; nontrivial inverse reconstruction under noise.",
            "domain_maturity": "Novel but grounded in compressive sensing and Bayesian inference; applied in recent geotechnical contexts as a promising interpolation approach.",
            "mechanistic_understanding_requirements": "Low-to-medium — outputs are used as inputs to mechanistic analyses, so they must be physically plausible; method itself is more data-driven and probabilistic than mechanistic.",
            "ai_methodology_name": "Bayesian compressive sampling (BCS)",
            "ai_methodology_description": "Assumes the spatial field can be represented as a sparse linear combination of pre-specified basis functions; Bayesian sparse inference recovers coefficients from sparse noisy measurements, yielding posterior distributions for reconstructed fields; used sequentially with stratigraphic realizations to map property variability per soil unit.",
            "ai_methodology_category": "Bayesian nonparametric / compressive-sensing (unsupervised or semi-supervised spatial reconstruction)",
            "applicability": "Suited for reconstructing spatially varying geotechnical properties from sparse measurements and for producing multiple realizations for uncertainty quantification in ground models.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "Promising for generating high-resolution estimates from limited CPT data and for propagating uncertainty; effectiveness depends on suitability of chosen basis functions and noise levels.",
            "impact_potential": "Enables richer, uncertainty-aware ground models that integrate sparse geotechnical measurements into practical engineering workflows, improving design robustness.",
            "comparison_to_alternatives": "Alternative geostatistical interpolation often relies on spatial correlation estimates; BCS bypasses explicit correlation modeling by leveraging sparsity in a basis domain, which can be advantageous with very sparse samples.",
            "success_factors": "Appropriate basis selection, good noise modeling, integration with stratigraphic realizations, and sufficient computational implementation.",
            "key_insight": "BCS provides a principled Bayesian way to reconstruct spatial geotechnical fields from sparse data by exploiting sparsity in an appropriate basis, enabling uncertainty-aware ground models when conventional geostatistics struggle with limited samples.",
            "uuid": "e2306.4",
            "source_info": {
                "paper_title": "Machine Learning Methods for Geotechnical Site Characterization and Scour Assessment",
                "publication_date_yy_mm": "2025-01"
            }
        },
        {
            "name_short": "DANN-KHMD + MRF (PyMRF)",
            "name_full": "Discriminant Adaptive Nearest Neighbor-based K-harmonic Mean Distance classifier combined with Markov Random Field and Gibbs sampling (PyMRF implementation)",
            "brief_description": "A Bayesian framework for automated stratigraphic interpolation and uncertainty quantification that generates initial stratigraphic fields using DANN-KHMD and refines them with Gibbs sampling under a Markov random field contextual model, implemented as 'PyMRF'.",
            "citation_title": "",
            "mention_or_use": "mention",
            "scientific_problem_domain": "Borehole-based subsurface stratigraphic interpolation and uncertainty quantification",
            "problem_description": "Infer stratigraphic cross-sections and associated uncertainties automatically from borehole stratigraphy data without relying on training images, suitable for cases with variable stratigraphic complexity.",
            "data_availability": "Relies on borehole stratigraphies collected at site; data requirement (number of boreholes) scales with stratigraphic complexity (more boreholes for complex folded structures).",
            "data_structure": "Spatial grid elements with categorical stratigraphic labels at borehole locations and unlabeled elsewhere; operates on discrete class labels.",
            "problem_complexity": "Handling discrete spatial classification with contextual constraints and limited observations; requires sampling from posterior distributions over high-dimensional discrete fields.",
            "domain_maturity": "Recent methodological development reported by Wei & Wang; implemented in Python (PyMRF) and aimed at practical unsupervised stratigraphic inference.",
            "mechanistic_understanding_requirements": "Medium — aims to provide plausible stratigraphic fields with quantified uncertainty; geological plausibility and contextual constraints are built into the MRF prior.",
            "ai_methodology_name": "DANN-KHMD classifier + Markov Random Field Gibbs sampling (Bayesian machine learning)",
            "ai_methodology_description": "Step 1: collect and label borehole stratigraphy. Step 2: generate multiple initial fields using the DANN-KHMD classifier that probabilistically labels unknown elements based on long-range spatial patterns learned from known elements. Step 3: perform Gibbs sampling to update stratigraphic configuration and MRF model parameters iteratively, sampling conditional distributions and updating parameters until convergence. Step 4: generate multiple simulations to quantify stratigraphic uncertainty (information entropy). Implemented in Python as PyMRF.",
            "ai_methodology_category": "Bayesian / probabilistic machine learning; unsupervised/semi-supervised spatial classification",
            "applicability": "Appropriate for stratigraphic inference when training images are not desired or available; automates initial labeling and accounts for model and stratigraphic uncertainty.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "Provides automatic, unsupervised inference of stratigraphic profiles with consideration of both stratigraphic and model uncertainty; advantages include lower computational cost for reasonable initial fields and avoidance of TI reliance.",
            "impact_potential": "Can standardize and automate stratigraphic inference workflows, reduce subjectivity, and provide uncertainty quantification for engineering design and risk assessments.",
            "comparison_to_alternatives": "Compared to TI-based image simulation methods: does not require training images and explicitly models both stratigraphic and model uncertainty; may require adequate borehole density for reliable inference.",
            "success_factors": "Quality and representativeness of borehole data, proper setting of MRF contextual priors, multiple initial fields and convergence criteria, and ability to sample adequate posterior realizations.",
            "key_insight": "Combining a discriminant nearest-neighbor initial labeling with Bayesian MRF Gibbs sampling yields an automated workflow that infers stratigraphy and quantifies uncertainty without the need for external training images, making it valuable where borehole data exist but TIs are unavailable.",
            "uuid": "e2306.5",
            "source_info": {
                "paper_title": "Machine Learning Methods for Geotechnical Site Characterization and Scour Assessment",
                "publication_date_yy_mm": "2025-01"
            }
        },
        {
            "name_short": "Bayesian NN / MCD / VI",
            "name_full": "Bayesian Neural Networks with Variational Inference and Monte Carlo Dropout for uncertainty quantification",
            "brief_description": "Approaches that integrate Bayesian treatments into neural networks (variational inference or Monte Carlo dropout) to provide predictive distributions (uncertainty estimates) for soil property prediction tasks.",
            "citation_title": "",
            "mention_or_use": "mention",
            "scientific_problem_domain": "Prediction of geomaterial properties (e.g., compression index, undrained shear strength) with uncertainty quantification",
            "problem_description": "Provide both point estimates and uncertainty bounds for geotechnical properties predicted from in-situ and laboratory data, enabling reliability assessment of ML-derived predictions.",
            "data_availability": "Moderate-size databases reported in the literature (examples: 241 triaxial tests, 61 block samples in one cited study); overall, geotechnical datasets are often limited and heterogeneous.",
            "data_structure": "Structured tabular data combining CPTU and laboratory measurements; input features include pressures, stresses, CPT measurements, and sample descriptors.",
            "problem_complexity": "Nonlinear regression under limited/heterogeneous data and measurement noise; need to propagate uncertainty for engineering reliability.",
            "domain_maturity": "Emerging practice in geotechnical ML; Bayesian NN approaches reported in recent studies to address deterministic ML limitations.",
            "mechanistic_understanding_requirements": "High — engineering decisions require error bounds and reliability measures; Bayesian approaches provide probabilistic outputs that support safer decisions.",
            "ai_methodology_name": "Bayesian neural networks (BNN) with variational inference (VI) and Monte Carlo dropout (MCD)",
            "ai_methodology_description": "BNNs trained using variational inference approximate posterior distributions over weights, producing predictive distributions for outputs; Monte Carlo dropout applied during inference approximates Bayesian model uncertainty by sampling multiple dropout realizations; used to predict compression index and undrained shear strength and to estimate predictive standard deviation.",
            "ai_methodology_category": "Bayesian supervised learning / uncertainty-aware deep learning",
            "applicability": "Well-suited to geotechnical regression tasks where uncertainty quantification is necessary for engineering risk assessment; requires careful training and appropriate data quality.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "Provides reliability estimates and standard deviation of predictions enabling risk-aware use of ML outputs; addresses major limitation of deterministic ML models by allowing reliability evaluation.",
            "impact_potential": "Improves safety and trust in ML-based geotechnical predictions by supplying uncertainty bounds, thereby supporting engineering decisions and possibly wider adoption.",
            "comparison_to_alternatives": "Improves over deterministic ANN approaches by quantifying prediction uncertainty; Monte Carlo dropout offers a practical approximation when full Bayesian training is expensive.",
            "success_factors": "High-quality labeled data, correct probabilistic model specification, adequate computational resources for sampling/ensemble inference, and careful validation against unseen data.",
            "key_insight": "In geotechnical regression tasks where data are limited and safety critical, Bayesian NN methods using VI or MCD provide essential uncertainty estimates that deterministic ML lacks, increasing the method's practical utility.",
            "uuid": "e2306.6",
            "source_info": {
                "paper_title": "Machine Learning Methods for Geotechnical Site Characterization and Scour Assessment",
                "publication_date_yy_mm": "2025-01"
            }
        },
        {
            "name_short": "ANN + seismic attributes (ground model)",
            "name_full": "Artificial Neural Network multi-attribute regression mapping seismic attributes to geotechnical properties",
            "brief_description": "Use of ANNs to map quantitative seismic attributes (e.g., acoustic impedance and derived attributes) into geotechnical properties such as CPT tip resistance to produce 3-D integrated ground models.",
            "citation_title": "",
            "mention_or_use": "mention",
            "scientific_problem_domain": "Integrated ground/soil model construction combining geophysical and geotechnical data",
            "problem_description": "Predict geotechnical property distributions (e.g., cone tip resistance) across areas covered by seismic surveys by learning relationships between seismic attributes and point geotechnical measurements.",
            "data_availability": "Joint datasets: seismic reflection volumes (abundant high-resolution data) and sparse calibration sites with CPTU measurements (limited); requires down-sampling and depth conversion steps.",
            "data_structure": "Multimodal: continuous seismic attribute volumes (images/3D grids) plus structured tabular CPTU point measurements; requires mapping from time-domain seismic to depth-domain geotechnical measurements.",
            "problem_complexity": "High spatial resolution inference combining different measurement modalities and scales; feature selection and time-depth conversion add complexity.",
            "domain_maturity": "Applied and maturing; various approaches (geometrical, geostatistical, ML) exist; paper cites ML as most accurate per comparative studies.",
            "mechanistic_understanding_requirements": "Medium — outputs are used for design; geological plausibility and validation against boreholes required.",
            "ai_methodology_name": "Artificial Neural Network multi-attribute regression (with genetic algorithm optimization for attribute selection)",
            "ai_methodology_description": "Derive quantitative seismic attributes (optimized by genetic algorithms for feature selection), convert time-domain seismic to depth domain, down-sample CPTU data to seismic sample interval, train ANN to regress CPTU q_c from seismic attributes at calibration sites; then predict across seismic volume.",
            "ai_methodology_category": "Supervised learning — multimodal regression",
            "applicability": "Applicable and effective for large projects where seismic coverage exists and a few calibration CPTs are available; ML approach shown to outperform geometrical and geostatistical approaches in referenced study.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "Reported to be the most accurate method among geometric and geostatistical approaches in cited comparative work, enabling more consistent and higher-resolution ground models.",
            "impact_potential": "Significant for offshore and large onshore projects: enables mapping of geotechnical properties at site-wide scales, improving foundation design and reducing need for dense borehole campaigns.",
            "comparison_to_alternatives": "Compared to geometrical and geostatistical approaches: ML/ANN provided most accurate predictions in the cited comparative study (Sauvin et al.).",
            "success_factors": "Availability of representative seismic attributes, good depth conversion, calibration sites with reliable CPTU data, and robust feature selection (genetic algorithm).",
            "key_insight": "Integrating abundant seismic attributes with sparse geotechnical measurements via ANNs can yield more accurate, higher-resolution ground models than traditional geometrical or geostatistical methods when properly calibrated.",
            "uuid": "e2306.7",
            "source_info": {
                "paper_title": "Machine Learning Methods for Geotechnical Site Characterization and Scour Assessment",
                "publication_date_yy_mm": "2025-01"
            }
        },
        {
            "name_short": "Classical ML vs DL (general)",
            "name_full": "Classical machine learning versus deep learning considerations in geotechnical problems",
            "brief_description": "A domain-level insight: conventional ML methods (SVM, RF, XGBoost, shallow NN) are generally better suited to small-sample geotechnical tasks, while deep learning (CNNs, RNNs, LSTMs, GNNs) requires large labeled datasets but can capture more complex patterns when data are sufficient.",
            "citation_title": "",
            "mention_or_use": "mention",
            "scientific_problem_domain": "General geotechnical / subsurface characterization and geohazard modeling",
            "problem_description": "Choosing appropriate ML/DL approaches depending on dataset size, data type and task complexity across many geotechnical subproblems (stratigraphy, property prediction, forecasting).",
            "data_availability": "Geotechnical data are often scarce (from several hundred to ~1000 samples at most) and heterogeneous; benchmark/global datasets exist but are limited.",
            "data_structure": "Varies: structured tabular data, images (training images), time series, graphs (e.g., GNN inputs), and multimodal combinations.",
            "problem_complexity": "Varies from low-dimensional empirical correlations to complex spatial-temporal processes requiring high-capacity models; data sparsity constrains model choice.",
            "domain_maturity": "Geotechnical engineering is mature but ML/DL adoption is recent and rapidly growing; no consensus on optimal ML/DL algorithm.",
            "mechanistic_understanding_requirements": "Often medium to high for engineering acceptance; interpretability and uncertainty quantification are important for deployment.",
            "ai_methodology_name": "Conventional ML (SVM, RF, XGBoost, GP) vs Deep Learning (CNN, RNN/LSTM, GNN, GAN)",
            "ai_methodology_description": "Paper summarizes that classical ML (tree-based, kernel methods, shallow NNs) suits small-sample problems and tabular tasks; DL architectures (CNNs for images, LSTMs for sequences, GNNs for structural data, GANs for generative training images) require larger labeled datasets and often more compute; hybrid strategies (transfer learning, ensembles, TI-based priors) are recommended to mitigate data scarcity.",
            "ai_methodology_category": "Supervised/unsupervised deep learning and classical supervised learning; hybrid approaches",
            "applicability": "Classical ML is broadly applicable to small datasets common in geotechnics; DL is applicable when large datasets or continuous monitoring data are available (or via transfer learning), or for image/time-series tasks.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "Empirical observation: DL dominated by neural networks generally requires large amounts of training data to outperform classical methods; classical ML performs well in small-sample settings.",
            "impact_potential": "Guides appropriate method selection in geotechnical applications and motivates database development, transfer learning and hybrid approaches to leverage DL strengths even with limited data.",
            "comparison_to_alternatives": "Paper reports that no single 'optimal' ML/DL algorithm exists; choice depends on data quantity/type and preference for explicit analytical expressions versus black-box modeling.",
            "success_factors": "Matching model capacity to dataset size, using transfer learning and ensembles, careful preprocessing/feature selection, and development of benchmark datasets.",
            "key_insight": "The effectiveness of ML vs DL in geotechnics is driven primarily by data availability and structure: classical ML is preferable for small, tabular datasets, while DL is advantageous for large image/time-series datasets or when transfer learning can be applied.",
            "uuid": "e2306.8",
            "source_info": {
                "paper_title": "Machine Learning Methods for Geotechnical Site Characterization and Scour Assessment",
                "publication_date_yy_mm": "2025-01"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Machine Learning Solutions for Bridge Scour Forecast based on Monitoring Data",
            "rating": 2,
            "sanitized_title": "machine_learning_solutions_for_bridge_scour_forecast_based_on_monitoring_data"
        },
        {
            "paper_title": "Towards an AI-Based Early Warning System for Bridge Scour",
            "rating": 2,
            "sanitized_title": "towards_an_aibased_early_warning_system_for_bridge_scour"
        },
        {
            "paper_title": "Development of Subsurface Geological Cross-Section from Limited Site-Specific Boreholes and Prior Geological Knowledge Using Iterative Convolution XGBoost",
            "rating": 2,
            "sanitized_title": "development_of_subsurface_geological_crosssection_from_limited_sitespecific_boreholes_and_prior_geological_knowledge_using_iterative_convolution_xgboost"
        },
        {
            "paper_title": "Stochastic Stratigraphic Modeling Using Bayesian Machine Learning",
            "rating": 2,
            "sanitized_title": "stochastic_stratigraphic_modeling_using_bayesian_machine_learning"
        },
        {
            "paper_title": "Prediction of Undrained Shear Strength Using Extreme Gradient Boosting and Random Forest Based on Bayesian Optimization",
            "rating": 1,
            "sanitized_title": "prediction_of_undrained_shear_strength_using_extreme_gradient_boosting_and_random_forest_based_on_bayesian_optimization"
        },
        {
            "paper_title": "Machine Learning and Landslide Studies: Recent Advances and Applications",
            "rating": 1,
            "sanitized_title": "machine_learning_and_landslide_studies_recent_advances_and_applications"
        }
    ],
    "cost": 0.0238425,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Foundations special collection</p>
<p>Negin Yousefpour negin.yousefpour@unimelb.edu.au 
Department of Infrastructure Engineering
The University of Melbourne
ParkvilleVictoriaAustralia</p>
<p>Zhongqiang Liu 
Norwegian Geotechnical Institute
OsloNorway</p>
<p>Chao Zhao 
Faculty of Engineering
China University of Geosciences
WuhanChina</p>
<p>Foundations special collection
991D95E771B7E54FA4E1F8E4D517DBA910.1177/03611981241257512ScourGeotechnical Site CharactrizationGeohazardsFoundations of bridgesGeotechnical Asset ManagementMachine Learning (Artificial Intelligence)Neural Networks
Reliable geotechnical site characterization and geohazard assessment are critical for bridge foundation design and management.This paper explores existing and emerging artificial intelligence-machine learning methods (AI-ML) transforming geotechnical site characterization and scour assessment for bridge foundation design and maintenance.The prevalent ML techniques applied for subsurface characterization are reviewed, and step-by-step methodologies for stratigraphy classification, borehole interpretation, geomaterial characterization, and ground modeling are provided.The ML techniques for maximum scour depth prediction are reviewed, and a simple ML methodology is proposed to provide a more reliable tool for scour depth estimation for implementation in practice.Also, a novel deep learning approach, with a detailed implementation description, is recommended for real-time scour monitoring and assessment of existing bridges.The challenges with database design and data processing for ML modeling, model optimization, training and validation, and uncertainty assessments are discussed, and innovative techniques for addressing them are reviewed.</p>
<p>Reliable geotechnical site characterization and geohazard assessment are critical elements in bridge infrastructure design and management.Scour, a major geohazard affecting bridges over waterways, is the main cause of failure in the United States and worldwide (1)(2)(3).In this paper, we review emerging artificial intelligence (AI) and machine learning (ML) technologies that are transforming geotechnical site characterization and scour assessments for bridge foundation design and maintenance.</p>
<p>AI, a versatile field encompassing ML, data analytics, and computational modeling, has catalyzed transformative change across various industries.Geotechnical engineering is no exception, benefiting from AI's capabilities to extract valuable insights, enhance predictive accuracy, and optimize decision-making processes, considering geohazards.This fusion of geotechnical engineering and AI has far-reaching implications, promising safer and more reliable infrastructure, cost savings, and minimized environmental impact.</p>
<p>There are state of the art reviews on ML/deep learning (DL) applications in geotechnical engineering, including Yousefpour and Fallah's (4) on ML applications in geotechnics, Zhang et al.'s (5) on DL applications in geotechnical engineering and ML modeling of soil properties (6), Dikshit et al.'s (7) on geohazard modeling, Tehrani et al.'s (8) landslide studies and recently Phoon and Zhang's (9) review on the future of ML in geotechnics.</p>
<p>The objective of this discussion is to highlight the recent advances and underscore the importance of continued research and innovation in harnessing the full potential of AI-ML for safer, more resilient, and costeffective bridge foundations.The paper is organized as follows.The next section introduces the synopsis on AI and ML.We then present subsurface characterization and scour assessment using ML.We also provide recommendations with step-by-step implementation methods for applications in practice.We end the paper with a conclusion section.</p>
<p>Synopsis on Artificial Intelligence and Machine Learning</p>
<p>AI and ML represent two dynamic and interrelated fields at the forefront of modern technology.AI is a broader concept, encompassing the development of intelligent systems capable of tasks traditionally requiring human intelligence, such as problem solving, language understanding, and decision making.ML, on the other hand, is a subset of AI focused on the development of algorithms that enable computers to learn from and make predictions or decisions based on data.</p>
<p>AI and ML have seen unprecedented growth and application across various industries.In the domain of AI, natural language processing (NLP) has enabled conversational AI and language translation (10).Computer vision has transformed image and video analysis (11), while reinforcement learning has empowered robots and autonomous systems (12).Meanwhile, ML techniques, including supervised learning, unsupervised learning, and reinforcement learning, have revolutionized data-driven decision-making processes in fields ranging from health care and finance to engineering applications (13,14).The synergy between AI and ML is evident in their iterative and data-centric approach.ML algorithms learn patterns from data and improve their performance over time, aligning with the AI goal of creating intelligent, adaptive systems.Additionally, the availability of vast data sets and increased computing power has fueled the advancement of AI and ML applications.</p>
<p>Deep learning employs artificial neural networks inspired by the human brain to solve complex problems (15).DL has revolutionized AI by enabling breakthroughs in computer vision, natural language processing, and speech recognition (16).Convolutional neural networks (CNNs) (17) have enhanced image recognition, while recurrent neural networks (RNNs) (18) and transformer models (19) have elevated language understanding and generation to unprecedented levels.Generative AI is the most recent advancement in this field, creating systems capable of generating content, such as images, text, music, and more, often with remarkable creativity.At its core, generative AI seeks to enable machines to produce novel, human-like output.The driving force behind many generative AI models is the use of neural networks, particularly generative adversarial networks (GANs) (20).</p>
<p>In civil engineering, AI-ML has been used mostly in structural health and performance monitoring (21)(22)(23), design optimization (24), predictive maintenance (25), construction automation and management (11,26), transport planning (27), and in various aspects of geotechnical engineering (4,5).</p>
<p>Subsurface Characterization Using ML</p>
<p>Subsurface characterization, including stratigraphic configuration and the associated geotechnical properties, has long been a challenge in geotechnical practice.Because of the geological processes leading to the compounded deposition and subsequent changes of geomaterials, including layering, each stratum exhibits variation from point to point within a volume (28).Nevertheless, the identification of subsurface stratification and the characterization of spatially varying soil and rock properties with the limited availability of site investigation information are indispensable for site characterization and following design analyses.</p>
<p>The TC309 (International Society for Soil Mechanics and Geotechnical Engineering [ISSMGE]'s Technical Committee for Machine Learning and Big Data) carried out an online survey in 2019, receiving 114 responses.The survey highlighted that machine learning is expected to have a significant impact on geotechnical site characterization among others.Site characterization is one of the leading areas where machine learning can transform practice over the next 10 years (Figure 1).</p>
<p>Stratigraphy Classification</p>
<p>Stratigraphy classification is essential in site investigation, as it provides the necessary knowledge on the geological body (29).For example, the significance of the stratigraphy classification might be observed in the failure of a slope consisting of multiple strata, in which the failure is often dominated by the spatial distribution of the weak stratum (30).However, the subsurface stratigraphic configuration at a site is hard to characterize accurately because of the complexity and inherent spatial variability of the strata and the limited availability of exploration data.</p>
<p>The essence of stratigraphic modeling is a process of interpolating and predicting strata of the whole area of interest from a limited amount of known data (31).It generally treats geological units as discrete variables, such as stratigraphic classes or rock classes, and thus formulates the modeling task as a classification problem corresponding to discrete variables.DL and ML are the methods that learn a model with statistical characteristics from known data and use the model to make judgments and predictions about new scenarios.In this way, the principles of stratigraphic modeling fit with DL and ML (32).</p>
<p>In recent years, there has been a boom in research on the stratigraphy classification based on DL or ML.As listed in Table 1 (33), the possibility of various machine learning algorithms in handling stratigraphy classification tasks has been verified, from shallow classification algorithms, such as convolutional neural networks (CNN), eXtreme gradient boosting (XGBoost), support vector machines (SVM), decision tree (DT), random forest (RF), and maximum likelihood, to variants of neural networks, such deep feed-forward neural networks (DFNN), RNNs, graph neural networks (GNN), and GAN.The modeling ideas of these methods may be divided into stratigraphy classification methods based on the image analysis and those based on the borehole interpretation.</p>
<p>The above studies have established the foundation for the application of machine learning to stratigraphy classification.In addition, they also reveal the characteristics of different approaches.Traditional machine learning classifiers are suitable for learning tasks with small samples, while DL algorithms dominated by neural networks generally require large amounts of training data to obtain better learning results.However, it is always troublesome to acquire and label geological data.The samples are too sparse to represent the feature space effectively, thus limiting to some extent the performance of DL models in geological reconstruction tasks.</p>
<p>Image Analysis</p>
<p>The depositional stratigraphic relationships can be quantitatively reflected in a training image (TI), which can be defined as a conceptual representation of the expected subsurface heterogeneities in the area of interest.Stochastic conditional simulation methods using TIs, for example, multiple-point statistics (34)(35)(36)(37)(38)(39)(40)(41)(42)(43)(44)(45)(46) and iterative convolution XGBoost (47), have been developed to depict stratigraphic connectivity between soil deposits.These image-based stochastic simulation algorithms have been successfully applied to tackle practical geotechnical problems, for example, reclamation and slope stability (48).</p>
<p>A TI is an ensemble of prior geological knowledge, which enables quantitative incorporation of subjective geological interpretation of a studied domain, and it can be directly obtained from a nearby site or previous projects with similar geological settings.The idea of TI is appealing to geological and geotechnical practitioners as it can effectively leverage on prior geological knowledge in a quantitative manner and combat the problem of scarce geological data often encountered in the development of subsurface geological cross sections.It should be noted that the performance of stochastic simulation methods for subsurface geological modeling can be greatly influenced by TI particularly when site-specific measurements are limited, and an improper TI may lead to geological realizations incompatible with observed data or even false interpretation of geological processes (49,50).This underscores the importance of selecting a proper TI for stochastic simulation methods.</p>
<p>Image-based stochastic simulations learn stratigraphic features from a single training image and leverage on the extracted patterns to yield an alternative representation of subsurface stratigraphy while conditioning on available site-specific data (e.g., slope outcrops or borehole logs).</p>
<p>A training image can be viewed as a prior ensemble of local geological knowledge and experience (e.g., interrelationships between soil types and orientations of soil layer boundaries) with the required spatial scale at the site of interest.More specifically, a qualified training image is a numerical representation of believed stratigraphic heterogeneities.Although it does not necessarily enclose all the detailed stratigraphic features at a target site, it should exhaust major repetitive stratigraphic relationships and structures (34).Training images essentially serve as effective supplements to overcome challenges associated with data sparsity, which is an intrinsic issue in geotechnical site investigation and geological modeling.</p>
<p>Shi and Wang (36) proposed a framework for the conditional simulation of subsurface stratigraphy, based on the typical cross sections for weathered granite and tuff slopes in Hong Kong.Subsequently, the proposed framework was applied to delineate subsurface stratigraphy and quantify associated stratigraphic uncertainty using real slope cross sections in Hong Kong.In the context of this framework, the inputs are the images of the geological cross sections.The geological cross section predicted by this framework is dependent on both the training image adopted (i.e., a prior geological model) and site-specific measurements (i.e., likelihood information).There is a balance between the prior geological model and site-specific measurements.Prior geological knowledge governs the posterior subsurface system when available measurements are limited.However, the influence of a training image weakens as the number of site-specific measurements increases (or likelihood information strengthens), and the final predicted geological cross section will be mainly dominated by sitespecific data when many measurements are taken from a specific site.The basic structure of this proposed framework can be summarized with the following steps.</p>
<p>Step 1. Collecting Training Images.The first step for establishing a training image database is to collect many geological cross sections from different sources and digitalize them using a consistent format.The potential training images can be obtained from four different sources: 1) the delineation of subsurface geological cross sections is a must for every geotechnical project, and it is, therefore, natural to collect geological cross sections developed from previous projects and use them as training images; 2) conceptual geological models developed by engineering practitioners, or even hand drawn by experienced geologists, can also be used as training images; 3) a training image can also be simulated using different generative models such as object-based, process-based, and processmimicking models, for example, Mariethoz and Caers (34); and 4) training images can snapshots taken directly from experiments using small-scale models.</p>
<p>Step 2. Categorizing Training Images.To facilitate the subsequent selection of training images for subsurface stratigraphy, all the collected training images may be further classified into different categories in accordance with their geological origin, location, and application scenarios.After determining the appropriate mode of origin or deposit type, a collected training image can be further categorized to different subgroups based on locations.Training images nearby are deemed to share similar local depositional environments.Finally, training images collected from similar application scenarios (e.g., slope stability analysis) should be grouped together as different application scenarios might focus on the accurate delineation of different stratigraphic patterns.</p>
<p>Step 3. Selecting Training Images.In the absence of training image databases, a candidate training image to be obtained from nearby sites or projects with similar geological settings can be adopted, which has achieved preliminary success in site planning and the appraisal of subsurface stratigraphy (47).However, the procedure for identifying a qualified training image can be greatly simplified when a suitable training image database is available.For a specific site with only slope outcrops available, a potential training image may be obtained directly from a training image category, which shares a similar geological origin, location, and application scenario with the concerned slope.Therefore, a compatible training image category can readily be set up by incorporating cross sections that are collected from nearby sites.Note that geological processes are invaluable when attempting to compile a database of training images and the geological process has been included in geological origins.</p>
<p>Step 4. Ensemble Learning Subsurface Stratigraphy Using Training Image Database.Each candidate training image can be viewed as an eigen-pattern set of the subsurface system and only represents a specific geological configuration under a given geological origin and application scenario.The combination of multiple training images can be considered an ''orthogonal decomposition'' of the subsurface system and enables a comprehensive appraisal of subsurface geological patterns and stratigraphic uncertainty.Ensemble learning bypasses the selection of a single best prior geological model or training image for subsurface stratigraphy but combines diverse stratigraphic patterns from multiple prior geological models for a unit characterization of stratigraphic uncertainty.This is particularly important for developing subsurface geological cross sections when only limited site-specific data are available, and it further emphasizes the necessity of establishing a training image database for subsurface stratigraphy.</p>
<p>Step 5. Simulating Subsurface Stratigraphy and Quantifying Stratigraphic Uncertainty.The subsurface stratigraphic configuration can be simulated using the image-based stochastic conditional methods, such as the multiple-point statistics (34) and iterative convolutional XGBoost algorithm (47).Essentially, the image-based stochastic conditional method relies on a flexible data event template to retrieve compatible stratigraphic patterns from a limited set of training images for establishing cumulative distribution function (CDF) curves, which are subsequently used for sampling and determination of soil types at unsampled locations.Then, a geological cross section or realization is completed.Based on the simulated stratigraphic configurations, the stratigraphic uncertainty can be quantified using the information entropy.</p>
<p>Borehole Interpretation</p>
<p>The subsurface stratigraphic configuration at a project site is usually obtained through spatial interpolation of the site-specific measurements (e.g., boreholes or cone penetration tests), coupled with local geological experience (51).Although linear interpolation may be conventionally used to develop subsurface geological cross sections from limited scattered data, a follow-up design or analysis based on this deterministic interpretation method might be considered a poor decision (e.g., Scheidt et al. [52]), particularly when the stratigraphic uncertainty is prevailing.To overcome the shortcomings of the linear interpolation, many techniques and methods have been developed to describe, simulate, and model strata, such as the octree model ( 53), B-rep model (54), geochron concepts (55), and tri-prism model (56).However, these methods rely on the guidance of expert knowledge and experience in the selection of assumptions, parameters, and data interpolation methods, which are subjective and limited (57).Assumptions about the borehole data distribution must be made, and it is difficult to evaluate the stratum simulation results effectively.</p>
<p>The recent advance in emerging machine learning methods provides a fresh perspective on the development of subsurface geological cross sections.For example, Porwal et al. ( 58) used radial function and neural network to evaluate potential maps in mineral exploration.Zhang et al. (59) predicted karst collapse based on the Gaussian process.Rodriguez-Galiano et al. (60) conducted a study on mineral exploration based on a decision tree.Gaurav (61) combined machine learning, pattern recognition, and multivariate geostatistics to estimate the final recoverable shale gas volume.Sha et al. (62) used a convolutional neural network to characterize unfavorable geological bodies and surface issues.It is noted that although the spatial distribution of strata can be characterized effectively with these approaches, the stratigraphic uncertainty is often ignored.</p>
<p>To this end, various machine learning methods, such as the Bayesian compressive sampling (63), the artificial neural network (64) and the multilayer perceptron neural network (65), have been advanced.These machine learning methods are appealing to practical engineers as they can effectively combine limited site-specific measurements and prior geological knowledge.Note that the stratigraphy's interpolation accuracy mainly depends on the number of measurements collected.In addition, to characterize the stratigraphic configuration and associated uncertainty, the geostatistical methods, Markovbased simulation methods (e.g., Markov random field and coupled Markov chain) (66-69) and conditional random field-based simulation methods (29,70), have been developed to derive probabilistic stratigraphic relationships between observed data for spatial interpolation of soil boundaries.The successful applications of those methods rely heavily on the accurate estimation of transition probabilities or spatial correlation.Directly estimating transition probabilities or spatial correlation from site-specific measurements can be complex as measurements are usually sparse and limited.</p>
<p>Note that the stratigraphic modeling with multi-source data fusion is expected to reduce the influence of the measurement error and then improve the simulation accuracy of the stratigraphy.Xiao et al. (71) proposed a coupled machine learning method to integrate the borehole and CPTU data under a rigorous Bayesian framework and to identify and separate the noisy CPTU data without subjective judgment, which contributes to more reliable soil classification and property evaluation.</p>
<p>Wei and Wang (72) developed a novel stratigraphic uncertainty quantification approach by integrating the Markov random field theory and the discriminant adaptive nearest neighbor-based k-harmonic mean distance classifier into a Bayesian framework.The inputs of this approach are the stratigraphies collected at borehole locations.And the number of the required boreholes may be dependent on the stratigraphic structure.For example, more boreholes may be required for the stratigraphic modeling at the site with the complicated stratigraphic structure (e.g., the fold stratigraphic structure) than that with the simple stratigraphic structure (e.g., the horizontally layered stratigraphic structure).This new approach has the following advantages: 1) inferring stratigraphic profile and associated uncertainty in an automatic and fully unsupervised manner; 2) reasonable initial stratigraphic configurations can be sampled and therefore lower the computational cost; 3) both stratigraphic uncertainty and model uncertainty are taken into consideration throughout the inferential process; 4) relying on no training stratigraphy images.The main procedures of the proposed method may be summarized as follows (this method has been implemented in Python 3.7.)Interested audiences may contact the corresponding author of Wei and Wang (72) for the in-house developed Python package ''PyMRF.''</p>
<p>Step 1. Collecting Borehole Data and Classifying the Stratigraphy.The first step is to collect the stratum information, which can be revealed through borehole exploration or directly observable from the ground surface, outcrops, or both.Then, the borehole stratigraphy should be classified based on the borehole data collected.</p>
<p>Step 2. Sampling an Initial Field Using the DANN-KHMD Classifier.For generating reasonable initial fields, the discriminant adaptive nearest neighbor-based k-harmonic mean distance (DANN-KHMD) classifier is developed to label the unknown (non-borehole) elements using long-range spatial patterns learned from known (borehole) elements.It is essentially an approach to roughly ''guess'' possible labels of the unknown elements given known elements in a probabilistic manner.Accordingly, the initial fields can be sampled independently on each element solely via the DANN-KHMD classifier.</p>
<p>Step 3. Conducting Gibbs Sampling and Updating Model Parameters. 1) Define a prior distribution of model parameters (i.e., the contextual constraint, b) via a multivariate Gaussian distribution with a mean vector and a diagonal covariate matrix.2) Provide an initial guess of model parameters b, and an initial stratigraphic configuration.3) Given the current model parameters b and the current stratigraphic configuration, calculate the conditional probability of all unknown elements.4) Generate an updated stratigraphic configuration via the chromatic sampler according to the conditional probability acquired.5) Update the model parameters b using prior distribution of b and the likelihood function.6) Iterate 3) to 5) until the specific convergence criterion is met.This is a single simulation of the stratigraphic configuration.</p>
<p>Step 4. Quantifying Stratigraphic Uncertainty.Generate multiple initial stratigraphic configurations from Step 2 and execute Step 3. Based on the simulated stratigraphic configurations, the stratigraphic uncertainty can be quantified using the information entropy.</p>
<p>Characterization of Geomaterials</p>
<p>Many parameters characterizing the properties of geomaterials, for example, index and strength parameters of soils, are intercorrelated.Many correlations of geomaterials were established in the early decades of soil and rock mechanics.They had been verified by sufficient researchers with wide practical geotechnical and rock engineering applications.Geomaterials are rarely homogeneous by nature and may vary spatially because of complex geological processes, which motivates geotechnical and rock engineers to update empirical correlations once more data are collected.An example is the CPTU correlations for Norwegian clays established by Karlsrud et al. (73) which have been updated by Paniagua et al. ( 74) using more advanced multiple regression methods based on a database of 61 block sample data points and CPTU measurements.There is, therefore, always a need for better understanding of the behavior of soils and rocks to improve geotechnical design.</p>
<p>Unlike statistical analyses, ML algorithms are able to learn the association between geotechnical design parameters (e.g., undrained shear strength) and index parameters without necessarily assuming a structural model in the data.Given that a large quantity of data has been collected and stored by the rapid advancement in digital technology over recent years, ML has been widely used to characterize complex behaviors of geomaterials because of its strong nonlinear fitting capability.</p>
<p>A recent overview of the application of ML algorithms to the prediction of soil properties in the past 10 years was presented by Zhang et al. (75).The implementation of ML techniques has shown exponential growth since 2018.Six classical ML algorithms were compared in their study, namely genetic programming (GP), evoloutionary polynomial regression (EPR), support vector regression (SVR), RF, feed-forward neural network (FFNN) and Monte Carlo dropout-based artificial neural network (ANN_MCD).However, important challenges still remain, such as site uniqueness, sparse and incomplete site-specific data, lack of a benchmark data set, and the generalization of ML models.</p>
<p>Site-and Region-Specific Data</p>
<p>A literature review is presented in this section, mainly discussing the most recent studies, within which a comparison among different ML techniques has been performed.Table 2 shows, for each article referenced, the list of ML algorithms adopted, the predicted parameters, and the location and area of the case studies.(82) assessed three machine learning-based approaches, namely SVM, RF, and deep neural network (DNN), for predicting the performance of lateritic soil shear strength based on soil samples collected along the Ratnagiri-Sangameshwar section of National Highway 66 in Maharashtra, India.They concluded that the DNN model has the highest prediction accuracy for the residual soil shear strength among the three distinct proposed ML models.Different authors have employed different operational procedures to move from the construction of the database needed to feed the ML algorithms, to the prediction of the properties of geomaterials, and to the performance evaluation of the computational model.Three main common phases of analysis may be recognized in each procedure: 1) data preprocessing; 2) model building and validation; and 3) testing.</p>
<p>Step 1. Data Preprocessing.Data preprocessing facilitates the training process by appropriately transforming the entire training data set to remove outliers, produce the optimal set of input variables (features), and normalize different features to an equivalent range, which can be used to build an ML model.It is not surprising that outlier detection is not very often carried out as only a limited number of data points are available in most of the studies.Moreover, outliers can be hard to define for geoproperties.Among the few studies, Li and Misra (83) used isolation forest to remove outliers of compressional and shear travel time logs (DTC and DTS) acquired using sonic logging tools.Correlation analysis and feature selection is another important step in data preprocessing.It is vital to remove highly correlated input features and irrelevant features for the prediction of physical and mechanical properties.Correlation coefficients are widely used to measure the correlation between features, for example, the Pearson correlation coefficient and Spearman correlation coefficient.Various feature selection techniques can be used for removing irrelevant features, such as least absolute shrinkage and selection operator algorithm (LASSO), random forests-recursive feature elimination (RF-RFE), and mutual information have been applied by Mittal et al. (78).SHapley Additive exPlanations (SHAP) (84) was used by Li et al. (80) to investigate the impact of each input variable on different output soil properties.These indices could be used to validate the results, enabling researchers to explore the algorithm's logic and verify its reliability.</p>
<p>Step 2. Model Building and Validation.As indicated in Table 2, most studies used conventional ML techniques, for example, ANN, SVM and tree-based methods.There is no consensus on a specific ''optimal'' ML algorithm for predicting physical properties of geomaterials.Pham et al. (76) concluded that out of four models the PANFIS emerges as a promising technique for prediction of the strength of soft soils.The ANN was the best model in Liu et al. (28), as it provided a simple analytical form with no hidden dependency between the bias and predicted indices.While building and testing the ML models, the entire data set is usually split into training and testing data sets.The training data set could be divided further into training and validating data sets, or the cross-validation techniques could be applied to a limited data sample, without further splitting of the training data set.</p>
<p>Step 3. Testing.The ML models established in Step 2 need further evaluation of their performance against unseen data sets.The common performance metrics that are typically adopted in the literature include: expressions quantifying the error of the analysis by means of an objective function (OF), the coefficient of determination (R 2 ), the mean absolute error (MAE), and the root mean square error (RMSE); the model bias method using bias mean, bias coefficient of variation (COV), and bias probability distribution (81).</p>
<p>Generic and Benchmark Data Sets</p>
<p>Site-specific data in geotechnical engineering are generally limited (from several hundred to a thousand at most).Therefore, data samples collected from various sources or places were used to develop ML models.It is worth mentioning that the database compilation by ISSMGE TC304 (304 dB) (http://140.112.12.21/issmge/ tc304.htm)could be a suitable platform for using open data sets.Asghari et al. (85) and Zhang et al. (6) used the 304 dB to investigate the application of ML methods for the prediction of the undrained shear strength of soft soils and other complex correlations in engineering metrics.Ma et al. (86) developed hybrid GA-SVM and PSO-SVM models for the prediction of permeability of cracked rock based on a database developed from existing literature.Zhang et al. (87) investigated the performance of five commonly used ML algorithms, that is, backpropagation neural network (BPNN), extreme learning machine (ELM), SVM, RF, and evolutionary polynomial regression (EPR) in predicting compression index Cc based on a global database consisting of 311 data points of initial void ratio e 0 , liquid limit water content w L , and plasticity index I p .Chen and Xue (88) collected a total of 151 data sets from the literature that were used to construct the ML models.</p>
<p>Uncertainty Quantification</p>
<p>Uncertainties associated with geomaterials (soils, rocks), geologic processes, and possible subsequent treatments are usually large and complex.Current ML modeling is always deterministic.As such, only high-quality data can be used because there is no capacity to address uncertainties.Zhang et al. (89) pointed out that applying the predicted result without any reliability evaluation using MLbased models may induce high risk.A Bayesian neural network (BNN) integrated with variational inference (VI) and Monte Carlo dropout (MCD) was used in their study to predict the compression index Cc and undrained shear strength s u of clays and to evaluate the reliability of the ML model.An ANN-based model that takes into account uncertainty estimates was developed in (90).The database of CPTU and triaxial tests used contained 241 laboratory triaxial tests.All test specimens were of high quality, including 180 undisturbed specimens taken with a 72-mm diameter fixed piston sampler and 61 undisturbed specimens taken with 40-cm diameter block samples.The ANN model requires the water pressure and effective stresses in addition to the CPTU data.The standard deviation estimate was performed based on the ''dropout method'' described in Gal (91).The predicted and measured undrained shear strength in triaxial compression are compared in Figure 2.An estimated standard deviation of the predicted undrained shear strength is also shown.</p>
<p>3-D Integrated Ground Model</p>
<p>For large geotechnical projects on land and offshore developments, it is current practice to conduct both geophysical and geotechnical investigations.Ground models integrate the geotechnical and geophysical data collected from a site and provide a three-dimensional map of the stratigraphy and the geo-properties.</p>
<p>In geotechnical projects, the quantitative integrated ground model is a requirement for cost-optimal site characterization.The ground model refers mainly to the stratigraphic configuration and the associated geotechnical properties in this study.Extensive studies focusing on the stratigraphy classification or the geomechanical characterization have been reported in the geotechnical literature (e.g., Mariethoz and Caers [34], Shi and Wang [47], and Wei and Wang [72]).However, relatively limited studies dealt with both the stratigraphic configuration and the geomechanical parameters in a specific model (92).Note that both the strata and the geo-properties at a site are a product of the same deposit histories, tectonic, and human activities; their spatial distributions are expected to share similar features.Thus, the study on the site characterization that considers both the stratigraphy classification and the geomechanical characterization, especially the spatial variabilities of the stratigraphic configuration and the associated geotechnical properties, is warranted.</p>
<p>In the conventional engineering approach, the subsurface stratigraphic configuration at a site is usually constructed through spatial interpolation of the stratigraphy collected at borehole locations, coupled with local experience (51).The geo-properties of each stratum are taken as fixed values (e.g., the mean of the geo-properties derived at borehole locations) (93).The ground model constructed with the conventional approach simplifies the actual geological body.Although this conventional approach has been widely adopted in practice, no scientific rationale is available to support this simplification (92).</p>
<p>Geotechnical analyses and interpretations often rely on isolated 1-D boreholes.On the other hand, geophysical data are collected in 2-D lines and 3-D volumes.Geophysical data therefore provide the natural link to repopulate geotechnical properties found in the 1-D boreholes onto a larger area and thereby build a consistent and robust ground model (94).Thus, it is current practice to conduct both geophysical and geotechnical investigations for large geotechnical projects on land and offshore developments.Ground models integrate the geotechnical and geophysical data collected from a site and provide a 3-D map of the stratigraphy and the geoproperties.Many approaches, such as the geometrical approach (94), the geostatistical approach (95), and the ANNs (96) have been reported to map the dynamic properties from the seismic data (stratigraphic information, Pwave velocities, amplitudes, and their attributes) into the geotechnical or geomechanical properties.Sauvin et al. (94) showed that the machine learning approach provides the most accurate prediction of the ground model from the geophysical data, over the geometrical geostatistical approach and the geostatistical approach.</p>
<p>The implementation procedures of the machine learning approach presented in Mittal et al. ( 78) can be summarized as follows.</p>
<p>Step 1. Derive a range of quantitative attributes from the seismic reflection data, particularly acoustic impedance using a genetic algorithm for optimization.</p>
<p>Step 2. Convert the seismic attributes from the time domain into the depth domain.</p>
<p>Step 3. Down-sample the piezocone penetration test (CPTU) tip resistance (q c ) to a sample interval matching that of the depth-converted seismic attributes.</p>
<p>Step 4. Use an ANN to perform multi-attribute regression between the range of quantitative seismic attributes and CPTU q c by training at several calibration sites.</p>
<p>It is worth noting that above approaches focused on deriving the most-probable ground model; however, the spatial variabilities of the stratigraphic configuration and the associated geotechnical properties were generally ignored.To overcome this obstacle, Shi and Wang (97) proposed a stochastic framework for modeling the stratigraphic uncertainty and spatial variability of soil properties by machine learning and random field simulation from limited site investigation data.This framework could effectively generate multiple realizations of geological cross-section and random field samples of geotechnical properties from limited measurements (obtained from the CPT), through which the uncertainties associated with the ground model can be characterized.We recommend the proposed framework for characterizing the ground model and associated uncertainties.</p>
<p>Step 1. CPT-Based Soil Classification and Interpretation of Consolidation Parameters</p>
<p>The cone penetration test (CPT) is a commonly used in situ testing method for soil classification and characterization of subsurface geotechnical property profiles.CPT provides direct continuous vertical line measurements of cone pressure, sleeve friction, and pore pressure.Apart from soil classification, CPT data can also be used to estimate the soil properties of fine-grained materials via empirical correlations established in the literature (e.g., Robertson and Cabal [98]).</p>
<p>Step 2. Stratigraphic Uncertainty Modeling by IC-XGBoost2D</p>
<p>The iterative convolution extreme gradient boosting (IC-XGBoost2D) is a stochastic simulation algorithm for developing 2-D subsurface geological cross sections from training images and limited site-specific measurements.</p>
<p>A training image reflects prior geological knowledge at the area of interest and serves as an effective supplement to limited site-specific data (99).</p>
<p>Step 3. Modeling Soil Property Spatial Variability from Limited Measurements Bayesian compressive sampling (BCS) is a nonparametric machine learning method developed for interpolating spatially varying geo-properties (e.g., cone pressure) from sparse measurements.Under compressive sensing/sampling, a complete signal (e.g., 2-D spatially varying soil property profiles) can be approximated as a weighted summation of a limited number of pre-specified basis functions (e.g., discrete cosine basis functions).</p>
<p>Step 4. Sequential Modeling of Soil Property Spatial Variability for Each Soil Type</p>
<p>Once subsurface geological cross sections or realizations are developed using IC-XGBoost2D, the best estimate of cone pressure, sleeve friction, and pore pressure within the 2-D cross section with high spatial resolution can be obtained using BCS and CPT measurements.</p>
<p>Scour Assessment Using ML</p>
<p>Various recent studies have looked into applications of AI-ML in geohazard assessment and management for geotechnical systems (100,101).In this paper, we focus on scour as one of the most critical mechanisms affecting bridge foundations and how ML techniques can be implemented step by step to provide more reliable bridge scour estimation and real-time risk assessment for design and maintenance purposes, respectively.</p>
<p>In the past two decades, numerous studies have explored local scour prediction around bridge piers using ML.SVM, genetic algorithms (102,103), and artificial neural networks (ANNs), particularly FFNN or multilayer perceptrons (MLP) (104)(105)(106)(107) are among the most commonly used techniques.These ML methods have shown superior performance over traditional empirical equations in the accuracy of maximum scour depth predictions for a given training data set; however, the generalization ability of these types of predictive models decays significantly outside the convex hull of the training data set, which can lead to poor generalization to unseen data (108).Therefore, to use these models for maximum scour depth prediction, the bridge characteristics must be within the training database range.A good review of the literature can be found in Sharafati et al. (109).</p>
<p>Given the limitations of the current scour prediction models, the complexity of scour phenomenon, uncertainty in flow (flood levels), riverbed and geomorphological conditions, real-time monitoring, and forecast to manage the scour risk is evolving as a promising tool.Yousefpour et al. (107,108) have pioneered this approach by using historical monitoring data from bridge piers, including timeseries of scour depth and river flow depth variation.In their approach, they have used both DL and Bayesian inference methods that have shown reasonable accuracy in providing real-time assessment of scour depth.In their most recent study, they have developed long short-term memory (LSTM) models that can provide estimates of scour depth a week in advance for case study bridges in Alaska (108).</p>
<p>Based on a critical review of the existing methods, the following techniques are recommended for maximum (design) and real-time scour depth prediction (maintenance).</p>
<p>Maximum Scour Depth Prediction Using Feed-Forward Neural Networks</p>
<p>Fully connected FFNNs or MLPs are powerful in representing nonlinear high dimensional processes influenced by multiple physical factors.MLPs are universal approximators theoretically capable of approximating any function, even with only one hidden layer with enough nonlinear computational units (neurons) (110,111).</p>
<p>The application of FFNNs in developing scour prediction models has been explored by numerous studies, as referenced in the previous section.Many used the US National Scour Study database developed by the US Geological Survey (USGS) in collaboration with the Federal Highway Administration (FHWA) (1, 2).However, these models can hardly be used in mainstream scour design.The major obstacles in upscaling such ML models to practice are: 1) Poor generalization/extrapolation capacity: This is a result of the dependency of ML models on the range of training data, meaning ML models need to be trained with a database that is statistically representative of a particular bridge.2) Database deficiencies and poor statistical design:</p>
<p>Databases are built with stitching scattered data sets without much statistical design, involving many variables that show sparse range across the various data sets.3) Errors and subjectivity in measurements: This issue with scour depth measurement requires a judgment on the reference surface.Different judgments/assumptions on reference levels such as ambient bathymetric, as-built, or maximum bed levels can result in different reported scour depth in field measurement data.For more information, refer to Landers and Mueller (1).4) ML knowledge and implementation complexities: Lack of ML (and coding) knowledge and experience in practice engineers, along with a lack of guidelines, hinder AI-ML application for bridge scour design.</p>
<p>The following methodology is proposed to develop a simple ML model to estimate the maximum scour depth with a confidence bound for a new bridge.For more details on the approach, readers are referred to Yousefpour et al. (107).Engineering due diligence and quality control checks must be taken when applying this method for design:</p>
<p>Step 1. Database Compilation.Using the USGS National Bridge Scour Database, a ''global'' ML model can be trained first.This model needs to be later retrained (transfer learning as explained in step 2) using a ''local'' or site-specific database with a well-designed statistical distribution.The local database should include data from several bridges with relatively similar riverbeds, flow, and structural characteristics.The key input/target parameters for the scour ML model are listed below, as identified in many earlier studies.These parameters for the new bridge should lie in the convex hull of the local database for a reliable scour prediction:</p>
<p>Input parameters (features)</p>
<p>Sediment transport (scour type): This can be divided into live-bed or clear-bed.In clear-water conditions, there is limited transport of bed material into the channel from upstream, whereas, in live-bed conditions, materials are transported through upstream flow and deposited downstream (filling after scour).For more details on the definition, refer to Landers and Mueller (1)  ) and can be measured on site or extracted from bridge plans/ drawings.</p>
<p>Bed condition: This determines the cohesive or non-cohesive nature of sediments around the bridge.</p>
<p>Sediment size: Median grain size (D 50 ) can be measured from sampling at the site or from bridge design site investigation reports.The common sampling methods are explained in Landers and Mueller (1).</p>
<p>Target parameter (output)</p>
<p>Scour depth: This should be measured after a flood event-within 24 to 48 h in a live-bed scour situation (mostly observed in non-cohesive river beds); this allows reaching to equilibrium scour depth.For clear-bed scour the time-dependency of scour needs to be established to determine the suitable time of scour depth measurements.</p>
<p>The key point in this step is to develop a statistically well-designed database that can be representative of the population of bridges in a region of interest.The importance of the statistical design of databases is seemingly overlooked in the current literature, especially given the surge of featureless DL approaches.By referring to core statistical knowledge, we know that the skewness of a database (especially for smaller data sets) can lead to the model favoring specific parameters and trends in the data (bias), which results in unreliable predictions.To have a well-designed database, the statistical distribution of all parameters in the database should be analyzed to ensure that there is a relatively uniform distribution across the range of variability.The data should be normalized before training the ML model.</p>
<p>Step 2. Developing a ''Simple Enough'' ML Model.A simple MLP (FFNN) network is shown in Figure 3.A threelayer architecture, with one hidden layer applying a sigmoid activation function such as the ones explained in Yousefpour et al. (112) can be followed.For regression problems, using more than one layer and too many units often does not lead to more accurate predictions.For theoretical details of MLP algorithms, readers are encouraged to refer to Hornik (110).Training in MLPs means adjusting the weights and biases to reach the universal minimum of a loss function, which is usually defined as the mean of squared prediction errors (MSE) across the training database.However, more often than not, optimization techniques find a local minimum instead of the global minimum.Several techniques can be implemented to avoid being trapped in a local minimum, such as regularization, cross-validation, and early stopping, among others.A practical method is early stopping based on a ''patience number,'' which is the maximum consecutive number of times to allow the error to increase over a validation data set during training (113,114).</p>
<p>The generalization of ML models is assessed based on a test data set, which represents the model performance on unseen data.Several metrics can be used for this purpose, including RMSE, coefficient of determination (R 2 ), MSE, and MAE.MAE and RMSE allow error measurement in the same unit as the target parameter.</p>
<p>Transfer learning has been proven to improve the performance of ML models significantly (115).In this method, instead of training an ML model from scratch, that is, starting from a random point in the space of weights and biases, the model is initialized using a set of parameters from a previously trained model.In the context of image data and pattern recognition, this can have a tremendous effect; therefore, using pre-trained models is a must.In the context of scour prediction, this can mean ''transferring the learning'' from a model trained using a global database of scour to a site-specific ML model that needs to be trained with a local database.</p>
<p>For this purpose, first a ''global ML'' model can be trained according to the recommendations in step 1, then a ''local ML'' can be trained, initializing from the set of weights and biases of the trained global model.</p>
<p>Step 3. Validation and Fine-Tuning.Using an ensemble of models provides more accuracy in predictions and enables uncertainty assessment.An ensemble of FFNN can be generated by repeating (random initiation of network weights and biases) the training over many times ( + 50) to find a group (ensemble) of best models.The  ensemble's performance can be reported by using firstorder statistics of the resulting distributions.Readers are referred to Yousefpour (3), Bateni et al. (104), and Sagi and Rokach (116) for more details on ensemble methods.</p>
<p>One of the most effective cross-validation techniques that also can be integrated with the ensemble method, is to use K-fold or Monte Carlo cross-validation (117) (as opposed to the hold-out method) to enable making the most out of a small database.In this technique, the networks in the ensemble use various parts of the data for training, validation, and testing, as shown in Figure 4.</p>
<p>Fine-tuning and hyperparameter optimization can lead to superior network configurations.The main hyperparameters for an FFNN model include the number of hidden layers, the number of units in each hidden layer, the type of activation function in units, input feature selection/combination, optimization, and training parameters such as learning rate, maximum number of epochs, and early stopping criteria (patience number, minimum error, etc.).The most commonly used hyperparameter search techniques are grid-search and random search, which can be applied to speed up the optimization process (108,118).Several available codes and libraries in Python can be readily applied, such as Optuna and Talos (119).</p>
<p>Step 4. Assessment of ML Predictions.The ensemble of the best FFNNs generates a distribution of predictions on scour depth for a given bridge.Having a larger ensemble ensures the uncertainty is better captured.Mean, standard deviation, and 95% confidence bound can be reported from the generated distribution.We recommend scatter-plotting the scour depth versus velocity and flow depth for all the records in the local database and locating where the ML prediction lies within the local and global database.The ultimate judgment on the scour depth estimates for a given bridge at a target flood level (e.g., 200-year return period), needs to be based on both the ML prediction and the historic local trends observed from past flood events.</p>
<p>Real-Time Scour Assessment Using Deep Learning</p>
<p>Regular inspection and monitoring of the scour in existing bridges has been mandatory in the United States and some other countries because of frequent catastrophic events in the past few decades caused by scour failure of bridges.Scour is the most common cause of failure for bridges, with approximately 260,000 scour critical bridges across the country (120).Given the shortcomings in scour depth estimation with existing methods, many bridges are highly vulnerable to scour.The US NBI has identified the scour risk of all bridges in the United States with a ''scour-vulnerability'' index (121).This index is assessed based on regular scour inspection and monitoring mandated by FHWA.</p>
<p>Real-time monitoring for bridges exposed to a higher risk of scour can enable reliable risk management and a data-driven understanding of scour process.Several US Departments of Transportation (DOT) in partnership with USGS have started rigorous scour monitoring programs for their most vulnerable bridges.States such as Alaska, with most bridges exposed to seasonal flooding, started this program in the early 2000s (available at Alaska Science Center).Other states such as Idaho, Colorado, and Oregon, have followed similar approaches.This monitoring program allows for real-time measurement of bed elevation and flow level at a bridge pier using sonic/echosounder devices (see Figure 5) that measure the distance based on the sonic wave travel time within a specific material (water or air).For more details, readers are referred to USGS published reports for each state (122).</p>
<p>Yousefpour et al. (107,108) studied the historic Alaska monitoring data in their recent research to develop scour forecast and early warning models using DL methods.They have proposed an AI-based methodology for realtime scour assessment to enable more reliable risk assessment for critical bridges.The DL models can also provide insights into estimating the maximum scour depth for new bridges within the same region with similar flow, structure, and characteristics.The proposed methodology can be implemented for the assessment of scour in existing bridges as per the following steps:</p>
<p>Step 1. Collecting Site-Specific Historic Scour Data: Continuous Measurement of Bed and Flow Level (and Velocity) Variation..A review of existing scour field monitoring data can be found in Hunt (123).Despite the challenges of sensor readings, which may result in missing data across a year, such as sensor damage resulting from flooding, accumulation of trash and debris, and vandalism, they can provide valuable information about the scour process for a particular bridge.The generated timeseries data of flow depth and scour depth enable site-specific scour assessment, which can be powerful in addressing the ''extrapolation'' problem of ML models discussed in the previous section.</p>
<p>Any type of sensor that can continuously measure flow and bed levels can be instrumental.The measurement of bed elevation measurement using sonar sensors is well explained in Henneberg (124).Current methods for measurement of flow level or stage are explained in Sauer and Turnipseed (125).Flow velocity measurements are also recommended, which can be measured by acoustic doppler and velocimeters as described in Sauer and Turnipseed (126).</p>
<p>Step 2. Data Processing.Data processing is a vital step before ML development.Although DL models have been proven to be powerful in addressing noise and outliers in training data (108,118,127), performing the following processing can enable faster learning and more reliable performance: 1) Basic cleaning and synchronization of timeseries:</p>
<p>For scour sensor data, that could mean ensuring random errors in data are removed and ensuring a reasonable resolution (reading intervals) for all timeseries data and synchronizing the readings among various sensors, such as bed elevation, flow elevation, and velocity.Down-sampling and up-sampling can be performed to ensure the data are captured with reliable resolution.For scour, half-hourly or hourly readings are recommended as scour and flooding can develop within a few hours.2) Outlier detection: Detecting outliers is essential as it can mislead the model with seemingly correct but erroneous readings.Figure 6 shows an example of how accurate outlier detection can affect identifying the true trend of the scour data.One of the common methods for outlier rejection is the median absolute deviation (MAD) method.Data is first normalized (standard normal) and points with absolute values greater than 3.5 are defined as outliers within a selected time window.The length of this window is critical and needs to be adjusted depending on reading intervals and expected time variations in the data.For instance, variation in scour depth (in case of live-bed scour) can happen within a few hours to a few days.MAD is more robust than traditional standard deviation methods and less sensitive to outliers and extremes.3) Missing data imputation: This is very common for scour data resulting from blockage of sensors by debris accumulation or flood-related disturbance, among other reasons.Therefore, applying emerging imputation techniques in cases where the available data is sparse but nevertheless valuable in understanding the scour trend is essential.Moritz and Bartz-Beyerstein (128) provide an overview of univariate timeseries imputation techniques.One of the simplest methods is linear interpolation and more advanced methods, such as the Gaussian process can enable more realistic data representations (129).4) Smoothing and filtering: Moving average and other auto-regressive methods can be quite powerful for timeseries smoothing and denoising (130,131).They have specifically been found useful for sonar and stage sensor data (171).Signal processing methods such as the low-pass filtering technique can enable removing extreme frequency ranges from the data.Figure 7 shows how these different methods compare for sonar data from a bridge in Alaska.</p>
<p>Step 3. Developing DL Models: LSTMs and CNNs.In RNNs, the output of each neuron goes back to itself, and the units in the subsequent layer at each time step.This enables these algorithms to keep a ''memory'' of past ''activations.''LSTM networks are particular types of RNN that use special ''gates''-input, forget, and output gates-to update the memory state at each step, as shown in Figure 8 (132).This enables LSTMs to maintain a short and long-term memory of temporal patterns within timeseries data and incorporate them into future predictions.LSTMs have shown superiority compared with other RNNs for timeseries forecasting in various fields, owing this success to their ability to overcome the problem of vanishing gradients (133).For scour forecasting, Yousefpour and Correa (108) showed that LSTM can provide far more accurate predictions of scour compared with empirical equations.In their case studies on Alaskan bridges, they developed three variants of LSTM algorithms that can provide scour prediction seven days in advance with an average error of 0.2 to 0.35m.In a more recent study, they explored applying CNNs as a more computationally efficient DL algorithm for real-time forecast of scour, and  compared CNN and LSTM performance on data from Alaskan bridges (118).Results showed competitive performance by temporal CNNs with significantly lower computational cost.Figure 9 shows the LSTM and CNN architectures used in these studies for sonar timeseries prediction.</p>
<p>The training of DL models is done by timeseries sequences generated by slicing the whole timeseries data   into smaller sequences (data slices) using a sliding window.This process is explained in detail in Yousefpour and Correa (108).The sliding window moves over the database one timestep at a time.Each sequence (data slice) has an ''input'' and a ''target'' or ''label'' segment, as shown in Figure 10.The training is done in batches containing several data slices.The network's weights and biases are adjusted like MLPs by minimizing the error of prediction over the label length of data slices.</p>
<p>Step 4. Fine-Tuning and Validation of DL.To obtain the optimal configuration of these DL algorithms, hyperparameter tuning must be performed, similar to what was recommended for FFNNs in the previous sections.One important hyperparameter in timeseries forecasting is the input and label width and their ratio.The impact of selecting the most optimal sequence length to ensure the temporal variations in the data are well explained in Yousefpour and Correa (108) and Yousefpour and Pouragha (134).The label width is the length of forecast window and should be selected to provide enough time for implementing proper risk countermeasures.In case of bridge scour, a minimum of seven days was deemed necessary.</p>
<p>Cross-validation methods similar to FFNNs can be implemented to improve the performance of the DL models and reduce the chances of overfitting.One crucial difference is the temporal dependencies in timeseries data, which can make data division for training a bit absurd.We recommend ensuring that training, validation, and testing are consecutive unless time is introduced as an additional feature to the models.Methods such as K-fold cross-validation can be implemented sequentially, as shown in Figure 11.In this method, the model is retrained at each step using transfer learning; the test data set in each step needs to be free of overlaps with the previous step data to avoid evaluating the model over ''seen'' data.A hold-out test data set can be kept aside to evaluate the final model at the end of sequential training.This metric can be compared and reported with the average performance of models over test data sets across the sequential training steps.</p>
<p>The prediction of the DL model over data slices that have continuous overlaps results in overlap in predictions which will provide an uncertainty assessment opportunity.In addition, repeating the training several times provides a range of predictions that can be included in the set of predictions.Based on that, confidence intervals and the meaning of predictions can be established.Figure 12 shows an example of an LSTM and CNN model prediction over a test subset for an Alaskan bridge (118).</p>
<p>In addition to metrics of average error (MSE, MAE, or RMSE), the DL model predictions should be evaluated for trend detection, that is, peaks and troughs through fill and scour episodes.The error in prediction of peaks and troughs can provide another performance metric for the scour forecast model performance (read more in Yousefpour and Correa [108]).</p>
<p>Step5.Assessment of Upcoming Scour.The proposed realtime DL forecast models can provide a tool for risk assessments of an upcoming scour event.The uncertainty and reliability of the forecast must be assessed using engineering judgment by also evaluating meteorological   and flood forecasts and the available historical trends for a particular bridge and/or similar bridges in a region.Lower bounds of scour depth predictions are recommended to minimize risk in detected major scours.Using real-time cameras or aerial photography (e.g., drones) can provide further inputs for more reliable decision making and taking the most appropriate plans of action to manage scour failure risks.</p>
<p>Conclusions</p>
<p>This paper discussed emerging AI-ML techniques for subsurface site characterization and geohazard assessments.Our review revealed that ML can be a promising solution for characterizing subsurface conditions and geomaterials.ML algorithms make more accurate predictions than traditional empirical correlations, while the interpretation and explanation of ML models need to be regarded as a secondary objective.There is no consensus on an ''optimal'' ML/DL algorithm for subsurface site characterization, even when looking at the results of the most recent comparative studies in the prediction of physical and mechanical properties of geomaterials.The choice between adopting conventional ML (ANN, RF, SVM, etc.) or DL algorithms primarily depends on the type and quantity of available data and if explicit expressions are preferred.The uncertainty associated with subsurface features (layer boundaries, discontinuities, voids, anomalies, etc.), spatial variability of geo-properties and ML modeling is another issue that needs further exploration.In the assessment of geohazards, bridge scour was the focus of this paper; nevertheless, the reviewed and recommended techniques can be applied to other types of geohazards.A step-by-step methodology for implementing both traditional ML and emerging DL methods was discussed in application to prediction and real-time forecasting of scour for bridge foundations.The guidelines and provided references can pave the way for implementing similar ML methods in practice.Some of the obstacles and challenges of applying these methods were also highlighted.</p>
<p>Figure 1 .
1
Figure 1.Machine learning survey: What are the machine learning applications that can transform value for our industry in the next 10 years?(Select all that apply).</p>
<p>Pham et al. (76) compared the performance of four machine learning methods: particle swarm optimization-adaptive network based fuzzy inference system (PANFIS), genetic algorithm-adaptive network based fuzzy inference system (GANFIS), SVR, and artificial neural networks (ANN) for predicting the undrained shear strength of soft soils, collected from two bridge projects in Vietnam.Nguyen et al. (77) developed a backpropagation neural network (BPNN) machine learning model to predict the internal friction angle of the soil based on 145 soil samples collected from Da Nang-Quang Ngai expressway project in Vietnam.With soil samples from another region in Vietnam, Mittal et al. (78) developed ML models, that is, multiple linear regression (MLR), ANN, SVR, and adaptive network based fuzzy inference system (ANFIS), to predict the coefficient of consolidation in the soil.Saedi and Mohammadi (79) investigated the relation between UCS (Unconfined Compression Strength) and E (Stiffness) of migmatites and microstructural characteristics using image processing and ANN techniques.Li et al. (80) developed a database containing both saturated and unsaturated hydraulic and mechanical soil properties in Singapore to predict unknown parameters, for example, permeability and soil-water characteristic curve (SWCC), using RF and ANN.Lin et al. (81) developed an ANN model to map the shear strength and compressibility of soft soils based on a database consisting of over 2,000 sets of physical and mechanical properties for soft soils in Zhuhai city, China.Liu et al. (28) developed three ML models-ANN, RF, and SVM-to map the two compressibility indices based on a database consisting of 743 sets of physical properties and corresponding compression indices for soft soils in Shenzhen, China.Niyogi et al.</p>
<p>Note: ML = machine learning; PANFIS = particle swarm optimization-adaptive network based fuzzy inference system; GANFIS = genetic algorithmadaptive network based fuzzy inference system; SVR = support vector regression; ANN = artificial neural network; BPNN = backpropagation neural network; MLR = multiple linear regression; ANFIS = adaptive network based fuzzy inference system; RF = random forest; SVM = support vector machine; DNN = deep neural network.</p>
<p>Figure 2 .
2
Figure 2. Predicted versus measured cone penetration test (CPT) undrained shear strength (in kPa) over the test data set.The vertical line shows the estimated standard deviation.The black dashed line is the 1:1 line.</p>
<p>Figure 3 .
3
Figure 3. Simple architecture for MLP/FNN (3).</p>
<p>Note: MLP = multilayer perceptron; FNN = feed-forward neural network.</p>
<p>Figure 4 .
4
Figure 4. Cross-validation methods: (a) K-Fold; and (b) Monte Carlo.</p>
<p>Figure 5 .
5
Figure 5. Sensors mounted on bridge piers in California and Alaska for continuous measurement of river water and bed elevation: (a) solar-powered stage; and (b) sonar.Source: Photo courtesy of Alaska USGS and Renesys.</p>
<p>Figure 6 .
6
Figure 6.Outlier detection in sonar (scour) data, comparing various denoising and filtering techniques.</p>
<p>Figure 7 .
7
Figure 7. Comparing various filtering/smoothing methods for sonar timeseries data.</p>
<p>Figure 8 .
8
Figure 8.Long short-term memory (LSTM) unit-showing details of input, output, and forget gates; x t = input feature at time step t; c t = cell memory state; h t = hidden state or output at time step t; s = sigmoid activation function; tanh = hyperbolic tangent function (108).</p>
<p>Figure 9 .
9
Figure 9. Architectures of networks for scour forecast: (a) LSTM; and (b) CNN: iw = input width; lw = label (output) width of a data slice (118).</p>
<p>Note: LSTM = long short-term memory; CNN = convolutional neural network.</p>
<p>Figure 10 .
10
Figure 10.Data slicing for scour timeseries forecasting with deep learning (DL): (a) example of a data slice (sequence) and how it is fed into a DL model; and (b) slicing the timeseries data using a sliding window, including input plus label sequence.</p>
<p>Figure 11 .
11
Figure 11.Sequential K-fold cross-validation with transfer learning: the arrow shows transfer learning between training steps.</p>
<p>Figure 12 .
12
Figure 12.Scour forecast (seven days in advance) over a test subset of data (June to Oct, 2021) from the top five best LSTM and CNN models (118).</p>
<p>Note: LSTM = long short-term memory; CNN = convolutional neural network.</p>
<p>Table 1 .
1
Summary of DL and ML Algorithms Used in Stratigraphy Classification Study
TargetStratum typeLithofaciesStratum typeSedimentary faciesSedimentary faciesRock type of iron oreMineralization typeStrataIso-value of potential fieldRock typesScalar field, rockStratum typeInputStrataPixel valueStrataPositionLog parametersPosition, mineral componentsStrata, rock, gravity, andmagneticPosition, orientationPosition, orientationPosition, residual density, andmagnetic susceptibilityGraph adjacency matrix, graphnode matrixCoordinates, elevationDataBoreholesTraining image of flowTraining image of geologicalcross sectionsWells, geology map, sectionsWell-logsDrill holesBoreholes, sections, geologicalmapWellsOrientation measuresBorehole and 3-D inversionmodelBorehole, orientationBoreholesDL or ML algorithmMultiple-point geostatisticsCNNXGBoostSVMSVMDecision treeRFMaximum likelihoodGaussian processStacking methodGNNRNNMariethoz and Caers (34)Bai and Tahmasebi (35)Shi and Wang (36)Smirnoff et al. (37)Wang et al. (38)Adeli et al. (39)Xiang et al. (40)Gonc xalves et al. (41)Gonc xalves et al. (42)Jia et al. (43)Hillier et al. (44)Zhou et al. (45)
Note: DL = deep learning; ML = machine learning; CNN = convolutional neural network; SVM = support vector machine; RF = random forest; GNN = graph neural network; RNN = recurrent neural network.</p>
<p>Table 2 .
2
Case Studies Recently Published by Some of the Most Prolific Authors Adopting ML for Site-or Region-Specific Analyses, Comparing the Performance of Different ML Algorithms
StudyML algorithmsPredicted parametersRegionPham et al. (76)PANFIS, GANFIS, SVR, ANNUndrained shear strength of softNhat Tan and Cua Dai bridges insoilsViet NamNguyen et al. (77)BPNNFriction angleDa Nang-Quang Ngaiexpressway project, VietnamMittal et al. (78)MLR, ANN, SVR, ANFISCoefficient of consolidationHa Noi-Hai Phong highwayproject, VietnamSaedi and Mohammadi (79)ANNUnconfined CompressionSanandaj-Sirjan, Takab,Strength (UCS) andHamedan, Borujerd, andStiffness (E)Neyriz sites in IranLi et al. (80)RF, ANNPermeability, soil-waterSingaporeCharacteristic Curve (SWCC)Lin et al. (81)ANNShear strength andZhuhai, ChinacompressibilityLiu et al. (28)ANN, RF, SVMModulus of compression andShen Zhen, Chinacoefficient of compressibilityNiyogi et al. (82)SVM, RF, DNNLateritic soil shear strengthThe Ratnagiri-Sangameshwarsection of National Highway66 in Maharashtra, India
AcknowledgmentWe acknowledge the contribution of Fatemeh Safari Honar in preparing the figures for this paper.Funding for this publication is provided by the Norwegian Geotechnical Institute, Oslo and the University of Melbourne.FundingThe author(s) disclosed receipt of the following financial support for the research, authorship, and/or publication of thisAuthor ContributionsThe authors confirm contribution to the paper as follows: study conception and design: Negin Yousefpour, Zhongqiang Liu; data collection: Negin Yousefpour, Zhongqiang Liu, Chao Zhao; analysis and interpretation of results: Negin Yousefpour, Zhongqiang Liu, Chao Zhao; draft manuscript preparation: Negin Yousefpour, Zhongqiang Liu, Chao Zhao.All authors reviewed the results and approved the final version of the manuscript.Declaration of Conflicting InterestsThe author(s) declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.
Channel Scour at Bridges in the United States. M N Landers, D S Mueller, Federal Highway Administration. Washington, D.C.1996</p>
<p>D S Mueller, C R Wagner, Field Observations and Evaluations of Streambed Scour at Bridges. Office of Engineering Research and Development, Federal Highway Administration. McLean, VA2005</p>
<p>Comparative Deterministic and Probabilistic Modeling in Geotechnics: Applications to Stabilization of Organic Soils, Determination of Unknown Foundations for Bridge Scour, and One-Dimensional Diffusion Processes. N Yousefpour, 2013Texas A&amp;M UniversityPhD dissertation</p>
<p>Applications of Machine Learning in Geotechnics. N Yousefpour, S Fallah, Proc., Civil Engineering Research in Ireland Conference. Civil Engineering Research in Ireland ConferenceCork2018</p>
<p>Application of Deep Learning Algorithms in Geotechnical Engineering: A Short Critical Review. W Zhang, H Li, Y Li, H Liu, Y Chen, X Ding, Artificial Intelligence Review. 5482021</p>
<p>Prediction of Undrained Shear Strength Using Extreme Gradient Boosting and Random Forest Based on Bayesian Optimization. W Zhang, C Wu, H Zhong, Y Li, L Wang, Geoscience Frontiers. 1212021</p>
<p>Pathways and Challenges of the Application of Artificial Intelligence to Geohazards Modelling. A Dikshit, B Pradhan, A M Alamri, Gondwana Research. 1002021</p>
<p>F S Tehrani, M Calvello, Z Liu, L Zhang, S Lacasse, Machine Learning and Landslide Studies: Recent Advances and Applications. 2022114</p>
<p>Future of Machine Learning in Geotechnics. K K Phoon, W Zhang, Georisk: Assessment and Management of Risk for Engineered Systems and Geohazards. 1712023</p>
<p>Neural Approaches to Conversational AI. J Gao, M Galley, L Li, Proc., 41st International ACM SIGIR Conference on Research and Development in Information Retrieval. 41st International ACM SIGIR Conference on Research and Development in Information RetrievalAnn Arbor, MI2018</p>
<p>Computer Vision Applications in Construction Safety Assurance. Automation in Construction. W Fang, L Ding, P E Love, H Luo, H Li, F Pena-Mora, B Zhong, C Zhou, 2020110103013</p>
<p>Safe Learning in Robotics: From Learning-Based Control to Safe Reinforcement Learning. L Brunke, M Greeff, A W Hall, Z Yuan, S Zhou, J Panerati, A P Schoellig, Annual Review of Control, Robotics, and Autonomous Systems. 52022</p>
<p>Data Driven Finance: A Bibliometric Review and Scientific Mapping. A Bashar, M R Rabbani, S Khan, M A Moh'd Ali, Proc., International Conference on Data Analytics for Business and Industry. International Conference on Data Analytics for Business and IndustrySakheer, Bahrain2021</p>
<p>AI-Based Modeling and Data-Driven Evaluation for Smart Manufacturing Processes. M Ghahramani, Y Qiao, M C Zhou, A O Hagan, J Sweeney, IEEE/CAA Journal of Automatica Sinica. 742020</p>
<p>Deep Learning: A Comprehensive Overview on Techniques, Taxonomy, Applications and Research Directions. I H Sarker, SN Computer Science. 264202021</p>
<p>Review of Deep Learning Algorithms and Architectures. A Shrestha, A Mahmood, IEEE Access. 72019</p>
<p>Deep Convolutional Neural Networks for Image Classification: A Comprehensive Review. W Rawat, Z Wang, Neural Computation. 2992017</p>
<p>Deep Learning in Neural Networks: An Overview. J Schmidhuber, Neural Networks. 612015</p>
<p>Attention is All You Need. A Vaswani, N Shazeer, N Parmar, J Uszkoreit, L Jones, A N Gomez, Q Kaiser, I Polosukhin, Advances in Neural Information Processing Systems. 302017</p>
<p>Generative Adversarial Text to Image Synthesis. S Reed, Z Akata, X Yan, L Logeswaran, B Schiele, H Lee, Proc., 33rd International Conference on Machine Learning. 33rd International Conference on Machine LearningNew York, NY2016</p>
<p>A Review of Vibration-Based Damage Detection in Civil Structures: From Traditional Methods to Machine Learning and Deep Learning Applications. O Avci, O Abdeljaber, S Kiranyaz, M Hussein, M Gabbouj, D J Inman, Mechanical Systems and Signal Processing. 1471070772021</p>
<p>Data-Driven Structural Health Monitoring and Damage Detection Through Deep Learning: State-of-the-Art Review. M Azimi, A D Eslamlou, G Pekcan, Sensors. 201027782020</p>
<p>The State of the Art of Data Science and Engineering in Structural. Y Bao, Z Chen, S Wei, Y Xu, Z Tang, H Li, Health Monitoring. Engineering. 522019</p>
<p>Model-Free Reinforcement Learning with Model-Based Safe Exploration: Optimizing Adaptive Recovery Process of Infrastructure Systems. M Memarzadeh, M Pozzi, Structural Safety. 802019</p>
<p>A Novel Predictive Maintenance Method based on Deep Adversarial Learning in the Intelligent Manufacturing System. C Liu, D Tang, H Zhu, Q Nie, IEEE Access. 92021</p>
<p>Deep Learning in the Construction Industry: A Review of Present Status and Future Innovations. T D Akinosho, L O Oyedele, M Bilal, A O Ajayi, M D Delgado, O O Akinade, A A Ahmed, Journal of Building Engineering. 321018272020</p>
<p>Smart Transportation Planning: Data, Models, and Algorithms. Z Karami, R Kashef, Transportation Engineering. 21000132020</p>
<p>Machine Learning Approaches to Estimation of the Compressibility of Soft Soils. H Liu, P Lin, J Wang, Frontiers in Earth Science. 1111478252023</p>
<p>W Gong, C Zhao, C H Juang, H Tang, H Wang, X Hu, Stratigraphic Uncertainty Modelling with Random Field Approach. 2020125103681</p>
<p>Identification of Weak Layers and Their Role for the Stability of Slopes at Finneidfjord, Northern Norway. J S L'heureux, O Longva, A Steiner, L Hansen, M E Vardy, M Vanneste, H Haflidason, Proc., Submarine Mass Movements and Their Consequences: 5th International Symposium. Submarine Mass Movements and Their Consequences: 5th International SymposiumNetherlandsSpringer2012</p>
<p>3D-Reconstruction of Complex Geological Interfaces from Irregularly Distributed and Noisy Point Data. T Frank, A L Tertois, J L Mallet, Computers and Geosciences. 3372007</p>
<p>A Karpatne, I Ebert-Uphoff, S Ravela, H A Babaie, V Kumar, Machine Learning for the Geosciences: Challenges and Opportunities. 201831</p>
<p>Progressive Geological Modeling and Uncertainty Analysis Using Machine Learning. H Li, B Wan, D Chu, R Wang, G Ma, J Fu, Z Xiao, ISPRS International Journal of Geo-Information. 123972023</p>
<p>Multiple-Point Geostatistics: Stochastic Modeling with Training Images. G Mariethoz, J Caers, 2014John Wiley &amp; SonsUK</p>
<p>Hybrid Geological Modeling: Combining Machine Learning and Multiple-Point Statistics. T Bai, P Tahmasebi, Computers and Geosciences. 1421045192020</p>
<p>C Shi, Y Wang, Development of Training Image Database for Subsurface Stratigraphy. Georisk: Assessment and Management of Risk for Engineered Systems and Geohazards. 202317</p>
<p>Support Vector Machine for 3D Modelling from Sparse Geological Information of Various Origins. A Smirnoff, E Boisvert, S J Paradis, Computers and Geosciences. 3422008</p>
<p>Identifying Organic-Rich Marcellus Shale Lithofacies by Support Vector Machine Classifier in the Appalachian Basin. G Wang, T R Carr, Y Ju, C Li, Computers and Geosciences. 642014</p>
<p>Geological Modelling and Validation of Geological Interpretations Via Simulation and Classification of Quantitative Covariates. A Adeli, X Emery, P Dowd, 2017Minerals87</p>
<p>3D Mineral Prospectivity Mapping with Random Forests: A Case Study of Tongling. J Xiang, K Xiao, E J M Carranza, J Chen, S Li, Natural Resources Research. 292020</p>
<p>A Machine Learning Approach to the Potential-Field Method for Implicit Modeling of Geological Structures. I ´ G Gonc Xalves, S Kumaira, F Guadagnin, Computers and Geosciences. 1032017</p>
<p>I ´ G Gonc Xalves, F Guadagnin, S Kumaira, S L Da, Silva, Machine Learning Model for Structural Trend Fields. 2021149104715</p>
<p>A Stacking Methodology of Machine Learning for 3D Geological Modeling with Geological-Geophysical Datasets. R Jia, Y Lv, G Wang, E Carranza, Y Chen, C Wei, Z Zhang, Computers and Geosciences. 1511047542021Laochang Sn camp</p>
<p>Three-Dimensional Structural Geological Modeling Using Graph Neural Networks. M Hillier, F Wellmann, B Brodaric, E Kemp, E Schetselaar, Mathematical Geosciences. 5382021</p>
<p>A Stratigraphic Prediction Method Based on Machine Learning. C Zhou, J Ouyang, W Ming, G Zhang, Z Du, Z Liu, Applied Sciences. 91735532019</p>
<p>Nonparametric and Data-Driven Interpolation of Subsurface Soil Stratigraphy from Limited Data Using Multiple Point Statistics. C Shi, Y Wang, Canadian Geotechnical Journal. 5822021</p>
<p>Development of Subsurface Geological Cross-Section from Limited Site-Specific Boreholes and Prior Geological Knowledge Using Iterative Convolution XGBoost. C Shi, Y Wang, Journal of Geotechnical and Geoenvironmental Engineering. 147940210822021</p>
<p>Machine Learning of Geological Details from Borehole Logs for Development of High-Resolution Subsurface Geological Cross-Section and Geotechnical Analysis. Y Wang, C Shi, X Li, Georisk: Assessment and Management of Risk for Engineered Systems and Geohazards. 1612021</p>
<p>Indicator Simulation Accounting for Multiple-Point Statistics. J M Ortiz, C V Deutsch, Mathematical Geosciences. 3652004</p>
<p>A Library of Training Images for Fluvial and Deepwater Reservoirs and Associated Code. M J Pyrcz, J B Boisvert, C V Deutsch, Computers and Geosciences. 3452008</p>
<p>Application of Bayesian Kriging to Subsurface Characterization. M M Nobre, J F Sykes, Canadian Geotechnical Journal. 2941992</p>
<p>Quantifying Uncertainty in Subsurface Systems. C Scheidt, L Li, J Caers, 2018John Wiley &amp; SonsHoboken, NJ</p>
<p>A Survey of Construction and Manipulation of Octrees. H H Chen, T S Huang, Computer Vision, Graphics, and Image Processing. 198843</p>
<p>Topology for 3-D Vector Maps. M Molenaar, International Journal of Applied Earth Observation and Geoinformation. 1992</p>
<p>3D Stratigraphic Models: Representation and Stochastic Modelling. G Caumon, J L Mallet, Proc., International Association for Mathematical Geology-XIth International Congres, Lie<code>ge. International Association for Mathematical Geology-XIth International Congres, Lie</code>geBelgium2006</p>
<p>Computer Techniques for Geological Characterization. S Houlding, Modeling Geoscience, 2012Springer Science &amp; Business MediaBerline</p>
<p>C H Randle, C E Bond, R M Lark, A A Monaghan, Uncertainty in Geological Interpretations: Effectiveness of Expert Elicitations. Geosphere201915</p>
<p>Artificial Neural Networks for Mineral-potential Mapping: A Case Study from Aravalli Province. A Porwal, E J M Carranza, M Hale, Western India. Natural Resources Research. 122003</p>
<p>Y Zhang, G Su, L Yan, Gaussian Process Machine Learning Model for Forecasting of Karstic Collapse. Proc., Applied Informatics and Communication: International Conference. Xi'an, China2011</p>
<p>Machine Learning Predictive Models for Mineral Prospectivity: An Evaluation of Neural Networks, Random Forest, Regression Trees and Support Vector Machines. V Rodriguez-Galiano, M Sanchez-Castillo, M Chica-Olmo, M Chica-Rivas, Ore Geology Reviews. 712015</p>
<p>Horizontal Shale Well EUR Determination Integrating Geology. A Gaurav, Machine Learning, Pattern Recognition and Multivariate Statistics Focused on the Permian Basin. Proc., SPE Liquids-Rich Basins Conference-North America. Odessa, Ukraine2017</p>
<p>Recognition and Measurement of Pavement Disasters based on Convolutional Neural Networks. A M Sha, Z Tong, J Gao, China Journal of Highway and Transport. 3112018</p>
<p>CPT-Based Subsurface Soil Classification and Zonation in a 2D Vertical Cross-Section Using Bayesian Compressive Sampling. Y Wang, Y Hu, T Zhao, 10.1139/cgj-2019-01312019</p>
<p>Neural Network Modeling and An Uncertainty Analysis in Bayesian Framework: A Case Study from the KTB Borehole Site. S Maiti, R K Tiwari, Journal of Geophysical Research: Solid Earth. 115B102010</p>
<p>3D Lithological Mapping of Borehole Descriptions Using Word Embeddings. I Fuentes, J Padarian, T Iwanaga, R W Vervoort, Computers &amp; Geosciences. 1411045162020</p>
<p>Evaluating Slope Stability Uncertainty Using Coupled Markov Chain. D Q Li, X H Qi, Z J Cao, X S Tang, K K Phoon, C B Zhou, Computers and Geotechnics. 732016</p>
<p>Quantifying Stratigraphic Uncertainties by Stochastic Simulation Techniques Based on. Z Li, X Wang, H Wang, R Y Liang, Markov Random Field. Engineering Geology. 2012016</p>
<p>. X H Qi, D Q Li, K K Phoon, Z J Cao, X S Tang, Simulation of Geologic Uncertainty Using Coupled Markov Chain. Engineering Geology. 2072016</p>
<p>Probabilistic Analysis and Design of Stabilizing Piles in Slope Considering Stratigraphic Uncertainty. W Gong, H Tang, H Wang, X Wang, C H Juang, Engineering Geology. 2591051622019</p>
<p>Probabilistic Characterization of Subsurface Stratigraphic Configuration with Modified Random Field Approach. C Zhao, W Gong, T Li, C H Juang, H Tang, H Wang, Engineering Geology. 2881061382021</p>
<p>Machine Learning-Enhanced Soil Classification by Integrating Borehole and CPTU Data with Noise Filtering. T Xiao, H F Zou, K S Yin, Y Du, L M Zhang, Bulletin of Engineering Geology and the Environment. 802021</p>
<p>X Wei, H Wang, Stochastic Stratigraphic Modeling Using Bayesian Machine Learning. 2022307106789</p>
<p>CPTU Correlations for Clays. K Karlsrud, T Lunne, D A Kort, S Strandvik, Proc., 16th International Conference on Soil Mechanics and Geotechnical Engineering. 16th International Conference on Soil Mechanics and Geotechnical EngineeringOsaka, Japan2005</p>
<p>P Paniagua, M D'ignazio, J -S. L'heureux, T Lunne, K Karlsrud, CPTU Correlations for Norwegian Clays: An Update. 20195</p>
<p>State-of-the-Art Review of Machine Learning Applications in Constitutive Modeling of Soils. P Zhang, Z Y Yin, Y F Jin, Archives of Computational Methods in Engineering. 282021</p>
<p>Prediction of Shear Strength of Soft Soil Using. B T Pham, T A Hoang, D M Nguyen, D T Bui, Machine Learning Methods. Catena. 1662018</p>
<p>Backpropagation Neural Network-Based Machine Learning Model for Prediction of Soil Friction Angle. T A Nguyen, H B Ly, B T Pham, Mathematical Problems in Engineering. 20202020</p>
<p>Prediction of Coefficient of Consolidation in Soil Using Machine Learning Techniques. M Mittal, S C Satapathy, V Pal, B Agarwal, L M Goyal, P Parwekar, Microprocessors and Microsystems. 821038302021</p>
<p>Prediction of Uniaxial Compressive Strength and Elastic Modulus of Migmatites by Microstructural Characteristics Using Artificial Neural Networks. B Saedi, S D Mohammadi, Rock Mechanics and Rock Engineering. 542021</p>
<p>Soil Database Development with the Application of Machine Learning Methods in Soil Properties Prediction. Y Li, H Rahardjo, A Satyanaga, S Rangarajan, D T T Lee, Engineering Geology. 3061067692022</p>
<p>Mapping Shear Strength and Compressibility of Soft Soils with. P Lin, X Chen, M Jiang, X Song, M Xu, S Huang, Artificial Neural Networks. Engineering Geology. 3001065852022</p>
<p>Machine Learning Algorithm for the Shear Strength Prediction of Basalt-Driven Lateritic Soil. A Niyogi, T A Ansari, S K Sathapathy, K Sarkar, T N Singh, Earth Science Informatics. 1612023</p>
<p>Robust Machine-Learning Workflow for Subsurface Geomechanical Characterization and Comparison Against Popular Empirical Correlations. H Li, S Misra, Expert Systems with Applications. 177149422021</p>
<p>A Unified Approach to Interpreting Model Predictions. S M Lundberg, S I Lee, Advances in Neural Information Processing Systems. 201730</p>
<p>Deep Neural Network Based Framework for Complex Correlations in Engineering Metrics. V Asghari, Y F Leung, S C Hsu, Advanced Engineering Informatics. 441010582020</p>
<p>Predictive Models for Permeability of Cracked Rock Masses Based on Support Vector Machine Techniques. G Ma, Z Chao, K He, Geotechnical and Geological Engineering. 392021</p>
<p>Intelligent Modelling of Clay Compressibility Using Hybrid Meta-heuristic and Machine Learning Algorithms. P Zhang, Z Y Yin, Y F Jin, T H Chan, F P Gao, Geoscience Frontiers. 1212021</p>
<p>A Novel Hybrid Intelligent Model for the Prediction of Creep Coefficients based on Random Forest and Support Vector Machine. C Chen, X Xue, Ocean Engineering. 2661131912022</p>
<p>Bayesian Neural Network-Based Uncertainty Modelling: Application to Soil Compressibility and Undrained Shear Strength Prediction. P Zhang, Z Y Yin, Y F Jin, Canadian Geotechnical Journal. 5942022</p>
<p>CPTU Prediction Model. 20190685- 01-TN. NGI2020NorwayNGITechncial Note</p>
<p>Uncertainty in Deep Learning, Doctoral Dissertation. Y Gal, 2016Cambridge, UKUniversity of</p>
<p>Coupled Characterization of Stratigraphic and Geo-Properties Uncertainties-A Conditional Random Field Approach. W Gong, C Zhao, C H Juang, Y Zhang, H Tang, Y Lu, Engineering Geology. 2941063482021</p>
<p>Probabilistic Slope Stability Analysis by Finite Elements. D V Griffiths, G A Fenton, Journal of Geotechnical and Geoenvironmental Engineering. 13052004</p>
<p>G Sauvin, M Vanneste, M E Vardy, R T Klinkvort, F Carl Fredrik, Machine Learning and Quantitative Ground Models for Improving Offshore Wind Site Characterization. Proc., Offshore Technology Conference. OTC, Houston, TX2019</p>
<p>Synthetic CPTs from Intelligent Ground Models Based on the Integration of Geology, Geotechnics and Geophysics as A Tool for Conceptual Foundation Design and Soil Investigation Planning. C F Forsberg, T Lunne, M Vanneste, L James, T I Tjelta, A Barwise, C Duffy, Proc., Offshore Site Investigation Geotechnics 8th International Conference Proceeding. Offshore Site Investigation Geotechnics 8th International Conference eedingLondon2017</p>
<p>M E Vardy, M A Clare, M Vanneste, C F Forsberg, J K Dix, Seismic Inversion for Site Characterization: When, Where and Why should We Use It? Proc., Offshore Technology Conference. Houston, TX2018</p>
<p>Assessment of Reclamation-induced Consolidation Settlement Considering Stratigraphic Uncertainty and Spatial Variability of Soil Properties. C Shi, Y Wang, Canadian Geotechnical Journal. 5972022</p>
<p>Guide to Cone Penetration Testing for Geotechnical Engineering. P K Robertson, K L , 2012Signal Hill, CAGregg Drilling and Testing</p>
<p>Multiple Point Statistics: A Review. P Tahmasebi, Handbook of Mathematical Geosciences: Fifty Years of IAMG. B Daya Sagar, Q Cheng, F Agterberg, ChamSpringer2018</p>
<p>H Ahmad, C Ningsheng, M Rahman, M M Islam, H R Pourghasemi, S F Hussain, J M Habumugisha, Geohazards Susceptibility Assessment along the Upper Indus Basin Using Four Machine Learning and Statistical Models. 202110315</p>
<p>Multi-Geohazards Susceptibility Mapping Based on Machine Learning-A Case Study in Jiuzhaigou. J Cao, Z Zhang, J Du, L Zhang, Y Song, G Sun, China. Natural Hazards. 10232020</p>
<p>Hybrid Computational Model for Predicting Bridge Scour Depth Near Piers and Abutments. J S Chou, A D Pham, Automation in Construction. 482014</p>
<p>NF-GMDH-Based Self-Organized Systems to Predict Bridge Pier Scour Depth Under Debris Flow Effects. M Najafzadeh, F Saberi-Movahed, S Sarkamaryan, Marine Georesources and Geotechnology. 3652018</p>
<p>Neural Network and Neuro-Fuzzy Assessments for Scour Depth around Bridge Piers. S M Bateni, S M Borghei, D S Jeng, Engineering Applications of Artificial Intelligence. 2032007</p>
<p>Artificial Neural Network Study of Observed Pattern of Scour Depth around Bridge Piers. A Kaya, Computers and Geotechnics. 3732010</p>
<p>Neural Network Modeling for Estimation of Scour Depth around Bridge Piers. T L Lee, D S Jeng, G H Zhang, J H Hong, Journal of Hydrodynamics. 1932007</p>
<p>Machine Learning Solutions for Bridge Scour Forecast based on Monitoring Data. N Yousefpour, S Downie, S Walker, N Perkins, H Dikanski, Transportation Research Record: Journal of the Transportation Research Board. 26752021</p>
<p>Towards an AI-Based Early Warning System for Bridge Scour. N Yousefpour, O Correa, Georisk. 1742023</p>
<p>The Application of Soft Computing Models and Empirical Formulations for Hydraulic Structure Scouring Depth Simulation: A Comprehensive Review, Assessment and Possible Future Research Direction. A Sharafati, M Haghbin, D Motta, Z M Yaseen, Archives of Computational Methods in Engineering. 2822021</p>
<p>Approximation Capabilities of Multilayer Feedforward Networks. K Hornik, Neural Networks. 421991</p>
<p>Approximation by Fully Complex Multilayer Perceptrons. T Kim, T Adali, Neural Computation. 1572003</p>
<p>Stiffness and Strength of Stabilized Organic Soils-Part II: Parametric Analysis and Modeling with. N Yousefpour, Z Medina-Cetina, F G Hernandez-Martinez, A Al-Tabbaa, Machine Learning. Geosciences. 1152182021</p>
<p>Probabilistic Evaluation of Unknown Foundations for Scour Susceptible Bridges. Z Medina-Cetina, N Yousefpour, J.-L Briaud, Journal of Bridge Engineering. 251040200742020</p>
<p>Evaluation of Unknown Foundations of Bridges Subjected to Scour Physically Driven Artificial Neural Network Approach. N Yousefpour, Z Medina-Cetina, J L Briaud, Transportation Research Record: Journal of the Transportation Research Board. 24332014</p>
<p>A Survey on Transfer Learning. S J Pan, Q Yang, IEEE Transactions on Knowledge and Data Engineering. 221013452010</p>
<p>Ensemble Learning: A Survey. O Sagi, L Rokach, Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery. 84e12492018</p>
<p>Cross-Validation of Regression Models. R R Picard, R D Cook, Journal of the American Statistical Association. 793871984</p>
<p>Application of Long-Short Term Memory and Convolutional Neural Networks for Real. T Hashem, N Yousefpour, 10.48550/arXiv.2404.16549arXiv:2404.16549Time Bridge Scour Forecast. 2024arXiv Preprint</p>
<p>On Hyperparameter Optimization of Machine Learning Algorithms: Theory and Practice. L Yang, A Shami, Neurocomputing. 4152020</p>
<p>Analysis of Recent Bridge Failures in the United States. K Wardhana, F C Hadipriono, Journal of Performance of Constructed Facilities. 1732003</p>
<p>Unknown Foundation Determination for Scour. J L Briaud, Z Medina-Cetina, S Hurlebaus, M Everett, S Tucker, N Yousefpour, R Arjwech, 2012Texas Transportation InstituteCollege Station, TX</p>
<p>Monitoring Scour Critical Bridges -A Synthesis of Highway Practice. B E Hunt, Transportation Research Board. 3962009NCHRP Synthesis</p>
<p>Real-time Streambed Scour Monitoring at Two Bridges over the Gunnison River in Western Colorado. M F Henneberg, 10.3133/sir20185123U.S. Geological Survey Scientific Investigation Report. 172016. 2018</p>
<p>V Sauer, D Turnipseed, Stage Measurement at Gaging Stations. U.S. Geological Survey (USGS), Virginia. 2010</p>
<p>Discharge Measurement at Gaging Stations. V Sauer, D Turnipseed, Geological Survey. 5362010</p>
<p>Deep Learning with Noisy Labels: Exploring Techniques and Remedies in Medical Image Analysis. D Karimi, H Dou, S K Warfield, A Gholipour, Medical Image Analysis. 651017592020</p>
<p>. S Moritz, T Bartz-Beielstein, imputeTS: Timeseries Missing Value Imputation in R. R Journal. 912072017</p>
<p>Multi-Output Gaussian Processes for Crowdsourced Traffic Data Imputation. F Rodrigues, K Henrickson, F C Pereira, IEEE Transactions on Intelligent Transportation Systems. 2022019</p>
<p>Smooth Transition Autoregressive Models -A Survey of Recent Developments. D Van Dijk, T Tera¨svirta, P H Franses, Econometric Reviews. 2112002</p>
<p>Early Detection of Internal Erosion in Earth Dams: Combining Seismic Monitoring and Convolutional AutoEncoders. N Yousefpour, F Fazel Mojtahedi, Georisk: Assessment and Management of Risk for Engineered Systems and Geohazards. 2023</p>
<p>Long Short-Term Memory. S Hochreiter, J Schmidhuber, Neural Computation. 981997</p>
<p>Learning Long-Term Dependencies with Gradient Descent is Difficult. Y Bengio, P Simard, P Frasconi, IEEE Transactions on Neural Networks. 521994</p>
<p>Prediction of the Post-Failure Behavior of Rocks: Combining Artificial Intelligence and Acoustic Emission Sensing. N Yousefpour, M Pouragha, International Journal for Numerical and Analytical Methods in Geomechanics. 46102022</p>            </div>
        </div>

    </div>
</body>
</html>