<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-450 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-450</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-450</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-17.html">extraction-schema-17</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <p><strong>Paper ID:</strong> paper-237491430</p>
                <p><strong>Paper Title:</strong> <a href="https://arxiv.org/pdf/2109.06133v1.pdf" target="_blank">Neuro-Symbolic AI: An Emerging Class of AI Workloads and their Characterization</a></p>
                <p><strong>Paper Abstract:</strong> Neuro-symbolic artificial intelligence is a novel area of AI research which seeks to combine traditional rules-based AI approaches with modern deep learning techniques. Neuro-symbolic models have already demonstrated the capability to outperform state-of-the-art deep learning models in domains such as image and video reasoning. They have also been shown to obtain high accuracy with significantly less training data than traditional models. Due to the recency of the field's emergence and relative sparsity of published results, the performance characteristics of these models are not well understood. In this paper, we describe and analyze the performance characteristics of three recent neuro-symbolic models. We find that symbolic models have less potential parallelism than traditional neural models due to complex control flow and low-operational-intensity operations, such as scalar multiplication and tensor addition. However, the neural aspect of computation dominates the symbolic part in cases where they are clearly separable. We also find that data movement poses a potential bottleneck, as it does in many ML workloads.</p>
                <p><strong>Cost:</strong> 0.014</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e450.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e450.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>NSCL</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Neuro-Symbolic Concept Learner</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A modular neuro-symbolic system that uses neural submodels (image parser, question parser) to extract perceptual features and a quasi-symbolic program executor to execute domain-specific programs for visual question answering; the executor is made differentiable via probabilistic/soft approximations to enable end-to-end learning of concept embeddings.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>The neurosymbolic concept learner: Interpreting scenes, words, and sentences from natural supervision.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Neuro-Symbolic Concept Learner (NSCL)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>NSCL is a modular hybrid reasoning system for visual question answering on CLEVR images. It consists of (1) an image parser (Mask R-CNN) that extracts object masks and attributes, (2) a question parser (neural machine translation / sequence model) that converts natural-language questions into a domain-specific program language (tokens describing filters, operations, and concepts), and (3) a quasi-symbolic program executor that sequentially applies parsed tokens to the extracted object-feature representations to produce answers. The executor represents object selection as probability vectors (Mask_i in [0,1]) and implements non-differentiable logical operations via probabilistic/soft approximations so the whole pipeline can be trained end-to-end to learn concept embeddings.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Quasi-symbolic program executor implementing tokenized domain-specific programs (filters, boolean/arithmetic reductions) operating on object-centric feature tables; logical structure and program tokens resemble a rule/program interpreter; outputs are probability vectors over object sets rather than strict booleans (soft logical representation).</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Neural subsystems: Mask R-CNN convolutional network for image parsing (object segmentation & features) and an NMT/question parser (bidirectional GRU in original, transformer used in profiling) for mapping natural-language questions to program tokens; these are trained with gradient-based learning.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Modular pipeline with differentiable coupling: neural perception modules produce structured feature tables; the quasi-symbolic executor uses soft/probabilistic approximations (e.g., softmax over object-selection vectors) to make symbolic operations differentiable, enabling joint end-to-end training so that concept embeddings (imperative parameters) are learned via backprop through the soft symbolic layer.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>High sample efficiency (ability to reach strong performance with far less supervised data than pure neural baselines), explicit intermediate symbolic programs providing human-readable structure of reasoning, learnable concept embeddings due to differentiable symbolic approximation enabling joint perceptual+concept learning, and improved compositional interpretability because question-to-program mapping decomposes reasoning steps.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Visual question answering / compositional image reasoning on the CLEVR dataset.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td>Qualitative: Reported by referenced work to outperform pure deep-learning baselines (TbD, MAC) when training data is scarce (example: strong advantage when only 10% of CLEVR training data is available). Inference performance profiled in this paper: full NSCL pipeline average runtime ≈ 375 ms per sample (question parser ≈ 310 ms dominates; image/frame parser ≈ 34.6 ms). No numeric accuracy figures are provided in this profiling paper.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Improved sample efficiency and compositional generalization: NSCL demonstrates faster convergence and better accuracy than pure neural models on CLEVR under limited-data regimes, and its program-based representation supports compositional application of learned concepts to novel queries; concept embeddings learned jointly allow some generalization to new combinations of attributes.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>High: the tokenized domain-specific programs and object-centric feature tables provide interpretable intermediate representations; the executor’s program sequence corresponds to human-understandable reasoning steps. The use of soft/probabilistic outputs preserves differentiability while maintaining readable program structure.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Executor is only quasi-symbolic (soft approximations), so exact logical behavior is approximated; symbolic operations are low-operational-intensity (vector/scalar ops) with complex control flow, limiting parallel acceleration; question parsing (NMT) is a major runtime cost; the executor and symbolic layer currently represent a limited set of operations and may struggle as symbolic complexity grows.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Division-of-labor principle: use neural modules for perceptual feature extraction and differentiable (soft) symbolic execution for structured reasoning, leveraging complementary strengths (data-driven perception + explicit rule-like manipulation); enabling differentiable symbolic steps allows end-to-end learning of concept embeddings.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Neuro-Symbolic AI: An Emerging Class of AI Workloads and their Characterization', 'publication_date_yy_mm': '2021-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e450.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e450.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>NS-DR</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Neuro-Symbolic Dynamic Reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A modular neuro-symbolic system for video reasoning (CLEVRER) that couples neural submodels (frame parser, question parser, learned dynamics predictor / PropNet) with a true symbolic program executor to reason about object interactions and causality in videos.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Clevrer: Collision events for video representation and reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Neuro-Symbolic Dynamic Reasoning (NS-DR)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>NS-DR is a pipeline hybrid system built for video question answering and causal reasoning on CLEVRER videos. Components: (1) video frame parser (Mask R-CNN run on each frame) providing per-frame object masks/attributes, (2) question parser (NMT/transformer) converting questions to tokenized programs, (3) a learned dynamics predictor (PropNet) that functions as a learned physics engine predicting object trajectories/collisions under partial observability, and (4) a fixed-function, true symbolic program executor that applies tokenized programs to the combined extracted and predicted features to answer causal and descriptive questions.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>True symbolic program executor (non-differentiable), implemented as a fixed-function interpreter that performs boolean/arithmetic operations, table lookups, filters and reductions on extracted features and predicted dynamics; behaves like a programming-language interpreter operating on structured feature tables.</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Neural components: frame parser (Mask R-CNN convolutional network), question parser (Seq2Seq originally; transformer used in profiling), and PropNet (learned dynamics predictor, composed of fully-connected and convolutional networks trained to model physical interactions). These are trained with gradient-based learning.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Modular, staged pipeline: neural submodels extract and/or predict features and write structured outputs (in original implementations via JSON in this paper's analyzed codepath) which the symbolic executor consumes. Integration is not end-to-end because the symbolic executor is non-differentiable; concept learning must occur in the neural frame parser (supervised) and the dynamics predictor is learned separately. Data is passed between modules (sometimes via JSON files) rather than via differentiable connections.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Ability to reason about causality and counterfactuals in video (e.g., identifying collisions and causes), combining learned physical prediction with symbolic query/execution enables answering complex causal questions beyond per-frame description; improved performance on video reasoning benchmarks relative to traditional non-symbolic approaches (as reported in the cited CLEVRER work).</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Video question answering and causal reasoning on the CLEVRER dataset (collision events, causal/counterfactual questions).</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td>Qualitative: Cited work reports state-of-the-art performance on CLEVRER, dramatically outperforming traditional non-symbolic approaches for causal questions. Inference performance profiled in this paper: total NS-DR pipeline average inference time ≈ 4.44 s per 25-frame video (dynamics predictor dominates runtime; PropNet average ≈ 3.4 s per video across samples). Symbolic executor average runtime ≈ 12.9 ms (CPU-only) and lies on the critical path.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Enhanced causal/generalization abilities through combination of physical-dynamics prediction and symbolic reasoning; PropNet supports partial-observation dynamics prediction (objects entering/leaving view) enabling robust reasoning over realistic video inputs; NS-DR generalizes to dynamic reasoning tasks that pure-perception models struggle with.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>High for symbolic part: the fixed-function symbolic executor performs explicit token-driven operations (database-like queries and arithmetic), offering transparent reasoning traces for question execution; however, the neural dynamics predictor and frame parser remain black-box perception modules.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Integration limitations: symbolic executor is non-differentiable so cannot be trained end-to-end (prevents learning concept embeddings via backward flow through symbolic logic); dynamics predictor is heavily data-movement-bound and suffers from inefficient 'tall-and-skinny' matrix multiplies, causing long runtimes and high variance; inter-module communication via JSON introduces nontrivial overhead; symbolic executor single-threaded CPU-only and exhibits limited coarse-grain parallelism due to sequential token dependencies.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Division-of-labor and pipeline modularity: perceptual and physical reasoning handled by neural predictors, high-level causal/relational reasoning handled by a traditional symbolic executor; this design exploits neural strengths for pattern and dynamics learning and symbolic strengths for explicit causal reasoning, but sacrifices end-to-end differentiability.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Neuro-Symbolic AI: An Emerging Class of AI Workloads and their Characterization', 'publication_date_yy_mm': '2021-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e450.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e450.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>NLM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Neural Logic Machines</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An end-to-end neuro-symbolic architecture that integrates neural inductive learning with logical reasoning over relations, properties, quantifiers and connectives to achieve strong compositional generalization on algorithmic and relational tasks (sorting, shortest path, Blocks World).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Neural logic machines.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Neural Logic Machines (NLM)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>NLMs are unified neuro-symbolic networks (not composed as separate submodels) that combine neural modules implementing lifted logical operations (relations, quantifiers, connectives) with probabilistic representations to perform inductive logic reasoning and generalize learned rules to larger problem sizes. The architecture applies layers that capture object relations and properties and uses neural parameterization of logical operators to inductively learn rules and reason about structured tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Representations and operations corresponding to logic: relations, quantifiers, logic connectives and lifted (rule-like) structures; NLM implements symbolic/logical rule structure within the network using differentiated neural modules that represent and manipulate relational predicates (a neuralized form of logical reasoning).</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>End-to-end neural network modules (layered architecture) that implement inductive learning and parametric approximations of logical operators; training is gradient-based and the network learns to implement rules/procedures for tasks like sorting, path finding, and Blocks World.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Tightly integrated end-to-end neural architecture where symbolic logical structure is embedded as neural modules (no separate submodels). The network encodes logical primitives (relations, connectives, quantifiers) in its layers and uses gradient-based learning to induce rules—i.e., integration by architectural embedding of symbolic primitives into a neural computational graph.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Strong compositional generalization and perfect (or near-perfect) generalization from small-scale training examples to larger-scale instances for algorithmic and relational tasks; capacity to learn lifted rules that scale with problem size; combines expressiveness of symbolic logic with data-driven robustness of neural nets, enabling tasks (sorting, shortest path, Blocks World) that are hard for purely neural or purely ILP systems.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Algorithmic/relational reasoning tasks: array sorting, critical path (shortest path) finding, Blocks World, family-tree decisions (benchmarks used in NLM work).</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td>Qualitative: NLMs reported to achieve perfect generalization on a variety of algorithmic and relational benchmarks in the referenced work. In this profiling paper, per-task inference runtimes measured: Path task total ≈ 18.3 s, Sort task total ≈ 41.7 s, Blocks World total ≈ 7.85 s (profiling breakdowns show substantial time in element-wise and 'other' categories). No numeric accuracy figures are provided in this profiling paper.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Excellent compositional and scale generalization: NLMs are described as able to learn from small-scale examples and generalize rules to much larger instances (lifting rules and premises), demonstrating better generalization than many conventional neural architectures and overcoming some limitations of inductive logic programming.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Moderate-to-high: NLMs aim to represent logical structure (relations and rules) explicitly inside the architecture, so learned rule-like behavior can be inspected conceptually; however, because rules are neuralized (parametric), exact symbolic transparency is not identical to hand-crafted symbolic systems.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Compute and inference costs: inference dominated by element-wise and miscellaneous operations with low operational intensity, making acceleration difficult; runtime grows with rule-set complexity and task size (profiling shows large runtimes for some tasks). As rule complexity scales, computational demand and difficulty of efficient acceleration increase. The 'other' category (miscellaneous internal querying/generation) is sizable in runtime.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Neuralization of logic: embed symbolic logical primitives inside a neural inductive-learning framework to gain both expressiveness (logical rules) and statistical learning capability; principle relies on combining symbols and probabilities to learn lifted rules that generalize.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Neuro-Symbolic AI: An Emerging Class of AI Workloads and their Characterization', 'publication_date_yy_mm': '2021-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>The neurosymbolic concept learner: Interpreting scenes, words, and sentences from natural supervision. <em>(Rating: 2)</em></li>
                <li>Clevrer: Collision events for video representation and reasoning. <em>(Rating: 2)</em></li>
                <li>Neural logic machines. <em>(Rating: 2)</em></li>
                <li>Propagation networks for model-based control under partial observation. <em>(Rating: 2)</em></li>
                <li>Visual concept-metaconcept learning. <em>(Rating: 1)</em></li>
                <li>Dynamic Concept Learner <em>(Rating: 1)</em></li>
                <li>Transparency by design: Closing the gap between performance and interpretability in visual reasoning. <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-450",
    "paper_id": "paper-237491430",
    "extraction_schema_id": "extraction-schema-17",
    "extracted_data": [
        {
            "name_short": "NSCL",
            "name_full": "Neuro-Symbolic Concept Learner",
            "brief_description": "A modular neuro-symbolic system that uses neural submodels (image parser, question parser) to extract perceptual features and a quasi-symbolic program executor to execute domain-specific programs for visual question answering; the executor is made differentiable via probabilistic/soft approximations to enable end-to-end learning of concept embeddings.",
            "citation_title": "The neurosymbolic concept learner: Interpreting scenes, words, and sentences from natural supervision.",
            "mention_or_use": "use",
            "system_name": "Neuro-Symbolic Concept Learner (NSCL)",
            "system_description": "NSCL is a modular hybrid reasoning system for visual question answering on CLEVR images. It consists of (1) an image parser (Mask R-CNN) that extracts object masks and attributes, (2) a question parser (neural machine translation / sequence model) that converts natural-language questions into a domain-specific program language (tokens describing filters, operations, and concepts), and (3) a quasi-symbolic program executor that sequentially applies parsed tokens to the extracted object-feature representations to produce answers. The executor represents object selection as probability vectors (Mask_i in [0,1]) and implements non-differentiable logical operations via probabilistic/soft approximations so the whole pipeline can be trained end-to-end to learn concept embeddings.",
            "declarative_component": "Quasi-symbolic program executor implementing tokenized domain-specific programs (filters, boolean/arithmetic reductions) operating on object-centric feature tables; logical structure and program tokens resemble a rule/program interpreter; outputs are probability vectors over object sets rather than strict booleans (soft logical representation).",
            "imperative_component": "Neural subsystems: Mask R-CNN convolutional network for image parsing (object segmentation & features) and an NMT/question parser (bidirectional GRU in original, transformer used in profiling) for mapping natural-language questions to program tokens; these are trained with gradient-based learning.",
            "integration_method": "Modular pipeline with differentiable coupling: neural perception modules produce structured feature tables; the quasi-symbolic executor uses soft/probabilistic approximations (e.g., softmax over object-selection vectors) to make symbolic operations differentiable, enabling joint end-to-end training so that concept embeddings (imperative parameters) are learned via backprop through the soft symbolic layer.",
            "emergent_properties": "High sample efficiency (ability to reach strong performance with far less supervised data than pure neural baselines), explicit intermediate symbolic programs providing human-readable structure of reasoning, learnable concept embeddings due to differentiable symbolic approximation enabling joint perceptual+concept learning, and improved compositional interpretability because question-to-program mapping decomposes reasoning steps.",
            "task_or_benchmark": "Visual question answering / compositional image reasoning on the CLEVR dataset.",
            "hybrid_performance": "Qualitative: Reported by referenced work to outperform pure deep-learning baselines (TbD, MAC) when training data is scarce (example: strong advantage when only 10% of CLEVR training data is available). Inference performance profiled in this paper: full NSCL pipeline average runtime ≈ 375 ms per sample (question parser ≈ 310 ms dominates; image/frame parser ≈ 34.6 ms). No numeric accuracy figures are provided in this profiling paper.",
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": true,
            "generalization_properties": "Improved sample efficiency and compositional generalization: NSCL demonstrates faster convergence and better accuracy than pure neural models on CLEVR under limited-data regimes, and its program-based representation supports compositional application of learned concepts to novel queries; concept embeddings learned jointly allow some generalization to new combinations of attributes.",
            "interpretability_properties": "High: the tokenized domain-specific programs and object-centric feature tables provide interpretable intermediate representations; the executor’s program sequence corresponds to human-understandable reasoning steps. The use of soft/probabilistic outputs preserves differentiability while maintaining readable program structure.",
            "limitations_or_failures": "Executor is only quasi-symbolic (soft approximations), so exact logical behavior is approximated; symbolic operations are low-operational-intensity (vector/scalar ops) with complex control flow, limiting parallel acceleration; question parsing (NMT) is a major runtime cost; the executor and symbolic layer currently represent a limited set of operations and may struggle as symbolic complexity grows.",
            "theoretical_framework": "Division-of-labor principle: use neural modules for perceptual feature extraction and differentiable (soft) symbolic execution for structured reasoning, leveraging complementary strengths (data-driven perception + explicit rule-like manipulation); enabling differentiable symbolic steps allows end-to-end learning of concept embeddings.",
            "uuid": "e450.0",
            "source_info": {
                "paper_title": "Neuro-Symbolic AI: An Emerging Class of AI Workloads and their Characterization",
                "publication_date_yy_mm": "2021-09"
            }
        },
        {
            "name_short": "NS-DR",
            "name_full": "Neuro-Symbolic Dynamic Reasoning",
            "brief_description": "A modular neuro-symbolic system for video reasoning (CLEVRER) that couples neural submodels (frame parser, question parser, learned dynamics predictor / PropNet) with a true symbolic program executor to reason about object interactions and causality in videos.",
            "citation_title": "Clevrer: Collision events for video representation and reasoning.",
            "mention_or_use": "use",
            "system_name": "Neuro-Symbolic Dynamic Reasoning (NS-DR)",
            "system_description": "NS-DR is a pipeline hybrid system built for video question answering and causal reasoning on CLEVRER videos. Components: (1) video frame parser (Mask R-CNN run on each frame) providing per-frame object masks/attributes, (2) question parser (NMT/transformer) converting questions to tokenized programs, (3) a learned dynamics predictor (PropNet) that functions as a learned physics engine predicting object trajectories/collisions under partial observability, and (4) a fixed-function, true symbolic program executor that applies tokenized programs to the combined extracted and predicted features to answer causal and descriptive questions.",
            "declarative_component": "True symbolic program executor (non-differentiable), implemented as a fixed-function interpreter that performs boolean/arithmetic operations, table lookups, filters and reductions on extracted features and predicted dynamics; behaves like a programming-language interpreter operating on structured feature tables.",
            "imperative_component": "Neural components: frame parser (Mask R-CNN convolutional network), question parser (Seq2Seq originally; transformer used in profiling), and PropNet (learned dynamics predictor, composed of fully-connected and convolutional networks trained to model physical interactions). These are trained with gradient-based learning.",
            "integration_method": "Modular, staged pipeline: neural submodels extract and/or predict features and write structured outputs (in original implementations via JSON in this paper's analyzed codepath) which the symbolic executor consumes. Integration is not end-to-end because the symbolic executor is non-differentiable; concept learning must occur in the neural frame parser (supervised) and the dynamics predictor is learned separately. Data is passed between modules (sometimes via JSON files) rather than via differentiable connections.",
            "emergent_properties": "Ability to reason about causality and counterfactuals in video (e.g., identifying collisions and causes), combining learned physical prediction with symbolic query/execution enables answering complex causal questions beyond per-frame description; improved performance on video reasoning benchmarks relative to traditional non-symbolic approaches (as reported in the cited CLEVRER work).",
            "task_or_benchmark": "Video question answering and causal reasoning on the CLEVRER dataset (collision events, causal/counterfactual questions).",
            "hybrid_performance": "Qualitative: Cited work reports state-of-the-art performance on CLEVRER, dramatically outperforming traditional non-symbolic approaches for causal questions. Inference performance profiled in this paper: total NS-DR pipeline average inference time ≈ 4.44 s per 25-frame video (dynamics predictor dominates runtime; PropNet average ≈ 3.4 s per video across samples). Symbolic executor average runtime ≈ 12.9 ms (CPU-only) and lies on the critical path.",
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": true,
            "generalization_properties": "Enhanced causal/generalization abilities through combination of physical-dynamics prediction and symbolic reasoning; PropNet supports partial-observation dynamics prediction (objects entering/leaving view) enabling robust reasoning over realistic video inputs; NS-DR generalizes to dynamic reasoning tasks that pure-perception models struggle with.",
            "interpretability_properties": "High for symbolic part: the fixed-function symbolic executor performs explicit token-driven operations (database-like queries and arithmetic), offering transparent reasoning traces for question execution; however, the neural dynamics predictor and frame parser remain black-box perception modules.",
            "limitations_or_failures": "Integration limitations: symbolic executor is non-differentiable so cannot be trained end-to-end (prevents learning concept embeddings via backward flow through symbolic logic); dynamics predictor is heavily data-movement-bound and suffers from inefficient 'tall-and-skinny' matrix multiplies, causing long runtimes and high variance; inter-module communication via JSON introduces nontrivial overhead; symbolic executor single-threaded CPU-only and exhibits limited coarse-grain parallelism due to sequential token dependencies.",
            "theoretical_framework": "Division-of-labor and pipeline modularity: perceptual and physical reasoning handled by neural predictors, high-level causal/relational reasoning handled by a traditional symbolic executor; this design exploits neural strengths for pattern and dynamics learning and symbolic strengths for explicit causal reasoning, but sacrifices end-to-end differentiability.",
            "uuid": "e450.1",
            "source_info": {
                "paper_title": "Neuro-Symbolic AI: An Emerging Class of AI Workloads and their Characterization",
                "publication_date_yy_mm": "2021-09"
            }
        },
        {
            "name_short": "NLM",
            "name_full": "Neural Logic Machines",
            "brief_description": "An end-to-end neuro-symbolic architecture that integrates neural inductive learning with logical reasoning over relations, properties, quantifiers and connectives to achieve strong compositional generalization on algorithmic and relational tasks (sorting, shortest path, Blocks World).",
            "citation_title": "Neural logic machines.",
            "mention_or_use": "use",
            "system_name": "Neural Logic Machines (NLM)",
            "system_description": "NLMs are unified neuro-symbolic networks (not composed as separate submodels) that combine neural modules implementing lifted logical operations (relations, quantifiers, connectives) with probabilistic representations to perform inductive logic reasoning and generalize learned rules to larger problem sizes. The architecture applies layers that capture object relations and properties and uses neural parameterization of logical operators to inductively learn rules and reason about structured tasks.",
            "declarative_component": "Representations and operations corresponding to logic: relations, quantifiers, logic connectives and lifted (rule-like) structures; NLM implements symbolic/logical rule structure within the network using differentiated neural modules that represent and manipulate relational predicates (a neuralized form of logical reasoning).",
            "imperative_component": "End-to-end neural network modules (layered architecture) that implement inductive learning and parametric approximations of logical operators; training is gradient-based and the network learns to implement rules/procedures for tasks like sorting, path finding, and Blocks World.",
            "integration_method": "Tightly integrated end-to-end neural architecture where symbolic logical structure is embedded as neural modules (no separate submodels). The network encodes logical primitives (relations, connectives, quantifiers) in its layers and uses gradient-based learning to induce rules—i.e., integration by architectural embedding of symbolic primitives into a neural computational graph.",
            "emergent_properties": "Strong compositional generalization and perfect (or near-perfect) generalization from small-scale training examples to larger-scale instances for algorithmic and relational tasks; capacity to learn lifted rules that scale with problem size; combines expressiveness of symbolic logic with data-driven robustness of neural nets, enabling tasks (sorting, shortest path, Blocks World) that are hard for purely neural or purely ILP systems.",
            "task_or_benchmark": "Algorithmic/relational reasoning tasks: array sorting, critical path (shortest path) finding, Blocks World, family-tree decisions (benchmarks used in NLM work).",
            "hybrid_performance": "Qualitative: NLMs reported to achieve perfect generalization on a variety of algorithmic and relational benchmarks in the referenced work. In this profiling paper, per-task inference runtimes measured: Path task total ≈ 18.3 s, Sort task total ≈ 41.7 s, Blocks World total ≈ 7.85 s (profiling breakdowns show substantial time in element-wise and 'other' categories). No numeric accuracy figures are provided in this profiling paper.",
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": true,
            "generalization_properties": "Excellent compositional and scale generalization: NLMs are described as able to learn from small-scale examples and generalize rules to much larger instances (lifting rules and premises), demonstrating better generalization than many conventional neural architectures and overcoming some limitations of inductive logic programming.",
            "interpretability_properties": "Moderate-to-high: NLMs aim to represent logical structure (relations and rules) explicitly inside the architecture, so learned rule-like behavior can be inspected conceptually; however, because rules are neuralized (parametric), exact symbolic transparency is not identical to hand-crafted symbolic systems.",
            "limitations_or_failures": "Compute and inference costs: inference dominated by element-wise and miscellaneous operations with low operational intensity, making acceleration difficult; runtime grows with rule-set complexity and task size (profiling shows large runtimes for some tasks). As rule complexity scales, computational demand and difficulty of efficient acceleration increase. The 'other' category (miscellaneous internal querying/generation) is sizable in runtime.",
            "theoretical_framework": "Neuralization of logic: embed symbolic logical primitives inside a neural inductive-learning framework to gain both expressiveness (logical rules) and statistical learning capability; principle relies on combining symbols and probabilities to learn lifted rules that generalize.",
            "uuid": "e450.2",
            "source_info": {
                "paper_title": "Neuro-Symbolic AI: An Emerging Class of AI Workloads and their Characterization",
                "publication_date_yy_mm": "2021-09"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "The neurosymbolic concept learner: Interpreting scenes, words, and sentences from natural supervision.",
            "rating": 2,
            "sanitized_title": "the_neurosymbolic_concept_learner_interpreting_scenes_words_and_sentences_from_natural_supervision"
        },
        {
            "paper_title": "Clevrer: Collision events for video representation and reasoning.",
            "rating": 2,
            "sanitized_title": "clevrer_collision_events_for_video_representation_and_reasoning"
        },
        {
            "paper_title": "Neural logic machines.",
            "rating": 2,
            "sanitized_title": "neural_logic_machines"
        },
        {
            "paper_title": "Propagation networks for model-based control under partial observation.",
            "rating": 2,
            "sanitized_title": "propagation_networks_for_modelbased_control_under_partial_observation"
        },
        {
            "paper_title": "Visual concept-metaconcept learning.",
            "rating": 1,
            "sanitized_title": "visual_conceptmetaconcept_learning"
        },
        {
            "paper_title": "Dynamic Concept Learner",
            "rating": 1,
            "sanitized_title": "dynamic_concept_learner"
        },
        {
            "paper_title": "Transparency by design: Closing the gap between performance and interpretability in visual reasoning.",
            "rating": 1,
            "sanitized_title": "transparency_by_design_closing_the_gap_between_performance_and_interpretability_in_visual_reasoning"
        }
    ],
    "cost": 0.013884,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Neuro-Symbolic AI: An Emerging Class of AI Workloads and their Characterization
13 Sep 2021</p>
<p>Zachary Susskind 
Department of Electrical and Computer Engineering
The University of Texas at Austin Austin
Texas</p>
<p>Bryce Arden 
Department of Electrical and Computer Engineering
The University of Texas at Austin Austin
Texas</p>
<p>Lizy K John ljohn@utexas.edu 
Department of Electrical and Computer Engineering
The University of Texas at Austin Austin
Texas</p>
<p>Patrick Stockton 
Department of Electrical and Computer Engineering
The University of Texas at San Antonio San Antonio
Texas patrick.stockton</p>
<p>Eugene B John eugene.john@utsa.edu 
Department of Electrical and Computer Engineering
The University of Texas at San Antonio San Antonio
Texas patrick.stockton</p>
<p>Neuro-Symbolic AI: An Emerging Class of AI Workloads and their Characterization
13 Sep 2021CF11CE08EF581D50E21E4DCA1A5D0C4FarXiv:2109.06133v1[cs.AI]Neuro-SymbolicMachine LearningPerformanceInference
Neuro-symbolic artificial intelligence is a novel area of AI research which seeks to combine traditional rules-based AI approaches with modern deep learning techniques.Neurosymbolic models have already demonstrated the capability to outperform state-of-the-art deep learning models in domains such as image and video reasoning.They have also been shown to obtain high accuracy with significantly less training data than traditional models.Due to the recency of the field's emergence and relative sparsity of published results, the performance characteristics of these models are not well understood.In this paper, we describe and analyze the performance characteristics of three recent neuro-symbolic models.We find that symbolic models have less potential parallelism than traditional neural models due to complex control flow and low-operational-intensity operations, such as scalar multiplication and tensor addition.However, the neural aspect of computation dominates the symbolic part in cases where they are clearly separable.We also find that data movement poses a potential bottleneck, as it does in many ML workloads.</p>
<p>I. INTRODUCTION</p>
<p>Conventional neural networks, based on Deep Learning (DL), have proven to be effective in solving problems in many domains.Recently, there has been an increase in the diversity of neural models, including those composed of multiple independently-trained submodels, and those which integrate symbolic reasoning concepts (neuro-symbolic models).At the same time, there is growing interest in heterogeneous architectures.These architectures pose the challenge of efficiently mapping problems to different resources.Even in a relatively simple heterogeneous design, such as a CPU-GPU system, it is necessary to determine which tasks should be mapped to which device.In order to facilitate this mapping, it is important to understand emerging AI applications.</p>
<p>Neural networks have traditionally been grey-box systems.It's trivial to observe the internal physical structure of a network, since a model's topology is explicitly defined as part of hyperparameter selection.However, mapping the highdimensional, abstract features which neural networks manipulate to concrete concepts which humans can understand has proven to be difficult.Such mappings are highly desirable for safety-critical fields such as medicine and self-driving cars, where we must be certain a model is learning the desired dataset features rather than over-fitting to data artifacts [1].Networks composed of independent submodels have an advantage here, since each submodel was trained for a specific purpose.Knowing the purpose of each submodel gives us some information about the internal state of the top-level model.</p>
<p>Neuro-Symbolic AI (NSAI) is another emerging AI domain that combines deep learning for feature extraction and rulesbased "intuition" for manipulating those features.Rules-based, or symbolic, approaches dominated the field of AI until the 1980s [2].Symbolic models had several advantages: they required only a few input samples, generalized well to new problems, and their internal functionality was conceptually simple when compared to DL models.At the same time, they required substantial hand-tuning, which made them difficult to create for complex problems.A far larger issue was that they simply weren't very accurate: in 1973, the entire field of AI was summarised as "increasingly disappointing" [3], and by the 1980s, research had spiraled into what became known as the "AI winter" [4].</p>
<p>NSAI is a hybrid between DL and symbolic approaches which attempts to capture the strengths of both fields.Deep learning has proven singularly successful in extracting complex features from data in tasks such as object detection and natural language processing.At the same time, symbolic AI is good for formalizing human-like reasoning.The objective of NSAI is extract features from data using DL approaches, then manipulate these features using symbolic approaches.Neurosymbolic models have outperformed pure DL models on image and video question answering tasks, and have proven to converge far quicker, with as little as 1/10 of the training data needed for accuracy.Figure 1 contrasts the NSCL, a neurosymbolic model for image reasoning [5], with two other pure-DL models (TbD [6] and MAC [7]).While all three models obtain similar final accuracies with 100% of the training data, the neuro-symbolic model dramatically outperforms the other two when restricted to training on only 10% of the total data (CLEVR dataset) [5].Therefore, neuro-symbolic models are a good choice for scenarios where the availability of training data is limited, or when training time is prohibitive.</p>
<p>In this paper, we analyze the inference performance characteristics of three separate neuro-symbolic models.Two of the models, the Neuro-Symbolic Concept Learner (NSCL) and Fig. 1.The neuro-symbolic model (NSCL [5]) achieves good accuracy even when only trained with 10% of the data (CLEVR dataset) whereas the accuracy of neural models (TbD [6] and MAC [7]) deteriorates when the training set is small.Data is drawn from [5].</p>
<p>Neuro-Symbolic Dynamic Reasoning (NS-DR), are composed of multiple independent "submodels", which extract problem features before passing them as input to a final symbolic submodel.The third, Neural Logic Machines (NLM), is an end-toend model without independent submodels.The NLM model uses an object's relations, properties, quantifiers, and logic connectives in order to accomplish the task of generalization.We provide an overview of all three models in Table I.</p>
<p>The remainder of this paper is organized as follows: Section II outlines the space of neuro-symbolic learning, including the progressive improvements to neuro-symbolic models.Section III describes the three models that we are analyzing in this paper in detail.Section IV describes our methodology for analyzing the performance of these models, based on classifying activity into eight distinct categories.Section V provides the results of our analysis with breakdowns for each submodel component.Section VI provides our takeaways on the behavior and potential opportunities for acceleration of neuro-symbolic models.Finally, in Section VII, we summarize our findings and propose future work.We also provide direct links to the repositories of the models cited in this paper as an appendix.</p>
<p>II. RELATED WORK</p>
<p>A large portion of the research in NSAI to date has been spearheaded by a collaborative effort between MIT and IBM research groups [5], [10].In 2019, the Neuro-Symbolic Concept Learner proved the viability of combining symbolic AI with deep learning techniques by parsing input questions and scenes into symbolic programs [5].The Concept Learner demonstrated a novel technique for parsing input scenes and questions into a semantic program, and introduced new techniques for training this parsing at the same time as the symbolic execution engine.The Concept Learner model was followed the next year by the Visual Concept-Metaconcept Learning (VCML) model, which used embeddings to learn object properties with less supervision [10].The VCML model introduced the joint learning of concepts and metaconcepts (e.g. the notion that two values describe the same property of objects), and the autonomous learning of new concepts (e.g.color, shape, etc.).The VMCL obtained near-perfect accuracy on the CLEVR image reasoning dataset.In early 2020, Chuang Gen et al. introduced the CLEVER dataset, which pushed the boundaries of dynamic reasoning by using videos instead of images, requiring models to learn both physical and causal relationships [8].The same paper also introduced the Neuro-Symbolic Dynamic Reasoning (NS-DR) model, which achieved state-of-the-art performance on the CLEVRER dataset, dramatically outperforming traditional, non-symbolic approaches to video reasoning.In early 2021, the same MIT researchers released the Dynamic Concept Learner (DCL) [11], which achieved a new state-of-the-art for the CLEVRER dataset by adding learned features for object behavior over time and using new training techniques.The DCL has also been shown to generalize well to new datasets for video question answering [11].</p>
<p>The neuro-symbolic Neural Logic Machine (NLM) research was conducted by a collaboration between Google Inc., ByteDance Inc., and Tsinghua University [9].The resulting NLM architecture provides a state-of-the-art method for solving general application tasks such as array sorting, critical path finding, and more complex tasks such as Blocks World [12].Blocks World is a classic symbolic reasoning problem where the model is given a set number of blocks and logical rules.Using the provided generalized rules, the model will need to perform the available logical actions to achieve the desired target result from the randomized starting layout.Following the neuro-symbolic work from Jiayuan Mao et al. introduced the concept learner for interpreting scenes, words, and sentences from natural supervision (NS-CL) [13].This NS-CL model utilized similar neuro-symbolic reasoning modules to build an object-based scene for the system to infer.The visual reasoning of the NS-CL model generalized tasks using new object attributes and properties with scaling rule sets which is supportive of the NLM work.</p>
<p>As mentioned in the introduction, the NS-DR and NSCL models are composed of independent submodels.Many of these are neural models similar to those already deployed in data centers, covering tasks such as natural language and image processing [14] [15].While the approximate performance profiles for some of these submodels is already known, the renewed interest in symbolic AI is relatively recent, and combining symbolic execution with neural networks is quite novel.NLM takes a different approach, integrating its symbolic and neural components, and does not contain any submodels.The field is still growing and evolving rapidly; to the best of our knowledge, there is no prior work which analyzes neuro-symbolic workloads.</p>
<p>III. MODEL OVERVIEW A. Neuro-Symbolic Concept Learner</p>
<p>The Neuro-Symbolic Concept Learner (NSCL) was designed for the CLEVR dataset [19].CLEVR is a dataset for "image reasoning": images are presented to the model, along with a set of related questions, and the model's outputs are the  OpenNMT [17] Neural (Transformer) Translates natural-language input questions into a purpose-designed "language" of tokens.Tokens may describe the properties of objects, or describe filtering and querying operations to be performed on the set of object features.</p>
<p>Dynamics Predictor</p>
<p>PropNet [18] Neural Learned physics engine for modeling and predicting collisions between objects.Is capable of accurately modeling complex collisions involving more than two objects, as well as operating with partial information (allowing objects to enter and leave the scene).Symbolic Executor NSCL [5] Quasi-Symbolic Fixed-function model which sequentially applies parsed tokens to extracted image features to answer input questions.Unlike a true symbolic model, approximates non-differentiable functions using probabilistic approaches and softmax, enabling backpropagation.Symbolic Executor NS-DR [8] Symbolic Fixed-function model which applies parsed tokens to both extracted video frame features and PropNet predicted features (collisions).A true symbolic model, it largely performs arithmetic and boolean operations as well as table lookups and queries.</p>
<p>answers to these questions.Image samples in CLEVR contain cubes, cylinders, and spheres with different sizes, colors, and materials.An example of a scene in the CLEVR dataset, with several of its accompanying questions, is shown in Figure 2.</p>
<p>As described in Table I, the NSCL is internally composed of three submodels.We describe each of these submodels in more detail here.</p>
<p>1) Image Parser: The objective of the image parser is to generate object "masks": pixel-accurate regions with annotated colors, shapes, and materials.This is accomplished using a Mask R-CNN model, which constructs object segmentation masks and classifications in parallel [20].While the addition of object mask generation makes its structure somewhat more complex than a traditional convolutional neural network, both branches of computation are internally convolutional.</p>
<p>The implementation of Mask R-CNN originally used for the NSCL proved challenging to run on modern hardware.</p>
<p>Not only was no pretrained model provided, but the software libraries required were obsolete and not compatible with modern CUDA versions.Therefore, we decided to use a more recent, pretrained Mask R-CNN model provided by Facebook's Detectron2 [16].This also had the advantage of giving us access to the profiling tools built into more recent versions of the PyTorch framework.</p>
<p>2) Question Parser: Questions in the CLEVR dataset are in the form of natural language, which presents the challenge of translating them into a form usable by the model.The authors of the NSCL accomplished this by defining a domain-specific language, including verbs, such as "Filter" or "Intersect", and concepts, such as "Blue" or "Left".This effectively converts the problem of question parsing into neural machine translation (NMT).A bidirectional GRU [21] was used to accomplish this task for the original NSDR.However, source code, a pretrained model, or any other information is not available for this model.As such, we chose to profile a small, modern pretrained Transformer-based NMT model provided by Harvard's OpenNMT toolkit [17].This provides similar advantages to the Detectron2 image model: more recent library versions and support for modern DL profiling tools.It also provides a more realistic insight into what deployment of this model would look like in a modern datacenter environment.</p>
<p>3) Symbolic Program Executor: The symbolic program executor converts extracted image features and question tokenizations into predictions.Formally, this model is "quasisymbolic": unlike a true symbolic AI model, which performs logical and boolean operations on data, the executor approximates non-differentiable functions in a probabilistic manner.The output of the NSCL is a vector in which the i'th element, Mask i ∈ [0, 1], represents the probability of the corresponding object in the scene being in the output set.This representation is useful for two reasons.First, it allows for multiple correct answers, which increases the complexity of the questions the model can answer.Second, it makes the symbolic step fully reversible, which allows back-propagation to occur.This approach avoids the limitations of true Boolean circuits, which are in general irreversible.In turn, this reversibility allows for the learning of concept embedding vectors: representations of object features which allow concepts (such as color, shape, and material) to be learned without explicit labels [5].</p>
<p>B. Neuro-Symbolic Dynamic Reasoning</p>
<p>The Neuro-Symbolic Dynamic Reasoning (NS-DR) model is a neuro-symbolic model for the CLEVRER video reasoning dataset.CLEVRER builds on CLEVR by replacing images with videos.Objects in CLEVRER may enter or exit the scene throughout the course of a (5 second, 25 frame) video, potentially colliding and rebounding with other objects.Using videos instead of images adds a new domain to the questions in CLEVRER: that of causality.As described in Table I, causal questions may range from the descriptive ("Which objects collided?") to more complex causal relations ("What caused the objects to collide?Would the objects still have collided if ...").Existing neural models were shown to perform poorly on all but the simple descriptive questions in CLEVRER [8].</p>
<p>In order to account for causal relations, the NS-DR introduces a new submodel: a neural dynamics predictor, which is essentially a learned physics engine.The introduction of the dynamics predictor brings the model up to a total of four independent submodels.We discuss the structure below.</p>
<p>1) Video Frame Parser: The video frame parser treats each frame of a video separately, using the same Mask R-CNN approach as the NSCL.Thus, for each input video, inference with this model must be run 25 times.</p>
<p>2) Question Parser: The original NS-DR model used a more modern NMT model than the NSCL: Seq2Seq [22], which was demonstrated to be more accurate on long inputs than prior models.Once again, we opted to replace this model with the OpenNMT transformer model.</p>
<p>3) Dynamics Predictor: The dynamics predictor, PropNet [18], is a learned physics engine that can represent complex collisions between objects.PropNet improves on prior work in the domain by accurately modeling propagation of force through multiple objects (such as in a Newton's cradle), and operating correctly in the presence of partial information (where not all objects are visible).Functional correctness with partial information is crucial, since all videos in CLEVRER are taken from a fixed camera angle, where objects are allowed to enter and leave the scene.Dynamics prediction provides the positions, trajectories, and collisions between objects for the NS-DR model.The results of the dynamics predictor are augmented with the properties identified by the video frame parser to provide a complete record of what occurred during the input video.</p>
<p>4) Symbolic Program Executor:</p>
<p>The program executor of the NS-DR is a true symbolic model: unlike the NSCL, it uses non-differentiable operations to make predictions.The disadvantage of non-differentiable operations is that it is not possible to back-propagate error; therefore, this model can not learn concept embeddings, so concepts must be learned directly by the frame parser via supervised training.This is an entirely fixed-function model with no learned component; internally, it behaves much like a programming language interpreter, using tokens to apply filter and reduction operations to the extracted video features.</p>
<p>The NS-DR program executor is single-threaded and CPUonly.The sequential nature of its processing does not expose any obvious opportunities for the sorts of coarse-grain parallelism typical of DL workloads: in general, processing the nth token of a sequence will require the result of processing the (n − 1)th token.An example symbolic program, shown in Figure 3, demonstrates how the symbolic program executor uses tokens to filter and perform basic arithmetic on the features extracted by the other submodels.</p>
<p>C. Neural Logic Machines</p>
<p>The Neural Logic Machine (NLM) is a neuro-symbolic architecture that applies both inductive learning and logic reasoning to an object's relations, properties, quantifiers, and logic connectives in order to accomplish the task of generalization.Unlike most traditional networks, NLMs are able to achieve perfect generalization in various tasks such as family tree decisions, sorting of arrays, finding the shortest path between points, or playing the Blocks World task.The NLM architecture provides the ability to solve historically challenging tasks that traditional neural network architectures struggle to complete.The challenge of generalization of tasks from small scale to large scale are proven to be overcome using NLM. Figure 4 shows an illustration for the NLM framework.</p>
<p>IV. METHODOLOGY</p>
<p>We used function-level profiling to capture statistics such as runtimes, invocation counts and tensor sizes.We then developed a post-processing tool to partition the profiling results into eight dominant categories of operations.</p>
<p>A. Experimental Methodology</p>
<p>The characterization of all GPU workloads was performed using the built-in PyTorch profiler (torch.autograd.profiler).This profiler collects CPU and GPU runtimes at a per-function granularity, differentiating between "total" runtime (including subfunctions) and "self" runtime (excluding sub-functions).In most cases, this profiling introduced some overhead, and in a few cases, it appeared to capture its own post-run analysis as overhead.We have compensated for this to the extent possible by comparing runs with and without the profiler enabled.</p>
<p>Since the symbolic executor for the NS-DR is a fixedfunction, CPU-only model, it can not be effectively analyzed using the PyTorch profiler.Instead, we used Python's cProfile module to get per-function execution times.The cProfile module has several limitations when compared to the PyTorch profiler -for instance, it does not profile GPU activity, and does not report input tensor sizes.However, these limitations have no impact on scalar, CPU-only code.</p>
<p>Data collection was performed on a system with two Intel Xeon E5-2698 v3 processors (totaling 32 cores and 64 threads), 128GB of DDR4 memory at 2133MHz, and two NVIDIA Tesla M40s.However, most models were only singlethreaded, and were only able to make efficient use of a single GPU for inference.</p>
<p>B. Workload Taxonomy</p>
<p>Since simply reporting per-function profiling results would require us to discuss an overwhelming number of individual functions, we devised a function classification scheme to partition the data into eight dominant categories of operations.We drew inspiration for this classification from the Berkeley "seven dwarfs" [23]: a mid-2000s effort to identify what were then the most crucial kernels for parallel computing.In fact, some of our categories are identical to Berkeley "dwarfs", but we identify several others that also appear highly relevant to the workloads discussed in this paper and/or machine learning more generally.Given the wide diversity of models in modern AI research, we do not claim that our classification scheme is universally applicable.However, we do hope to show that workload classification schemes are valuable for exploring the differences between models.</p>
<p>1) Dense Matrix Multiplication: Fast, efficient dense matrix multiplication (GEMM) remains a critical requirement for large DL models.Fully-connected layers in neural networks use GEMM as their primary mathematical operation, often with very large input matrices.</p>
<p>Multiplication of large, dense matrices is very computationally intensive: the work to multiply a m × k matrix with a k × m matrix W = O(mnk).At the same time, data intensity only grows quadratically with input size: given the two input matrices and m × n output matrix, the data intensity Q = O(mk +kn+mn) = O(max(mk, kn, mn)).This gives an operational intensity of:
I = W Q = O(mkn) O(max(mk, kn, mn)) = O(min(m, k, n))
When m, k, and n are all large, operational intensity can be very high.Since there are no internal dependencies in matrix multiplication (the multiply-and-add operations can be performed in any order), the multiplication of large, roughlysquare matrices is highly parallelizable.The challenge emerges when any one of the dimensions is small relative to the other two; in this case, the operational intensity approaches O(1), requiring highly efficient data movement to avoid becoming memory-bound.Such "tall-and-skinny" matrices are difficult to process efficiently on GPUs [24].While operational intensity can sometimes be addressed by processing multiple inputs simultaneously via batching, this may not be an option for latency-sensitive inference operations where input must be processed as soon as it is received.An extreme case of tall-and-skinny GEMM is the multiplication of a matrix by a vector, as an n-element vector can be viewed as an n × 1 matrix.2) Sparse Matrix Multiplication: Sparse matrices are those in which the values of only some elements are specified; all other elements are assumed to be some constant value, typically 0. There are numerous ways to implement sparse matrices; in general, there is a tradeoff between the generality of the sparsity (how much structure is assumed) and how easy it is to implement in hardware [25].Sparse matrix multiplication requires efficient mechanisms to perform lookups into the tables of non-zero values.</p>
<p>3) Convolution: Convolutions are another class of common, computationally intensive operation.Unlike in GEMM, one of the inputs, the filter, is multiplied with a set of submatrices of the other input.In theory, this should lead to excellent operational intensity, since filter weights are reused for each individual multiplication, and weights from the other matrix are reused by overlapping submatrices.In practice, convolutions have proven difficult to parallelize, and are frequently implemented using the im2col algorithm, which reduces the problem to matrix multiplication.Performing im2col requires substantial data movement and duplication, worsening the performance and memory footprint of convolution.Recent efforts have focused on performing convolution "natively", without invoking im2col [26].The more complex memory access patterns of these approaches have their own considerations for efficient implementation.Whether im2col is used or not, convolution presents a workload distinct from simple GEMM.4) Element-wise Tensor Operations: Many operations in deep learning are applied uniformly to all elements in a tensor.These include activation, normalization, tensor addition, Hadamard products, tensor-scalar operations, and relational operations.All of these operations are "embarrassingly parallel" in that they can be applied to every element of a tensor simultaneously, but are challenging in that they have poor operational intensity; each element of the input is only operated on once.5) Regional Operations: Some operations act on spatially local regions of tensors.The best-known example of a regional operation is pooling, which reduces the size of a tensor in one or more dimensions by performing some reduction operation (such as max or average) regionally.This is not the only class of regional operation; other examples include non-maximum suppression and region-of-interest alignment in object detection networks.These operations are distinct from element-wise operations in that they operate on potentially overlapping regions rather than single elements and thus have more complex access patterns; they are distinct from convolution in that they operate on only a single tensor and typically involve less computation.</p>
<p>6) Embedding Lookups: Embeddings are a way of transforming data indices or high-dimensional one-hot vectors into low-dimensional learned vectors.In practice, during inference, embeddings function as lookup tables.The irregular memory access patterns of embedding lookups and the large sizes of embedding tables make acceleration a challenge.Traditionally, embedding lookups are latency-sensitive, memory-bound operations for inference [27].</p>
<p>7) Data Movement: Many types of operations require substantial data movement but little or no computation.This primarily consists of host-device and device-host transfers; we also include operations such as tensor duplication and assignment.</p>
<p>8) Data Transformation: The last category of operations we identify is data transformation: operations which reshape or subsample data.This includes matrix transposes, tensor reordering, and masked selection.We also include coalescing in this category, which is a process in which duplicate entries for the same coordinates in a sparse matrix are eliminated by summing their associated values [28].</p>
<p>V. RESULTS</p>
<p>In this section, we present and discuss results for the individual submodels introduced in Section IV.We first present and discuss the performance characterizations of the individual submodels, then discuss the aggregate inference runtime behavior of the NSCL, NS-DR, and NLM models.</p>
<p>A. Image and Video Frame Parser</p>
<p>Mask R-CNN, the video frame parser, has a well-studied performance profile that is dominated by convolution and activation functions [20].As mentioned in Section III, we used Detectron2 due to difficulties bringing up the version of Mask R-CNN used in the NS-DR paper.Mobile-optimized, production ready implementations of Detectron2 models are provided by the d2go project [29], which we used to collect realistic performance measurements for Mask R-CNN inference latency.The pretrained model we used was not trained on the CLEVR or CLEVRER dataset, as there is no pretrained model, model source, or training instructions for CLEVRER, and we wanted to use the same submodel for both the NSCL and NS-DR.However, we do not anticipate that the performance characteristics of the model would be any different if it were trained for a different dataset, particularly since the runtime of this model does not significantly vary with the number of objects in the input image.</p>
<p>Our analysis of Detectron2, as shown in Table III and Figure 6, shows that Mask R-CNN spends the most execution time on convolution and element-wise operations (such as activation functions and normalization).This is not particularly surprising, but serves as a simple example of our classification scheme.With an average 34.6ms inference time on our target machine, a full 25-frame video requires 865ms of inference time for the CLEVRER dataset.Thus, the NS-DR video frame parser takes dramatically longer than the NSCL image parser.</p>
<p>B. Question Parser</p>
<p>NLP models such as Seq2Seq, the original question parser in the NS-DR, are a well-established family, having seen datacenter deployments since at least 2016 [30].However, transformer-based attention models, such as the OpenNMT model we profiled, typically outperform RNN-based models such as Seq2Seq, and have seen wider adoption since 2017 [31].</p>
<p>The amount of computation required to perform inference for an NMT model is dependent on the input sequence length.Sentences in the CLEVR dataset have an average length of 18.4 words.The CLEVRER dataset is split between openended questions with an average length of 10.9 words and multiple-choice questions with an average length of 51.3 words (counting the answer choices), for an overall average of 22.2 words.</p>
<p>Figure 6 shows that the performance of the transformerbased OpenNMT model is dominated by dense matrix multiplication and data movement.The OpenNMT model performed inference in an average of 13.5ms per input word/token.In practice, the runtime of a transformer model asymptotically grows quadratically with input sequence length [32], but we observed a linear relation on sample input sentences.It is likely that, for the relatively short lengths of the inputs we were observing, linear per-word operations dominated the quadratic attention operations.</p>
<p>C. Dynamics Predictor</p>
<p>PropNet, the neural dynamics predictor, spends the majority of its runtime on data movement.In fact, while analyzing the behavior of this model using the nvidia-smi utility, we noticed it was rarely able to exceed 50% utilization of one GPU.The model also spends a substantial amount of time on coalescing, which entails merging duplicate entries in sparse tensors.It is unclear to what extent this coalescing could be avoided through better-optimized code.A substantial portion of the remaining runtime is spent on dense matrix multiplication.This is because the workload involves the multiplication of many very tall and skinny matrices, where m and n are quite large, but k may be as small as 1.As discussed in Section IV, these types of matrices are challenging to multiply efficiently.</p>
<p>Internally, this model consists of several smaller fullyconnected and convolutional networks.Some of these models must be run multiple times for a single frame in order to compute the propagation of forces.This contributes to this model's large amount of data movement and generally long runtime.The data movement of this model could be reduced by leveraging sparsity and weight reuse; since the same submodel is used for inference many times, it is wasteful to move over the weights for each inference.</p>
<p>Some tensor dimensions are input-dependent, corresponding to the number of objects in the frame.We also observed substantial variation in inference runtimes.Across 400 samples, the fastest inference finished in 1.8 seconds, and the slowest in 5.3 seconds, with an average of 3.4 seconds.Fig. 6.Runtime breakdown for each of the three models, including submodels for NSCL and NS-DR and three distinct tasks for NLM.Note the differing Y scales for the three models.</p>
<p>D. NSCL Symbolic Program Executor</p>
<p>The symbolic executor for the NSCL spends a large portion of its execution time on element-wise operations, and a smaller but still significant amount of time on data movement.These element-wise operations stem from its manipulation of vectors of probabilities (with entries corresponding to the probabilities of each object in the scene being a correct answer).In addition to simple arithmetic, the model computes numerous softmax functions over these vectors in order to isolate predictions.Notably, not much time is spent on matrix-matrix operations (GEMM and convolution), which would have better operational intensity and potential for parallelism than the scalar and vector operations we see dominating.</p>
<p>E. NS-DR Symbolic Program Executor</p>
<p>The symbolic program executor for the NS-DR has an average runtime of 12.9ms per sample.While this is not large compared to the other models in the network, all other models must finish before the executor can begin, and it therefore lies on the critical path for inference.Since the NS-DR executor is a CPU-only, scalar model, it would not make sense to categorize it according to the scheme we derived for the other workloads.Therefore, we used Python's built-in cProfile profiler to perform functionlevel profiling and identified categories of similar functions.The results of this analysis are shown in Figure 7. Note, however, that the plurality of the runtime still falls into the "Other" category.This is a consequence of there being many miscellaneous functions which individually contribute little to runtime, but collectively contribute more than any of the major categories.</p>
<p>Much of the executor's runtime is spent on querying the set of extracted features.Examples of these queries include finding the ID of an object with given properties, looking up the properties of an object given its ID, and queries relating multiple objects such as finding an object's closest neighbor.These queries look similar to standard database operations.For a sufficiently large set of symbolic features, it is likely that feature querying could be approached using existing work in parallelizing SQL queries [33].However, the feature set the NS-DR extracts is relatively small, meaning that the overhead which parallelism incurs would almost certainly overwhelm the speedup for this model.</p>
<p>The next-largest category of execution time is spent on scalar arithmetic operations, in particular summing large arrays.In principle these sorts of operations can sometimes benefit from being spread across multiple CPU cores, but in practice we again expect the small size of the feature set to make this pointless.</p>
<p>The third-largest category of operation is in fact JSON parsing.This is an unfortunate artifact of the way data is passed in the NS-DR model: rather than an end-to-end integration, it stores data in JSON files between submodels.This means that the executor has to load in the questions and extracted features from JSONs for each inference sample.This overhead turns out to be substantial for the very short runtime of this model.</p>
<p>F. Neural Logic Machines</p>
<p>A characterization profile was created for each of the NLM tasks: Sort, Path, and Blocks World.Each task provided ranging variations in the produced results.The largest category of operation was the "other" category, where a significant amount of overall time was spent.The percentage of time spent in the other category can be determined as 40.9 percent for the Sort task, 40.0 percent for the critical path task, and 45.1 percent for the Blocks World task.The amount of time spent in the other category can be attributed to miscellaneous internal querying and generation functions for the different tasks.</p>
<p>Following the "other" category, the element-wise category contributed the second most to the task executions.The Sort task resulted in the highest percentage of element-wise functions related to the vector multiplication being performed on the numerical task.The high percentage of element-wise functions is also represented in the Path task, with approximately a third of the total runtime spent on element-wise tasks.</p>
<p>Data movement represents the third largest category that was characterized during the task executions.The Sort task and Path task shared the highest percentage of data movement within the model's execution.This is predominantly due to the frequent movement of numerical values in these general tasks.Blocks World yielded the lowest data movement characteristic which can be perceived by the more symbolic and logical flow of functions and it's data.</p>
<p>VI. ANALYSIS</p>
<p>Figure 6 shows the execution time breakdowns for single input samples for each of the three models in this paper.We now discuss each model individually.</p>
<p>A. NSCL and NS-DR</p>
<p>The NSCL runs in an average of 375ms per sample, with 310ms of this coming just from the question parser.The clear bottleneck for this workload, dominating the question parser's runtime, is dense matrix multiplication.This is another case where a sparse version of the model could potentially yield improvements to runtime.However, this is not the only contributing factor to the question parser's long runtime.Although the ability to ask questions of a model using natural language is convenient, it is worth keeping in mind that it can add substantial overhead and complexity, and considering whether a simpler, machine-readable input "language" could be used instead.</p>
<p>It is clear that the dynamics predictor dominates the inference runtime of the NS-DR.The total inference time for this model is 4.44 seconds.Since input videos are 5 seconds long, this does in theory allow for real-time inference on this system, but this would not hold true for low-power or embedded platforms.Some portions of the NS-DR and NSCL are more suited for acceleration than others.The CNN-based video frame parser and the transformer-based question parser model can be accelerated with existing GPU or accelerator architectures [34].On the other hand, the NS-DR's dynamics predictor is severely data-movement-bound due to its many sparse and small tensor operations, and also suffers from the difficulty of multiplying "tall-and-skinny" matrices.It is possible that data movement could be reduced somewhat through code optimization, but it is fundamentally difficult to accelerate workloads with poor operational intensity.There have also been several approaches investigated for near-memory linear algebra [35] [36], which would likely be beneficial for PropNet as the reduced time accessing memory would help compensate for the poor operational intensity.</p>
<p>The symbolic executor of the NS-DR exhibits complex control flow and heterogeneous functionality.Overall, this workload has very little of the coarse-grain parallelism typical of deep learning workloads.However, there are still opportunities for fine-grain parallelism in its database queries and arithmetic operations.It is doubtful that a multicore CPU implementation would give any speedup for this particular workload, given the relatively small sizes of the feature sets, but this could be a viable approach for larger symbolic models.</p>
<p>Our biggest takeaway from analyzing the performance of the NSCL and NS-DR models is that these NSAI models still perform largely the same work as other AI models that have been previously studied, in large part due to the small amount of time spent on symbolic execution.We were able to largely classify the types of operations performed by the neural dynamics predictor, the bottleneck in the NS-DR, into the same primitive operations performed by other ML models in different domains.Although the symbolic executor is currently a small fraction of the inference runtime for both models, it is likely that this component's complexity will increase over time as model developers seek to extract and manipulate more complex relations between features.We believe that it is possible to leverage work from similar program architectures, such as relational databases, to reduce the impact of this.</p>
<p>B. NLM</p>
<p>The NLM showcased the ability for the architecture to train a model on small scale tasks and generalize to solve large scale tasks with lifted rules and added premises, which shows the expressive power of the network.The ability to scale the rule set from a small sized rule set to a large sized rule set has proven to be difficult for inductive logic programming systems.The combination of using both symbols and probabilities helps solve these issues.The NLM proves to accomplish complex tasks by overcoming major challenges that traditional neural networks and inductive logic reasoning systems cannot solve alone.The tasks that were used involved the graph-based path task, the general sort application task, and the more complex Blocks World task.These different problems presented variations in the system's performance, as each task involved different levels of logic rule set complexity.In addition, the NLM architecture also solves the problem of scalability with respect to the complexity of rules given to the system.As the rules of the task scale up, the complexity of the logic rules to be learned will also scale up exponentially.This allows the NLM to adjust its trained rules based on uses of a minimal set of prior examples.Using a minimum set of prior data illustrates the ability for the NLM to effectively improve as it learns.As these different tasks use a variation of input data and parameters, the performance evaluation of these exercises gives many opportunities for improvement.</p>
<p>VII. CONCLUSION</p>
<p>While neuro-symbolic models with submodels look topologically distinct from traditional deep learning models, our analysis suggests that their performance characteristics can be largely viewed as a combination of existing workloads.Our analysis of the NSCL and NS-DR show that there are relatively few opportunities for acceleration of symbolic computation.The symbolic workloads of these two models have low operational intensities, consisting of vector and/or scalar operations, and exhibit complex control flow.These factors combined greatly limit the potential for parallelism.However, the symbolic components do not make up large portions of the execution times of either workload, and are therefore unlikely to pose a bottleneck.On the other hand, the NLP, dynamics predictor, and vision submodels exhibit different dominant operation categories, including dense GEMM in the question parser, data movement in the dynamics predictor, and a co-dominance of convolution and element-wise operations in the image and frame parser.NLM models require numerous element-wise operations for inference, with the computational demand increasing with the complexity of the task-specific logical rule set.</p>
<p>The challenge of accelerating the low-operational-intensity, element-wise computations of workloads such as NLM will become increasingly important as this field sees further development.</p>
<p>ACKNOWLEDGEMENT</p>
<p>This research was supported in part by Semiconductor Research Corporation (SRC) Task 3015.001/3016.001and National Science Foundation grant number 1763848.Any opinions, findings, conclusions or recommendations are those of the authors and not of the funding agencies.</p>
<p>Fig. 2 .
2
Fig.2.A sample from the CLEVR image reasoning dataset with several accompanying questions.Questions explore the properties of and relations between objects in the scene.</p>
<p>Fig. 3 .
3
Fig.3.An example of the tokenized representation of a question in the CLEVRER dataset."Noun/Adjective" tokens -features -have white backgrounds, while "verb" tokens -actions -are shaded.Arrows show the dependencies for token processing[8].</p>
<p>Fig. 4 .Fig. 5 .
45
Fig. 4.An illustration of the NLM framework showing object properties and object relations as inputs, the concluding outputs of the objects properties and relations, and the internal logical structure.Image originally from [9].</p>
<p>Fig. 7 .
7
Fig. 7. Breakdown of the NS-DR's symbolic component (This model is broken down separately since it is the only CPU-only component.)</p>
<p>TABLE III RUNTIMES
III
AND RUNTIME BREAKDOWNS FOR SINGLE INPUTS TO THE MODELS DISCUSSED IN THIS PAPER.
ModelGEMM Sparse MMConvElement-Wise RegionalEmbedding Data Move Data TransformOtherTotalImage/Frame Parser0.19ms0ms11.8ms11.1ms0.54ms0ms6.0ms2.4ms2.6ms34.6msQuestion Parser166ms0ms0ms53.5ms0ms0.27ms50.1ms9.9ms17.3ms297msDynamics Predictor715ms9.9ms294ms345ms0ms0ms1300ms403ms125ms3200msNSCL Executor39.9us0us46.4us122.4us33.5us0.0us76.0us20.5us149.5us488.3usNS-DR ExecutorN/AN/AN/AN/AN/AN/AN/AN/A12.9ms*12.9msNLM Path1.2s0s0s4.7s0s0s3.6s1.5s7.3s18.3sNLM Sort2.6s0s0s11.1s0s7.5s3.4s17.1s41.7sNLM Blocks World635ms0ms0ms2100ms0ms0ms1400ms618ms3100ms7850ms
APPENDIX Repository links for the models referenced in this paper: NSCL https://github.com/vacancy/NSCL-PyTorch-ReleaseNS-DR https://github.com/chuangg/CLEVRERDetectron2 (d2go) https://github.com/facebookresearch/d2goOpenNMT https://github.com/OpenNMT/OpenNMT-pyPropnet https://github.com/YunzhuLi/PropNetNLM https://github.com/google/neural-logic-machines
Methods for interpreting and understanding deep neural networks. G Montavon, W Samek, K.-R Müller, Digital Signal Processing. 732018</p>
<p>Reconciling deep learning with symbolic artificial intelligence: representing objects and relations. M Garnelo, M Shanahan, Current Opinion in Behavioral Sciences. 292019</p>
<p>Artificial intelligence: A general survey. J Lighthill, Artificial Intelligence: a paper symposium. 1973</p>
<p>Avoiding another ai winter. J Hendler, IEEE Annals of the History of Computing. 23022008</p>
<p>The neurosymbolic concept learner: Interpreting scenes, words, and sentences from natural supervision. J Mao, C Gan, P Kohli, J B Tenenbaum, J Wu, 2019</p>
<p>Transparency by design: Closing the gap between performance and interpretability in visual reasoning. D Mascharka, P Tran, R Soklaski, A Majumdar, abs/1803.05268CoRR. 2018</p>
<p>Compositional attention networks for machine reasoning. D A Hudson, C D Manning, International Conference on Learning Representations. 2018</p>
<p>Clevrer: Collision events for video representation and reasoning. K Yi, C Gan, Y Li, P Kohli, J Wu, A Torralba, J B Tenenbaum, 2020</p>
<p>Neural logic machines. H Dong, J Mao, T Lin, C Wang, L Li, D Zhou, CoRR. 1904.11694, 2019</p>
<p>Visual conceptmetaconcept learning. C Han, J Mao, C Gan, J B Tenenbaum, J Wu, 2020</p>
<p>Grounding physical concepts of objects and events through dynamic visual reasoning. Z Chen, J Mao, J Wu, K.-Y K Wong, J B Tenenbaum, C Gan, International Conference on Learning Representations. 2021</p>
<p>Principles of artificial intelligence. N J Nilsson, Principles of Artificial Intelligence. Berlin HeidelbergSpringer-Verlag1982</p>
<p>The neuro-symbolic concept learner: Interpreting scenes, words, and sentences from natural supervision. J Mao, C Gan, P Kohli, J B Tenenbaum, J Wu, International Conference on Learning Representations. 2019</p>
<p>Low latency rnn inference with cellular batching. P Gao, L Yu, Y Wu, J Li, 10.1145/3190508.3190541Proceedings of the Thirteenth EuroSys Conference, ser. EuroSys '18. the Thirteenth EuroSys Conference, ser. EuroSys '18New York, NY, USAAssociation for Computing Machinery2018</p>
<p>Lightweight mask R-CNN for long-range wireless power transfer systems. H Li, A Wu, W Fang, Q Zhang, M Liu, Q Liu, W Chen, CoRR. 2004.08761. 2020</p>
<p>Detectron2. Y Wu, A Kirillov, F Massa, W.-Y Lo, R Girshick, 2019</p>
<p>Opennmt: Open-source toolkit for neural machine translation. G Klein, Y Kim, Y Deng, J Senellart, A M Rush, 2017</p>
<p>Propagation networks for model-based control under partial observation. Y Li, J Wu, J.-Y Zhu, J B Tenenbaum, A Torralba, R Tedrake, ICRA2019</p>
<p>CLEVR: A diagnostic dataset for compositional language and elementary visual reasoning. J Johnson, B Hariharan, L Van Der Maaten, L Fei-Fei, C L Zitnick, R B Girshick, abs/1612.06890CoRR. 2016</p>
<p>Mask r-cnn. K He, G Gkioxari, P Dollár, R Girshick, 2018</p>
<p>Learning phrase representations using RNN encoder-decoder for statistical machine translation. K Cho, B Van Merriënboer, C Gulcehre, D Bahdanau, F Bougares, H Schwenk, Y Bengio, Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP). the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)Doha, QatarAssociation for Computational LinguisticsOct. 2014</p>
<p>Neural machine translation by jointly learning to align and translate. D Bahdanau, K Cho, Y Bengio, 2016</p>
<p>K Asanovic, R Bodik, B Catanzaro, J Gebis, P Husbands, K Keutzer, D Patterson, W Plishker, J Shalf, S Williams, K Yelick, The landscape of parallel computing research: A view from berkeley. 122006</p>
<p>Tsm2x: High-performance tall-and-skinny matrix-matrix multiplication on gpus. C Rivera, J Chen, N Xiong, J Zhang, S L Song, D Tao, 10.1016/j.jpdc.2021.02.013Journal of Parallel and Distributed Computing. 151May 2021</p>
<p>Learning N: M fine-grained structured sparse neural networks from scratch. A Zhou, Y Ma, J Zhu, J Liu, Z Zhang, K Yuan, W Sun, H Li, abs/2102.04010CoRR. 2021</p>
<p>Parallel multi channel convolution using general matrix multiplication. A Vasudevan, A Anderson, D Gregg, 2017 IEEE 28th International Conference on Application-specific Systems, Architectures and Processors. 2017</p>
<p>Recnmp: Accelerating personalized recommendation with near-memory processing. L Ke, U Gupta, B Y Cho, D Brooks, V Chandra, U Diril, A Firoozshahian, K Hazelwood, B Jia, H.-H S Lee, M Li, B Maher, D Mudigere, M Naumov, M Schatz, M Smelyanskiy, X Wang, B Reagen, C.-J Wu, M Hempstead, X Zhang, 2020 ACM/IEEE 47th Annual International Symposium on Computer Architecture (ISCA). 2020</p>
<p>D2go brings detectron2 to mobile. </p>
<p>Sequence to sequence learning with neural networks. I Sutskever, O Vinyals, Q V Le, 2014</p>
<p>Attention is all you need. A Vaswani, N Shazeer, N Parmar, J Uszkoreit, L Jones, A N Gomez, L Kaiser, I Polosukhin, 2017</p>
<p>Transformers are rnns: Fast autoregressive transformers with linear attention. A Katharopoulos, A Vyas, N Pappas, F Fleuret, CoRR. 2006.16236. 2020</p>
<p>Parallel sql execution in oracle 10g. T Cruanes, B Dageville, B Ghosh, 10.1145/1007568.1007666Proceedings of the 2004 ACM SIGMOD International Conference on Management of Data, ser. SIGMOD '04. the 2004 ACM SIGMOD International Conference on Management of Data, ser. SIGMOD '04New York, NY, USAAssociation for Computing Machinery2004</p>
<p>High-performance deep-learning coprocessor integrated into x86 soc with server-class cpus industrial product. G Henry, P Palangpour, M Thomson, J S Gardner, B Arden, J Donahue, K Houck, J Johnson, K O'brien, S Petersen, B Seroussi, T Walker, 2020 ACM/IEEE 47th Annual International Symposium on Computer Architecture (ISCA). 2020</p>
<p>Near-memory data transformation for efficient sparse matrix multi-vector multiplication. D Fujiki, N Chatterjee, D Lee, M O'connor, 10.1145/3295500.3356154Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis, ser. SC '19. the International Conference for High Performance Computing, Networking, Storage and Analysis, ser. SC '19New York, NY, USAAssociation for Computing Machinery2019</p>
<p>Spacea: Sparse matrix vector multiplication on processing-inmemory accelerator. X Xie, Z Liang, P Gu, A Basak, L Deng, L Liang, X Hu, Y Xie, 2021 IEEE International Symposium on High-Performance Computer Architecture (HPCA). 2021</p>            </div>
        </div>

    </div>
</body>
</html>