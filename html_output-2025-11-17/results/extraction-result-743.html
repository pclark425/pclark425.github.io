<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-743 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-743</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-743</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-20.html">extraction-schema-20</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <p><strong>Paper ID:</strong> paper-244423474</p>
                <p><strong>Paper Title:</strong> Explaining and predicting human behavior and social dynamics in simulated virtual worlds: reproducibility, generalizability, and robustness of causal discovery methods</p>
                <p><strong>Paper Abstract:</strong> Ground Truth program was designed to evaluate social science modeling approaches using simulation test beds with ground truth intentionally and systematically embedded to understand and model complex Human Domain systems and their dynamics Lazer et al. (Science 369:1060–1062, 2020). Our multidisciplinary team of data scientists, statisticians, experts in Artificial Intelligence (AI) and visual analytics had a unique role on the program to investigate accuracy, reproducibility, generalizability, and robustness of the state-of-the-art (SOTA) causal structure learning approaches applied to fully observed and sampled simulated data across virtual worlds. In addition, we analyzed the feasibility of using machine learning models to predict future social behavior with and without causal knowledge explicitly embedded. In this paper, we first present our causal modeling approach to discover the causal structure of four virtual worlds produced by the simulation teams—Urban Life, Financial Governance, Disaster and Geopolitical Conflict. Our approach adapts the state-of-the-art causal discovery (including ensemble models), machine learning, data analytics, and visualization techniques to allow a human-machine team to reverse-engineer the true causal relations from sampled and fully observed data. We next present our reproducibility analysis of two research methods team’s performance using a range of causal discovery models applied to both sampled and fully observed data, and analyze their effectiveness and limitations. We further investigate the generalizability and robustness to sampling of the SOTA causal discovery approaches on additional simulated datasets with known ground truth. Our results reveal the limitations of existing causal modeling approaches when applied to large-scale, noisy, high-dimensional data with unobserved variables and unknown relationships between them. We show that the SOTA causal models explored in our experiments are not designed to take advantage from vasts amounts of data and have difficulty recovering ground truth when latent confounders are present; they do not generalize well across simulation scenarios and are not robust to sampling; they are vulnerable to data and modeling assumptions, and therefore, the results are hard to reproduce. Finally, when we outline lessons learned and provide recommendations to improve models for causal discovery and prediction of human social behavior from observational data, we highlight the importance of learning data to knowledge representations or transformations to improve causal discovery and describe the benefit of causal feature selection for predictive and prescriptive modeling.</p>
                <p><strong>Cost:</strong> 0.019</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e743.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e743.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Causal ensemble</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Causal discovery ensemble pipeline (Volkova et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An ensemble pipeline that combines multiple state-of-the-art causal structure learning algorithms to produce a single ranked causal link prediction model; used with human-in-the-loop visual analytics and post-hoc filtering to improve robustness to sampling and noisy data.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Causal discovery ensemble</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Combines outputs of multiple causal discovery algorithms (constraint- and score-based) to produce an aggregated causal graph. The pipeline aggregates candidate edges (with associated edge weights or confidence scores) produced by individual algorithms and then ranks/filters edges to produce a final graph. The authors experimented with ensembles built from all available algorithms and with restricted ensembles composed of the top-performing four algorithms (GES, PC, GS, IAMB / variants), showing that excluding the least-stable algorithms improves ensemble stability. The pipeline is paired with a human-in-the-loop visual analytics tool for inspection and manual analysis.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>GT virtual worlds (Urban, Power, Disaster, Conflict) and synthetic benchmarks (pcalg-generated DAGs, bnlearn datasets)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Large simulated virtual worlds (four scenario-specific simulation outputs) and synthetic datasets: fully observed simulation outputs and sampled (research request) subsets; these are observational simulation datasets (not interactive experiments in this paper), and include sampled data with high sparsity and mixed data types. Additional experiments used synthetic DAGs (pcalg) and bnlearn benchmark networks.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Consensus/aggregation across multiple causal discovery algorithms to reduce algorithm-specific false positives, plus post-aggregation edge scoring and threshold/filtering to remove low-confidence (potentially spurious) edges.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Irrelevant/spuriously correlated variables, sampling-induced spurious edges, noisy measurements, and instability from finite samples.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Empirical resampling-based robustness analysis: repeat causal discovery on multiple subsamples and measure frequency of each edge/node; edges with low repeat frequency are treated as unstable/spurious. Comparison of sampled vs full data and comparison against known ground truth on synthetic graphs are also used to detect spurious signals.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Edge confidence aggregation (averaging/combining algorithm outputs) and explicit edge weight thresholding (e.g., 0.65 threshold used in experiments) to remove or downweight low-confidence edges.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Resampling variability (low presence across repeated runs) used to refute edges; comparing inferred edges to ground-truth graphs for synthetic data; comparing sampled-data graphs to full-data graphs to determine absent signal versus methodological failures.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>Top-four-algorithm ensemble (restricted ensemble) was highly stable on full data and more robust to sampling than the all-algorithm ensemble; applying edge filtering (threshold 0.65) increased robustness by ~6% on average. Node discovery F1 on full data ranged 0.3–0.8; sampled-data node F1 ranged 0.13–0.53. Edge discovery F1 was much lower (highest observed edge F1 = 0.30 for the Disaster scenario).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td>All-algorithm ensemble (no selection/filtering) was less stable and more sensitive to sampling; exact comparative F1 values not provided per-ensemble but robustness analyses show notable improvements after restricting to top algorithms and filtering.</td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Ensembling across algorithms can reduce some spurious signals but is vulnerable to the least-stable constituent algorithms; restricting an ensemble to the top-performing algorithms and applying edge-weight filtering improves robustness to sampling and reduces low-confidence/spurious edges. Larger sample sizes increase ensemble stability; ensembles still struggle when latent confounders or insufficient signal exist.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Explaining and predicting human behavior and social dynamics in simulated virtual worlds: reproducibility, generalizability, and robustness of causal discovery methods', 'publication_date_yy_mm': '2021-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e743.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e743.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Edge filtering / thresholding</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Edge weight thresholding (ensemble filtering)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Post-processing technique that removes low-confidence edges from aggregated ensemble outputs by applying an edge-weight threshold (the authors used 0.65) to improve robustness to spurious edges.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Edge weight thresholding</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>After aggregating edge scores from multiple causal discovery algorithms, apply a cutoff threshold to edge confidence/weight; edges below the threshold are discarded from the final causal graph. The technique is used to trade off recall for higher precision and increased robustness across resampled datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>GT virtual worlds and synthetic pcalg/bnlearn datasets</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Observational simulation outputs and synthetic DAG-generated datasets evaluated under repeated subsampling (8%, 16%, 32%, 64%) and full-data runs to measure stability.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Low-confidence edge removal via fixed thresholding on aggregated edge scores.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Low-confidence/spurious edges caused by sampling noise, algorithmic variance, and weak statistical signals.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Hard thresholding of aggregated edge weights (edges below threshold removed); implicitly downweights signals with low consensus across algorithms or low aggregated confidence.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Edges filtered out by threshold are treated as insufficiently supported and thus refuted in the final graph; empirical evaluation shows filtered graphs have higher robustness.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>Applying an edge weight threshold (0.65) increased robustness of predicted edges by approximately 6% on average in the tests reported.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td>Without thresholding, predicted edges included more low-confidence edges and ensemble robustness decreased; exact numerical baseline not reported other than relative improvement.</td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Simple post-hoc edge filtering meaningfully increases the robustness of ensemble causal predictions across resamples; filtering prefers higher-precision, lower-recall graphs and can reduce spurious links introduced by algorithmic variance.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Explaining and predicting human behavior and social dynamics in simulated virtual worlds: reproducibility, generalizability, and robustness of causal discovery methods', 'publication_date_yy_mm': '2021-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e743.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e743.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Causal feature selection (parents / ancestors)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Causal feature selection using inferred parents and ancestors (Volkova et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Feature selection strategy that uses a learned causal graph to restrict model inputs to the causal ancestry (or direct parents) of a target variable, thereby removing spuriously correlated features and reducing dimensionality for predictive tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Causal feature selection (ancestry / parent selection)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Given a causal graph (learned or ground truth), select as predictive features either (a) all nodes in the causal ancestry of the target, or (b) only direct parents of the target (Markov blanket style). Train standard ML models using only these causal features to reduce influence of spurious correlates. The authors used this approach both when the true graph was available (synthetic experiments) and when graphs were inferred from data.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Synthetic pcalg DAG experiments and GT virtual worlds predictive experiments</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Non-interventional simulated datasets (synthetic linear-Gaussian DAG data and sampled virtual-world observational data), used for training ML predictors for node values and agent decisions.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Explicit exclusion of non-ancestral/non-parent features (feature pruning) using causal graph structure (parents or ancestors), equivalent to Markov-blanket style selection for direct parents.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Irrelevant/spuriously correlated input features and high-dimensional irrelevant variables that do not lie on causal paths to the target.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Relies on structure learned by causal discovery algorithms (or ground truth) to identify causal parents/ancestors; does not itself run additional detectors.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Hard exclusion of non-causal features rather than continuous downweighting; selected causal features are used exclusively for prediction.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Performance comparison (ablation) between using all features vs ancestry vs parents: improved predictive performance on many tasks supports that excluded features were spurious.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>In synthetic experiments with ground-truth graphs, using direct parents improved predictive F1 for binary outputs (example: binary→binary DNN: All nodes F1=0.702 vs Indirect F1=0.750*** vs Direct F1=0.763**), and reduced RMSE for many continuous tasks (statistically significant improvements reported). For GT virtual worlds, causal feature selection improved end-to-end predictive performance in 2 of 4 scenarios (Disaster and Power).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td>Using all available variables as inputs often matched or outperformed causal selection on mixed-type datasets; in practice, using inferred (noisy) graphs can reduce or eliminate the benefit if causal discovery errors are present.</td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>When the causal graph is correct (ground truth), restricting predictors to direct parents or ancestors reliably reduces spurious correlations and improves predictive performance—especially for binary outputs. However, when the graph is inferred with uncertainty, errors in causal structure can negate benefits; thus causal feature selection requires sufficiently accurate causal discovery to be effective.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Explaining and predicting human behavior and social dynamics in simulated virtual worlds: reproducibility, generalizability, and robustness of causal discovery methods', 'publication_date_yy_mm': '2021-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e743.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e743.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Resampling robustness</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Resampling-based edge/node robustness measurement</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A detection and evaluation protocol that repeats causal discovery across multiple subsamples and quantifies the frequency with which each node/edge appears as a robustness/confidence score to identify unstable (potentially spurious) relationships.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Resampling robustness metric</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Repeat causal discovery N times on different subsamples (the authors used sample fractions 8%, 16%, 32%, 64%) and compute for each directed/undirected edge and node the proportion of runs in which it appears; use these proportions as robustness/confidence scores. Low-frequency edges are considered unstable/spurious. This metric is used to compare algorithms and ensembles, and to guide filtering.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Synthetic pcalg DAG experiments and GT virtual worlds (sampled/full)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Observational datasets evaluated under repeated random subsampling and repeated causal discovery runs; not an interactive experimental environment but uses repeated computational subsampling.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Detects distractors/spurious edges by low reproducibility across resamples; informs subsequent filtering/downweighting.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Sampling-induced spurious correlations and low-signal noisy edges introduced by finite samples or unstable algorithms.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Directly detects spurious/unstable edges via low presence frequency across repeated subsampled runs.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Edges with low resampling frequency can be downweighted or removed (used in conjunction with ensemble aggregation and thresholding).</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Edges absent or with low robustness across resamples are treated as refuted/unsupported; comparisons to full-data runs and ground truth provide additional refutation evidence.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>Shows that robustness increases with sample size; ensemble restricted to top four algorithms becomes highly stable on full data; filtering based on resampling-informed weights increases predicted-edge robustness by ~6% on a tested subset.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td>Without resampling analysis, many low-confidence/spurious edges remain in ensemble outputs and ensemble stability suffers; quantitative baseline depends on algorithm/ensemble configuration.</td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Resampling-based robustness scoring is an effective empirical detector of unstable/spurious causal claims; it enables quantifying how sensitive predictions are to sampling and supports filtering decisions that increase ensemble stability.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Explaining and predicting human behavior and social dynamics in simulated virtual worlds: reproducibility, generalizability, and robustness of causal discovery methods', 'publication_date_yy_mm': '2021-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e743.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e743.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Markov blanket induction (IAMB / Aliferis)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Local causal and Markov blanket induction (IAMB and related algorithms)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Markov blanket induction algorithms (e.g., IAMB, algorithms by Aliferis et al.) identify a target node's local Markov blanket (parents, children, spouses) to perform causal feature selection and remove irrelevant features; referenced and used conceptually for causal feature selection in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Local causal and markov blanket induction for causal discovery and feature selection for classification part i: algorithms and empirical evaluation</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>IAMB / Markov blanket induction</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Constraint-based local structure learning algorithms that identify the Markov blanket of a target variable by iterative conditional independence tests (incremental association). The Markov blanket provides a theoretically minimal set of features necessary for optimal prediction of the target, removing extraneous correlated distractors.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Referenced for feature selection; not directly benchmarked as a primary distractor-robust technique in the GT ensemble experiments (IAMB was one of the algorithms executed in experiments).</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Originally designed for high-dimensional classification/causal discovery settings; in this paper it is referenced as relevant prior work and used as one of several algorithms that were run on simulated datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Explicitly identifies and returns the minimal Markov blanket (parents/children/spouses) of a target to exclude irrelevant features (distractors) from predictive models.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Irrelevant/spuriously correlated variables and high-dimensional irrelevant features that do not belong to the Markov blanket.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Iterative conditional independence testing to grow and shrink a candidate Markov blanket around the target variable.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Hard exclusion of variables not in the discovered Markov blanket.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Variables excluded by the Markov blanket test are treated as non-causal for that target (in the local sense).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>Paper notes IAMB executed successfully in multiple scenarios (Table 2) and is part of analyses; however, overall ensemble stability and robustness findings indicate IAMB alone is not universally robust across complex noisy/sampled scenarios—performance depends on data traits and assumptions.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Markov blanket methods are relevant for removing spurious predictors and are cited as foundational for causal feature selection; their effectiveness depends on accurate independence testing and data quality, and they were among algorithms whose outputs were aggregated by the ensemble.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Explaining and predicting human behavior and social dynamics in simulated virtual worlds: reproducibility, generalizability, and robustness of causal discovery methods', 'publication_date_yy_mm': '2021-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e743.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e743.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Missing-data-aware causal discovery (refs)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Causal discovery under missing data / MNAR approaches (Gain & Shpitser 2018; Tu et al. 2019; Strobl 2019)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A set of methods and recent works that aim to perform causal structure learning in the presence of missing data (including MNAR mechanisms) or heterogenous longitudinal data (mixture of DAGs), cited by the paper as approaches designed to address missingness-related biases that can otherwise produce spurious causal signals.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Structure learning under missing data / Causal discovery in the presence of missing data / Mixture-of-DAGs approaches</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Gain & Shpitser (2018): theoretical and algorithmic proposals for structure learning when data are missing (including approaches to account for MNAR). Tu et al. (2019): algorithms for causal discovery specifically designed to handle missing data patterns. Strobl (2019): improved causal discovery from longitudinal data using mixtures of DAGs to model heterogeneity/latent substructure across temporal segments. These are referenced as relevant methods to mitigate biases introduced by missingness and heterogeneity.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Mentioned as relevant methods for causal discovery under missingness in GT sampled-data scenarios</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Methods are applicable to observational datasets with missing-at-random and missing-not-at-random mechanisms, and to longitudinal / heterogeneous simulated data.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Missing-data-induced biases, selection bias due to missingness, and heterogeneity-induced spurious relations.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>The paper cites these works as potential solutions when missing-data mechanisms (including MNAR) could bias causal discovery; the authors warn that standard imputation assuming MAR can bias downstream causal discovery and that MNAR-aware methods are relevant for reducing spurious signals resulting from missingness.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Explaining and predicting human behavior and social dynamics in simulated virtual worlds: reproducibility, generalizability, and robustness of causal discovery methods', 'publication_date_yy_mm': '2021-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e743.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e743.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Individual algorithms (GES, MMPC, PC, GS, CCDr, LiNGAM)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Greedy Equivalence Search (GES); Max-Min Parents and Children (MMPC); Peter-Clark (PC); Grow-Shrink (GS); CCDr; LiNGAM (and others)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A collection of widely used causal discovery algorithms (score-based, constraint-based, and specialized linear/non-Gaussian methods) that were run individually and as constituents of the ensemble to produce candidate causal graphs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>GES / MMPC / PC / GS / CCDr / LiNGAM</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>GES: score-based greedy search over equivalence classes optimizing a score (e.g., BIC). MMPC: constraint-based parents/children discovery using max-min heuristics. PC: constraint-based algorithm using conditional independence tests to recover a CPDAG. GS: Grow-Shrink constraint-based local algorithm. CCDr: penalized likelihood approach using concave penalties with coordinate descent for high-dimensional structure learning. LiNGAM: structural equation model assuming non-Gaussianity to identify causal directions. The authors executed these algorithms on full and sampled datasets to compare execution success and as inputs to the ensemble.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>GT virtual worlds and synthetic pcalg/bnlearn datasets</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Applied to large, noisy, high-dimensional simulated datasets with mixed data types, missingness, sampling, and latent confounding; execution success varied by algorithm and scenario (Table 2 reports which algorithms ran without error per scenario).</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>General algorithms do not explicitly target distractor removal beyond their statistical assumptions; they are susceptible to sampling variability, latent confounding, and missing data-induced spurious edges.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>GES and MMPC were the most generalizable (finished and returned graphs across scenarios); only about half of algorithms worked per scenario. Individual algorithms vary in stability and susceptibility to sampling; ensemble selection of best-performing algorithms improved robustness.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Explaining and predicting human behavior and social dynamics in simulated virtual worlds: reproducibility, generalizability, and robustness of causal discovery methods', 'publication_date_yy_mm': '2021-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Structure learning under missing data <em>(Rating: 2)</em></li>
                <li>Causal discovery in the presence of missing data <em>(Rating: 2)</em></li>
                <li>Simulations evaluating resampling methods for causal discovery: ensemble performance and calibration <em>(Rating: 2)</em></li>
                <li>Local causal and markov blanket induction for causal discovery and feature selection for classification part i: algorithms and empirical evaluation <em>(Rating: 2)</em></li>
                <li>Toward causal representation learning <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-743",
    "paper_id": "paper-244423474",
    "extraction_schema_id": "extraction-schema-20",
    "extracted_data": [
        {
            "name_short": "Causal ensemble",
            "name_full": "Causal discovery ensemble pipeline (Volkova et al.)",
            "brief_description": "An ensemble pipeline that combines multiple state-of-the-art causal structure learning algorithms to produce a single ranked causal link prediction model; used with human-in-the-loop visual analytics and post-hoc filtering to improve robustness to sampling and noisy data.",
            "citation_title": "here",
            "mention_or_use": "use",
            "method_name": "Causal discovery ensemble",
            "method_description": "Combines outputs of multiple causal discovery algorithms (constraint- and score-based) to produce an aggregated causal graph. The pipeline aggregates candidate edges (with associated edge weights or confidence scores) produced by individual algorithms and then ranks/filters edges to produce a final graph. The authors experimented with ensembles built from all available algorithms and with restricted ensembles composed of the top-performing four algorithms (GES, PC, GS, IAMB / variants), showing that excluding the least-stable algorithms improves ensemble stability. The pipeline is paired with a human-in-the-loop visual analytics tool for inspection and manual analysis.",
            "environment_name": "GT virtual worlds (Urban, Power, Disaster, Conflict) and synthetic benchmarks (pcalg-generated DAGs, bnlearn datasets)",
            "environment_description": "Large simulated virtual worlds (four scenario-specific simulation outputs) and synthetic datasets: fully observed simulation outputs and sampled (research request) subsets; these are observational simulation datasets (not interactive experiments in this paper), and include sampled data with high sparsity and mixed data types. Additional experiments used synthetic DAGs (pcalg) and bnlearn benchmark networks.",
            "handles_distractors": true,
            "distractor_handling_technique": "Consensus/aggregation across multiple causal discovery algorithms to reduce algorithm-specific false positives, plus post-aggregation edge scoring and threshold/filtering to remove low-confidence (potentially spurious) edges.",
            "spurious_signal_types": "Irrelevant/spuriously correlated variables, sampling-induced spurious edges, noisy measurements, and instability from finite samples.",
            "detection_method": "Empirical resampling-based robustness analysis: repeat causal discovery on multiple subsamples and measure frequency of each edge/node; edges with low repeat frequency are treated as unstable/spurious. Comparison of sampled vs full data and comparison against known ground truth on synthetic graphs are also used to detect spurious signals.",
            "downweighting_method": "Edge confidence aggregation (averaging/combining algorithm outputs) and explicit edge weight thresholding (e.g., 0.65 threshold used in experiments) to remove or downweight low-confidence edges.",
            "refutation_method": "Resampling variability (low presence across repeated runs) used to refute edges; comparing inferred edges to ground-truth graphs for synthetic data; comparing sampled-data graphs to full-data graphs to determine absent signal versus methodological failures.",
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": "Top-four-algorithm ensemble (restricted ensemble) was highly stable on full data and more robust to sampling than the all-algorithm ensemble; applying edge filtering (threshold 0.65) increased robustness by ~6% on average. Node discovery F1 on full data ranged 0.3–0.8; sampled-data node F1 ranged 0.13–0.53. Edge discovery F1 was much lower (highest observed edge F1 = 0.30 for the Disaster scenario).",
            "performance_without_robustness": "All-algorithm ensemble (no selection/filtering) was less stable and more sensitive to sampling; exact comparative F1 values not provided per-ensemble but robustness analyses show notable improvements after restricting to top algorithms and filtering.",
            "has_ablation_study": true,
            "number_of_distractors": null,
            "key_findings": "Ensembling across algorithms can reduce some spurious signals but is vulnerable to the least-stable constituent algorithms; restricting an ensemble to the top-performing algorithms and applying edge-weight filtering improves robustness to sampling and reduces low-confidence/spurious edges. Larger sample sizes increase ensemble stability; ensembles still struggle when latent confounders or insufficient signal exist.",
            "uuid": "e743.0",
            "source_info": {
                "paper_title": "Explaining and predicting human behavior and social dynamics in simulated virtual worlds: reproducibility, generalizability, and robustness of causal discovery methods",
                "publication_date_yy_mm": "2021-11"
            }
        },
        {
            "name_short": "Edge filtering / thresholding",
            "name_full": "Edge weight thresholding (ensemble filtering)",
            "brief_description": "Post-processing technique that removes low-confidence edges from aggregated ensemble outputs by applying an edge-weight threshold (the authors used 0.65) to improve robustness to spurious edges.",
            "citation_title": "here",
            "mention_or_use": "use",
            "method_name": "Edge weight thresholding",
            "method_description": "After aggregating edge scores from multiple causal discovery algorithms, apply a cutoff threshold to edge confidence/weight; edges below the threshold are discarded from the final causal graph. The technique is used to trade off recall for higher precision and increased robustness across resampled datasets.",
            "environment_name": "GT virtual worlds and synthetic pcalg/bnlearn datasets",
            "environment_description": "Observational simulation outputs and synthetic DAG-generated datasets evaluated under repeated subsampling (8%, 16%, 32%, 64%) and full-data runs to measure stability.",
            "handles_distractors": true,
            "distractor_handling_technique": "Low-confidence edge removal via fixed thresholding on aggregated edge scores.",
            "spurious_signal_types": "Low-confidence/spurious edges caused by sampling noise, algorithmic variance, and weak statistical signals.",
            "detection_method": null,
            "downweighting_method": "Hard thresholding of aggregated edge weights (edges below threshold removed); implicitly downweights signals with low consensus across algorithms or low aggregated confidence.",
            "refutation_method": "Edges filtered out by threshold are treated as insufficiently supported and thus refuted in the final graph; empirical evaluation shows filtered graphs have higher robustness.",
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": "Applying an edge weight threshold (0.65) increased robustness of predicted edges by approximately 6% on average in the tests reported.",
            "performance_without_robustness": "Without thresholding, predicted edges included more low-confidence edges and ensemble robustness decreased; exact numerical baseline not reported other than relative improvement.",
            "has_ablation_study": true,
            "number_of_distractors": null,
            "key_findings": "Simple post-hoc edge filtering meaningfully increases the robustness of ensemble causal predictions across resamples; filtering prefers higher-precision, lower-recall graphs and can reduce spurious links introduced by algorithmic variance.",
            "uuid": "e743.1",
            "source_info": {
                "paper_title": "Explaining and predicting human behavior and social dynamics in simulated virtual worlds: reproducibility, generalizability, and robustness of causal discovery methods",
                "publication_date_yy_mm": "2021-11"
            }
        },
        {
            "name_short": "Causal feature selection (parents / ancestors)",
            "name_full": "Causal feature selection using inferred parents and ancestors (Volkova et al.)",
            "brief_description": "Feature selection strategy that uses a learned causal graph to restrict model inputs to the causal ancestry (or direct parents) of a target variable, thereby removing spuriously correlated features and reducing dimensionality for predictive tasks.",
            "citation_title": "here",
            "mention_or_use": "use",
            "method_name": "Causal feature selection (ancestry / parent selection)",
            "method_description": "Given a causal graph (learned or ground truth), select as predictive features either (a) all nodes in the causal ancestry of the target, or (b) only direct parents of the target (Markov blanket style). Train standard ML models using only these causal features to reduce influence of spurious correlates. The authors used this approach both when the true graph was available (synthetic experiments) and when graphs were inferred from data.",
            "environment_name": "Synthetic pcalg DAG experiments and GT virtual worlds predictive experiments",
            "environment_description": "Non-interventional simulated datasets (synthetic linear-Gaussian DAG data and sampled virtual-world observational data), used for training ML predictors for node values and agent decisions.",
            "handles_distractors": true,
            "distractor_handling_technique": "Explicit exclusion of non-ancestral/non-parent features (feature pruning) using causal graph structure (parents or ancestors), equivalent to Markov-blanket style selection for direct parents.",
            "spurious_signal_types": "Irrelevant/spuriously correlated input features and high-dimensional irrelevant variables that do not lie on causal paths to the target.",
            "detection_method": "Relies on structure learned by causal discovery algorithms (or ground truth) to identify causal parents/ancestors; does not itself run additional detectors.",
            "downweighting_method": "Hard exclusion of non-causal features rather than continuous downweighting; selected causal features are used exclusively for prediction.",
            "refutation_method": "Performance comparison (ablation) between using all features vs ancestry vs parents: improved predictive performance on many tasks supports that excluded features were spurious.",
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": "In synthetic experiments with ground-truth graphs, using direct parents improved predictive F1 for binary outputs (example: binary→binary DNN: All nodes F1=0.702 vs Indirect F1=0.750*** vs Direct F1=0.763**), and reduced RMSE for many continuous tasks (statistically significant improvements reported). For GT virtual worlds, causal feature selection improved end-to-end predictive performance in 2 of 4 scenarios (Disaster and Power).",
            "performance_without_robustness": "Using all available variables as inputs often matched or outperformed causal selection on mixed-type datasets; in practice, using inferred (noisy) graphs can reduce or eliminate the benefit if causal discovery errors are present.",
            "has_ablation_study": true,
            "number_of_distractors": null,
            "key_findings": "When the causal graph is correct (ground truth), restricting predictors to direct parents or ancestors reliably reduces spurious correlations and improves predictive performance—especially for binary outputs. However, when the graph is inferred with uncertainty, errors in causal structure can negate benefits; thus causal feature selection requires sufficiently accurate causal discovery to be effective.",
            "uuid": "e743.2",
            "source_info": {
                "paper_title": "Explaining and predicting human behavior and social dynamics in simulated virtual worlds: reproducibility, generalizability, and robustness of causal discovery methods",
                "publication_date_yy_mm": "2021-11"
            }
        },
        {
            "name_short": "Resampling robustness",
            "name_full": "Resampling-based edge/node robustness measurement",
            "brief_description": "A detection and evaluation protocol that repeats causal discovery across multiple subsamples and quantifies the frequency with which each node/edge appears as a robustness/confidence score to identify unstable (potentially spurious) relationships.",
            "citation_title": "here",
            "mention_or_use": "use",
            "method_name": "Resampling robustness metric",
            "method_description": "Repeat causal discovery N times on different subsamples (the authors used sample fractions 8%, 16%, 32%, 64%) and compute for each directed/undirected edge and node the proportion of runs in which it appears; use these proportions as robustness/confidence scores. Low-frequency edges are considered unstable/spurious. This metric is used to compare algorithms and ensembles, and to guide filtering.",
            "environment_name": "Synthetic pcalg DAG experiments and GT virtual worlds (sampled/full)",
            "environment_description": "Observational datasets evaluated under repeated random subsampling and repeated causal discovery runs; not an interactive experimental environment but uses repeated computational subsampling.",
            "handles_distractors": true,
            "distractor_handling_technique": "Detects distractors/spurious edges by low reproducibility across resamples; informs subsequent filtering/downweighting.",
            "spurious_signal_types": "Sampling-induced spurious correlations and low-signal noisy edges introduced by finite samples or unstable algorithms.",
            "detection_method": "Directly detects spurious/unstable edges via low presence frequency across repeated subsampled runs.",
            "downweighting_method": "Edges with low resampling frequency can be downweighted or removed (used in conjunction with ensemble aggregation and thresholding).",
            "refutation_method": "Edges absent or with low robustness across resamples are treated as refuted/unsupported; comparisons to full-data runs and ground truth provide additional refutation evidence.",
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": "Shows that robustness increases with sample size; ensemble restricted to top four algorithms becomes highly stable on full data; filtering based on resampling-informed weights increases predicted-edge robustness by ~6% on a tested subset.",
            "performance_without_robustness": "Without resampling analysis, many low-confidence/spurious edges remain in ensemble outputs and ensemble stability suffers; quantitative baseline depends on algorithm/ensemble configuration.",
            "has_ablation_study": true,
            "number_of_distractors": null,
            "key_findings": "Resampling-based robustness scoring is an effective empirical detector of unstable/spurious causal claims; it enables quantifying how sensitive predictions are to sampling and supports filtering decisions that increase ensemble stability.",
            "uuid": "e743.3",
            "source_info": {
                "paper_title": "Explaining and predicting human behavior and social dynamics in simulated virtual worlds: reproducibility, generalizability, and robustness of causal discovery methods",
                "publication_date_yy_mm": "2021-11"
            }
        },
        {
            "name_short": "Markov blanket induction (IAMB / Aliferis)",
            "name_full": "Local causal and Markov blanket induction (IAMB and related algorithms)",
            "brief_description": "Markov blanket induction algorithms (e.g., IAMB, algorithms by Aliferis et al.) identify a target node's local Markov blanket (parents, children, spouses) to perform causal feature selection and remove irrelevant features; referenced and used conceptually for causal feature selection in the paper.",
            "citation_title": "Local causal and markov blanket induction for causal discovery and feature selection for classification part i: algorithms and empirical evaluation",
            "mention_or_use": "mention",
            "method_name": "IAMB / Markov blanket induction",
            "method_description": "Constraint-based local structure learning algorithms that identify the Markov blanket of a target variable by iterative conditional independence tests (incremental association). The Markov blanket provides a theoretically minimal set of features necessary for optimal prediction of the target, removing extraneous correlated distractors.",
            "environment_name": "Referenced for feature selection; not directly benchmarked as a primary distractor-robust technique in the GT ensemble experiments (IAMB was one of the algorithms executed in experiments).",
            "environment_description": "Originally designed for high-dimensional classification/causal discovery settings; in this paper it is referenced as relevant prior work and used as one of several algorithms that were run on simulated datasets.",
            "handles_distractors": true,
            "distractor_handling_technique": "Explicitly identifies and returns the minimal Markov blanket (parents/children/spouses) of a target to exclude irrelevant features (distractors) from predictive models.",
            "spurious_signal_types": "Irrelevant/spuriously correlated variables and high-dimensional irrelevant features that do not belong to the Markov blanket.",
            "detection_method": "Iterative conditional independence testing to grow and shrink a candidate Markov blanket around the target variable.",
            "downweighting_method": "Hard exclusion of variables not in the discovered Markov blanket.",
            "refutation_method": "Variables excluded by the Markov blanket test are treated as non-causal for that target (in the local sense).",
            "uses_active_learning": null,
            "inquiry_strategy": null,
            "performance_with_robustness": "Paper notes IAMB executed successfully in multiple scenarios (Table 2) and is part of analyses; however, overall ensemble stability and robustness findings indicate IAMB alone is not universally robust across complex noisy/sampled scenarios—performance depends on data traits and assumptions.",
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "Markov blanket methods are relevant for removing spurious predictors and are cited as foundational for causal feature selection; their effectiveness depends on accurate independence testing and data quality, and they were among algorithms whose outputs were aggregated by the ensemble.",
            "uuid": "e743.4",
            "source_info": {
                "paper_title": "Explaining and predicting human behavior and social dynamics in simulated virtual worlds: reproducibility, generalizability, and robustness of causal discovery methods",
                "publication_date_yy_mm": "2021-11"
            }
        },
        {
            "name_short": "Missing-data-aware causal discovery (refs)",
            "name_full": "Causal discovery under missing data / MNAR approaches (Gain & Shpitser 2018; Tu et al. 2019; Strobl 2019)",
            "brief_description": "A set of methods and recent works that aim to perform causal structure learning in the presence of missing data (including MNAR mechanisms) or heterogenous longitudinal data (mixture of DAGs), cited by the paper as approaches designed to address missingness-related biases that can otherwise produce spurious causal signals.",
            "citation_title": "",
            "mention_or_use": "mention",
            "method_name": "Structure learning under missing data / Causal discovery in the presence of missing data / Mixture-of-DAGs approaches",
            "method_description": "Gain & Shpitser (2018): theoretical and algorithmic proposals for structure learning when data are missing (including approaches to account for MNAR). Tu et al. (2019): algorithms for causal discovery specifically designed to handle missing data patterns. Strobl (2019): improved causal discovery from longitudinal data using mixtures of DAGs to model heterogeneity/latent substructure across temporal segments. These are referenced as relevant methods to mitigate biases introduced by missingness and heterogeneity.",
            "environment_name": "Mentioned as relevant methods for causal discovery under missingness in GT sampled-data scenarios",
            "environment_description": "Methods are applicable to observational datasets with missing-at-random and missing-not-at-random mechanisms, and to longitudinal / heterogeneous simulated data.",
            "handles_distractors": null,
            "distractor_handling_technique": null,
            "spurious_signal_types": "Missing-data-induced biases, selection bias due to missingness, and heterogeneity-induced spurious relations.",
            "detection_method": null,
            "downweighting_method": null,
            "refutation_method": null,
            "uses_active_learning": null,
            "inquiry_strategy": null,
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "The paper cites these works as potential solutions when missing-data mechanisms (including MNAR) could bias causal discovery; the authors warn that standard imputation assuming MAR can bias downstream causal discovery and that MNAR-aware methods are relevant for reducing spurious signals resulting from missingness.",
            "uuid": "e743.5",
            "source_info": {
                "paper_title": "Explaining and predicting human behavior and social dynamics in simulated virtual worlds: reproducibility, generalizability, and robustness of causal discovery methods",
                "publication_date_yy_mm": "2021-11"
            }
        },
        {
            "name_short": "Individual algorithms (GES, MMPC, PC, GS, CCDr, LiNGAM)",
            "name_full": "Greedy Equivalence Search (GES); Max-Min Parents and Children (MMPC); Peter-Clark (PC); Grow-Shrink (GS); CCDr; LiNGAM (and others)",
            "brief_description": "A collection of widely used causal discovery algorithms (score-based, constraint-based, and specialized linear/non-Gaussian methods) that were run individually and as constituents of the ensemble to produce candidate causal graphs.",
            "citation_title": "",
            "mention_or_use": "use",
            "method_name": "GES / MMPC / PC / GS / CCDr / LiNGAM",
            "method_description": "GES: score-based greedy search over equivalence classes optimizing a score (e.g., BIC). MMPC: constraint-based parents/children discovery using max-min heuristics. PC: constraint-based algorithm using conditional independence tests to recover a CPDAG. GS: Grow-Shrink constraint-based local algorithm. CCDr: penalized likelihood approach using concave penalties with coordinate descent for high-dimensional structure learning. LiNGAM: structural equation model assuming non-Gaussianity to identify causal directions. The authors executed these algorithms on full and sampled datasets to compare execution success and as inputs to the ensemble.",
            "environment_name": "GT virtual worlds and synthetic pcalg/bnlearn datasets",
            "environment_description": "Applied to large, noisy, high-dimensional simulated datasets with mixed data types, missingness, sampling, and latent confounding; execution success varied by algorithm and scenario (Table 2 reports which algorithms ran without error per scenario).",
            "handles_distractors": false,
            "distractor_handling_technique": null,
            "spurious_signal_types": "General algorithms do not explicitly target distractor removal beyond their statistical assumptions; they are susceptible to sampling variability, latent confounding, and missing data-induced spurious edges.",
            "detection_method": null,
            "downweighting_method": null,
            "refutation_method": null,
            "uses_active_learning": null,
            "inquiry_strategy": null,
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "GES and MMPC were the most generalizable (finished and returned graphs across scenarios); only about half of algorithms worked per scenario. Individual algorithms vary in stability and susceptibility to sampling; ensemble selection of best-performing algorithms improved robustness.",
            "uuid": "e743.6",
            "source_info": {
                "paper_title": "Explaining and predicting human behavior and social dynamics in simulated virtual worlds: reproducibility, generalizability, and robustness of causal discovery methods",
                "publication_date_yy_mm": "2021-11"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Structure learning under missing data",
            "rating": 2,
            "sanitized_title": "structure_learning_under_missing_data"
        },
        {
            "paper_title": "Causal discovery in the presence of missing data",
            "rating": 2,
            "sanitized_title": "causal_discovery_in_the_presence_of_missing_data"
        },
        {
            "paper_title": "Simulations evaluating resampling methods for causal discovery: ensemble performance and calibration",
            "rating": 2,
            "sanitized_title": "simulations_evaluating_resampling_methods_for_causal_discovery_ensemble_performance_and_calibration"
        },
        {
            "paper_title": "Local causal and markov blanket induction for causal discovery and feature selection for classification part i: algorithms and empirical evaluation",
            "rating": 2,
            "sanitized_title": "local_causal_and_markov_blanket_induction_for_causal_discovery_and_feature_selection_for_classification_part_i_algorithms_and_empirical_evaluation"
        },
        {
            "paper_title": "Toward causal representation learning",
            "rating": 1,
            "sanitized_title": "toward_causal_representation_learning"
        }
    ],
    "cost": 0.0186,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>2023</p>
<p>(1234567890) Computational and Mathematical Organization Theory
29202310.1007/s10588-021-09351-yAccepted: 23 October 2021 / Published online: 18 November 20211 3 S.I. : GROUND TRUTH: IN SILICO SOCIAL SCIENCE (GTIS3)Causal discovery · Causal structure learning · Ensemble models · Reproducibility · Generalizability · Robustness · Predictive modeling · Machine learning · Data science
Explaining and predicting human behavior and social dynamics in simulated virtual worlds: reproducibility, generalizability, and robustness of causal discovery methodsSvitlana Volkova, et al. [full author details at the end of the article]AbstractGround Truth program was designed to evaluate social science modeling approaches using simulation test beds with ground truth intentionally and systematically embedded to understand and model complex Human Domain systems and their dynamics Lazer et al. (Science 369:1060(Science 369: -1062(Science 369: , 2020. Our multidisciplinary team of data scientists, statisticians, experts in Artificial Intelligence (AI) and visual analytics had a unique role on the program to investigate accuracy, reproducibility, generalizability, and robustness of the state-of-the-art (SOTA) causal structure learning approaches applied to fully observed and sampled simulated data across virtual worlds. In addition, we analyzed the feasibility of using machine learning models to predict future social behavior with and without causal knowledge explicitly embedded. In this paper, we first present our causal modeling approach to discover the causal structure of four virtual worlds produced by the simulation teams-Urban Life, Financial Governance, Disaster and Geopolitical Conflict. Our approach adapts the stateof-the-art causal discovery (including ensemble models), machine learning, data analytics, and visualization techniques to allow a human-machine team to reverseengineer the true causal relations from sampled and fully observed data. We next present our reproducibility analysis of two research methods team's performance using a range of causal discovery models applied to both sampled and fully observed data, and analyze their effectiveness and limitations. We further investigate the generalizability and robustness to sampling of the SOTA causal discovery approaches on additional simulated datasets with known ground truth. Our results reveal the limitations of existing causal modeling approaches when applied to large-scale, noisy, high-dimensional data with unobserved variables and unknown relationships between them. We show that the SOTA causal models explored in our experiments are not designed to take advantage from vasts amounts of data and have difficulty recovering ground truth when latent confounders are present; they do not generalize well across simulation scenarios and are not robust to sampling; they are vulnerable to data and modeling assumptions, and therefore, the results are hard to reproduce. Finally, when we outline lessons learned and provide recommendations to improve models for causal discovery and prediction of human social behavior from 221 1 3Explaining and predicting human behavior and social dynamics… observational data, we highlight the importance of learning data to knowledge representations or transformations to improve causal discovery and describe the benefit of causal feature selection for predictive and prescriptive modeling.</p>
<p>Introduction</p>
<p>The ability to learn causal relationships from observational data is considered a significant component of human-level intelligence and can serve as one of the foundations of artificial intelligence (AI) (Bengio 2019;Chollet 2020;Pearl 2019;Lake et al. 2017). Understanding how latent properties of the data, including various sources of bias effect causal discovery accuracy, generalizability (Yarkoni 2019), reproducibility (Munafò et al. 2017), and robustness (Kummerfeld and Rix 2019;Olteanu et al. 2019) is essential to make progress and improve the existing approaches for causal discovery across many domains such as earth sciences, biology, economy (Runge et al. 2019;Glymour et al. 2019;Athey 2015), and social sciences (Lazer et al. 2020;Watts et al. 2018;Hofman et al. 2017).</p>
<p>Many different algorithms for causal discovery (aka causal structure learning) have been developed over the last twenty years (Guo et al. 2020;Pearl 2009). Existing approaches broadly fall into two categories: constraint-based (Spirtes et al. 2000;Yu et al. 2016 andscore-based Chickering 2002).</p>
<p>-Constraint-based methods subject causal relationships to a set of constraints, for example conditional dependencies among the variables. -Score-based methods discover causal relationships by optimizing a scoring function.</p>
<p>While each causal structure learning algorithm often relies on assumptions about the data generation process and underlying causal structure Greenland and Mansournia 2015 as shown in Table 1, it cannot be known from the data alone whether these assumptions are satisfied. Some causal discovery methods may tend to perform better on data from specific domains with different complexity and data generated from certain types of causal graph structures (e.g., sparser graphs) but such properties are obviously unknown a priori. Therefore, given a large number of possible causal modeling approaches, it is not clear which one to use in any given situation and whether a single approach will generalize across datasets and tasks with different complexities (Yarkoni 2019), which is especially important for the Human Domain Lazer et al. (2020). It is also important to investigate the relationship between causal model accuracy and robustness to sampling, and study the reproducibility of the SOTA causal modeling techniques (Stodden et al. 2016).</p>
<p>3</p>
<p>Our contributions to the Ground Truth program are presented below. We first outline our causal discovery workflow and discuss scenario-specific representation learning (node discovery) and modeling (link discovery) experimental decisions in Sect. 2. Then, acting as a reasonable upper bound, in addition to being a reproducibility control to other research methods teams' approaches, we recover the ground truth signal from the full simulation output to determine whether it was not possible to uncover the ground truth due to methodological failures or due to the absence of usable ground truth signal in the sampled simulation output and describe our findings in Sects. 2.3 and 2.4. Next we investigate robustness and generalizability of individual causal discovery algorithms and our causal ensemble approach on a range of simulated datasets (Saldanha et al. 2020) in additional to four virtual worlds produced by the simulation teams in Sect. 3. We further present and evaluate our predictive approach that takes advantage of machine learning and deep learning models to anticipate human behavior and social dynamics in the Human Domain using sampled data collected by research methods teams from four virtual worlds and additional simulated datasets produced by our team in Sect. 4. Finally, we conclude by summarizing our key results on reproducibility, generalizability, and robustness analysis of causal discovery approaches and data-driven research methods to explain, and predict human behavior and social dynamics in the Human Domain.</p>
<p>Causal discovery in the human domain: selected methods and limitations</p>
<p>This section presents our approach to causal structure learning of causal structure learning from fully observable and sampled data across four simulation scenarios provided under the GT program (Urban, Power, Disaster, and Conflict), that served as proxies for the real world. Our main objective for the causal structure learning (aka the explain task) was to analyze the existing causal discovery 
Score CAM × × CCDr × × × × GES × × × • • LiNGAM × × × × Constr. GS × × × • • MMPC × × × • • PC × × × • • IAMB × × × • • 1 3
Explaining and predicting human behavior and social dynamics… approaches' limitations when applied to large-scale, noisy, high-dimensional data with unobserved variables (aka unknown unknowns), mixed data types, and unknown statistical dependencies between them that describe complex social dynamics. More specifically, we focused on answering research questions below.</p>
<p>RQ1: Is it possible to design generalizable workflows for causal discovery of complex social behavior and social dynamics (generalizability analysis)? RQ2: Are other research method teams' reproducible using state-of-the-art causal discovery approaches when applied to the same sampled data (reproducibility analysis)? RQ3: In case it is impossible to uncover the ground truth using sampled data, is it because of research method failures or simply the absence of usable ground truth signal in the sampled simulation output (robustness analysis)?</p>
<p>Figure 1 presents our causal discovery workflow with the human-in-the-loop evaluation (Cottam et al. 2021), taking specific steps for individual scenarios. For example, it shows that for the Urban scenario with the sampled data A we performed representation learning, dense block identification, and SOTA data imputation steps before applying our causal ensemble approach to the data. Note, SOTA imputation algorithms assume a Missing At Random mechanism which may bias downstream causal discovery. Thus, approaches like (Strobl 2019;Tu Fig. 1 Causal discovery workflow for four simulated virtual worlds (as defined in details in other chapters) when we rely on sampled data collected by two research methods teams (A and B). Alternative (Alt) experiments were performed on sampled data after we performed causal discovery on the full dataset to measure the effect of additional variables and modeling assumptions on causal discovery performance (RQ1) et al. 2019; Gain and Shpitser 2018) are designed for causal discovery in the presence of missing not at random mechanisms.</p>
<p>Causal node discovery</p>
<p>As shown in the workflow diagram, causal node discovery steps focused on learning variable representations at multiple levels of granularity by performing data fusion, construct building (aka feature extraction), aggregation, data imputation, and normalization steps. For that we used a range of data science and statistical approaches including but not limited to regression, correlation analysis, statistical tests, social network analysis, data visualization, and machine learning.</p>
<p>The most time consuming step during causal node discovery was to understand the complexity of each scenario. Processing sampled (aka research request data A and B) was scenario-specific. Each scenario required learning customized data representations and perform scenario-specific data manipulations as reflected in the workflow diagram in Fig. 1.</p>
<p>In all scenarios we worked with missing and extremely sparse sampled data with limited temporal overlap across variables, for example data sparsity for samples A and B in the Urban scenario was 60% and 77%, and in the Power scenario 79% and 63%, respectively. Data sparsity and the granularity of variable representations could constrain causal discovery results.</p>
<p>However, our additional analysis of causal discovery performance and data sparsity demonstrated that the final results are not only constrained by sparsity. We observed no correlation between data sparsity and node discovery F1 score, but we found that lower density leads to higher edge F1 score. Thus, it is important to note that causal discovery performance also depends on scenario complexity, data size, and data quality-the presence of the signal in the data and feature representations (e.g., constructs), observed versus unobserved variables constructed by subject matter experts.</p>
<p>Causal link discovery</p>
<p>For causal link discovery, we developed an ensemble approach that combines several commonly used causal discovery approaches in order to produce one optimal causal link prediction model as presented in Fig. 2. The output of our causal ensemble pipeline is a causal model that formally consists of two sets of variables U (exogenous variables that are external to the model) and V (endogenous variables that are descendants of exogenous variables), and a set of functions f that assign each variable in V a value based on the values of the other variables in the model. To expand this definition: a variable X is a direct cause of a variable Y if X appears in the function that assigns Y value.</p>
<p>As expected, there was no universal causal discovery model that generalized across all scenarios, but some algorithms worked consistently (the algorithm finished running and returned a causal graph)-Greedy Equivalence Search (GES) and Max-Min Parents and Children (MMPC)-with full or sampled data A and B as demonstrated in Table 2. We evaluated causal discovery ensemble performance using an in-house-developed the human-in-the-loop visual analytics tool (Cottam et al. 2021).</p>
<p>We observed that early assumptions (e.g., in the data fusion or representation learning steps) hurt the resulting causal discovery performance. Moreover, testing algorithm-specific data and modeling assumptions outlined in Table 1 was nontrivial and, sometimes, impossible. Figure 3 presents reproducibility analysis of causal discovery results with data samples A and B using our causal ensemble approach applied to the same research request data (aka data samples A and B). We observe that even when using the same sample data as other performers, changes in modeling assumptions and data manipulations created big discrepancies across inferred causal graphs. Our causal pipeline with the state-of-the-art causal discovery approaches was able to demonstrate improvement over TA2 results only in the Urban scenario in terms of node discovery F1 score, and in the Disaster and Power scenarios in terms of edge discovery F1 score. We can also see that it was more difficult to outperform causal discovery approaches applied to sampled data B than sampled data A.</p>
<p>Reproducibility of causal discovery</p>
<p>It is important to note that our ability to discover nodes from sampled data was limited because our team did not collect sampled data compared to other teams, which in turn bounded downstream causal link discovery. Finally, our team made different data and modeling assumptions compared to other teams, for example our causal structure learning approach did not use any social theory and was datadriven which could explain our inability to fully reproduce other teams' causal discovery results across all simulated scenarios. Our modeling assumptions about how agents make decisions, interact with each other and with the environment, and the interaction between the environmental factors drove or constrained the final causal discovery performance.</p>
<p>Fig. 2</p>
<p>Our ensemble approach to discover the causal structure of simulated human behavior and social dynamics from observational data (RQ1) 1 3</p>
<p>Causal discovery with sampled versus full data</p>
<p>Figure 4 presents causal discovery performance using our ensemble approach applied across four simulation scenarios with full versus sampled data. As expected, node discovery performance for the full data was much higher compared to sampled data (aka research request data sampled by teams A and B). Depending on the scenario, node discovery F1 score ranged between 0.13 and 0.53 for the sampled data and between 0.3 and 0.8 for the full data. Edge discovery F1 was significantly lower. The highest F1 of 0.3 was obtained for the Disaster scenario on both sampled and full data. Reproducibility analysis presented as differences in causal node and link discovery performance (measured as F1 score) between our causal ensemble approach and other causal discovery approaches using data samples A and B (RQ2) Table 2 An overview of which causal discovery algorithms executed without errors and returned the causal graph when they were directly applied to sampled data (A and B collected by other performers) and full simulated data across four simulated worlds (RQ3)</p>
<p>Urban</p>
<p>Power
Disaster Conflict Algorithm A B Full A B Full A B Full A B Full PC + - + + - + + + + + + + MMPC + + + + + + + + + + + + GS - + + + - - + + - + + + IAMB - + + + - - - - - - - - GES + + + + + + + + + + + + GEIS + - - - + - - - - + + + LiNGAM - - - - - + - - + - - - CCDr + + - + - + - + + + + + 1 3
Explaining and predicting human behavior and social dynamics…</p>
<p>Our full versus sampled data results further demonstrate that causal discovery is not about having lots of data like e.g., deep learning, it is about having the signal in the data, learning the right representations and encoding the complexity of the scenario. As we can see from Fig. 4, Urban scenario has 2TB of data, but causal discovery performance is much higher for the Disaster scenario with 300Mb of data.</p>
<p>Knowledge representations are important for both node and edge discovery with full or sampled data as shown in Fig. 4. Extracting knowledge from data through transformations (e.g., aggregation, construct building, fusion, imputation, and normalization) effects the final node discovery performance, which in turn effects edge discovery results. We found that the full data performance exceeds sampled data performance only for the Disaster scenario and it is equal for other scenarios. This could be explained by strategic and targeted sampling by subject matter experts from teams A and B during research request data collection.</p>
<p>Finally, our results demonstrate that SOTA causal discovery approaches are vulnerable to data and modeling assumptions. We found that only half of the algorithms worked per scenario as shown in Table 2. GES and MMPC were the most generalizable across four simulation scenarios, then Peter-Clark (PC), Concave penalized Coordinate Descent with reparameterization (CCDr), and Grow-Shrink (GS) approaches. 1 Fig. 4 Causal discovery results (measured as F1 score) across four simulated worlds using our causal ensemble approach on sampled (Redo TA2A and Redo TA2B) and fully observed data (RQ3)</p>
<p>Robustness evaluation of causal discovery</p>
<p>In this section we perform additional analysis of causal discovery algorithm robustness-specifically robustness to sampling-which is extremely important in the real-world setting when it is not possible to observe the full data. We aim to answer two research questions below and present an extended analysis in Saldanha et al. (2020).</p>
<p>RQ5: How sensitive are the individual causal discovery algorithms and the ensemble approach to sampling in terms of variability of predictions? RQ6: Does robustness depend on properties of the underlying causal graph or the observational data?</p>
<p>Pcalg causal graphs</p>
<p>For our additional experiments, we generated 1140 random directed acyclic graphs (DAGs) with different properties using the randDAG function of the R pcalg library. 2 We used DAGs of size 20, 40, and 60 nodes, with 1 through 5 expected edges per node, and 8 different generation methods designed to target different graph topological properties. These generation methods were regular-a graph where every node has exactly d incident edges, er-an Erdos-Renyi graph where every edge is present independently, watts-an interpolation between regular graph and Erdoes-Renyi graph, power-a graph with power-law degree distribution, bipartite-a bipartite graph, barabasi -a graph with power-law degree distribution and preferential attachment, geometric-a geometric random graph, and interEr-a graph with two islands of Erdoes-Renyi graphs connected by a small number of edges. For each combination of DAG properties, we randomly generated 10 graphs. We used each generated DAG to simulate data that follows the given causal structure using linear Gaussian models with the edge weight and noise parameters drawn from uniform distributions. Example graphs can be seen in Fig. 5.</p>
<p>Bnlearn causal graphs</p>
<p>In addition to pcalg data, we leverage eight public datasets provided by the Bayesian Network Repository 3 to perform generalization tests of our results on datasets outside the Human Domain that have varied complexity, more data types, and different relationships between variable. The properties of the data are described in Table 3. </p>
<p>Robustness analysis</p>
<p>To measure robustness of the causal discovery approach, we repeated the causal discovery 10 times and calculated the average proportion of these repetitions that each node or edge is present. For example, if A → B appears in 8 out of 10 graphs, A → C appears in 6 out of 10, and B → D appears in 4 out of 10, the directed edge robustness of the graph would be 0.6. We evaluated the robustness of both directed edges, counting A → B different than B → A , and undirected edges, where we evaluated robustness of the pairs of variables that are causally  related in either direction. We also evaluated node robustness because when certain edges fail to be discovered it can cause nodes to drop out. We measure this robustness starting from a very small sample size of 8% of the data and double the sample size to 16%, 32%, and 64% to evaluate the sensitivity of the algorithm to the sampling proportion. Figure 6 (left) shows the robustness of directed edges for each algorithm and ensemble methods without edge weight thresholding as a function of the size of the data.</p>
<p>We find that the all-algorithm ensemble approach is less stable than each of the individual algorithms at each sample size. Ensembles with the top four performing algorithms have better robustness, but are still hindered by the least stable algorithms. This indicates that the algorithms are sensitive to data variability unless a very large fraction of the data is included.</p>
<p>In Fig. 6 (right) we examine the robustness of all graph components (nodes, undirected edges, and directed edges) of the top four ensemble method without edge weight thresholding as a function of sample size. As we increase with sample size, the robustness of ensemble algorithms also increases. With access to the full data sample (dashed lines), we find the four-algorithm ensemble to be highly stable across multiple runs.</p>
<p>In addition to studying the robustness across the full population of test datasets, we also explore whether the robustness varies based on how the graph structure was generated. In Fig. 7, we examine the directed edge stability for the 32% sample in comparison to several graph properties from all 10 runs of the pcalg data. For data generated from graphs with many nodes (e.g., 80 nodes), the robustness is lower on average than for smaller graphs with fewer nodes (e.g., 20 nodes). A similar trend exists when we examine the expected number of edges per node. We see increasingly more instability as the number of edges per node rises. Finally, we compare the directed edge robustness of data generated from each pcalg graph generation method. The most stable are regular graphs and the least stable are power graphs. These results are presented for the ensemble method with edge filtering, which may include some low-confidence edges. To study whether filtering to high-confidence edges impacts the robustness of the predictions, we compare the robustness with and without edge filtering for a subset of the 40-nodes graphs in Fig. 8. We find that filtering the edges increases the robustness of the predictions by about 6% on average.</p>
<p>Robustness and graph properties</p>
<p>We compare the performance of the four-algorithm ensemble across graphs with different structural properties. In Fig. 9, we show how robustness varies with the density and diameter of the ground truth causal graph. Because the causal graph may not be fully connected, we consider the largest diameter among the graph components rather than the diameter of the full graph. We find that robustness decreases for denser graphs, while increasing for causal graphs with larger diameters. Fig. 9 Robustness of the four-algorithm ensemble as a function of two graph structure properties-the graph density (top) and the graph diameter (bottom). Each pink point is an individual pcalg graph, while other colors are the bnlearn graphs. The line of best fit is plotted in black When we compare the bnlearn results to the pcalg results in these plots, we see that the F1 scores for the bnlearn data are typically somewhat lower than average given their graph properties while their robustness values are significantly higher than those observed for the pcalg graphs. This indicates that the data generation process of the bnlearn data is overall more challenging for the causal discovery algorithms, but that interestingly the predictions of the ensemble are more consistent across samples.</p>
<p>Predictive modeling of human behavior and social dynamics</p>
<p>We implemented an agent-based approach outlined in Fig. 10 to answer predict questions for four simulated scenarios, for example "How many people will evacuate at least once during the new hurricane?" Agents are modeled as having an internal state that consists of relationships, beliefs, and attributes. Agents can observe the population (e.g., the current total number of casualties) and the state of nature (e.g., current hurricane severity). Agents can remember their past, such as how many times an agent experienced a severe hurricane.</p>
<p>We experimented with SOTA machine learning models-Random Forest (RF), k-Nearest Neighbors (KNN), Logistic Regression (LR), Deep Neural Network (DNN)-to model decisions that agents make during individual time steps. We use data-driven models to fit a function from observational data, for example sampled data collected by research methods teams, that predicts what action an agent will take and how an agent will change as a result of their observation's current state (Zhang et al. 2016). Thus, our mechanistic simulation "stepper" then considers the agents collectively to determine outcomes and updates the agent states appropriately.</p>
<p>We apply our causal ensemble approach as described in the previous section to determine the causal relationships between agent observations, beliefs, attributes and actions. This produces a causal graph we use to perform feature selection in the 1 3 predictive model. When there is a chain between inputs and actions, all ancestors in that chain are included as features to train the machine learning model. The advantage is that this reduces the dimensionality of the problem and removes inputs that are spuriously correlated with the agent's decision. As a baseline, we simply do not perform feature selection and train ML model using all features.</p>
<p>Different scenarios produced vastly different training data for the agent decision models, with the smallest training data coming from the Disaster scenario and the largest coming from the Conflict scenario. Though we attempted to use a standard set of machine learning models, not all models were practical or effective across all scenarios. We found that LR was typically not fast enough to apply to most scenarios. In some scenarios RF was also too time consuming to apply. Most models we trained had similar single-step accuracy, they could predict what an agent will do next. Interestingly KNN models tended to exhibit better end-to-end accuracy on our held-out validation set. Generally, causal discovery did not produce better endto-end results on the held-out validation set. Across all four scenarios, the benefit of causal feature selection was only shown for the Disaster and Power scenarios. Using TA2A versus TA2B sampled (research request) data led to equal predictive performance. For the Power scenario DNN demonstrated the highest performance followed by KNN and RF models; however, for the Disaster scenario KNN outperformed DNN and RF models. The performance was comparable when we experimented with different modeling decision for the Disaster scenario, for example model at the agent versus population-level, deterministic versus stochastic modeling, agent making multiple or one-choice decisions, etc.</p>
<p>To summarize our findings, our predict performance was influenced by how compatible our ML-based simulation architecture matched the original simulation approach. It is important to note that predict questions were of different complexity (Mitchell and Newman 2002;Ladyman et al. 2013) across and within simulation scenarios, which explains varied performance and the fact that no universal predictive model could be applied across four simulation scenarios. Predict answers with sampled data A versus B were comparable. Running predict analysis on full data would have helped our understanding of the effect of sampling on predict performance. Thus, additional experiments needed to fully explain our predict results and determine whether there were incorrect modeling assumptions made, the causal graphs were too noisy, the causal knowledge was not incorporated properly, there was not sufficient data for models to generalize on, or the predict questions were beyond a forecasting horizon (Martin et al. 2016;Abeliuk et al. 2020;Salganik et al. 2020).</p>
<p>Incorporating causal knowledge into predictive models</p>
<p>In addition to evaluating predictive models with and without causal knowledge systematically embedded on sampled data A and B across four simulation scenarios, we performed an extensive evaluation on internally simulated data with known ground truth (instead of inferred ground truth). We experimented with continuous binary and mixed data types on non-intervened datasets and demonstrated that embedding causal knowledge improved predictive performance in several experimental settings.</p>
<p>Binary output variables (both causal parents and ancestors of mixed and binary inputs) and continuous output variables (causal parents of mixed and continuous inputs) demonstrated the benefit of relying on causal knowledge for predictive modeling.</p>
<p>The data for our predict experiments were simulated using the R pcalg library as described in Sect. 3. We generated 1140 random DAGs of various sizes to represent varied causal structures and presented the example graphs in Fig. 5. For every simulated graph, we predicted the value of each node under three experimental setting as illustrated in Fig. 11. In the first setting, input information from all nodes is available (excluding the node we are predicting). In the second setting, information from the nodes in the causal ancestry of the predicted node is available. Finally, in the third setting, only nodes that are direct parents of the predicted node are available as inputs to the model.</p>
<p>With the generated datasets, we trained a DNN and two baseline ML models, RF and LR for prediction, classification (for binary outputs), and regression (for continuous outputs). Distinct models were trained for each graph with 70% of the samples used for training, 10% for validation, and 20% held out for testing. Our DNN for both regression and classification consists of three layers with 64 units and a dropout rate of 0.25. We used the Adam optimizer with a learning rate of 0.005 and early stopping. Mixed datasets made use of all models depending on the data type of the output node. A mix of binary and continuous data was given as input.</p>
<p>Training three types of models for each node as the output in every graph under all three experimental settings is computationally expensive. Therefore, we randomly select 255 unique graphs that covered each generation method at each graph size. In total, 6,468 models were trained and evaluated.</p>
<p>We investigated the relationship between the predictive power of each model and the inclusion of the causal knowledge. For that we measured the differences in the mean performance scores between the non-causal and the causally informed models, and evaluated the statistical significance of the comparisons using 1-tailed t-test. Table 4 shows the p-values and significance for the pairwise t-tests.  Fig. 11 Each graph illustrates an example of the input nodes and output node defined by the experimental setting under which we trained ML models (Tsamardinos et al. 2003;Aliferis et al. 2010). Green signifies an input node; striped orange indicates the output node. In setting 1, all nodes excluding the output node are inputs to the model. In setting 2, all nodes in the ancestry of the output node are model inputs.</p>
<p>In setting 3, only direct parents of the output node are model inputs 1 3</p>
<p>In datasets with a mix of continuous and binary data types, a non-causal model (all available variables as input) outperformed any causal model in most instances. For strictly binary datasets, a model leveraging causal feature selection had shown to always improve F1 scores. In particular, a model trained with only direct causal parents of the prediction node yielded the best performance (similar to Aliferis et al. 2010). In a continuous setting, our results were more varied. The root-mean-square deviation (RMSE) values from a causal DNN model are statistically lower than the non-causal DNN; however, this result was reversed when using a linear model. The RF model showed little differences in the RMSE values.</p>
<p>It is important to note that unlike predict experiments with four simulated worlds, our additional experiments and analyses rely on having the true causal graph for a dataset. In practice, access to the ground truth graph is exceedingly rare. Most likely, researchers will have a learned causal graph produced from one of the many causal discovery algorithms or other methods. Errors in the inferred causal relationships are likely to lead to reduced performance of causal feature selection methods. In future work, we will perform similar predict experiments with (a) interventional simulated data and (b) learned causal graphs in order to quantify the impact of such errors in the causal structure. In combination with our current results, such analysis will provide practical evidence to researchers about the importance of causal feature selection and the potential need for improved methods of determining the underlying causal structure as discussed in earlier e (Aliferis et al. 2010). </p>
<p>3</p>
<p>Explaining and predicting human behavior and social dynamics…</p>
<p>Conclusions and future work</p>
<p>In this work we evaluated multiple approaches to discover the causal mechanisms of human behavior and social dynamics from observational data using four simulated worlds. In addition, we performed an additional evaluation on simulated datasets frequently used for benchmarking outside the human domain. We validated generalizability, reproducibility and robustness of these approaches for causal discovery (aka causal structure learning) and outlined their strength, weaknesses and limitations. We demonstrated that the existing methods are not generalizable across use cases and datasets, and are not robust to sampling. Specifically, we showed that causal ensembles with the top four performing algorithms are more robust to sampling, but are still hindered by the least stable algorithms.</p>
<p>As expected, as we increase the sample size, the stability of ensemble algorithms also increases. Both explain and predict methods are vulnerable to data and modeling assumptions e.g., how agents make decisions, interact with each other and with the environment, and how interactions occur across the environmental factors. We also measured how causal discovery performance depends on the task complexity, data size, and the signal in the data. We demonstrated the importance of data to knowledge representation learning for causal discovery (Schölkopf et al. 2021) by empirically evaluating how knowledge extraction from data effects model performance.</p>
<p>When explicitly incorporating inferred causal knowledge into predictive models, we demonstrated the benefit of causal feature selection for two out of four simulation scenarios. However, it is important to note that the causal knowledge were inferred with high uncertainty. Therefore, it is necessary but not sufficient to improve causal discovery methods in order to boost predictive modeling of complex systems including but not limited to human behavior. The causes of uncertainty were compatibility of our simulation approach with virtual worlds' simulation approaches, not having sufficient data for models to learn from, or task complexity and the forecasting horizon. Our additional predict experiments where we incorporated known ground truth into machine learning models (rather than the inferred ground truth) showed the benefit of including causal knowledge for predictive modeling for multiple output variable type --binary and continuous.</p>
<p>Our causal discovery and modeling results to explain and predict human behavior and social dynamics raise a number of interesting questions and directions for future work. However, as of now, traditional causal discovery approaches are limited and are insufficient to explain and anticipate human social dynamics. First, accounting for individual differences can significantly increase dimensionality of the data and confound estimates of causal effects when the structure of the causal model is not known a priori. Second, relatively little research exists on designing personalized interventions. Finally, little is known about how to enable contextualized reasoning, when changes in the individual and the environment inform interventions.</p>
<p>Mining real-world human behavioral data to discover natural experiments (King et al. 2011;Alipourfard et al. 2018) could be an alternative to inferring the causal mechanisms from human behavioral data to study complex social phenomena in the Human Domain like social inequality, perception and susceptibility to disinformation or the spread infectious diseases e.g., Haushofer and Metcalf, 2020. But it presents major computational challenges for causal discovery and inference, and other multidisciplinary computational social science approaches. The major challenge is explicitly measuring the effects, which is difficult as treatment may itself be correlated with some aspects of human behavioral data, confounding analysis. Additional challenges include continuous treatments, fair causal inference, high-dimensional feature spaces (Feder et al. 2021) etc. Addressing national security challenges relevant to the Human Domain by discovering natural experiments or by using other computational methods, to save lives or to strengthen the democracy, will require extensive validation of the existing computational methods, as well as rethinking ethical usage of sharing data and strong multidisciplinary collaborations (Lazer et al. 2020;Watts 2011;Kahneman 2011).</p>
<p>Dr. Svitlana Volkova is a recognized leader in the field of computational linguistics, machine learning and computational social science. She leads the development of human-centered analytics to explain, predict and prescribe human social systems and behaviors as they relate to national security challenges in the human domain. Solutions developed by Svitlana and her team advance understanding, analysis, and effective reasoning about extreme volumes of dynamic, multilingual, multimodal real-world social data. Since joining PNNL in 2015, Dr. Volkova has led more than ten projects, including two DARPA efforts. She authored more than 50 peer-previewed conference and journal publications. Svitlana was a Vice Chair of the ACM Future of Computing Academy between 2017 and 2019. She received her PhD in Computer Science in 2015 from Johns Hopkins University where she was affiliated with the Center for Language and Speech Processing and the Human Language Technology Center of Excellence.</p>
<p>Dr. Dustin Arendt is a Senior Research Scientist and Team Lead in the Visual Analytics Group at Pacific</p>
<p>Northwest National Laboratory, joining the lab in October 2014. He received his Ph.D. from Virginia Tech in 2012 and completed a postdoc at the Air Force Research Laboratory from 2012 to 2014 where he researched graph visualization and applied machine learning. Since joining PNNL he has worked in several domains including visualization for cybersecurity, streaming data visual analytics, visual abstraction, dynamic graph visualization, visualization for natural language processing, interactive machine learning, explainable machine learning, and visualization for machine learning model validation and comparison. Currently, his interests are at the intersection of human-computer interaction, data science, and visual analytics, with a focus on validating machine learning models through explanations and exploratory data analysis. His research involves rapid prototyping and empirical evaluation of tools that blend machine learning, data science, and visualization.</p>
<p>Dr. Emily Saldanha is a research scientist in the area of data science at PNNL where her work focuses on applying machine learning and deep learning techniques to identify and understand patterns in complex data. She has specific interests in the development of robust methods for application areas ranging from energy technologies to computational social science. She received her Ph.D. in physics from Princeton University in 2016, where her work focused on the development and application of calibration algorithms for microwave sensors for cosmological observations. Dr. Maria Glenski is a Data Scientist in the Data Science and Analytics Group, National Security Directorate at the Pacific Northwest National Laboratory. Her research focuses include computational social science approaches to behavior analysis, characterization, and modeling of complex social behavior in diverse online social environments and explainable artificial intelligence (XAI) evaluating the impacts of algorithmic biases in machine learning models. Dr. Glenski received her Ph.D. in Computer Science from the University of Notre Dame where she was an Arthur J Schmitt Leadership in Science and Engineering Fellow. Dr. Glenski's research has been published in top tier venues including WWW, ACL, ACM TIST, and CSCW and she regularly serves on the program committee of several international conferences and journals.</p>
<p>Fig. 3
3Fig. 3 Reproducibility analysis presented as differences in causal node and link discovery performance (measured as F1 score) between our causal ensemble approach and other causal discovery approaches using data samples A and B (RQ2)</p>
<p>Fig. 5
5Examples of causal graphs with N = 20 nodes and E = 2 expected edges per node, generated using each method of the pcalg random DAG function.</p>
<p>Fig. 6
6Robustness of different approaches as a function of the fraction of the data sampled. (Left) The directed edge robustness of the individual algorithms and ensembles. (Right) The node, directed edge, and undirected edges robustness of the four-algorithm ensemble-GES, PC, GS, IAMB algorithms Fig. 7 The mean and standard deviation of the directed edge robustness of the four-algorithm ensemble with a 32% sample of the data across different graph structure properties including the number of nodes (left), the expected number of edges per node (middle), and the graph generation method (right)</p>
<p>Fig. 8
8The robustness of predicted edges when applying an edge weight threshold of 0.65 to the ensemble prediction versus without applying a threshold. Each point is an individual graph</p>
<p>Fig. 10
10An overview of our modeling approach to predict human behavior and social dynamics in simulated virtual wordsShmueli 2010 </p>
<p>Table 1
1Table of assumptions defined inGreenland and Mansournia (2015) for example causal discovery algorithms ordered by score-based versus constraint-based approaches ×-indicates necessary assumption. •-indicates sufficient assumptionAlgorithm Causal 
suffi-
ciency </p>
<p>Causal 
faithful-
ness </p>
<p>Causal 
markov </p>
<p>Gaussian 
data </p>
<p>Non-gauss. 
data </p>
<p>Multi-
nomial 
data </p>
<p>Linear 
relations. </p>
<p>Table 3
3Properties of thebnlearn datasets 
Dataset 
Nodes 
Edges 
Data type 
Data size </p>
<p>Coronary 
6 
9 
Binary 
1841 </p>
<p>Asia 
8 
8 
Binary 
5000 </p>
<p>Sachs 
11 
17 
Continuous 
853 </p>
<p>Child 
20 
25 
Categorical 
10,000 </p>
<p>Insurance 
27 
52 
Categorical 
20,000 </p>
<p>Alarm 
37 
46 
Categorical 
20,000 </p>
<p>Water 
32 
66 
Continuous 
10,000 </p>
<p>Andes 
223 
338 
Binary 
10,000 </p>
<p>Table 4
4Predictive model performance on non-interventional simulated dataSignificance is denoted with * for p &lt; 0.05 , ** for p &lt; 0.01 , and *** for p &lt; 0.001Input type 
Output type Model 
All nodes avg F1 
Indirect avg F1 
Direct avg F1 </p>
<p>Mixed 
Binary 
DNN 
0.874<strong> 
0.845 
0.852</strong> </p>
<p>Random Forest 0.855*** 
0.816 
0.821 </p>
<p>Logistic Reg. 
0.865**<em> 
0.845 
0.849</em> </p>
<p>Binary 
Binary 
DNN 
0.702 
0.750<strong>* 
0.763</strong> </p>
<p>Random Forest 0.706 
0.751<strong><em> 
0.762</em></strong> </p>
<p>Logistic Reg. 
0.731 
0.744<strong>* 
0.748</strong> </p>
<p>Input type Output type Model 
All nodes avg 
RMSE </p>
<p>Indirect avg RMSE Direct avg RMSE </p>
<p>Mixed 
Continuous DNN 
1.574 
1.420<strong> 
1.278</strong> </p>
<p>Random Forest 1.091<strong> 
1.421 
1.270</strong>* </p>
<p>Linear Reg. 
1.607*** 
1.938 
1.800 </p>
<p>Continuous Continuous DNN 
0.177 
0.145<strong>* 
0.141</strong> </p>
<p>Random Forest 0.148<em> 
0.151 
0.149</em>* </p>
<p>Linear Reg. 
0.079*** 
0.092 
0.092 </p>
<p>References to causal discovery approaches are provided at https:// github. com/ FenTe chSol utions/ Causa lDisc overy Toolb ox.
https:// www. rdocu menta tion. org/ packa ges/ pcalg/ versi ons/2. 6-8/ topics/ randD AG. 3 https:// www. bnlea rn. com/ bnrep osito ry/.
Pacific Northwest National Laboratory, 902 Battelle Blvd, Richland, WA 99354, USA
AcknowledgementsThe project was conducted at Pacific Northwest National Laboratory, a multiprogram national laboratory operated by Battelle for the U.S. Department of Energy and was sponsored by the Defense Advanced Research Projects Agency (DARPA) under cooperative agreements HR0011939944 and HR0011044266. The content of the information does not necessarily reflect the position or the policy of the government and no official endorsement should be inferred. We would like to thank Robin Cosbey, Sannisth Soni, Zhuanyi H Shaw, Austin Golding, and Ryan Rabello for their contributions to this work. We are also grateful to Asmeret Naugle and Adam Russell for their guidance and recommendations.Ellyn Ayton is a Data Scientist at PNNL. She received her Master's in Computer Science from Western Washington University. Her research areas of interest include deep learning and its many applications, such as detecting digital deception. She contributes to projects that use NLP to extract predictive signals from open source data, evaluates the effectiveness of causal mechanisms in machine learning models, and develops methods of interpretability and explainability of black-box deep learning models.Dr. Joseph Cottam works on visualization and data analysis frameworks. He is interested in involving expert knowledge in analytic processes and applications where data comparison s are major part of exploration. Currently he is working with biological data, networks that change over time and causal analysis. He has significant experience with graph analytics, data analysis in out-of-core and streaming scenarios and HPC systems. He is also interested in programming language design and distributed computing.Dr. Sinan G. Aksoy is a discrete mathematician and data scientist specializing in graph theory and network science at Pacific Northwest National Laboratory. In addition to his theoretical research in spectral and extremal graph theory, he is interested in applying graph theoretic methods to study wide-ranging complex systems, including those arising from social networks, power and communication systems, supercomputing, and cyber security. In these domains, his work focuses on developing methodologies that draw from probability, statistics and combinatorics. Sinan's research spans over 20 publications and has appeared in journals such as the SIAM Journal on Discrete Mathematics, SIAM Journal on Mathematics of Data Science, EPJ Data Science, Advances in Applied Mathematics, and the Journal of Supercomputing. Sinan holds a PhD in mathematics from the University of California, San Diego, and a BA in economics and mathematics from the University of Chicago.Dr. Brett Jefferson is a data scientist at Pacific Northwest National Laboratory, where he's conducted research for the past two years. Prior to joining the laboratory, Brett completed a Ph.D. program in mathematical psychology and a M.A. degree program in mathematics at Indiana University. Brett's research focuses on three main areas, mathematical modeling using topology, robustness assessment of machine learning classifiers, and quantitative assessments of human and machine systems. Dr. Jefferson is a committee member for the National Association of Mathematicians, member of the Cognitive Science Society and member of the Society for Mathematical Psychology.Karthik Shivaram is PhD Student at Tulane University, where his research focuses on Computational Social Science, Machine Learning and Natural Language Processing. Currently he is working on developing semi-supervised learning methods to aid Stance Classification in Social Networks. He has previously interned at PNNL where he worked on applying Graphical Causal Discovery Models to determine causal relationships for computer simulations and investigated the use of Representational Learning methods to aid Causal Inference Performance. Previous to this he has worked as a Data Scientist and as a Software Developer at Accenture. He also holds a master's degree in computer science from Illinois Institute of Technology and a bachelor's degree in Mechanical Engineering from BMS Institute of Technology.Authors and AffiliationsSvitlana Volkova 1 · Dustin Arendt 1 · Emily Saldanha 1 · Maria Glenski 1 · Ellyn Ayton 1 · Joseph Cottam 1 · Sinan Aksoy 1 · Brett Jefferson 1 · Karthnik Shrivaram 1 * Svitlana Volkova svitlana.volkova@pnnl.gov
Predictability limit of partially observed systems. A Abeliuk, Z Huang, E Ferrara, K Lerman, Scientific Rep. 101Abeliuk A, Huang Z, Ferrara E, Lerman K (2020) Predictability limit of partially observed systems. Sci- entific Rep 10(1):1-10</p>
<p>Local causal and markov blanket induction for causal discovery and feature selection for classification part i: algorithms and empirical evaluation. C F Aliferis, A Statnikov, I Tsamardinos, S Mani, X D Koutsoukos, J Mach Learn Res. 111Aliferis CF, Statnikov A, Tsamardinos I, Mani S, Koutsoukos XD (2010) Local causal and markov blan- ket induction for causal discovery and feature selection for classification part i: algorithms and empirical evaluation. J Mach Learn Res 11(1):171-234</p>
<p>Using Simpson's paradox to discover interesting patterns in behavioral data. N Alipourfard, P G Fennell, K Lerman, arXiv:1805.03094Preprint atAlipourfard N, Fennell PG, Lerman K (2018) Using Simpson's paradox to discover interesting patterns in behavioral data. Preprint at arXiv: 1805. 03094</p>
<p>Machine learning and causal inference for policy evaluation. S Athey, Proceedings of the 21th ACM SIGKDD international conference on knowledge discovery and data mining. the 21th ACM SIGKDD international conference on knowledge discovery and data miningAthey S (2015) Machine learning and causal inference for policy evaluation. In: Proceedings of the 21th ACM SIGKDD international conference on knowledge discovery and data mining, pp 5-6</p>
<p>From system 1 deep learning to system 2 deep learning. Y Bengio, 11Bengio Y (2019) From system 1 deep learning to system 2 deep learning. http:// www. iro. umont real. ca/ bengi oy/ NeurI PS-11dec 2019. pdfAccessed 11 Nov 2021</p>
<p>Optimal structure identification with greedy search. D M Chickering, J Mach Learn Res. 3Chickering DM (2002) Optimal structure identification with greedy search. J Mach Learn Res 3:507-554</p>
<p>Chollet F (2020) A definition of intelligence for the real world. J Artif Gen Intell. 112Chollet F (2020) A definition of intelligence for the real world. J Artif Gen Intell 11(2):27-30</p>
<p>Explaining and predicting human behavior and social dynamics…. Explaining and predicting human behavior and social dynamics…</p>
<p>Graph comparison for causal discovery. Visualization in data science. J Cottam, M Glenski, Y Shaw, R Rabello, A Golding, S Volkova, D Arendt, Cottam J, Glenski M, Shaw Y, Rabello R, Golding A, Volkova S, Arendt D (2021) Graph comparison for causal discovery. Visualization in data science</p>
<p>Causal inference in natural language processing: estimation, prediction, interpretation and beyond. A Feder, K A Keith, E Manzoor, R Pryzant, D Sridhar, Z Wood-Doughty, J Eisenstein, J Grimmer, R Reichart, M E Roberts, arXiv:2109.00725Preprint atFeder A, Keith KA, Manzoor E, Pryzant R, Sridhar D, Wood-Doughty Z, Eisenstein J, Grimmer J, Reich- art R, Roberts ME, et al (2021) Causal inference in natural language processing: estimation, predic- tion, interpretation and beyond. Preprint at arXiv: 2109. 00725</p>
<p>Structure learning under missing data. A Gain, I Shpitser, PMLRInternational conference on probabilistic graphical models. Gain A, Shpitser I (2018) Structure learning under missing data. In: International conference on probabil- istic graphical models, PMLR, pp 121-132</p>
<p>Review of causal discovery methods based on graphical models. C Glymour, K Zhang, P Spirtes, Front Genet. 10524Glymour C, Zhang K, Spirtes P (2019) Review of causal discovery methods based on graphical models. Front Genet 10:524</p>
<p>Limitations of individual causal models, causal graphs, and ignorability assumptions, as illustrated by random confounding and design unfaithfulness. S Greenland, M A Mansournia, Eur J Epidemiol. 3010Greenland S, Mansournia MA (2015) Limitations of individual causal models, causal graphs, and ignor- ability assumptions, as illustrated by random confounding and design unfaithfulness. Eur J Epide- miol 30(10):1101-1110</p>
<p>A survey of learning causality with data: problems and methods. R Guo, L Cheng, J Li, P R Hahn, H Liu, ACM Comput Surv (CSUR). 534Guo R, Cheng L, Li J, Hahn PR, Liu H (2020) A survey of learning causality with data: problems and methods. ACM Comput Surv (CSUR) 53(4):1-37</p>
<p>Which interventions work best in a pandemic?. J Haushofer, Cje Metcalf, Science. 3686495Haushofer J, Metcalf CJE (2020) Which interventions work best in a pandemic? Science 368(6495):1063-1065</p>
<p>Prediction and explanation in social systems. J M Hofman, A Sharma, D J Watts, Science. 3556324Hofman JM, Sharma A, Watts DJ (2017) Prediction and explanation in social systems. Science 355(6324):486-488</p>
<p>Thinking, fast and slow. D Kahneman, Macmillan, LondonKahneman D (2011) Thinking, fast and slow. Macmillan, London</p>
<p>Comparative effectiveness of matching methods for causal inference. G King, R Nielsen, C Coberley, J E Pope, A Wells, 15King G, Nielsen R, Coberley C, Pope JE, Wells A (2011) Comparative effectiveness of matching methods for causal inference. 15(1):41-67</p>
<p>Simulations evaluating resampling methods for causal discovery: ensemble performance and calibration. E Kummerfeld, A Rix, arXiv:1910.02047Preprint atKummerfeld E, Rix A (2019) Simulations evaluating resampling methods for causal discovery: ensemble performance and calibration. Preprint at arXiv: 1910. 02047</p>
<p>What is a complex system?. J Ladyman, J Lambert, K Wiesner, Eur J Philos Sci. 31Ladyman J, Lambert J, Wiesner K (2013) What is a complex system? Eur J Philos Sci 3(1):33-67</p>
<p>Building machines that learn and think like people. B M Lake, T D Ullman, J B Tenenbaum, S J Gershman, 10.1017/S0140525X16001837Behav Brain Sci. Lake BM, Ullman TD, Tenenbaum JB, Gershman SJ (2017) Building machines that learn and think like people. Behav Brain Sci. https:// doi. org/ 10. 1017/ S0140 525X1 60018 37</p>
<p>Computational social science: obstacles and opportunities. D M Lazer, A Pentland, D J Watts, S Aral, S Athey, N Contractor, D Freelon, S Gonzalez-Bailon, G King, H Margetts, Science. 3696507Lazer DM, Pentland A, Watts DJ, Aral S, Athey S, Contractor N, Freelon D, Gonzalez-Bailon S, King G, Margetts H et al (2020) Computational social science: obstacles and opportunities. Science 369(6507):1060-1062</p>
<p>Exploring limits to prediction in complex social systems. T Martin, J M Hofman, A Sharma, A Anderson, D J Watts, Proceedings of the 25th international conference on world wide web. the 25th international conference on world wide webMartin T, Hofman JM, Sharma A, Anderson A, Watts DJ (2016) Exploring limits to prediction in com- plex social systems. In: Proceedings of the 25th international conference on world wide web, pp. 683-694</p>
<p>Complex systems theory and evolution. M Mitchell, M Newman, Encycl Evol. 1Mitchell M, Newman M (2002) Complex systems theory and evolution. Encycl Evol 1:1-5</p>
<p>A manifesto for reproducible science. M R Munafò, B A Nosek, D V Bishop, K S Button, C D Chambers, Du Sert, N P Simonsohn, U Wagenmakers, E J Ware, J J Ioannidis, J P , Nat Hum Behav. 11Munafò MR, Nosek BA, Bishop DV, Button KS, Chambers CD, Du Sert NP, Simonsohn U, Wagenmak- ers EJ, Ware JJ, Ioannidis JP (2017) A manifesto for reproducible science. Nat Hum Behav 1(1):1-9</p>
<p>Social data: biases, methodological pitfalls, and ethical boundaries. A Olteanu, C Castillo, F Diaz, E Kiciman, Front Big Data. 213Olteanu A, Castillo C, Diaz F, Kiciman E (2019) Social data: biases, methodological pitfalls, and ethical boundaries. Front Big Data 2:13</p>
<p>The seven tools of causal inference, with reflections on machine learning. J Pearl, Cambridge Pearl J. 623Cambridge University PressCommun ACMPearl J (2009) Causality. Cambridge University Press, Cambridge Pearl J (2019) The seven tools of causal inference, with reflections on machine learning. Commun ACM 62(3):54-60</p>
<p>Inferring causation from time series in earth system sciences. J Runge, S Bathiany, E Bollt, G Camps-Valls, D Coumou, E Deyle, C Glymour, M Kretschmer, M Mahecha, J Muñoz, E Nes, J Peters, R Quax, M Reichstein, M Scheffer, B Schölkopf, P Spirtes, G Sugihara, J Sun, J Zscheischler, 10.1038/s41467-019-10105-3Nat Commun. Runge J, Bathiany S, Bollt E, Camps-Valls G, Coumou D, Deyle E, Glymour C, Kretschmer M, Mahecha M, Muñoz J, Nes E, Peters J, Quax R, Reichstein M, Scheffer M, Schölkopf B, Spirtes P, Sugihara G, Sun J, Zscheischler J (2019) Inferring causation from time series in earth system sciences. Nat Commun. https:// doi. org/ 10. 1038/ s41467-019-10105-3</p>
<p>Measuring the predictability of life outcomes with a scientific mass collaboration. E Saldanha, R Cosbey, E Ayton, M Glenski, J Cottam, K Shivaram, B Jefferson, B Hutchinson, D Arendt, S Volkova, M J Salganik, I Lundberg, A T Kindel, C E Ahearn, K Al-Ghoneim, A Almaatouq, D M Altschul, J E Brand, N B Carnegie, R J Compton, Proc Natl Acad Sci. 11715Evaluation of algorithm selection and ensemble methods for causal discoverySaldanha E, Cosbey R, Ayton E, Glenski M, Cottam J, Shivaram K, Jefferson B, Hutchinson B, Arendt D, Volkova S (2020) Evaluation of algorithm selection and ensemble methods for causal discovery Salganik MJ, Lundberg I, Kindel AT, Ahearn CE, Al-Ghoneim K, Almaatouq A, Altschul DM, Brand JE, Carnegie NB, Compton RJ et al (2020) Measuring the predictability of life outcomes with a scien- tific mass collaboration. Proc Natl Acad Sci 117(15):8398-8403</p>
<p>Toward causal representation learning. B Schölkopf, F Locatello, S Bauer, N R Ke, N Kalchbrenner, A Goyal, Y Bengio, Proc IEEE. 1095Schölkopf B, Locatello F, Bauer S, Ke NR, Kalchbrenner N, Goyal A, Bengio Y (2021) Toward causal representation learning. Proc IEEE 109(5):612-634</p>
<p>To explain or to predict?. G Shmueli, Stat Sci. 253Shmueli G et al (2010) To explain or to predict? Stat Sci 25(3):289-310</p>
<p>Enhancing reproducibility for computational methods. P Spirtes, C N Glymour, R Scheines, D Heckerman, V ; Cambridge Stodden, M Mcnutt, D H Bailey, E Deelman, Y Gil, B Hanson, M A Heroux, J P Ioannidis, M Taufer, Science. 3546317MIT pressCausation, prediction, and searchSpirtes P, Glymour CN, Scheines R, Heckerman D (2000) Causation, prediction, and search. MIT press, Cambridge Stodden V, McNutt M, Bailey DH, Deelman E, Gil Y, Hanson B, Heroux MA, Ioannidis JP, Taufer M (2016) Enhancing reproducibility for computational methods. Science 354(6317):1240-1241</p>
<p>Improved causal discovery from longitudinal data using a mixture of dags. E V Strobl, PMLRThe 2019 ACM SIGKDD workshop on causal discovery. Strobl EV (2019) Improved causal discovery from longitudinal data using a mixture of dags. In: The 2019 ACM SIGKDD workshop on causal discovery, PMLR, pp 100-133</p>
<p>Algorithms for large scale Markov blanket discovery. I Tsamardinos, C F Aliferis, A R Statnikov, E Statnikov, FLAIRS conference. 2Tsamardinos I, Aliferis CF, Statnikov AR, Statnikov E (2003) Algorithms for large scale Markov blanket discovery. FLAIRS conference 2:376-380</p>
<p>Causal discovery in the presence of missing data. R Tu, C Zhang, P Ackermann, K Mohan, H Kjellstrm, K Zhang, PMLRThe 22nd international conference on artificial intelligence and statistics. Tu R, Zhang C, Ackermann P, Mohan K, Kjellstrm H, Zhang K (2019) Causal discovery in the pres- ence of missing data. In: The 22nd international conference on artificial intelligence and statistics, PMLR, pp 1762-1770</p>
<p>Everything is obvious:<em> Once you know the answer. Duncan J ; Currency Watts, D J Watts, E D Beck, E J Bienenstock, J Bowers, A Frank, A Grubesic, J Hofman, J M Rohrer, M Salganik, 10.1017/S0140525X20001685Explanation, prediction, and causality: three sides of the same coinWatts, Duncan J (2011) Everything is obvious:</em> Once you know the answer. Currency Watts DJ, Beck ED, Bienenstock EJ, Bowers J, Frank A, Grubesic A, Hofman J, Rohrer JM, Salganik M (2018) Explanation, prediction, and causality: three sides of the same coin?</p>
<p>The generalizability crisis. T Yarkoni, 10.1017/S0140525X20001685Behav Brain Sci. Yarkoni T (2019) The generalizability crisis. Behav Brain Sci. https:// doi. org/ 10. 1017/ S0140 525X2 00016 85</p>
<p>A review on algorithms for constraint-based causal discovery. K Yu, J Li, L Liu, arXiv:1611.03977Preprint atYu K, Li J, Liu L (2016) A review on algorithms for constraint-based causal discovery. Preprint at arXiv: 1611. 03977</p>
<p>Data-driven agent-based modeling, with application to rooftop solar adoption. H Zhang, Y Vorobeychik, J Letchford, K Lakkaraju, Auton Agents Multi-Agent Syst. 306Zhang H, Vorobeychik Y, Letchford J, Lakkaraju K (2016) Data-driven agent-based modeling, with application to rooftop solar adoption. Auton Agents Multi-Agent Syst 30(6):1023-1049</p>            </div>
        </div>

    </div>
</body>
</html>