<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-5851 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-5851</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-5851</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-119.html">extraction-schema-119</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) or AI systems being used to extract, discover, or distill quantitative laws, mathematical relationships, or empirical equations from large collections of scientific or scholarly papers.</div>
                <p><strong>Paper ID:</strong> paper-266210371</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2312.09038v1.pdf" target="_blank">Object Recognition from Scientific Document Based on Compartment and Text Blocks Refinement Framework</a></p>
                <p><strong>Paper Abstract:</strong> With the rapid development of the internet in the past decade, it has become increasingly important to extract valuable information from vast resources efficiently, which is crucial for establishing a comprehensive digital ecosystem, particularly in the context of research surveys and comprehension. The foundation of these tasks focuses on accurate extraction and deep mining of data from scientific documents, which are essential for building a robust data infrastructure. However, parsing raw data or extracting data from complex scientific documents have been ongoing challenges. Current data extraction methods for scientific documents typically use rule-based (RB) or machine learning (ML) approaches. However, using rule-based methods can incur high coding costs for articles with intricate typesetting. Conversely, relying solely on machine learning methods necessitates annotation work for complex content types within the scientific document, which can be costly. Additionally, few studies have thoroughly defined and explored the hierarchical layout within scientific documents. The lack of a comprehensive definition of the internal structure and elements of the documents indirectly impacts the accuracy of text classification and object recognition tasks. From the perspective of analyzing the standard layout and typesetting used in the specified publication, we propose a new document layout analysis framework called Compartment and Text Blocks Refinement (CTBR). Firstly, we define scientific documents into hierarchical divisions: base domain, compartment, and text blocks. Next, we conduct an in-depth exploration and classification of the meanings of text blocks. Finally, we utilize the results of text block classification to implement object recognition within scientific documents based on rule-based compartment segmentation. For the experiment, we used the well-known ACL format proceeding articles as experimental data for the validation experiment. The experiment shows that our approach achieved over 95% text block classification accuracy and 90% object recognition accuracy for tables and figures.</p>
                <p><strong>Cost:</strong> 0.003</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <p class="empty-note">No extracted data.</p>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <p class="empty-note">No potentially relevant new papers extracted.</p>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-5851",
    "paper_id": "paper-266210371",
    "extraction_schema_id": "extraction-schema-119",
    "extracted_data": [],
    "potentially_relevant_new_papers": [],
    "cost": 0.003415,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Object Recognition from Scientific Document based on Compartment &amp; Text Blocks Refinement Framework
23 Aug 2024</p>
<p>Jinghong Li lijinghong-n@jaist.ac.jp 
Center for Innovative Distance Education and Research
Advanced Institute of Science and Technology
9231292Asahidai, Nomi, IshikawaJapan, Japan</p>
<p>Wen Gu 
Center for Innovative Distance Education and Research
Advanced Institute of Science and Technology
9231292Asahidai, Nomi, IshikawaJapan, Japan</p>
<p>Koichi Ota 
Center for Innovative Distance Education and Research
Advanced Institute of Science and Technology
9231292Asahidai, Nomi, IshikawaJapan, Japan</p>
<p>Shinobu Hasegawa hasegawa@jaist.ac.jp 
Center for Innovative Distance Education and Research
Advanced Institute of Science and Technology
9231292Asahidai, Nomi, IshikawaJapan, Japan</p>
<p>Division of Advanced Science and Technology
Advanced Institute of Science and Technology
9231292Asahidai, NomiIshikawaJapan, Japan</p>
<p>Object Recognition from Scientific Document based on Compartment &amp; Text Blocks Refinement Framework
23 Aug 20243E1B405138124BDC96ABD8154364B361arXiv:2312.09038v4[cs.CV]Scientific DocumentsCompartmentRule-basedMachine learningText Block RefinementObject Recognition
With the rapid development of the internet in the past decade, it has become increasingly important to extract valuable information from vast resources efficiently, which is crucial for establishing a comprehensive digital ecosystem, particularly in the context of research surveys and comprehension.The foundation of these tasks focuses on accurate extraction and deep mining of data from scientific documents, which are essential for building a robust data infrastructure.However, parsing raw data or extracting data from complex scientific documents have been ongoing challenges.Current data extraction methods for scientific documents typically use rule-based (RB) or machine learning (ML) approaches.However, using rule-based methods can incur high coding costs for articles with intricate typesetting.Conversely, relying solely on machine learning methods necessitates annotation work for complex content types within the scientific document, which can be costly.Additionally, few studies have thoroughly defined and explored the hierarchical layout within scientific documents.The lack of a comprehensive definition of the internal structure and elements of the documents indirectly impacts the accuracy of text classification and object recognition tasks.From the perspective of analyzing the standard layout and typesetting used</p>
<p>Introduction</p>
<p>Over the preceding decade, technologies opened up new fields of research and practice that center on database mining and knowledge discovery [1].With the boom in the development of Digital Ecosystems, an overwhelming number of scientific articles are available online, including Springer, ACM, IEEE Xplore, etc. [2].The open-access articles in these platforms are processed to build infrastructure databases, such as the Semantic Scholar API [3] and unarXive [4], which are important for researchers and students as critical sources of advanced knowledge and reference material [5].</p>
<p>ChatGPT is an AI-powered conversational large language model (LLM).The potential uses of LLMs in research activities could be promising, as long as we actively consider and address any valid concerns associated with them [6].With the rise of ChatGPT, which relies on vast amounts of background data, researchers are using generative AI, including scispace [7] [8], for conducting research surveys.The generated responses are mostly based on existing papers and academic data.However, the information provided to the generating AI is affected by intermittent textual information and incomplete charts, so the output of the generating AI may be incomplete, leading to low-quality generation.Therefore, To achieve higher-quality outputs from generative AI, it is crucial to accurately identify and segment content from the raw data of scientific documents.</p>
<p>Data mining technology is essential for constructing foundational data for research articles.As the Text analysis tools for scientific documents have been increasingly developed, which include techniques like extractive automatic summarization, abstract automatic summarization, and visualization slide generation using natural language processing [9].In order to carry out the task mentioned above, it is important to efficiently collect and organize the language text elements (main text, itemized form, sections, footnotes) and non-language text elements (figures, tables, formulas, quotation marks) within scientific documents [10].For this issue, data extraction techniques are fundamental approaches to classify and identify information in the article into different categories [11].Document layout analysis (DLA) purposes to detect and annotate the physical structure of documents [12].However, parsing the layout and analyzing the content of scientific documents can be challenging and intricate.The layout of research articles is often irregular, and the typesetting styles vary depending on the publication [13].Therefore, there is a tendency to extract discontinuous data when extracting internal information from scientific documents.For instance, the flow of the main narrative from a file may be broken in mid-sentence by errors derived from the reading order of individual text blocks and interruptions, including figure titles, footnotes, and headers [14].Rule-based conditional branching and regular expressions are conventional methods to process text to solve the above issue, such as parsing sentences and identifying keywords [13].However, these methods could be improved in their ability to process the complex structure used in scientific documents, which may contain many patterns and irregularities that are not easily detected by traditional algorithms.To address this issue, researchers have turned to machine learning algorithms, which are more flexible and able to learn and adapt based on the presented data.Machine learning methods can take into account the specific patterns in scientific documents and improve the accuracy and effectiveness of automatic text processing [15].However, scientific documents may have varying fonts and typesetting, which require more complex vectorization and annotation methods to increase generality.Formulating these intricate techniques can be time-consuming and expensive [16].In this study, we propose the compartment &amp; text blocks refinement(CTBR) Framework to recognize objects from scientific documents.We utilize a rule-based method to extract single-modal blocks and rough segment the compartment based on them.Then, we use machine learning techniques to classify multi-modal text blocks that contain complex information.This helps refine the compartment and achieve object recognition in scientific documents.The contribution of the CTBR framework is mainly in the following four aspects.</p>
<p>Contribution</p>
<p>• We propose a novel framework for understanding the layout of scientific documents in a hierarchical structure.This framework includes base domains, compartments, and text blocks, with a hierarchical structure that clearly represents the functionality of single-modal and multi-modal elements.• To process text blocks, which are the fundamental elements of scientific document layout analysis in this work, we developed an integrated encoding template highlighting their characteristics.These patterns encompass dimensions, coordinates, font type, font size, and text density within the text blocks.• To differentiate between the different types of information conveyed by each text block, we manually annotated the linguistic and non-linguistic information in a short period.This allowed us to create a small-scale dataset for implementing a text block classification module based on machine learning technology.Our approach is characterized by its relatively low time cost for training on specific sets of scientific documents.This enables accurate multi-modal text block classification and information extraction for large volumes of similarly formatted scientific documents.• Based on the classification results, we implemented a compartment segmentation module to improve the identification of figures and tables to achieve more accurate object recognition for complex cases.In order to evaluate the effectiveness of our proposed method for object recognition, we conducted comparison experiments with existing multi-modal document processing models.</p>
<p>Position of this work</p>
<p>The Table 1 presents a summary of the previous research and their limitations on data extraction for scientific documents.Previous studies have faced difficulty in accurately distinguishing text blocks within figures and tables.This study aims to address these limitations by refining text blocks using different features, including position, size, line and column spacing, font type, and font size.By considering these features and compartment segmentation, we can enhance the ability to distinguish various objects within scientific documents.Miss detection in complex pattern matching involving continuous tables.</p>
<p>Table net (2020)[22]</p>
<p>End-to-end Deep learning This model uses interdependence between 0table detection and structure recognition tasks to segment table and column regions.</p>
<p>Header of the table is difficult to fit.</p>
<p>Pdffigure 2.0 (2016) [19] Rule-based Analyzes page structure and locates figures and tables by analyzing empty regions within text.</p>
<p>Miss detection occurred when figures and tables appear continuously.</p>
<p>Tabula (2018)[20]</p>
<p>Rule-based It uses customizable heuristics to detect tables and reconstruct cell structure based on text and ruling lines in the PDF.</p>
<p>If recognition is not restricted to the table zone, the body-text and section title patterns may be mixed with the detected result.</p>
<p>Grobid (2008-2023)[18]</p>
<p>CRF Extract and reorganize not only the content but also the layout and text styling information.</p>
<p>It is difficult to extract noise-free text because information with figures, tables, and equations are included in the body-text.</p>
<p>3 Methodology-Definition</p>
<p>Overview</p>
<p>We are dedicated to creating a framework for document layout analysis using text block and compartment analysis.Our approach utilizes rule-based algorithms to process text within identifiable text blocks to implement rough compartment segmentation.Additionally, we employ machine learning models for multi-modal text block classification.Furthermore, by combining the classification result with rough compartment segmentation, we use a sophisticated compartment refinement algorithm to achieve object recognition.Our framework consists of three stages, as illustrated in Fig. 1.</p>
<p>Fig. 1: Overview</p>
<p>• The first stage is preprocessing, which provides detailed instructions on parsing PDFs and extracting information from text blocks from scientific documents.</p>
<p>• The second stage involves text block classification, using a combination of rulebased methods to identify single-modal text blocks and machine learning to classify complex text blocks.</p>
<p>• The third stage focuses on the algorithm of compartment segmentation and object recognition for figures and tables based on the results of text block classification in the second stage.</p>
<p>Internal Environment of scientific document</p>
<p>To gain a deeper understanding of document layout, it is important to define the Internal Environment in the document for developing a simulation model, similar to urban planning or apartment room layout design.In this study, we categorize the internal structure of scientific documents into three levels.In this section, we provide specific definitions for the base domains, compartments, and text blocks within the context of scientific documents, as well as the roles they play in our overall system.The intuitive hierarchical structure is shown in Fig. 2.</p>
<p>Fig. 2: Internal Environment of scientific document</p>
<p>• 1.The first level consists of base domains that form the overall structure, such as basic information domain (the region before the chapter 1 included title, author information, mail address, abstract.etc.),Its function is to provide readers about the meta information of this article and a general understanding.Comparable to the entrance area inside a house, when you step into the entrance area of a house, you may see the overall style and structure of the house, such as the color scheme, the general layout of the rooms, and the decorative style.This will give you a rough impression of the house.</p>
<p>• 2. The second level further subdivides each base domain into compartments, representing the different functions they serve.For instance, a model diagram can provide readers with an overview of research methods, helping them organize their thoughts and injecting energy into their understanding of the documents.Comparable to the dining compartment , which provide people with the necessary energy for their daily lives that promote engagement in more activities within the house.</p>
<p>• 3. The third level comprises text block within the compartments, which are the components that make up the compartments.Each text block also has specific functions that contribute to the overall function of the compartment.For instance, in a table, some text blocks contain data of accuracy rate that gives readers an intuitive expression to help them understand the intended purpose of the table as conveyed by the author.Comparable to the furniture in the dining compartment, such as dining tables, chairs, and wine cabinets, these furniture items are physical objects that we use in our dining process.They provide us a more tangible experience of the dining scene.</p>
<p>Text block in scientific document</p>
<p>The text block is a collection of different character strings.Just like authors organize scientific documents, they often group strings that express specific contents for formatting purposes.When these strings are closely arranged, they tend to form groups.Some text blocks feature single-modal expressions that convey singular and easily processed information, such as figure titles, table titles and section titles.These can be classified using rule-based and regular expression methods.However, rule-based methods do not easily understand some text blocks, particularly those embedded in figures/tables and separated from the body-text.These multi-modal text blocks appearing in tables may represent measurements of experimental evaluation criteria, while those appearing in figures may describe components of research modules.These text blocks serve different purposes than similar-looking text blocks in the body-text.In this study, we aim to use machine learning methods for feature recognition of multi-modal text blocks.The types of text blocks are summarized in Table 2. To enable machines to analyze text blocks containing multi-modal information, we categorized the usage of text blocks in scientific documents that carry multi-modal information into three categories: Bodytext, Supplementary information, and Accessory information [16].Their definitions are shown in Table 3.</p>
<p>Definition of Compartment</p>
<p>This study defines a compartment in scientific documents as a group of multiple text blocks.These compartments provide a richer information combination than a single text block.For instance, when we see a figure in an article, we need to integrate the relationships between different parts of the figure to understand them fully.In this case, the figure region can be viewed as a compartment, where the information of different parts is often presented through text blocks or graphic elements.Therefore, accurately segmenting and recognizing the content inside compartments and the information they convey is crucial for improving machine perception of the document layout.In section 4.4, we explain in detail how to utilize the results of text block classification for object detection based on a compartment segmentation algorithm.</p>
<p>4 Methodology-implementation 4.1 Phase1:Preprocessing</p>
<p>Text block parsing</p>
<p>Scientific repositories currently store research articles in PDF format.The first step is to focus on parsing the text blocks within PDF articles.This can be automated using the external library pymupdf [23] in Python.By analyzing the raw structure of scientific documents, the line and column spacing, characteristics can be used to divide the text of a PDF file into multiple sub-text blocks.These blocks contain specific content, and their combination results compose the unstructured page layout, as depicted in Fig. 3.The Page.get text("blocks") method of pymupdf can be used to extract the text blocks of each page.</p>
<p>Extracting accompanying information from text</p>
<p>When extracting text blocks using pymupdf, the accompanying text's information, such as font, size, and style, can also be obtained [23].This information can be used in various ways, such as analyzing the document's structure, identifying headers and footers, and detecting text requiring special formatting.Analyzing these characteristics makes  it possible to optimize the extraction process and improve the accuracy of extracting specific features.For example, font size can be used to identify the main-sections of the document or to differentiate between headings and body-text.Font style can be used to detect emphasis or to identify quotes.Moreover, utilizing the accompanying text's information enables data extraction in a more organized and structured manner, resulting in more easily obtainable, low-noise output.The accompanying information extracted in this study is shown in Table 4.</p>
<p>Single-modal text block recognition</p>
<p>This study focuses on processing scientific documents that have specific section numbers assigned.There are two types of section titles: main-section and sub-section.</p>
<p>Table 5 shows each matching method using regular expression.The font characteristics(font type and font size) of the text are also utilized to distinguish similar patterns in the body-text.Figure and table titles use a similar recognition method, as shown in Table 5.</p>
<p>Phase 2-2: Classification for complex text block element</p>
<p>In contrast to the processing method described in the previous section for singlemodal text blocks, effectively classifying the information contained in multi-modal text blocks is challenging using rule-based algorithms.This is because the conditions required for rule-based processing are complex, making it difficult to capture individual cases.This chapter extracts features from complex element's text blocks and encodes them to address the issue of classifying multi-modal information.The SVM method in machine learning is then used to recognize these feature patterns for comprehensive classification.</p>
<p>Encoder template</p>
<p>Nine vector elements are selected to create a vector that reflects the characteristics of an article.Each vector element is constructed to embed the characteristics of a specific object.The encoding method for each element is as follows:</p>
<p>1-2, Left Position and Right Position: As the body-text block is often Justify Align, the goal is to accurately calculate the location of the beginning of each block and obtain common characteristics of the text.Expressly, we set the Left/Right-aligned block as a left/right boundary line and calculate the division between each block's left/Right coordinate and the boundary coordinate.
Block f s = Index of {M ax{ f ss 1, ..., f ss N }} (5.2) Code f s = Block f s Body f s (5.3)
9, Density of text block(D): In contrast to the basic characteristics of a text block mentioned earlier, we propose the concept of a higher-dimensional feature of text block density.This feature is defined as the ratio of the occupied area of text within a text block to the size of the text block.A larger ratio indicates a smaller blank area within the text block.Typically, body-text containing intensive text arrangement has a small occupied area of blank space.On the other hand, text blocks corresponding to table information tend to have a larger blank area due to the presence of spaces and empty lines.Therefore, we calculate the text block density using equation (6.1 -6.3), which combines several characteristics mentioned in the previous section to determine the category of a text block.</p>
<p>Code density =</p>
<p>Area of text block Area of text occupy = S block Length text * Code f s (</p>
<p>S block = W idth of Block size * Height of Block size (6.2)
Length text = Count of text in block(6.3)</p>
<p>Annotation for text block</p>
<p>To enable the machine to recognize the types of information mentioned in Section 3.2.1 for each text block, we follow a process of encoding and vectorizing the text blocks.These text blocks, which contain multi-modal information, are manually annotated by humans.By combining the vectors of the constructed text blocks, we create a dataset for text box classification.This dataset has short annotation time, easy judgment, and high accuracy.An example of the labels can be seen in Fig. 4.</p>
<p>Classifier</p>
<p>Support Vector Machine (SVM) is one of the classifiers that boast particularly high accuracy in machine learning.SVM has the advantage of high applicability even to unknown data [28].It seeks to maximize the margin when drawing a boundary line to divide the training data.Maximizing the margin improves the classification accuracy for unknown data, and the generalization performance becomes higher.Therefore, SVM has high adaptability and versatility for scientific documents with complex structure combinations.For instance, some special cases of text blocks in figures have the same font and size as the body-text.The SVM classifier's margin and tolerance range setting are considered to improve training effectiveness to recognize these cases.</p>
<p>Phase3 : Compartment Segmentation&amp; Object Recognition</p>
<p>Using the text block classification results from Phase 2, we aim to cluster the classification results of text blocks into group levels for compartment segmentation and object recognition.Initially, we use single-modal text blocks such as section titles, figure titles, and table titles to establish the boundaries (refer to Fig. 5).The content between these single-modal text blocks (for double-column layout documents, page break coordinates need to be set) may represent a compartment containing body-text or a compartment containing figures and tables.By combining the classification results of multi-modal text blocks, we statistically determine the category of the text blocks within this compartment and identify the type of object they represented.Finally, we establish the correlation between figure/table titles and their respective compartment based on their positions.</p>
<p>Boundary setting based on simple text block</p>
<p>We analogize the boundary lines in the document to doors or walls separating independent rooms.These boundary lines divide the entire document into several rough compartments.We determine the boundaries by considering the position and order of simple text blocks in the document, as illustrated in Fig. 5.</p>
<p>Sophisticated Compartment Segmentation&amp; Object recognition</p>
<p>In this section, we utilize the classification results of the text blocks and the position of the boundary to enhance the refinement of the rough compartment.We begin by assigning sequential numbers to the rough compartment and the boundary based on their arrangement in the document.Next, we iterate through the sequence of appearance of the figure and table titles that correspond to the boundary.Based on this strategy, we can infer the position and size of the compartments where the figures and tables are located, following the rules outlined below.This approach enables more precise compartment recognition.</p>
<p>Conclusion</p>
<p>In this study, we developed an advanced framework called CTBR for text block classification and object recognition in scientific documents.This framework first defines the hierarchical structure of scientific document's layout, including base domains, compartments, and text blocks.We developed a bottom-up level encoded template to refine these text blocks, which contain multi-modal data, and performed text block classification using machine learning and rule-based methods.Furthermore, we achieved more advanced compartment segmentation and object recognition using the classification results.The effectiveness of this framework was demonstrated through hierarchical scientific document layout analysis, using a small-scale training dataset and an SVM classifier for text block classification.We also developed a specialized algorithm for compartment segmentation to determine the region of figures and tables based on the classification results of text blocks, achieving an accuracy of over 90%.Overall, the experimental results showed the effectiveness of this framework.</p>
<p>Future tasks to improve this framework include the following:</p>
<p>• 1.More refined compartment planning algorithm:</p>
<p>This study divides the sections of figures, body-text, and footnotes in scientific documents.One of the future challenges is to add a finer level of division within the body-text, such as recognizing compartments of equations, itemized forms, algorithm areas, and lists.</p>
<p>• 2. Compartment Internal Functional Differentiation In this work, we acknowledge the importance of the compartment in scientific documents.However, the function within these compartments is also crucial for a comprehensive understanding of the document.For example, the text blocks in figures can be considered components, each with a special meaning.In a statistical graph, the data on the horizontal and vertical axes reflect the range of the object, while the names of the axes indicate the measured indicators and so on.Similarly, the components of a model diagram in a scientific document provide a clear representation of the input-output and basic logic of the model.Exploring such detailed information further can optimize the dataset for scientific document understanding and greatly enhance the interpretability of figures in scientific documents.</p>
<p>Fig. 3 :
3
Fig.3: Unstructured page layout: Sample article[25]</p>
<p>Fig. 4 :
4
Fig.4: Human annotation for text blocks[26].</p>
<p>Fig. 5 :
5
Fig. 5: Boundary setting &amp; compartment[27].</p>
<p>Fig. 6 :
6
Fig.6: Sample of Object Detection: Sample article[29]</p>
<p>Table 1 :
1
THE SUMMARY OF PREVIOUS WORK
LimitationFeature/Advantage• New diverse and detailedmanually-annotated dataset D 4Large training data, and supports multipleinput modalities and is useful for manymodeling approaches.MethodGridTransformerDetectionTransformerReferenceVGT(2023)[17]TableTransformer(2022)[21]
LA • In-depth layout analysis • Pre-trained for 2D token-level and segment-level semantic understanding If there is a cluster of text blocks in a figure/table, it can be difficult to distinguish whether it is body text or figure/table region.</p>
<p>Table 2 :
2
Type &amp; characteristics of Object
ObjectTypeReasonMethodSection TitleObvious• Continuity of section numbers • Specific fonts for section titlesRBTab&amp;Fig TitleObviousThe format of Tab/Fig titles is same academic publication. generally consistent within theRBBody-TextUnobviousDiscontinuous dataMLFigureUnobviousIrregular text block includedMLTableUnobviousIrregular text block includedMLPage NumUnobviousSimilar text block in tablesMLFootnoteUnobviousSimilar text block in body-textML</p>
<p>Table 3 :
3
Type of text block
TypeDisciptionBody-textSentence group in body of articleSupplementary informationFigure and Table regions, Figure and Table titles Equations, Algorithms, Sections titleAccessory informationPage number, Footnote, Meta information</p>
<p>Table 4 :
4
Accompanying information and their usage</p>
<p>Accompanying information Usage Bounding box Encode for left, right, top, bottom, width,height Font size • Boundary setting • Encode for font size, text blockdensity Font type • Boundary setting • Encode for font type Media box Compartment segmentation</p>
<p>Table 5 :
5
Regular expression for single-modal text block recognition in ACL formatWe defined the Basic Information Domain, Body Domain, Reference Domain, and Appendix Domain as the fundamental domains.The subsequent work of this research specifically focuses on the Body Domain.We utilize regular expressions and text accompanying information within the text blocks to perform compartment segmentation.
ElementRegular expressionMain section title ^[0-9]{1,2}\s<em>[.|,].</em>$Sub section title^[0-9]{1,2}(.[0-9]{1,2}){1,4}\s+.<em>$Figure title^[F|f][I|i][G|g][U|u][R|r][E|e]\s</em>\d+\s<em>:.</em>$Table title^[T|t][A|a][B|b][L|l][E|e]\d+\s<em>:.</em>$4.2 Phase 2-1: Rule-based Implementation for simple textblock element4.2.1 Base domain segmentation</p>
<p>Table Title Crossing the Central Axis If the text block area corresponding to the title of a figure or table crosses the central axis of the document, the region of the figure/table will also cross the central axis of the document.• Type2: Figure &amp; Table Title Not Crossing the Central Axis Conversely, if the text block area corresponding to the title of a figure or table does not cross the central axis of the document, then the region of the figure or table will follow the dual-column layout.</p>
<p>.</p>
<p>1.If the boundary where the figure/table title is located is at the top of the page (without any compartments appearing before it), the compartment where the figure or table is located must be directly below the boundary.2. If the boundary where the figure/table title is located is at the bottom of the page (without any compartments appearing after it), the compartment where the figure or table is located must be directly above the boundary.3.If the boundary where the figure/table title is located is in the middle of the page (with compartments before and after it), we need to use the text block classification results from the rough compartment, following Equation (7.1 -7.3), to infer whether the corresponding figure/table region appears directly above or below.In Equation (7.1 -7.3), S means area.Bbox compartment = (lef t pos , right pos , up pos, bottom pos ) (8.1) Lef t pos |T op pos = M in Lef t|T op T ext block of ′ supplementary ′ (8.2) Right pos |Bottom pos = M ax Right|Bottom T ext block of ′ supplementary ′ (8.3) 6. Referring to the pdffigure2.0method[19], if the width of the figure/table compartment is larger than the figure/table title, it is determined as the figure/table compartment.If the block's width where the figure/table title is located is larger, resize the figure/table compartment to match that width.The results of the Compartment recognition samples are shown in Fig.6.
Above|Below = Area of label ′ Supplementary ′ Occupied(7.1)Above|Below =S Compartment S block label of ′ Supplementary ′(7.2)Compartment =Above &gt; Below , Above is F igure/T able region Above &lt; Below , Below is F igure/T able region(7.3)4. Once the boundary-compartment correspondence is confirmed, other boundariescannot occupy the same compartment.5. Since some compartments may contain additional information such as body-text orfootnotes, we need to use the text block classification results for refining the roughcompartment, following Equation (8.1 -8.3) to further segment the figure &amp; tableregion
Code (lef t|right) = Block coordinate (Lef t|Right)Boundary coordinate (Lef t|Right)(1)3-4, Top Position and Bottom Position: Footnote and page number information is often displayed at the bottom of the page, so it is necessary to encode that information to distinguish it from other information.The encoding method is the same as the one described in Left /Right Position but switches from left/right to upper/lower.5-6, Width Length and Height Length: While the blocks of body-text are distributed more regularly, it is necessary to grasp the width and height characteristics of the blocks to recognize the supplement information blocks, as they are irregularly distributed and have many small blocks.Therefore, in an article, set the largest width/height as the standard for all blocks, perform a division of the width/height of each block, and encode it.7, Font Type(ft): In most cases, the body-text font has the highest frequency in scientific documents.Therefore, following the font acquisition method in section 4.1.2,all blocks are scanned to aggregate the corresponding character count for each font, and the font type with the highest frequency is considered the body-text font.Next, the most frequently appearing font in each block is calculated, and if it is the body-text font, it is encoded as' 1'.Otherwise, it is encoded as' 0'.Body f ont = Index of {M ax{ f t1, ..., f tN }} (4.1)8, Font Size(fs): First, set the standard font size to the most frequently appeared font size among the body fonts.Next, determine the most frequent font size in each block and set it as the font size for that block.Finally, divide each block's font size by the standard font size and encode it.In equation (5.1 -5.3), fss means font size in that text block.Body f s = Index of {M ax{ f s 1, ..., f s N }} (5.1)
Next-generation digital ecosystem for climate data mining and knowledge discovery: a review of digital data collection technologies. A Hsu, W Khoo, N Goyal, M Wainstein, Frontiers in big Data. 3292020</p>
<p>Semantic Relation Extraction: A Review of Approaches, Datasets, and Evaluation Methods. H Gharagozlou, J Mohammadzadeh, A Bastanfard, S S Ghidary, ACM Transactions on Asian and Low-Resource Language Information Processing. 2023</p>
<p>R Kinney, C Anastasiades, R Authur, I Beltagy, J Bragg, A Buraczynski, . . Weld, D S , arXiv:2301.10140The semantic scholar open data platform. 2023arXiv preprint</p>
<p>unarxive 2022: All arxiv publications pre-processed for nlp, including structured full-text and citation network. T Saier, J Krause, M Färber, arXiv:2303.149572023arXiv preprint</p>
<p>Automatic Summarization for Academic Articles using Deep Learning and Reinforcement Learning with Viewpoints. J Li, H Tanabe, K Ota, W Gu, S Hasegawa, 10.32473/flairs.36.133308The International FLAIRS Conference Proceedings. 202336</p>
<p>ChatGPT utility in healthcare education, research, and practice: systematic review on the promising perspectives and valid concerns. M Sallam, In Healthcare. 1168872023. MarchMDPI</p>
<p>What is the impact of ChatGPT on education? A rapid review of the literature. C K Lo, Education Sciences. 1344102023</p>
<p>The use of artificial intelligence to improve the scientific writing of non-native english speakers. A D Giglio, M U P D Costa, 10.1590/1806-9282.20230560Revista da Associacao Medica Brasileira. 6992023. 1992</p>
<p>Automatic summarization of scientific articles: A survey. N I Altmami, M E B Menai, Journal of King Saud University-Computer and Information Sciences. 3442022</p>
<p>Analysis of academic papers using natural language processing: Current status and prospects. Akiko Aizawa, Journal of The Japanese Society for Artificial Intelligence Society. 3832023</p>
<p>An Ontological Framework for Information Extraction From Diverse Scientific Sources. G Zaman, H B Mahdin, K Hussain, . Atta-Ur-Rahman, J H Abawajy, S A Mostafa, IEEE Access. 92021</p>
<p>Document layout analysis: a comprehensive survey. G M Binmakhashen, S A Mahmoud, ACM Computing Surveys (CSUR). 5262019</p>
<p>Deep learning-based extraction of algorithmic metadata in full-text scholarly documents. Information processing &amp; management. I Safder, S U Hassan, A Visvizi, T Noraset, R Nawaz, S Tuarob, 202057102269</p>
<p>Layout-aware text extraction from full-text PDF of scientific articles. C Ramakrishnan, A Patnia, E Hovy, Source Code Biol Med. 772012</p>
<p>Extracting scientific figures with distantly supervised neural networks. N Siegel, N Lourie, R Power, W Ammar, Proceedings of the 18th ACM/IEEE on joint conference on digital libraries. the 18th ACM/IEEE on joint conference on digital libraries2018. May</p>
<p>A Text Block Refinement Framework For Text Classification and Object Recognition From scientific documents. L Jinghong, O Koichi, G Wen, H Shinobu, 10.1109/IN-ISTA59065.2023.103103202023 International Conference on Innovations in Intelligent Systems and Applications (INISTA). Hammamet, Tunisia2023</p>
<p>Vision grid transformer for document layout analysis. C Da, C Luo, Q Zheng, C Yao, Proceedings of the IEEE/CVF International Conference on Computer Vision. the IEEE/CVF International Conference on Computer Vision2023</p>
<p>GROBID: Combining automatic bibliographic data recognition and term extraction for scholarship publications. P Lopez, Research and Advanced Technology for Digital Libraries: 13th European Conference. Proceedings. Corfu, Greece; Berlin HeidelbergSpringer2009. 2009. September 27-October 2, 200913</p>
<p>Pdffigures 2.0: Mining figures from research articles. C Clark, S Divvala, Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries. the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries2016. June</p>
<p>tabula: An R Package for Analysis, Seriation, and Visualization of Archaeological Count Data. N Frerebeau, 1821.DOI10.21105/joss.01821Journal of Open Source Software. 4442019</p>
<p>PubTables-1M: Towards comprehensive table extraction from unstructured documents. B Smock, R Pesala, R , Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern Recognition2022</p>
<p>Tablenet: Deep learning model for end-to-end table detection and tabular data extraction from scanned document images. S S Paliwal, D Vishwanath, R Rahul, M Sharma, L Vig, 2019 International Conference on Document Analysis and Recognition (ICDAR). IEEE2019September)</p>
<p>Supervised Machine Learning and Deep Learning Classification Techniques to Identify Scholarly and Research Content. H Chang, Y Eshetu, C Lemrow, 2021 Systems and Information Engineering Design Symposium (SIEDS). IEEE2021. April</p>
<p>Hierarchical Sketch Induction for Paraphrase Generation. T Hosking, H Tang, M Lapata, Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics. Long Papers. the 60th Annual Meeting of the Association for Computational Linguistics2022. May1</p>
<p>ePiC: Employing Proverbs in Context as a Benchmark for Abstract Language Understanding. S Ghosh, S Srivastava, Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics. Long Papers. the 60th Annual Meeting of the Association for Computational Linguistics2022. May1</p>
<p>M3ED: Multi-modal Multi-scene Multi-label Emotional Dialogue Database. J Zhao, T Zhang, J Hu, Y Liu, Q Jin, X Wang, H Li, Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics. Long Papers. the 60th Annual Meeting of the Association for Computational Linguistics2022. May1</p>
<p>UCTopic: Unsupervised Contrastive Learning for Phrase Representations and Topic Mining. J Li, J Shang, J Mcauley, Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics. Long Papers. the 60th Annual Meeting of the Association for Computational Linguistics2022. May1</p>
<p>A comprehensive survey on support vector machine classification: Applications, challenges and trends. J Cervantes, F Garcia-Lamont, L Rodríguez-Mazahua, A Lopez, Neurocomputing. 4082020</p>
<p>Learning Disentangled Representations of Negation and Uncertainty. J Vasilakes, C Zerva, M Miwa, S Ananiadou, Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics. Long Papers. the 60th Annual Meeting of the Association for Computational Linguistics2022. May1</p>            </div>
        </div>

    </div>
</body>
</html>