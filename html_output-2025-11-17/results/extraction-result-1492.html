<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1492 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1492</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1492</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-29.html">extraction-schema-29</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <p><strong>Paper ID:</strong> paper-14835537faab715841d0a852225e07d38f8092fb</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/14835537faab715841d0a852225e07d38f8092fb" target="_blank">Falsification of Learning-Based Controllers through Multi-Fidelity Bayesian Optimization</a></p>
                <p><strong>Paper Venue:</strong> European Control Conference</p>
                <p><strong>Paper TL;DR:</strong> This work proposes a multi-fidelity falsification framework using Bayesian optimization, which is able to determine at which level of fidelity the authors should conduct a safety evaluation in addition to finding possible instances from the environment that cause the system to fail.</p>
                <p><strong>Paper Abstract:</strong> Simulation-based falsification is a practical testing method to increase confidence that the system will meet safety requirements. Because full-fidelity simulations can be computationally demanding, we investigate the use of simulators with different levels of fidelity. As a first step, we express the overall safety specification in terms of environment parameters and structure this safety specification as an optimization problem. We propose a multi-fidelity falsification framework using Bayesian optimization, which is able to determine at which level of fidelity we should conduct a safety evaluation in addition to finding possible instances from the environment that cause the system to fail. This method allows us to automatically switch between inexpensive, inaccurate information from a low-fidelity simulator and expensive, accurate information from a high-fidelity simulator in a cost-effective way. Our experiments on various environments in simulation demonstrate that multi-fidelity Bayesian optimization has falsification performance comparable to single-fidelity Bayesian optimization but with much lower cost.</p>
                <p><strong>Cost:</strong> 0.011</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1492.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1492.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Cart-Pole (OpenAI Gym)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Cart-Pole environment (OpenAI Gym)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A classical control benchmark simulating a cart with a pivoted pole; used here within a multi-fidelity falsification study to find safety counterexamples for a learned controller.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Falsification of Learning-Based Controllers through Multi-Fidelity Bayesian Optimization</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_name</strong></td>
                            <td>OpenAI Gym Cart-Pole (custom low-/high-fidelity wrappers)</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_description</strong></td>
                            <td>Physics-based cart-and-pole simulator from OpenAI Gym used to generate finite-horizon trajectories given environment configuration vectors; the authors constructed two fidelity variants (low- and high-fidelity) by modifying sensor noise and numeric precision.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>mechanics / control (dynamical systems)</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_level</strong></td>
                            <td>Two-level setup: high-fidelity = baseline Gym simulator with accurate sensors and 32-bit state precision; low-fidelity = modified variants (Scenario 1: added Gaussian noise to states; Scenario 2: states rounded to 2 decimal places).</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_characteristics</strong></td>
                            <td>High-fidelity: accurate sensor outputs, 32-bit continuous state representation; Low-fidelity Scenario 1: adds normal measurement noise to states; Scenario 2: state precision reduced by rounding to 2 decimal places; both use same underlying dynamics but differ in observation fidelity and numeric precision. Query cost model: low-fidelity cost = 1, high-fidelity cost = 5.</td>
                        </tr>
                        <tr>
                            <td><strong>model_or_agent_name</strong></td>
                            <td>PPO policy (proximal policy optimization)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Reinforcement learning agent trained with PPO (policy gradient-based RL) controlling the cart-pole; agent maps states to discrete left/right force actions.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task</strong></td>
                            <td>Safety falsification: search for environment configurations (disturbances) that produce trajectories violating temporal-logic-like safety specifications (e.g., pole angle, position, momentum constraints).</td>
                        </tr>
                        <tr>
                            <td><strong>training_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_target</strong></td>
                            <td>High-fidelity simulator (predictions / minima of high-fidelity robustness inferred using low-fidelity data via multi-fidelity GP)</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance</strong></td>
                            <td>Multi-fidelity BO achieved falsification performance comparable to single-fidelity BO while reducing the number of expensive high-fidelity simulator queries by up to 20% (first scenario) and ~10% on average (second scenario). Reported averages of minimum specification robustness over 10 experiments (25 BO iterations): first MFBO scenario = -0.1023, second MFBO scenario = -0.1023, standard BO (high-fidelity only) = -0.0994, random search = -0.0980.</td>
                        </tr>
                        <tr>
                            <td><strong>compares_fidelity_levels</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td>Comparisons across the two low-fidelity scenarios and high-fidelity BO show that multi-fidelity BO finds as many or more counterexamples than random search and achieves minima of robustness comparable to single-fidelity BO while substantially reducing costly high-fidelity evaluations.</td>
                        </tr>
                        <tr>
                            <td><strong>minimal_fidelity_discussion</strong></td>
                            <td>No explicit prescription of a minimum required fidelity is provided; authors study two specific low-fidelity constructions (sensor noise, reduced numeric precision) and note that differences in fidelity can influence count of counterexamples.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>No direct failure case reported where low-fidelity prevented finding counterexamples, but the authors note that the difference between low- and high-fidelity simulators affects results and thus fidelity mismatch can influence falsification outcomes.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Falsification of Learning-Based Controllers through Multi-Fidelity Bayesian Optimization', 'publication_date_yy_mm': '2022-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1492.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e1492.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Mountain Car (OpenAI Gym)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Mountain Car environment (OpenAI Gym)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A momentum-exploitation control benchmark where an agent must drive a car up a steep hill; used to evaluate multi-fidelity Bayesian optimization for safety falsification under environment uncertainties.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Falsification of Learning-Based Controllers through Multi-Fidelity Bayesian Optimization</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_name</strong></td>
                            <td>OpenAI Gym MountainCar (custom low-/high-fidelity wrappers)</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_description</strong></td>
                            <td>Physics-based 1D car-on-hill simulator from OpenAI Gym; authors create low- and high-fidelity simulator variants by injecting measurement noise or reducing state precision while keeping underlying dynamics identical.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>mechanics / control (dynamical systems)</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_level</strong></td>
                            <td>Two-level: high-fidelity = baseline Gym simulator with accurate state representation (32-bit); low-fidelity = either added measurement noise (Scenario 1) or rounded state variables to 2 decimal places (Scenario 2).</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_characteristics</strong></td>
                            <td>High-fidelity: accurate continuous states and precise numeric representation; Low-fidelity: either noisy observations or lower-precision discrete representation. Cost model: low-fidelity cost = 1, high-fidelity cost = 5.</td>
                        </tr>
                        <tr>
                            <td><strong>model_or_agent_name</strong></td>
                            <td>PPO policy (proximal policy optimization)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>RL agent trained with PPO controlling the continuous action-power and velocity to reach the goal; trained in simulation.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task</strong></td>
                            <td>Safety falsification: find environment parameter instantiations leading to velocity or position violations against safety constraints (e.g., velocity staying in bounds, goal reach behavior).</td>
                        </tr>
                        <tr>
                            <td><strong>training_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_target</strong></td>
                            <td>High-fidelity simulator (multi-fidelity GP uses low-fidelity data to reduce high-fidelity evaluations while predicting high-fidelity robustness minima)</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance</strong></td>
                            <td>Multi-fidelity BO reduced high-fidelity simulator experiments by ~24% (first scenario) and ~12% (second scenario) on average. Reported averages of minimum robustness over experiments: first MFBO scenario = -0.05351, second MFBO scenario = -0.05354, standard BO (high-fidelity) = -0.05144, random search = -0.04176.</td>
                        </tr>
                        <tr>
                            <td><strong>compares_fidelity_levels</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td>Multi-fidelity BO found more counterexamples per unit cost than single-fidelity BO and random search, and reduced expensive high-fidelity queries substantially while yielding comparable minima of robustness (slightly more negative minima in MFBO cases versus standard BO in some reported statistics).</td>
                        </tr>
                        <tr>
                            <td><strong>minimal_fidelity_discussion</strong></td>
                            <td>No explicit minimal-fidelity threshold is given; only two constructed low-fidelity variants are tested and shown to be informative for predicting high-fidelity falsification outcomes.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>No explicit failure case reported, though the authors note that fidelity differences influence outcomes and therefore inappropriate low-fidelity models may affect detection of counterexamples.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Falsification of Learning-Based Controllers through Multi-Fidelity Bayesian Optimization', 'publication_date_yy_mm': '2022-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1492.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e1492.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Lunar Lander (OpenAI Gym)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Lunar Lander environment (OpenAI Gym)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A low-gravity landing simulation with continuous dynamics and discrete actions; used to test multi-fidelity BO for falsifying safety properties of a learned controller (maintaining horizontal position, orientation, and rotational speed bounds).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Falsification of Learning-Based Controllers through Multi-Fidelity Bayesian Optimization</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_name</strong></td>
                            <td>OpenAI Gym LunarLander (custom low-/high-fidelity wrappers)</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_description</strong></td>
                            <td>A 2D physics engine simulating lander dynamics (positions, velocities, orientation, legs contact); authors use two fidelity variants by altering observation noise and numeric precision while keeping the same core physics engine.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>mechanics / control (aerospace dynamics)</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_level</strong></td>
                            <td>Two-level: high-fidelity = baseline Gym physics engine with full state precision; low-fidelity = either added measurement noise (Scenario 1) or reduced numeric precision (Scenario 2).</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_characteristics</strong></td>
                            <td>High-fidelity: accurate continuous states and physics implementation; Low-fidelity: modified observations (Gaussian noise) or reduced state precision via rounding. Query cost model: low-fidelity cost = 1, high-fidelity cost = 5.</td>
                        </tr>
                        <tr>
                            <td><strong>model_or_agent_name</strong></td>
                            <td>DDPG policy (deep deterministic policy gradient)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Continuous-control RL agent trained with DDPG to command main/orientation engines; neural-network actor-critic architecture typical of DDPG.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task</strong></td>
                            <td>Safety falsification: search for environment perturbations that cause the lander to violate horizontal position, orientation, or rotational speed safety constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>training_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_target</strong></td>
                            <td>High-fidelity simulator (low-fidelity evaluations are used by multi-fidelity GP to predict and discover counterexamples of high-fidelity robustness)</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance</strong></td>
                            <td>Multi-fidelity BO reduced the number of high-fidelity simulator experiments by roughly 23% (first scenario) and 20% (second scenario). Reported averages of minimum robustness over 10 experiments (35 BO iterations) are: first MFBO scenario = -0.3616, second MFBO scenario = -0.4920, standard BO (high-fidelity) = -0.5513, random search = -0.2910 (note standard BO produced the most negative minima in this case).</td>
                        </tr>
                        <tr>
                            <td><strong>compares_fidelity_levels</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td>Multi-fidelity BO generally finds more counterexamples per cost than random search and reduces expensive high-fidelity queries significantly; however, for the lunar lander the single-fidelity high-accuracy BO attained a more negative minimum robustness (stronger falsification) than the multi-fidelity variants in the reported averages.</td>
                        </tr>
                        <tr>
                            <td><strong>minimal_fidelity_discussion</strong></td>
                            <td>No explicit statement of a minimum required fidelity; only the two illustrative low-fidelity modifications are evaluated and authors emphasize that fidelity gap magnitude affects results.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>Authors do not report explicit catastrophic failures of low-fidelity transfer, but report that in at least one environment (lunar lander) single-fidelity high-accuracy BO achieved a more negative robustness minimum than the multi-fidelity variants, indicating potential limitations when fidelity gap or model mismatch exists.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Falsification of Learning-Based Controllers through Multi-Fidelity Bayesian Optimization', 'publication_date_yy_mm': '2022-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Virtual vs. real: Trading off simulations and physical experiments in reinforcement learning with Bayesian optimization <em>(Rating: 2)</em></li>
                <li>Reinforcement learning with multi-fidelity simulators <em>(Rating: 2)</em></li>
                <li>Recursive co-kriging model for design of computer experiments with multiple levels of fidelity <em>(Rating: 2)</em></li>
                <li>Testing cyber-physical systems through Bayesian optimization <em>(Rating: 1)</em></li>
                <li>Finding failures in high-fidelity simulation using adaptive stress testing and the backward algorithm <em>(Rating: 1)</em></li>
                <li>OpenAI Gym <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1492",
    "paper_id": "paper-14835537faab715841d0a852225e07d38f8092fb",
    "extraction_schema_id": "extraction-schema-29",
    "extracted_data": [
        {
            "name_short": "Cart-Pole (OpenAI Gym)",
            "name_full": "Cart-Pole environment (OpenAI Gym)",
            "brief_description": "A classical control benchmark simulating a cart with a pivoted pole; used here within a multi-fidelity falsification study to find safety counterexamples for a learned controller.",
            "citation_title": "Falsification of Learning-Based Controllers through Multi-Fidelity Bayesian Optimization",
            "mention_or_use": "use",
            "simulator_name": "OpenAI Gym Cart-Pole (custom low-/high-fidelity wrappers)",
            "simulator_description": "Physics-based cart-and-pole simulator from OpenAI Gym used to generate finite-horizon trajectories given environment configuration vectors; the authors constructed two fidelity variants (low- and high-fidelity) by modifying sensor noise and numeric precision.",
            "scientific_domain": "mechanics / control (dynamical systems)",
            "fidelity_level": "Two-level setup: high-fidelity = baseline Gym simulator with accurate sensors and 32-bit state precision; low-fidelity = modified variants (Scenario 1: added Gaussian noise to states; Scenario 2: states rounded to 2 decimal places).",
            "fidelity_characteristics": "High-fidelity: accurate sensor outputs, 32-bit continuous state representation; Low-fidelity Scenario 1: adds normal measurement noise to states; Scenario 2: state precision reduced by rounding to 2 decimal places; both use same underlying dynamics but differ in observation fidelity and numeric precision. Query cost model: low-fidelity cost = 1, high-fidelity cost = 5.",
            "model_or_agent_name": "PPO policy (proximal policy optimization)",
            "model_description": "Reinforcement learning agent trained with PPO (policy gradient-based RL) controlling the cart-pole; agent maps states to discrete left/right force actions.",
            "reasoning_task": "Safety falsification: search for environment configurations (disturbances) that produce trajectories violating temporal-logic-like safety specifications (e.g., pole angle, position, momentum constraints).",
            "training_performance": null,
            "transfer_target": "High-fidelity simulator (predictions / minima of high-fidelity robustness inferred using low-fidelity data via multi-fidelity GP)",
            "transfer_performance": "Multi-fidelity BO achieved falsification performance comparable to single-fidelity BO while reducing the number of expensive high-fidelity simulator queries by up to 20% (first scenario) and ~10% on average (second scenario). Reported averages of minimum specification robustness over 10 experiments (25 BO iterations): first MFBO scenario = -0.1023, second MFBO scenario = -0.1023, standard BO (high-fidelity only) = -0.0994, random search = -0.0980.",
            "compares_fidelity_levels": true,
            "fidelity_comparison_results": "Comparisons across the two low-fidelity scenarios and high-fidelity BO show that multi-fidelity BO finds as many or more counterexamples than random search and achieves minima of robustness comparable to single-fidelity BO while substantially reducing costly high-fidelity evaluations.",
            "minimal_fidelity_discussion": "No explicit prescription of a minimum required fidelity is provided; authors study two specific low-fidelity constructions (sensor noise, reduced numeric precision) and note that differences in fidelity can influence count of counterexamples.",
            "failure_cases": "No direct failure case reported where low-fidelity prevented finding counterexamples, but the authors note that the difference between low- and high-fidelity simulators affects results and thus fidelity mismatch can influence falsification outcomes.",
            "uuid": "e1492.0",
            "source_info": {
                "paper_title": "Falsification of Learning-Based Controllers through Multi-Fidelity Bayesian Optimization",
                "publication_date_yy_mm": "2022-12"
            }
        },
        {
            "name_short": "Mountain Car (OpenAI Gym)",
            "name_full": "Mountain Car environment (OpenAI Gym)",
            "brief_description": "A momentum-exploitation control benchmark where an agent must drive a car up a steep hill; used to evaluate multi-fidelity Bayesian optimization for safety falsification under environment uncertainties.",
            "citation_title": "Falsification of Learning-Based Controllers through Multi-Fidelity Bayesian Optimization",
            "mention_or_use": "use",
            "simulator_name": "OpenAI Gym MountainCar (custom low-/high-fidelity wrappers)",
            "simulator_description": "Physics-based 1D car-on-hill simulator from OpenAI Gym; authors create low- and high-fidelity simulator variants by injecting measurement noise or reducing state precision while keeping underlying dynamics identical.",
            "scientific_domain": "mechanics / control (dynamical systems)",
            "fidelity_level": "Two-level: high-fidelity = baseline Gym simulator with accurate state representation (32-bit); low-fidelity = either added measurement noise (Scenario 1) or rounded state variables to 2 decimal places (Scenario 2).",
            "fidelity_characteristics": "High-fidelity: accurate continuous states and precise numeric representation; Low-fidelity: either noisy observations or lower-precision discrete representation. Cost model: low-fidelity cost = 1, high-fidelity cost = 5.",
            "model_or_agent_name": "PPO policy (proximal policy optimization)",
            "model_description": "RL agent trained with PPO controlling the continuous action-power and velocity to reach the goal; trained in simulation.",
            "reasoning_task": "Safety falsification: find environment parameter instantiations leading to velocity or position violations against safety constraints (e.g., velocity staying in bounds, goal reach behavior).",
            "training_performance": null,
            "transfer_target": "High-fidelity simulator (multi-fidelity GP uses low-fidelity data to reduce high-fidelity evaluations while predicting high-fidelity robustness minima)",
            "transfer_performance": "Multi-fidelity BO reduced high-fidelity simulator experiments by ~24% (first scenario) and ~12% (second scenario) on average. Reported averages of minimum robustness over experiments: first MFBO scenario = -0.05351, second MFBO scenario = -0.05354, standard BO (high-fidelity) = -0.05144, random search = -0.04176.",
            "compares_fidelity_levels": true,
            "fidelity_comparison_results": "Multi-fidelity BO found more counterexamples per unit cost than single-fidelity BO and random search, and reduced expensive high-fidelity queries substantially while yielding comparable minima of robustness (slightly more negative minima in MFBO cases versus standard BO in some reported statistics).",
            "minimal_fidelity_discussion": "No explicit minimal-fidelity threshold is given; only two constructed low-fidelity variants are tested and shown to be informative for predicting high-fidelity falsification outcomes.",
            "failure_cases": "No explicit failure case reported, though the authors note that fidelity differences influence outcomes and therefore inappropriate low-fidelity models may affect detection of counterexamples.",
            "uuid": "e1492.1",
            "source_info": {
                "paper_title": "Falsification of Learning-Based Controllers through Multi-Fidelity Bayesian Optimization",
                "publication_date_yy_mm": "2022-12"
            }
        },
        {
            "name_short": "Lunar Lander (OpenAI Gym)",
            "name_full": "Lunar Lander environment (OpenAI Gym)",
            "brief_description": "A low-gravity landing simulation with continuous dynamics and discrete actions; used to test multi-fidelity BO for falsifying safety properties of a learned controller (maintaining horizontal position, orientation, and rotational speed bounds).",
            "citation_title": "Falsification of Learning-Based Controllers through Multi-Fidelity Bayesian Optimization",
            "mention_or_use": "use",
            "simulator_name": "OpenAI Gym LunarLander (custom low-/high-fidelity wrappers)",
            "simulator_description": "A 2D physics engine simulating lander dynamics (positions, velocities, orientation, legs contact); authors use two fidelity variants by altering observation noise and numeric precision while keeping the same core physics engine.",
            "scientific_domain": "mechanics / control (aerospace dynamics)",
            "fidelity_level": "Two-level: high-fidelity = baseline Gym physics engine with full state precision; low-fidelity = either added measurement noise (Scenario 1) or reduced numeric precision (Scenario 2).",
            "fidelity_characteristics": "High-fidelity: accurate continuous states and physics implementation; Low-fidelity: modified observations (Gaussian noise) or reduced state precision via rounding. Query cost model: low-fidelity cost = 1, high-fidelity cost = 5.",
            "model_or_agent_name": "DDPG policy (deep deterministic policy gradient)",
            "model_description": "Continuous-control RL agent trained with DDPG to command main/orientation engines; neural-network actor-critic architecture typical of DDPG.",
            "reasoning_task": "Safety falsification: search for environment perturbations that cause the lander to violate horizontal position, orientation, or rotational speed safety constraints.",
            "training_performance": null,
            "transfer_target": "High-fidelity simulator (low-fidelity evaluations are used by multi-fidelity GP to predict and discover counterexamples of high-fidelity robustness)",
            "transfer_performance": "Multi-fidelity BO reduced the number of high-fidelity simulator experiments by roughly 23% (first scenario) and 20% (second scenario). Reported averages of minimum robustness over 10 experiments (35 BO iterations) are: first MFBO scenario = -0.3616, second MFBO scenario = -0.4920, standard BO (high-fidelity) = -0.5513, random search = -0.2910 (note standard BO produced the most negative minima in this case).",
            "compares_fidelity_levels": true,
            "fidelity_comparison_results": "Multi-fidelity BO generally finds more counterexamples per cost than random search and reduces expensive high-fidelity queries significantly; however, for the lunar lander the single-fidelity high-accuracy BO attained a more negative minimum robustness (stronger falsification) than the multi-fidelity variants in the reported averages.",
            "minimal_fidelity_discussion": "No explicit statement of a minimum required fidelity; only the two illustrative low-fidelity modifications are evaluated and authors emphasize that fidelity gap magnitude affects results.",
            "failure_cases": "Authors do not report explicit catastrophic failures of low-fidelity transfer, but report that in at least one environment (lunar lander) single-fidelity high-accuracy BO achieved a more negative robustness minimum than the multi-fidelity variants, indicating potential limitations when fidelity gap or model mismatch exists.",
            "uuid": "e1492.2",
            "source_info": {
                "paper_title": "Falsification of Learning-Based Controllers through Multi-Fidelity Bayesian Optimization",
                "publication_date_yy_mm": "2022-12"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Virtual vs. real: Trading off simulations and physical experiments in reinforcement learning with Bayesian optimization",
            "rating": 2
        },
        {
            "paper_title": "Reinforcement learning with multi-fidelity simulators",
            "rating": 2
        },
        {
            "paper_title": "Recursive co-kriging model for design of computer experiments with multiple levels of fidelity",
            "rating": 2
        },
        {
            "paper_title": "Testing cyber-physical systems through Bayesian optimization",
            "rating": 1
        },
        {
            "paper_title": "Finding failures in high-fidelity simulation using adaptive stress testing and the backward algorithm",
            "rating": 1
        },
        {
            "paper_title": "OpenAI Gym",
            "rating": 2
        }
    ],
    "cost": 0.0114135,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Falsification of Learning-Based Controllers through Multi-Fidelity Bayesian Optimization</h1>
<p>Zahra Shahrooei^{1}, Mykel J. Kochenderfer^{2}, and Ali Baheri^{3}
[^{1{Zahra Shahrooei is with the Department of Mechanical and Aerospace engineering at West Virginia University. zs00018@mix.wvu.edu}</p>
<p>^{2}Mykel J. Kochenderfer is with the Department of Aeronautics &amp; Astronautics at Stanford University. mykel@stanford.edu</p>
<p>^{3}Ali Baheri is with the Department of Mechanical engineering at Rochester Institute of Technology. akbeme@rit.edu]</p>
<h6>Abstract</h6>
<p>Simulation-based falsification is a practical testing method to increase confidence that the system will meet safety requirements. Because full-fidelity simulations can be computationally demanding, we investigate the use of simulators with different levels of fidelity. As a first step, we express the overall safety specification in terms of environment parameters and structure this safety specification as an optimization problem. We propose a multi-fidelity falsification framework using Bayesian optimization, which is able to determine at which level of fidelity we should conduct a safety evaluation in addition to finding possible instances from the environment that cause the system to fail. This method allows us to automatically switch between inexpensive, inaccurate information from a low-fidelity simulator and expensive, accurate information from a high-fidelity simulator in a cost-effective way. Our experiments on various environments in simulation demonstrate that multi-fidelity Bayesian optimization has falsification performance comparable to single-fidelity Bayesian optimization but with much lower cost.</p>
<h2>I. INTRODUCTION</h2>
<p>Safety-critical autonomous systems operating with humans are increasing rapidly, making it important to develop robust testing procedures to ensure safety. Falsification is a type of testing procedure that involves discovering a trajectory that violates a specification. Such a trajectory is known as a counterexample or failure mode. A safety specification represents properties defined over several behaviors of the system or individual system executions. In falsification, the specification is often modeled using signal temporal logic [1] or metric interval temporal logic [2]. The naive approach to searching for counterexamples is to sample randomly from disturbance trajectories. In order to guide the search more efficiently an appropriate cost function is often used. Once a cost function is defined, safety validation becomes an optimization problem over disturbance trajectories [3]. In this paper, we study the falsification of safety specifications for closed-loop control systems. Black-box techniques assume that no prior knowledge of the system is available. They consider a general mapping from input to output that can be sampled. Recently, Bayesian optimization (BO) has been applied to black-box falsification [4]. BO constructs a probabilistic model that defines a distribution over the objective function, and then refines this model when new data is sampled. It identifies the next sample using the posterior distribution over functions. This step is accomplished by optimizing acquisition functions. Through optimizing an optimization objective, known as acquisition function, BO balances between exploring and focusing on promising areas [5], [6]. Although using search algorithms based on BO can result in a more efficient search for counterexamples compared to random search, it can still be computationally expensive. Recent reinforcement learning approaches use multiple fidelity simulators and integrate information from each simulator, which decreases the need for evaluations from high-fidelity simulators [7]. Generally, the level of fidelity refers to how the simulator imitates the system model. High-fidelity simulators provide a more realistic representation of the system. In contrast, low-fidelity simulators are simpler and involve a greater number of assumptions.</p>
<p>Related Work. There have been several applications of BO in testing learning-based control systems [8]–[11]. Generally, these studies address the problem of safely optimizing an unknown function using Gaussian process (GP) models [12]. Our work closely follows the formulations of Ghosh et al. [11] where they use BO to solve the falsification problem for closed-loop control systems under uncertainty. To model the unknown specification more accurately, they decompose the system specification into a parse tree where the nodes represent individual constraints and model each constraint with a GP. There have also been a few studies that combine multiple sources of information [13]–[16]. Marco et al. [13] apply multi-fidelity BO to optimize controller parameters. They use two levels of fidelity comprising both simulation and physical system experiments and propose an acquisition function to trade-off between cost and accuracy. We focus on</p>
<p>engaging multi-fidelity BO to solve the falsification problem in a cost-effective manner.</p>
<p>Contributions. In summary, this paper presents an approach to the falsification problem with the following features: 1) It employs a multi-fidelity BO algorithm to reduce the number of simulations required in a costly high-fidelity simulator. Experiments show that our method decreases the computational cost of using high-fidelity simulators when searching for counterexamples. 2) To the best of our knowledge, this is the first work that uses a multi-fidelity BO framework to solve falsification tasks.</p>
<p>Organization. We structure this paper as follows: Section II specifies the problem under study and describes the mathematical overview of single-fidelity BO. Section III gives details of extending the single-fidelity BO setting to the multi-fidelity BO setup. Section IV presents three experiments with safety falsification and their results. Section V concludes and provides future direction.</p>
<h2>II. Falsification by Bayesian Optimization</h2>
<p>We investigate the problem of finding counterexamples of a closed-loop control system under uncertainty that arises from stochastic environments and errors in modeling. To start, we assume that a simulator of the physical system of interest and a controller are already available. The simulator operates in a given environment $\mathbf{e} \in \mathcal{E}$, which is able to model various sources of uncertainty. It takes as its input a configuration $\mathbf{e}$ and outputs a finite-horizon trajectory specified by $\xi(t ; \mathbf{e})$ indexed by time $t$.</p>
<p>We aim to determine whether the simulator operates safely in the presence of uncertainty in $\mathcal{E}$. The safety specification is denoted by $\varphi$, which is evaluated on the finitelength trajectories $\xi(\cdot ; \mathbf{e})$. If a trajectory $\xi(\cdot ; \mathbf{e})$ satisfies the specification, then $\varphi(\xi(\cdot ; \mathbf{e}))$ evaluates to true, and false otherwise. To measure how close a trajectory is to falsifying $\varphi$, we use the specification robustness value $\rho_{\varphi}(\xi(\cdot ; \mathbf{e}))$. A positive robustness value shows that the specification is satisfied whereas a negative robustness value indicates that the specification is falsified. We use $\rho_{\varphi}(\mathbf{e})$ for shorthand for $\rho_{\varphi}(\xi(\cdot ; \mathbf{e}))$. We would like to determine whether there exists a counterexample $\mathbf{e} \in \mathcal{E}$ where the specification is violated, i.e., $\rho_{\varphi}(\mathbf{e})&lt;0$. Therefore, the falsification problem can be stated as the following optimization problem:</p>
<p>$$
\underset{\mathbf{e}}{\operatorname{argmin}} \rho_{\varphi}(\mathbf{e})
$$</p>
<p>We use Bayesian optimization to solve this optimization problem. GPs can be used to estimate evaluations of $\rho_{\varphi}(\mathbf{e})$ based on prior evaluations to aid in the optimization [17]. GPs assume the function value of an unknown nonlinear function $\rho_{\varphi}: \mathcal{E} \rightarrow \mathbb{R}$ to be random variables such that any finite number of them can be modeled by a joint Gaussian distribution. In this paper, the prior mean of the distribution $m(\mathbf{e})$ is set to 0 . The kernel function $k\left(\mathbf{e}, \mathbf{e}^{\prime}\right)$ is used to model the covariance between the function values $\rho_{\varphi}(\mathbf{e})$ and $\rho_{\varphi}\left(\mathbf{e}^{\prime}\right)$ at two points $\mathbf{e}$ and $\mathbf{e}^{\prime}$. Suppose that we have a set of environment configurations $\mathcal{E}<em 1="1">{n}=$ $\left[\mathbf{e}</em>}, \mathbf{e<em n="n">{2}, \ldots, \mathbf{e}</em>}\right]$ and a corresponding set of noisy evaluations $\mathbf{y<em _varphi="\varphi">{n}=\left[\hat{\rho}</em>}\left(\mathbf{e<em _varphi="\varphi">{1}\right), \hat{\rho}</em>}\left(\mathbf{e<em _varphi="\varphi">{2}\right), \ldots, \hat{\rho}</em>}\left(\mathbf{e<em _varphi="\varphi">{n}\right)\right]$, where $\hat{\rho}</em>)$ as follows:}(\mathbf{e})=\rho_{\varphi}(\mathbf{e})+$ $\omega$ and $\omega \sim \mathcal{N}\left(0, \sigma^{2}\right)$ is a random disturbance that is normally distributed. By treating the outputs as random variables, we can obtain the posterior distribution of $\rho_{\varphi}(\mathbf{e</p>
<p>$$
\begin{aligned}
m_{n}(\mathbf{e}) &amp; =\mathbf{k}<em n="n">{n}(\mathbf{e})\left(\mathbf{K}</em>}+\mathbf{I<em n="n">{n} \sigma^{2}\right)^{-1} \mathbf{y}</em> \
k_{n}\left(\mathbf{e}, \mathbf{e}^{\prime}\right) &amp; =k\left(\mathbf{e}, \mathbf{e}^{\prime}\right)-\mathbf{k}<em n="n">{n}(\mathbf{e})\left(\mathbf{K}</em>}+\mathbf{I<em n="n">{n} \sigma^{2}\right)^{-1} \mathbf{k}</em>\right) \
\sigma_{n}^{2}(\mathbf{e}) &amp; =k_{n}\left(\mathbf{e}, \mathbf{e}^{\prime}\right)
\end{aligned}
$$}^{T}\left(\mathbf{e}^{\prime</p>
<p>where the vector $\mathbf{k}<em 1="1">{n}(\mathbf{e})=\left[k\left(\mathbf{e}, \mathbf{e}</em>}\right), \ldots, k\left(\mathbf{e}, \mathbf{e<em n="n">{n}\right)\right], \sigma</em>}^{2}(\mathbf{e})$ is variance, $\mathbf{I<em n="n">{n}$ is the identity matrix, and $\mathbf{K}</em>\right)\right]}$ is the positive definite kernel matrix $\left[k\left(\mathbf{e}, \mathbf{e}^{\prime<em n="n">{\mathbf{e}, \mathbf{e}^{\prime} \in \mathcal{E}</em>$.}</p>
<p>Once we model the unknown function, we use acquisition functions to guide the search. An acquisition function is computed from the posterior distribution over the unknown function and indicates the desirability of sampling each configuration next and depending on how it is defined, it can favor exploration or exploitation. In this study, we use the entropy search acquisition function [18], which attempts to maximize the information gain about the global optimum $\mathbf{e}^{<em>}=\underset{\mathbf{e}}{\operatorname{argmin}} \rho_{\varphi}(\mathbf{e})$. Let us represent the $n$th posterior distribution on $\mathbf{e}^{</em>}$ by $P_{n}\left(\mathbf{e}^{<em>}\right)$ and its entropy by $H\left(P_{n}\left(\mathbf{e}^{</em>}\right)\right)$. Similarly, $H\left(P_{n}\left(\mathbf{e}^{<em>} \mid \overline{\mathbf{e}}, \bar{\rho}_{\varphi}(\overline{\mathbf{e}})\right)\right)$ indicates the entropy of what $n+1$ posterior distribution on $\mathbf{e}^{</em>}$ would be if we observe at $\overline{\mathbf{e}}$ and see $\bar{\rho}<em _varphi="\varphi">{\varphi}(\overline{\mathbf{e}})$. This quantity depends on the value of the observed $\bar{\rho}</em>)$. The entropy reduction as a result of sampling can be written as:}(\overline{\mathbf{e}</p>
<p>$$
\alpha^{\mathrm{ES}}(\overline{\mathbf{e}})=H\left(P_{n}\left(\mathbf{e}^{<em>}\right)\right)-\mathbb{E}\left[H\left(P_{n}\left(\mathbf{e}^{</em>} \mid \bar{\rho}_{\varphi}(\overline{\mathbf{e}})\right)\right)\right]
$$</p>
<p>where $\mathbb{E}$ denotes expectation. Maximizing $\alpha^{\mathrm{ES}}(\overline{\mathbf{e}})$ implies minimizing the posterior entropy after a new observation.</p>
<h2>III. Multi-Fidelity Falsification</h2>
<p>In this section, we extend the procedure in the previous section to multi-fidelity simulated environments. Multifidelity BO aims to accelerate the optimization of the target objective and reduce the optimization cost by jointly learning the maximum amount of information from all fidelity models. Considering that we have a range of simulators with different levels of fidelity, we aim to query all simulators to find the minimum of the specification robustness value of the highest fidelity simulator more efficiently with fewer experiments on this simulator. Accordingly, in order to model the relationship between environment configurations and the specification robustness value of the highest fidelity, we employ a multi-fidelity GP and use BO to predict the configurations that cause the system to violate safety requirements (Fig. 1).</p>
<h2>A. Multi-Fidelity Modelling</h2>
<p>We have a range of simulators $\mathcal{S}<em q="q">{1}, \ldots, \mathcal{S}</em>$ in increasing level of fidelity. Our goal is to map the information gained from the lower-fidelity simulators into the higher-fidelity simulators. We will model the relation between specification robustness values on different simulators as follows:</p>
<p>$$
\rho_{\varphi}^{i}(\mathbf{e})=\eta_{i} \rho_{\varphi}^{i-1}(\mathbf{e})+\rho_{g a p}^{i}(\mathbf{e})
$$</p>
<p>Here, $\eta_{i}$ is a constant regression parameter that needs to be inferred and indicates the magnitude of the correlation between the fidelity levels. The bias term between fidelities is modelled by $\rho_{g a p}^{i}(\mathbf{e})$, an independent GP with its own mean function $m_{g a p}^{i}$ and kernel function $k_{g a p}^{i}\left(\mathbf{e}, \mathbf{e}^{i}\right)$. We assume $\rho_{\varphi}^{i-1}(\mathbf{e})$ and $\rho_{g a p}^{i}(\mathbf{e})$ are independent processes linked only by the above equation [19]. To improve computational efficiency, we suppose that the training dataset for $\rho_{\varphi}^{i}(\mathbf{e})$ and $\rho_{\varphi}^{i-1}(\mathbf{e})$ have a nested structure, i.e., the lower fidelity simulator's training data is a subset of that of the higher fidelity simulator's training data. We group the data from all fidelity simulators, and then create the joint prior distribution as follows:</p>
<p>$$
\left[\begin{array}{c}
\rho_{\varphi}^{i-1} \
\rho_{\varphi}^{i}
\end{array}\right] \sim G P\left(\left[\begin{array}{l}
\boldsymbol{\theta} \
\boldsymbol{\theta}
\end{array}\right],\left[\begin{array}{cc}
k_{i-1} &amp; \eta_{i} k_{i-1} \
\eta_{i} k_{i-1} &amp; \eta_{i}^{2} k_{i-1}+k_{g a p}^{i}
\end{array}\right]\right)
$$</p>
<p>The choice of kernel function is problem-dependent and encodes assumptions about smoothness and rate of change of objective function. We use the radial basis function (RBF) kernel for both the error $\left(k_{g a p}^{i}\right)$ and lower fidelity simulator $\left(k_{i-1}\right)$.</p>
<h2>B. Multi-Fidelity Entropy Search</h2>
<p>Once we have modeled the safety specification and the relationship between all fidelity simulators, we use this model to choose which environment configuration to sample next. The cost of querying the level- $i$ simulator is given by $\lambda_{i}$, with $\lambda_{1}&lt;\ldots&lt;\lambda_{q}$. We select the next environment configuration and the next level of fidelity as follows:</p>
<p>$$
\mathbf{e}<em i="i">{n}, i=\underset{\mathbf{e} \in \mathcal{E}, i \in{1, \ldots, q}}{\operatorname{argmax}} \alpha</em>
$$}^{\mathrm{ES}}(\mathbf{e}) / \lambda_{i</p>
<p>Eq. 8 shows that we not only search to find counterexamples or otherwise verify the underlying system but also determine at which level of fidelity we should perform our evaluations by means of an additional decision variable $i$. This approach allows us to switch between various levels of fidelity to reduce the computational cost of our experiments.</p>
<p>Algorithm 1 specifies how multi-fidelity BO for falsification is performed. The algorithm is designed to model the specification robustness value using high-accuracy data from simulators with higher fidelity levels as well as the datarichness of simulators with lower fidelity levels. Once the prior GP over these $q$ simulators is obtained, BO is done in an iterative manner until a stopping criterion is met. On each iteration, we seek to find the minimum of $\rho_{\varphi}^{q}(\mathbf{e})$ by maximizing the acquisition function in Eq. 8. Depending on the costs of the simulators and the gap between the simulators, the algorithm decides the next configuration and which simulator to use to run the experiment. Then, the GP is updated with the new configuration and corresponding specification robustness value of the $i$ th simulator at each iteration.</p>
<h2>C. Levels of Fidelity</h2>
<p>For the rest of this paper, we make use of a low-fidelity simulator and a high-fidelity simulator of the physical system to analyze the multi-fidelity BO approach. We consider two</p>
<div class="codehilite"><pre><span></span><code><span class="n">Algorithm</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="n">MFBO</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">falsification</span>
<span class="n">Require</span><span class="p">:</span><span class="w"> </span>\<span class="p">(</span><span class="n">q</span>\<span class="p">)</span><span class="w"> </span><span class="n">simulators</span><span class="p">,</span><span class="w"> </span><span class="n">search</span><span class="w"> </span><span class="n">space</span><span class="w"> </span>\<span class="p">(</span>\<span class="n">mathcal</span><span class="p">{</span><span class="n">E</span><span class="p">}</span>\<span class="p">),</span><span class="w"> </span><span class="n">safety</span><span class="w"> </span><span class="n">specification</span>
<span class="w">    </span>\<span class="p">(</span>\<span class="n">varphi</span>\<span class="p">),</span><span class="w"> </span><span class="n">costs</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">simulators</span><span class="w"> </span>\<span class="p">(</span>\<span class="n">lambda_</span><span class="p">{</span><span class="mi">1</span><span class="p">},</span><span class="w"> </span>\<span class="n">ldots</span><span class="p">,</span><span class="w"> </span>\<span class="n">lambda_</span><span class="p">{</span><span class="n">q</span><span class="p">}</span>\<span class="p">),</span><span class="w"> </span><span class="n">number</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">BO</span><span class="w"> </span><span class="n">itera</span><span class="o">-</span>
<span class="w">    </span><span class="n">tions</span><span class="w"> </span>\<span class="p">(</span><span class="n">n</span>\<span class="p">)</span>
<span class="w">    </span><span class="n">Construct</span><span class="w"> </span><span class="n">prior</span><span class="w"> </span><span class="n">GP</span><span class="w"> </span><span class="n">over</span><span class="w"> </span><span class="n">training</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="n">from</span><span class="w"> </span><span class="n">the</span><span class="w"> </span>\<span class="p">(</span><span class="n">q</span>\<span class="p">)</span><span class="w"> </span><span class="n">simu</span><span class="o">-</span>
<span class="w">    </span><span class="n">lators</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span>\<span class="p">(</span><span class="n">t</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="w"> </span>\<span class="n">ldots</span><span class="p">,</span><span class="w"> </span><span class="n">n</span>\<span class="p">)</span><span class="w"> </span><span class="n">do</span>
<span class="w">        </span><span class="n">Compute</span><span class="w"> </span>\<span class="p">(</span>\<span class="n">alpha</span><span class="o">^</span><span class="p">{</span>\<span class="n">mathrm</span><span class="p">{</span><span class="n">ES</span><span class="p">}}(</span>\<span class="n">mathbf</span><span class="p">{</span><span class="n">e</span><span class="p">})</span>\<span class="p">)</span><span class="w"> </span><span class="n">over</span><span class="w"> </span><span class="n">GP</span><span class="w"> </span><span class="n">model</span><span class="w"> </span><span class="n">according</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">Eq</span><span class="o">.</span><span class="w"> </span><span class="mi">5</span>
<span class="w">            </span>\<span class="p">(</span>\<span class="n">mathbf</span><span class="p">{</span><span class="n">e</span><span class="p">}</span><span class="n">_</span><span class="p">{</span><span class="n">n</span><span class="p">},</span><span class="w"> </span><span class="n">i</span><span class="o">=</span>\<span class="n">underset</span><span class="p">{</span>\<span class="n">mathbf</span><span class="p">{</span><span class="n">e</span><span class="p">},</span><span class="w"> </span><span class="n">i</span><span class="w"> </span>\<span class="ow">in</span>\<span class="p">{</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span>\<span class="n">ldots</span><span class="p">,</span><span class="w"> </span><span class="n">q</span>\<span class="p">}}{</span>\<span class="n">operatorname</span><span class="p">{</span><span class="n">argmax</span><span class="p">}}</span><span class="w"> </span>\<span class="n">alpha_</span><span class="p">{</span><span class="n">i</span><span class="p">}</span><span class="o">^</span><span class="p">{</span>\<span class="n">mathrm</span><span class="p">{</span><span class="n">ES</span><span class="p">}}(</span>\<span class="n">mathbf</span><span class="p">{</span><span class="n">e</span><span class="p">})</span><span class="w"> </span><span class="o">/</span><span class="w"> </span>\<span class="n">lambda_</span><span class="p">{</span><span class="n">i</span><span class="p">}</span>\<span class="p">)</span>
<span class="w">        </span><span class="n">Update</span><span class="w"> </span><span class="n">GP</span><span class="w"> </span><span class="n">model</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="n">new</span><span class="w"> </span><span class="n">data</span>
<span class="w">        </span><span class="n">Return</span><span class="w"> </span><span class="n">minimum</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">GP</span>
</code></pre></div>

<p>scenarios to distinguish between the low-fidelity simulator and the high-fidelity simulator.</p>
<p>Scenario 1. In the first scenario, the difference between the low-fidelity simulator and the high-fidelity simulator is due to measurement errors in sensor data. As the high-fidelity simulator is equipped with accurate sensors, we create the low-fidelity simulator by adding normal noise to the states of the high-fidelity simulator.</p>
<p>Scenario 2. In the second scenario, the fidelity difference is in the precision of the simulator's states. The low-fidelity simulator runs with state variables of interest rounded to 2 decimal places, while the high-fidelity simulator uses 32-bit variables.</p>
<p>We assume that the query cost for the high-fidelity simulator and the low-fidelity simulator is 5 and 1 , respectively. Different physical units can be used to describe these cost measures, such as the amount of time it takes the high-fidelity simulator to run compared to the low-fidelity simulator or the difference in accuracy between the high-fidelity simulator and the low-fidelity simulator.</p>
<h2>IV. RESULTS</h2>
<p>For the purpose of demonstration, we selected test cases from OpenAI Gym [20], shown in Fig. 2. In each case study, we identified a set of safety criteria and uncertainties in environment. We open-sourced our Python package containing an implementation of the multi-fidelity BO algorithm for falsification. ${ }^{1}$</p>
<h2>A. Case Study 1. Cart-Pole Environment</h2>
<p>The cart-pole environment consists of a cart and a vertical pole attached to the cart using a passive pivot joint. The goal is to prevent the vertical pole from falling by moving the cart left or right. The system's state vector is a tuple with cart position $x$, cart velocity $v$, pole angle $\theta$, and pole angular velocity $\dot{\theta}$. The agent can perform two different actions: apply force to move the cart left or right. The environment comes with seven sources of uncertainty: $\mathcal{E}=[-2,2] \times[-0.05,0.05] \times[-0.2,0.2] \times[-0.05,0.05] \times$ $[0.05,0.15] \times[0.4,0.6] \times[0,10]$. The first four uncertainty</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Fig. 2. Environments visualization: (a) Cart-pole. A safety specification for the cart-pole might be that the angle made by the cart-pole never deviates too far from vertical and never exceeds 9 degrees. (b) Mountain car. A safety requirement for this environment is that the car maintains its velocity in [−0.04, +0.04]. (c) Lunar lander. We want to ensure that the lander always holds its horizontal coordinate within the range [−0.1, 0.1].</p>
<p>Intervals are for the position, velocity, angle, and angular velocity perturbations. The next two intervals are for mass and length of the pole, respectively, and the last is for force magnitude. A system's trajectory is a sequence of states over time, i.e., ξ = (x(t), v(t), θ(t), θ̂(t)). Given an instance of e ∈ ℓ, the trajectory of the system is uniquely defined. We trained a policy for this environment using proximal policy optimization (PPO) [21]. We set the maximum episode length to 400 steps.</p>
<p><strong>Specification.</strong> We want the cart position x to stay within [−1, 1], maintain an absolute momentum of less than 1, and keep the angle made by the cart-pole less than 9 degrees from vertical.</p>
<p><strong>Results.</strong> We compare three methods: the multi-fidelity BO, standard BO on the high-fidelity simulator, and random search. Fig. 3 shows the number of counterexamples found by three methods over 30 BO iterations. All experiments were run with 15 random seeds. Multi-fidelity BO outperforms random search. In addition, the number of counterexamples found by multi-fidelity BO in the second scenario is higher than other approaches. This gives us the intuition that the differences between the low-fidelity simulator and the high-fidelity simulator can influence the number of counterexamples found by the multi-fidelity BO method. Multi-fidelity BO significantly reduced the number of computationally expensive experiments on the high-fidelity simulator by up to 20% and 10% on average in the first and the second scenarios, respectively.</p>
<p>For illustration purposes, we also run 10 experiments over 10, 15, 20, 25, and 30 BO iterations with 15 random seeds. Fig. 4 shows that using multi-fidelity BO can effectively decrease the cost of solving the falsification problem. For the goal of finding 20 counterexamples, one can do 20 evaluations using multi-fidelity BO instead of doing 20 experiments on the high-fidelity simulator. We believe that multi-fidelity BO can compete with standard BO on the high-fidelity simulator. To support our claim, we studied the minimum of the specification robustness value over 10 experiments with 25 BO iterations. The averages of the minimum values for the first and second multi-fidelity BO scenarios, standard BO on the high-fidelity simulator, and random search are −0.1023, −0.1023, −0.0994, and −0.0980. We can conclude that multi-fidelity BO results are more falsifying since the average of minimum of the specification robustness value is smaller than standard BO and random search.</p>
<h3><em>B. Case Study 2. Mountain Car Environment</em></h3>
<p>Mountain car is a benchmark problem in which the task is to train a controller to exploit momentum in order to climb a steep hill. The car has two states, position x and velocity v. For this environment, we consider 5 sources of uncertainty. Two for initial position and velocity are [−0.6, −0.4] and [−0.003, 0.003], respectively. One is for goal position [0.4, 0.6], next for maximum speed [0.055, 0.075], and the last is for maximum power magnitude to be in the range [0.0005, 0.0025]. A trajectory of this system is ξ = (x(t), v(t), θ(t), θ̂(t)); Given an instance of e ∈ ℓ, the system's trajectory is uniquely defined. Using PPO we trained a controller for the mountain car. We set the maximum episode length to 350 steps.</p>
<p><strong>Specification.</strong> The car will be on a safe trajectory, either reaching the goal soon or not deviating too much from its initial location. Additionally, we require that the car always maintains its velocity in [−0.04, +0.04].</p>
<p><strong>Results.</strong> We compare multi-fidelity BO, standard BO on the high-fidelity simulator, and random search. Fig. 5 shows the number of counterexamples found by three methods over 25 BO iterations with 15 random seeds. According to our results in Fig. 5, multi-fidelity BO in the second scenario, standard BO, and multi-fidelity BO in the first scenario detect</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Fig. 3. Comparison between number of counterexamples detected by multi-fidelity BO, BO, and random search methods over 30 BO iterations.</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Fig. 4. Number of discovered counterexamples per cost by multi-fidelity BO, BO, and random search methods.</p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Fig. 5. Comparison between the number of counterexamples detected by multi-fidelity BO, BO, and random search methods over 25 BO iterations.</p>
<p>More counterexamples in comparison to random search. In addition, we found that multi-fidelity BO decreased the number of experiments on the high-fidelity simulator by around 24% and 12% on average in the first and second scenarios. Further, we also made an analysis of the cost for 10 experiments over 5, 10, 15, 20, and 25 BO iterations with 15 random seeds through the three aforementioned methods. Fig. 6 shows that in comparison to the standard BO on the high-fidelity simulator, multi-fidelity BO discovered more counterexamples for the same cost. This is not surprising as we already discuss the reduction of the number of expensive experiments on the high-fidelity simulator. We also analyze the minimum of the specification robustness value. The averages of minimum robustness values are -0.05351, -0.05354, -0.05144, and -0.04176 for the first and the second multi-fidelity scenarios, standard BO, and random search.</p>
<h3><em>C. Case Study 3. Lunar Lander</em></h3>
<p>This environment simulates the situation where a lander needs to land at a specific location under low-gravity conditions and has a well-defined physics engine implemented. The main goal is to direct the agent to the landing pad as softly and fuel-efficiently as possible. Specifically, there are eight state variables associated with the state space: $(x, y)$ coordinates of the lander, $(v_x, v_y)$ the horizontal and vertical velocities, $\theta$ the orientation in the space, $v_\theta$ the angular velocity and two Boolean parameters which show if the left (right) leg touched the ground or not. There are four discrete actions available: do nothing, fire left orientation engine, fire right orientation engine, and fire main engine. We consider four sources of uncertainty: $\delta_x \in [-0.5, 0.5]$ and $\delta_y \in [0, 3]$ are for coordinate perturbations, and the two for velocities are $\delta_{vx} \in [-2, 2]$ and $\delta_{vy} \in [0, 2]$. A trajectory of this system could be represented as $\xi = (x(t), y(t), v_x(t), v_y(t), \theta(t), \dot{\theta}(t))$; Given an instance of $\mathbf{e} \in \mathcal{E}$, the system's trajectory is uniquely defined. We trained a controller for this environment using deep deterministic policy gradient (DDPG) [22]. The maximum episode length is set to be 600 steps for the lunar lander.</p>
<p><strong>Specification.</strong> We want the lander to maintain its horizontal coordinate $(x)$ near the origin, not tilt beyond the angle $\pi/4$, and not rotate faster than 0.2 radians per second.</p>
<p><strong>Results.</strong> We make a comparison between multi-fidelity BO, standard BO on the high-fidelity simulator, and random search results. In Fig. 7, the number of counterexamples found by three methods over 35 BO iterations with 15 random seed values is displayed. Compared to random search, multi-fidelity BO in the second scenario, standard BO, and multi-fidelity BO in the first scenario detect more counterexamples. Moreover, multi-fidelity BO was associated with dramatically fewer experiments on the high-fidelity simulator at roughly 23% and 20% in the first and the second scenarios. Also, we conduct 10 experiments over 15, 20, 25, 30, and 35 BO iterations with 15 random seeds through the three methods outlined above. Fig. 8 shows that in comparison to the standard BO performed on the high-fidelity simulator, multi-fidelity BO discovered more counterexamples for a similar cost, as expected. We investigate the minimum of the specification robustness value for 10 experiments over 35 BO iterations. The averages of minimum robustness values are -0.3616, -0.4920, -0.5513, and -0.2910 for the first and the second multi-fidelity scenarios, standard BO, and random search, respectively.</p>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Fig. 6. Number of discovered counterexamples per cost by multi-fidelity BO, BO, and random search methods.</p>
<p><img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Fig. 7. Comparison between the number of counterexamples found by multi-fidelity BO, BO, and random search over 35 BO iterations.</p>
<p><img alt="img-6.jpeg" src="img-6.jpeg" /></p>
<p>Fig. 8. Number of discovered counterexamples per cost by multi-fidelity BO, BO, and random search.</p>
<h2>V. CONCLUSIONS</h2>
<p>We presented an algorithm for addressing the falsification problem of closed-loop control systems under uncertainty based on multi-fidelity Bayesian optimization. This approach can bring many benefits when searching for counterexamples. The algorithm is able to incorporate evaluations from low-fidelity and high-fidelity simulators to reduce the number of costly experiments required on the high-fidelity simulator. With respect to other approaches, we demonstrated the applicability of the proposed method to three environments and showed considerable savings in computational cost through switching between low-fidelity and high-fidelity simulators. Future work includes extending the proposed framework to handle more complex correlations between low-fidelity and high-fidelity simulators.</p>
<h2>ACKNOWLEDGEMENTS</h2>
<p>This research was supported in part by the National Science Foundation (NSF) under Award No. 2132060 and the Federal Aviation Administration (FAA) under Contract No. 692M15-21-T-00022.</p>
<h2>REFERENCES</h2>
<ul>
<li>[1] A. Donzé and O. Maler, "Robust satisfaction of temporal logic over real-valued signals," in <em>International Conference on Formal Modeling and Analysis of Timed Systems</em>, Springer, 2010, pp. 92–106.</li>
<li>[2] G. E. Fainekos and G. J. Pappas, "Robustness of temporal logic specifications for continuous-time signals," <em>Theoretical Computer Science</em>, vol. 410, no. 42, pp. 4262–4291, 2009.</li>
<li>[3] A. Corso, R. Moss, M. Koren, R. Lee, and M. Kochenderfer, "A survey of algorithms for black-box safety validation of cyber-physical systems," <em>Journal of Artificial Intelligence Research</em>, vol. 72, pp. 377–428, 2021.</li>
<li>[4] J. Mockus, <em>Bayesian approach to global optimization: theory and applications</em>. Springer Science &amp; Business Media, 2012, vol. 37.</li>
<li>[5] A. Baheri and C. Vermillion, "Combined plant and controller design using batch Bayesian optimization: A case study in airborne wind energy systems," <em>Journal of Dynamic Systems, Measurement, and Control</em>, vol. 141, no. 9, 2019.</li>
<li>[6] A. Baheri, S. Bin-Karim, A. Bafandeh, and C. Vermillion, "Realtime control using Bayesian optimization: A case study in airborne wind energy systems," <em>Control Engineering Practice</em>, vol. 69, pp. 131–140, 2017.</li>
<li>[7] M. Cutler, T. J. Walsh, and J. P. How, "Reinforcement learning with multi-fidelity simulators," in <em>IEEE International Conference on Robotics and Automation (ICRA)</em>, IEEE, 2014, pp. 3888–3895.</li>
<li>[8] J. Deshmukh, M. Horvat, X. Jin, R. Majumdar, and V. S. Prabhu, "Testing cyber-physical systems through Bayesian optimization," <em>ACM Transactions on Embedded Computing Systems (TECS)</em>, vol. 16, no. 5s, pp. 1–18, 2017.</li>
<li>[9] F. Berkenkamp, A. Krause, and A. P. Schoellig, "Bayesian optimization with safety constraints: Safe and automatic parameter tuning in robotics," <em>Machine Learning</em>, pp. 1–35, 2021.</li>
<li>[10] Y. Sui, V. Zhuang, J. Burdick, and Y. Yue, "Stagewise safe Bayesian optimization with Gaussian processes," in <em>International Conference on Machine Learning (ICML)</em>, 2018, pp. 4781–4789.</li>
<li>[11] S. Ghosh, F. Berkenkamp, G. Ranade, S. Qadeer, and A. Kapoor, "Verifying controllers against adversarial examples with Bayesian optimization," in <em>IEEE International Conference on Robotics and Automation (ICRA)</em>, IEEE, 2018, pp. 7306–7313.</li>
<li>[12] Y. Kim, R. Allmendinger, and M. López-Ibáñez, "Safe learning and optimization techniques: Towards a survey of the state of the art," in <em>International Workshop on the Foundations of Trustworthy AI Integrating Learning, Optimization and Reasoning</em>, 2020, pp. 123–139.</li>
<li>[13] A. Marco, F. Berkenkamp, P. Hennig, A. P. Schoellig, A. Krause, S. Schaal, and S. Trimpe, "Virtual vs. real: Trading off simulations and physical experiments in reinforcement learning with Bayesian optimization," in <em>IEEE International Conference on Robotics and Automation (ICRA)</em>, 2017, pp. 1557–1563.</li>
<li>[14] M. Koren, A. Nassar, and M. J. Kochenderfer, "Finding failures in high-fidelity simulation using adaptive stress testing and the backward algorithm," in <em>IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</em>, 2021, pp. 5944–5949.</li>
<li>[15] J. J. Beard and A. Baheri, "Safety verification of autonomous systems: A multi-fidelity reinforcement learning approach," <em>arXiv preprint arXiv:2203.03451</em>, 2022.</li>
<li>[16] A. Baheri, H. Ren, B. Johnson, P. Razzaghi, and P. Wei, "A verification framework for certifying learning-based safety-critical aviation systems," in <em>AIAA AVIATION</em>, 2022.</li>
<li>[17] C. K. Williams and C. E. Rasmussen, <em>Gaussian processes for machine learning</em>. MIT Press, 2006.</li>
<li>[18] P. Hennig and C. J. Schuler, "Entropy search for information-efficient global optimization," <em>Journal of Machine Learning Research</em>, vol. 13, no. 6, pp. 1809–1837, 2012.</li>
<li>[19] L. Le Gratiet and J. Garnier, "Recursive co-kriging model for design of computer experiments with multiple levels of fidelity," <em>International Journal for Uncertainty Quantification</em>, vol. 4, no. 5, pp. 365–386, 2014.</li>
<li>[20] G. Brockman, V. Cheung, L. Pettersson, J. Schneider, J. Schulman, J. Tang, and W. Zaremba, "OpenAI Gym," <em>arXiv preprint arXiv:1606.01540</em>, 2016.</li>
<li>[21] J. Schulman, F. Wolski, P. Dhariwal, A. Radford, and O. Klimov, "Proximal policy optimization algorithms," <em>arXiv preprint arXiv:1707.06347</em>, 2017.</li>
<li>[22] T. P. Lillicrap, J. J. Hunt, A. Pritzel, N. Heess, T. Erez, Y. Tassa, D. Silver, and D. Wierstra, "Continuous control with deep reinforcement learning," in <em>International Conference on Learning Representations (ICLR)</em>, 2016.</li>
</ul>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{1}$ https://github.com/ZahraShahrooei/MFBO-for-falsification&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>