<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-168 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-168</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-168</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-8.html">extraction-schema-8</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of evaluations of LLMs on theory-of-mind tasks, focusing on model architecture, training data, task performance, explicit mental state and recursive belief representations, limitations, and proposed improvements.</div>
                <p><strong>Paper ID:</strong> paper-a5378efef0f3942fd2639e2e6e9996bf9edc59b2</p>
                <p><strong>Cost:</strong> 0.004</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e168.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e168.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of evaluations of LLMs on theory-of-mind tasks, focusing on model architecture, training data, task performance, explicit mental state and recursive belief representations, limitations, and proposed improvements.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ToMi</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Theory of Mind benchmark (ToMi)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A benchmark designed to evaluate the theory of mind capabilities of language models through story-based tasks, focusing on first-order and second-order beliefs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Theory of Mind in Large Language Models: Assessment and Enhancement</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ToMi</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>A benchmark that enhances data generation for evaluating mental state reasoning in language models, incorporating complexity with random distractors.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>N/A</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_nature</strong></td>
                            <td>Synthetic data generated from templates, focusing on narrative stories.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>ToMi</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Evaluates the ability to infer mental states through questions related to characters' beliefs and actions in narrative contexts.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>first-order and second-order belief</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Demonstrated effectiveness in evaluating LLMs' ToM capabilities.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Template-based question generation and story accuracy assessment.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_reported</strong></td>
                            <td>Relies on synthetic data, which may not reflect real-world scenarios accurately.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_of_mental_state_representation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_of_recursive_belief_modeling</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>multimodal_grounding_reported</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>symbolic_hybrid_methods</strong></td>
                            <td>N/A</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>N/A</td>
                        </tr>
                        <tr>
                            <td><strong>proposed_improvements</strong></td>
                            <td>Incorporation of more complex narratives and real-world scenarios.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_of_model_size</strong></td>
                            <td>N/A</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_performance</strong></td>
                            <td>N/A</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e168.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e168.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of evaluations of LLMs on theory-of-mind tasks, focusing on model architecture, training data, task performance, explicit mental state and recursive belief representations, limitations, and proposed improvements.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>HI-TOM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Higher-Order Theory of Mind benchmark (HI-TOM)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A benchmark that includes higher-order ToM questions to assess LLMs' reasoning capabilities beyond second-order beliefs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Theory of Mind in Large Language Models: Assessment and Enhancement</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>HI-TOM</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>A benchmark that evaluates higher-order ToM reasoning through automatically generated stories and questions.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>N/A</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_nature</strong></td>
                            <td>Automatically generated narratives based on templates inspired by established psychological tests.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>HI-TOM</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Assesses reasoning levels from zeroth to fourth order in ToM tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>higher-order belief</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Designed to evaluate complex reasoning but lacks extensive empirical results.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Template-based story generation with multiple questions per narrative.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_reported</strong></td>
                            <td>Limited to narrative formats and may not capture dynamic interactions.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_of_mental_state_representation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_of_recursive_belief_modeling</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>multimodal_grounding_reported</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>symbolic_hybrid_methods</strong></td>
                            <td>N/A</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>N/A</td>
                        </tr>
                        <tr>
                            <td><strong>proposed_improvements</strong></td>
                            <td>Integration of more diverse scenarios and interactive elements.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_of_model_size</strong></td>
                            <td>N/A</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_performance</strong></td>
                            <td>N/A</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e168.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e168.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of evaluations of LLMs on theory-of-mind tasks, focusing on model architecture, training data, task performance, explicit mental state and recursive belief representations, limitations, and proposed improvements.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>FANTOM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Conversational Theory of Mind benchmark (FANTOM)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A benchmark that uses LLM-generated conversations to evaluate ToM capabilities in more realistic social contexts.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Theory of Mind in Large Language Models: Assessment and Enhancement</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>FANTOM</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>A benchmark that evaluates ToM through conversations generated by LLMs, focusing on belief-related questions.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>N/A</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_nature</strong></td>
                            <td>Conversations generated by LLMs on various topics.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>FANTOM</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Evaluates the ability to infer beliefs and intentions in conversational contexts.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>first-order and second-order belief</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Highlights the challenges of evaluating ToM in conversational settings.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Open-ended and multiple-choice questions based on LLM-generated dialogues.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_reported</strong></td>
                            <td>Limited to small talk and lacks prior knowledge about characters.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_of_mental_state_representation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_of_recursive_belief_modeling</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>multimodal_grounding_reported</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>symbolic_hybrid_methods</strong></td>
                            <td>N/A</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>N/A</td>
                        </tr>
                        <tr>
                            <td><strong>proposed_improvements</strong></td>
                            <td>Incorporation of more complex conversational scenarios.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_of_model_size</strong></td>
                            <td>N/A</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_performance</strong></td>
                            <td>N/A</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e168.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e168.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of evaluations of LLMs on theory-of-mind tasks, focusing on model architecture, training data, task performance, explicit mental state and recursive belief representations, limitations, and proposed improvements.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>NegotiationToM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Negotiation Theory of Mind benchmark (NegotiationToM)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A benchmark designed to evaluate ToM in negotiation scenarios, assessing multiple rounds of dialogue.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Theory of Mind in Large Language Models: Assessment and Enhancement</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>NegotiationToM</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>A benchmark that rigorously evaluates ToM in negotiation contexts, focusing on desires and intentions.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>N/A</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_nature</strong></td>
                            <td>Based on negotiation scenarios from the CaSiNo dataset.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>NegotiationToM</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Assesses the ability to understand and predict mental states in negotiation dialogues.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>second-order belief</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>First of its kind for negotiation contexts but remains passive.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Multi-choice and ranking questions based on dialogue interactions.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_reported</strong></td>
                            <td>Passive evaluation and potential data contamination from existing datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_of_mental_state_representation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_of_recursive_belief_modeling</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>multimodal_grounding_reported</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>symbolic_hybrid_methods</strong></td>
                            <td>N/A</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>N/A</td>
                        </tr>
                        <tr>
                            <td><strong>proposed_improvements</strong></td>
                            <td>Development of active benchmarks for dynamic ToM evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_of_model_size</strong></td>
                            <td>N/A</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_performance</strong></td>
                            <td>N/A</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Towards a holistic landscape of situated theory of mind in large language models <em>(Rating: 2)</em></li>
                <li>A benchmark for stress-testing machine theory of mind in interactions <em>(Rating: 2)</em></li>
                <li>MMToM-QA: Multimodal theory of mind question answering <em>(Rating: 2)</em></li>
                <li>OpenToM: A comprehensive benchmark for evaluating theory-of-mind reasoning capabilities of large language models <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-168",
    "paper_id": "paper-a5378efef0f3942fd2639e2e6e9996bf9edc59b2",
    "extraction_schema_id": "extraction-schema-8",
    "extracted_data": [
        {
            "name_short": "ToMi",
            "name_full": "Theory of Mind benchmark (ToMi)",
            "brief_description": "A benchmark designed to evaluate the theory of mind capabilities of language models through story-based tasks, focusing on first-order and second-order beliefs.",
            "citation_title": "Theory of Mind in Large Language Models: Assessment and Enhancement",
            "mention_or_use": "use",
            "model_name": "ToMi",
            "model_description": "A benchmark that enhances data generation for evaluating mental state reasoning in language models, incorporating complexity with random distractors.",
            "model_size": "N/A",
            "training_data_nature": "Synthetic data generated from templates, focusing on narrative stories.",
            "task_name": "ToMi",
            "task_description": "Evaluates the ability to infer mental states through questions related to characters' beliefs and actions in narrative contexts.",
            "task_type": "first-order and second-order belief",
            "performance": "Demonstrated effectiveness in evaluating LLMs' ToM capabilities.",
            "evaluation_method": "Template-based question generation and story accuracy assessment.",
            "limitations_reported": "Relies on synthetic data, which may not reflect real-world scenarios accurately.",
            "evidence_of_mental_state_representation": true,
            "evidence_of_recursive_belief_modeling": true,
            "multimodal_grounding_reported": false,
            "symbolic_hybrid_methods": "N/A",
            "counter_evidence": "N/A",
            "proposed_improvements": "Incorporation of more complex narratives and real-world scenarios.",
            "impact_of_model_size": "N/A",
            "comparison_to_human_performance": "N/A",
            "uuid": "e168.0"
        },
        {
            "name_short": "HI-TOM",
            "name_full": "Higher-Order Theory of Mind benchmark (HI-TOM)",
            "brief_description": "A benchmark that includes higher-order ToM questions to assess LLMs' reasoning capabilities beyond second-order beliefs.",
            "citation_title": "Theory of Mind in Large Language Models: Assessment and Enhancement",
            "mention_or_use": "use",
            "model_name": "HI-TOM",
            "model_description": "A benchmark that evaluates higher-order ToM reasoning through automatically generated stories and questions.",
            "model_size": "N/A",
            "training_data_nature": "Automatically generated narratives based on templates inspired by established psychological tests.",
            "task_name": "HI-TOM",
            "task_description": "Assesses reasoning levels from zeroth to fourth order in ToM tasks.",
            "task_type": "higher-order belief",
            "performance": "Designed to evaluate complex reasoning but lacks extensive empirical results.",
            "evaluation_method": "Template-based story generation with multiple questions per narrative.",
            "limitations_reported": "Limited to narrative formats and may not capture dynamic interactions.",
            "evidence_of_mental_state_representation": true,
            "evidence_of_recursive_belief_modeling": true,
            "multimodal_grounding_reported": false,
            "symbolic_hybrid_methods": "N/A",
            "counter_evidence": "N/A",
            "proposed_improvements": "Integration of more diverse scenarios and interactive elements.",
            "impact_of_model_size": "N/A",
            "comparison_to_human_performance": "N/A",
            "uuid": "e168.1"
        },
        {
            "name_short": "FANTOM",
            "name_full": "Conversational Theory of Mind benchmark (FANTOM)",
            "brief_description": "A benchmark that uses LLM-generated conversations to evaluate ToM capabilities in more realistic social contexts.",
            "citation_title": "Theory of Mind in Large Language Models: Assessment and Enhancement",
            "mention_or_use": "use",
            "model_name": "FANTOM",
            "model_description": "A benchmark that evaluates ToM through conversations generated by LLMs, focusing on belief-related questions.",
            "model_size": "N/A",
            "training_data_nature": "Conversations generated by LLMs on various topics.",
            "task_name": "FANTOM",
            "task_description": "Evaluates the ability to infer beliefs and intentions in conversational contexts.",
            "task_type": "first-order and second-order belief",
            "performance": "Highlights the challenges of evaluating ToM in conversational settings.",
            "evaluation_method": "Open-ended and multiple-choice questions based on LLM-generated dialogues.",
            "limitations_reported": "Limited to small talk and lacks prior knowledge about characters.",
            "evidence_of_mental_state_representation": true,
            "evidence_of_recursive_belief_modeling": false,
            "multimodal_grounding_reported": false,
            "symbolic_hybrid_methods": "N/A",
            "counter_evidence": "N/A",
            "proposed_improvements": "Incorporation of more complex conversational scenarios.",
            "impact_of_model_size": "N/A",
            "comparison_to_human_performance": "N/A",
            "uuid": "e168.2"
        },
        {
            "name_short": "NegotiationToM",
            "name_full": "Negotiation Theory of Mind benchmark (NegotiationToM)",
            "brief_description": "A benchmark designed to evaluate ToM in negotiation scenarios, assessing multiple rounds of dialogue.",
            "citation_title": "Theory of Mind in Large Language Models: Assessment and Enhancement",
            "mention_or_use": "use",
            "model_name": "NegotiationToM",
            "model_description": "A benchmark that rigorously evaluates ToM in negotiation contexts, focusing on desires and intentions.",
            "model_size": "N/A",
            "training_data_nature": "Based on negotiation scenarios from the CaSiNo dataset.",
            "task_name": "NegotiationToM",
            "task_description": "Assesses the ability to understand and predict mental states in negotiation dialogues.",
            "task_type": "second-order belief",
            "performance": "First of its kind for negotiation contexts but remains passive.",
            "evaluation_method": "Multi-choice and ranking questions based on dialogue interactions.",
            "limitations_reported": "Passive evaluation and potential data contamination from existing datasets.",
            "evidence_of_mental_state_representation": true,
            "evidence_of_recursive_belief_modeling": false,
            "multimodal_grounding_reported": false,
            "symbolic_hybrid_methods": "N/A",
            "counter_evidence": "N/A",
            "proposed_improvements": "Development of active benchmarks for dynamic ToM evaluation.",
            "impact_of_model_size": "N/A",
            "comparison_to_human_performance": "N/A",
            "uuid": "e168.3"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Towards a holistic landscape of situated theory of mind in large language models",
            "rating": 2
        },
        {
            "paper_title": "A benchmark for stress-testing machine theory of mind in interactions",
            "rating": 2
        },
        {
            "paper_title": "MMToM-QA: Multimodal theory of mind question answering",
            "rating": 2
        },
        {
            "paper_title": "OpenToM: A comprehensive benchmark for evaluating theory-of-mind reasoning capabilities of large language models",
            "rating": 2
        }
    ],
    "cost": 0.00401595,
    "model_str": null
}</code></pre>
        </div>

    </div>
</body>
</html>