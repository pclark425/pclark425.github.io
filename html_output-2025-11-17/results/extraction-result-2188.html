<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2188 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2188</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2188</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-58.html">extraction-schema-58</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of validation approaches in automated or AI-driven scientific research systems, including experimental validation, computational validation, simulation-based validation, and comparisons between these approaches.</div>
                <p><strong>Paper ID:</strong> paper-277621634</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2504.03810v1.pdf" target="_blank">Hierarchically Encapsulated Representation for Protocol Design in Self-Driving Labs</a></p>
                <p><strong>Paper Abstract:</strong> Self-driving laboratories have begun to replace human experimenters in performing single experimental skills or predetermined experimental protocols. However, as the pace of idea iteration in scientific research has been intensified by Artificial Intelligence, the demand for rapid design of new protocols for new discoveries become evident. Efforts to automate protocol design have been initiated, but the capabilities of knowledge-based machine designers, such as Large Language Models, have not been fully elicited, probably for the absence of a systematic representation of experimental knowledge, as opposed to isolated, flatten pieces of information. To tackle this issue, we propose a multi-faceted, multi-scale representation, where instance actions, generalized operations, and product flow models are hierarchically encapsulated using Domain-Specific Languages. We further develop a data-driven algorithm based on non-parametric modeling that autonomously customizes these representations for specific domains. The proposed representation is equipped with various machine designers to manage protocol design tasks, including planning, modification, and adjustment. The results demonstrate that the proposed method could effectively complement Large Language Models in the protocol design process, serving as an auxiliary module in the realm of machine-assisted scientific exploration.</p>
                <p><strong>Cost:</strong> 0.019</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2188.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2188.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of validation approaches in automated or AI-driven scientific research systems, including experimental validation, computational validation, simulation-based validation, and comparisons between these approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Reciprocative DSL verification</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Reciprocative Verification over Dual Domain-Specific Languages (Operation- and Product-Flow-Centric Views)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A computational verification mechanism that cross-checks operation pre/postconditions against explicit product-flow states by running two interacting verification threads (operation verification and product-flow verification) implemented as DSL program checks and producing feedback for iterative refinement.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_or_method_name</strong></td>
                            <td>Reciprocative DSL verification</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Laboratory protocol design / Experimental biology (general experimental sciences)</td>
                        </tr>
                        <tr>
                            <td><strong>validation_type</strong></td>
                            <td>computational validation</td>
                        </tr>
                        <tr>
                            <td><strong>validation_description</strong></td>
                            <td>Implements two verifier threads: (1) operation verification that checks each operation's preconditions are satisfiable from previously produced products and that postconditions are well-defined; (2) product-flow verification that tracks each product FlowUnit ensuring it is produced by the stated predecessor operation and has required properties for the successor operation. Verification runs on the generated DSL programs and emits error messages (e.g. missing product) which are fed back to LLM designers in a feedback-refine loop until the program passes verification or a max iteration limit is reached. LLMs implement helper functions CHECKOPCONDITIONS and CHECKPROPERTIES for natural-language-derived checks.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_fidelity</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation_performed</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_simulation_vs_experiment</strong></td>
                            <td>Not applicable — verification is a static, symbolic/computational check of DSL programs; no wet-lab experiments are performed for verification comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_success_rate</strong></td>
                            <td>Not reported as a single percentage; success inferred from improved benchmark metrics (e.g., EE+ and EI+ outperform counterparts in held-out protocol consistency measures) rather than direct pass/fail counts of verifier runs.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_validation_standards</strong></td>
                            <td>The paper frames DSL program verification as a program-level soundness/completeness check but states this is not equivalent to formal domain certification; domain experts remain the gold-standard certifiers.</td>
                        </tr>
                        <tr>
                            <td><strong>when_simulation_sufficient</strong></td>
                            <td>The paper does not claim verification alone is sufficient; it explicitly states DSL verification is helpful but inadequate to replace manual experimental certification.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_failures</strong></td>
                            <td>No simulation used, so no simulation failures described; the authors note DSL verification can miss long-tail, rare failure modes and cannot guarantee elimination of false positives.</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>Quantified indirectly via downstream protocol-design benchmark improvements (statistical tests: paired t-tests with reported t statistics and p-values) and standard errors reported in result tables; no explicit uncertainty propagation for the verifier outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>fabrication_detection</strong></td>
                            <td>The verifier produces concrete error messages for missing/incorrect pre/postconditions (e.g. "Error: The product {product} required by operation {operation} at step {i} is not available from previous steps."); these messages are used for refinement but are not described as a general detector of fabricated/wrong scientific claims.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_cost_time</strong></td>
                            <td>Runs purely computationally; reported overall computational costs for design tasks: representation generation preprocessing (GPT calls) ≈ $60, designers ≈ $10; verifier is part of DSL pipeline and feedback loop—no separate timing for verifier alone given. DPMM iterations for operation-centric view ≈ 55 s per iteration; product-centric ≈ 2 s per iteration (for representation generation).</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_validation_approach</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_limitations</strong></td>
                            <td>DSL verification is symbolic and cannot replace wet-lab certification; it may miss rare or tacit domain-specific failure modes and is dependent on the quality of the extracted DSL artifacts; cannot guarantee safety or complete correctness in engineering contexts.</td>
                        </tr>
                        <tr>
                            <td><strong>acceptance_credibility</strong></td>
                            <td>Authors argue DSL verification increases plausibility/coherence of generated protocols and thus acceptance, but stress human domain experts are still required for final certification; provide no direct sociological evidence, only improved benchmark scores.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_gold_standard</strong></td>
                            <td>Gold standard remains manual expert certification. The paper shows computational DSL verification improves similarity metrics against human ground-truth protocols but explicitly states it is insufficient to replace manual certification; no numeric comparison to wet-lab success rates is provided.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2188.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2188.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of validation approaches in automated or AI-driven scientific research systems, including experimental validation, computational validation, simulation-based validation, and comparisons between these approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>External verifier + feedback-refine loop</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>External DSL Verifier with LLM Feedback-Refine Loop (Self-Refine style)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An external verification architecture where an LLM generates a DSL program and an external DSL-based verifier checks it, returns structured error messages, and the LLM iteratively refines the plan until verification passes or a maximum number of iterations is reached.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_or_method_name</strong></td>
                            <td>External verifier + feedback-refine loop</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Automated protocol synthesis for experimental sciences / AI-assisted laboratory automation</td>
                        </tr>
                        <tr>
                            <td><strong>validation_type</strong></td>
                            <td>computational validation (iterative symbolic verification)</td>
                        </tr>
                        <tr>
                            <td><strong>validation_description</strong></td>
                            <td>Verifier inspects both operation-view DSL and product-view DSL programs: verifies that preconditions are outputs of prior steps and that postconditions are used later; in dual-view (EE+) it checks that operations cause corresponding product state transitions. When mismatches occur the verifier returns explicit error messages; LLM (using self-refinement strategy) takes feedback and revises the program. The loop proceeds until verification success or iteration cap; best result selected based on verification status.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_fidelity</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation_performed</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_simulation_vs_experiment</strong></td>
                            <td>Not applicable — approach is evaluated by computational comparison to held-out human protocols rather than by wet-lab execution.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_success_rate</strong></td>
                            <td>Not reported as direct pass/fail counts for the loop; success inferred by improved evaluation metrics (EE+ shows higher IoU and sequence similarity versus baselines).</td>
                        </tr>
                        <tr>
                            <td><strong>domain_validation_standards</strong></td>
                            <td>Standards are operationalized as DSL pre/postcondition consistency and product-flow coherence rather than physical validation; paper emphasizes this is a domain-level consistency standard but not a substitute for laboratory certification.</td>
                        </tr>
                        <tr>
                            <td><strong>when_simulation_sufficient</strong></td>
                            <td>The authors discuss that a high-fidelity digital twin could in principle be used for automated certification, but such simulation resources are not available in this work and would require extensive development.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_failures</strong></td>
                            <td>No simulations were executed; authors note constructing digital twins is challenging and out of scope.</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>Statistical validation of resulting protocol quality is provided (paired t-tests, standard errors) but no probabilistic confidence scores for verifier outputs are provided.</td>
                        </tr>
                        <tr>
                            <td><strong>fabrication_detection</strong></td>
                            <td>Verifier detects logical inconsistencies within the DSL representation (missing origin of product, unused postconditions), serving as a syntactic/semantic filter against nonsensical generated protocols, but is not a general anti-fabrication detector for content beyond these checks.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_cost_time</strong></td>
                            <td>Computation costs for the overall pipeline (representation generation and design) are reported (~$70 total for GPT calls across tasks); no per-iteration wall-clock for the verifier loop is provided. DPMM representation generation timings given elsewhere (55 s/iteration op-centric).</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_validation_approach</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_limitations</strong></td>
                            <td>Cannot detect domain tacit knowledge issues and rare long-tail safety issues; limited by DSL extraction accuracy and by LLM reliability in applying corrective feedback.</td>
                        </tr>
                        <tr>
                            <td><strong>acceptance_credibility</strong></td>
                            <td>Authors present quantitative improvements relative to baselines as evidence of increased credibility, but emphasize need for human expert certification for final acceptance.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_gold_standard</strong></td>
                            <td>Compared computationally to held-out human-authored protocols via multi-dimensional metrics; no wet-lab or clinical gold-standard comparison performed.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2188.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2188.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of validation approaches in automated or AI-driven scientific research systems, including experimental validation, computational validation, simulation-based validation, and comparisons between these approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Held-out protocol benchmark</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Computational Benchmarking Against Held-Out Human-Authored Protocols (IoU/Sequence/Parameter Metrics)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A computational validation framework that measures consistency between generated protocols and withheld human ground-truth protocols using six dimensions (IoU on operations, products, devices; sequence similarity; goal similarity; parameter-wise similarity) and statistical tests.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_or_method_name</strong></td>
                            <td>Held-out protocol benchmark (IoU & Sim metrics)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Experimental protocol design / Computational evaluation</td>
                        </tr>
                        <tr>
                            <td><strong>validation_type</strong></td>
                            <td>computational validation (benchmarking against held-out ground truth)</td>
                        </tr>
                        <tr>
                            <td><strong>validation_description</strong></td>
                            <td>The authors construct a testing set by excluding an outlier subset from each domain's corpora; evaluate generated protocols against ground-truth via six metrics: IoU(Op), IoU(Prod), IoU(Dev), Sim(Exec) (sequence alignment), Sim(Goal) (cosine similarity over serialized structure), Sim(Param) (parameter-wise cosine similarity). They report mean scores, standard errors, and paired-sample t-tests comparing methods (t-statistics and p-values). The testing set included 140 novel protocols (1757 steps) across domains.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_fidelity</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation_performed</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_simulation_vs_experiment</strong></td>
                            <td>No simulation-to-experiment comparisons; evaluation is between algorithm outputs and held-out human-written protocols.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_success_rate</strong></td>
                            <td>Expressed via metric scores (e.g., EE+ and EI+ achieved substantially higher IoU and similarity metrics; specific numeric averages and SEs are reported in result tables), but not a single overall success percentage.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_validation_standards</strong></td>
                            <td>The paper adopts protocol-consistency metrics as proxy validation standards for automated protocol design; emphasizes these as objective but not equivalent to experimental confirmation.</td>
                        </tr>
                        <tr>
                            <td><strong>when_simulation_sufficient</strong></td>
                            <td>Not discussed in the benchmark context; paper asserts computational similarity metrics are helpful proxies for plausibility but not replacements for wet-lab validation.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_failures</strong></td>
                            <td>Not applicable.</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>Reported via standard errors for metric means and paired t-tests with p-values; tables give SE and t-test statistics (e.g., t(278) values and p < .0001 for method comparisons).</td>
                        </tr>
                        <tr>
                            <td><strong>fabrication_detection</strong></td>
                            <td>Not directly targeted; held-out benchmark can reveal implausible or low-similarity outputs but doesn't detect fabricated experimental outcomes.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_cost_time</strong></td>
                            <td>Benchmarking run costs modest; overall machine designer GPT costs ~ $10 across 7 methods and 140 protocols. No experimental resource costs involved.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_validation_approach</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>validation_limitations</strong></td>
                            <td>Benchmark compares to published protocols only, so success means reproducing or matching human-written protocols—not proving wet-lab viability; dataset sizes vary by domain which may bias results.</td>
                        </tr>
                        <tr>
                            <td><strong>acceptance_credibility</strong></td>
                            <td>Authors use benchmark results and statistical significance to argue for improved computational plausibility and likely increased community acceptance of LLM-assisted designs, but stress that final credibility requires human certification or wet-lab validation.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_gold_standard</strong></td>
                            <td>Gold standard (wet-lab confirmation) not performed; benchmark compared methods against human-authored protocols only.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2188.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2188.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of validation approaches in automated or AI-driven scientific research systems, including experimental validation, computational validation, simulation-based validation, and comparisons between these approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Perplexity-based memorization check</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Perplexity Comparison to Detect LLM Memorization of Test Protocols</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A computational check using LLM perplexity on held-out novel protocol prefixes versus a synthesized reference set to assess whether the LLM had memorized test-set protocol content.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_or_method_name</strong></td>
                            <td>Perplexity-based memorization check</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Language-model evaluation within protocol processing (NLP applied to scientific protocols)</td>
                        </tr>
                        <tr>
                            <td><strong>validation_type</strong></td>
                            <td>computational validation (model-training-data-memorization detection)</td>
                        </tr>
                        <tr>
                            <td><strong>validation_description</strong></td>
                            <td>Authors synthesize a reference set similar in style to protocol steps using gpt-4o mini, sample 100 sequences from test and reference sets, truncate to prefixes, prompt the LLM to predict next tokens and compute perplexity. They compare average perplexity between the test set and reference set; significantly higher perplexity on the test set indicates the LLM did not memorize the test protocols (t(198)=3.040, p < .05).</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_fidelity</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation_performed</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_simulation_vs_experiment</strong></td>
                            <td>Not applicable.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_success_rate</strong></td>
                            <td>Authors report a statistically significant difference in perplexity (test set higher), but do not provide a percent success metric for detection.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_validation_standards</strong></td>
                            <td>This is an accepted proxy (per prior literature) for detecting memorization of data by LLMs; authors cite Carlini et al. methods and Skywork methodology.</td>
                        </tr>
                        <tr>
                            <td><strong>when_simulation_sufficient</strong></td>
                            <td>Not applicable.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_failures</strong></td>
                            <td>Not applicable.</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>Statistical test provided (t-test with degrees of freedom and p-value) comparing perplexity distributions; no confidence intervals reported for the perplexity means.</td>
                        </tr>
                        <tr>
                            <td><strong>fabrication_detection</strong></td>
                            <td>Used to judge whether generated outputs could be memorized reproductions rather than generalizable synthesis; not a detector of fabricated experimental results per se.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_cost_time</strong></td>
                            <td>Perplexity evaluation performed on small sampled sets; no cost/time metrics provided for this step specifically.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_validation_approach</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>validation_limitations</strong></td>
                            <td>Perplexity-based checks detect memorization risk but cannot guarantee lack of data leakage or assess factual correctness of generated protocols.</td>
                        </tr>
                        <tr>
                            <td><strong>acceptance_credibility</strong></td>
                            <td>Used to support the claim that LLM outputs are not simple memorized reproductions of test protocols, which strengthens credibility of benchmarking results.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_gold_standard</strong></td>
                            <td>Compared to synthesized reference set as a control; no wet-lab gold-standard involved.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2188.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2188.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of validation approaches in automated or AI-driven scientific research systems, including experimental validation, computational validation, simulation-based validation, and comparisons between these approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Manual expert certification</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Human Domain-Expert Certification and Cross-Validation of Designed Protocols</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A manual validation step where domain experts (Masters-level or higher) inspect candidate protocols, refine ground-truth selection, and certify applicability and safety; used as the final adjudicator for the testing set and recommended path for production deployment.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_or_method_name</strong></td>
                            <td>Manual expert certification (human-in-the-loop)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Experimental sciences (biology/medical/bioengineering/ecology)</td>
                        </tr>
                        <tr>
                            <td><strong>validation_type</strong></td>
                            <td>experimental (human/peer review-based validation) / other</td>
                        </tr>
                        <tr>
                            <td><strong>validation_description</strong></td>
                            <td>Domain experts manually inspect and cross-validate candidate novel protocols filtered by computational outlier detection; they discard misclassified ones, request further candidates, and refine ground-truth files. The IRB-approved human-in-the-loop process paid experts and gathered informed consent; the human experts are responsible for final certification before any wet-lab execution.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_fidelity</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation_performed</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_simulation_vs_experiment</strong></td>
                            <td>Manual certification is positioned as the practical gold-standard prior to any wet-lab execution; authors explicitly retain manual certification because DSL verification alone is insufficient.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_success_rate</strong></td>
                            <td>Not expressed as a numeric success rate; success manifested as curated testing set of 140 protocols validated by experts and used as ground-truth.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_validation_standards</strong></td>
                            <td>Authors align with standard operating practices in experimental sciences: human expert review and certification is required for engineering/lab automation deployment; DSL verification is complementary, not substitutive.</td>
                        </tr>
                        <tr>
                            <td><strong>when_simulation_sufficient</strong></td>
                            <td>Authors state that simulation (digital twins) could enable machine-based certification in the future but is not currently sufficient or available.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_failures</strong></td>
                            <td>No simulation used; authors discuss challenges and potential failures in building digital twins (granularity design, rule production) as reasons human certification remains necessary.</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>Human review process described qualitatively; dataset statistics (counts, steps) and IRB oversight reported but no formal inter-rater reliability metrics provided.</td>
                        </tr>
                        <tr>
                            <td><strong>fabrication_detection</strong></td>
                            <td>Human experts are considered the primary defense against fabricated or unsafe protocols; manual review intended to catch cases machine verifiers miss.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_cost_time</strong></td>
                            <td>Human expert labor: paid $22.5/h; IRB-approved process. Time per review not enumerated but testing set formation involved iterative checks between automated outlier detection and experts.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_validation_approach</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_limitations</strong></td>
                            <td>Labor-intensive, not scalable to all generated protocols; experts rely on tacit knowledge and may still miss rare failure modes; authors emphasize humans remain necessary until robust digital twins exist.</td>
                        </tr>
                        <tr>
                            <td><strong>acceptance_credibility</strong></td>
                            <td>Authors treat human certification as essential for community acceptance and safety; they argue DSL-based methods improve efficiency but do not obviate expert validation.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_gold_standard</strong></td>
                            <td>Manual expert certification is treated as the gold standard in the paper; computational methods are compared against it indirectly via similarity to human-authored protocols, but no wet-lab experiments were used to compare computational outputs to physical outcomes.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2188.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e2188.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of validation approaches in automated or AI-driven scientific research systems, including experimental validation, computational validation, simulation-based validation, and comparisons between these approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Digital twin / simulation discussion</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Digital Twin / High-Fidelity Simulation for Automated Protocol Certification (discussion/future work)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A discussion of high-fidelity simulation/digital twin approaches as a potential future route to automate wet-lab validation and certification, noting substantial practical challenges and being out of scope for this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_or_method_name</strong></td>
                            <td>Digital twin / High-fidelity simulation (proposed)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Laboratory automation / Experimental simulation / Digital twin engineering</td>
                        </tr>
                        <tr>
                            <td><strong>validation_type</strong></td>
                            <td>high-fidelity simulation (discussed, not implemented)</td>
                        </tr>
                        <tr>
                            <td><strong>validation_description</strong></td>
                            <td>Authors describe the aspiration to build digital twins that model experiments with sufficient granularity to predict, explain, and perform counterfactual analysis for unseen behaviors, which could enable machine-based certification; requirements would include exhaustive primitive principles, appropriate simulation granularity, rule production, and reward functions for MDP/HRL approaches. However, they note these efforts are labor-intensive and out of scope.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_fidelity</strong></td>
                            <td>Not implemented; fidelity requirements are described qualitatively: would need physics/chemistry modeling of system, precise state-space, and accurate transition dynamics; no numerical fidelity metrics are provided.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation_performed</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_simulation_vs_experiment</strong></td>
                            <td>Not applicable — no simulations executed. Authors explain that robust comparison would be required to validate such digital twins but is beyond this work.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_validation_standards</strong></td>
                            <td>Authors indicate that a viable digital twin must support prediction accuracy sufficient for certification, but do not provide formal domain thresholds; they warn that defining precise evaluation metrics for simulation-to-experiment distance (reward functions) is challenging.</td>
                        </tr>
                        <tr>
                            <td><strong>when_simulation_sufficient</strong></td>
                            <td>Paper suggests simulation could be sufficient if digital twins achieve high accuracy and cover tacit domain knowledge, but emphasizes development challenges: granularity, data-efficient model construction, and tacit knowledge injection.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_failures</strong></td>
                            <td>No concrete simulation failures reported (because none were run); authors highlight conceptual failure modes: overly coarse granularity, missing physical principles, or inadequate reward definition would render simulations insufficient.</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>Not addressed for hypothetical digital twins; authors note uncertainty quantification would be a necessary component but do not prescribe methods.</td>
                        </tr>
                        <tr>
                            <td><strong>fabrication_detection</strong></td>
                            <td>Not discussed specifically in simulation context; the authors suggest digital twins could improve detection of unrealistic behaviors if accurate.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_cost_time</strong></td>
                            <td>Authors state the effort would be labor-intensive and expensive (exhaustive design and data collection) but give no numerical cost estimates.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_validation_approach</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_limitations</strong></td>
                            <td>Practical implementation barriers: defining simulation granularity, collecting primitive principles and data, implementing rules, and creating reliable reward functions; insufficient data available currently for RL formulations.</td>
                        </tr>
                        <tr>
                            <td><strong>acceptance_credibility</strong></td>
                            <td>Authors opine high-fidelity digital twins would increase machine-certification credibility if successfully developed, but they acknowledge this is a long-term objective requiring significant resources.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_gold_standard</strong></td>
                            <td>No empirical comparison; paper positions digital twins as a possible route to approximate or replace manual certification only if built to high standards.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Digitization and validation of a chemical synthesis literature database in the chempu <em>(Rating: 2)</em></li>
                <li>Autonomous chemical research with large language models <em>(Rating: 2)</em></li>
                <li>Self-refine: Iterative refinement with self-feedback <em>(Rating: 2)</em></li>
                <li>Building an open representation for biological protocols <em>(Rating: 2)</em></li>
                <li>An integrated self-optimizing programmable chemical synthesis and reaction engine <em>(Rating: 1)</em></li>
                <li>Reconfigurable system for automated optimization of diverse chemical reactions <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2188",
    "paper_id": "paper-277621634",
    "extraction_schema_id": "extraction-schema-58",
    "extracted_data": [
        {
            "name_short": "Reciprocative DSL verification",
            "name_full": "Reciprocative Verification over Dual Domain-Specific Languages (Operation- and Product-Flow-Centric Views)",
            "brief_description": "A computational verification mechanism that cross-checks operation pre/postconditions against explicit product-flow states by running two interacting verification threads (operation verification and product-flow verification) implemented as DSL program checks and producing feedback for iterative refinement.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_or_method_name": "Reciprocative DSL verification",
            "scientific_domain": "Laboratory protocol design / Experimental biology (general experimental sciences)",
            "validation_type": "computational validation",
            "validation_description": "Implements two verifier threads: (1) operation verification that checks each operation's preconditions are satisfiable from previously produced products and that postconditions are well-defined; (2) product-flow verification that tracks each product FlowUnit ensuring it is produced by the stated predecessor operation and has required properties for the successor operation. Verification runs on the generated DSL programs and emits error messages (e.g. missing product) which are fed back to LLM designers in a feedback-refine loop until the program passes verification or a max iteration limit is reached. LLMs implement helper functions CHECKOPCONDITIONS and CHECKPROPERTIES for natural-language-derived checks.",
            "simulation_fidelity": null,
            "experimental_validation_performed": false,
            "comparison_simulation_vs_experiment": "Not applicable — verification is a static, symbolic/computational check of DSL programs; no wet-lab experiments are performed for verification comparisons.",
            "validation_success_rate": "Not reported as a single percentage; success inferred from improved benchmark metrics (e.g., EE+ and EI+ outperform counterparts in held-out protocol consistency measures) rather than direct pass/fail counts of verifier runs.",
            "domain_validation_standards": "The paper frames DSL program verification as a program-level soundness/completeness check but states this is not equivalent to formal domain certification; domain experts remain the gold-standard certifiers.",
            "when_simulation_sufficient": "The paper does not claim verification alone is sufficient; it explicitly states DSL verification is helpful but inadequate to replace manual experimental certification.",
            "simulation_failures": "No simulation used, so no simulation failures described; the authors note DSL verification can miss long-tail, rare failure modes and cannot guarantee elimination of false positives.",
            "uncertainty_quantification": "Quantified indirectly via downstream protocol-design benchmark improvements (statistical tests: paired t-tests with reported t statistics and p-values) and standard errors reported in result tables; no explicit uncertainty propagation for the verifier outputs.",
            "fabrication_detection": "The verifier produces concrete error messages for missing/incorrect pre/postconditions (e.g. \"Error: The product {product} required by operation {operation} at step {i} is not available from previous steps.\"); these messages are used for refinement but are not described as a general detector of fabricated/wrong scientific claims.",
            "validation_cost_time": "Runs purely computationally; reported overall computational costs for design tasks: representation generation preprocessing (GPT calls) ≈ $60, designers ≈ $10; verifier is part of DSL pipeline and feedback loop—no separate timing for verifier alone given. DPMM iterations for operation-centric view ≈ 55 s per iteration; product-centric ≈ 2 s per iteration (for representation generation).",
            "hybrid_validation_approach": true,
            "validation_limitations": "DSL verification is symbolic and cannot replace wet-lab certification; it may miss rare or tacit domain-specific failure modes and is dependent on the quality of the extracted DSL artifacts; cannot guarantee safety or complete correctness in engineering contexts.",
            "acceptance_credibility": "Authors argue DSL verification increases plausibility/coherence of generated protocols and thus acceptance, but stress human domain experts are still required for final certification; provide no direct sociological evidence, only improved benchmark scores.",
            "comparison_to_gold_standard": "Gold standard remains manual expert certification. The paper shows computational DSL verification improves similarity metrics against human ground-truth protocols but explicitly states it is insufficient to replace manual certification; no numeric comparison to wet-lab success rates is provided.",
            "uuid": "e2188.0"
        },
        {
            "name_short": "External verifier + feedback-refine loop",
            "name_full": "External DSL Verifier with LLM Feedback-Refine Loop (Self-Refine style)",
            "brief_description": "An external verification architecture where an LLM generates a DSL program and an external DSL-based verifier checks it, returns structured error messages, and the LLM iteratively refines the plan until verification passes or a maximum number of iterations is reached.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_or_method_name": "External verifier + feedback-refine loop",
            "scientific_domain": "Automated protocol synthesis for experimental sciences / AI-assisted laboratory automation",
            "validation_type": "computational validation (iterative symbolic verification)",
            "validation_description": "Verifier inspects both operation-view DSL and product-view DSL programs: verifies that preconditions are outputs of prior steps and that postconditions are used later; in dual-view (EE+) it checks that operations cause corresponding product state transitions. When mismatches occur the verifier returns explicit error messages; LLM (using self-refinement strategy) takes feedback and revises the program. The loop proceeds until verification success or iteration cap; best result selected based on verification status.",
            "simulation_fidelity": null,
            "experimental_validation_performed": false,
            "comparison_simulation_vs_experiment": "Not applicable — approach is evaluated by computational comparison to held-out human protocols rather than by wet-lab execution.",
            "validation_success_rate": "Not reported as direct pass/fail counts for the loop; success inferred by improved evaluation metrics (EE+ shows higher IoU and sequence similarity versus baselines).",
            "domain_validation_standards": "Standards are operationalized as DSL pre/postcondition consistency and product-flow coherence rather than physical validation; paper emphasizes this is a domain-level consistency standard but not a substitute for laboratory certification.",
            "when_simulation_sufficient": "The authors discuss that a high-fidelity digital twin could in principle be used for automated certification, but such simulation resources are not available in this work and would require extensive development.",
            "simulation_failures": "No simulations were executed; authors note constructing digital twins is challenging and out of scope.",
            "uncertainty_quantification": "Statistical validation of resulting protocol quality is provided (paired t-tests, standard errors) but no probabilistic confidence scores for verifier outputs are provided.",
            "fabrication_detection": "Verifier detects logical inconsistencies within the DSL representation (missing origin of product, unused postconditions), serving as a syntactic/semantic filter against nonsensical generated protocols, but is not a general anti-fabrication detector for content beyond these checks.",
            "validation_cost_time": "Computation costs for the overall pipeline (representation generation and design) are reported (~$70 total for GPT calls across tasks); no per-iteration wall-clock for the verifier loop is provided. DPMM representation generation timings given elsewhere (55 s/iteration op-centric).",
            "hybrid_validation_approach": true,
            "validation_limitations": "Cannot detect domain tacit knowledge issues and rare long-tail safety issues; limited by DSL extraction accuracy and by LLM reliability in applying corrective feedback.",
            "acceptance_credibility": "Authors present quantitative improvements relative to baselines as evidence of increased credibility, but emphasize need for human expert certification for final acceptance.",
            "comparison_to_gold_standard": "Compared computationally to held-out human-authored protocols via multi-dimensional metrics; no wet-lab or clinical gold-standard comparison performed.",
            "uuid": "e2188.1"
        },
        {
            "name_short": "Held-out protocol benchmark",
            "name_full": "Computational Benchmarking Against Held-Out Human-Authored Protocols (IoU/Sequence/Parameter Metrics)",
            "brief_description": "A computational validation framework that measures consistency between generated protocols and withheld human ground-truth protocols using six dimensions (IoU on operations, products, devices; sequence similarity; goal similarity; parameter-wise similarity) and statistical tests.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_or_method_name": "Held-out protocol benchmark (IoU & Sim metrics)",
            "scientific_domain": "Experimental protocol design / Computational evaluation",
            "validation_type": "computational validation (benchmarking against held-out ground truth)",
            "validation_description": "The authors construct a testing set by excluding an outlier subset from each domain's corpora; evaluate generated protocols against ground-truth via six metrics: IoU(Op), IoU(Prod), IoU(Dev), Sim(Exec) (sequence alignment), Sim(Goal) (cosine similarity over serialized structure), Sim(Param) (parameter-wise cosine similarity). They report mean scores, standard errors, and paired-sample t-tests comparing methods (t-statistics and p-values). The testing set included 140 novel protocols (1757 steps) across domains.",
            "simulation_fidelity": null,
            "experimental_validation_performed": false,
            "comparison_simulation_vs_experiment": "No simulation-to-experiment comparisons; evaluation is between algorithm outputs and held-out human-written protocols.",
            "validation_success_rate": "Expressed via metric scores (e.g., EE+ and EI+ achieved substantially higher IoU and similarity metrics; specific numeric averages and SEs are reported in result tables), but not a single overall success percentage.",
            "domain_validation_standards": "The paper adopts protocol-consistency metrics as proxy validation standards for automated protocol design; emphasizes these as objective but not equivalent to experimental confirmation.",
            "when_simulation_sufficient": "Not discussed in the benchmark context; paper asserts computational similarity metrics are helpful proxies for plausibility but not replacements for wet-lab validation.",
            "simulation_failures": "Not applicable.",
            "uncertainty_quantification": "Reported via standard errors for metric means and paired t-tests with p-values; tables give SE and t-test statistics (e.g., t(278) values and p &lt; .0001 for method comparisons).",
            "fabrication_detection": "Not directly targeted; held-out benchmark can reveal implausible or low-similarity outputs but doesn't detect fabricated experimental outcomes.",
            "validation_cost_time": "Benchmarking run costs modest; overall machine designer GPT costs ~ $10 across 7 methods and 140 protocols. No experimental resource costs involved.",
            "hybrid_validation_approach": false,
            "validation_limitations": "Benchmark compares to published protocols only, so success means reproducing or matching human-written protocols—not proving wet-lab viability; dataset sizes vary by domain which may bias results.",
            "acceptance_credibility": "Authors use benchmark results and statistical significance to argue for improved computational plausibility and likely increased community acceptance of LLM-assisted designs, but stress that final credibility requires human certification or wet-lab validation.",
            "comparison_to_gold_standard": "Gold standard (wet-lab confirmation) not performed; benchmark compared methods against human-authored protocols only.",
            "uuid": "e2188.2"
        },
        {
            "name_short": "Perplexity-based memorization check",
            "name_full": "Perplexity Comparison to Detect LLM Memorization of Test Protocols",
            "brief_description": "A computational check using LLM perplexity on held-out novel protocol prefixes versus a synthesized reference set to assess whether the LLM had memorized test-set protocol content.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_or_method_name": "Perplexity-based memorization check",
            "scientific_domain": "Language-model evaluation within protocol processing (NLP applied to scientific protocols)",
            "validation_type": "computational validation (model-training-data-memorization detection)",
            "validation_description": "Authors synthesize a reference set similar in style to protocol steps using gpt-4o mini, sample 100 sequences from test and reference sets, truncate to prefixes, prompt the LLM to predict next tokens and compute perplexity. They compare average perplexity between the test set and reference set; significantly higher perplexity on the test set indicates the LLM did not memorize the test protocols (t(198)=3.040, p &lt; .05).",
            "simulation_fidelity": null,
            "experimental_validation_performed": false,
            "comparison_simulation_vs_experiment": "Not applicable.",
            "validation_success_rate": "Authors report a statistically significant difference in perplexity (test set higher), but do not provide a percent success metric for detection.",
            "domain_validation_standards": "This is an accepted proxy (per prior literature) for detecting memorization of data by LLMs; authors cite Carlini et al. methods and Skywork methodology.",
            "when_simulation_sufficient": "Not applicable.",
            "simulation_failures": "Not applicable.",
            "uncertainty_quantification": "Statistical test provided (t-test with degrees of freedom and p-value) comparing perplexity distributions; no confidence intervals reported for the perplexity means.",
            "fabrication_detection": "Used to judge whether generated outputs could be memorized reproductions rather than generalizable synthesis; not a detector of fabricated experimental results per se.",
            "validation_cost_time": "Perplexity evaluation performed on small sampled sets; no cost/time metrics provided for this step specifically.",
            "hybrid_validation_approach": false,
            "validation_limitations": "Perplexity-based checks detect memorization risk but cannot guarantee lack of data leakage or assess factual correctness of generated protocols.",
            "acceptance_credibility": "Used to support the claim that LLM outputs are not simple memorized reproductions of test protocols, which strengthens credibility of benchmarking results.",
            "comparison_to_gold_standard": "Compared to synthesized reference set as a control; no wet-lab gold-standard involved.",
            "uuid": "e2188.3"
        },
        {
            "name_short": "Manual expert certification",
            "name_full": "Human Domain-Expert Certification and Cross-Validation of Designed Protocols",
            "brief_description": "A manual validation step where domain experts (Masters-level or higher) inspect candidate protocols, refine ground-truth selection, and certify applicability and safety; used as the final adjudicator for the testing set and recommended path for production deployment.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_or_method_name": "Manual expert certification (human-in-the-loop)",
            "scientific_domain": "Experimental sciences (biology/medical/bioengineering/ecology)",
            "validation_type": "experimental (human/peer review-based validation) / other",
            "validation_description": "Domain experts manually inspect and cross-validate candidate novel protocols filtered by computational outlier detection; they discard misclassified ones, request further candidates, and refine ground-truth files. The IRB-approved human-in-the-loop process paid experts and gathered informed consent; the human experts are responsible for final certification before any wet-lab execution.",
            "simulation_fidelity": null,
            "experimental_validation_performed": false,
            "comparison_simulation_vs_experiment": "Manual certification is positioned as the practical gold-standard prior to any wet-lab execution; authors explicitly retain manual certification because DSL verification alone is insufficient.",
            "validation_success_rate": "Not expressed as a numeric success rate; success manifested as curated testing set of 140 protocols validated by experts and used as ground-truth.",
            "domain_validation_standards": "Authors align with standard operating practices in experimental sciences: human expert review and certification is required for engineering/lab automation deployment; DSL verification is complementary, not substitutive.",
            "when_simulation_sufficient": "Authors state that simulation (digital twins) could enable machine-based certification in the future but is not currently sufficient or available.",
            "simulation_failures": "No simulation used; authors discuss challenges and potential failures in building digital twins (granularity design, rule production) as reasons human certification remains necessary.",
            "uncertainty_quantification": "Human review process described qualitatively; dataset statistics (counts, steps) and IRB oversight reported but no formal inter-rater reliability metrics provided.",
            "fabrication_detection": "Human experts are considered the primary defense against fabricated or unsafe protocols; manual review intended to catch cases machine verifiers miss.",
            "validation_cost_time": "Human expert labor: paid $22.5/h; IRB-approved process. Time per review not enumerated but testing set formation involved iterative checks between automated outlier detection and experts.",
            "hybrid_validation_approach": true,
            "validation_limitations": "Labor-intensive, not scalable to all generated protocols; experts rely on tacit knowledge and may still miss rare failure modes; authors emphasize humans remain necessary until robust digital twins exist.",
            "acceptance_credibility": "Authors treat human certification as essential for community acceptance and safety; they argue DSL-based methods improve efficiency but do not obviate expert validation.",
            "comparison_to_gold_standard": "Manual expert certification is treated as the gold standard in the paper; computational methods are compared against it indirectly via similarity to human-authored protocols, but no wet-lab experiments were used to compare computational outputs to physical outcomes.",
            "uuid": "e2188.4"
        },
        {
            "name_short": "Digital twin / simulation discussion",
            "name_full": "Digital Twin / High-Fidelity Simulation for Automated Protocol Certification (discussion/future work)",
            "brief_description": "A discussion of high-fidelity simulation/digital twin approaches as a potential future route to automate wet-lab validation and certification, noting substantial practical challenges and being out of scope for this paper.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_or_method_name": "Digital twin / High-fidelity simulation (proposed)",
            "scientific_domain": "Laboratory automation / Experimental simulation / Digital twin engineering",
            "validation_type": "high-fidelity simulation (discussed, not implemented)",
            "validation_description": "Authors describe the aspiration to build digital twins that model experiments with sufficient granularity to predict, explain, and perform counterfactual analysis for unseen behaviors, which could enable machine-based certification; requirements would include exhaustive primitive principles, appropriate simulation granularity, rule production, and reward functions for MDP/HRL approaches. However, they note these efforts are labor-intensive and out of scope.",
            "simulation_fidelity": "Not implemented; fidelity requirements are described qualitatively: would need physics/chemistry modeling of system, precise state-space, and accurate transition dynamics; no numerical fidelity metrics are provided.",
            "experimental_validation_performed": null,
            "comparison_simulation_vs_experiment": "Not applicable — no simulations executed. Authors explain that robust comparison would be required to validate such digital twins but is beyond this work.",
            "validation_success_rate": null,
            "domain_validation_standards": "Authors indicate that a viable digital twin must support prediction accuracy sufficient for certification, but do not provide formal domain thresholds; they warn that defining precise evaluation metrics for simulation-to-experiment distance (reward functions) is challenging.",
            "when_simulation_sufficient": "Paper suggests simulation could be sufficient if digital twins achieve high accuracy and cover tacit domain knowledge, but emphasizes development challenges: granularity, data-efficient model construction, and tacit knowledge injection.",
            "simulation_failures": "No concrete simulation failures reported (because none were run); authors highlight conceptual failure modes: overly coarse granularity, missing physical principles, or inadequate reward definition would render simulations insufficient.",
            "uncertainty_quantification": "Not addressed for hypothetical digital twins; authors note uncertainty quantification would be a necessary component but do not prescribe methods.",
            "fabrication_detection": "Not discussed specifically in simulation context; the authors suggest digital twins could improve detection of unrealistic behaviors if accurate.",
            "validation_cost_time": "Authors state the effort would be labor-intensive and expensive (exhaustive design and data collection) but give no numerical cost estimates.",
            "hybrid_validation_approach": null,
            "validation_limitations": "Practical implementation barriers: defining simulation granularity, collecting primitive principles and data, implementing rules, and creating reliable reward functions; insufficient data available currently for RL formulations.",
            "acceptance_credibility": "Authors opine high-fidelity digital twins would increase machine-certification credibility if successfully developed, but they acknowledge this is a long-term objective requiring significant resources.",
            "comparison_to_gold_standard": "No empirical comparison; paper positions digital twins as a possible route to approximate or replace manual certification only if built to high standards.",
            "uuid": "e2188.5"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Digitization and validation of a chemical synthesis literature database in the chempu",
            "rating": 2
        },
        {
            "paper_title": "Autonomous chemical research with large language models",
            "rating": 2
        },
        {
            "paper_title": "Self-refine: Iterative refinement with self-feedback",
            "rating": 2
        },
        {
            "paper_title": "Building an open representation for biological protocols",
            "rating": 2
        },
        {
            "paper_title": "An integrated self-optimizing programmable chemical synthesis and reaction engine",
            "rating": 1
        },
        {
            "paper_title": "Reconfigurable system for automated optimization of diverse chemical reactions",
            "rating": 1
        }
    ],
    "cost": 0.019443,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>HIERARCHICALLY ENCAPSULATED REPRESENTATION FOR PROTOCOL DESIGN IN SELF-DRIVING LABS
4 Apr 2025</p>
<p>Yu-Zhe Shi 
Department of Advanced Manufacturing and Robotics
Peking University</p>
<p>Mingchen Liu 
School of Computer Science and Technology
Huazhong University of Science and Technology ⋆ Equal contribution</p>
<p>Fanxu Meng 
Department of Advanced Manufacturing and Robotics
Peking University</p>
<p>Qiao Xu 
Zhangqian Bi 
Department of Advanced Manufacturing and Robotics
Peking University</p>
<p>School of Computer Science and Technology
Huazhong University of Science and Technology ⋆ Equal contribution</p>
<p>Kun He 
School of Computer Science and Technology
Huazhong University of Science and Technology ⋆ Equal contribution</p>
<p>Lecheng Ruan ruanlecheng@ucla.edu 
Department of Advanced Manufacturing and Robotics
Peking University</p>
<p>Qining Wang qiningwang@pku.edu.cn 
Department of Advanced Manufacturing and Robotics
Peking University</p>
<p>HIERARCHICALLY ENCAPSULATED REPRESENTATION FOR PROTOCOL DESIGN IN SELF-DRIVING LABS
4 Apr 2025EDD38CD17EB8C7C912EC6439E3D4B78EarXiv:2504.03810v1[cs.AI]
Self-driving laboratories have begun to replace human experimenters in performing single experimental skills or predetermined experimental protocols.However, as the pace of idea iteration in scientific research has been intensified by Artificial Intelligence, the demand for rapid design of new protocols for new discoveries become evident.Efforts to automate protocol design have been initiated, but the capabilities of knowledge-based machine designers, such as Large Language Models, have not been fully elicited, probably for the absence of a systematic representation of experimental knowledge, as opposed to isolated, flatten pieces of information.To tackle this issue, we propose a multi-faceted, multiscale representation, where instance actions, generalized operations, and product flow models are hierarchically encapsulated using Domain-Specific Languages.We further develop a data-driven algorithm based on non-parametric modeling that autonomously customizes these representations for specific domains.The proposed representation is equipped with various machine designers to manage protocol design tasks, including planning, modification, and adjustment.The results demonstrate that the proposed method could effectively complement Large Language Models in the protocol design process, serving as an auxiliary module in the realm of machine-assisted scientific exploration.</p>
<p>INTRODUCTION</p>
<p>The rapid advancement of Artificial Intelligence (AI) models for the assistance of scientific discovery (Wang et al., 2023b) has precipitated an increased demand for rapid iteration of ideas, from the generation to the verification of hypotheses.Although AI models have expedited the process of hypothesis generation, the validation phase still requires intensive empirical experimentation from human.The concept of self-driving laboratory has been introduced to substantially accelerate the validation process, in organic chemical synthesis (Mehr et al., 2020;Burger et al., 2020), cell biology for medical research (Kanda et al., 2022), and novel material discovery (Szymanski et al., 2023).With the expertise and effort of experimental scientists and automation engineers, mobile robots and Internet of Things (IoT) pipelines are configured to perform a sequence of actions in accordance with a detailed description of the specific experimental procedure, referred to as the protocol.</p>
<p>While existing protocols suffice for some experimental tasks, discovery processes often demand a higher degree of specificity, including: (i) confirmation of unverified experimental objectives to seek specific findings; (ii) testing parallel hypotheses or solutions; and (iii) replication of established experiments within the constraints of available laboratory resources.These necessitate the design of new protocols, going beyond the reuse of existing ones available in the protocol databases.Particularly, this includes the planning of novel protocols, and the modification and adjustment of current protocols as appropriate, respectively.Unfortunately, self-driving laboratories currently only execute isolated and duplicated experimental skills (Bédard et al., 2018;Steiner et al., 2019), or pre-specified protocols with sequential actions (Rohrbach et al., 2022;Manzano et al., 2022).Any innovation in protocols imposes intensive manual design burden (McNutt, 2014;Baker, 2016), potentially becoming a bottleneck in accelerating scientific discovery.Consequently, there is a quest for the automatic design of protocols tailored to specific goals for self-driving laboratories.</p>
<p>Designing new protocols is a non-trivial task even for human scientists.Novice scientists tend to adhere strictly to established protocols and may be at a loss when faced with the need for variations, from minor adjustments like different available devices to more significant shifts in the overall experimental goal.In contrast, veteran scientists typically have the capability to create or modify protocols as needed, from variations in available resources ("what I have") to desired outcomes ("what I want"), even in situations where a similar protocol was not encountered before.</p>
<p>The distinction arises because veteran scientists possess a systematic understanding of every ingredient and procedure, contextualizing them globally within the domain of experiment.They know "what kind of ingredient is used for what purposes" and "what kind of operation is used under what conditions', while novice scientists mechanically memorize the sequential execution orders and corresponding parameters in a local context.This systematic understanding, or conceptual knowledge (Ryle &amp; Tanney, 1949), includes the background knowledge of ingredients and atomic operations, as well as the relationships between them.Experienced experimental scientists develop such conceptual knowledge as a representation for protocol design (McCarthy, 1959), which serves as the vehicle for reasoning processes.Reasoning over conceptual knowledge leverages the rich context of generalized, abstracted concepts of ingredients and operations rather than specified, instantialized ones, which spans a semantic space where originally isolated dots are connected with each other, thereby enhancing the simplicity and flexibility of protocol design (Boden, 1980;Newell, 1982).In summary, veteran scientists' capability to design new protocols stems from an appropriate representation of background knowledge that supports reasoning processes (see Fig. 1A).</p>
<p>To implement automatic protocol design on machines, a reasonable choice may be leveraging a Large Language Model (LLM).Trained on extensive corpora, including scientific documents, LLMs possess the potential to facilitate protocol design with the corresponding background knowledge (AI4Science &amp; Quantum, 2023).Recently, researchers have made beneficial attempts to design new protocols using LLMs based on descriptions of new experimental goals (Boiko et al., 2023;M. Bran et al., 2024).Regrettably, benchmarking results indicate that the expected capability of LLMs in protocol design is not fully elicited (O'Donoghue et al., 2023).One significant limitation is that LLMs excel at generating new protocols similar to existing ones, i.e., protocols with similar sequential execution orders, but fail to generate those with distinct dependency distributions.This limitation hampers LLMs in scenarios where experimental goals change in high intensity.Another limitation is that the generated protocols sometimes lose critical configuration details for operation execution, necessitating manual correction.These empirical evidences suggest that LLMs exhibit limitations akin to those of novice human experts, implying that LLMs may necessitate a more suitable representation of background knowledge to fully unleash their potential in protocol design.</p>
<p>Protocol design is a multi-faceted, multi-scale effort requiring the integration of information from different perspectives, from low-level to high-level.This information includes detailed configurations of each atomic operation, temporal relationships between atomic operations, the scope of application for atomic operations with the same reference name, and the reactive relationships between reagents and operations.While LLMs undoubtedly capture such knowledge from their training corpora, the pieces of knowledge remain isolated, unorganized, and not articulated.These flatten background knowledge, rather than conceptual knowledge, hinders LLMs from flying over a global view of the novel objectives and diving into the details of operations.Therefore, we propose developing a multi-faceted and multi-scale representation for protocol design that provides the designer, such as LLMs, with a vehicle to reason over conceptual knowledge of ingredients and procedures.</p>
<p>We draw inspiration from both cognitive science literature on rationality (Monsell, 2003;Griffiths, 2020), which suggests that we cannot consider information from different views and scales in a single thread (Shi et al., 2023a).We also learn from computer science literature on hierarchical abstraction (Liskov, 1987), which indicates that higher-level abstraction semantics possess more powerful expressivity compared to their lower-level counterparts (Abelson &amp; Sussman, 1996;Hopcroft et al., 1996).Combining these insights, we suggest that our desired representation should encapsulate information of different granularities in corresponding hierarchies of abstraction, gaining global design insights with higher-level semantics while completing execution configurations with lowerlevel semantics.Specifically, we investigate three levels of encapsulation (see Fig. 3B).Starting from the set of original protocols, namely the basic level, we have (i) protocol element instantialization, which decomposes full protocols into instance operations with attributes, within the local context of the specific protocol, resulting a structural representation of the elementary information; (ii) function abstraction, which offers an operation-centric view that generalizes the precondition, postcondition, and execution configurations of each operation in the global context of the experiment domain, resulting a sequential representation of the operations; (iii) model abstraction, which offers an reagent and intermediate product centric view that unifies the status transitions in the global context of the experiment domain, resulting a continuous representation of the experimental environ- ment.This hierarchical structure provides the designer with a representation to consider all possible associations among operations, among products, and between operations and products, with a high degree of freedom, by disentangling originally intertwined information.We implement the representation using Domain-Specific Languages (DSLs).The hierarchical syntax of DSLs maintains both the abstract semantics at the high-level and the precise information at the low-level.Furthermore, the compositionality of DSL syntax facilitates the flexible protocol designs, addressing the "flying over global views" requirement; while DSL program verification over the generated protocols upholds their soundness and completeness; addressing the "diving into details" requirements.</p>
<p>However, the proposed representation does not come without drawbacks-it can be highly dependent on domain-specific knowledge (Mernik et al., 2005;Fowler, 2010).The distributions of reagents, operations, and execution dependencies vary significantly across different domains in experimental sciences, such as Genetics, Medical, Bioengineering, and Ecology.Manually crafting DSLs specialized for these domains requires deep integration between domain experts and programming language experts, which is labour-intensive, case-by-case, and costly (Shi et al., 2024a;b).This obstacle hinders the application of our representation to a broader set of domains (Shi et al., 2024d).</p>
<p>To make the representation specification more affordable, we develop an algorithm that conducts multi-hierarchy encapsulation automatically driven by the domain-specific corpus of existing protocols.Ultimately, we may be able to take a critical step toward closing the loop of autonomous scientific discovery by establishing these two building blocks: (i) the automatic generation of representation for protocol design; and (ii) the automatic designer working on the representation.</p>
<p>Our contributions in this work are three-fold: (i) we identify the problem of representation for protocol design and develop a hierarchically encapsulated representation for protocol design (Sec.2);</p>
<p>(ii) we propose a data-driven algorithm that automatically generates the representation for protocol design specialized for the domain of application (Sec.3); and (iii) we demonstrate the utility of the resulting representation by conducting protocol planning, modification and adjustment tasks using a variety of machine designers across different domains (Sec. 4).This further indicates that our proposed automatic representation generation approach possesses the potential to function as an auxiliary module for LLMs, enhancing their capability on protocol design.</p>
<p>REPRESENTATION FOR PROTOCOL DESIGN</p>
<p>In this section, we describe our representation for protocol design (see Fig. 1B).We first formulate the basic protocol design problem in Sec.2.1.Afterwards, starting from the original full protocol, we introduce the three hierarchies of representations: (i) structural representation, i.e., instance actions with attributes (Sec.2.2); (ii) sequential operation-centric representation, i.e., function abstraction (Sec.2.3); and (iii) continuous product-flow-centric representation, i.e., model abstraction (Sec.2.4).Furthermore, we describe how the dual representation of operation-centric and product-flow-centric views reciprocatively facilitates the verification of the designed protocols in Sec.2.5.</p>
<p>THE PROTOCOL DESIGN PROBLEM</p>
<p>Protocol design problem PD = (Φ | ω * , P, Ω) is generating a desired protocol Φ given the new coming experimental objective ρ, domain of experiment P, and available reagents Ω.A protocol Φ = ⟨φ 1 , φ 2 , . . .⟩ is a sequence of experimental steps φ t .An experimental objective ω * is the expected final product of the experiment.Experimental objectives can range from preparing a desired product, to testing the significance of a specific hypothesis and detecting a predicted behavior, with the latter two potentially followed by additional standalone steps for property test, observation, and interpretation.We denote domains of experiment as P, which influences the distributions of protocols by means of the distributions of operations, reagents, and execution orders, etc.The set of available reagents Ω includes originally accessible reagents and excludes those requiring production.</p>
<p>INSTANCE ACTIONS WITH ATTRIBUTES</p>
<p>Protocols are originally represented in Natural Language (NL), which is the representation suitable for humans' comprehension, but not for machines (Bartley et al., 2023).Without a syntax decomposing a NL-based protocol into information elements precisely, machines are likely to capture only overall, coarse-grained information of protocols and may only retrieve within existing protocols for the one that is most similar to the new experimental objective.Consequently, according to the standards and conventions of experimental sciences (Baker, 2021), the prerequisite of representation for a machine protocol designer should be a structural representation which decompose NL-based protocols into instance actions with attributes {φ t | (φ prec t , φ post t , φ exec t )}.The instance actions are decomposed by execution order and their attributes are the exact context for their execution, namely the precondition φ prec t , i.e., the availability of resources required for this action, postcondition φ post t , i.e., resulting product of the operation, and execution configurations φ exec t .Execution configurations includes the configuration parameters and their corresponding values, e.g., the device for conducting the operation and required experimental conditions such as duration, acidity, and lightening.An instance action can be reusable in another protocol once the execution context is matched.</p>
<p>With such reusability, we are on the first time to have building blocks for constructing a new protocol rather than retrieving existing ones.These building blocks capture fine-grained execution configuration parameters through maintaining the nested data structures of key-value pairs.This structural representation serves as a syntactic constraint on the preciseness of designed protocols.Practical attempts have been made echoing this idea (O'Donoghue et al., 2023;Leonov et al., 2024).</p>
<p>OPERATION-CENTRIC VIEW WITH FUNCTION ABSTRACTION</p>
<p>The reusability of instance actions with attributes is highly limited, as their semantics are highly specified in the low-level.The total amount of the instance actions can be extremely high, i.e., about 150K per domain, thus the probability of the exact matching between execution contexts can be extremely low.Consider the three different instance actions with attributes "Homogenization of mouse liver tissue using a bead mill", "Homogenization of bacterial cell suspension using an ultrasonic homogenizer", and "Homogenization of bacterial air samples using a nebulizer".Although they come with totally different preconditions, postconditions, and execution configurations, particularly the required device varying according to the phase of the experimental subject, they share the semantic identifier "Homogenization" for reference.Sharing semantic identifier indicates that these instance actions share the same purpose on the semantics level.In experimental sciences, "Homogenization" always refers to the breakdown of a sample into a uniform mixture.Whether it's tissue, cell suspension, or gas doesn't change the purpose of the operation.This is critical for protocol design, since it essentially requires satisfying the ultimate goal through a series of subgoals.Therefore, the desired representation should generalize the semantics of operations to any possible contexts in the corresponding domain of experiment, rather than only specific contexts.</p>
<p>We implement such generalization by encapsulating varied instances of preconditions, postconditions, and execution configurations into an interface for the operation.Namely, we refer to an operation with semantic identifier φ through an interface ϕ to a set of execution contexts, in the form of ⟨φ → ϕ → {(φ prec , φ post , φ exec )}⟩.The operation φ can be grounded to a corresponding instance action in any matched execution contexts, echoing modular design (Hirtz et al., 2002).The reusability of encapsulated operations comes with greater significance than that of instance actions, as there are only about 1K operations per domain in total, which is only 1/150 of that of instance actions.As flexible building blocks, operations can be easily fitted into any breakpoints with suitable preconditions and postconditions in the constructing experiment sequence.This sequential representation of the operations serves as a semantic constraint on the compact permissible set of primitives for protocol design (Shi et al., 2023b), maintaining both degree of freedom and correctness.</p>
<p>PRODUCT-FLOW-CENTRIC VIEW WITH MODEL ABSTRACTION</p>
<p>Sequence of operations make up of protocols.However, operations are the methods to realize rather than the objectives to achieve.For experimental objectives of testing, preparing, or detecting (Schwab &amp; Held, 2020), the common focus is always the specific status of final product, not the operations.Starting from initial reagents, the status of product flow is manipulated step-by-step by the operations, till the final product.Unfortunately, the information of product status transition is latent in protocols and is twisted with descriptions of experimental steps.For the operation-centric view, the transitions of product flow statuses remains a black box environment.For example, the operation description "Centrifuge the tubes at 15,000 x g for 20 minutes" does not directly reveal the transition from product in mixture status to products in distinct phases.The lack of coherent tracking of the product flow is problematic of protocol design, as the product flow holds spatialtemporal invariance, just the same as the general physical environment.Status transitions of the product flow are primarily caused by the effects of operations, thereby it serves as the invariant in executing the protocol from the perspective of programming.Therefore, the desired representation should also serve as the model interacting with the sequence of operations.</p>
<p>To disentangle product status from their latent representation in the operation-centric view, we propose an explicit product flow centric view that tracks the status of the product flows with detail, such as component, volume, container, and other physical and chemical properties of the product, and also the predecessor operation that yields the product and the successor operation that takes the product as input.Each product flow unit, i.e., one individual component in the product flow between two adjacent steps, is an instance with attributes {ω t | (ω pred t , ω succ t , ω prop t )}.Analogous to the generalization of operations' semantics, product flow units share commonalities between components with the same semantic identifier for reference-they may share a specific range of predecessor operations ω pred and successor operations ω succ , and a selected set of key properties to consider ω prop .For example, the "supernatant" is usually generated by a "centrifugation" operation, passing into "filtration" or "spectrophotometric analysis", and focusing on the properties acidity and viscosity rather than other possible properties.Thus, we encapsulate the information of contexts and properties into the semantics of product flow units, in the form of ⟨ω → (ω pred , ω succ , ω prop )⟩.As solid pipelines bridging the building blocks, product flow units can verify the coherency of the entire designed protocol.This continuous representation of the environments serves as a program verifier, checking the prerequisite and simulating the effect of each operation, alleviating unpredictable behaviors among the interaction between operations and product flows.</p>
<p>RECIPROCATIVE VERIFICATION OVER THE DUAL REPRESENTATION</p>
<p>Algorithm 1 Reciprocative Verification procedure OFVERIFICATION(M , φ) ▷ Check that the pre/ post conditions are met The dual representation of operation-centric and product-flow-centric views intrinsically equips with a verification mechanism through a reciprocative process akin to two interacting threads.The first thread focuses on verifying the operation flow, taking as input an operation φ t along with its precondition φ prec t and postcondition φ post t .The second thread handles the verification of the product flow, taking as input a product ω t along with its predecessor operation ω pred t and successor operation ω succ t .Specifically, for the operation verification (corresponding to OFVERIFICATION in Alg.1), we ensure that each operation can be correctly executed given its input reagents and that it yields the expected output products.This involves checking that the preconditions are satisfied by the available products from preceding operations and that the postconditions are well-defined for subsequent use.Concurrently, the product flow verification (corresponding to PFVERIFICATION in Alg. 1) involves tracking each
CHECKOPCONDITIONS(φ, φ prec , φ post ) if φ prec ⊆ M (Ω) then M (Ω) ← (M (Ω) \ φ prec ) ∪ φ post ▷ ProceedÀ ÉÈÇAEÄÅÃÂÈÁAE 4$3%2$ 0 ('$&amp;#)#"!"$0 0 4$1 1)$0
YEVGYRW5EWDGYSGTICYHFY@I@GEEIU9BBA 8G7W7@GUT Y6IEVYCY7GDQ5Q9IRC5BBA EVGYRG55YTGHDI7YIUYEVGY5F7CEGBBA PDGRI@IECEG EVGYRG55YTGHDI7YIUY BBA 8GSQXGY YHFY@I@GEEIU9BBA EVGY@G55GEY6IEVYCY7GDQ5Q9IRC5BBB unit of product flow through the protocol.We verify that the product is generated by the specified operation and that it possesses the necessary properties ω prop t for consumption by the next operation.</p>
<p>The interaction between these two threads forms a feedback loop where the verification of operations and products mutually inform and constrain each other.This reciprocative method allows us to iteratively refine the protocol, ensuring that each step is both operationally feasible and chemically coherent.LLMs are employed to implement the functions CHECKOPCONDITIONS and CHECK-PROPERTIES, extracting and verifying operation conditions and product properties from natural language protocol descriptions through instruction-following in-context learning (Wei et al., 2021;Brown et al., 2020).For the prompts employed, readers are referred to Appx.D.6.</p>
<p>AUTOMATIC REPRESENTATION GENERATION</p>
<p>In this section, we describe the proposed data-driven algorithm to automatically generate the hierarchically encapsulated representation for protocol design (see Fig. 2A).We first define the problem of generating the desired representation by means of DSL design (Sec.3.1).We then introduce methods for generating operation-centric (Sec.3.2) and product-flow-centric (Sec.3.3) DSL views.</p>
<p>THE REPRESENTATION GENERATION PROBLEM</p>
<p>We denote the problem of generating the representation for protocol design within a given domain as RG = ({⟨φ⟩, ⟨ω⟩} | P, C).The representation is a DSL with language features accommodating both the operation-centric program view ⟨φ⟩ and the product-flow-centric program view ⟨ω⟩.</p>
<p>The domain-specific corpus C = {Φ 1 , Φ 2 , . . ., Φ |C| } consists of existing protocols published in top-quality journals within the corresponding experimental domain.The source and profiles of C of each domain is detailed in Appx.E.1.We can obtain instance action with attributes based on C in a straightforward way through NL information extraction (see Appx.D.3 for implementation details).</p>
<p>The prior knowledge of operations and products, p(φ) and p(ω), including the basic syntax of the key-value structures and the elementary taxonomies, is derived according to the general commonsense of experimental sciences, as aforementioned in Sec. 2. Specifically, the problem essentially aims to fit the joint distribution models p(φ, ϕ, φ prec , φ post , φ exec ) and p(ω, ω pred , ω succ , ω prop ) with domain-specific corpus C given prior knowledge p(φ) and p(ω).</p>
<p>AUTOMATIC FUNCTION ABSTRACTION</p>
<p>The key challenge of encapsulating the operation-centric view is to aggregate all possible execution contexts for an operation, and then generalize the contexts to the interface.If we keep each of the use case as one single instance of the interface, which can be in thousands regarding one operation, the generalization is meaningless.Since there is no prior knowledge about the interface in advance, we develop the algorithm following the idea of non-parametric modeling, i.e., Dirichlet Process Mixture Model (DPMM), resulting in flexible identification of interface instances.</p>
<p>Hierarchical non-parametric modeling As we must handle information coming in different granularities, from interface structures to values of parameters, we choose to model the operations in a hierarchical fashion.Compared with the flatten spectral clustering approach developed by Shi et al. (2024a), which compresses all information of an operation into a embedding vector, our modeling is competent for considering information at different levels comprehensively.We carefully adopt the prerequisite that the interface is generated subject to the operation, preconditions, postconditions, and execution configurations are generated subject to the interface, and the value of configuration parameters are generated subject to their corresponding keys.Thus, we have the model:
p(φ, ϕ, φ prec , φ post , φ exec , φ exec-v ) = p(φ exec-v | φ, ϕ, φ exec )p(φ exec | φ, ϕ)p(φ prec | φ, ϕ)p(φ post | φ, ϕ)p(ϕ | φ)p(φ),(1)
where φ exec-v denotes the values of configuration parameters.Within each iteration of the DPMM process, we sample the variables level-by-level.Since the structures of preconditions, postconditions, and the selection of devices and configuration parameters are discrete, we sample them directly from the Dirichlet Process.As permissible values of parameters can be discrete, e.g., an array of specific values, common in acidity preparation; continuous, e.g., an interval with minimum and maximum values, common in temperature setting; or mixed, e.g., an array of specific values with random perturbations around the mean, common in timing control, we conduct the sampling by integrating Gaussian Process with Dirichlet Process
φ exec-v | φ, ϕ, φ exec ∼ DP (α, H(φ exec ), ϕ, φ) × GP (m, K)
, where α, H, m, and K are corresponding hyperparameters.</p>
<p>Unification of the interface While clustering similar interface instances encapsulates operations, there may remain redundant interfaces due to minor discrepancies.These discrepancies often arise from differences in parameter values or naming conventions that do not fundamentally alter the operation's functionality.To alleviate such redundancies, we implement a unification process for the interfaces.Specifically, interface instances associated with the same operation are considered equivalent if they have the same number of slots and emits and share the same keys in their execution configuration parameters.By abstracting away differences in parameter values and names, we unify these interfaces into a single, generalized interface, akin to the algorithm proposed by Martelli &amp; Montanari (1982).Unification enhances the generality of the operation-centric view by consolidating functionally-identical interfaces, maintaining a concise and representative set of operations.</p>
<p>Results Function abstraction converges on the domains respectively, as shown by the likelihood curve yielded by non-parametric model in Fig. 2B.In the DSL of Genetics, there are 304 operations in total, with an average of 7.9 interface instances per operation; for Medical, these two quantities are 269 and 6.9; for Bioengineering, they are 196 and 7.8; and for Ecology, they are 100 and 3.5.We find that a majority of operations with high occurrence frequency are unique to one domain, such as Pipette to Medical and Lyse to Genetics (see Fig. 2D).There are also common operations across domains, such as Concentrate and Culture.Take Concentrate for an example, its interface captures the instances with different devices according to input phases, e.g., use Bench-top_centrifuge for Liquid while Isotope_separation_centrifuge for Gas, and also instances with different emits, e.g., selecting Supernatant or Suspension as the product to keep.</p>
<p>AUTOMATIC MODEL ABSTRACTION</p>
<p>The key challenge of encapsulating the product-flow-centric view is to select proper descriptive properties of a flow unit component.There exists false positive cases, where properties are attributed to components with the same semantic identifier but in different phases, e.g., we consider ethanol with the property volume when it comes in liquid and with the property pressure when it comes in gas.There also exists false negative cases, where exact same components are regarded as different ones due to different reference names, e.g., Acetylsalicylic Acid, ASA, and Aspirin refer to the same thing.To alleviate false positive and false negative results, we discard the design choice of the interface in the operation-centric view, which tends to cover the possibly richest context, and thereby have the non-parametric model:
p(ω, ω pred , ω succ , ω prop , ω prop-v ) = p(ω prop-v | ω prop , ω)p(ω prop | ω)p(ω pred | ω)p(ω succ | ω)p(ω),(2)
where ω prop-v denotes the values of property parameters.Results Model abstraction converges on the domains respectively, as shown by the likelihood curve in Fig. 2C.In the DSL of Genetics, there are 17, 190 model states, i.e., product flow unit as product status, in total; the quantity is 12, 472 for Medical; 11, 418 for Bioengineering; and 2, 205 for Ecology.We find that most components of product flow units with high occurrence frequency are unique to one domain, such as RNA to Genetics and HCC to Medical (see Fig. 2E/F).Take Ethanol for example, the model captures its possible concentrations in liquid rather than in gas.</p>
<p>EXPERIMENTS AND DISCUSSION</p>
<p>In this section, we report and discuss the results of our experiments.We start from describing our realistic novel protocol design tasks (Sec.4.1), along with the metrics to measure the consistency between the designed protocol and the groundtruth protocol (Sec.4.2).Afterwards, we introduce the alternative representations and machine designers used for comparison (Sec.4.3).Finally, we report and analyze the experimental results both quantitatively and qualitatively (Sec.4.4).Generating unverified experimental objectives and their corresponding protocols specially for our protocol design tasks is impractical because those experiments which have not been peer-reviewed and published can be problematic regarding the contents themselves.To maintain both reality and scale of the testing set, for each domain we filter out a small subset of protocols which significantly differ from the remaining major part of the protocol set and exclude this subset from the corpora for automatic representation generation (Appx.E.1).This selected subset form the groundtruth of the testing set.</p>
<p>PROTOCOL DESIGN TASKS</p>
<p>We exploit quantitative indicators to assist testing set selection, which follows the convention of measuring a protocol's novelty in experimental sciences (Schwab &amp; Held, 2020).We comprehensively consider three indicators: (i) similarity between the text embedding of the NL-based description of purpose of protocols, employing the evaluation model in O'Donoghue et al. ( 2023); (ii) Intersection over Union (IoU) between the instance actions of protocols; (iii) similarity between the execution sequence of protocols, implemented through the Sequence Alignment (SA) algorithm (Smith et al., 1981).To note, indicators (ii) and (iii) are calculated upon the protocols pre-processed by the workflow described in Appx.D.3.Indicator (i) captures the high-level idea of protocol design, indicator (ii) is correlated to the implementation of the protocol design, while indicator (iii) captures the low-level information of protocol execution.</p>
<p>In response to the three purposes of protocol design introduced in Sec. 1, we specify the planning, modification, and adjustment tasks of protocol design.Candidate planning tasks, which are the confirmation of unverified experimental goals, come with relatively low scores (within the 20% lowest) on indicators (i) and (ii).Candidate modification tasks come with fair scores (around the 40% lowest) on indicators (i) and (ii) and relative low score on indicator (iii).Candidate adjustment tasks come with relatively high scores (within the 40% highest) on all of the three indicators.</p>
<p>We obtain the final testing set through a human-machine collaborative workflow.We first detect the outliers of the original protocol corpus of each domain under the metrics above, thereby forming a candidate set.Afterwards, experts of the corresponding domain (holding at least a Master's degree majoring in that domain) manually check the applicability of protocols in the candidate set with cross-validation, discarding the misclassified ones, requesting for more candidate protocols, and refining the groundtruth file when necessary.The testing set includes 140 new protocols and 1757 steps in total, across the domains of Genetics, Medical, Bioengineering, and Ecology, with 23% for planning, 52% for modification, and 25% for adjustment (see Tab. 1 and Fig. 3A for details).</p>
<p>INTER-PROTOCOL CONSISTENCY METRICS</p>
<p>Evaluating the consistency between a designed protocol and the groundtruth is not like comparing between two plain strings (O'Donoghue et al., 2023).Based on the corresponding commonground in experimental sciences (Bartley et al., 2023) S(Φ ′ )).These six dimensions capture protocol information from low to high granularities, and also measure the consistency of both ingredient knowledge and procedural knowledge, offering a relatively objective evaluation standard.</p>
<p>MACHINE DESIGNERS</p>
<p>We implement an array of designers by combining different representations with different LLMbased automatic designers under tractable computing load (see Appx.D.7).We investigate four types of representations, including the original NL-based protocol representation (Flatten) and the three levels of encapsulation described in Sec. 2, i.e., instance actions with attributes (Instance), operation-centric view only (Encapsulated), and the dual representation with operation-and product-flow-centric views (Encapsulated+).We consider three types of LLM-based protocol designers: (i) Baseline, a pure LLM-based approach with Retrieval-Augmented Generation (RAG) on the corresponding corpora (Appx.D.4); (ii) Internal, which takes the specific representation as part of the prompt of an LLM, requesting it to output the protocol under the constraint of the given representation (Appx.D.5); (iii) External, where the representation serves as an external constraint layer for the output of an LLM, verifying and refining the designed protocols (Appx.D.6).Notably, the external verifier is part of the resulting DSL as our proposed representation for protocol design.</p>
<p>The combination of representation and designer does not span a Cartesian space due to the intrinsic limitations of Flatten and Baseline.Therefore, we implement seven machine designers, including: (i) Flatten-Baseline(FB), LLM with RAG on original protocol corpora; (ii) Instance-Baseline(IB), LLM retrieval on the protocol corpora translated into instance actions; (iii) Instance-Internal(II), prompting LLM with the Instruction Set Assembly (ISA) of instance actions, following the implementation of the currently state-of-the-art method O'Donoghue et al.</p>
<p>PROTOCOL DESIGN RESULTS</p>
<p>The complete quantitative results across the four domains, the three tasks, and the six dimensions of evaluation metrics are presented at Appx.B. Through paired samples t-test, we find that EE+ and EI+ significantly outperform other alternative approaches (EE+ outperforms EE: t(278) = 8.007, µ d &lt; 0, p &lt; .0001;EI+ outperforms EI: t(278) = 8.397, µ d &lt; 0, p &lt; .0001;EE+ outperforms II: t(278) = 24.493,µ d &lt; 0, p &lt; .0001;EI+ outperforms II: t(278) = 23.855,µ d &lt; 0, p &lt; .0001;see Fig. 3C-E).These comparisons demonstrate the suitability of our desired representation for protocol design.Similarly, we find that approaches equipping with a relatively higher-level representation significantly outperforms their counterparts with a relatively lower-level representation (EE outperforms II: t(278) = 16.315,µ d &lt; 0, p &lt; .0001;EI outperforms II: t(278) = 15.259,µ d &lt; 0, p &lt; .0001;II outperforms FB: t(278) = 8.340, µ d &lt; 0, p &lt; .0001;see Fig. 3B).</p>
<p>DISCUSSION</p>
<p>This work proposes a hierarchically encapsulated representation for the conceptual knowledge in experimental sciences, including instance actions with attributes, sequential representation of operations with function abstraction, and continuous representation of product-flows with model abstraction, to fully elicit LLMs' capability on protocol design as an auxiliary module.The following discussions on results reveal the design rationality, scalability, and generality of the representation.</p>
<p>Contributions of the building blocks</p>
<p>The encapsulated representation approaches with dual views outperform their counterparts without dual views by enhancing both intra-step and inter-step details.At the intra-step level, EI and EE offer richer semantic information than IB and II, leveraging protocol-centric view to capture detailed configuration each operation.This feature accounts for their satisfactory performance on IoU(Op).At the inter-step level, EI+ and EE+ treat each step as a FlowUnit, incorporating both preceding and succeeding step contexts, leading to notable improvements in Sim(Exec) and IoU(Prod).This creates a double assurance mechanism (Shi et al., 2024c): the first assurance comes from internal input/output checks within each instruction, and the second from the input/output characteristics inferred from neighboring instructions.Namely, we estimate the output of the preceding operation and check its alignment with the current step's input.This design enhances step linkage, verification, and overall coherence, ensuring higher consistency and robustness in complex protocol workflows.Please refer to Appx.I.1 for the case study.</p>
<p>Handling different task complexities</p>
<p>The overall performance aligns with the trend in complexity across the three tasks (Fig. 3A); however, the dual-view encapsulated representations, EI+ and EE+, demonstrate superior performance compared to their counterparts.In planning, these methods consider all necessary components, enabling creative yet structured protocol generation.For modification tasks, they provide feedback on parameter changes, detecting inconsistencies that their counterparts might fail to capture.In adjustment tasks, EE+'s external verifier maintains protocol integrity by identifying component relationships.Please refer to Appx.I.2 for the case study.</p>
<p>Generality across domains Our DSL-based approaches offer a unified, modular representation with generalizability across scientific domains (see domain-indexed results at Appx.B.2).The dualview approach abstracts experimental processes into operations and flow units, capturing essential details while remaining applicable across fields.By representing dependencies between steps and tracking product flow, the replication of experiments could be enhanced.The framework captures cross-domain commonalities while allowing domain-specific content like specialized operations and reagents.This unified representation standardizes protocols and enables researchers to adopt experimental protocols from multiple fields, fostering interdisciplinary collaboration and innovation.Please refer to Appx.I.3 for the case study.Limitations on generality are discussed at Appx.G.</p>
<p>A ADDITIONAL REMARKS</p>
<p>A.1 RATIONALE OF THE OVERALL DESIGN CHOICE</p>
<p>It seems that we can formulate the protocol design problem in the fashion of Markov Decision Process (MDP) and solve it by heuristic-based planning methods or Hierarchical Reinforcement Learning (HRL) approaches.However, although the formulation itself is feasible, solving the problem may not be practical.Consider solving the problem through an HRL approach designed for heterogeneous action space with parameters (as the protocol is required to decide both the key properties of an operation and the corresponding values).This hierarchical agent may be trained to converge on a fine-grained environment with a clearly designed reward function, or on a large dataset with trajectories for offline learning.Unfortunately, we have access to neither an interactive environment simulating the experiments nor sufficient data to support offline training (Pateria et al., 2021).</p>
<p>Treating the experimental procedures as a white box and creating digital twins for experiments can be an elegant solution and thereby facilitate various applications other than protocol design.This effort requires elaborated design of simulation granularity, exhaustive collection of primitive principles of the system, efficient implementation of rule production, and define precise metrics for evaluating the distance between current and objective states (serving as a reward function), which can be labor-intensive and is far out of the scope of this work.On the other hand, viewing those published protocols as trajectories for offline training, the scale of the offline dataset and the density of the reward function are much too insufficient to support training to convergence.Augmenting the data, synthesizing realistic trajectories, or enhancing the accessibility of protocols, are out of the scope of this work.Given the current obstacles, we choose not to formulate the problem in an MDP fashion.Though an MDP-style formulation can be more precise and elegant, it may misguide the readers to some extent.Instead, we decide to leverage the rich domain-specific knowledge provided by knowledge-based agents such as LLMs, where knowledge may complement the lack of data and dense reward function.This design choice is also in line with the initial attempts on automatic experiment design (Boiko et al., 2023;M. Bran et al., 2024).</p>
<p>In summary, our design choice of formulation is a compromise based on currently limited resources and restricted scope.Nonetheless, the exploration of more precise and elegant formulations represents a promising avenue for future research.</p>
<p>A.2 INTUITION BEHIND THE INTERFACE</p>
<p>Interface is a concept of functional abstraction (Abelson &amp; Sussman, 1996).Interface disentangles the abstract functionality on the semantics level and its corresponding implementation details on the execution level.This approach encapsulates the implementation of an operation into a black-box, so the users of the operation would only need to consider its input and output.Therefore, with such encapsulated representation for protocol design, we only need to care about the consistency between the output of the predecessor operation and the input of the successor operation, without caring about their implementation details.This is the idea behind operationalization.Operationalization makes the interface an abstract function over all relative instance actions.The interface is abstracted from the execution contexts of all instance actions with the same reference name, i.e., the same purpose, and can be instantiated to an instance action given a specific execution context.A specific context can be the predecessor operation, the successor operation, the precondition, or the postcondition of the considered operation.An instance action configures a specific implementation for a specific execution context.For the operation "Homogenization", the implementation of one instance action can be "using an ultrasonic homogenizer" if the precondition, namely, the execution context, has intermediate product "cell suspension" available; the implementation of another instance action can be "using a bead mill" if the precondition contains tissue.This example demonstrates the relationship between interface and instance actions of an operation: the interface is abstracted from the set of instance actions and can be instantiated to instance actions.</p>
<p>Here we also give a more intuitive example to enhance the reader's comprehension.Consider the culinary scenario with the actions "frying the egg", "frying the fish", and "frying the steak".These are different instance actions coming with the same purpose "to fry something".Therefore, we can abstract the interface from these instance actions to operationalize the operation "fry".The input of "fry" should be something raw and its output should be something fried.Given different preconditions with available eggs or pieces of steak, the abstract semantic operation "fry" can be grounded to instance actions "frying the egg" or "frying the steak" respectively, through the instantiation of the interface.In summary, an interface serves as the bridge between the semantics level and the execution level.</p>
<p>A.3 VALUES OF MANUAL PROTOCOL CERTIFICATION</p>
<p>Certification is always one of the central focuses in the engineering practices of automation.In our practice, we only automate the process of protocol design, which is the primary objective of this work, and keep the manual certification part.On one hand, relieving experimental scientists from the labour-intensive protocol design tasks, thereby allowing them more time for high-level thinking, is a sufficiently significant improvement so far.On the other hand, engineering practices such as lab automation and manufacturing are in high demand for preciseness.This leads to the requirement of manual certification.Domain experts handle subtle cases through their tacit domainspecific knowledge and are responsible for their decisions (Wang et al., 2023b).According to these considerations and the standard operating processes of experimental sciences, we choose to certify the designed protocols by domain experts.</p>
<p>Our current choice is a compromise on the limitation of techniques and the demand for preciseness.In future work, we can conduct investigations on how to build digital twins of self-driving laboratories.Such digital twins support prediction, explanation, and counterfactual analysis of unseen behaviors of the experiments, which may facilitate machine-based protocol certification.Grounding these blue-sky thoughts necessitates addressing the challenging problems regarding the decision of simulation granularity, the implementation of data-efficient simulation model construction, and the injection of tacit domain-specific knowledge.In summary, the exploration of generated-protocolcertification by machines represents a promising avenue for future research.</p>
<p>A.4 LIMITATIONS OF AUTOMATIC PROTOCOL CERTIFICATION</p>
<p>LLMs can be much too uncontrollable for engineering practices such as lab automation, which may lead to unpredictable dangerous situations (Wang et al., 2023b).There comes a dilemma-we try to exploit the capability of reasoning over knowledge of LLMs, while we try to alleviate the drawbacks brought up by the uncontrollable nature of LLMs.Our proposed representation is dedicated to resolving the dilemma.The representations not only elicit LLMs' potential on protocol design through structural knowledge representation, but also serve as a guardrail for LLMs.Since the generated protocols are represented as corresponding DSL programs, the permissible output space is much more confined compared with that of pure LLMs, serving as constraints upon the LLMgenerated protocols.Thanks to the verification mechanisms provided by DSLs, the correctness of the generated protocols can be checked to some extent.Therefore, by equipping LLMs with an auxiliary constraint layer, we may approach a balance between knowledge utilization and preciseness.</p>
<p>However, the current verification on the level of DSL programs is far from sufficient for serving as a certification.Certification is a serious process, where any possibilities of reporting false positive cases are required to be eliminated.Some cases can be highly long-tailed distributed, which may not be detected by data-driven and knowledge-driven machine certifiers.In this context, human domain experts are responsible for coming up with these potential risks through their experiences and tacit knowledge.Therefore, we are not likely to move human experts out of the loop, except that we can efficiently build up appropriate digital twins for self-driving laboratories.In current practices, the automation of protocol design puts human experts into a larger loop without focusing on the lowlevel details of experiments.As a result, they are allowed more time for high-level thoughts on things like values, which are not likely to be alternated by machines.In summary, it is neither practical nor necessary to totally move human experts out of the loop of automatic scientific discovery.The investigation of human-machine coordination in protocol certification represents a promising avenue for future research.</p>
<p>A.5 RATIONALE FOR THE REAGENT CONSUMPTION MODEL</p>
<p>We treat the instantiation and the consumption of reagents a one-time deal without considering the exact volume of consumption and the corresponding remainder.The rationale for such design choice comes from both the current Standard Operating Process (SOP) of experimental sciences and the properties of self-driving laboratories (Bartley et al., 2023).</p>
<p>In the current SOP for manually conducted experiments, experimenters are required to use prefabricated sets of reagents.Similarly, experimenters use specific containers with predefined capacities to transfer intermediate products.Therefore, one pack of reagents or one container of intermediate products is only used once for an operation, without considering the remainder.This results in a more succinct representation where reagents are regarded as discrete elements rather than continuous volumes.</p>
<p>For self-driving laboratories, this is deliberately designed for efficient variable management following the corresponding principles in computer system design (Abelson &amp; Sussman, 1996).In computer systems, not removing used variables would cause out-of-memory errors, let alone in physical automation systems, where the physical memory slots are much harder than the virtual memory slots in computer systems to manage.Hence, we exploit this variable management mechanism to enhance the execution efficiency of self-driving laboratories.</p>
<p>A.6 RELATION TO LLM REASONING</p>
<p>We would like to clarify that our objective is not to alternate Chain-of-Thought (CoT) reasoning.According to recent studies on the properties of CoT, LLMs with CoT may generate coherent but unprofessional text in expertise-intensive application scenarios (Xiao et al., 2023).Therefore, our proposed representation serves as an auxiliary guardrail module for LLMs with reasoning techniques such as CoT, enhancing LLMs' reasoning capability from two aspects: (i) the representation constrain the scope of reasoning into a close set of entities, such as available operations, reagents, and devices commonly used in the domain; and (ii) the representation provides fine-grained injection of domain-specific knowledge for LLMs, resulting in not only coherent but also expertise-compatible generated content.</p>
<p>A.7 APPLICABILITY TO DOMAINS BEYOND SCIENTIFIC EXPERIMENT</p>
<p>In theory, our framework can be applied to any field that requires adherence to specific protocols and has a need for automated execution.Let us consider an automated kitchen controlled by a computer as an example.</p>
<p>Assuming the automated kitchen's computer is already programmed to prepare "braised pork ribs" and "steamed sea bass": Next, we can derive the corresponding DSL.For instance:</p>
<p>{ " cooking_methods ": { " braise ": { " steps ": [ {" type ": " fry ", " temperature ": " high ", " time ": "5 min "} , {" type ": " simmer ", " temperature ": " medium ", " time ": "30 min "} ], " seasoning ": [" soy sauce ", " sugar "] }, " steam ": { " steps ": [ {" type ": " steam ", " temperature ": " high ", " time ": "15 min "} ], " seasoning ": [" ginger ", " scallion "] } } , " ingredients ": { " ribs ": { " category ": " meat ", " default_braise_time ": "30 min " }, " sea_bass ": { " category ": " fish ", " default_braise_time ": "20 min ", " default_steam_time ": "15 min " } } } Now, let us create a new recipe for Braised Sea Bass by combining the braising technique with sea bass as the main ingredient.</p>
<p>START SELECT ingredient : sea bass ACTION : fry , temperature : high , time : 5 min ADD seasoning : soy sauce , sugar ACTION : simmer , temperature : medium , time : 20 min END</p>
<p>B COMPLETE RESULTS</p>
<p>B.1 TASK-INDEXED COMPLETE RESULTS</p>
<p>Table A1: Complete quantitative results on protocol design, specifically the planning task.Each cell represents the machine designer's average score (at the top of the cell) on all testing samples across the four domains and the corresponding standard error of mean (at the bottom of the cell).For each dimension, we highlight the results of both the best and the second best ones.</p>
<p>IoU(Op) IoU(Prod) IoU(Dev) Sim(Exec) Sim( Goal   Table A4: Complete quantitative results on protocol design, specifically the Genetics domain.</p>
<p>Each cell represents the machine designer's average score (at the top of the cell) on all testing samples across the three tasks and the corresponding standard error of mean (at the bottom of the cell).For each dimension, we highlight the results of both the best and the second best ones.The testing set selection and groundtruth checking tasks conducted by human experts in this work has been approved by the Institutional Review Board (IRB) of Peking University.We have been committed to upholding the highest ethical standards in conducting this study and ensuring the protection of the rights and welfare of all participants.We paid the domain experts a wage of $22.5/h for their work in this study.</p>
<p>We have obtained informed consent from all human experts, including clear and comprehensive information about the purpose of the study, the procedures involved, the risks and benefits, and the right to withdraw at any time without penalty.Participants were also assured of the confidentiality of their information.Any personal data collected (including name, age, and gender) was handled in accordance with applicable laws and regulations.</p>
<p>C.2 CORPORA COLLECTION</p>
<p>We carefully ensure that all protocols included in our corpora strictly comply with open access policies under the Creative Commons license.This strategy guarantees adherence to copyright and intellectual property laws, thereby preventing any potential infringement or unauthorized use of protected materials.By exclusively employing resources that are freely accessible and legally distributable, we maintain the highest standards of ethical research conduct, promoting transparency and respect for the intellectual property rights of others.This commitment ensures that our work advances the frontiers of knowledge in a manner that is both legally sound and ethically responsible.</p>
<p>D.3 PRE-PROCESSING OF THE PROTOCOLS</p>
<p>The protocol pre-processing steps begin by reading all JSON files of the protocols.Each protocol is then splitted sentence-by-sentence using Spacy1 , with the constraint that every sentence is longer than ten characters.Due to the large volume of data, sentence splitting is handled in parallel.Afterwards, deeper sentence splitting is performed based on specific conditions for further refinement, such as the presence of "and/then/and then" followed by a verb2 .We then parse sentences into root verbs and purpose clauses, which are identified using token.dep_== "ROOT" for root verbs and prepositional/adverbial/modals for purpose clauses.Lastly, we merge phrases based on punctuation, and their classification into valid sentences or decorative phrases depends on whether they contain a root verb or lack a purpose clause.</p>
<p>The first verb in each sentence is extracted as an opcode, again utilizing parallel processing for efficiency.Opcode frequency is filtered to exclude stopwords, which are recorded in a separate text file.Then we categorize these opcodes into high-level operation classes using a GPT model (gpt-4o mini), where each opcode is classified into categories like Transfer Operations, Transformation Operations, or Data Operations.</p>
<p>Once operation classification is complete, entity recognition is performed (also using gpt-4o mini) to identify entities like devices, input_flow_units, output_flow_units, and total_time.Each flow unit is further categorized (also using gpt-4o mini) with a high-level classification composed of a phase, i.e., Gas, Liquid, Solid, etc.; and a type, i.e., Chemical Compound, Biological Material, etc.When both phase and type are successfully labeled, phase is preferred as the feature of the flow unit.If phase labeling fails, we use type the feature of the flow unit.If neither phase nor type is successfully labeled, the corresponding feature is set to None.Part of the rationale is that there are non-reagent components in the general sense, i.e., data, files, obscure or undefined substances, etc.Therefore, we apply this strategy to maximize the possibility that there is a meaningful upper class labeling of the components without any redundancy.</p>
<p>Finally, we conduct a synonym merge process on the devices, which starts by using transformers AutoTokenizer3 to get an embedding for each device name.Afterwards, we use sklearn4 to identify potentially similar entity pairs by calculating the cosine similarity of the candidate entities, and then passing these entity pairs to the GPT model for synonym detection, thereby merging devices belonging to the same type.The reference names of these combined devices will be one of the features.</p>
<p>D.4 PURE LLM-BASED DESIGNER</p>
<p>The pure LLM-based designer employs RAG to retrieve similar protocols from the corresponding corpora for representation, following the design choice of the baseline in O' Donoghue et al. (2023).Specifically, in the FB approach, three similar protocols are first retrieved from the original protocol corpora using RAG, and then, along with the title and description of the target protocol, they are provided to the LLM to generate a NL plan.The LLM subsequently translates the NL plan into Python pseudocode.In the IB approach, three similar protocols' instance actions (like Python pseudofunctions definitions) are first retrieved from the corpora, and after randomizing their order, they are provided to the LLM along with the title and description of the target protocol to generate a plan in the form of Python pseudocode.</p>
<p>[ Prompt for retrieving similar protocols from corpora ] You are an expert in biology and you are very familiar with the experiment protocols .</p>
<p>I would like to make a protocol for { title }.I will give you some related protocols in the database .</p>
<p>Could you find me the most three similar and relevant protocols for reference in the given range ?</p>
<p>Here is an example of how to convert a protocol for { example protocol title } into python pseudocode { example protocol } { example python pseudocode } YOUR TASK : Here is a biology protocol entitled '{ title } ' The protocol steps are as follows : { protocol } Please convert this protocol into python pseudocode .python pseudocode :</p>
<p>[ Prompt for generating plan in pseudocode ] Your goal is to generate python pseudocode for biology protocols .</p>
<p>Here is an example of how to generate pseudocode for a biology protocol .EXAMPLE : { example protocol title } Here are some extra details about the protocol : { example protocol description } example pseudocode : { example pseudocode } YOUR TASK : Generate pseudocode for a protocol for { title }.Here are some extra details about the protocol : { details } You may only make use of the following python pseudocode functions : { psuedofunctions } your pseudocode :</p>
<p>D.5 INTERNAL DESIGNER</p>
<p>The internal designer incorporates the specific representation as part of the prompt for an LLM, asking it to output the protocol while adhering to the given representation constraints, echoing the idea of Wang et al. (2023a).Specifically, in II, the instance actions retrieved from the corpora via RAG and the pseudofunctions definitions of the target protocol are shuffled and then provided together to the LLM, constraining it to generate a plan in the form of Python pseudocode using the given pseudofunctions definitions.In EI and EI+, relevant DSL instructions are selected from a domain-specific operation-centric view DSL and product-flow-centric view DSL, respectively.These instructions and the target protocol's title and description are provided to the LLM, prompting it to output the corresponding plan as instantiated DSL instructions.</p>
<p>[ Protocol for generating plan in DSL program using operation -centric view DSL ]</p>
<p>Your goal is to generate plan in domain specific language ( DSL ) for biology protocols .</p>
<p>The DSL specifications related to the operations involved in the experiment are provided .The DSL specification of each operation consists of multiple patterns , each pattern is an operation execution paradigm .Here is an example of how to generate plan in DSL for a biology protocol .EXAMPLE : { example protocol title } Here are some extra details about the protocol : { example protocol description } example plan in DSL : { example plan } [ Requirements ] 1. Design the experiment with finer granularity , incorporating more steps to complete the experiment in a more rigorous , complex , and comprehensive manner .</p>
<ol>
<li>There are some missing parameters in the DSL specification .You should generate each step of the DSL program as detailed as possible based on your understanding of the protocol plan .[ Protocol for generating plan in DSL program using dual representation ] Your goal is to generate plan in domain specific language ( DSL ) for biology protocols .</li>
</ol>
<p>Two perspectives of the DSL specification are provided : the specification for experimental operations and the specification for experimental products .</p>
<p>The DSL specification of each operation or product consists of multiple patterns , each pattern is an operation execution paradigm or a product flow paradigm .</p>
<p>Output every operation of the plan in the form of an operation DSL program and every product of the plan in the form of a product DSL program .Here is an example of how to generate plan in DSL for a biology protocol .If you believe the error in a particular step is due to a mismatch in product names between the two perspectives rather than an actual error , you can ignore this error .Output your refined plan in DSL , returning a JSON block without any additional information or comments .YOUR TASK : Refine the plan in DSL for a protocol for { title }.</p>
<p>Here are some extra details about the protocol : { details } Refine the following plan : { plan } Here is the feedback of the plan : { feedback } Your refined plan in DSL :</p>
<p>D.7 COMPUTING LOAD OF THE MACHINE DESIGNERS</p>
<p>For automated representation generation, we primarily used GPT-4o mini with OpenAI's Batch API5 for preprocessing, incurring a cost of approximately $60 across four domains.The design of the DSLs was executed on a MacBook with an M2 chip, running 1,000 iterations to ensure convergence.This process required an average of 55 seconds per iteration for the operation-centric view DSL and an average of 2 seconds per iteration for the product-centric view DSL.For the machine designer, we primarily utilized GPT-4o mini combined with RAG for design, with a total cost of approximately $10 (7 methods, 140 protocols).In summary, the overall computational load is relatively low, highlighting the accessibility of our machine designers when utilizing the proposed representations and the corresponding automatic representation generation modules.</p>
<p>E DATA COLLECTION E.1 CORPORA SOURCES</p>
<p>The corpora C for the automatic generation of representations (Sec.3.1) and the corpora for selecting the testing set (Sec.4.1) are both retrieved from open-sourced websites run by top-tier publishers, including Nature's Protocolexchange 6 , Cell's Star-protocols 7 , Bio-protocol 8 , Wiley's Current Pro-tocols9 , and Jove10 .These sources compile a dataset of 15,837 experimental protocols across four domains: Genetics (8794 protocols), Medical (7351), Ecology (812), and Bioengineering (3597), with minimal overlap between them.We aggregated the corpora and analyzed the themes of the protocols according to the first-and second-level labels attached to them.We adopt measures to ensure that C is mutually exclusive with the testing set.</p>
<p>Other domains, such as Physics and Chemistry, are also representative domains of experimental sciences, besides Biology, Medical, and Ecology.The preliminary factor that restricts our current scope is data accessibility.Due to the higher cost of accessing the corpora of protocols for conducting physics and chemistry experiments, for example, mining the protocol from the "method" section of relevant published papers, we leave the application to Physics and Chemistry for future work.We employ the broadly accepted standard operating process to empirically verify that LLMs have not memorized the data we use.We adopt the methodology outlined in Section 5.2 of Skywork (Wei et al., 2023) and draw upon recent studies on detecting memorization in LLMs (Carlini et al., 2021;2022).Specifically, we use gpt-4o mini to synthesize data resembling the style of steps from novel protocols, and then calculate the perplexity on the test set and reference set.Since the reference set is newly generated, we consider it clean, not belonging to any training set of any model.</p>
<p>We randomly sample 100 sequences each from the test set and the reference set of the novel protocols.Each sequence corresponds to a single procedural step described in NL.We truncate the final 50 tokens of each sequence, retaining the prefixes.These prefixes are then used as prompts for the LLM to predict the next 50 tokens, for which we calculate the perplexity.If the perplexity of the test set is significantly lower than that of the reference set, the test set might have appeared in the model's training phase.</p>
<p>The results indicate that the LLM's average perplexity on the test set is significantly higher than that on the reference set (t(198) = 3.040, µ d &lt; 0, p &lt; .05;see Fig. A1), suggesting that the LLM encounters greater uncertainty with the novel protocols in the test set.This finding implies that for a published, widely accepted, and standardized operating process, there is no evidence to suggest that the LLM has memorized the data.</p>
<p>E.3 ON THE DIVERSITY OF NOVEL PROTOCOLS</p>
<p>Assessing diversity among novel protocols is both informative and meaningful.To further support our analysis, we incorporate a t-SNE visualization of the experimental objectives (described in natural language) for the novel protocols we select, as shown at Fig. A2.The results demonstrate a well-dispersed distribution, indicating a sufficient level of diversity among the protocols.3. Cell lysates are homogenized by passing through 22 -gauge needles , and tubes are put on ice for 15 min to complete the lysis .Crude extracts are then centrifuged at 2500 RPM for 5 min .Supernatants are transferred to fresh centrifuge tubes , and cold 5 M NaCl is added to each sample to make a salt concentration of between 0.7 -1.0 M to disrupt protein -protein interactions .</p>
<p>E.4 SHOWCASES</p>
<p>Spin the crude extracts by ultracentrifugation at 55000 RPM to</p>
<p>properly pellet residual insoluble proteins from the extract .Transfer supernatants into fresh centrifuge tubes .</p>
<p>Immunoprecipitation 5. Rinse Protein A beads in Hypotonic Buffer and place on ice until ready for use .</p>
<ol>
<li>
<p>Take a volume of cell lysates ( prepared as described above ) , and dilute with Hypotonic Buffer to 250 -500 mM salt to enable proteinprotein interactions .</p>
</li>
<li>
<p>Add 2 µg of preclearing antibody to the diluted lysate (e.g., anti -Myc or anti -p65 ) , vortex , add 50 µL of Protein A beads , and rock for 45 min .</p>
</li>
<li>
<p>Touchspin samples , and transfer supernatant to a fresh tube .9. Add 2 µg of polyclonal anti -MEKK1 to the lysates , and rock for 1 h.</p>
</li>
</ol>
<p>After this period , add 50 µL of Protein A beads and rock tubes at 4 • C for 1 h.</p>
<ol>
<li>
<p>Touchspin beads , wash beads with hypotonic buffer ( supplemented with NaCl to a concentration of 300 mM ) , vortex , and rock for 10 min .In total , 3 -5 washes of the beads are performed .</p>
</li>
<li>
<p>Finally , wash once with Hypotonic Buffer , and resuspend in Kinase Assay Buffer .Purified MEKK1 may be stored by snap -freezing in liquid nitrogen and long -term storage at -80 • C. Kinase assay Following preparation of MEKK1 immunoprecipitates ( as above ) , incubate with 7 µ g of JNKK1 ( K131M ) along with 5 µCi of ATP in Kinase Assay Buffer for 30 min at 30 • C ."</p>
</li>
<li>
<p>Collect the cells by spinning down without freezing on ice .Discard supernatant .</p>
</li>
<li>
<p>Re -suspend cells with 1 mL water and transfer to a 1.5 eppendorf tube , quickly spin down at 3 ,000 x g for 15 sec .12. Spin down at 20 ,000 x g for 5 min in a standard laboratory microfuge .13. Transfer supernatant ( around 350 µL) to a fresh 1.5 mL eppendorf tube .Add CHCl3 : isoamyl alcohol (24:1) .Vortex vigorously for 1 min at RT .</p>
</li>
<li>
<p>Transfer aqueous supernatant to a fresh 1.5 mL microfuge tube .If white cloudy precipitate is observed between the aqueous phase and organic phase , repeat steps 17 -18.</p>
</li>
<li>
<p>Add 1/10 volume of 3 M NaOAc ( pH 5) and vortex vigorously .Add 2.5 volumes of ethanol .Vortex again .</p>
</li>
<li>
<p>Place at -20 4. Dry the plate and add 100 µL of blocking solution per well to the plate .</p>
</li>
<li>
<p>Incubate the plate at room temperature ( RT ) for 1.5 h.</p>
</li>
<li>
<p>Discard the blocking solution and wash the plate with 1x PBS -Tween 5 times .</p>
</li>
<li>
<p>Dry the plate and keep it at 4 • C for later use .8. Harvest the spleen and create a single -cell suspension by gently smashing spleen pieces with the frosted surface of a pair of microscope slides in 5 mL of DMEM .9. Transfer the cells into 50 mL conical tubes and spin down the cells at 300 RCF for 5 min at 4 • C.</p>
</li>
<li>
<p>Discard the supernatant with aspiration without disturbing the pellet .</p>
</li>
<li>
<p>Re -suspend the cells with 5 mL of 0.17 M ammonium chloride and keep the cells on ice for 5 min .</p>
</li>
<li>
<p>Add 15 mL DMEM to the cells and spin at 300 RCF for 5 min at 4 • C. 13.Discard the supernatant and re -suspend the cells with 20 mL of DMEM and count the cells .</p>
</li>
<li>
<p>Re -suspend 2 x 10^7 cells in 2 mL of 10% DMEM and make a three -fold serial dilution (a total of 8 dilutions ) with 10% DMEM .</p>
</li>
<li>
<p>Add 50 µL/ well of the serial dilutions on the DNA -coated plate and centrifuge at 300 RCF for 5 min at 4 • C.</p>
</li>
<li>
<p>Incubate the cells at 30 • C for 2 h in a cell -culture incubator with 6% CO2 .17. Add 50 µL/ well of biotin -conjugated anti -IgM or anti -IgG (1:350 in 10% DMEM ) to the cells .</p>
</li>
<li>
<p>Centrifuge the cells at 300 RCF for 5 min at 4 • C and incubate the cells overnight in a cell -culture incubator with 6% CO2 .</p>
</li>
<li>
<p>Discard the cells and wash the plates 10 times with 10 x PBS -Tween 20.20.Dry the plates and add 50 µL of streptavidin alkaline phosphatase (1:1 ,000 in 1% BSA / PBS ) to the plate .</p>
</li>
<li>
<p>Incubate the plate at RT for 1 h and wash the plate 10 times with 10 x PBS -Tween 20.</p>
</li>
<li>
<p>Dry the plate and add 50 µL/ well of 1 mg / mL BCIP in AMP buffer to develop the plate .</p>
</li>
</ol>
<p>23.When the spots are clearly visible under a dissecting microscope , stop the development by discarding the BCIP solution and rinsing the plate with tap water thoroughly .</p>
<ol>
<li>Spots can be counted using a dissecting microscope or using an ELISpot reader ."</li>
</ol>
<p>F REPRODUCIBILITY</p>
<p>The project page with supplementary files for reproducing the results of this paper will be available at https://autodsl.org/procedure/papers/iclr25shi.html.</p>
<p>G LIMITATIONS</p>
<p>As a representation designed for a relatively new problem, the design and evaluation of the proposed framework come with limitations, leading to further investigations:</p>
<p>• Overall, our method achieves promising results across the four domains.Specifically, it performs best in experimental design for Genetics, shows comparable effectiveness in Medical and Bioengineering, but is less effective in Ecology.Notably, the Genetics corpus is the largest among the four domains, while the Ecology corpus is significantly smaller than the others.These observations suggest a potential positive correlation between the size of the domain-specific corpus and the "quality" of the resulting DSL.In other words, a larger corpus may lead to a "better" representation, thereby influencing the outcomes of protocol design.This hypothesis necessitates further investigation through rigorously designed experiments and carefully defined metrics for evaluating what constitutes a "better" representation.• We majorly consider the imperative programming DSLs as the implementation of representation in this work.This raises the question of whether incorporating objective-oriented programming paradigms could enhance the representation of complex entities within protocols, particularly the properties of reagents and intermediate products.If we are able to make the DSLs model the finegrained reactions between different components and automate the design of those DSLs based on a broader source of data, such as the Wikipedia pages, we can ultimately manage to build up a symbolic digital twin for a domain-specific system, such as the cell cultivation environment.Such simulation systems may greatly benefit protocol design with their power of prediction, explanation, and counterfactual analysis.• Can we explicitly extend our proposed representation to a hierarchical graph, thereby establishing the foundation for employing the advanced algorithms on graph routing and graph optimization?Results on the hierarchical graph can also serve as a external heuristic and constraint for LLMbased protocol designers.This hybrid approach may combine both the advantages of LLMs, i.e., exploitation of background knowledge, and those of classical algorithms, i.e., white-boxed properties with high explainability.• Can we apply the representation and the automatic representation generator to other critical domains with a high demand for automating procedure design, such as designing product route sheets for advanced manufacturing?</p>
<p>With many questions unanswered, we hope to explore more on automated protocol design for selfdriving laboratories and beyond.</p>
<p>H THE AUTOMATICALLY GENERATED REPRESENTATIONS</p>
<p>H.1 OPERATION-CENTRIC VIEW DSL { " Operation ": " Precipitate ", " pattern_0 ": { " Precond ": { " SlotArgNum ": 2, " SlotArg ": [" Liquid ", " Solid "] }, " Execution ": { " DeviceType ": " falcon tube ", " Capacity ": "15 mL ", " Config ": {} }, " Postcond ": { " EmitArgNum ": 1, " EmitArg ": [" Liquid "] }, " Example ": [ " Precipitate RNA by adding 600 µL of 100 % EtOH , 20 µL of 3 M NaOAc ( pH 5.5 ) , and 3 µL of glycogen .", " Precipitate the DNA in each tube by adding 20 µl of 3 M sodium acetate ( pH 5.2 ) and 550 µl of 100 % ethanol .", " Ethanol precipitate the RNA by adding 5 µl 3 M sodium acetate ( pH 5.2 ) ,2 µl of glycogen ( 20 mg / ml ) , and 171 µl of 100 % ethanol .", " Nuclei washing and tagmentation : Spin down nuclei at 600 g for 10 mins at 4 • C , resuspended with 50 µL Complete Buffer .", " Spin the sample at 4 ,000 × g at 4 • C until the volume reduces to about 1 mL .Quantify protein concentration as described in step 60." , " Spin down the 15 mL tubes at 2 ,500 ×g and 4 • C for 20 min .", " Spin for 2 min at 1 ,000 x g.Save a few µL of concentrated sample to run on an agarose gel later .", " Spin the tube for 30 sec at 12 ,000 x g to consolidate the gel at the bottom of the tube .", " Spin plate at 300×g for 1 min to collect liquid at the bottom of the wells .", " Once NXT PCR program is complete , quick spin the sample tube then place it on the magnet for 1 min .Transfer the supernatant containing the amplified mRNA -seq library into a new PCR tube .", " Spin down 2 mill nuclei at 600×g for 5 min ( whole liver nuclei ) or use a magnet ( bead -bound nuclei ) ." ] }, " pattern_1 ": { " Precond ": { " SlotArgNum ": 1, " SlotArg ": [" Mixture "] }, " Execution ": { " DeviceType ": " microcentrifuge ", " Config ": {} }, " Postcond ": {} , " Example ": [ " Small volumes , 1 -3 mL should be spun in a small tube where these fewer EVPs can more readily be collected .", " Briefly spin down the bead -lysate mixture .", " Spin down the mix tube to eliminate bubbles / air in a bench microcentrifuge .Add 19 µL of the mix to each well ."] }, " pattern_2 ": { " Precond ": { " SlotArgNum ": 1, " SlotArg ": [" Liquid "] }, " Execution ": { " DeviceType ": " centrifuge ", " Config ": { " speed ": ["800 g "] , " time ": ["7 min "] } }, " SlotArg ": [" Liquid ", " Solid "] }, " Execution ": [ { " DeviceType ": " bransonic ", " Config ": { " temperature ": ["60 • C "] , " time ": ["90 min "] } }, { " DeviceType ": " sonicator ", " Config ": {} } ], " Postcond ": {} , " Example ": [ " Sonicate 10 µg BAC DNA or 50 µg genomic DNA in total ( you will recover 10 % DNA after sonication and size selection ) ." , " Sonicated chromatin is immunoprecipitated with the chosen antibodies and non -enriched chromatin washed with a series of washing buffers .", " If the herring sperm DNA has not been sufficiently sonicated or too much has been used , the DNA pellet might not adhere to the microfuge tube and can be lost with the ethanol .", " Sonicate the lipid tube to dissolve lipids with the mineral oil for 90 min at 60 • C by using Bransonic ."] } } H.2 PRODUCT-FLOW-CENTRIC VIEW DSL { " Pred ": " Modification Operations ", " FlowUnit ": { " Component ": " FBS ", " ComponentType ": " Liquid ", " UnitArgType ": " MAT " " Vol ": ["0.1 mL ", "0.5 mL ", "1 mL ", "1.5 mL ", "2 mL ", "3 mL ", "5 mL ", "10 mL ", "25 mL ", "50 mL ", "400 µL", "500 µL", "500 mL "] ,</p>
<p>" Container ": " Tube ", " Cond ": { " Concentration ": ["0.5%" , "1%" , "2%" , "2.5%" , "5%" , "10%" , "15%" , "20%" , "30%" , "50%" , "90%" , "100%"] ,</p>
<p>" Temperature ": [" -150 • C", "4 • C", "18 • C -26 • C", "37 • C", "56 • C "] ,</p>
<p>" State ": " heat -inactivated " } " Succ ": " Transfer Operations " } , { " Pred ": " Detection and Measurement Operations ", " FlowUnit ": { " Component ": " ethidium bromide ", " ComponentType ": " Solid ", " UnitArgType ": " MAT ", " Vol ": ["0.25 µL/ mL ", "0.5 µL/ mL ", "2 -3 µL", "10 µL", "15 µL", "10 µg/ mL ", "0.5 µg/µL "] ,</p>
<p>" Container ": " Flask ", " Cond ": { " Concentration ": ["0.0024%" , "0.3 -10 µg/ mL ", "1.5% (w/v)", "5 µM", "1:1000"] ,</p>
<p>" Temperature ": ["25 • C", " room temperature "] , " State ": [" toxic ", " carcinogenic "] , " Charge ": [" positively charged "] } }, " Succ ": " Modification Operations " } , { " Pred ": " Transfer Operations ", " FlowUnit ": { " Component ": " gel ", " ComponentType ": " Semi -Solid ", " UnitArgType ": " MAT ", " Vol ": ["0.5 mL "] , " Container ": [" Gel Cassette ", " Tank ", " Tube "] , " Cond ": { " Impedance ": [" under 20 kOhm "] , " Size ": ["50 -250 nt "] } }, " Succ ": " Transfer Operations " } I CASE STUDIES I.1 CASE STUDY: CONTRIBUTIONS OF THE BUILDING BLOCKS Part of protocol designed by EE+: { " Pred ": "" , " FlowUnit ": { " Component ": " Lysis solution ", " ComponentType ": " Liquid ", " RefName ": " Lysis_solution -1" , " UnitArgType ": " MAT ", " Vol ": "50 µL", " Container ": "" ,</p>
<p>Figure 1 :
1
Figure 1: The representations for protocol design.(A) The example of protocol design by novice and veteran experimental scientists.(B) The hierarchies of our proposed representation, from original full protocol representation, to dual representation of operation-and product-flow-centric views.</p>
<p>Figure 2 :
2
Figure 2: Diagram of automatic representation generation.(A) Illustration of the workflow.(B) Convergence curve of automatic function abstraction.(C) Convergence curve of automatic model abstraction.(D-F) Confusion matrices on operation distribution (D), product distribution (E), and device distribution (F), between DSLs across domains.Correlation scores are low except the ones along the diagonals, indicating the significant inter-domain distinctions between the resulting DSLs.</p>
<p>Figure 3 :
3
Figure 3: Results of protocol design.(A) Profile of text-level similarity between testing sets of the three tasks.(B) Pairwise comparison between the capabilities of different machine designers across the six dimensions.(C-E) Performances of the seven machine designers on the planning (C), modification (D), and adjustment (E) tasks across the six dimensions (index by column).</p>
<p>, we design six-dimensional metrics to comprehensively cover all of the major factors without biased weighting and composition.The six dimensions include: (i) IoU on operations, IoU(Op) = IoU({φ 1...|Φ| }, {φ ′ 1...|Φ ′ | }), IoU between instance actions of the designed protocol Φ and the groundtruth Φ ′ ; (ii) IoU on reagents and intermediate products, IoU(Prod) = IoU({ω 0...|Φ| }, {ω ′ 0...|Φ ′ | }); (iii) IoU on devices, IoU(Dev) = IoU({φ(Dev) 1...|Φ| }, {φ(Dev) ′ 1...|Φ ′ | }), where φ(Dev) t denotes the exact device for conducting the instance action φ t ; (iv) Similarity between the execution sequences, Sim(Exec) = SeqAlign(⟨φ 0...|Φ| ⟩, ⟨φ ′ 0...|Φ ′ | ⟩), where SeqAlign(•, •) denotes the ordered sequence similarity score calculation by the SA algorithm; (v) Similarity between experimental objectives, Sim(Goal) = Cos(S(ρ), S(ρ ′ )), where S(•) represents the serialization operation on structural representations of protocols; (vi) Similarity between complete protocols at parameter-wise level, Sim(Param) = Cos(S(Φ),</p>
<p>(2023); (iv) Encapsulated-Internal(EI), prompting LLM with the DSL with operation-centric view; (v) Encapsulated-External(EE), LLM equipping with the external verifier provided by the DSL with operation-centric view; (vi) Encapsulated-Internal+(EI+), prompting LLM with the DSL with the dual representation; and (vii) Encapsulated-External+(EE+), LLM equipping with the external verifier provided by the DSL with the dual representation.</p>
<p>D IMPLEMENTATION DETAILS D.1 PRIOR MODEL OF PRODUCT FLOW-CENTRIC VIEW &lt; Pred &gt; ::= &lt; Operation .UniqueName &gt; &lt; Succ &gt; ::= &lt; Operation .UniqueName &gt; &lt; FlowUnit &gt; ::= &lt; Component &gt; &lt; ComponentType &gt; &lt; RefName &gt; <Vol > &lt; Container &gt; <em>&lt; Cond &gt; &lt; Component &gt; ::= <STR > &lt; ComponentType &gt; ::= Gas | Liquid | Solid | Semi -Solid | Mixture | ChemicalCompound | BiologicalMaterial | Reagent | PhysicalObject | File / Data | ... [ Known component types ] &lt; RefName &gt; ::= &lt; Component &gt; &lt; Index &gt; &lt; UnitArgType &gt; ::= MAT | PROD <Vol > ::= <REAL > <MEAS > &lt; Container &gt; ::= Tube | Flask | Pipette | ... [ Known container types ] &lt; Cond &gt; ::= &lt; ArgKey &gt; &lt; ArgValue &gt; &lt; ArgKey &gt; ::= Temperature | Pressure | Acidity | Lighting | ... [ Known conditional keys ] &lt; ArgValue &gt; ::= <REAL > <MEAS > D.2 PRIOR MODEL OF OPERATION-CENTRIC VIEW &lt; Operation &gt; ::= &lt; UniqueName &gt; </em>&lt; Pattern &gt; &lt; UniqueName &gt; ::= <STR > &lt; Pattern &gt; ::= &lt; Precond &gt; &lt; Execution &gt; &lt; Postcond &gt; <em>&lt; Example &gt; &lt; Precond &gt; ::= &lt; SlotArgNum &gt; </em>&lt; SlotArg &gt; &lt; SlotArgNum &gt; ::= <INT > &lt; SlotArg &gt; ::= &lt; ProductFlow .FlowUnit .ComponentType &gt; &lt; Postcond &gt; ::= &lt; EmitArgNum &gt; <em>&lt; EmitArg &gt; &lt; EmitArgNum &gt; ::= <INT > &lt; EmitArg &gt; ::= &lt; ProductFlow .FlowUnit .ComponentType &gt; &lt; Example &gt; ::= <STR > &lt; Execution &gt; ::= &lt; DeviceType &gt; &lt; Capacity &gt; </em>&lt; Config &gt; &lt; DeviceType &gt; ::= Incubator | Autoclave | Centrifuge | ... [ Known device types ] &lt; Capacity &gt; ::= <REAL > <MEAS > &lt; Config &gt; ::= &lt; ArgKey &gt; &lt; ArgValue &gt; &lt; ArgKey &gt; ::= Duration | Pace | Power | Quantity | ... [ Known device configuration items ] &lt; ArgValue &gt; ::= <REAL > <MEAS ></p>
<ol>
<li>In Precond and Postcond , use formal name of the component to represent the SlotArg and EmitArg of each step .The component name should clearly describe the content of the component .YOUR TASK : Generate plan in DSL for a protocol for { title }.Here are some extra details about the protocol : { details } You can choose to instantiate the following DSL specification to construct the DSL program : { DSL } Your plan in DSL program :</li>
</ol>
<p>EXAMPLE : { example protocol title } Here are some extra details about the protocol : { example protocol description } example plan in DSL : { example plan } YOUR TASK : Generate plan in DSL for a protocol for { title }.Here are some extra details about the protocol : { details } You can choose to instantiate the following DSL specifications to construct the DSL program : Operation -view DSL specification : { Operation -DSL } Product -view DSL specification : { Product -DSL } Your plan in DSL program : If you believe the error in a particular step is due to the step preparing reagents rather than using a previous intermediate product , you can ignore this error .Output your refined plan in DSL , returning a JSON block without any additional information or comments .YOUR TASK : Refine the plan in DSL for a protocol for { title }.Here are some extra details about the protocol : { details } Refine the following plan : { plan } Here is the feedback of the plan : { feedback } Your refined plan in DSL : [ Prompt for refining the plan according to the feedback vertified by DSL with dual representation ]Your task is to improve a Biology experimental protocol plan represented in domain -specific language ( DSL ) based on provided feedback .The input plan in DSL consists of multiple DSL programs from two perspectives : operation -view and product -view .The DSL programs from these two perspectives alternate and constrain each other .This is the format of a product -view DSL program : // Each product view DSL program represents the state of the product at that moment .{ Pred : &lt; Operation &gt;, // Pred represents the operation that precedes the creation of this product , need to align to the operation name in the operation view DSL program .If the product is in its initial state , return "".FlowUnit : { // FlowUnit defines the properties of the product being processed .Component : , // Component represents the actual product or material being processed , need to be the formal name of the component .ComponentType : Gas | Liquid | Solid | Semi -Solid | Mixture | ChemicalCompound | BiologicalMaterial | Reagent | PhysicalObject | File / Data , // ComponentType describes the type of the component , which can be one of the following : Gas , Liquid , Solid , Semi -Solid , Mixture , The provided feedback indicates errors that occurred when compiling the DSL programs .You need to correct the program to ensure that the state changes of each product ' s RefName in the Product -view are caused by the corresponding operations in the Operation -view .</p>
<p>EFigure A1 :
A1
Figure A1: Comparison between the perplexity of the test set and the reference set</p>
<p>approximately 1 x 10^7 cells by centrifugation at 2000 RPM for 5 min .Aspirate media and resuspend cell pellet with 1 mL of icecold PBS and transfer to a 1 mL centrifuge tube .Microcentrifuge at 2000 RPM for 5 min at 4 • C.</p>
<p>Figure A2 :
A2
Figure A2: Visualization of diversity between novel protocols</p>
<p>Table 1 :
1
Statistics of the testing set.Each cell presents the total number of protocols m and experimental steps n in the form m (n).
Genetics Medical Bioengineering EcologyPlanning10 (130)7 (96)12 (157)2 (25)Modification 37 (442) 15 (225)16 (210)6 (59)Adjustment23 (219)5 (87)2 (26)5 (81)</p>
<p>Table A2 :
A2
Complete quantitative results on protocol design, specifically the modification task.Each cell represents the machine designer's average score (at the top of the cell) on all testing samples across the four domains and the corresponding standard error of mean (at the bottom of the cell).For each dimension, we highlight the results of both the best and the second best ones.
IoU(Op) IoU(Prod) IoU(Dev) Sim(Exec) Sim(Goal) Sim(Param)FB0.1810.0500.0380.3040.7960.809(0.102)(0.071)(0.071)(0.102)(0.090)(0.060)IB0.1500.0380.0390.2810.7720.788(0.100)(0.065)(0.076)(0.100)(0.089)(0.060)II0.3310.1010.0610.4160.8020.851(0.143)(0.131)(0.135)(0.127)(0.087)(0.059)EI0.5930.3180.3360.6020.8660.937(0.186)(0.158)(0.235)(0.164)(0.066)(0.030)EI+0.6480.6260.4130.7650.8830.952(0.210)(0.188)(0.256)(0.170)(0.055)(0.031)EE0.5880.4030.3320.6010.8730.940(0.185)(0.192)(0.228)(0.164)(0.053)(0.028)EE+0.6400.6610.4100.7570.8930.953(0.213)(0.179)(0.253)(0.170)(0.043)(0.032)</p>
<p>Table A3 :
A3
Complete quantitative results on protocol design, specifically the adjustment task.Each cell represents the machine designer's average score (at the top of the cell) on all testing samples across the four domains and the corresponding standard error of mean (at the bottom of the cell).For each dimension, we highlight the results of both the best and the second best ones.
IoU(Op) IoU(Prod) IoU(Dev) Sim(Exec) Sim(Goal) Sim(Param)FB0.1920.0770.0510.3190.8110.823(0.100)(0.104)(0.094)(0.103)(0.078)(0.051)IB0.1970.0390.0060.3370.8020.810(0.131)(0.063)(0.021)(0.141)(0.082)(0.049)II0.4530.1150.0910.5080.8050.873(0.208)(0.161)(0.211)(0.184)(0.081)(0.056)EI0.5870.3280.4000.6230.8630.944(0.190)(0.186)(0.265)(0.165)(0.055)(0.027)EI+0.6680.5450.4490.7750.8830.950(0.208)(0.259)(0.247)(0.152)(0.056)(0.040)EE0.5810.4040.3950.6160.8750.946(0.184)(0.205)(0.261)(0.162)(0.039)(0.026)EE+0.6500.5890.4410.7580.8930.950(0.220)(0.229)(0.248)(0.160)(0.033)(0.042)B.2 DOMAIN-INDEXED COMPLETE RESULTS</p>
<p>Table A5 :
A5
Complete quantitative results on protocol design, specifically the Medical domain.Each cell represents the machine designer's average score (at the top of the cell) on all testing samples across the three tasks and the corresponding standard error of mean (at the bottom of the cell).For each dimension, we highlight the results of both the best and the second best ones.
IoU(Op) IoU(Prod) IoU(Dev) Sim(Exec) Sim(Goal) Sim(Param)FB0.1740.0480.0300.3120.7960.839(0.085)(0.070)(0.067)(0.075)(0.087)(0.043)IB0.1390.0290.0230.2640.7210.795(0.054)(0.038)(0.063)(0.045)(0.123)(0.070)II0.3730.0810.0910.4240.7760.871(0.093)(0.087)(0.205)(0.072)(0.097)(0.041)EI0.6040.3220.3090.5940.8610.932(0.167)(0.146)(0.253)(0.148)(0.079)(0.031)EI+0.6150.5740.4000.7580.8710.952(0.196)(0.242)(0.198)(0.149)(0.060)(0.021)EE0.5910.3730.2980.5830.8730.936(0.158)(0.166)(0.234)(0.149)(0.054)(0.030)EE+0.6150.6130.3900.7560.8910.955(0.197)(0.210)(0.202)(0.151)(0.040)(0.019)</p>
<p>Table A6 :
A6
Complete quantitative results on protocol design, specifically the Ecology domain.Each cell represents the machine designer's average score (at the top of the cell) on all testing samples across the three tasks and the corresponding standard error of mean (at the bottom of the cell).For each dimension, we highlight the results of both the best and the second best ones.
IoU(Op) IoU(Prod) IoU(Dev) Sim(Exec) Sim(Goal) Sim(Param)FB0.1550.0300.0210.2970.7810.807(0.085)(0.035)(0.048)(0.088)(0.096)(0.056)IB0.1620.0060.0300.2750.7630.788(0.118)(0.015)(0.058)(0.105)(0.090)(0.063)II0.3860.0430.0270.4480.7880.856(0.176)(0.062)(0.062)(0.131)(0.065)(0.044)EI0.4580.2590.3510.5140.8790.933(0.171)(0.134)(0.195)(0.142)(0.048)(0.028)EI+0.4110.5690.3590.5860.8880.945(0.134)(0.133)(0.175)(0.127)(0.052)(0.023)EE0.4580.3470.3510.5070.8740.934(0.171)(0.151)(0.195)(0.138)(0.048)(0.029)EE+0.4140.5810.3460.5860.9100.944(0.142)(0.141)(0.177)(0.131)(0.035)(0.024)</p>
<p>Table A7 :
A7
Complete quantitative results on protocol design, specifically the Bioengineering domain.Each cell represents the machine designer's average score (at the top of the cell) on all testing samples across the three tasks and the corresponding standard error of mean (at the bottom of the cell).For each dimension, we highlight the results of both the best and the second best ones.
IoU(Op) IoU(Prod) IoU(Dev) Sim(Exec) Sim(Goal) Sim(Param)FB0.1760.0480.0500.3000.7900.826(0.085)(0.089)(0.081)(0.084)(0.090)(0.042)IB0.1490.0500.0380.2860.7670.797(0.077)(0.087)(0.091)(0.078)(0.083)(0.046)II0.3520.0620.0660.4430.8100.860(0.151)(0.090)(0.187)(0.125)(0.073)(0.045)EI0.5650.3070.3100.6030.8510.930(0.164)(0.186)(0.249)(0.169)(0.072)(0.033)EI+0.6570.5770.3940.7430.8880.944(0.209)(0.177)(0.241)(0.179)(0.056)(0.041)EE0.5580.3920.3030.5980.8550.933(0.162)(0.214)(0.246)(0.165)(0.076)(0.030)EE+0.6530.6140.4010.7420.9000.945(0.206)(0.172)(0.246)(0.176)(0.046)(0.041)C ETHICS STATEMENTC.1 HUMAN EXPERT PARTICIPANTS
&lt; ProductFlow &gt; ::= <Pred > &lt; FlowUnit &gt; <Succ >
https://spacy.io/api/sentencizer
https://spacy.io/api/matcher#<em>title
https://huggingface.co/docs/transformers/v4.45.1/en/model_doc/auto#transformers. AutoTokenizer
https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine</em> similarity.html#cosine-similarity
https://platform.openai.com/docs/guides/batch/batch-api
https://protocolexchange.researchsquare.com/
https://star-protocols.cell.com/
https://bio-protocol.org/en
https://currentprotocols.onlinelibrary.wiley.com/
https://www.jove.com/
ACKNOWLEDGEMENTSThis work was partially supported by the National Natural Science Foundation of China under Grants 52475001.Q. Xu is a visiting student at Peking University from University of Science and Technology of China.The authors would like to thank Haofei Hou for his earlier works regarding domain-specific representations, and also Jiawen Liu for her assistance in figure drawings.Please output id of your selected protocols , separating with a comma .Don ' t output any other information .[ Output format ] id_1 , id_2 , id_3 [ Related protocols ] { context } Answer :[ Prompt for generating NL plan ] Your goal is to generate steps for a biology protocol .These protocol steps must accurately describe a complete scientific protocol to obtain a result .Steps of some similar protocols will be provided as a reference for you to generate the new one .Output should only contain the steps without any other information .Here is an example of how to generate steps for a biology protocol .EXAMPLE : { example protocol title } Here are some extra details about the protocol : { example protocol description } example steps : { example protocol steps } YOUR TASK : Generate steps for a protocol for { title }.Here are some extra details about the protocol : { details } Here are some similar protocols ' steps for reference : { steps } your steps :[ Prompt for translating NL plan to pseudocode ] Your goal is to convert biology protocols into python pseudocode .EXAMPLED.6 EXTERNAL DESIGNERThe external designer combines (i) deductive verification through DSL; and (ii) self-improvement by the LLM(Madaan et al., 2023).In EE, the external verifier is provided by the operation-centric view DSL and performs checks on two main aspects: (i) whether the precondition of each operation is an intermediate product of a previous step rather than appearing from nowhere; and (ii) whether the postcondition of each operation is used in subsequent steps rather than being omitted.Similarly, in EE+, the external verifier is provided by the DSL with a dual representation, focusing on crossverifying the parallel dual tracks (the two perspectives of the DSL program).It checks whether the corresponding operation causes each status transition of the product: (i) whether the product in each product-view program is the output of its preceding operation; and (ii) whether the product in each product-view program is the input for its succeeding operation.If a mismatch occurs, the verifier generates corresponding error messages, such as "Error: The product {product} required by operation {operation} at step {i} is not available from previous steps."These error messages are then fed into the feedback-refine loop as feedback for the LLM to revise the plan.The loop terminates when the program passes the verification or reaches the maximum number of iterations, and the best result is retained based on the verification information.// EmitArg represents the output product or material resulting from the operation , using formal component names from the product perspective DSL program , with serial numbers to distinguish repeated components in different states .} } ] }, " pattern_1 ": { " Precond ": { " SlotArgNum ": 4, " SlotArg ": [" Liquid ", " Liquid ", " Liquid ", " Liquid "] }, " Execution ": { " DeviceType ": " centrifuge ", " capacity ": "1.5 ml ", " Config ": { " time ": "10 -15 min ", " speed ": ["12 ,000 × g", "20 ,000 × g "] ," temperature ": "4 • C", } }, " Postcond ": { " EmitArgNum ": 1, " EmitArg ": [" Solid "] }, " examples ": [ " Precipitate the cell debris in the lysate by centrifugation at 20 ,000 × g for 10 -15 min at 4 • C ." , " precipitate DNA with 13.5 µL of following mixture (1 µL of 20 mg / ml Glycogen , 12.5 µL of 3 M NaOAc [ pH 5.3]) and 340 µL ethanol .", " precipitate the total RNA by centrifuging at 12 ,000 × g for 15 min at 4" Operation ": " Spin ", " pattern_0 ": { " Precond ": { " SlotArgNum ": 2, " SlotArg ": [" Liquid ", " Liquid "] }, " Execution ": { " DeviceType ": " spin plate ", " Config ": { " time ": ["1 min "] } }, " Postcond ": { " EmitArgNum ": 1, " EmitArg ": [" Physical Object "] }, " Example ": [ " Postcond ": { " EmitArgNum ": 1, " EmitArg ": [" Liquid "] }, " Example ": [ " Spin lysate at 14 krcf for 10 min at 4 • C; transfer cleared lysate to new tube .", " Spin down the beads for 60 s at 2 ,000 x g.Discard the supernatant by carefully pipetting out the buffer .", " Spin at 12 ,000 × g until the total volume in both filters is reduced to 120 µL ( &lt;=30 min ).Keep aside 5 µL of purified labeled histone for SDS -PAGE analysis ." , " Quickly spin the FACS tube to allow the cell suspension to pass through the filter to remove undigested large tissue debris .", " Spin once for 7 min at 800 g.Use the BD cytofix / cytoperm kit according to the manufacturer ' s instructions and thereafter add antibodies for intracellular detection of IFN and TNF ."] } } , { " Operation ": " Sonicate ", " pattern_0 ": { " Precond ": { " SlotArgNum ": 1, " SlotArg ": [" Liquid "] }, " Execution ": { " DeviceType ": " sonicator ", " Config ": { " time ": ["20 -30 s "] } }, " Postcond ": { " EmitArgNum ": 1, " EmitArg ": [" Semi -Solid "] }, " Example ": [ " Sonicate the pellet suspension on ice under a 50 % duty cycle for 5 min .", " Agarose gel of sonicated Arabidopsis chromatin .", " Sonicate proteoliposomes for 20 -30 s or 3 times for 10 s , placing on ice in between sonication , if necessary .", " The lipid suspension is sonicated to form small unilamellar vesicles ( SUVs ) ." ] }, " pattern_1 ": { " Precond ": { " SlotArgNum ": 2, " Cond ": { " State ": " Liquid " } }, " Succ ": " Pipette " } , { " Operation ": " Pipette ", " Precond ": { " SlotArgNum ": 1, " SlotArg ": [ " Lysis_solution -1" ] }, " Execution ": { " DeviceType ": " Pipette ", " Config ": { " time ": "10 times ", " volume ": "50 µL" } }, " Postcond ": { " EmitArgNum ": 1, " EmitArg ": [ " Lysis_solution -2" ] } } Part of protocol designed by EE: { " Operation ": " Add ", " Precond ": { " SlotArgNum ": 1, " SlotArg ": [ " Triton -X" ] }, " Execution ": { " DeviceType ": "8 -channel pipette ", " Config ": { " Volume ": "1% solution " } }, " Postcond ": { " EmitArgNum ": 1, " EmitArg ": [ " Triton_X_Solution " ] } } { " Operation ": " Run ", " Precond ": { " SlotArgNum ": 1, " SlotArg ": [ " Cell_Lysis_Mixture " ] }, " Execution ": { " DeviceType ": " Thermal Cycler ", " Config ": { " Temperature ": "70 • C", " Time ": "15 min " } }, " Postcond ": { " EmitArgNum ": 1, " EmitArg ": [ " cDNA_Reverse_Transcription " ] } } Part of protocol designed by EI: { " Operation ": " Run ", " Precond ": { " SlotArgNum ": 1, " SlotArg ": [ " Cell_Lysis_Mixture " ] }, " Execution ": { " DeviceType ": " Thermal Cycler ", " Config ": { " Temperature ": "70 • C", " Time ": "15 min " } }, " Postcond ": { " EmitArgNum ": 1, " EmitArg ": [ " cDNA_Reverse_Transcription " ] } } Part of protocol designed by II: " reverse_transcribe ": { " muscs ": " cells ", " buffer ": " RT buffer ", " enzyme ": " reverse transcriptase ", " incubation_time ": "60 minutes ", " temperature ": "42" } " prepare_single_cell_suspension ": { " input_cells ": " lysed cells " } Part of protocol designed by IB:" reverse_transcribe ": { " muscs ": " RNA ", " buffer ": " reverse transcription buffer ", " enzyme ": " reverse transcriptase ", " incubation_time ": "60 minutes ", " temperature ": "42" } " prepare_single_cell_suspension ": { " input_cells ": " single -cell samples " } Part of protocol designed by FB:" sort_single_cell ": { " plate ": " PCR plate ", " nozzle_size ": "100 µm", " mode ": " single -cell purity " }I.2 CASE STUDY: HANDLING DIFFERENT TASK COMPLEXITIESPart of protocol designed in Planning:{ " Operation ": " Obtain ", " Precond ": { " SlotArgNum ": 1, " SlotArg ": [ " File / Data " ] }, " Execution ": { " DeviceType ": " QIAGEN Blood &amp; Cell Culture DNA Maxi Kit ", " Config ": {} }, " Postcond ": { " EmitArgNum ": 1, " EmitArg ": [ " HMW genomic DNA " ] } } Part of protocol designed in Modification:{ " Operation ": " Centrifuge ", " Precond ": { " SlotArgNum ": 1, " SlotArg ": [ " Serum_Plasma_in_PBS -1" ] }, " Execution ": { " DeviceType ": " Ultracentrifuge ", " Config ": { " speed ": [ "12 ,000 × g" ], " time ": [ "20 min " ], " temperature ": [ "4Part of protocol designed in Adjustment:{ " Operation ": " Incubate ", " Precond ": { " SlotArgNum ": 2, " SlotArg ": [ " Washed sections with 1 st antibody -1" , "2 nd antibody mixture -1" ] }, " Execution ": { " DeviceType ": " Moistening box ", " Config ": { " temperature ": "37 C", " time ": "1 h" } }, " Postcond ": { " EmitArgNum ": 1, " EmitArg ": [ " Sections with 2 nd antibody -1" ] } } I.3 CASE STUDY: GENERALITY ACROSS DOMAINS Part of protocol designed for Bioengineering: { { " Operation ": " Incubate ", " Precond ": { " SlotArgNum ": 2, " SlotArg ": [ " Lysis Mixture -2" , " Stop Buffer -1" ] }, " Execution ": { " DeviceType ": " Thermocycler ", " Config ": { " temperature ": "65 • C", " time ": "30 min " } }, " Postcond ": { " EmitArgNum ": 1, " EmitArg ": [ " Neutralized Mixture -1" ] } }, { " Pred ": " Incubate ", " FlowUnit ": { " Component ": " Neutralized Mixture ", " ComponentType ": " Mixture ", " RefName ": " Neutralized Mixture -1" , " UnitArgType ": " PROD ", " Vol ": "60 µL", " Container ": "0.2 -ml PCR tube ", " Cond ": { " State ": " Neutralized " } }, " Succ ": " Mix " }, { " Operation ": " Elute ", " Precond ": { " SlotArgNum ": 1, " SlotArg ": [ " Washed Beads -1" ] }, " Execution ": { " DeviceType ": " Centrifuge ", " Config ": { " time ": "1 min " } }, " Postcond ": { " EmitArgNum ": 1, " EmitArg ": [ " Eluted Product -1" ] } }, { " Pred ": " Elute ", " FlowUnit ": { " Component ": " Eluted Product ", " ComponentType ": " BiologicalMaterial ", " RefName ": " Eluted Product -1" , " UnitArgType ": " PROD ", " Vol ": "50 µL", " Container ": "0.2 -ml PCR tube ", " Cond ": { " State ": " Eluted " } }, " Succ ": " Incubate Clear " }, { " Operation ": " Quantify ", " Precond ": { " SlotArgNum ": 1, " SlotArg ": [ " Clear Eluted Solution -1" ] }, " Execution ": { " DeviceType ": " Nanodrop ", " Config ": {} }, " Postcond ": { " EmitArgNum ": 1, " EmitArg ": [ " Quantified Sample -1" ] } }, { " Pred ": " Quantify ", " FlowUnit ": { " Component ": " Quantified Sample ", " ComponentType ": " Liquid ", " RefName ": " Quantified Sample -1" , " UnitArgType ": " PROD ", " Vol ": "50 µL", " Container ": "0.2 -ml PCR tube ", " Cond ": { " State ": " Quantified ", " Concentration ": "150 ng /µL", " A260 / A280 ": 1.85 , " A260 / A230 ": 2.1 } }, " Succ ": " Dilute " } } Part of protocol designed for Ecology: { { " Operation ": " Grow ", " Precond ": { " SlotArgNum ": 1, " SlotArg ": [ " Watered_Rice_Plants -1" ] }, " Execution ": { " DeviceType ": " Environmental growth chamber ", " Config ": { " Temperature ": "24 • C", " LightCycle ": "12 h light /12 h dark " } }, " Postcond ": { " EmitArgNum ": 1, " EmitArg ": [ " Mature rice plants " ] } }, { " Pred ": " Grow ", " FlowUnit ": { " Component ": " Mature rice plants ", " ComponentType ": " BiologicalMaterial ", " RefName ": " Mature_Rice_Plants -1" , " UnitArgType ": " PROD ", " Vol ": "N/A", " Container ": " Plastic pot ", " Cond ": { " State ": " Mature ", " Height ": "50 -60 cm " } }, " Succ ": " Anesthetize " }, { " Operation ": " Collect ", " Precond ": { " SlotArgNum ": 2, " SlotArg ": [ " Monitored_Aphid -1" , " Mature_Rice_Plants -1" ] }, " Execution ": { " DeviceType ": " Microcapillary tube ", " Config ": {} }, " Postcond ": { " EmitArgNum ": 1, " EmitArg ": [ " Phloem sap " ] } }, { " Pred ": " Collect ", " FlowUnit ": { " Component ": " Phloem sap ", " ComponentType ": " Liquid ", " RefName ": " Phloem_Sap -1" , " UnitArgType ": " PROD ", " Vol ": "1 -2 µL", " Container ": " Microcapillary tube ", " Cond ": {
Structure and interpretation of computer programs. Harold Abelson, Gerald Jay Sussman, 1996The MIT Press</p>
<p>Monya Baker. 1,500 scientists lift the lid on reproducibility. arXiv:2311.07361Microsoft Research AI4Science and Microsoft Azure Quantum. The impact of large language models on scientific discovery: a preliminary study using gpt-4. 2023. 2016. 2021533arXiv preprintNature</p>
<p>Building an open representation for biological protocols. Bryan Bartley, Jacob Beal, Miles Rogers, Daniel Bryce, Benjamin Robert P Goldman, Peter Keller, Vanessa Lee, Joshua Biggers, Mark Nowak, Weston, ACM Journal on Emerging Technologies in Computing Systems. 1932023</p>
<p>Reconfigurable system for automated optimization of diverse chemical reactions. Anne-Catherine Bédard, Andrea Adamo, Grace Kosi C Aroh, Aaron A Russell, Jeremy Bedermann, Brian Torosian, Klavs F Yue, Timothy F Jensen, Jamison, Science. 36164082018</p>
<p>Artificial intelligence and natural man. Margaret Boden, Synthese. 4331980</p>
<p>Autonomous chemical research with large language models. Robert Daniil A Boiko, Ben Macknight, Gabe Kline, Gomes, Nature. 62479922023</p>
<p>Language models are few-shot learners. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Advances in Neural Information Processing Systems. 2020</p>
<p>Rob Clowes, et al. A mobile robotic chemist. Benjamin Burger, Vladimir V Phillip M Maffettone, Catherine M Gusev, Yang Aitchison, Xiaoyan Bai, Xiaobo Wang, Li, Buyi Ben M Alston, Li, Nature. 58378152020</p>
<p>Extracting training data from large language models. Nicholas Carlini, Florian Tramer, Eric Wallace, Matthew Jagielski, Ariel Herbert-Voss, Katherine Lee, Adam Roberts, Tom Brown, Dawn Song, Ulfar Erlingsson, 30th USENIX Security Symposium (USENIX Security 21). 2021</p>
<p>Quantifying memorization across neural language models. Nicholas Carlini, Daphne Ippolito, Matthew Jagielski, Katherine Lee, Florian Tramer, Chiyuan Zhang, arXiv:2202.076462022arXiv preprint</p>
<p>Domain-specific languages. Martin Fowler, 2010Pearson Education</p>
<p>Understanding human intelligence through human limitations. L Thomas, Griffiths, Trends in Cognitive Sciences. 202024</p>
<p>A functional basis for engineering design: reconciling and evolving previous efforts. Julie Hirtz, Robert B Stone, Daniel A Mcadams, Simon Szykman, Kristin L Wood, 200213Research in Engineering Design</p>
<p>Introduction to Automata Theory, Languages, and Computation. John E Hopcroft, Rajeev Motwani, Jeffrey D Ullman, 1996Addison-Wesley Longman Publishing Co., Inc</p>
<p>Robotic search for optimal cell culture in regenerative medicine. Taku Genki N Kanda, Motoki Tsuzuki, Noriko Terada, Naohiro Sakai, Tomohiro Motozawa, Mitsuhiro Masuda, Nishida, Tatsuki Chihaya T Watanabe, Higashi, A Shuhei, Horiguchi, 2022Elife11e77007</p>
<p>An integrated self-optimizing programmable chemical synthesis and reaction engine. Alexander Js Artem I Leonov, Slawomir Hammer, S Lach, Dario Hessam M Mehr, Davide Caramelli, Aamir Angelone, Khan, O' Steven, Matthew Sullivan, Liam Craven, Wilbraham, Nature Communications. 15112402024</p>
<p>Keynote address-data abstraction and hierarchy. Barbara Liskov, Addendum to the proceedings on Object-oriented programming systems, languages and applications (Addendum). 1987</p>
<p>Augmenting large language models with chemistry tools. Andres M Bran, Sam Cox, Oliver Schilter, Carlo Baldassari, Andrew D White, Philippe Schwaller, Nature Machine Intelligence. 2024</p>
<p>Self-refine: Iterative refinement with self-feedback. Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, Advances in Neural Information Processing Systems. 2023</p>
<p>An autonomous portable platform for universal chemical synthesis. Wenduan J Sebastián Manzano, Hou, Przemyslaw Sergey S Zalesskiy, Hsin Frei, Philip J Wang, Leroy Kitson, Cronin, Nature Chemistry. 14112022</p>
<p>An efficient unification algorithm. Alberto Martelli, Ugo Montanari, ACM Transactions on Programming Languages and Systems (TOPLAS). 421982</p>
<p>Programs with common sense. John Mccarthy, 1959London</p>
<p>. Marcia Mcnutt, Reproducibility, Science. 34361682014</p>
<p>A universal system for digitization and automatic execution of the chemical synthesis literature. M Hessam, Matthew Mehr, Artem I Craven, Graham Leonov, Leroy Keenan, Cronin, Science. 37065122020</p>
<p>When and how to develop domain-specific languages. Marjan Mernik, Jan Heering, Anthony M Sloane, ACM Computing Surveys (CSUR). 3742005</p>
<p>Allen Newell. The knowledge level. Stephen Monsell, Trends in Cognitive Sciences. 732003. 1982Artificial Intelligence</p>
<p>Bioplanner: Automatic evaluation of llms on protocol planning in biology. Aleksandar Odhran O'donoghue, John Shtedritski, Ralph Ginger, Ali Abboud, Samuel Ghareeb, Rodriques, Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing. the 2023 Conference on Empirical Methods in Natural Language Processing2023</p>
<p>Hierarchical reinforcement learning: A comprehensive survey. Shubham Pateria, Budhitama Subagdja, Ah-Hwee Tan, Chai Quek, ACM Computing Surveys (CSUR). 5452021</p>
<p>Digitization and validation of a chemical synthesis literature database in the chempu. Simon Rohrbach, Mindaugas Šiaučiulis, Greig Chisholm, Petrisor-Alin Pirvan, Michael Saleeb, S Hessam M Mehr, Ekaterina Trushina, I Artem, Graham Leonov, Aamir Keenan, Khan, Science. 37766022022</p>
<p>The concept of mind. Gilbert Ryle, Julia Tanney, 1949Routledge</p>
<p>Different worlds confirmatory versus exploratory research. Simon Schwab, Leonhard Held, Significance. 1722020</p>
<p>PersLEARN: Research Training through the Lens of Perspective Cultivation. Yu-Zhe Shi, Shiqian Li, Xinyi Niu, Qiao Xu, Jiawen Liu, Yifan Xu, Shiyu Gu, Bingru He, Xinyang Li, Xinyu Zhao, Annual Meeting of the Association for Computational Linguistics. 2023a</p>
<p>On the complexity of Bayesian generalization. Yu-Zhe Shi, Manjie Xu, John E Hopcroft, Kun He, Joshua B Tenenbaum, Song-Chun Zhu, Ying Nian Wu, Wenjuan Han, Yixin Zhu, International Conference on Machine Learning. 2023b</p>
<p>AutoDSL: Automated domain-specific language design for structural representation of procedures with constraints. Yu-Zhe Shi, Haofei Hou, Zhangqian Bi, Fanxu Meng, Xiang Wei, Lecheng Ruan, Qining Wang, Yu-Zhe Shi, Haotian Li, Annual Meeting of the Association for Computational Linguistics. 2024a. 2024bIEEE Visualization and Visual Analytics Gen4DS Workshop</p>
<p>Expert-level protocol translation for self-driving labs. Yu-Zhe Shi, Fanxu Meng, Haofei Hou, Zhangqian Bi, Qiao Xu, Lecheng Ruan, Qining Wang, Advances in Neural Information Processing Systems. 2024c</p>
<p>Abstract Hardware Grounding towards the Automated Design of Automation Systems. Yu-Zhe Shi, Qiao Xu, Fanxu Meng, Lecheng Ruan, Qining Wang, International Conference on Intelligent Robotics and Applications. 2024d</p>
<p>Identification of common molecular subsequences. F Temple, Smith, Michael S Waterman, Journal of Molecular Biology. 14711981</p>
<p>Organic synthesis in a modular robotic system driven by a chemical programming language. Sebastian Steiner, Jakob Wolf, Stefan Glatzel, Anna Andreou, M Jarosław, Graham Granda, Trevor Keenan, Gerardo Hinkley, Philip J Aragon-Camarasa, Davide Kitson, Angelone, Science. 363642322112019</p>
<p>Ekin Dogus Cubuk, Amil Merchant, et al. An autonomous laboratory for the accelerated synthesis of novel materials. Nathan J Szymanski, Bernardus Rendy, Yuxing Fei, Rishi E Kumar, Tanjin He, David Milsted, Matthew J Mcdermott, Max Gallant, Nature. 62479902023</p>
<p>Grammar prompting for domain-specific language generation with large language models. Bailin Wang, Zi Wang, Xuezhi Wang, Yuan Cao, Rif A Saurous, Yoon Kim, Advances in Neural Information Processing Systems. 2023a</p>
<p>Scientific discovery in the age of artificial intelligence. Hanchen Wang, Tianfan Fu, Yuanqi Du, Wenhao Gao, Kexin Huang, Ziming Liu, Payal Chandak, Shengchao Liu, Peter Van Katwyk, Andreea Deac, Nature. 62079722023b</p>
<p>Jason Wei, Maarten Bosma, Y Vincent, Kelvin Zhao, Adams Wei Guu, Brian Yu, Nan Lester, Andrew M Du, Quoc V Dai, Le, arXiv:2109.01652Finetuned language models are zero-shot learners. 2021arXiv preprint</p>
<p>Tianwen Wei, Liang Zhao, Lichang Zhang, Bo Zhu, Lijie Wang, Haihua Yang, Biye Li, Cheng Cheng, Weiwei Lü, Rui Hu, arXiv:2310.19341A more open bilingual foundation model. 2023arXiv preprint</p>
<p>Chain-of-experts: When llms meet complex operations research problems. Ziyang Xiao, Dongxiang Zhang, Yangjun Wu, Lilin Xu, Jessica Yuan, Xiongwei Wang, Xiaojin Han, Tao Fu, Jia Zhong, Mingli Zeng, Song, International Conference on Learning Representations. 2023</p>            </div>
        </div>

    </div>
</body>
</html>