<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-964 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-964</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-964</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-20.html">extraction-schema-20</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <p><strong>Paper ID:</strong> paper-a2bf2e83df0c8b3257a8a809cb96c3ea58ec04b3</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/a2bf2e83df0c8b3257a8a809cb96c3ea58ec04b3" target="_blank">Causal inference by using invariant prediction: identification and confidence intervals</a></p>
                <p><strong>Paper TL;DR:</strong> This work proposes to exploit invariance of a prediction under a causal model for causal inference: given different experimental settings (e.g. various interventions) the authors collect all models that do show invariance in their predictive accuracy across settings and interventions, and yields valid confidence intervals for the causal relationships in quite general scenarios.</p>
                <p><strong>Paper Abstract:</strong> What is the difference between a prediction that is made with a causal model and that with a non‐causal model? Suppose that we intervene on the predictor variables or change the whole environment. The predictions from a causal model will in general work as well under interventions as for observational data. In contrast, predictions from a non‐causal model can potentially be very wrong if we actively intervene on variables. Here, we propose to exploit this invariance of a prediction under a causal model for causal inference: given different experimental settings (e.g. various interventions) we collect all models that do show invariance in their predictive accuracy across settings and interventions. The causal model will be a member of this set of models with high probability. This approach yields valid confidence intervals for the causal relationships in quite general scenarios. We examine the example of structural equation models in more detail and provide sufficient assumptions under which the set of causal predictors becomes identifiable. We further investigate robustness properties of our approach under model misspecification and discuss possible extensions. The empirical properties are studied for various data sets, including large‐scale gene perturbation experiments.</p>
                <p><strong>Cost:</strong> 0.013</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e964.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e964.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ICP</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Invariant Causal Prediction</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A causal discovery and inference framework that selects predictor sets whose conditional distribution of the target given the predictors remains invariant across multiple environments/experimental settings; provides hypothesis tests and conservative confidence sets for causal predictors and coefficients.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Invariant Causal Prediction (ICP)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>ICP searches over subsets S of predictors and tests whether the conditional model Y | X_S is identical across environments e in E. For linear models the method equates plausible causal coefficients to the population least-squares regression vector that is constant across environments; it rejects subsets S when population regression coefficients or residual distributions differ across environments. The accepted subsets are intersected to produce a conservative estimate of identifiable causal predictors S(E); pooled-data confidence regions for regression coefficients are produced for accepted sets. Two concrete testing instantiations are provided (Chow-type test of regression coefficients and a faster residual mean/variance test). The method makes no requirement to know intervention targets and controls Type I error for inclusion of non-causal predictors.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Multi-environment / interventional datasets (observational + interventional)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Data are grouped into environments (experimental settings) that may be observational or produced by unknown or known interventions; environments can be arbitrary mixtures of interventional regimes and need not be actively designed by the method. The framework applies when the conditional distribution of Y given the true causal predictors remains invariant across these environments.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Variable selection via invariance testing: only predictors that yield invariant conditional models across environments are retained; intersection across all accepted invariant sets yields robust variable selection. Screening (e.g., Lasso) can be used pre-search to reduce candidate distractors.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Spurious correlations due to changes in marginal distributions across environments, confounding effects that do not preserve conditional invariance, irrelevant/ancillary variables whose association with Y changes across environments, model misspecification across regimes; extensions consider hidden variables/instrumental-variable style confounding.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Statistical tests of invariance across environments: (i) equality of population regression coefficients across environments (Chow-style F-test using leave-one-environment-out OLS predictions and covariance adjustments); (ii) faster residual-based tests comparing residual means and variances across environments (t-tests and F-tests with Bonferroni correction); rejection indicates presence of spurious/non-invariant signals.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Hypothesis testing of null H0_{S}(E) that a single regression vector and residual distribution explain all environments; sets S are rejected when invariance is violated. Accepted sets that survive tests are used to form confidence regions and intersections; thus spurious predictors are refuted by failing invariance tests and excluded from the intersection estimate.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td>Not an active-experiment-design method: assumes given environments (which may arise from interventions) and does not require selecting which experiments to run; pooling/splitting strategies are discussed for trade-offs between power and identifiability but no explicit active intervention selection is prescribed.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Invariant prediction yields conservative guarantees: with valid level-α tests, the estimated predictor set will not include non-causal variables with probability ≥1−α, and pooled confidence sets for causal coefficients have controlled coverage. ICP does not require knowledge of intervention targets, works with unknown/mixture interventions, and identifies parents in linear SEMs under reasonable intervention designs (Theorems 2 and 3). Pooling increases power but may reduce identifiability; screening (e.g., Lasso) can reduce computational cost while retaining coverage.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Causal inference by using invariant prediction: identification and confidence intervals', 'publication_date_yy_mm': '2015-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e964.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e964.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ICP-Chow</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ICP with Chow-style test on regression coefficients (Method I)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A concrete instantiation of ICP using a Chow-type F-test that compares observations in each environment to OLS predictions trained on the complement; tests equality of regression coefficients/fit across environments to detect non-invariance.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>ICP (Method I) — Regression-coefficient invariance test (Chow-style)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>For each candidate set S and each environment e, fit OLS on data excluding environment e, predict on environment e and form prediction residuals D; under Gaussian errors and invariance the test statistic (D' Sigma_D^{-1} D) / (hat{sigma}^2 n_e) follows an F-distribution (Chow test generalization). Reject S if any environment yields p-value < α/|E|. Accepted S produce pooled-data confidence regions for regression coefficients. Uses leave-one-environment-out prediction and covariance-corrected test statistic.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Multi-environment / interventional datasets (observational + interventional)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Same as ICP: grouped data from environments which may be observational or interventional; method requires enough samples per environment for OLS fits and assumes (for the test) Gaussian errors and full-rank design matrices within environments.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Refutation of non-invariant predictors via Chow-style hypothesis testing on regression effects; spurious predictors whose regression contribution changes across environments are rejected.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Environment-specific associations (spurious correlations) manifesting as changes in regression coefficients or residual distributions across environments; selection bias arising from different mixtures of latent regimes across environments.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Chow-type F-test comparing predictions from models trained on complementary environments to observations in the held-out environment; matrix Σ_D accounts for prediction covariance. Bonferroni correction across environments is used.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Reject null of equal regression coefficients/fit across environments; rejected S are considered non-invariant and excluded from candidate causal sets; intersection across accepted S yields robust variable selection.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Provides an exact parametric test under Gaussian errors and full-rank design; suitable when environment-specific OLS fits are feasible but computationally more expensive than residual-based alternatives. The test yields valid Type I control for set rejection and thereby helps refute spurious predictors that change effect across environments.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Causal inference by using invariant prediction: identification and confidence intervals', 'publication_date_yy_mm': '2015-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e964.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e964.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ICP-Residual</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ICP with fast residual-based test (Method II)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A computationally cheaper ICP variant that fits a single pooled regression and tests whether the residuals' mean and variance differ across environments, using t-tests and F-tests with Bonferroni correction.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>ICP (Method II) — Residual mean/variance invariance test</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Fit a single pooled regression for candidate set S to obtain residuals R = Y − X beta_hat. For each environment e compare residual mean (two-sample t-test) and variance (F-test) between I_e and I_{-e}; combine p-values (Bonferroni across environments and two tests) and reject S if combined p-value < α. Faster because it avoids per-environment refitting, and readily extends to generalized models (e.g., logistic or nonlinear) by testing model residuals across environments.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Multi-environment / interventional datasets (observational + interventional)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Same multi-environment setting; method is designed for larger p or many sets S where per-environment refitting is costly; applicable when pooled model residuals are informative about invariance violations.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Detection and elimination of predictors whose inclusion yields residual distributions that vary across environments; effectively refutes spurious predictors by non-invariance of residuals.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Spurious associations that cause changes in conditional mean or conditional variance of residuals across environments, including environmental confounding and changes in noise scale affecting non-causal predictors.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Two-sample t-tests for residual means and F-tests for residual variances between each environment and the complement, combined with Bonferroni correction; uses pooled fit residuals as the basis for detecting non-invariance.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Reject S when residual statistics differ across environments; rejected sets yield empty confidence regions, preventing inclusion of spurious predictors in the intersection estimate.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Faster and more scalable approximate test that trades exactness for computational efficiency; easily generalizable to nonlinear and classification models by testing appropriate residuals, but it ignores sampling variability of coefficients estimated from pooled data.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Causal inference by using invariant prediction: identification and confidence intervals', 'publication_date_yy_mm': '2015-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Causality: Models, Reasoning and Inference <em>(Rating: 2)</em></li>
                <li>A Linear Non-Gaussian Acyclic Model for Causal Discovery <em>(Rating: 2)</em></li>
                <li>Nonlinear causal discovery with additive noise models <em>(Rating: 2)</em></li>
                <li>Information-Geometric Approach to Inferring Causal Directions <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-964",
    "paper_id": "paper-a2bf2e83df0c8b3257a8a809cb96c3ea58ec04b3",
    "extraction_schema_id": "extraction-schema-20",
    "extracted_data": [
        {
            "name_short": "ICP",
            "name_full": "Invariant Causal Prediction",
            "brief_description": "A causal discovery and inference framework that selects predictor sets whose conditional distribution of the target given the predictors remains invariant across multiple environments/experimental settings; provides hypothesis tests and conservative confidence sets for causal predictors and coefficients.",
            "citation_title": "here",
            "mention_or_use": "use",
            "method_name": "Invariant Causal Prediction (ICP)",
            "method_description": "ICP searches over subsets S of predictors and tests whether the conditional model Y | X_S is identical across environments e in E. For linear models the method equates plausible causal coefficients to the population least-squares regression vector that is constant across environments; it rejects subsets S when population regression coefficients or residual distributions differ across environments. The accepted subsets are intersected to produce a conservative estimate of identifiable causal predictors S(E); pooled-data confidence regions for regression coefficients are produced for accepted sets. Two concrete testing instantiations are provided (Chow-type test of regression coefficients and a faster residual mean/variance test). The method makes no requirement to know intervention targets and controls Type I error for inclusion of non-causal predictors.",
            "environment_name": "Multi-environment / interventional datasets (observational + interventional)",
            "environment_description": "Data are grouped into environments (experimental settings) that may be observational or produced by unknown or known interventions; environments can be arbitrary mixtures of interventional regimes and need not be actively designed by the method. The framework applies when the conditional distribution of Y given the true causal predictors remains invariant across these environments.",
            "handles_distractors": true,
            "distractor_handling_technique": "Variable selection via invariance testing: only predictors that yield invariant conditional models across environments are retained; intersection across all accepted invariant sets yields robust variable selection. Screening (e.g., Lasso) can be used pre-search to reduce candidate distractors.",
            "spurious_signal_types": "Spurious correlations due to changes in marginal distributions across environments, confounding effects that do not preserve conditional invariance, irrelevant/ancillary variables whose association with Y changes across environments, model misspecification across regimes; extensions consider hidden variables/instrumental-variable style confounding.",
            "detection_method": "Statistical tests of invariance across environments: (i) equality of population regression coefficients across environments (Chow-style F-test using leave-one-environment-out OLS predictions and covariance adjustments); (ii) faster residual-based tests comparing residual means and variances across environments (t-tests and F-tests with Bonferroni correction); rejection indicates presence of spurious/non-invariant signals.",
            "downweighting_method": null,
            "refutation_method": "Hypothesis testing of null H0_{S}(E) that a single regression vector and residual distribution explain all environments; sets S are rejected when invariance is violated. Accepted sets that survive tests are used to form confidence regions and intersections; thus spurious predictors are refuted by failing invariance tests and excluded from the intersection estimate.",
            "uses_active_learning": false,
            "inquiry_strategy": "Not an active-experiment-design method: assumes given environments (which may arise from interventions) and does not require selecting which experiments to run; pooling/splitting strategies are discussed for trade-offs between power and identifiability but no explicit active intervention selection is prescribed.",
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "Invariant prediction yields conservative guarantees: with valid level-α tests, the estimated predictor set will not include non-causal variables with probability ≥1−α, and pooled confidence sets for causal coefficients have controlled coverage. ICP does not require knowledge of intervention targets, works with unknown/mixture interventions, and identifies parents in linear SEMs under reasonable intervention designs (Theorems 2 and 3). Pooling increases power but may reduce identifiability; screening (e.g., Lasso) can reduce computational cost while retaining coverage.",
            "uuid": "e964.0",
            "source_info": {
                "paper_title": "Causal inference by using invariant prediction: identification and confidence intervals",
                "publication_date_yy_mm": "2015-01"
            }
        },
        {
            "name_short": "ICP-Chow",
            "name_full": "ICP with Chow-style test on regression coefficients (Method I)",
            "brief_description": "A concrete instantiation of ICP using a Chow-type F-test that compares observations in each environment to OLS predictions trained on the complement; tests equality of regression coefficients/fit across environments to detect non-invariance.",
            "citation_title": "here",
            "mention_or_use": "use",
            "method_name": "ICP (Method I) — Regression-coefficient invariance test (Chow-style)",
            "method_description": "For each candidate set S and each environment e, fit OLS on data excluding environment e, predict on environment e and form prediction residuals D; under Gaussian errors and invariance the test statistic (D' Sigma_D^{-1} D) / (hat{sigma}^2 n_e) follows an F-distribution (Chow test generalization). Reject S if any environment yields p-value &lt; α/|E|. Accepted S produce pooled-data confidence regions for regression coefficients. Uses leave-one-environment-out prediction and covariance-corrected test statistic.",
            "environment_name": "Multi-environment / interventional datasets (observational + interventional)",
            "environment_description": "Same as ICP: grouped data from environments which may be observational or interventional; method requires enough samples per environment for OLS fits and assumes (for the test) Gaussian errors and full-rank design matrices within environments.",
            "handles_distractors": true,
            "distractor_handling_technique": "Refutation of non-invariant predictors via Chow-style hypothesis testing on regression effects; spurious predictors whose regression contribution changes across environments are rejected.",
            "spurious_signal_types": "Environment-specific associations (spurious correlations) manifesting as changes in regression coefficients or residual distributions across environments; selection bias arising from different mixtures of latent regimes across environments.",
            "detection_method": "Chow-type F-test comparing predictions from models trained on complementary environments to observations in the held-out environment; matrix Σ_D accounts for prediction covariance. Bonferroni correction across environments is used.",
            "downweighting_method": null,
            "refutation_method": "Reject null of equal regression coefficients/fit across environments; rejected S are considered non-invariant and excluded from candidate causal sets; intersection across accepted S yields robust variable selection.",
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "Provides an exact parametric test under Gaussian errors and full-rank design; suitable when environment-specific OLS fits are feasible but computationally more expensive than residual-based alternatives. The test yields valid Type I control for set rejection and thereby helps refute spurious predictors that change effect across environments.",
            "uuid": "e964.1",
            "source_info": {
                "paper_title": "Causal inference by using invariant prediction: identification and confidence intervals",
                "publication_date_yy_mm": "2015-01"
            }
        },
        {
            "name_short": "ICP-Residual",
            "name_full": "ICP with fast residual-based test (Method II)",
            "brief_description": "A computationally cheaper ICP variant that fits a single pooled regression and tests whether the residuals' mean and variance differ across environments, using t-tests and F-tests with Bonferroni correction.",
            "citation_title": "here",
            "mention_or_use": "use",
            "method_name": "ICP (Method II) — Residual mean/variance invariance test",
            "method_description": "Fit a single pooled regression for candidate set S to obtain residuals R = Y − X beta_hat. For each environment e compare residual mean (two-sample t-test) and variance (F-test) between I_e and I_{-e}; combine p-values (Bonferroni across environments and two tests) and reject S if combined p-value &lt; α. Faster because it avoids per-environment refitting, and readily extends to generalized models (e.g., logistic or nonlinear) by testing model residuals across environments.",
            "environment_name": "Multi-environment / interventional datasets (observational + interventional)",
            "environment_description": "Same multi-environment setting; method is designed for larger p or many sets S where per-environment refitting is costly; applicable when pooled model residuals are informative about invariance violations.",
            "handles_distractors": true,
            "distractor_handling_technique": "Detection and elimination of predictors whose inclusion yields residual distributions that vary across environments; effectively refutes spurious predictors by non-invariance of residuals.",
            "spurious_signal_types": "Spurious associations that cause changes in conditional mean or conditional variance of residuals across environments, including environmental confounding and changes in noise scale affecting non-causal predictors.",
            "detection_method": "Two-sample t-tests for residual means and F-tests for residual variances between each environment and the complement, combined with Bonferroni correction; uses pooled fit residuals as the basis for detecting non-invariance.",
            "downweighting_method": null,
            "refutation_method": "Reject S when residual statistics differ across environments; rejected sets yield empty confidence regions, preventing inclusion of spurious predictors in the intersection estimate.",
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "Faster and more scalable approximate test that trades exactness for computational efficiency; easily generalizable to nonlinear and classification models by testing appropriate residuals, but it ignores sampling variability of coefficients estimated from pooled data.",
            "uuid": "e964.2",
            "source_info": {
                "paper_title": "Causal inference by using invariant prediction: identification and confidence intervals",
                "publication_date_yy_mm": "2015-01"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Causality: Models, Reasoning and Inference",
            "rating": 2
        },
        {
            "paper_title": "A Linear Non-Gaussian Acyclic Model for Causal Discovery",
            "rating": 2
        },
        {
            "paper_title": "Nonlinear causal discovery with additive noise models",
            "rating": 2
        },
        {
            "paper_title": "Information-Geometric Approach to Inferring Causal Directions",
            "rating": 1
        }
    ],
    "cost": 0.0132,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Causal inference using invariant prediction: identification and confidence intervals</h1>
<p>Jonas Peters ${ }^{\text {b,§ }}$, Peter Bühlmann ${ }^{\text { }}$ and Nicolai Meinshausen ${ }^{\text { }}$<br>${ }^{b}$ MPI for Intelligent Systems, Tübingen, Germany<br>${ }^{\text {S }}$ Seminar für Statistik, ETH Zürich, Switzerland<br>{peters,buhlmann,meinshausen}@stat.math.ethz.ch</p>
<p>May 24, 2024</p>
<h4>Abstract</h4>
<p>What is the difference of a prediction that is made with a causal model and a noncausal model? Suppose we intervene on the predictor variables or change the whole environment. The predictions from a causal model will in general work as well under interventions as for observational data. In contrast, predictions from a non-causal model can potentially be very wrong if we actively intervene on variables. Here, we propose to exploit this invariance of a prediction under a causal model for causal inference: given different experimental settings (for example various interventions) we collect all models that do show invariance in their predictive accuracy across settings and interventions. The causal model will be a member of this set of models with high probability. This approach yields valid confidence intervals for the causal relationships in quite general scenarios. We examine the example of structural equation models in more detail and provide sufficient assumptions under which the set of causal predictors becomes identifiable. We further investigate robustness properties of our approach under model misspecification and discuss possible extensions. The empirical properties are studied for various data sets, including large-scale gene perturbation experiments.</p>
<h2>1 Introduction</h2>
<p>Inferring cause-effect relationships between variables is a primary goal in many applications. Such causal inference has its roots in different fields and various concepts have contributed to its understanding and quantification. Among them are the framework of potential outcomes and counterfactuals [cf. Dawid, 2000, Rubin, 2005]; or structural equation modelling [cf. Bollen, 1989, Robins et al., 2000, Pearl, 2009] and graphical modeling [cf. Lauritzen and Spiegelhalter, 1988, Greenland et al., 1999, Spirtes et al., 2000], where the book by Pearl [2009] provides a nice overview. Richardson and Robins [2013] make a connection between the frameworks using single-world intervention graphs.</p>
<p>A typical approach for causal discovery, in the context of unknown causal structure, is to characterise the Markov equivalence class of structures (or graphs) [Verma and Pearl, 1991, Andersson et al., 1997, Tian and Pearl, 2001, Hauser and Bühlmann, 2012], estimate</p>
<p>the correct Markov equivalence class based on observational or interventional data [Spirtes et al., 2000, Chickering, 2002, Castelo and Kocka, 2003, Kalisch and Bühlmann, 2007, He and Geng., 2008, Hauser and Bühlmann, 2015, cf.], and finally infer the identifiable causal effects or provide some bounds [Maathuis et al., 2009, VanderWeele and Robins, 2010, cf.]. More recently, within the framework of structural equation models, interesting work has been done for fully identifiable structures exploiting additional restrictions such as non-Gaussianity [Shimizu et al., 2006], nonlinearity [Hoyer et al., 2009, Peters et al., 2014] or equal error variances [Peters and Bühlmann, 2014]. Janzing et al. [2012] exploit an independence between causal mechanisms.</p>
<p>We propose here a new method for causal discovery. The approach of the paper is to note that if we consider all "direct causes" of a target variable of interest, then the conditional distribution of the target given the the direct causes will not change when we interfere experimentally with all other variables in the model except the target itself. This does not necessarily hold, however, if some of the direct causes are ignored in the conditioning. ${ }^{1}$ We exploit, in other words, that the conditional distribution of the target variable of interest (often also termed "response variable"), given the complete set of corresponding direct causal predictors, has to remain identical under interventions on variables other than the target variable. This invariance idea is closely linked to causality and has been discussed, for example, under the term "autonomy" and "modularity" [Haavelmo, 1944, Aldrich, 1989, Hoover, 1990, Pearl, 2009, Schölkopf et al., 2012] or also "stability" [Dawid and Didelez, 2010] [Pearl, 2009, Sec. 1.3.2]. While it is well-known that causal models have an invariance property, we try to exploit this fact for inference. Our proposed procedure gathers all submodels that are statistically invariant across environments in a suitable sense. The causal submodel consisting of the set of variables with a direct causal effect on the target variable will be one of these invariant submodels, with controlled high probability, and this allows to control the probability of making false causal discoveries.</p>
<p>Our method is tailored for (but not restricted to) the setting where we have data from different experimental settings or regimes [Didelez et al., 2006]. For example, two different interventional data samples, or a combination of observational and interventional data [cf. He and Geng., 2008] belong to such a scenario. For known intervention targets, Cooper and Yoo [1999] incorporate the intervention effects as mechanism changes [Tian and Pearl, 2001] into a Bayesian framework and Hauser and Bühlmann [2015] modify the greedy equivalence search [Chickering, 2002] for perfect interventions. Our framework does not require to know the location of interventions. For this setting, Eaton and Murphy [2007] use intervention nodes with unknown children and Tian and Pearl [2001] consider changes in marginal distributions, while Dawid [2012, 2015] make use of different regimes for a decision-theoretic approach. In contrast to these approaches, our framework does not require the fitting of graphical, structural equation or potential outcome models and comes with statistical guarantees. Further advantages are indicated below in Section 1.2.</p>
<p>We primarily consider the situation with no hidden (confounder) variables that influence the target variable. A rigorous treatment with hidden variables would be more</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: An example including three environments. The invariance (1) and (2) holds if we consider S* = {X2,X4}. Considering indirect causes instead of direct ones (e.g. {X2,X5}) or an incomplete set of direct causes (e.g. {X4}) may not be sufficient to guarantee invariant prediction.</p>
<p>involved [see Richardson and Spirtes, 2002, for graphical language] but we provide an example with instrumental variables in Section 5 to illustrate that the method could also work more generally in the context of hidden variables. We do not touch very much on the framework of feedback models [Lauritzen and Richardson, 2002, Mooij et al., 2011, Hyttinen et al., 2012, cf.], although a constrained form of feedback is allowed. It is an open question whether our approach could be generalised to include general feedback models.</p>
<h3>1.1 Data from multiple environments or experimental settings</h3>
<p>We consider the setting where we have different experimental conditions e ∈ E and have an i.i.d. sample of (X<sup>e</sup>, Y<sup>e</sup>) in each environment, where X<sup>e</sup> ∈ ℝ<sup>p</sup> is a predictor variable and Y<sup>e</sup> ∈ ℝ a target variable of interest. While the environments e ∈ E can be created by precise experimental design for X<sup>e</sup> (for example by randomising some or all elements of X<sup>e</sup>), we are more interested in settings where such careful experimentation is not possible and the different distributions of X<sup>e</sup> in the environments are generated by unknown and not precisely controlled interventions. If a subset S* ⊆ {1, . . . , p} is causal for the prediction of a response Y, we assume that</p>
<p>for all e ∈ E : X<sup>e</sup> has an arbitrary distribution and</p>
<p>$$Y^e = g(X_{S^<em>}^e, \varepsilon^e), \qquad \varepsilon^e \sim F_{\varepsilon} \text{ and } \varepsilon^e \Perp X_{S^</em>}^e,$$</p>
<p>where g : ℝ|S<em>| × ℝ → ℝ is a real-valued function in a suitable function class, X<sup>e</sup><sub>S</em></sub> is the vector of predictors X<sup>e</sup> with indices in a set S<em> and both the error distribution ε<sup>e</sup> ∼ F<sub>ε</sub> and the function g are assumed to be the same for all the experimental settings. Equations (1) and (2) can also be interpreted as requiring that the conditionals Y<sup>e</sup> | X<sup>e</sup><sub>S</em></sub> and Y<sup>f</sup> | X<sup>f</sup><sub>S*} are identical for all environments e, f ∈ E (this equivalence is proved in Section 6.1).</p>
<p>An example of a set of environments can be seen in Figure 1. The invariance (1)</p>
<p>and (2) holds if the set $S^{*}$ consists of all direct causes of the target variable $Y$ and if we do not intervene on $Y$, see Proposition 1.</p>
<p>Sections 5, 6.2 and 6.3 discuss violations and possible relaxations of this assumption.</p>
<h1>1.2 New contribution</h1>
<p>The main and novel idea is that we can use the invariance of the causal relationships under different settings $e \in \mathcal{E}$ for statistical estimation, which opens a new road for causal discovery and inference.</p>
<p>For the sake of simplicity, we will mostly focus on a linear model with a target or response variable and various predictor variables, where Equation (1) is unchanged and (2) then reads $Y^{e}=\mu+X^{e} \gamma^{<em>}+\varepsilon^{e}$, with $\mu$ a constant intercept term. The set $S^{</em>}$ of predictors is then given by the support of $\gamma^{<em>}$, that is $S^{</em>}:=\left{k ; \gamma_{k}^{<em>} \neq 0\right}$. Assumption 1 in Section 2 summarises all requirements. Proposition 1 shows that structural equation models with the traditional notion of interventions [Pearl, 2009] satisfy Assumption 1 if we choose the set $S^{</em>}$ to be the parents of $Y$. Proposition 6 in Appendix D sheds some light on the relationship to potential outcomes.</p>
<p>Obtaining confidence statements for existing causal discovery methods is often difficult as one would need to determine the distribution of causal effects estimators after having searched and estimated a graphical structure of the model. It is unknown how one could do this, except relying on data-splitting strategies which have been found to perform rather poorly in such a setting [Bühlmann et al., 2013]. We propose in Section 3 a new method for the construction of (potentially) conservative confidence statements for causal predictors $S^{<em>}$ and of (potentially) conservative intervals for $\gamma_{j}^{</em>}$ for $j=1, \ldots, p$ without a-priori knowing or assuming a causal ordering of variables. The method provides confidence intervals without relying on assumptions such as faithfulness or other identifiability assumptions. If a causal effect is not identifiable from the given data, it would automatically detect this fact and not make false causal discoveries.</p>
<p>Another main advantage of our methodology is that we do not need to know how the experimental conditions arise or which type of interventions they induce. We only assume that the intervention does not change the conditional distribution of the target given the causal predictors (no intervention on the target or a hidden confounder): it is simply a device exploiting the grouping of data into blocks, where every block corresponds to an experimental condition $e \in \mathcal{E}$. We will show in Section 3.2 that such grouping can be misspecified and the coverage statements are still correct. This is again a major bonus in practice as it is often difficult to specify what an intervention or change of environment actually means. In contrast, for a so-called do-intervention for structural equation models [Pearl, 2009] it needs to be specified on which variables it acts. Interesting areas of applications include studies where observational data alone are not sufficient to infer causal effects but randomised studies are infeasible to conduct.</p>
<p>We believe that the method's underlying invariance principle is rather general. However, for simplicity, we present our main results for linear Gaussian models, including some settings with instrumental variables and hidden variables.</p>
<h1>1.3 Organization</h1>
<p>The invariance assumption is formulated and discussed in Section 2. Using this invariance assumption, a general way to construct confidence statements for causal predictors and associated coefficients is derived in Section 3. Two specific methods are shown, using regression effects for various sets of predictors as the main ingredient. Identifiability results for structural equation models are given in Section 4. The relation to instrumental variables and the behaviour in presence of hidden variables is discussed in Section 5. We will discuss extensions to the nonlinear model (2) in Section 6.1 and extenstions to intervened targets in Section 6.2. Some robustness property against model misspecifications is discussed in Section 6.3.</p>
<p>Simulations and applications to a biological gene perturbation data set and an educational study related to instrumental variables are presented in Section 7. We discuss the results and provide an outlook in Section 8.</p>
<h3>1.4 Software</h3>
<p>The methods are available in the package InvariantCausalPrediction for the R-language [R Core Team, 2014].</p>
<h2>2 Assumed invariance of causal prediction</h2>
<p>We formulate here the invariance assumption and discuss the notion of identifiable causal predictors. Let $\mathcal{E}$ denote again the index set of $|\mathcal{E}|$ possible interventional or experimental settings. As stated above, we have variables $\left(X^{e}, Y^{e}\right)$ with a joint distribution that will in general depend on the environment $e \in \mathcal{E}$. In the simplest case, $|\mathcal{E}|=2$, and we have for example in the first setting observational data and interventions of some (possibly unknown) nature in the second setting.</p>
<p>Our discussion will rest on the following assumption. We assume the existence of a model that is invariant under different experimental or intervention settings. Let for any set $S \subseteq{1, \ldots, p}, X_{S}$ be the vector containing all variables $X_{k}, k \in S$.</p>
<p>Assumption 1 (Invariant prediction) There exists a vector of coefficients $\gamma^{<em>}=\left(\gamma_{1}^{</em>}, \ldots, \gamma_{p}^{<em>}\right)^{t}$ with support $S^{</em>}:=\left{k: \gamma_{k}^{*} \neq 0\right} \subseteq{1, \ldots, p}$ that satisfies</p>
<p>$$
\begin{aligned}
\text { for all } e \in \mathcal{E}: \quad X^{e} \text { has an arbitrary distribution and } \
Y^{e}=\mu+X^{e} \gamma^{<em>}+\varepsilon^{e}, \quad \varepsilon^{e} \sim F_{\varepsilon} \text { and } \varepsilon^{e} \Perp X_{S^{</em>}}^{e}
\end{aligned}
$$</p>
<p>where $\mu \in \mathbb{R}$ is an intercept term, $\varepsilon^{e}$ is random noise with mean zero, finite variance and the same distribution $F_{\varepsilon}$ across all $e \in \mathcal{E}$.</p>
<p>The distribution $F_{\varepsilon}$ is not assumed to be known in general. If not mentioned otherwise, we will always assume that an intercept $\mu$ is added to the model (3). To simplify notation, we will from now on refrain from writing the intercept down explicitly. We discuss the invariance assumption with the help of some examples in Figure 1 and 2; see also Appendix A for another artificial example.</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: Some examples from the gene-knockout experiments in Kemmeren et al. [2014], which will be discussed in more detail in Section 7.2. Each panel shows the distribution of a target gene activity Y (on the respective y-axis), conditional on a predictor gene activity X (shown on respective x-axis). Blue crosses show observational data and red dots show interventional data. The interventions do not occur on any of the shown genes. The conditional distribution of Y, given X, is not invariant for the examples in the first row, while invariance cannot be rejected for the two examples in the bottom row. Take the example of the bottom left panel. The variance of the activity of gene YMR321C is clearly higher for interventional than observational data, so we can reject that the invariance assumption holds for the empty set S = ∅. However, if conditioning on the activity X of gene YPL273W, the conditional distribution of the activity Y of gene YMR321C is not significantly different between interventional and observational data, so that the set S = {YPL273W} fulfils the invariance assumption (3), at least approximately.</p>
<p>We observe each unit $i$ in only one experimental setting. The distribution of the error $\varepsilon^{e}$ is assumed to stay identical across all environments (though see Sections 6.2 and 6.3 for approaches when this assumption is violated). It is in general not possible to estimate the correlation between the noise variables $\varepsilon_{i}^{e}$ and $\varepsilon_{i}^{f}$ for a single unit $i$ in different hypothetical environments $e$ and $f$, as the outcome is observed for only one environment [Dawid, 2006, 2012]. Knowledge of the correlation would be necessary to answer counterfactual questions about the outcome. Knowledge of the correlation is not necessary for our method.</p>
<p>We deliberately avoid the term "causality" in Assumption 1 in order to keep it purely mathematical. Proposition 1 establishes a link to causality by showing that the parents of $Y$ in a structural equation model (SEM) satisfy Assumption 1. In other words, the variables that have a direct causal effect on $Y$ in a SEM form a set $S^{<em>}$ for which Assumption 1 is satisfied. This must not necessarily be true for the variables that have an (in)direct effect on $Y$, i.e., the ancestors of $Y$. However, the set $S^{</em>}$ is not necessarily unique. For a given set of experimental conditions $\mathcal{E}$, there can be multiple vectors $\gamma^{<em>}$ that satisfy (3). For example, if only observational data are available, i.e. all environments are identical, it is apparent that for any model (3) the distribution $F_{\varepsilon}$ of the residuals $\varepsilon^{e}$ does not depend on $e$. If additionally $(X, Y)$ have a joint Gaussian distribution and $X$ and $Y$ are not independent, for example, then one can find a solution $\gamma^{</em>}$ to (3) for every subset $S^{<em>} \subseteq{1, \ldots, p}$. The inference we propose works for any possible choice among the set of solutions. We can at most identify the subset of $S^{</em>}$ that is common among all possible solutions of (3), see Section 4 for settings with complete identifiability.</p>
<p>It is perhaps easiest to think about the example of a linear structural equation model (SEM), as defined in Section 4.1, see also Figure 8 in Appendix A. We show in the following proposition that the set of parents of $Y$ in a linear SEM is a valid set $S^{*}$ satisfying (3).</p>
<p>Proposition 1 Consider a linear structural equation model, as formally defined in Section 4.1, for the variables $\left(X_{1}=Y, X_{2}, \ldots, X_{p}, X_{p+1}\right)$, with coefficients $\left(\beta_{j k}\right)<em 1="1">{j, k=1, \ldots, p+1}$, whose structure is given by a directed acyclic graph. The independence assumption on the noise variables in Section 4.1 can here be replaced by the strictly weaker assumption that $\varepsilon</em>(1)$ are the ancestors of $Y$. Then Assumption 1 holds for the parents of $Y$, namely $S^{}^{e} \Perp\left{\varepsilon_{j}^{e} ; j \in \mathbf{A N}(1)\right}$ for all environments $e \in \mathcal{E}$, where $\mathbf{A N<em>}=\mathbf{P A}(1)$, and $\gamma^{</em>}=\beta_{1,}$. as defined in Section 4.1, under the following assumption:
for each $e \in \mathcal{E}$ : the experimental setting e arises by one or several interventions on variables from $\left{X_{2}, \ldots, X_{p+1}\right}$ but interventions on $Y$ are not allowed; here, we allow for do-interventions [Pearl, 2009] (see also Section 4.2.1, and note that the assigned values can be random, too), or soft-interventions [Eberhardt and Scheines, 2007] (see also Sections 4.2.2 and 4.2.3).</p>
<p>Proof. It follows by the definition of the interventions in Section 4.2 and because the interventions do not act on the target variable $Y$, that $Y^{e}=\sum_{j \in \mathbf{P A}(1)} \beta_{1, j} X_{j}^{e}+\varepsilon_{Y}^{e}$ for all $e \in \mathcal{E}$, where $\varepsilon_{Y}^{e}=\varepsilon_{1}^{e}$ is independent of $X_{\mathbf{P A}(1)}$ and has the same distribution for all $e \in \mathcal{E}$. Thus, Assumption 1 holds.</p>
<p>We remark that Proposition 1 can be generalised to include some hidden variables: the exact statement is given in Proposition 4 in Appendix B.</p>
<p>Instead of allowing only do- or soft-interventions in Proposition 1, we can allow for more general interventions which could change the structural equations for $X_{2}, \ldots, X_{p+1}$ (including for example a change in the graphical structure of the model among the variables $\left.X_{2}, \ldots, X_{p+1}\right)$, as long as the conditional distribution of $Y^{e}$ given $X_{S^{e}}^{e}$ remains the same. Such a weaker requirement is sometimes referred to as "modularity" [Pearl, 2009] or what is called "autonomy" [Haavelmo, 1944, Aldrich, 1989]; structural equations are autonomous if whenever we replace one of them due to an intervention, all other structural equations do not change, they remain invariant. The remaining part of the condition in Proposition 1 about excluding interventions on the target variable $Y$ is often verifiable in many applications; see Sections 6.2 and 6.3 for violations of this assumption.</p>
<p>Proposition 1 refers to standard linear SEMs that do not allow for feedback cycles. We may, however, include feedback into the SEM and consider equilibrium solutions of the new set of equations. The independence assumption between $\varepsilon^{e}$ and $X_{S}^{e}$, allows for some feedback cycles in the linear SEM. The independence assumption prohibits, however, cycles that include the target variable $Y$. We will leave it as an open question to what extent the approach can be generalised to more general forms of feedback models.</p>
<p>It is noteworthy that our inference is valid for any set that satisfies Assumption 1 and not only parents in a linear SEM. For the following statements we do not specify whether the set $S^{*}$ refers to the set of parents in a linear SEM or any other set that satisfies (3), as the confidence guarantees will be valid in either case. Proposition 6 in Appendix D discusses some relationship to the potential outcome framework.</p>
<h1>2.1 Plausible causal predictors and identifiable causal predictors</h1>
<p>In general, $\left(\gamma^{<em>}, S^{</em>}\right)$ is not the only pair that satisfies the assumption of invariance in (3). We therefore define for $\gamma \in \mathbb{R}^{p}$ and $S \subseteq{1, \ldots, p}$ the null hypothesis $H_{0, \gamma, S}(\mathcal{E})$ as</p>
<p>$$
H_{0, \gamma, S}(\mathcal{E}): \quad \gamma_{k}=0 \text { if } k \notin S \quad \text { and } \quad\left{\begin{array}{l}
\exists F_{\varepsilon} \text { such that for all } e \in \mathcal{E} \
Y^{e}=X^{e} \gamma+\varepsilon^{e}, \text { where } \varepsilon^{e} \Perp X_{S}^{e} \text { and } \varepsilon^{e} \sim F_{\varepsilon}
\end{array}\right.
$$</p>
<p>As stated above, we have dropped the constant intercept notationally. The variables that appear in any set $S$ that satisfies $H_{0, S}(\mathcal{E})$, we call plausible causal predictors.</p>
<h2>Definition 1 (Plausible causal predictors and coefficients)</h2>
<p>(i) We call the variables $S \subseteq{1, \ldots, p}$ plausible causal predictors under $\mathcal{E}$ if the following null hypothesis holds true:</p>
<p>$$
H_{0, S}(\mathcal{E}): \quad \exists \gamma \in \mathbb{R}^{p} \text { such that } H_{0, \gamma, S}(\mathcal{E}) \text { is true. }
$$</p>
<p>(ii) The identifiable causal predictors under interventions $\mathcal{E}$ are defined as the following subset of plausible causal predictors</p>
<p>$$
S(\mathcal{E}):=\bigcap_{S: H_{0, S}(\mathcal{E}) \text { is true }} S=\bigcap_{\gamma \in \Gamma(\mathcal{E})}\left{k: \gamma_{k} \neq 0\right}
$$</p>
<p>Here, $\Gamma(\mathcal{E})$ is defined in (13) below (the second equation in (6) can be ignored for now). Under Assumption 1, $H_{0, \gamma^{<em>}, S^{</em>}}(\mathcal{E})$ is true and therefore $S^{<em>}$ are plausible causal predictors, that is $H_{0, S^{</em>}}(\mathcal{E})$ is correct, too. The identifiable causal predictors are thus a subset of the true causal predictors,</p>
<p>$$
S(\mathcal{E}) \subseteq S^{*}
$$</p>
<p>This fact will guarantee the coverage properties of the estimators we define below. Furthermore, the set of identifiable causal predictors under interventions $\mathcal{E}$ is growing monotonically if we enlarge the set $\mathcal{E}$,</p>
<p>$$
S\left(\mathcal{E}<em 2="2">{1}\right) \subseteq S\left(\mathcal{E}</em>}\right) \quad \text { for two sets of environments } \mathcal{E<em 2="2">{1}, \mathcal{E}</em>} \text { with } \quad \mathcal{E<em 2="2">{1} \subseteq \mathcal{E}</em>
$$</p>
<p>In particular, if $|\mathcal{E}|=1$ (for example, there is only observational data), then $S(\mathcal{E})=\emptyset$ because $H_{0, \emptyset}(\mathcal{E})$ will be true. The set of identifiable causal predictors under a single environment is thus empty and we make no statement as to which variables are causal.</p>
<p>In Section 4, we examine conditions for structural equation models (see Proposition 1) under which $S(\mathcal{E})$ is identical to the parents of $Y$ we thus have complete identifiability of the causal coefficients. In practice, the set $\mathcal{E}$ of experimental settings might often be such that $S(\mathcal{E})$ identifies some but not all parents of $Y$ in a SEM.</p>
<h1>2.2 Plausible causal coefficients</h1>
<p>We have seen that the null hypothesis (4) $H_{0, \gamma, S}(\mathcal{E})$ is in general not only fulfilled for $\gamma^{<em>}$ and its support $S^{</em>}$ but also potentially for other vectors $\gamma \in \mathbb{R}^{p}$. This is true especially if the experimental settings $\mathcal{E}$ are very similar to each other. If we consider again the extreme example of just a single environment, $|\mathcal{E}|=1$, and a multivariate Gaussian distribution for $(X, Y)$, we can find for any set $S \subseteq{1, \ldots, p}$ a vector $\gamma$ with support $S$ that fulfills the null hypothesis $H_{0, \gamma, S}(\mathcal{E})$, namely by using the regression coefficient when regressing $Y$ on $X_{S}$. If the interventions that produce the environments $\mathcal{E}$ are stronger and we have more of those environments, the set of vectors that fulfill the null becomes smaller. We call vectors that fulfill the null hypothesis plausible causal coefficients.</p>
<p>Definition 2 (Plausible causal coefficients) We define the set $\Gamma_{S}(\mathcal{E})$ of plausible causal coefficients for the set $S \subseteq{1, \ldots, p}$ and the global set $\Gamma(\mathcal{E})$ of plausible causal coefficients under $\mathcal{E}$ as</p>
<p>$$
\begin{aligned}
\Gamma_{S}(\mathcal{E}) &amp; :=\left{\gamma \in \mathbb{R}^{p}: H_{0, \gamma, S}(\mathcal{E}) \text { is true }\right} \
\Gamma(\mathcal{E}) &amp; :=\bigcup_{S \subseteq{1, \ldots, p}} \Gamma_{S}(\mathcal{E})
\end{aligned}
$$</p>
<p>Thus,</p>
<p>$$
\Gamma\left(\mathcal{E}<em 2="2">{1}\right) \supseteq \Gamma\left(\mathcal{E}</em>}\right) \quad \text { for two sets of environments } \mathcal{E<em 2="2">{1}, \mathcal{E}</em>} \text { with } \quad \mathcal{E<em 2="2">{1} \subseteq \mathcal{E}</em>
$$</p>
<p>The global set of plausible causal coefficients $\Gamma(\mathcal{E})$ is, in other words, shrinking as we enlarge the set $\mathcal{E}$ of possible experimental settings.</p>
<p>The null hypothesis $H_{0, S}(\mathcal{E})$ in (5) can be simplified. Writing</p>
<p>$$
\beta^{\text {pred, } e}(S):=\operatorname{argmin}<em k="k">{\beta \in \mathbb{R}^{p}: \beta</em>
$$}=0 \text { if } k \notin S} E\left(Y^{e}-X^{e} \beta\right)^{2</p>
<p>for the least-squares population regression coefficients when regressing the target of interest onto the variables in $S$ in experimental setting $e \in \mathcal{E}$, we obtain the equivalent formulation of the null hypothesis for set $S \subseteq{1, \ldots, p}$,</p>
<p>$$
H_{0, S}(\mathcal{E}): \quad\left{\begin{array}{l}
\exists \beta \in \mathbb{R}^{p} \text { and } \exists F_{\varepsilon} \text { such that for all } e \in \mathcal{E} \text { we have } \
\beta^{\text {pred }, e}(S) \equiv \beta \text { and } Y^{e}=X^{e} \beta+\varepsilon^{e}, \text { where } \varepsilon^{e} \Perp X_{S}^{e} \text { and } \varepsilon^{e} \sim F_{\varepsilon}
\end{array}\right.
$$</p>
<p>We conclude that</p>
<p>$$
\Gamma_{S}(\mathcal{E})=\left{\begin{array}{cl}
\emptyset &amp; \text { if } H_{0, S}(\mathcal{E}) \text { is false } \
\beta^{\text {pred }, e}(S) &amp; \text { otherwise. }
\end{array}\right.
$$</p>
<p>In other words, the set of plausible causal coefficients for a set $S$ is either empty or contains only the population regression vector. We will make use of this fact further below in Section 3 when computing empirical estimators.</p>
<h1>3 Estimation of identifiable causal predictors</h1>
<p>We would like to estimate the set $S(\mathcal{E})$ of identifiable causal predictors (6) when observing the distribution of $\left(X^{e}, Y^{e}\right)$ under different experimental conditions $e \in \mathcal{E}$. At the same time, we might be interested in obtaining confidence intervals for the linear causal coefficients.</p>
<p>Recall again the definition (5) of the null hypothesis $H_{0, S}(\mathcal{E})$. Suppose for the moment that a statistical test for $H_{0, S}(\mathcal{E})$ with size smaller than a significance level $\alpha$ is available. Then the construction of an estimator $\hat{S}(\mathcal{E})$ and confidence sets $\hat{\Gamma}(\mathcal{E})$ for the causal coefficients can work as follows.</p>
<h2>Generic method for invariant prediction</h2>
<p>1) For each set $S \subseteq{1, \ldots, p}$, test whether $H_{0, S}(\mathcal{E})$ holds at level $\alpha$ (we will discuss later concrete examples).
2) Set $\hat{S}(\mathcal{E})$ as</p>
<p>$$
\hat{S}(\mathcal{E}):=\bigcap_{S: H_{0, S}(\mathcal{E}) \text { not rejected }} S
$$</p>
<p>3) For the confidence sets, define</p>
<p>$$
\hat{\Gamma}(\mathcal{E}):=\bigcup_{S \subseteq{1, \ldots, p}} \hat{\Gamma}_{S}(\mathcal{E})
$$</p>
<p>where</p>
<p>$$
\hat{\Gamma}<em 0_="0," S="S">{S}(\mathcal{E}):=\left{\begin{array}{cl}
\emptyset &amp; H</em> \alpha \
\hat{C}(S) &amp; \text { otherwise. }
\end{array}\right.
$$}(\mathcal{E}) \text { can be rejected at level </p>
<p>Here, $\hat{C}(S)$ is a $(1-\alpha)$-confidence set for the regression vector $\beta^{\text {pred }}(S)$ that is obtained by pooling the data.
As an example, consider again Figure 2. Taking the example in the bottom left panel, we cannot reject $H_{0, S}(\mathcal{E})$ for $S={$ YPL273W $}$. Hence we can see already from this plot that $\hat{S}(\mathcal{E})$ is either empty or that $\hat{S}(\mathcal{E})={Y P L 273 W}$. The latter case happens if no</p>
<p>further set of variables is accepted that does not include the activity of gene YPL273W as predictor.</p>
<p>A justification for pooling the data in (14) is given in Section 3.2. (The construction is also valid if the confidence set is based only on data from a single environment, but a confidence set for the pooled data will be smaller in general.) This defines a whole family of estimators and confidence sets as we have flexibility in the test we are using for the null hypothesis (5) and how the confidence interval $\hat{C}(S)$ is constructed.</p>
<p>If the test and pooled confidence interval have the claimed size and coverage probability, we can guarantee coverage of the true causal predictors and the true causal coefficient, as shown below in Theorem 1.</p>
<p>Theorem 1 Assume that the estimator $\hat{S}(\mathcal{E})$ is constructed according to (12) with a valid test for $H_{0, S}(\mathcal{E})$ for all sets $S \subseteq{1, \ldots, p}$ at level $\alpha$ in the sense that for all $S$, $\sup <em 0_="0," S="S">{P: H</em>)\right.$ rejected $] \leq \alpha$. Consider now a distribution $P$ over $(Y, X)$ and consider any $\gamma^{}(\mathcal{E}) \text { true }} P\left[H_{0, S}(\mathcal{E<em>}$ and $S^{</em>}$ such that Assumption 1 holds. Then, $\hat{S}(\mathcal{E})$ satisfies</p>
<p>$$
P\left[\hat{S}(\mathcal{E}) \subseteq S^{*}\right] \geq 1-\alpha
$$</p>
<p>If, moreover, for all $(\gamma, S)$ that satisfy Assumption 1, the confidence set $\hat{C}(S)$ in (14) satisfies $P[\gamma \in \hat{C}(S)] \geq 1-\alpha$ then the set $\hat{\Gamma}(\mathcal{E})(13)$ has coverage at least level $1-2 \alpha$ :</p>
<p>$$
P\left[\gamma^{*} \in \hat{\Gamma}(\mathcal{E})\right] \geq 1-2 \alpha
$$</p>
<p>Proof. The first property follows immediately since</p>
<p>$$
P\left[\hat{S}(\mathcal{E}) \subseteq S^{<em>}\right]=P\left[\bigcap_{S: H_{0, S}(\mathcal{E}) \text { not rejected }} S \subseteq S^{</em>}\right] \geq P\left[H_{0, S^{*}}(\mathcal{E}) \text { not rejected }\right] \geq 1-\alpha
$$</p>
<p>where the last inequality follows by the assumption that the test for $H_{0, S}$ is valid at level $\alpha$ for all sets $S \subseteq{1, \ldots, p}$. The second property follows since</p>
<p>$$
P\left[\gamma^{<em>} \notin \hat{\Gamma}(\mathcal{E})\right] \leq P\left[H_{0, S^{</em>}}(\mathcal{E}) \text { rejected or } \gamma^{<em>} \notin \hat{C}\left(S^{</em>}\right)\right] \leq \alpha+\alpha=2 \alpha
$$</p>
<p>The confidence sets thus have the correct (conservative) coverage. The estimator of the causal predictors will, with probability at least $1-\alpha$, not erroneously include non-causal predictors. Note that the statement is true for any set of experimental or intervention settings. In the worst case, the set $\hat{S}(\mathcal{E})$ might be empty but the error control is valid nonetheless.</p>
<p>Since Theorem 1 holds for any $\gamma^{<em>}, S^{</em>}$ which fulfil Assumption 1, and assuming the setting of Proposition 1, we obtain the corresponding confidence statements for the causal coefficients and causal variables in a linear structural equation model, that is for $\gamma^{<em>}=\beta_{1,}$. and $S^{</em>}=\mathbf{P A}(1)$ in the notation of Proposition 1.</p>
<p>Remark 1 (i) We obtain the following empirical version of (6):</p>
<p>$$
\hat{S}(\mathcal{E})=\bigcap_{\gamma \in \hat{\Gamma}(\mathcal{E})}\left{k: \gamma_{k} \neq 0\right}=\bigcap_{S: H_{0, S}(\mathcal{E}) \text { not rejected at } \alpha} S
$$</p>
<p>provided that if $H_{0, S}(\mathcal{E})$ is not rejected, then for all $\gamma \in \hat{\Gamma}<em 0_="0," _operatorname_supp="\operatorname{supp">{S}(\mathcal{E})$ we have $\operatorname{supp}(\gamma) \subseteq S$ and $H</em>)$ is not rejected either.
(ii) In (14), we have constructed confidence sets $\hat{\Gamma}}(\gamma)}(\mathcal{E<em 0_="0," S="S">{S}(\mathcal{E})$ based on a test for $H</em>}(\mathcal{E})$. Alternatively, confidence sets $\hat{\Gamma<em 0_="0," S="S">{S}(\mathcal{E})$ may be available that are not based on a test procedure for $H</em>)$.}(\mathcal{E})$. In this case, we may take them as a starting point and define $\hat{S}(\mathcal{E})$ using the first equality in (15), instead of (12). Analogously to Theorem 1, the correct coverage property of $\hat{\Gamma}_{S^{*}}(\mathcal{E})$ then implies confidence statements for $\hat{\Gamma}(\mathcal{E})$ and $\hat{S}(\mathcal{E</p>
<h1>3.1 Two concrete proposals</h1>
<p>The missing piece in the generic procedure given by (12) and (13) is a test for $H_{0, S}(\mathcal{E})$ that is valid at level $\alpha$ for any given set of variables $S \subseteq{1, \ldots, p}$ and thus implies</p>
<p>$$
P\left[H_{0, S^{*}}(\mathcal{E}) \text { rejected }\right] \leq \alpha
$$</p>
<p>To specify a concrete procedure and derive its statistical properties, we assume throughout the paper that the data consist of $n$ independent observations. Within each experimental setting $e$, we assume that we receive $n_{e}$ independent and identically distributed data points from $\left(X^{e}, Y^{e}\right)$ and thus, $\sum_{e \in \mathcal{E}} n_{e}=n$.</p>
<p>We now propose a way to construct such a test, but acknowledge that different choices are possible. Our construction will be based on the fact that the causal coefficients are identical to the regression effects in all experimental settings $e \in \mathcal{E}$ if we consider only variables in the set $S^{*}$ of causal predictors.</p>
<p>For experimental setting $e \in \mathcal{E}$ and a subset $S$ of variables, define the regression coefficients $\beta^{\text {pred, } e}(S) \in \mathbb{R}^{p}$ as above in (9). Define further the population residual standard deviations when regressing $Y^{e}$ on variables $X_{S}^{e}$ as</p>
<p>$$
\sigma^{e}(S):=\left[E\left(Y^{e}-X^{e} \beta^{\text {pred, } e}(S)\right)^{2}\right]^{1 / 2}
$$</p>
<p>These definitions are population quantities. The corresponding sample quantities are denoted with a hat. As mentioned above, under Assumption 1, for $S=S^{*}$, the regression effects are identical to the causal coefficients: for all $e \in E$,</p>
<p>$$
\beta^{\text {pred, } e}\left(S^{<em>}\right) \equiv \gamma^{</em>} \quad \text { and } \quad \sigma^{e}\left(S^{*}\right) \equiv \operatorname{Var}\left(F_{\varepsilon}\right)^{1 / 2}
$$</p>
<p>To get a test valid at level $\alpha$ for all subsets $S$ of predictor variables, we first weaken $H_{0, S}(\mathcal{E})$ in (10) to</p>
<p>$$
\tilde{H}<em _="+">{0, S}(\mathcal{E}): \quad \exists(\beta, \sigma) \in \mathbb{R}^{p} \times \mathbb{R}</em>
$$} \text {such that } \beta^{\text {pred, } e}(S) \equiv \beta \text { and } \sigma^{e}(S) \equiv \sigma \text { for all } e \in \mathcal{E</p>
<p>The null hypothesis $\tilde{H}_{0, S}(\mathcal{E})$ is true whenever the original null hypothesis (10) is true. As in (14), we set</p>
<p>$$
\hat{\Gamma}<em 0_="0," S="S">{S}(\mathcal{E}):= \begin{cases}\emptyset &amp; \tilde{H}</em>
$$}(\mathcal{E}) \text { can be rejected at level } \alpha \ \hat{C}(S) &amp; \text { otherwise }\end{cases</p>
<p>We now give a concrete example which we will use in the numerical examples under the assumption of Gaussian errors and that the design matrix $\mathbf{X}<em e="e">{e}$ of all $n</em>$ samples in</p>
<p>experimental setting $e \in \mathcal{E}$ has full rank. (We write the design matrix in bold letters, as opposed to the random variables $X^{e}$.) The whole procedure is then a specific version of the general procedure given further above, where we use a specific test in the first step (the second step is unchanged).</p>
<h1>Method I: Invariant prediction using test on regression coefficients</h1>
<p>1) For each $S \subseteq{1, \ldots, p}$ and $e \in \mathcal{E}$ :
(a) Let $I_{e}$ with $n_{e}=\left|I_{e}\right|$ be the set of observations where experimental setting $e \in$ $\mathcal{E}$ was active. Likewise, let $I_{-e}={1, \ldots, n} \backslash I_{e}$ with $n_{-e}:=\left|I_{-e}\right|$ be the set of observations when using only observations where experimental setting $e \in \mathcal{E}$ was not active. Let $\mathbf{X}<em e="e">{e, S}$ be the $n</em>} \times(1+|S|)$-dimensional matrix when using all samples in $I_{e}$ and all predictor variables in $S$, adding an intercept term to the design matrix as mentioned previously. If $S=\emptyset$, the matrix consists only of a single intercept column. Analogously, $\mathbf{X<em -e="-e">{-e, S}$ is defined with the samples in $I</em>}$. Let $\hat{Y<em e="e">{e}$ be the predictions for observations in set $I</em>}$ when using the OLS estimator computed on samples in $I_{-e}$ and let $D:=Y_{e}-\hat{Y<em e="e">{e}$ be the difference between the actual observations $Y</em>$ and the predictions.
(b) Under Gaussian errors, if (16) is true for a set $S$, then [Chow, 1960]}$ on $I_{e</p>
<p>$$
\frac{D^{t} \Sigma_{D}^{-1} D}{\hat{\sigma}^{2} n_{e}} \sim F\left(n_{e}, n_{-e}-|S|-1\right)
$$</p>
<p>where $\hat{\sigma}^{2}$ is the estimated variance on the set $I_{-e}$ on which the OLS estimator is computed. The covariance matrix $\Sigma_{D}$ is given by</p>
<p>$$
\Sigma_{D}=1_{n_{e}}+\mathbf{X}<em -e_="-e," S="S">{e, S}\left(\mathbf{X}</em>}^{t} \mathbf{X<em S="S" e_="e,">{-e, S}\right)^{-1} \mathbf{X}</em>
$$}^{t</p>
<p>letting $1_{n}$ be the identity matrix in $n$-dimensions. For any set $S$, we reject the null hypothesis $\hat{H}<em S="S">{0, S}(\mathcal{E})$ if the $p$-value of (17) is below $\alpha /|\mathcal{E}|$ for any $e \in \mathcal{E}$.
2) As in the generic algorithm, using (12).
3) If we do reject a set $S$ we set $\hat{\Gamma}</em>}(\mathcal{E})=\emptyset$. Otherwise, we set $\hat{\Gamma<em k="k">{S}(\mathcal{E})$ to be a $(1-\alpha)$ confidence interval for $\beta^{\text {pred }}(S)$ when using all data simultaneously. For simplicity, we will use a rectangular confidence region where the constraint for $\beta^{\text {pred }}(S)</em>(S)\right)}$ is identically 0 if $k \notin S$ and for coefficients in $S$ given by $\left(\hat{\beta}^{\text {pred }<em 1-_alpha="1-\alpha" _2_S_="/(2|S|)," n-_S_-1="n-|S|-1">{S} \pm t</em>} \cdot \hat{\sigma} \operatorname{diag}\left(\left(\mathbf{X<em S="S">{S}^{t} \mathbf{X}</em>}\right)^{-1}\right)$, where $\mathbf{X<em 1-_alpha:="1-\alpha:" q="q">{S}$ is the design matrix of the pooled data when using variables in $S, t</em>$ the estimated residual variance.}$ is the $(1-\alpha)$-quantile of a t-distribution with $q$ degrees of freedom, and $\hat{\sigma}^{2</p>
<p>A justification of the pooling in step 3 is given in Section 3.2. The procedure above has some shortcomings. For example, the inversion of the covariance matrix in (17) might be too slow if we have to search many sets and the sample size is large. One can then just work with a random subsample of the set $I_{e}$ of size, say, a few hundred, to speed up the computation. It also depends on the assumption of Gaussian errors, although this could be addressed by using rank tests or other nonparametric procedures. Lastly, it is not straightforward to extend this approach to classification and nonlinear models.</p>
<p>We thus provide a second possibility. The fast approximate version below is not fitting a model on each experimental setting separately as in Method I, but is just fitting one global model to all data and comparing the distribution of the residuals in each experimental setting. This is ignoring the sampling variability of the coefficient estimates but leads to</p>
<p>a faster procedure.</p>
<h1>Method II: Invariant prediction using fast(er) approximate test on residuals</h1>
<p>1) For each $S \subseteq{1, \ldots, p}$ and $e \in \mathcal{E}$ :
(a) Fit a linear regression model on all data to get an estimate $\hat{\beta}^{\text {pred }}(S)$ of the optimal coefficients using set $S$ of variables for linear prediction in regression. Let $R=Y-$ $X \hat{\beta}^{\text {pred }}(S)$.
(b) Test the null hypothesis that the mean of $R$ is identical for each set $I_{e}$ and $e \in \mathcal{E}$, using a two-sample t-test for residuals in $I_{e}$ against residuals in $I_{-e}$ and combing via Bonferroni correction across all $e \in \mathcal{E}$. Furthermore, test whether the variances of $R$ are identical in $I_{e}$ and $I_{-e}$, using an F-test, and combine again via Bonferroni correction for all $e \in \mathcal{E}$. Combine the two $p$-values of equal variance and equal mean by taking twice the smaller of the two values. If the $p$-value for the set $S$ is smaller than $\alpha$, we reject the set $S$.
2) As in the generic algorithm, using (12).
3) If we do reject a set $S$ we set $\hat{\Gamma}<em S="S">{S}(\mathcal{E})=\emptyset$. Otherwise, we set $\hat{\Gamma}</em>(S)$ when using all data simultaneously. For simplicity, we will use rectangular confidence regions, exactly as in step 3 of Method I.}(\mathcal{E})$ to be the conventional $(1-\alpha)$-confidence region for $\beta^{\text {pred }</p>
<p>Besides a computational advantage, the method can also easily be extended to nonlinear and logistic regression models. For logistic regression, one can test the residuals $R=Y-\hat{f}(X)$ for equal mean across the experimental settings, for example.</p>
<h3>3.2 Data pooling</h3>
<p>So far, we have assumed that the set $\mathcal{E}$ of experimental settings is given and fixed. An experimental setting $e \in \mathcal{E}$ can for example correspond to
(i) observational data;
(ii) a known intervention of a certain type at a known variable;
(iii) a random intervention at an unknown and random location;
(iv) observational data in a changed environment.</p>
<p>We have used data pooling in Methods I and II to get confidence intervals for the regression coefficients (which is not necessary but increases power in general). A justification of this pooling is in order. The joint distribution of $\left(X_{S^{<em>}}^{e}, Y^{e}\right)$ will vary in general with $e \in \mathcal{E}$. Under Assumption 1, however, the conditional distribution $Y^{e} \mid X_{S^{</em>}}^{e}$ is constant as a function of $e \in \mathcal{E}$, see Section 6.1. As long as our tests and confidence intervals require only an invariant conditional distribution for $S^{*}$ (which is the case for the procedures given above), we can pool data from various $e \in \mathcal{E}$.</p>
<p>To make it more precise, assume there is a set of countably many experimental settings or interventions $\mathcal{J}$ and $\left(X^{j}, Y^{j}\right)$ follow a certain distribution $F_{j}$ for each $j \in \mathcal{J}$. Then each encountered experimental setting $e$ can be considered to be equivalent to a probability mixture distribution over the experimental settings in $\mathcal{J}$, that is</p>
<p>$$
F_{e}=\sum_{j \in \mathcal{J}} w_{j}^{e} F_{j}
$$</p>
<p>where $w_{j}^{e}$ corresponds to the probability that an observation under setting $e$ follows the distribution $F_{j}$. We can then pool two experimental settings $e_{1}$ and $e_{2}$, for example, thereby creating a new experimental setting with the averaged weights $\left(w^{e_{1}}+w^{e_{2}}\right) / 2$.</p>
<p>Pooling is a trade-off between identifiability and statistical power, assuming that Assumption 1 holds for the settings from $\mathcal{J}$. The richer the set $\mathcal{E}$ of experimental settings, the smaller the set $\Gamma(\mathcal{E})$ of plausible causal coefficients will be and the larger the set of identifiable causal predictors $S(\mathcal{E})$. By pooling data, we make the set of identifiable causal variables smaller, that is $S(\mathcal{E})$ is shrinking as we reduce the number $|\mathcal{E}|$ of different settings. The trade-off can either be settled a-priori (for example if we know that we have "sufficiently" many observations in each known experimental setting, we would typically not pool data) or one can try various pooling procedures and combine all results, after adjusting the level $\alpha$ to account for the increased multiplicity of the associated testing problem. Section 4 discusses conditions on the interventions under which all true causal effects are identifiable.</p>
<h1>3.3 Splitting purely observational data</h1>
<p>In the case of purely observational data, the null hypothesis (4) is correct for $\gamma=0$ and $S=\emptyset$. Therefore, $S(\mathcal{E})=\emptyset$ and $\bar{S}(\mathcal{E})=\emptyset$ with high probability, i.e., our method stays conservative and does not make any causal claims.</p>
<p>In a reverse operation to data pooling across experiments, the question arises whether we can identify the causal predictors by artificially separating data into several blocks although the data have been generated under only one experimental setting (e.g. the data are purely observational). If the distribution is generated by a SEM (see Section 4.1), we may consider a variable $U$ that is not $Y$ and known to be a non-descendant of the target variable $Y$, that is, there is no directed path from $Y$ to $U$, for example as it precedes $Y$ chronologically. (This is similar as in an instrumental variable setting, see Section 5.) We may now split the data by conditioning on this variable $U$ or any function $h(U)$. Our method then still has the correct coverage for any function $h(U)$ as long as $U$ is a nondescendant of $Y$, because the conditional distribution of $Y$ given its true causal predictors $X_{S^{*}}$ does not change and for all $z$ in the image of $h$,</p>
<p>$$
Y \mid X_{S^{<em>}} \quad \stackrel{d}{=} \quad Y \mid X_{S^{</em>}}, h(U)=z
$$</p>
<p>Note that $U$ might or might not be part of the set $X_{S^{*}}$ but we expect the method to have more power if it is not. Equation (18) is a direct implication of the local Markov property that is satisfied for a SEM [Pearl, 2009, Theorem 1.4.1]. The confidence intervals remain valid but the implication on (partial) identifiability of the causal predictors remains as an open question.</p>
<p>Even without data splitting, there might still be some directional information in the data set that is not exploited by our method; this may either be information in the conditional independence structure [Spirtes et al., 2000, Chickering, 2002], information from non-Gaussianity [Shimizu et al., 2006], nonlinearities [Hoyer et al., 2009, Peters et al., 2014, Bühlmann et al., 2014], equal error variances [Peters and Bühlmann, 2014] or shared</p>
<p>information between regression function and target variable [Janzing et al., 2012]. Our method does not exploit these sources of identifiability. We believe, however, that it might be possible to incorporate the identifiability based on non-Gaussianity or nonlinearity.</p>
<h1>3.4 Computational requirements</h1>
<p>The construction of the confidence regions for the set of plausible causal coefficients and the identifiable causal predictors requires to go through all possible sets of variables in step 1) of the procedures given above. The computational complexity of the brute force scheme seems to grow super-exponentially with the number of variables.</p>
<p>There are several aspects to this issue. Firstly, we often do not have to go through all sets of variables. If we are looking for a non-empty set $\hat{S}(\mathcal{E})$, it is worthwhile in general to start generating the confidence regions $\hat{\Gamma}_{S}(\mathcal{E})$ for the empty set $S=\emptyset$, then for all singletons and so forth. If the empty set is not rejected, we can stop the search immediately, as then $\hat{S}(\mathcal{E})=\emptyset$. If the empty set is rejected, we can stop early as soon as we have accepted more than one set $S$ and the sets have an empty overlap (as $\hat{S}=\emptyset$ in this case no matter what other sets are accepted). The method can thus finish quickly if $\hat{S}=\emptyset$. However, in a positive case (where we do hope to get a non-empty confidence set) we will still have to go through all sets of variables eventually. There are two options to address the computational complexity.</p>
<p>The first option is to limit a-priori the size of the set of causal predictors. Say we are willing to make the assumption that the set of causal variables is at most $s&lt;p$. Then we just have to search over all subsets of size at most $s$ and incur a computational complexity that grows like $O\left(p^{s}\right)$ as a function of the number of variables.</p>
<p>A second option (which can be combined with the first one) is an adaptation of the confidence interval defined above, in which the number of variables is first reduced to a subset of small size that contains the causal predictors with high probability. Let $\hat{B} \subseteq$ ${1, \ldots, p}$ be, for the pooled data, an estimator of the variables with non-zero regression coefficient when using all variables as predictors. For example, $\hat{B}$ could be the set of variables with non-zero regression coefficient with square-root Lasso estimation [Belloni et al., 2011], Lasso [Tibshirani, 1996] or boosting [Schapire et al., 1998, Friedman, 2001, Bühlmann and Yu, 2003] with cross-validated penalty parameter. If the initial screening is chosen such that the causal predictors are contained with high probability, $P\left[S^{*} \subseteq \hat{B}\right] \geq$ $1-\alpha$, and we construct the confidence set $\hat{S}(\mathcal{E})$ as above, but just letting $S$ be a subset of $\hat{B}$ instead of ${1, \ldots, p}$, it will have coverage at least $1-2 \alpha$. Sufficient assumptions of such a coverage (or screening) condition are discussed in the literature [e.g. Bühlmann and van de Geer, 2011]. If the second option is combined with the first option, the computational complexity would then scale like $O\left(q^{s}\right)$ instead of $O\left(p^{s}\right)$, where $q$ is the maximal size of the set $\hat{B}$ of selected variables. For the sake of simplicity, we will not develop this argument further here but rather focus on the identifiability results for the low(er)-dimensional case.</p>
<h1>4 Identifiability results for structural equation models</h1>
<p>The question arises whether the proposed confidence sets for the causal predictors can recover an assumed true set of causal predictors. Such identifiability issues are discussed next. Sections 4.1 and 4.2 describe possible data generating mechanisms and Section 4.3 provides corresponding identifiability results.</p>
<h3>4.1 Linear Gaussian SEMs</h3>
<p>We consider linear Gaussian structural equation models (SEMs) [e.g. Wright, 1921, Duncan, 1975]. We assume that each element $e \in \mathcal{E}$ represents a different interventional setup. Let the first block of data $(e=1)$ always correspond to an "observational" (linear) Gaussian SEM. Here, a distribution over $\left(X_{1}^{1}, \ldots, X_{p+1}^{1}\right)$ is said to be generated from a Gaussian SEM if</p>
<p>$$
X_{j}^{1}=\sum_{k \neq j} \beta_{j, k}^{1} X_{k}^{1}+\varepsilon_{j}^{1}, \quad j=1, \ldots, p+1
$$</p>
<p>with $\varepsilon_{j}^{1} \stackrel{\text { iid }}{\sim} \mathcal{N}\left(0, \sigma_{j}^{2}\right), j=1, \ldots, p+1$. The corresponding directed graph is obtained by drawing arrows from variables $X_{k}^{1}$ on the right-hand side of (19) with $\beta_{j k}^{1} \neq 0$ to the variables $X_{j}^{1}$ of the left-hand side. This graph is assumed to be acyclic. Without loss of generality let us assume that $Y^{1}:=X_{1}^{1}$ is the target variable and we write $X:=$ $\left(X_{2}, \ldots, X_{p+1}\right)$. We further assume that all variables are observed; this assumption can be weakened, see Proposition 4 in Appendix B and Section 5.</p>
<p>The parents of $Y$ are given by</p>
<p>$$
\mathbf{P A}(Y)=\mathbf{P A}(1)={k \in{2, \ldots, p+1}: \beta_{1, k}^{1} \neq 0}
$$</p>
<p>Here, we adapt the usual notation of graphical models [e.g. Lauritzen, 1996]. For example, we write $\mathbf{P A}(j), \mathbf{D E}(j), \mathbf{A N}(j)$ and $\mathbf{N D}(j)$ for the parents, descendants, ancestors and non-descendants of $X_{j}$, respectively.</p>
<p>Let us assume that the other data blocks are generated by a linear SEM, too:</p>
<p>$$
X_{j}^{e}=\sum_{k \neq j} \beta_{j, k}^{e} X_{k}^{e}+\varepsilon_{j}^{e}, \quad j=1, \ldots, p+1, \quad e \in \mathcal{E}
$$</p>
<p>Assumption 1 states that the influence of the causal predictors remains the same under interventions, that is $Y^{e}=X^{e} \gamma^{<em>}+\varepsilon_{1}^{1}$ for $\gamma^{</em>}=\left(\beta_{1,2}^{1}, \ldots, \beta_{1, p+1}^{1}\right)^{t}$ and $\varepsilon_{1}^{e} \stackrel{d}{=} \varepsilon_{1}^{1}$ for $e \in \mathcal{E}$. The other coefficients $\beta_{j, k}^{e}$ and noise variables $\varepsilon_{j}^{e}, j \neq 1$, however, may be different from the ones in the observational setting (19). Within this setting, we now define various sorts of interventions.</p>
<h3>4.2 Interventions</h3>
<p>We next discuss three different types of interventions that all lead to identifiability of the causal predictors for the target variable.</p>
<h1>4.2.1 Do-interventions</h1>
<p>These types of interventions correspond to the classical do-operation from Pearl [2009, e.g.]. In the $e$-th experiment, we intervene on variables $\mathcal{A}^{e} \subseteq{2, \ldots, p+1}$ and set them to values $a_{j}^{e} \in \mathbb{R}, j \in \mathcal{A}^{e}$. For the observational setting $e=1$, we have $\mathcal{A}^{1}=\emptyset$. We specify the model (20), for $e \neq 1$, as follows:</p>
<p>$$
\beta_{j, k}^{e}= \begin{cases}\beta_{j, k}^{1} &amp; \text { if } j \notin \mathcal{A}^{e} \ 0 &amp; \text { if } j \in \mathcal{A}^{e}\end{cases}
$$</p>
<p>and</p>
<p>$$
\varepsilon_{j}^{e} \stackrel{d}{=} \begin{cases}\varepsilon_{j}^{1} &amp; \text { if } j \notin \mathcal{A}^{e} \ a_{j}^{e} &amp; \text { if } j \in \mathcal{A}^{e}\end{cases}
$$</p>
<p>The do-interventions correspond to fixing the intervened variable at a specific value. The following two types of interventions consider "softer" forms of interventions which might be more realistic for certain applications.</p>
<h3>4.2.2 Noise interventions</h3>
<p>Instead of fixing the intervened variable at a specific value, noise interventions correspond to "disturbing" the variable by changing the distribution of the noise variable. This is an instance of what is sometimes called a "soft intervention" [e.g. Eberhardt and Scheines, 2007]. We now consider a kind of soft intervention, in which we scale the noise distributions of variables $\mathcal{A}^{e} \subseteq{2, \ldots, p+1}$ by a factor $A_{j}^{e}, j \in \mathcal{A}^{e}$. Alternatively, we may also shift the error distribution by a variable $C_{j}^{e}$. More precisely, we specify the model in (20), for $e \neq 1$, as follows:</p>
<p>$$
\beta_{j, k}^{e}=\beta_{j, k}^{1} \quad \text { for all } j
$$</p>
<p>and</p>
<p>$$
\varepsilon_{j}^{e} \stackrel{d}{=} \begin{cases}\varepsilon_{j}^{1} &amp; \text { if } j \notin \mathcal{A}^{e} \ A_{j}^{e} \varepsilon_{j}^{1} &amp; \text { if } j \in \mathcal{A}^{e}\end{cases} \quad \text { or } \quad \varepsilon_{j}^{e} \stackrel{d}{=} \begin{cases}\varepsilon_{j}^{1} &amp; \text { if } j \notin \mathcal{A}^{e} \ \varepsilon_{j}^{1}+C_{j}^{e} &amp; \text { if } j \in \mathcal{A}^{e}\end{cases}
$$</p>
<p>The factors $A_{j}^{e}$ and the shifts $C_{j}^{e}$ are considered as random but may be constant with probability one. They are assumed to be independent of each other and independent of all other random variables considered in the model except for $X_{k}^{e}$ for $k \in \mathbf{D E}(j)$.</p>
<h3>4.2.3 Simultaneous noise interventions</h3>
<p>The noise interventions above operate on clearly defined variables $\mathcal{A}^{e}$ which can vary between different experimental settings $e \in \mathcal{E}$. In some applications, it might be difficult to change or influence the noise distribution at a single variable but instead one could imagine interventions that change the noise distributions at many variables simultaneously. As a third example, we thus consider a special case of the preceding Section 4.2.2, in which we pool all interventional experiments into a single data set. That is, $|\mathcal{E}|=2$ and, for all $j \in{2, \ldots, p+1}$,</p>
<p>$$
\beta_{j, k}^{e=2}=\beta_{j, k}^{e=1}
$$</p>
<p>and</p>
<p>$$
\varepsilon_{j}^{e=2} \stackrel{d}{=} A_{j} \varepsilon_{j}^{e=1} \quad \text { or } \quad \varepsilon_{j}^{e=2} \stackrel{d}{=} \varepsilon_{j}^{e=1}+C_{j}
$$</p>
<p>The random variables $A_{j} \geq 0$ are assumed to have a distribution that is absolutely continuous w.r.t. Lebesgue measure with $E A_{j}^{2}&lt;\infty$ and to be independent of all other variables and among themselves. The pooling can either happen explicitly or, as stated above, as we cannot control the target of the interventions precisely and a given change in environment might lead to changes in the error distributions in many variables simultaneously. As an example we mention gene knock-out experiments with off-target effects in biology [e.g. Jackson et al., 2003, Kulkarni et al., 2006].</p>
<h1>4.3 Identifiability results</h1>
<p>The following Theorem 2 gives sufficient conditions for identifiability of the causal predictors. We then discuss some conditions under which the assumptions can or cannot be relaxed further below. Proofs can be found in Appendix F.</p>
<p>Theorem 2 Consider a (linear) Gaussian SEM as in (19) and (20) with interventions. Then, with $S(\mathcal{E})$ as in (6), all causal predictors are identifiable, that is</p>
<p>$$
S(\mathcal{E})=\mathbf{P A}(Y)=\mathbf{P A}(1)
$$</p>
<p>if one of the following three assumptions is satisfied:
i) The interventions are do-interventions (Section 4.2.1) with $a_{j}^{e} \neq E\left(X_{j}^{1}\right)$ and there is at least one single intervention on each variable other than $Y$, that is for each $j \in{2, \ldots, p+1}$ there is an experiment $e$ with $\mathcal{A}^{e}={j}$.
ii) The interventions are noise interventions (Section 4.2.2) with $1 \neq E\left(A_{j}^{e}\right)^{2}&lt;\infty$, and again, there is at least one single intervention on each variable other than $Y$. If the interventions act additively rather than multiplicatively, we require $E C_{j}^{v} \neq 0$ or $0&lt;\operatorname{Var} C_{j}^{e}&lt;\infty$.
iii) The interventions are simultaneous noise interventions (Section 4.2.3). This result still holds if we allow changing linear coefficients $\beta_{j, k}^{e=2} \neq \beta_{j, k}^{e=1}$ in (21) with (possibly random) coefficients $\beta_{j, k}^{e=2}$.
The statements remain correct if we replace the null hypothesis (10) with its weaker version (16).</p>
<p>These are examples for sufficient conditions for identifiability but there may be many more. For example, one may also consider random coefficients or changing graph structures (only the parents of $Y$ must remain the same).</p>
<p>Remark. In general, the conditions given above are not necessary. The following remarks, however, provide two specific counter examples that show the necessity of some conditions.</p>
<p>i) We cannot remove the condition $a_{j}^{e} \neq E\left(X_{j}^{1}\right)$ from Theorem 2 i): the following SEMs correspond to observational data in experiment $e=1$, interventional data with $d o\left(X_{2}=0\right)$ in experiment $e=2$, and interventional data with $d o\left(X_{3}=0\right)$ in experiment $e=3$ :</p>
<p>$$
\begin{array}{llll}
e=1: &amp; Y^{1}=X_{2}^{1}+X_{3}^{1}+\varepsilon_{Y}, &amp; X_{2}^{1}=\varepsilon_{2}, &amp; X_{3}^{1}=-X_{2}^{1}+\varepsilon_{3} \
e=2: &amp; Y^{2}=X_{2}^{2}+X_{3}^{2}+\varepsilon_{Y}, &amp; X_{2}^{2}=0, &amp; X_{3}^{2}=-X_{2}^{2}+\varepsilon_{3} \
e=3: &amp; Y^{3}=X_{2}^{3}+X_{3}^{3}+\varepsilon_{Y}, &amp; X_{2}^{3}=\varepsilon_{2}, &amp; X_{3}^{3}=0
\end{array}
$$</p>
<p>with $\varepsilon_{2}$ and $\varepsilon_{3}$ having the same distribution. Then, we cannot identify the correct set of parents $S^{*}={1,2}$. The reason is that even $S=\emptyset$ leads to a correct null hypothesis (10).
ii) If we only check the null hypothesis (16) instead of the stronger version (10) (namely whether the residuals have the same variance rather than the same distribution), the condition $E\left(A_{j}^{e}\right)^{2} \neq 1$ is essential. Consider a two-dimensional observational distribution from experiment $e=1$ and an intervention distribution from experiment $e=2$ :</p>
<p>$$
\begin{array}{lll}
e=1: &amp; X^{1}=\varepsilon_{X}, &amp; Y^{1}=X^{1}+\varepsilon_{Y} \
e=2: &amp; X^{2}=A \cdot \varepsilon_{X}, &amp; Y^{2}=X^{2}+\varepsilon_{Y}
\end{array}
$$</p>
<p>with $E(A)^{2}=1$ and $\varepsilon_{X}, \varepsilon_{Y} \stackrel{\text { iid }}{\sim} \mathcal{N}(0,1)$. Then we cannot identify the correct set of parents $\mathbf{P A}(Y)={X}$ because again $S=\emptyset$ leads to the same residual variance and therefore a correct null hypothesis (16). If we use hypothesis (10), however, condition $E\left(A_{j}^{e}\right)^{2} \neq 1$ can be weakened (if densities exist), see the proof of Theorem 2 (iii).
In practice, we expect stronger identifiability results than Theorem 2. Intuitively, intervening on (some of) the ancestors of $Y$ should be sufficient for identifiability in many cases. Note that the two counter-examples above are non-generic in the way that they violate faithfulness [e.g. Spirtes et al., 2000]. The following theorem shows for some graph structures (which need not to be known) that even one interventional setting with an intervention on a single node may be sufficient, as long as the data generating model is chosen "generically" (see Appendix A for an example).</p>
<p>Theorem 3 Assume a linear Gaussian SEM as in (19) and (20) with all non-zero parameters drawn from a joint density w.r.t. Lebesgue measure. Let $X_{k_{0}}$ be a youngest parent of target variable $Y=X_{1}$, that is there is no directed path from $X_{k_{0}}$ to any other parent of $Y$. Assume further that there is an edge from any other parent of $Y$ to $X_{k_{0}}$. Assume that there is only one intervention setting, where the intervention took place on $X_{k_{0}}$, that is $|\mathcal{E}|=2$ and $\mathcal{A}^{e=2}=\left{k_{0}\right}$ ( $k_{0}$ does not need to be known).</p>
<p>Then, with probability one, all causal predictors are identifiable, that is</p>
<p>$$
S(\mathcal{E})=\mathbf{P A}(Y)=\mathbf{P A}(1)
$$</p>
<p>if one of the following two assumptions is satisfied:</p>
<p>i) The intervention is a do-intervention (Section 4.2.1) with $a_{k_{0}}^{e=2} \neq E X_{k_{0}}^{1}$.
ii) The intervention is a noise intervention (Section 4.2.2) with $1 \neq E\left(A_{k_{0}}^{e=2}\right)^{2}&lt;\infty$ or $E C_{k_{0}}^{e=2} \neq 0$, respectively.</p>
<p>It is, of course, also sufficient for identifiability if the interventional setting $\mathcal{A}^{e=2}=$ $\left{k_{0}\right}$ is just a member of a larger number of interventional settings. We anticipate that more identifiability results of similar type can be derived in specific settings. Theorem 3 shows that interving on the youngest parent can reveal the whole set of parents of the target variable so this intervention is in a sense the most informative intervention under the made assumptions. Intervening on descendants of $Y$ will, in contrast, only rule out these variables as parents of $Y$. Some interventions are also completely non-informative; intervening on a variable that is independent of all other variables (including the target) will, for example, not help with identification of the set of parents of the target variable.</p>
<h1>5 Instrumental and hidden variables with confounding</h1>
<p>We now discuss an extension of the invariance idea that is suitable in the presence of hidden variables. Instrumental variables can sometimes be used when the causal relationship of interest is confounded and there are no randomised experiments available [Wright, 1928, Bowden and Turkington, 1990, Angrist et al., 1996, Didelez et al., 2010]. For simplicity, let us assume that $I$ is binary. We assume that the SEM for a $p$-dimensional predictor $X$,
<img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3: In this example of a graph of model that satisfies (23), variable $Y$ has a direct causal effect only on $X_{2}$, while there is a feedback between $Y$ and $X_{1}$.
a univariate target variable $Y$ of interest and a $q$-dimensional hidden variable $H$ can be written as</p>
<p>$$
\begin{aligned}
&amp; X=f(I, H, Y, \eta) \
&amp; Y=X \gamma^{*}+g(H, \varepsilon)
\end{aligned}
$$</p>
<p>where $\gamma^{*}$ is the unknown vector of causal coefficients, $f, g$ are unknown real-valued functions and $\eta$ and $\varepsilon$ are random noise variables in $p$ dimensions and one dimension respectively. As it is commonly done for SEMs, we require the noise variables $H, \eta, \varepsilon, I$ to be jointly independent. Figure 3 shows an example of a SEM that satisfies (23).</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{1}$ We thank a referee for suggesting this succinct description of the main idea.&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>