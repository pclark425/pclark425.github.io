<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-5605 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-5605</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-5605</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-114.html">extraction-schema-114</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used as text-based simulators in specific scientific subdomains, including details on the simulation tasks, reported accuracy, evaluation methods, and any factors identified as affecting the accuracy of these simulations.</div>
                <p><strong>Paper ID:</strong> paper-1c6c9dd66554debf28cffb29a1fcc22415b57655</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/1c6c9dd66554debf28cffb29a1fcc22415b57655" target="_blank">Exploring the Capabilities and Limitations of Large Language Models in the Electric Energy Sector</a></p>
                <p><strong>Paper Venue:</strong> Joule</p>
                <p><strong>Paper TL;DR:</strong> Key future research directions include data collection systems for fine-tuning LLMs, embedding power system-specific tools in the LLMs, and retrieval augmented generation (RAG)-based knowledge pool to improve the quality of LLM responses and LLMs in safety-critical use cases.</p>
                <p><strong>Cost:</strong> 0.013</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e5605.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e5605.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used as text-based simulators in specific scientific subdomains, including details on the simulation tasks, reported accuracy, evaluation methods, and any factors identified as affecting the accuracy of these simulations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-4 (Power-flow EDA)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-4 used for exploratory data analysis of power-flow time-series</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>GPT-4 (web interface) was used to ingest JSON network descriptions and CSV time-series produced by PyPower, generate code, compute correlations between injections/loads and branch flows, produce visualizations, and identify candidate congested lines.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4 (Web Interface)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>A large transformer-based conversational LLM from OpenAI accessed via web interface; training corpora and parameters unspecified in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_subdomain</strong></td>
                            <td>Electric power systems — power-flow analysis / transmission congestion</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task</strong></td>
                            <td>Exploratory analysis of simulated power-flow time-series (generated by PyPower) to compute correlations, identify branches approaching limits, and visualize relationships between renewable injections and line flows.</td>
                        </tr>
                        <tr>
                            <td><strong>accuracy_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reported_accuracy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>factors_affecting_accuracy</strong></td>
                            <td>['Prompt phrasing and explicit instructions (e.g., asking to load dictionaries first)', 'Whether absolute values of flows are considered (domain-specific guidance)', 'Context provided with data (e.g., JSON dictionaries describing columns)', 'Generative variability across runs']</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_for_factors</strong></td>
                            <td>Authors observed GPT-4 often misinterpreted CSVs unless prompted to 'load the dictionaries first'; giving domain knowledge (e.g., 'consider absolute value') changed outputs to be correct; small prompt changes yielded notably different analyses/visualizations (Figure S1 vs S1(b)).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Qualitative comparison against domain expectations and manual verification by authors (visual inspection of generated scatterplots, code inspection showing correct comparison of max absolute branch flows to limits).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>GPT-4 initially misidentified CSV structure without explicit instruction; interpretations may ignore sign/direction of flows unless guided; results are variable across prompts and runs.</td>
                        </tr>
                        <tr>
                            <td><strong>comparisons</strong></td>
                            <td>Compared behavior under slightly different prompts (e.g., 'provide insights' vs 'perform EDA'); no numerical benchmark against specialized tools reported.</td>
                        </tr>
                        <tr>
                            <td><strong>recommendations_or_best_practices</strong></td>
                            <td>Provide explicit domain context (dictionaries), ask GPT to load metadata first, include domain-specific instructions (e.g., consider absolute values), and validate GPT-generated analyses with domain knowledge/tools.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Exploring the Capabilities and Limitations of Large Language Models in the Electric Energy Sector', 'publication_date_yy_mm': '2024-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5605.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e5605.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used as text-based simulators in specific scientific subdomains, including details on the simulation tasks, reported accuracy, evaluation methods, and any factors identified as affecting the accuracy of these simulations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-4 (Demand/Price EDA & Forecasting)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-4 used for exploratory analysis and for producing forecasting code suggestions for load/price time-series</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>GPT-4 performed time-series visualization, correlation and distribution analyses, suggested modeling approaches (e.g., LSTM), and generated training scripts, but could not reliably run code in the web environment and did not report model performance metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4 (Web Interface)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Transformer-based LLM accessed via web interface; used to propose and generate forecasting model code (e.g., LSTM) and to perform EDA on provided CSV rows.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_subdomain</strong></td>
                            <td>Electric power systems — load and price forecasting (time-series analysis)</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task</strong></td>
                            <td>Exploratory data analysis and generation of forecasting model code (LSTM and regression models) for farm load using historical RTM/DA prices, wind/solar, and load features.</td>
                        </tr>
                        <tr>
                            <td><strong>accuracy_metric</strong></td>
                            <td>Model residual analysis / qualitative diagnostics when asked (residual distribution, heteroscedasticity, autocorrelation) but no formal numeric forecasting metric reported (e.g., RMSE) in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>reported_accuracy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>factors_affecting_accuracy</strong></td>
                            <td>["Platform execution limits (GPT couldn't execute training end-to-end in web interface)", "Prompt detail (requesting 'best judgment' led GPT to select procedures)", 'Modeling choices suggested by GPT (LSTM vs random forest vs linear regression)', 'Lack of domain-specific pretraining / domain knowledge']</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_for_factors</strong></td>
                            <td>GPT-4 generated TensorFlow/Keras scripts but encountered execution errors in web interface; when prompted differently it switched between random forest and linear regression; GPT flagged but did not automatically fix residual issues.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Authors inspected generated code and GPT's diagnostic comments; where GPT trained models were proposed, evaluation was limited due to platform execution constraints — authors note code likely runs locally but were unable to fully validate within the web interface.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>GPT-4 failed to execute training end-to-end in the web environment, produced models without numeric performance metrics, and did not automatically resolve data distribution issues unless explicitly instructed.</td>
                        </tr>
                        <tr>
                            <td><strong>comparisons</strong></td>
                            <td>GPT-4 suggested multiple modeling approaches; no quantitative comparison of forecasting accuracy against specialized forecasting models was provided.</td>
                        </tr>
                        <tr>
                            <td><strong>recommendations_or_best_practices</strong></td>
                            <td>Run GPT-generated training code locally (not only in web UI); provide explicit diagnostic requests (e.g., ask GPT to compute residual statistics and perform transformations); consider fine-tuning LLMs with domain data for better recommendations.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Exploring the Capabilities and Limitations of Large Language Models in the Electric Energy Sector', 'publication_date_yy_mm': '2024-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5605.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e5605.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used as text-based simulators in specific scientific subdomains, including details on the simulation tasks, reported accuracy, evaluation methods, and any factors identified as affecting the accuracy of these simulations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-4 (Wildfire-Transmission Overlay)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-4 multimodal tool-embedding for extracting wildfire polygons and overlaying on transmission maps</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>GPT-4 was used with tool embedding (image-processing code generation) to extract red wildfire regions from satellite/incident maps and overlay them onto transmission line maps to visualize lines at risk; results varied but were feasible with prompt engineering.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4 (Web Interface) with tool embedding (code generation for image processing)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Multimodal-capable LLM used to generate Python image-processing code to extract regions and overlay layers; relied on file metadata and prompt instructions to label and process multiple images.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_subdomain</strong></td>
                            <td>Electric power systems — geospatial risk visualization (wildfire impact on transmission infrastructure)</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task</strong></td>
                            <td>Image-region extraction (wildfire polygons) and geospatial overlay onto transmission line maps to identify potentially affected lines; iterative overlay to synthesize combined impact across months.</td>
                        </tr>
                        <tr>
                            <td><strong>accuracy_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reported_accuracy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>factors_affecting_accuracy</strong></td>
                            <td>['Prompt directness and decomposition of task (clear, specific prompts reduced code variability)', 'Quality of image-processing code generated (filter application errors affected performance)', 'Availability of file metadata and clear labeling of inputs', 'Generative variability across trials']</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_for_factors</strong></td>
                            <td>Authors ran multiple trials and used AST similarity scoring to show that more direct prompts produced nearly identical code across runs (lower AST variability). Errors were due to mistakes in filter applications and code differences in extraction steps (Figures S7 and S8).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Visual inspection of resulting overlays (Figures S5, S8, S9) and analysis of code similarity across multiple GPT runs; qualitative assessment of whether overlays correctly extracted red wildfire areas and superimposed them.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Generated code sometimes failed due to incorrect filter logic; GPT refused (by policy) to predict future wildfire spread ('unable to predict future wildfire spread'), limiting forward simulation capabilities; generative variability required iterative prompt refinement.</td>
                        </tr>
                        <tr>
                            <td><strong>comparisons</strong></td>
                            <td>Compared outputs across prompt variants and single vs multiple image inputs; used AST-based code-similarity histograms to quantify variability.</td>
                        </tr>
                        <tr>
                            <td><strong>recommendations_or_best_practices</strong></td>
                            <td>Use highly specific prompts, decompose tasks into smaller image-processing steps, supply clear file metadata/names, and validate generated code locally; tool embedding should be used but outputs must be checked for filter/logic correctness.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Exploring the Capabilities and Limitations of Large Language Models in the Electric Energy Sector', 'publication_date_yy_mm': '2024-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5605.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e5605.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used as text-based simulators in specific scientific subdomains, including details on the simulation tasks, reported accuracy, evaluation methods, and any factors identified as affecting the accuracy of these simulations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-4 (Insulator Fault Detection)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-4 multimodal few-shot classification for insulator defect detection</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>GPT-4 was applied in a few-shot setup to classify insulator images as 'Intact' or 'Failure' using example-labeled images; performance on a 40-image test set (20 intact, 20 faulty) achieved 80% overall accuracy, with 85% on intact and 70% on faulty examples.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4 (Web Interface, multimodal)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Multimodal LLM that ingests images and few-shot textual examples to perform image classification without conventional supervised training on the domain dataset.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_subdomain</strong></td>
                            <td>Electric power systems — equipment condition monitoring / computer vision for insulator defect detection</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task</strong></td>
                            <td>Image classification (detecting insulator defects) via few-shot examples embedded in the prompt.</td>
                        </tr>
                        <tr>
                            <td><strong>accuracy_metric</strong></td>
                            <td>Classification accuracy (percent correct) broken down by class.</td>
                        </tr>
                        <tr>
                            <td><strong>reported_accuracy</strong></td>
                            <td>Overall accuracy 80%; intact class accuracy 85%; faulty class accuracy 70% (dataset: 40 images, balanced).</td>
                        </tr>
                        <tr>
                            <td><strong>factors_affecting_accuracy</strong></td>
                            <td>['Presence and quality of few-shot examples (improved accuracy when richer examples provided)', 'Image quality (low-quality images led to failures)', 'Novelty of failure modes (unseen fault types decreased accuracy)', 'Prompt style consistency (responses were consistent across prompt styles in this case)']</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_for_factors</strong></td>
                            <td>Authors showed that adding labeled examples improved recognition; low-quality images (from prior study) caused GPT-4 to miss defects; GPT sometimes misclassified shadows as chips; few-shot method achieved 80% while referenced specialized model achieved >90% (but on larger/synthetic dataset).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Quantitative classification on a 40-image dataset with manual ground-truth labels; authors report per-class accuracies and discuss error modes.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Lower accuracy on faulty examples (70%); misclassification of novel fault types; confusion caused by shadows; smaller dataset than specialized CV models leading to inferior performance compared to literature (>90%).</td>
                        </tr>
                        <tr>
                            <td><strong>comparisons</strong></td>
                            <td>Compared to an external study (reference 6) reporting >90% accuracy using a larger/synthetic dataset; authors note their dataset was smaller and no synthetic augmentation used.</td>
                        </tr>
                        <tr>
                            <td><strong>recommendations_or_best_practices</strong></td>
                            <td>Use few-shot examples to improve performance, supply high-quality images, expand the set of example failure modes, and consider fine-tuning or combining LLM multimodal inputs with domain-specific CV models for higher robustness.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Exploring the Capabilities and Limitations of Large Language Models in the Electric Energy Sector', 'publication_date_yy_mm': '2024-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5605.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e5605.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used as text-based simulators in specific scientific subdomains, including details on the simulation tasks, reported accuracy, evaluation methods, and any factors identified as affecting the accuracy of these simulations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-4 (On-site Hazard Scoring)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-4 for photographic safety audit scoring of powerline worksite</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>GPT-4 was used to assign scores (0–10) across multiple safety factors from a single site photograph and compute an aggregated audit score; variability assessed over 55 repeated runs to quantify consistency and uncertainty.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4 (Web Interface, multimodal with embedded python tool)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Transformer-based LLM applied to image content and asked to produce structured numeric assessments; used embedded Python for aggregation and repeated sampling to measure variability.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_subdomain</strong></td>
                            <td>Electric power systems — occupational safety / on-site hazard recognition</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task</strong></td>
                            <td>Visual safety assessment: assign per-factor scores (Distance from Power Lines, PPE, Lockout/Tagout, etc.) and compute aggregated safety audit score for a worksite photograph.</td>
                        </tr>
                        <tr>
                            <td><strong>accuracy_metric</strong></td>
                            <td>Aggregated audit score distribution (statistical consistency across runs) and per-factor score distributions; no ground-truth numeric label available so evaluation is relative/diagnostic.</td>
                        </tr>
                        <tr>
                            <td><strong>reported_accuracy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>factors_affecting_accuracy</strong></td>
                            <td>["Prompt specification (instruction to assign '5' if unsure affected distributions)", "Ambiguity inherent in single-image inputs for some factors causing GPT to default to '5' when uncertain", 'Generative variability across repeated runs', 'Tool-use for backend aggregation (embedded Python)']</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_for_factors</strong></td>
                            <td>Authors ran 55 trials; aggregated audit score concentrated between 3 and 4 for ~60% runs with peak at 3.5; many factors frequently scored '5' due to instruction for uncertainty; variability analyzed via histograms (Figure S12).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Repeated-run statistical analysis (55 repetitions) producing distributions for each factor and aggregated score; authors qualitatively interpreted consistency and uncertainty.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>GPT refused to provide a single precise numerical score in one case (policy constraint), and single-image inputs are insufficient to assess some audit components; variability in outputs across runs necessitates aggregated/statistical approach.</td>
                        </tr>
                        <tr>
                            <td><strong>comparisons</strong></td>
                            <td>Not compared to human auditors numerically; analysis focuses on internal consistency and sensitivity to prompt instructions.</td>
                        </tr>
                        <tr>
                            <td><strong>recommendations_or_best_practices</strong></td>
                            <td>Provide clear instructions for handling uncertainty, include more context (multiple images, metadata) to reduce '5' defaulting, use repeated sampling to estimate uncertainty, and combine GPT output with human oversight for safety-critical decisions.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Exploring the Capabilities and Limitations of Large Language Models in the Electric Energy Sector', 'publication_date_yy_mm': '2024-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5605.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e5605.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used as text-based simulators in specific scientific subdomains, including details on the simulation tasks, reported accuracy, evaluation methods, and any factors identified as affecting the accuracy of these simulations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RAG + GPT-3.5-Turbo (Document QA)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Retrieval-Augmented Generation system using LangChain + OpenAIEmbeddings with GPT-3.5-Turbo for question answering on ERCOT nodal protocols</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A RAG pipeline (vector store + embeddings + GPT-3.5-Turbo) was built to answer document-specific questions; it provided accurate answers for direct look-up questions but struggled with complex reasoning questions requiring synthesis across protocol sections.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5-Turbo (via RAG pipeline)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>GPT-3.5-Turbo LLM coupled with OpenAIEmbeddings and FAISS vector store via LangChain for retrieval-augmented QA on segmented ERCOT protocol documents.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_subdomain</strong></td>
                            <td>Electric power systems — document analysis / protocol question-answering</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task</strong></td>
                            <td>Answering direct and complex protocol questions by retrieving relevant text fragments and generating responses (RAG).</td>
                        </tr>
                        <tr>
                            <td><strong>accuracy_metric</strong></td>
                            <td>Qualitative alignment with source document excerpts and correctness of answers; direct questions compared against protocol text for precision.</td>
                        </tr>
                        <tr>
                            <td><strong>reported_accuracy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>factors_affecting_accuracy</strong></td>
                            <td>['Type of question (direct factual vs complex reasoning)', 'Quality of segmentation and retrieval (vector similarity effectiveness)', 'Underlying model capability (GPT-3.5-Turbo vs GPT-4 differences noted qualitatively)', 'Temperature/hyperparameters (lower temperatures tested but complex queries still failed)']</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_for_factors</strong></td>
                            <td>Authors report RAG performed well for direct questions (example: 'What is the Opportunity Outage?') with answers aligning with protocol excerpts (Figure S13), but failed or produced incomplete answers for complex queries (protocol 6.5.7.5) even at lower temperatures (Figure S14).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Manual comparison of RAG answers to source protocol text and qualitative assessment of completeness/precision; experiments across question types.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>RAG performed poorly on nuanced reasoning questions requiring synthesis across sections; variability in thoroughness of answers across attempts.</td>
                        </tr>
                        <tr>
                            <td><strong>comparisons</strong></td>
                            <td>Authors compared RAG answers to GPT-4 WI (GPT-4 web interface) and found RAG responses surpassed GPT-4 WI for precision on direct text-based queries; RAG still underperforms on complex reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>recommendations_or_best_practices</strong></td>
                            <td>Use RAG for document-specific direct queries; ensure high-quality retrieval (good segmentation and embeddings); combine RAG with human experts for complex reasoning; tune retrieval and prompt templates for challenging questions.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Exploring the Capabilities and Limitations of Large Language Models in the Electric Energy Sector', 'publication_date_yy_mm': '2024-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>On the Potential of ChatGPT to Generate Distribution Systems for Load Flow Studies Using OpenDSS <em>(Rating: 2)</em></li>
                <li>Real-Time Optimal Power Flow With Linguistic Stipulations: Integrating GPT-Agent and Deep Reinforcement Learning <em>(Rating: 2)</em></li>
                <li>Large Foundation Models for Power Systems <em>(Rating: 2)</em></li>
                <li>Large Foundation Models for Power Systems. arXiv. <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-5605",
    "paper_id": "paper-1c6c9dd66554debf28cffb29a1fcc22415b57655",
    "extraction_schema_id": "extraction-schema-114",
    "extracted_data": [
        {
            "name_short": "GPT-4 (Power-flow EDA)",
            "name_full": "GPT-4 used for exploratory data analysis of power-flow time-series",
            "brief_description": "GPT-4 (web interface) was used to ingest JSON network descriptions and CSV time-series produced by PyPower, generate code, compute correlations between injections/loads and branch flows, produce visualizations, and identify candidate congested lines.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-4 (Web Interface)",
            "model_description": "A large transformer-based conversational LLM from OpenAI accessed via web interface; training corpora and parameters unspecified in the paper.",
            "model_size": null,
            "scientific_subdomain": "Electric power systems — power-flow analysis / transmission congestion",
            "simulation_task": "Exploratory analysis of simulated power-flow time-series (generated by PyPower) to compute correlations, identify branches approaching limits, and visualize relationships between renewable injections and line flows.",
            "accuracy_metric": null,
            "reported_accuracy": null,
            "factors_affecting_accuracy": [
                "Prompt phrasing and explicit instructions (e.g., asking to load dictionaries first)",
                "Whether absolute values of flows are considered (domain-specific guidance)",
                "Context provided with data (e.g., JSON dictionaries describing columns)",
                "Generative variability across runs"
            ],
            "evidence_for_factors": "Authors observed GPT-4 often misinterpreted CSVs unless prompted to 'load the dictionaries first'; giving domain knowledge (e.g., 'consider absolute value') changed outputs to be correct; small prompt changes yielded notably different analyses/visualizations (Figure S1 vs S1(b)).",
            "evaluation_method": "Qualitative comparison against domain expectations and manual verification by authors (visual inspection of generated scatterplots, code inspection showing correct comparison of max absolute branch flows to limits).",
            "limitations_or_failure_cases": "GPT-4 initially misidentified CSV structure without explicit instruction; interpretations may ignore sign/direction of flows unless guided; results are variable across prompts and runs.",
            "comparisons": "Compared behavior under slightly different prompts (e.g., 'provide insights' vs 'perform EDA'); no numerical benchmark against specialized tools reported.",
            "recommendations_or_best_practices": "Provide explicit domain context (dictionaries), ask GPT to load metadata first, include domain-specific instructions (e.g., consider absolute values), and validate GPT-generated analyses with domain knowledge/tools.",
            "uuid": "e5605.0",
            "source_info": {
                "paper_title": "Exploring the Capabilities and Limitations of Large Language Models in the Electric Energy Sector",
                "publication_date_yy_mm": "2024-03"
            }
        },
        {
            "name_short": "GPT-4 (Demand/Price EDA & Forecasting)",
            "name_full": "GPT-4 used for exploratory analysis and for producing forecasting code suggestions for load/price time-series",
            "brief_description": "GPT-4 performed time-series visualization, correlation and distribution analyses, suggested modeling approaches (e.g., LSTM), and generated training scripts, but could not reliably run code in the web environment and did not report model performance metrics.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-4 (Web Interface)",
            "model_description": "Transformer-based LLM accessed via web interface; used to propose and generate forecasting model code (e.g., LSTM) and to perform EDA on provided CSV rows.",
            "model_size": null,
            "scientific_subdomain": "Electric power systems — load and price forecasting (time-series analysis)",
            "simulation_task": "Exploratory data analysis and generation of forecasting model code (LSTM and regression models) for farm load using historical RTM/DA prices, wind/solar, and load features.",
            "accuracy_metric": "Model residual analysis / qualitative diagnostics when asked (residual distribution, heteroscedasticity, autocorrelation) but no formal numeric forecasting metric reported (e.g., RMSE) in experiments.",
            "reported_accuracy": null,
            "factors_affecting_accuracy": [
                "Platform execution limits (GPT couldn't execute training end-to-end in web interface)",
                "Prompt detail (requesting 'best judgment' led GPT to select procedures)",
                "Modeling choices suggested by GPT (LSTM vs random forest vs linear regression)",
                "Lack of domain-specific pretraining / domain knowledge"
            ],
            "evidence_for_factors": "GPT-4 generated TensorFlow/Keras scripts but encountered execution errors in web interface; when prompted differently it switched between random forest and linear regression; GPT flagged but did not automatically fix residual issues.",
            "evaluation_method": "Authors inspected generated code and GPT's diagnostic comments; where GPT trained models were proposed, evaluation was limited due to platform execution constraints — authors note code likely runs locally but were unable to fully validate within the web interface.",
            "limitations_or_failure_cases": "GPT-4 failed to execute training end-to-end in the web environment, produced models without numeric performance metrics, and did not automatically resolve data distribution issues unless explicitly instructed.",
            "comparisons": "GPT-4 suggested multiple modeling approaches; no quantitative comparison of forecasting accuracy against specialized forecasting models was provided.",
            "recommendations_or_best_practices": "Run GPT-generated training code locally (not only in web UI); provide explicit diagnostic requests (e.g., ask GPT to compute residual statistics and perform transformations); consider fine-tuning LLMs with domain data for better recommendations.",
            "uuid": "e5605.1",
            "source_info": {
                "paper_title": "Exploring the Capabilities and Limitations of Large Language Models in the Electric Energy Sector",
                "publication_date_yy_mm": "2024-03"
            }
        },
        {
            "name_short": "GPT-4 (Wildfire-Transmission Overlay)",
            "name_full": "GPT-4 multimodal tool-embedding for extracting wildfire polygons and overlaying on transmission maps",
            "brief_description": "GPT-4 was used with tool embedding (image-processing code generation) to extract red wildfire regions from satellite/incident maps and overlay them onto transmission line maps to visualize lines at risk; results varied but were feasible with prompt engineering.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-4 (Web Interface) with tool embedding (code generation for image processing)",
            "model_description": "Multimodal-capable LLM used to generate Python image-processing code to extract regions and overlay layers; relied on file metadata and prompt instructions to label and process multiple images.",
            "model_size": null,
            "scientific_subdomain": "Electric power systems — geospatial risk visualization (wildfire impact on transmission infrastructure)",
            "simulation_task": "Image-region extraction (wildfire polygons) and geospatial overlay onto transmission line maps to identify potentially affected lines; iterative overlay to synthesize combined impact across months.",
            "accuracy_metric": null,
            "reported_accuracy": null,
            "factors_affecting_accuracy": [
                "Prompt directness and decomposition of task (clear, specific prompts reduced code variability)",
                "Quality of image-processing code generated (filter application errors affected performance)",
                "Availability of file metadata and clear labeling of inputs",
                "Generative variability across trials"
            ],
            "evidence_for_factors": "Authors ran multiple trials and used AST similarity scoring to show that more direct prompts produced nearly identical code across runs (lower AST variability). Errors were due to mistakes in filter applications and code differences in extraction steps (Figures S7 and S8).",
            "evaluation_method": "Visual inspection of resulting overlays (Figures S5, S8, S9) and analysis of code similarity across multiple GPT runs; qualitative assessment of whether overlays correctly extracted red wildfire areas and superimposed them.",
            "limitations_or_failure_cases": "Generated code sometimes failed due to incorrect filter logic; GPT refused (by policy) to predict future wildfire spread ('unable to predict future wildfire spread'), limiting forward simulation capabilities; generative variability required iterative prompt refinement.",
            "comparisons": "Compared outputs across prompt variants and single vs multiple image inputs; used AST-based code-similarity histograms to quantify variability.",
            "recommendations_or_best_practices": "Use highly specific prompts, decompose tasks into smaller image-processing steps, supply clear file metadata/names, and validate generated code locally; tool embedding should be used but outputs must be checked for filter/logic correctness.",
            "uuid": "e5605.2",
            "source_info": {
                "paper_title": "Exploring the Capabilities and Limitations of Large Language Models in the Electric Energy Sector",
                "publication_date_yy_mm": "2024-03"
            }
        },
        {
            "name_short": "GPT-4 (Insulator Fault Detection)",
            "name_full": "GPT-4 multimodal few-shot classification for insulator defect detection",
            "brief_description": "GPT-4 was applied in a few-shot setup to classify insulator images as 'Intact' or 'Failure' using example-labeled images; performance on a 40-image test set (20 intact, 20 faulty) achieved 80% overall accuracy, with 85% on intact and 70% on faulty examples.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-4 (Web Interface, multimodal)",
            "model_description": "Multimodal LLM that ingests images and few-shot textual examples to perform image classification without conventional supervised training on the domain dataset.",
            "model_size": null,
            "scientific_subdomain": "Electric power systems — equipment condition monitoring / computer vision for insulator defect detection",
            "simulation_task": "Image classification (detecting insulator defects) via few-shot examples embedded in the prompt.",
            "accuracy_metric": "Classification accuracy (percent correct) broken down by class.",
            "reported_accuracy": "Overall accuracy 80%; intact class accuracy 85%; faulty class accuracy 70% (dataset: 40 images, balanced).",
            "factors_affecting_accuracy": [
                "Presence and quality of few-shot examples (improved accuracy when richer examples provided)",
                "Image quality (low-quality images led to failures)",
                "Novelty of failure modes (unseen fault types decreased accuracy)",
                "Prompt style consistency (responses were consistent across prompt styles in this case)"
            ],
            "evidence_for_factors": "Authors showed that adding labeled examples improved recognition; low-quality images (from prior study) caused GPT-4 to miss defects; GPT sometimes misclassified shadows as chips; few-shot method achieved 80% while referenced specialized model achieved &gt;90% (but on larger/synthetic dataset).",
            "evaluation_method": "Quantitative classification on a 40-image dataset with manual ground-truth labels; authors report per-class accuracies and discuss error modes.",
            "limitations_or_failure_cases": "Lower accuracy on faulty examples (70%); misclassification of novel fault types; confusion caused by shadows; smaller dataset than specialized CV models leading to inferior performance compared to literature (&gt;90%).",
            "comparisons": "Compared to an external study (reference 6) reporting &gt;90% accuracy using a larger/synthetic dataset; authors note their dataset was smaller and no synthetic augmentation used.",
            "recommendations_or_best_practices": "Use few-shot examples to improve performance, supply high-quality images, expand the set of example failure modes, and consider fine-tuning or combining LLM multimodal inputs with domain-specific CV models for higher robustness.",
            "uuid": "e5605.3",
            "source_info": {
                "paper_title": "Exploring the Capabilities and Limitations of Large Language Models in the Electric Energy Sector",
                "publication_date_yy_mm": "2024-03"
            }
        },
        {
            "name_short": "GPT-4 (On-site Hazard Scoring)",
            "name_full": "GPT-4 for photographic safety audit scoring of powerline worksite",
            "brief_description": "GPT-4 was used to assign scores (0–10) across multiple safety factors from a single site photograph and compute an aggregated audit score; variability assessed over 55 repeated runs to quantify consistency and uncertainty.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-4 (Web Interface, multimodal with embedded python tool)",
            "model_description": "Transformer-based LLM applied to image content and asked to produce structured numeric assessments; used embedded Python for aggregation and repeated sampling to measure variability.",
            "model_size": null,
            "scientific_subdomain": "Electric power systems — occupational safety / on-site hazard recognition",
            "simulation_task": "Visual safety assessment: assign per-factor scores (Distance from Power Lines, PPE, Lockout/Tagout, etc.) and compute aggregated safety audit score for a worksite photograph.",
            "accuracy_metric": "Aggregated audit score distribution (statistical consistency across runs) and per-factor score distributions; no ground-truth numeric label available so evaluation is relative/diagnostic.",
            "reported_accuracy": null,
            "factors_affecting_accuracy": [
                "Prompt specification (instruction to assign '5' if unsure affected distributions)",
                "Ambiguity inherent in single-image inputs for some factors causing GPT to default to '5' when uncertain",
                "Generative variability across repeated runs",
                "Tool-use for backend aggregation (embedded Python)"
            ],
            "evidence_for_factors": "Authors ran 55 trials; aggregated audit score concentrated between 3 and 4 for ~60% runs with peak at 3.5; many factors frequently scored '5' due to instruction for uncertainty; variability analyzed via histograms (Figure S12).",
            "evaluation_method": "Repeated-run statistical analysis (55 repetitions) producing distributions for each factor and aggregated score; authors qualitatively interpreted consistency and uncertainty.",
            "limitations_or_failure_cases": "GPT refused to provide a single precise numerical score in one case (policy constraint), and single-image inputs are insufficient to assess some audit components; variability in outputs across runs necessitates aggregated/statistical approach.",
            "comparisons": "Not compared to human auditors numerically; analysis focuses on internal consistency and sensitivity to prompt instructions.",
            "recommendations_or_best_practices": "Provide clear instructions for handling uncertainty, include more context (multiple images, metadata) to reduce '5' defaulting, use repeated sampling to estimate uncertainty, and combine GPT output with human oversight for safety-critical decisions.",
            "uuid": "e5605.4",
            "source_info": {
                "paper_title": "Exploring the Capabilities and Limitations of Large Language Models in the Electric Energy Sector",
                "publication_date_yy_mm": "2024-03"
            }
        },
        {
            "name_short": "RAG + GPT-3.5-Turbo (Document QA)",
            "name_full": "Retrieval-Augmented Generation system using LangChain + OpenAIEmbeddings with GPT-3.5-Turbo for question answering on ERCOT nodal protocols",
            "brief_description": "A RAG pipeline (vector store + embeddings + GPT-3.5-Turbo) was built to answer document-specific questions; it provided accurate answers for direct look-up questions but struggled with complex reasoning questions requiring synthesis across protocol sections.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-3.5-Turbo (via RAG pipeline)",
            "model_description": "GPT-3.5-Turbo LLM coupled with OpenAIEmbeddings and FAISS vector store via LangChain for retrieval-augmented QA on segmented ERCOT protocol documents.",
            "model_size": null,
            "scientific_subdomain": "Electric power systems — document analysis / protocol question-answering",
            "simulation_task": "Answering direct and complex protocol questions by retrieving relevant text fragments and generating responses (RAG).",
            "accuracy_metric": "Qualitative alignment with source document excerpts and correctness of answers; direct questions compared against protocol text for precision.",
            "reported_accuracy": null,
            "factors_affecting_accuracy": [
                "Type of question (direct factual vs complex reasoning)",
                "Quality of segmentation and retrieval (vector similarity effectiveness)",
                "Underlying model capability (GPT-3.5-Turbo vs GPT-4 differences noted qualitatively)",
                "Temperature/hyperparameters (lower temperatures tested but complex queries still failed)"
            ],
            "evidence_for_factors": "Authors report RAG performed well for direct questions (example: 'What is the Opportunity Outage?') with answers aligning with protocol excerpts (Figure S13), but failed or produced incomplete answers for complex queries (protocol 6.5.7.5) even at lower temperatures (Figure S14).",
            "evaluation_method": "Manual comparison of RAG answers to source protocol text and qualitative assessment of completeness/precision; experiments across question types.",
            "limitations_or_failure_cases": "RAG performed poorly on nuanced reasoning questions requiring synthesis across sections; variability in thoroughness of answers across attempts.",
            "comparisons": "Authors compared RAG answers to GPT-4 WI (GPT-4 web interface) and found RAG responses surpassed GPT-4 WI for precision on direct text-based queries; RAG still underperforms on complex reasoning.",
            "recommendations_or_best_practices": "Use RAG for document-specific direct queries; ensure high-quality retrieval (good segmentation and embeddings); combine RAG with human experts for complex reasoning; tune retrieval and prompt templates for challenging questions.",
            "uuid": "e5605.5",
            "source_info": {
                "paper_title": "Exploring the Capabilities and Limitations of Large Language Models in the Electric Energy Sector",
                "publication_date_yy_mm": "2024-03"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "On the Potential of ChatGPT to Generate Distribution Systems for Load Flow Studies Using OpenDSS",
            "rating": 2
        },
        {
            "paper_title": "Real-Time Optimal Power Flow With Linguistic Stipulations: Integrating GPT-Agent and Deep Reinforcement Learning",
            "rating": 2
        },
        {
            "paper_title": "Large Foundation Models for Power Systems",
            "rating": 2
        },
        {
            "paper_title": "Large Foundation Models for Power Systems. arXiv.",
            "rating": 1
        }
    ],
    "cost": 0.01333225,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>EXPLORING THE CAPABILITIES AND LIMITATIONS OF LARGE Language MODELS IN THE Electric ENERGY SECTOR *</h1>
<p>Subir Majumder, ${ }^{1}$ Lin Dong, ${ }^{2}$ Fatemeh Doudi, ${ }^{3}$ Yuting Cai, ${ }^{4}$<br>Chao Tian, Dileep Kalathil<br>Department of Electrical and Computer Engineering<br>Texas A\&amp;M University<br>College Station, Texas, USA<br>Kevin Ding<br>CenterPoint Energy<br>Houston, Texas, USA<br>Anupam A. Thatte ${ }^{2}$<br>Midcontinent Independent System Operator (MISO)<br>Carmel, Indiana, USA<br>Na Li<br>School of Engineering and Applied Sciences<br>Harvard University<br>Cambridge, Massachusetts, USA<br>Le Xie (Corresponding author)<br>Department of Electrical and Computer Engineering<br>Texas A\&amp;M University, and<br>Texas A\&amp;M Energy Institute<br>College Station, Texas, USA<br>le.xie@tamu.edu</p>
<h4>Abstract</h4>
<p>Large Language Models (LLMs) as ChatBots have drawn remarkable attention thanks to their versatile capability in natural language processing as well as in a wide range of tasks. While there has been great enthusiasm towards adopting such foundational model-based artificial intelligence tools in all sectors possible, the capabilities and limitations of such LLMs in improving the operation of the electric energy sector need to be explored, and this article identifies fruitful directions in this regard. Key future research directions include data collection systems for fine-tuning LLMs, embedding power system-specific tools in the LLMs, and retrieval augmented generation (RAG)based knowledge pool to improve the quality of LLM responses and LLMs in safety-critical use cases.</p>
<p>Keywords Large Language Models $\cdot$ Electric Energy Sector $\cdot$ Capabilities $\cdot$ Limitations</p>
<h2>1 Introduction</h2>
<p>The transformative impact of self-attention and multi-head attention mechanisms, integral components of the transformer architecture ${ }^{1}$, has reshaped the landscape of AI research. Particularly noteworthy is their role in developing models to comprehend sequential data, notably text. These breakthroughs have been a cornerstone of large language models (LLMs) known for their capability to perform a wide range of tasks without being explicitly programmed for them. This architecture's scalability and efficiency in capturing long-range dependencies led to the development of Generative Pre-trained Transformer (GPT) models ${ }^{2}$. Due to their versatility, these LLMs are swiftly finding applications across many sectors, with researchers actively exploring their potential within the electric energy sector. While research has</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>showcased their potential in tasks such as generating customized code [3], utilizing retrieval augmented generation (RAG) capabilities in answering technical questions [3], power network data synthesis [4], using deep reinforcement learning for in-context optimal power-flow solution [5], concerns regarding data ownership [6], privacy [7], and safety guarantees [8], have also been raised.</p>
<p>The electric energy sector is the lifeblood of modern society. Power consumption not only serves as a barometer of societal behavior and prosperity but also underpins economic activities within the industrial and commercial sectors. Driven by the urgent imperative of global climate change and increasing electricity demand, the power industry is encountering an unprecedented volume of sensor integration, growing adoption of variable renewable resources such as solar and wind, and integration of newer technologies like hydrogen, electric vehicles, and large computing loads. Customer expectations regarding the quality and reliability of electricity supply are also evolving. This expansion has led to an exponential increase in the volume of equipment/devices and associated data, posing significant challenges for power system operators and utilities who must manage these complexities without a corresponding increase in the workforce. The rapid accumulation of new knowledge and instantaneous data exceeds the human capacity to process it unaided. These developments are propelling the power system into a phase of transition, necessitating adaptations to accommodate these new technologies and mitigate their associated challenges.</p>
<p>In this landscape, LLMs offer promising value to the electric energy sector, thanks to their ability to interpret human prompts and alleviate sensory overload, especially providing near real-time guidance in managing extreme weather events and risks associated with diverse sources of uncertainty. Therefore, it is important to demystify the capabilities and limitations of LLMs in performing realistic power-engineering tasks by themselves or delegate them via add-on capabilities, if needed. In this vein, as shown in Figure 1, through rigorous testing and analysis utilizing a production-grade LLM, specifically the GPT models, our study embarks on a comprehensive exploration of the capabilities of LLMs to scrutinize their readiness as an interface between human and electric energy systems. Further, we investigate how to better facilitate the integration of LLMs in the new era, considering their potential limitations. Finally, we discuss future research opportunities in the electric energy sector.
<img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: Capabilities and Limitations of Applying LLMs in the Electric Energy Sector.</p>
<h1>2 Capabilities of LLMs to Fill in the Gap</h1>
<p>In this section, we explore the capabilities of LLMs in tackling power engineering challenges as exemplified in Figure 2 based on experiments provided in the Supplemental Information (contain Sections SI.1-8). Our research delves into the accuracy of LLMs in performing various electrical engineering domain-specific tasks, including power flow analysis,</p>
<p>optimal power flow analysis, forecasting, image and pattern recognition, and answering questions utilizing a custom domain-specific knowledge base, among others. While our focus primarily revolves around the GPT model series, most of our observations are relevant to other mainstream models. In this section, we expand on the four key strengths of LLMs, illustrated in Figure 1, and elaborate on how these four strengths translate into key LLM capabilities for performing power engineering tasks.</p>
<h1>2.1 Language Models and In-weight Learning</h1>
<p>A foundational capability of LLMs is to produce semantically meaningful text outputs (responses) from text inputs (prompts). Though it is not clear what the pre-training datasets are, based on our investigation, current language models have the capability to provide schematically logical responses for power engineering domain-specific questions (see Sections SI.5). A major part of this capability may be a natural consequence of the large number of model parameters where certain information has been memorized. Then, the efficient processing in the transformer architecture allows efficient retrievals of such memorized information. This memorization and retrieval capability is sometimes referred to as in-weight learning. Foundational LLM models usually allow users to refine the model on a newer corpus of information through the 'fine-tuning' process ${ }^{9}$, which we have harnessed for load forecasting tasks as shown in Figure 2(B) (see Section SI.6). This process allows the model parameters within the LLM to be changed.
LLMs have profound implications for power systems, where LLMs can improve operational efficiency and support decision-making processes within the power sector by facilitating interaction between power system data, software, tools, and cross-domain datasets. Leveraging their inference capabilities, LLMs can enable real-time diagnostics (Section SI.1), on-demand analysis, and augment traditional control center operations.</p>
<h3>2.2 Prompt Engineering and In-context Learning</h3>
<p>The efficacy of LLMs in generating responses is significantly influenced by the structure and style of queries or prompts ${ }^{10}$, a practice commonly referred to as prompt engineering. Prompt engineering can help power engineers obtain more meaningful responses on difficult problem-solving tasks, while naïve prompts usually fail to induce desirable responses (Sections SI. 2 and SI.4). Some of the most well-known techniques in this direction are chain-of-thoughts prompts and retrieval augmented generations (RAGs). As illustrated in Figure 2(D), LLMs can sift through documents with large amounts of text information, which can be extremely useful in fast-paced work environments such as those in power system operations (Section SI.5.2).
One of the most surprising capabilities of LLMs observed in prompt engineering research is the emergent in-context learning capability, based on a few example prompts, as demonstrated in Figure 2(A) (see Section SI.3). More precisely, LLMs appear to derive patterns or learn rules from the prompts without the underlying model going through any additional changes and are then able to apply the learned patterns and rules from the prompts to produce correct responses (also demonstrated in one of the load forecasting examples in Section SI.6). Even if the LLM's performance may not be the best in class, the ability to learn based on limited data can be extremely useful for power engineers, given that power system datasets are usually protected. LLM-generated responses are typically variable, and one can reduce the variability of LLM-generated responses by harnessing custom domain-specific knowledge as a part of prompt engineering.</p>
<h3>2.3 Enhanced Capability via Tool Embedding</h3>
<p>LLMs, by themselves, are complex language processing units; however, their capability could be enhanced by including further processing units. Tool embedding is one of such enhanced capabilities, where LLMs are trained to delegate some of the tasks. For example, we have noted that GPT-4 prioritizes writing text files, executing codes utilizing the embedded tools, and inferring the generated results (as shown in the examples of Section SI.1, SI.2). As depicted in Figure 2(C), LLMs utilizes its tool embedding capability to extract regions with wildfire and superimpose on top of transmission line infrastructure map to identify the transmission lines at risk (Section SI.2).
This tool embedding capability can be extremely powerful for the power system engineers, where many of the applications require solving non-linear non-convex problems. Power system engineers utilize physics-based modeling and simulation tools, such as PSS/E, PSCAD, PowerWorld, and CyME, which could be called upon by LLMs to solve complex problems. This tool embedding capability could be facilitated by API-calling ${ }^{11}$. Tool embedding also facilitates on-demand remote processing of typical spatiotemporal time series power system data (e.g., SCADA data) (see Section SI.1).</p>
<h1>2.4 Enhanced Multi-modal Capabilities</h1>
<p>Many times, power engineers are expected to work with non-text and non-numeric data (see Sections SI. 3 and SI.4), such as time-series measurements, images, or videos. Foundational LLMs can be combined with other models to obtain multi-modal processing capabilities, enabling them to contextualize information presented in various non-text formats. Such capabilities are primarily facilitated by semantic embeddings, which are similar to the embeddings commonly used in natural language processing. Consequently, large language models (LLMs) exhibit robust performance for multi-modal data. Notably, state-of-the-art computer science literature are focusing on enhancing the capabilities of LLMs with multi-modal input and output. We anticipate that in the near future, multi-modal capabilities will be a native part of most off-the-shelf LLMs and that the next-generation applications will indeed exploit these capabilities. In our experiments, LLMs demonstrate proficiency in interpreting image data. In this regard, as shown in Figure 2(A), LLMs utilize multi-modal capability in addition to their in-context learning ability to diagnose defects in the insulator images (see Section SI.3).
<img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: Applications of LLMs in the Electric Energy Sector. This figure illustrates four distinct applications of LLMs in power systems. (A) Highlights the use of LLMs' multi-modality and appropriate choice of prompts in insulator defect detection from captured images. (B) Illustrates that fine-tuned language models through in-weight learning and further enhanced by prompt engineering techniques can be used for time-series forecasting. (C) Depicts LLMs' tool-embedding ability alongside prompt engineering can be employed to analyze wildfire patterns for risk assessments. (D) Demonstrates natural language processing strengths of LLMs and the use of RAG to generate precise responses to documents LLMs may not have seen before.</p>
<h1>3 Limitations of LLMs for Applications in the Electric Energy Sector</h1>
<h3>3.1 Challenges in Domain-Specific Data Availability and Processing</h3>
<p>A significant challenge in applying large language models (LLMs) within the power sector is the scarcity of domainspecific data in the pre-training of LLMs. Due to privacy concerns and regulations, pre-training of LLMs can only rely on publicly available and licensed third-party datasets ${ }^{12}$. Therefore, an open question for the research community is how to construct large power system domain specific training datasets for LLMs overcoming Critical Energy/Electric Infrastructure Information (CEII) per section 215A(d) of the United States Federal Power Act ${ }^{13}$. Constrained by this reality, smaller curated high-quality (labeled) datasets can be used for fine-tuning; which, for example, can assist the user in performing power flow analysis (Section SI.7), or even to prevent LLMs from generating unsafe responses (Section SI.8). Depending on usage scenarios, these fine-tuning datasets may need to be processed to prevent privacy leakage and converted into a format that is most efficient to fine-tune for downstream tasks. In-context few-shot learning capability of LLMs, including limited high-quality data as part of the prompt can potentially improve the performance, and some researchers are already exploring such possibilities ${ }^{4}$.
Additionally, a significant portion of power system data comes in the form of long-range time series datasets from diverse measuring instruments that may not be in natural language. This may require a customized design of more efficient embedding algorithms. Also, LLMs can only process a limited amount of information during each query, which is also known as context window, and power system signals may exhibit long-range dependence, which may not be captured due to these limitations.</p>
<h3>3.2 Lack of Safety Guardrails</h3>
<p>Safety in the power system context includes a broad spectrum, encompassing equipment safety, personnel safety, end-user safety, and safe operation of the electric energy systems. LLMs integrated into the power system must uphold these safety standards. Firstly, the results obtained from LLMs is probabilistic due to the nature of the generative models, and therefore, the correctness of responses may not be fully guaranteed. Secondly, LLMs generally do not provide uncertainty estimates for their outputs. Power system operations must comply with very strict safety performance guidelines, such as voltage magnitude limits. These power system operational requirements do not easily get satisfied by the LLMs. In our experiments, we observed that with subtle changes in prompts, LLMs generated varied responses and codes, which can potentially lead to erroneous results. We also found out that there are different ways LLMs could be tricked into providing responses that are unsafe (see Section SI.8). The lack of customized safety guardrails may also prevent us from performing some of the tasks necessary to do in electric energy systems. For example, during our experiments, we were not able to predict wildfire propagation or conduct auditing based solely on visual inputs. Additionally, since the LLMs are trained based on a large corpus of data, we need to ensure that minority voices are not suppressed ${ }^{14}$. Domain experts play a major role by providing real-time guidance and flagging problematic content to train LLMs.
Therefore, while LLMs could greatly benefit the power industry, they also pose unique risks that are different from traditional software systems. Hence, a governance framework is needed to mitigate their unique risks. As an example, the U.S. National Institute of Standards and Technology's (NIST) AI Risk Management Framework provides a voluntary guideline built upon the universal principles of responsible $\mathrm{AI}^{15}$. Creating a safe LLM-based system is a crucial area of research, especially in safety-critical infrastructure system such as the power industry.</p>
<h3>3.3 Not Adapted to Handle Physical Principles</h3>
<p>Energy production and consumption is a complex process governed by a set of physical principles such as Maxwell's equations, machine dynamics as well as human behavior. Modeling human behavior through LLMs, particularly in tasks like price forecasting and demand response policy design, presents formidable challenges, probably because prices are a much more compounded outcome of loads, human decisions, and market rules. Using more data might improve renewable generation prediction, price forecasting (Section SI.6), and understanding of human behavior, which could benefit power grid operation. While efforts have been underway to incorporate multiple specialized attention-seeking transformers ${ }^{16}$ for decision-making, which could also be utilized for power flow analysis (Section SI.7), the LLMs used in the control process are heavily specialized.
Foundational LLMs often lack explainability due to the black-box nature of these models. They can also be problematic in power systems where unexpected conditions can frequently arise. Therefore, LLM explainability will be a crucial component of building systems that are interpretable and transparent ${ }^{17}$. This also makes us believe that existing physics-driven, complex, specialized tools for power engineers remain indispensable. General purpose LLMs can serve</p>
<p>as valuable assistants, summarizing and finding implications of decision-making and assisting power engineers through tool embedding without delving into complex processes.</p>
<h1>3.4 Potential Exposure to Cybersecurity and Privacy Threats</h1>
<p>While integrating large language models (LLMs) into electric energy systems, cybersecurity and privacy emerge as a paramount concern. Even within the local LLM setups, there are potential cyber vulnerabilities. For example, building an LLM using power system-related company-specific data could inadvertently expose organizations to privilege escalation attacks, backdoor exploits, and the extraction of sensitive training data ${ }^{18}$. Online LLMs used for safety-critical tasks, such as price forecasting (Section SI.6), would be a frequent target of cyber-attacks. Furthermore, specialized prompts could be treated as trade secrets, which malicious actors could expose (Section SI.7).
As concerns regarding data privacy loom large, particularly as LLMs become integrated into power systems, establishing a standard protocol becomes imperative to ensure the data is sufficiently anonymized and sanitized to remove personal identification information before utilizing data for training. However, challenges persist in cases where personal or group information is context-dependent ${ }^{7}$.</p>
<h2>4 Future Prospects</h2>
<p>LLMs, such as, GPT models, have shown great promise in interpreting power engineering tasks through natural language-based inputs. Through this study, we tested the capabilities and limitations of LLMs when applied to the electric energy sector. We discussed the effectiveness of LLMs in answering general power system queries, code generation and data analysis. Further, through retrieval augmented generation, LLMs can serve as a documentation knowledge base and help with tasks such as operator training. Finally, the multi-modal capabilities of LLMs can be useful in diagnosing equipment failure and remote monitoring. Effectively, general-purpose LLMs show strong capabilities in detecting the correlation between objects (text, image, data), while they are still lacking in solving problems highly related to physics, which usually involve complex mathematical principles.
There are multiple possibilities to expand and enhance the capabilities of LLMs in power system research and applications. The first direction is curated data collection for fine-tuning foundational LLMs. This would require strong power system expertise to recognize the most effective data sources and design collection mechanisms to ensure the availability of high-quality datasets. Uncertainty quantification of the outcome of the LLMs is also an important direction for research in the electric power sector. The second direction is to allow power-system-specific tool embeddings. There are already strong and diverse tools for various power system functionalities, and LLMs can serve as a central point to connect all these tools through high-quality embedding. Naïve embeddings are likely to lose efficiency and may further cause different tools to conflict; therefore, power system expertise may be required to identify the desired behaviors for such tool embedding. A third direction is to build a power system knowledge base for retrieval augmentation. Although there are already generic approaches to generating such knowledge bases, they may not fully take advantage of physical constraints and power system specifics; therefore, this effort may require a deep understanding of power system operation and capabilities. The future of foundational model-based AI tools as a decision support co-pilot in the electric energy sector is bright.</p>
<h2>5 Declaration of Interests</h2>
<p>The authors declare no competing interests.</p>
<h2>6 Acknowledgements</h2>
<p>This work is supported in part by the Texas A\&amp;M Engineering Smart Grid Center and Texas A\&amp;M Energy Institute.</p>
<h1>References</h1>
<ol>
<li>Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, Ł. \&amp; Polosukhin, I. Attention is all you need Proceedings of the 31st International Conference on Neural Information Processing Systems (Curran Associates Inc., Long Beach, California, USA, 2017), 6000-6010. https://dl.acm.org/doi/10. $5555 / 3295222.3295349$.</li>
<li>Radford, A., Narasimhan, K., Salimans, T. \&amp; Sutskever, I. Improving Language Understanding by Generative Pre-Training OpenAI (2018). https://cdn.openai.com/research-covers/language-unsupervised/ language_understanding_paper.pdf.</li>
<li>Huang, C., Li, S., Liu, R., Wang, H. \&amp; Chen, Y. Large Foundation Models for Power Systems. arXiv. https : //doi.org/10.48550/arXiv.2312.07044 (2023).</li>
<li>Bonadia, R. S., Trindade, F. C. L., Freitas, W. \&amp; Venkatesh, B. On the Potential of ChatGPT to Generate Distribution Systems for Load Flow Studies Using OpenDSS. IEEE Trans. Power Syst. 38, 5965-5968 (2023).</li>
<li>Yan, Z. \&amp; Xu, Y. Real-Time Optimal Power Flow With Linguistic Stipulations: Integrating GPT-Agent and Deep Reinforcement Learning. IEEE Trans. Power Syst. 39, 4747-4750 (2024).</li>
<li>Jernite, Y. et al. Data Governance in the Age of Large-Scale Data-Driven Language Technology. Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency (Association for Computing Machinery, Seoul, Republic of Korea, 2022), 2206-2222. https://doi.org/10.1145/3531146.3534637.</li>
<li>Li, H., Chen, Y., Luo, J., Kang, Y., Zhang, X., Hu, Q., Chan, C. \&amp; Song, Y. Privacy in Large Language Models: Attacks, Defenses and Future Directions. arXiv. https://doi.org/10.48550/arXiv.2310.10383 (2023).</li>
<li>Huang, X. et al. A Survey of Safety and Trustworthiness of Large Language Models through the Lens of Verification and Validation. arXiv. https://doi.org/10.48550/arXiv.2305.11391 (2023).</li>
<li>Ziegler, D. M., Stiennon, N., Wu, J., Brown, T. B., Radford, A., Amodei, D., Christiano, P. \&amp; Irving, G. Fine-tuning language models from human preferences. arXiv. https://doi.org/10.48550/arXiv.1909.08593 (2019).</li>
<li>Bubeck, S., Chandrasekaran, V., Eldan, R., Gehrke, J., Horvitz, E., Kamar, E., Lee, P., Lee, Y. T., Li, Y., Lundberg, S., et al. Sparks of artificial general intelligence: Early experiments with gpt-4. arXiv. https://doi.org/10. 48550/arXiv. 2303.12712 (2023).</li>
<li>Song, Y., Xiong, W., Zhu, D., Li, C., Wang, K., Tian, Y. \&amp; Li, S. Restgpt: Connecting large language models with real-world applications via restful apis. arXiv. https://doi.org/10.48550/arXiv.2306.06624 (2023).</li>
<li>OpenAI. Enterprise Privacy at OpenAI Accessed: 13/03/2024. 2023. https://openai.com/enterpriseprivacy.</li>
<li>Department of Energy. Critical Electric Infrastructure Information; New Administrative Procedures https : //www.govinfo.gov/content/pkg/FR-2020-03-16/pdf/2020-04640.pdf. Mar. 2020.</li>
<li>Okerlund, J., Klasky, E., Middha, A., Kim, S., Rosenfeld, H., Kleinman, M. \&amp; Parthasarathy, S. What's in the chatterbox? Large language models, why they matter, and what we should do about them. tech. rep. (2022). https://stpp.fordschool.umich.edu/research/research-report/whats-in-the-chatterbox.</li>
<li>NIST AI Risk Management Framework https://www.nist.gov/itl/ai-risk-management-framework.</li>
<li>Zhang, L., Xiong, Y., Yang, Z., Casas, S., Hu, R. \&amp; Urtasun, R. Learning unsupervised world models for autonomous driving via discrete diffusion. arXiv. https://doi.org/10.48550/arXiv.2311.01017 (2023).</li>
<li>Luo, H. \&amp; Specia, L. From Understanding to Utilization: A Survey on Explainability for Large Language Models. arXiv. https://doi.org/10.48550/arXiv. 2401.12874 (2024).</li>
<li>Yao, Y., Duan, J., Xu, K., Cai, Y., Sun, Z. \&amp; Zhang, Y. A survey on large language model (llm) security and privacy: The good, the bad, and the ugly. High-Confidence Computing, 100211 (2024).</li>
</ol>
<p>This supplemental information contains supporting experimental results to understand the capabilities and limitations of large language models (LLMs) in the electric energy sector. Experiments appear in the same order as they were introduced in Figure 1 of the main article. Detailed discussions on the capabilities and limitations of LLMs in the main article have primarily been drawn from these experimental results. For each experiment, we first briefly introduce the relevant power engineering applications and then elaborate on how we have utilized the LLM to solve the underlying task. For experimentation and analysis, we have explicitly used OpenAI's GPT series models either through Web Interface (WI) or through Application Programming Interface (API). Unless specifically mentioned, we utilized WI for experimentation. It should be noted that the experiments conducted in this supplemental information are only meant to explore the many capabilities and limitations of LLM in the electric energy sector. Due to the generative nature of the LLMs, each time, the answers may not be consistent. Future research will investigate each of these use cases in much more detail. All the codes, prompts, and specific datasets as a part of this research analysis are available in ${ }^{1}$. While the detailed step-by-step responses generated by the LLM are not reproduced in their entirety in this document, they can be accessed through our shared Github repository.
Section Items:</p>
<ul>
<li>SI.1: Correlation Analysis for the Power Systems</li>
<li>SI.1.1: Correlation Analysis with Power Flow Data</li>
<li>SI.1.2: Correlation Analysis with Demand and Prices Data</li>
<li>SI.2: Wildfire Risks Recognition on the Power Lines</li>
<li>SI.3: Equipment Damage Detection in Power Grids</li>
<li>SI.4: On-site Hazards Recognition</li>
<li>SI.5: Document analysis for power systems</li>
<li>SI.5.1: Document Summarizing</li>
<li>SI.5.2: Knowledge Pool Analysis Through Retrieval-Augmented Generation</li>
<li>SI.6: Forecasting in Power Systems: Load and Price Forecasts</li>
<li>SI.7: Power Flow-related Problems</li>
<li>SI.7.1: Power Flow</li>
<li>SI.7.2: Optimal Power Flow</li>
<li>SI.8: Ensuring Safe Power Systems Operation</li>
</ul>
<h1>SI. 1 Correlation Analysis for the Power Systems</h1>
<p>Correlation analysis is a valuable tool for identifying the influence of one parameter on another, reducing the necessity for elaborate simulations commonly employed in power systems analysis. Its utility extends to control rooms, where operators can employ it as a preliminary step before in-depth analysis. Here, we emphasize two primary aspects concerning power systems operators: (i) the pivotal role of correlation analysis in augmenting decision-making within control rooms, and (ii) its potential to unveil insights into the dynamics of specific load demands. Our objective is twofold: to assess the efficacy of the foundational GPT model in aiding this endeavor and to explore how incremental prompt engineering can bridge this gap. It should be highlighted that this study is an exploratory analysis and not a comprehensive performance evaluation.</p>
<h2>SI.1.1 Correlation Analysis with Power Flow Data</h2>
<p>To be able to perform correlation analysis with power flow data, we have conducted a detailed simulation with an IEEE 24-node RTS, modified by wind generators at nodes 18, 21, and 22 and solar generators at nodes 2 and 3. We utilized PyPower for power flow calculations, with the results serialized into time-series CSV files for correlation analysis. Notably, the code to run PyPower and store the generated data in the CSV file was obtained from the GPT-4 Web Interface (WI). GPT-4 seems well-versed in the PyPower data structure, which would be useful in data analysis. GPT-4 WI also interprets dictionaries in JSON format extremely well.
Subsequently, we queried the GPT-4 with the dictionaries and CSV files in the following way. A sample of the network's architecture in JSON format is also provided below for reference:</p>
<p>Buses "1": {"type":2, "Pd":83.85, "Qd":22.0, "area":1, "Vm":1.0, "Va":0.0, "zone":1, "VA":"bus_1_VA", "PD":"bus_1_PD"}
Generators "1": {"bus":1,"Pg":10.0,"Qg":0.0,"status":1,"Pmax":100.0,"Pmin":16.0,"PG":"gen_1_PG"}
Branches "1": {"x":0.01, rateA":350.0, "ratio":0.0, "angle":0.0, "status":1, "from_bus":1, "to_bus":2, "PF": "branch_2_PF", "PT":"branch_2_PT"},
The CSV file contains time series power flow data. Can you perform exploratory data analytics for me? The dictionary for interpreting the csv file is also provided. Please load the dictionaries first.</p>
<p>Based on our observation, at GPT-4's current capability, it may not load the dictionary first, which often results in misidentification of the CSV file containing power flow data. The prompt "Please load the dictionaries first." seems to alleviate this challenge.
While we have indicated that the GPT-4 seems to automatically focus on exploratory data analysis, of which correlation is an integral part, for time series power flow data. If we slightly change our query to "provide us with insights", the generated response differs significantly. Comparative visualization of LLMs responses are shown in Figure S1. Figure S1(a) demonstrates how changing loads and generations impact power flow. Figure S1(b) demonstrates comprehensive correlation analysis as provided by GPT-4. Here, red represents a positive correlation, and blue represents a negative correlation.</p>
<p>In the next prompt, we ask the GPT-4 about the lines approaching their limits, and from the generated Python code, we observe that it correctly compares the maximum of the absolute value of the branch flows while comparing with flow limits as available in the JSON dictionary:
max_flows = data[branch_pf_columns].abs().max().reset_index()
max_flows.columns = ['Branch', 'Max Flow']
In the subsequent prompt, we furnish GPT-4 with the specifics regarding the locations of the wind and solar generators mentioned earlier. We then pose the query "how solar and wind generators are contributing to the line congestion". GPT responds by highlighting some branches that negatively correlate with power generation, this is also evident in Figure S1(b). However, based on our electrical engineering knowledge, we know that line flows are direction-specific, which can also be seen in Figure S1(a). Still, our objective here is to ascertain whether renewable energy sources contribute to line overload. To ensure accurate analysis, we provide additional guidance: "Knowledge: When comparing power generation or load with branch flow, please consider the absolute value." With this knowledge, GPT-4 can accurately identify the correlation between generator injection and branch flow. Additionally, GPT-4 generates a scatterplot illustrating the impact of solar/wind generation on line flows as shown in Figure S2 . GPT-4 can also estimate overloads for an unknown scenario based on these correlations.</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" />
(a) LLM asked to provide insights based on power flow data.
<img alt="img-3.jpeg" src="img-3.jpeg" />
(b) LLM asked to perform EDA with power flow data.</p>
<p>Figure S1: Correlation analysis demonstrating GPT-4 WI's capability in analyzing power flow data (Figures generated by GPT).</p>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Figure S2: Correlation analysis between renewable generation and branch flow (Figures generated by GPT).</p>
<h1>SI.1.2 Correlation Analysis with Demand and Prices Data</h1>
<p>Analyzing the correlation between demand and prices is significant for distinguishing load groups contributing to demand response initiatives. Identifying such correlation could be of absolute importance to an operator in managing resources, especially during peak demand days. For such analysis, we compiled a large time-series dataset comprising historical real-time price data, day-ahead price data, total wind generation, total solar generation, aggregated systemwide load demand, and the farm load data, which we tried to model. We provided the following prompt to the GPT-4 with the first two rows of the CSV file provided for reference.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">time</th>
<th style="text-align: center;">rtm_lz_south</th>
<th style="text-align: center;">dam_lz_south</th>
<th style="text-align: center;">wind</th>
<th style="text-align: center;">solar</th>
<th style="text-align: center;">ercot</th>
<th style="text-align: center;">farm_load</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">7/1/2022 0:00</td>
<td style="text-align: center;">0.015257266</td>
<td style="text-align: center;">0.019299607</td>
<td style="text-align: center;">0.668166171</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0.650940015</td>
<td style="text-align: center;">0.998710355</td>
</tr>
<tr>
<td style="text-align: center;">7/1/2022 1:00</td>
<td style="text-align: center;">0.010880517</td>
<td style="text-align: center;">0.016610027</td>
<td style="text-align: center;">0.684359174</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0.615978621</td>
<td style="text-align: center;">0.997153536</td>
</tr>
<tr>
<td style="text-align: center;">$\vdots$</td>
<td style="text-align: center;">$\vdots$</td>
<td style="text-align: center;">$\vdots$</td>
<td style="text-align: center;">$\vdots$</td>
<td style="text-align: center;">$\vdots$</td>
<td style="text-align: center;">$\vdots$</td>
<td style="text-align: center;">$\vdots$</td>
</tr>
</tbody>
</table>
<p>I wanted to model the farm load as available in the ' .csv ' file. Can you help me with the exploratory data analytics?
GPT-4 demonstrates an ability to discern contextual cues within the dataset, interpreting column headers such as 'rtm_lz_south' and 'dam_lz_south' as indicative of real-time and day-ahead prices, respectively. It contextualizes 'wind' and 'solar' columns further to identify them as corresponding to respective generation availability, while 'ercot' represents an energy-related metric specific to Texas. Notably, the Electric Reliability Council of Texas (ERCOT), the transmission grid operator in Texas, USA, widely utilizes the column header 'ercot' to signify total electricity demand across ERCOT-managed areas.
Given the enormous scope of exploratory data analytics, GPT-4 suggests a few possible directions, and upon request for "consider your best judgment", it performs time-series visualization, correlation analysis, and distribution analysis, with key insights and visualizations as shown in Figure S3. Based on our observation, in two subsequent interactions, GPT-4 recommends constructing a load forecasting model utilizing LSTM (Long Short-Term Memory), an AI-model typically used for forecasting. However, when generating the answer, we again observe a lack of self-awareness of the GPT-4,</p>
<p><img alt="img-5.jpeg" src="img-5.jpeg" />
(a) Correlation in the data across multiple columns.
<img alt="img-6.jpeg" src="img-6.jpeg" />
(b) Data visualizations through histograms.</p>
<p>Figure S3: LLM demand and prices correlation analysis visualization (Figures generated by GPT).</p>
<p>where it prepares a Python script to train an LSTM model using the TensorFlow/Keras environment, encountering errors likely due to platform limitations-potentially imposed by the OpenAI. It's worth noting that such constraints may be mitigated when executing the code on local machines, reducing the likelihood of encountering such issues in actual deployment.</p>
<p>In the second experiment, we directed GPT-4 to identify why the loads are behaving in a certain way, especially when the loads are below 0.9. GPT responded by conducting regression analysis using random forest. However, recognizing that power systems engineers might be more familiar with regression methods, we adjusted our prompt accordingly. GPT then conducted linear regression without data transformation. When we specifically inquired "about the accuracy of this model based on the residuals," GPT identified that the residuals are expected to be normally distributed around zero. Additionally, GPT-4 flagged potential issues such as heteroscedasticity or autocorrelation in the residuals and proposed applying transformations to address them but did not apply them automatically.
Key points:
(i) LLMs require contextual information for time-series data analysis. LLMs lack crucial insights about power systems and, therefore, still require human oversight and guidance for insights.
(ii) LLMs exhibit proficiency in conducting exploratory data analysis even without explicit guidance, yielding desired models. However, the model could be erroneous unless the user specifically checks for the model's accuracy.
(iii) LLMs may not inherently address data distribution issues unless specifically prompted. Power systems engineers may not always be able to understand these nuances, and LLMs do not bridge these gaps.</p>
<h1>SI. 2 Wildfire Risks Recognition on the Power Lines</h1>
<p>Historically, wildfires have caused unprecedented damages in California, USA, causing nearly $\$ 20$ billion in property damage over the past five years alone. These events pushed PG\&amp;E, a major utility company, to bankruptcy. As wildfires progress, power systems operators would receive a meteorological map as part of situational awareness, and the operators could be interested in overlaying the weather map onto the power map to assess the risk of the power lines. We wanted to investigate whether LLM's multi-modal capabilities could be leveraged to identify the risk of wildfires on power lines. To demonstrate this capability, we utilized data from the August Complex wildfire, California's largest wildfire in 2020. This wildfire persisted throughout August, September, and October. The wildfire-affected areas (maps are sourced from ${ }^{2}$ ) and transmission line maps (sourced from ${ }^{3}$ ) are given in Figure S4.
<img alt="img-7.jpeg" src="img-7.jpeg" />
(a) Fire situation in August.
<img alt="img-8.jpeg" src="img-8.jpeg" />
(b) Fire situation in September.
<img alt="img-9.jpeg" src="img-9.jpeg" />
(c) Fire situation in October.
<img alt="img-10.jpeg" src="img-10.jpeg" />
(d) Transmission Line Map.</p>
<p>Figure S4: August complex wildfire map and transmission lines.
We prompted GPT-4 with the instruction: "I will provide you with a wildfire map of August, September, and October. The area in red implies the wildfire area. A map of transmission lines is provided for the same area. Can you extract the wildfire areas for all three months and plot them in distinguishable colors on top of the transmission line map?" Given that we uploaded multiple files together, the identification of labels is not trivial. We observe from the generated codebases that GPT-4 can browse through metadata (e.g., file name) to correctly label the figures and use them for overlaying. This is demonstrated in Figure S5(b).
<img alt="img-11.jpeg" src="img-11.jpeg" /></p>
<p>Figure S5: LLM's Variational Results: wildfires superimposed on transmission Lines (Figures generated by GPT-4 through overlaying by generating suitable codes).</p>
<p>The generative nature of the LLMs is visible in Figure S5. Based on our experience, LLMs exclusively utilize tool embedding for image manipulation. Upon close inspection, we observe that the code primarily fails due to mistakes in filter applications. To investigate if prompt engineering can reduce some of the variabilities in code generation, we performed two additional sets of experiments and extracted the Python code generated by the GPT-4 across multiple trial runs. We then utilize the Abstract Syntax Tree (AST) data structure to compare the generated Python codes and generate the similarity score ${ }^{4}$. For the scenario in Figure S7(A), we provided all three wildfire maps as well as the transmission line map to the GPT, while for the scenarios in Figure S7(B) and (C) we considered only one of the wildfire maps. It can be seen that directness in the prompt can help GPT-4 to understand the problem statement better, and the codes so generated across multiple runs can become nearly identical, leading to a decreasing AST score. In all three scenarios, we conducted these experiments utilizing the map data obtained from Fire Information for Resource Management System of NASA ${ }^{5}$, as shown in Figure S6.</p>
<p><img alt="img-12.jpeg" src="img-12.jpeg" /></p>
<p>Figure S6: Unannotated August complex wildfire map and transmission lines (revised).
<img alt="img-13.jpeg" src="img-13.jpeg" /></p>
<p>Figure S7: Variation in the codebase generated using python tool. Histograms in Figures (A), (B) and (C) are generated using codes considering different prompts.</p>
<p>We utilized the best prompt in the previous experiments, namely, "Remove all background and keep only red area for me" for extracting wildfire-affected regions. While the generated codes are similar, differences exist in the extraction process, as highlighted in Figures S8(b) and S8(c). Nevertheless, once the images with transparent backgrounds are generated, they can be superimposed on top of the transmission line map as shown in S8(d).
<img alt="img-14.jpeg" src="img-14.jpeg" /></p>
<p>Figure S8: August complex wildfire map and transmission lines (Figures (b), (c) and (d) are generated through GPT).
Next, we utilized an iterative approach to generate the wildfire map overlayed on the power line as demonstrated in Figure S9. We systematically extracted wildfire-affected areas and overlayed all the extracted figures atop one another to gain a comprehensive understanding of the wildfire's impact on power lines. This exercise demonstrates that LLMs could be leveraged to overlay wildfire risk onto the electric energy systems map for visualization and situational awareness.</p>
<p><img alt="img-15.jpeg" src="img-15.jpeg" /></p>
<p>Figure S9: LLM-generated wildfire impact on transmission line identification and visualization (Bottom figures generated by GPT-4 through overlaying).</p>
<p>With this capability in mind, we presented GPT-4 with this prompt: "In the wildfire map, the green patches symbolize vegetation. Can you show the area that can catch fire next month?" However, we encountered a bottleneck with this command, where GPT-4 indicated: "As an AI, I'm unable to predict future wildfire spread as I do not have real-time data or the ability to run such models." such limitation appears to be an imposition by OpenAI, which may not be a concern with localized LLMs.</p>
<p>Key points:
(i) The capability of LLMs is continuously improving. However, GPTs are generative models. Based on their contextualization, the results can vary widely.
(ii) Prompt engineering can help in dividing the overall tasks into manageable tasks that GPT can do without error and would improve their credibility to the power systems engineers.</p>
<h1>SI. 3 Equipment Damage Detection in Power Grids</h1>
<p>With the growing complexity of power systems infrastructures, manual condition monitoring of equipment becomes practically infeasible. While machine learning can aid engineers ${ }^{6}$, such a capability would require training with a vast amount of data, which may not always be available. Given the foundational model nature of GPTs and leveraging its multi-modal feature, we wanted to investigate if LLMs can detect faulty equipment.
Initially, we explored whether GPT-4 could accurately identify faulty insulators using its inherent knowledge. Encountering limited accuracy, we aimed to overcome this by introducing a richer set of examples of intact and faulty insulators as shown in S10. We tagged every intact insulator as "Intact." Conversely, each faulty insulator was labeled and accompanied by a detailed description of its defects.
<img alt="img-16.jpeg" src="img-16.jpeg" /></p>
<p>Figure S10: Images of faulty insulators presented to GPT-4 for comprehension/questionnaire.</p>
<p>We introduced the figures to the GPT-4 one by one using the following knowledge base as a part of few-shot learning.
Figure (a): Insulator with breakage on the third layer. Status: Failure.
Figure (b): Insulator is not damaged. Status: Intact.
Figure (c): Insulator with breakage on the fifth layer. Status: Failure.
Now, tell me the status of Figure (d).
This strategy was designed to implement the few-shot prompt technique to improve GPT's ability to distinguish faulty and intact insulators by supplying clear, well-defined examples and criteria. Consequently, GPT-4 demonstrated a marked improvement, successfully recognizing insulator status with greater accuracy.
To assess accuracy quantitatively, we used a dataset comprising 40 insulators evenly split between intact and defective conditions. The GPT model tended to mislabel defective insulators when encountering unfamiliar failure conditions. GPT-4 sometimes mistook shadows for actual chips, leading to false classifications. Overall accuracy with this few-shot training method is reported in Table S1. Although the accuracy achieved in this study is lower than the results reported by ${ }^{6}$, which exceeds $90 \%$, it is important to note that our dataset was significantly smaller than theirs, and we did not use any synthetic images for training.</p>
<p>Table S1: Insulator Accuracy</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Dataset</th>
<th style="text-align: center;">Accuracy(\%)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Overall Accuracy</td>
<td style="text-align: center;">80</td>
</tr>
<tr>
<td style="text-align: center;">Only Intact Insulator</td>
<td style="text-align: center;">85</td>
</tr>
<tr>
<td style="text-align: center;">Only Faulty Insulator</td>
<td style="text-align: center;">70</td>
</tr>
</tbody>
</table>
<p>We continued our evaluation of this experiment by analyzing GPT's robustness in two additional scenarios: (i) whether the responses were consistent across various prompts and (ii) how the accuracy of the responses was influenced by the quality of the images used. As a part of the first question, we utilized an identical training dataset within a different prompt to analyze the outcomes. Our findings showed that, despite asking questions in various styles while conveying the same information, GPT-4 responses were consistent in this case. As for the second question, we investigated how GPT performs where low-quality images were presented as a part of the question and where the context images were of high quality. These low-quality images were generated in ${ }^{6}$. We observe that the GPT fails to identify faulty Insulators even with apparent flaws.</p>
<p>These assessments suggest that while both prompt engineering and multi-modal LLMs are promising candidates for facilitating fault detection tasks in power grids, further research is required to enhance their performance and robustness. Ultimately, it is important to highlight that although our analysis was exclusively focused on insulators, the methodology we employed can be adapted to include a wider range of power system equipment.</p>
<p>Key points:
(i) Due to vast pre-training datasets, LLMs may achieve satisfying performance while requiring less data compared to models developed from scratch.
(ii) LLMs may struggle to accurately label insulators if they encounter faults that have not been previously seen.</p>
<h1>SI. 4 On-site Hazards Recognition</h1>
<p>Electrical work around the power grid infrastructures ranks among the most hazardous professions, necessitating unwavering attention and stringent precautions throughout operations. Supervision and safety checks are indispensable to ensure adherence to these protocols. Remote supervision offers efficiency in ensuring safe operation around power grid infrastructures. To investigate GPT's proficiency in recognizing risks around the power lines, we posed the question "Between 0-10 give me a safety score for the given figure" with Figure S11.
<img alt="img-17.jpeg" src="img-17.jpeg" /></p>
<p>Figure S11: Electrical project site. Taken from ${ }^{7}$.
Our expectation behind this prompt was to investigate whether an LLM would properly recognize hazards and alert site engineers to take necessary actions. However, we encountered a bottleneck when GPT-4 indicated: "I can't give a precise numerical safety score," which is an artificial constraint imposed by OpenAI as we suspected. Nonetheless, GPT-4 demonstrated its ability to identify several critical safety concerns, including 'Proximity to power lines', 'Personal protective equipment (PPE)', 'Stability of the crane', 'Fall protection', 'Observing a safe working radius'. To gain insight into GPT's situational awareness regarding power lines, we prompted it with the question, "What factor should I consider for giving score for working around power lines," we devised the following prompt based on the response from GPT-4 with a range list of factors:</p>
<p>Give an aggregated safety score for this picture.
Instruction: First, allocate a score between $0-10$ for each of the following factors. If you are unsure about a particular aspect, give it a score of 5 . My aggregated score will be the average of all individual scores.
Factors: Distance from Power Lines, Use of Insulating Equipment, Personal Protective Equipment (PPE), Training and Awareness, Lockout/Tagout Procedures, Warning Signs and Barriers, Weather Conditions, Supervision and Safety Protocols, Emergency Plans, Inspection and Maintenance</p>
<p>We observed that GPT-4 provided the following individual scores(s) in one of the instances: Distance from Power Lines (Score: 2), Use of Insulating Equipment (Score: 2), Personal Protective Equipment (PPE) (Score: 1), Training and Awareness (Score: 3), Lockout/Tagout Procedures (Score: 2), Warning Signs and Barriers (Score: 1), Weather Conditions (Score: 8), Supervision and Safety Protocols (Score: 3), Emergency Plans (Score: 5, unavailable), Inspection and Maintenance (Score: 5, unavailable). Given the limitations of self-consistency prompting, we observed that GPT-4 employed its embedded Python tool to compute aggregated scores in the backend. To investigate the ability to deploy this method in the real world, we have repeated this experiment 55 times, and the distribution of individual components scores and the aggregated score is given in Figure S12.
It can be observed that the aggregated audit score lies between 3 and 4 (out of 10) for $\sim 60 \%$ of the time, with a peak at 3.5 , symbolizing the GPT-4 consistently identifies hazards and poor operating conditions around the electricity infrastructures. To understand what contributes to these variations, we looked into distributions of individual components of the audit score. The prompt specifically states that we should allocate a score of 5 if uncertain, and we observe the associated impact on the decision-making. For the individual metrics, such as Training and Awareness, Lockout/Tagout Procedures, Supervision and Safety Protocols, Emergency Plans, Inspection, and Maintenance, it is hard to determine the presence of these protocols from one picture, so we observe GPT-4 allocating a score of 5 in those cases in several instances. We also observe GPT-4 consistently drawing lower values, for example, in Lockout/Tagout Procedures, Supervision, and Safety Protocols, where GPT-4 seems to be quite certain that these guidelines are not being followed.</p>
<p><img alt="img-18.jpeg" src="img-18.jpeg" /></p>
<p>Figure S12: Variations in GPT generated audit scores. (A) (a) Distance from Power Lines, (b) Use of Insulating Equipment, (c) Personal Protective Equipment (PPE), (d) Training and Awareness, (e) Lockout/Tagout Procedures, (f) Warning Signs and Barriers, (g) Weather Conditions, (h) Supervision and Safety Protocols, (i) Emergency Plans, (j) Inspection and Maintenance. (B) Aggregated Audit Score.</p>
<p>Given the unsafeness of the operating condition, GPT-4 extrapolates the absence of warning signs and barriers. Finally, while we observe a blue sky from one picture, it is hard to determine the entire weather condition. Therefore, we observe GPT-4 allocating scores ranging from 6 to 9 , with scores peaking at 8 , symbolizing the GPT-4 is able to capture the uncertainty.
These experiments demonstrate the suitability of GPTs in real-world situational surveillance based on constant supply of images and we can extrapolate that videos could also be suitably embedded for this applications. Therefore, this tool can be of immense value to power engineers.
Key points:
(i) LLMs have the capability to identify on-site security risks and furnish supervisors with necessary feedback with sufficient prompts.
(ii) Including more contexts in the calculation of scores would help in generating consistent safety scores for decision-making.</p>
<h1>SI. 5 Document analysis for power systems</h1>
<p>In power systems management, efficient processing of information is crucial for effective decision-making. This sector relies extensively on diverse documents such as protocols, guidelines, and technical reports, making it crucial to utilize tools that can adeptly manage this information. This section examines two such tools ideally suited for document processing in the power system domain: the GPT-4 Web Interface (WI) and the Retrieval-Augmented Generation (RAG) model. We assess the GPT-4 WI by its performance in document summarization tasks, and evaluate the RAG model through its capability for question answering, which aligns well with its design purpose. It should be highlighted that this study is an exploratory analysis and not a comprehensive performance evaluation.</p>
<h2>SI.5.1 Document Summarizing</h2>
<p>In this context, we referred to the Department of Energy (DoE)'s technical report ${ }^{8}$ on smart grids and tasked the GPT-4 WI with summarizing the document without providing additional context. GPT-4 excelled in comprehending and discussing all sections of the 170-page report. It summarized smart grids as "more intelligent, efficient, and resilient infrastructure through the adoption of digital sensing, communication, and control technologies." However, we sought to explore how GPT-4 would perform with more specific instructions. To this end, we asked it to "interpret the document from the perspective of a power system technician?" In response, GPT-4 provided a more detailed and technical summary, describing smart grids as "transition from traditional grid systems to more advanced, digitally enabled grids that integrate renewable energy sources, manage distributed energy resources (DERs), and enhance grid reliability and efficiency through digital communication and control technologies." These varied responses clearly demonstrate GPT's ability to tailor its analysis based on the audience or questions posed, which could be instrumental in developing structured summaries.</p>
<p>This experiment not only served as a practical demonstration of the GPT-4 WI's capabilities in document processing but also highlighted the importance of customized prompts in significantly improving the system's ability to generate specialized content, affirming its potential as a valuable tool in technical fields.</p>
<h2>SI.5.2 Knowledge Pool Analysis Through Retrieval-Augmented Generation</h2>
<p>Retrieval-Augmented Generation (RAG) enhances the performance of LLMs by combining their text-generating capabilities with the ability to retrieve relevant information from external databases. This integration significantly improves both the accuracy and contextual relevance of the responses generated by LLMs. Introduced in ${ }^{9}$, RAG first processes the content of the query. It then uses this processed query to search an external database to find the most relevant text fragments. This search typically employs vector similarity measures, where both the query and the documents are represented as high-dimensional vectors. The goal is to retrieve documents whose vectors closely match the query vector, indicating high relevance to the input query. Given the promising enhancements brought by the RAG system, in this section, we evaluate RAG's effectiveness in the power sector by assessing its question-answering capabilities across power-specific documents.
We integrate Langchain with OpenAI's API to develop a Retrieval-Augmented Generation (RAG) system, utilizing the GPT-3.5-Turbo model. Following data segmentation, we employ the following techniques for processing:</p>
<ul>
<li>OpenAIEmbeddings which utilize Byte Pair Encoding (BPE) for tokenization and vectorization.</li>
<li>Facebook AI Similarity Search is employed for storing vectors, which is crucial for the retrieval capabilities of our RAG system.</li>
</ul>
<p>In our investigation of RAG's potential as a knowledge repository, we concentrated on nodal protocols 2 through 9 from ERCOT ${ }^{10}$. Initially, we appended these documents into a single corpus for analysis and then segmented this corpus to facilitate the knowledge examination. Our evaluation of RAG's performance was based on two types of questions: (i) those that could be directly answered from the text (e.g., "What is the Opportunity Outage?"), and (ii) those that require nuanced reasoning for a response (e.g., "How do you calculate physical responsive ancillary service capability across ERCOT?" - the term 'Ancillary service' was included in the question to introduce complexity).
Based on our repeated experiments so far, we observed that RAG can provide more accurate and coherent answers to direct questions. As shown in S13, when compared with the excerpt from the ERCOT nodal protocol, the RAG's responses surpassed even those generated by the GPT-4 WI in terms of precision and alignment. However, RAG's ability got diminished when addressing more complex queries. For example, it either failed to provide an answer or offered responses that are not thorough and vary with each attempt. As demonstrated in S14(a), RAG struggled to pinpoint the correct response according to nodal protocol 6.5.7.5, Even when tested under lower temperatures. In LLMs,</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>*Preprint to the paper accepted by Joule: https://doi.org/10.1016/j.joule.2024.05.009
${ }^{1}$ Equal contribution as joint first co-authors
${ }^{2}$ The views expressed in this paper are solely those of the author and do not necessarily represent those of MISO.&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>