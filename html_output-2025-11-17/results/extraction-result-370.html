<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-370 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-370</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-370</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-16.html">extraction-schema-16</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <p><strong>Paper ID:</strong> paper-218674375</p>
                <p><strong>Paper Title:</strong> A Scientific Information Extraction Dataset for Nature Inspired Engineering</p>
                <p><strong>Paper Abstract:</strong> Nature has inspired various ground-breaking technological developments in applications ranging from robotics to aerospace engineering and the manufacturing of medical devices. However, accessing the information captured in scientific biology texts is a time-consuming and hard task that requires domain-specific knowledge. Improving access for outsiders can help interdisciplinary research like Nature Inspired Engineering. This paper describes a dataset of 1,500 manually-annotated sentences that express domain-independent relations between central concepts in a scientific biology text, such as trade-offs and correlations. The arguments of these relations can be Multi Word Expressions and have been annotated with modifying phrases to form non-projective graphs. The dataset allows for training and evaluating Relation Extraction algorithms that aim for coarse-grained typing of scientific biological documents, enabling a high-level filter for engineers.</p>
                <p><strong>Cost:</strong> 0.014</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e370.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e370.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SCIIE (applied)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>SCIIE span-based scientific information extraction model (applied to FOBIE)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A span-based neural information extraction model (originally developed for scientific text in AI/ML venues) that jointly predicts spans (entities/keyphrases) and relations; here it was trained and evaluated on the FOBIE biology trade-off dataset with a small adaptation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Multi-Task Identification of Entities, Relations, and Coreference for Scientific Knowledge Graph Construction</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>SCIIE span-based neural relation and entity extraction</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>SCIIE enumerates candidate spans (all contiguous token sequences up to a configured max length), represents each token with concatenated word, character and ELMo embeddings, encodes the sentence with a bi-LSTM, represents each span with the bi-LSTM outputs at span boundaries plus an attention-weighted span-head vector, classifies spans (span vs. non-span) and classifies relations between span pairs (relation vs. non-relation) in a multi-task setup that shares weights across tasks (span identification and relation classification). It requires no external POS/dependency input and relies on learned contextual representations.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>computational method / machine learning relation extraction</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>computer science / natural language processing (scientific IE on AI/ML text)</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>biology / biomimetics / scientific biology text (TRADE-OFF extraction)</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>adapted/modified for new context</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>Trained SCIIE on the new FOBIE annotated biology dataset (trigger and argument spans). The only hyperparameter change reported was increasing the maximum candidate span length to 14 tokens to accommodate longer multi-word keyphrases common in biological full-text sentences; otherwise default hyperparameters were kept. Input spans were interpreted as trigger spans and argument spans specific to trade-off relations.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>Partially to largely successful: SCIIE substantially outperformed the simple Rule-Based System on FOBIE. Reported metrics: Relation Extraction F1 on development = 69.60 (P=69.60, R=69.60) and test = 69.04 (P=68.28, R=69.82). Span boundary F1: dev = 82.40 (P=84.50, R=80.40), test = 81.90 (P=84.26, R=79.67). The model performed better at extracting TRADE-OFF relations than ARGUMENT-MODIFIER relations, indicating some limitations for modifier-specific classes.</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>Challenges included longer sentences and longer multi-word argument spans typical of full-text biology papers (requiring span-length adjustment), high syntactic variability of trade-off expressions, and lower performance on ARGUMENT-MODIFIER relations—suggesting domain-specific attachment and modifier phenomena that the model had difficulty with.</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>Availability of the manually annotated FOBIE dataset for supervised training, pre-trained contextual embeddings (ELMo) that provide robustness to syntactic variance, and the span-based multi-task architecture that naturally handles multi-word expressions.</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>Required a domain-expert annotated training set (FOBIE), adequate compute for training a bi-LSTM with ELMo, and hyperparameter adjustment (max span length) to match the longer keyphrases in biology texts.</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>Likely generalizable to other scientific domains provided domain-specific annotated data and minor hyperparameter tuning (e.g., max span length); pretrained contextual embeddings and the span-based architecture afford cross-domain flexibility, but per-domain annotation is still required for best performance.</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>explicit procedural / technical (computational method and implementation details) combined with representational artifacts (pretrained embeddings) and applied empirical know-how (hyperparameter tuning for span length).</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e370.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e370.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RBS (simple)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Simple Rule-Based System inspired by Open Information Extraction</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A handcrafted rule-based extractor using a curated list of trade-off trigger words and dependency-parse traversal to find argument subtrees; used to pre-select and bootstrap annotation of biological sentences expressing trade-offs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>Rule-Based Dependency-parse Traversal Extraction (RBS)</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>The RBS stems and matches a curated list of trigger words (derived from an analysis of 200 biology papers) and, when a trigger is found, traverses the sentence dependency parse tree to identify subtrees corresponding to argument phrases and modifiers. Heuristics handle prepositional phrases and nested modifiers; the RBS does not classify relations but flags candidate TRADE-OFF expressions for manual correction.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>computational method / rule-based information extraction</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>natural language processing / Open Information Extraction (computer science)</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>biology / biomimetics (extraction of TRADE-OFF relations from biological texts)</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>adapted/modified for new context</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>Compiled domain-specific trigger vocabulary from 200 biology papers (e.g., association, balance, conflict, correlation, compromise, interaction, interplay, optimization, ratio, relationship, tradeoff), stemmed triggers, and created dependency-traversal heuristics and PP-handling rules and heuristics for nested modifiers tailored to the syntactic patterns observed in biology full-text sentences. The system was explicitly designed to produce candidates for subsequent manual correction rather than fully automated extraction.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>Partially successful as a bootstrapping/annotation aid but insufficient as a stand-alone extractor. Quantitative boundary detection performance was low: boundaries P/R/F1 on dev ~45.17 / 35.84 / 39.97 and test ~44.31 / 35.32 / 39.31. The RBS struggled with many real-sentence phenomena and was not used as the final extractor.</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>Problems included negation handling, long and syntactically complex sentences, pronoun subjects, abbreviations used as adjectives, prepositional phrase attachment ambiguity, co-reference, and wide lexical/syntactic variation in how trade-offs are expressed (e.g., 'negative correlation', 'balance'). Many trigger occurrences did not actually indicate a trade-off and required domain reasoning to disambiguate.</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>Availability of dependency parses (spaCy), a curated trigger-word list derived from domain papers, and the ability to use RBS outputs as high-quality candidates for domain-expert manual annotation (saving annotation time).</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>Relied on quality dependency parses, domain-expert analysis to produce the trigger list and correction of outputs, and bespoke heuristics for PP and nested modifier handling; insufficient without manual relabeling.</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>Limited: while the approach can be ported to other domains by building a domain-specific trigger vocabulary and new heuristics, coverage of the long tail of syntactic patterns is poor and extensive rule engineering plus domain expertise are required for each target domain.</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>explicit procedural rules combined with tacit domain know-how (selection of trigger vocabulary and heuristic exceptions).</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e370.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e370.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ELMo (used)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ELMo (Deep Contextualized Word Representations)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Pretrained deep contextualized word embeddings used as token-level inputs to SCIIE, providing context-sensitive lexical representations that help handle syntactic variability in biological texts.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Deep Contextualized Word Representations</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>ELMo contextualized embeddings (pretrained language model embeddings)</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>ELMo produces contextualized token vectors from a pretrained bidirectional language model; vectors are concatenated with word and character embeddings as token representations fed into the sentence encoder (bi-LSTM) to produce span representations and support span and relation classification.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>computational method / representation learning / pretrained embeddings</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>natural language processing / deep learning</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>scientific biology information extraction (TRADE-OFF extraction)</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>direct application with integration into the target model</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>No algorithmic modification reported; ELMo vectors were concatenated with word and character embeddings as in the original SCIIE architecture and used unchanged as pretrained inputs.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>Successful as a facilitating component: authors state that pretrained embeddings provide reliable flexibility with respect to syntactic variance and contributed to the neural model (SCIIE) outperforming the RBS. No isolated quantitative ablation was reported in this paper, but overall SCIIE results demonstrate improved performance.</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>Potential domain mismatch between ELMo pretraining corpora and full-text biology language is possible but not reported as a major impediment; handling long multi-word keyphrases still required span-length hyperparameter adjustment.</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>Availability of pretrained models and their ease of integration into SCIIE; embeddings capture contextual usage patterns that transfer across domains to some extent.</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>Computational resources to load and use ELMo vectors; compatible tokenization and integration into the span-based model pipeline; supervised labeled data for downstream fine-tuning/classification.</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>Likely highly generalizable to other scientific domains; pretrained contextual embeddings have broad applicability, though domain-adaptive pretraining or fine-tuning may improve results further for highly specialized corpora.</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>explicit technical artifact (representational knowledge) and instrumental/technical skill (integration into ML pipelines).</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Multi-Task Identification of Entities, Relations, and Coreference for Scientific Knowledge Graph Construction <em>(Rating: 2)</em></li>
                <li>Open information extraction from the web <em>(Rating: 2)</em></li>
                <li>Open information extraction: The second generation <em>(Rating: 1)</em></li>
                <li>Computer-aided biomimetics <em>(Rating: 2)</em></li>
                <li>Towards a Design Process for Computer-Aided Biomimetics <em>(Rating: 2)</em></li>
                <li>Deep Contextualized Word Representations <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-370",
    "paper_id": "paper-218674375",
    "extraction_schema_id": "extraction-schema-16",
    "extracted_data": [
        {
            "name_short": "SCIIE (applied)",
            "name_full": "SCIIE span-based scientific information extraction model (applied to FOBIE)",
            "brief_description": "A span-based neural information extraction model (originally developed for scientific text in AI/ML venues) that jointly predicts spans (entities/keyphrases) and relations; here it was trained and evaluated on the FOBIE biology trade-off dataset with a small adaptation.",
            "citation_title": "Multi-Task Identification of Entities, Relations, and Coreference for Scientific Knowledge Graph Construction",
            "mention_or_use": "use",
            "procedure_name": "SCIIE span-based neural relation and entity extraction",
            "procedure_description": "SCIIE enumerates candidate spans (all contiguous token sequences up to a configured max length), represents each token with concatenated word, character and ELMo embeddings, encodes the sentence with a bi-LSTM, represents each span with the bi-LSTM outputs at span boundaries plus an attention-weighted span-head vector, classifies spans (span vs. non-span) and classifies relations between span pairs (relation vs. non-relation) in a multi-task setup that shares weights across tasks (span identification and relation classification). It requires no external POS/dependency input and relies on learned contextual representations.",
            "procedure_type": "computational method / machine learning relation extraction",
            "source_domain": "computer science / natural language processing (scientific IE on AI/ML text)",
            "target_domain": "biology / biomimetics / scientific biology text (TRADE-OFF extraction)",
            "transfer_type": "adapted/modified for new context",
            "modifications_made": "Trained SCIIE on the new FOBIE annotated biology dataset (trigger and argument spans). The only hyperparameter change reported was increasing the maximum candidate span length to 14 tokens to accommodate longer multi-word keyphrases common in biological full-text sentences; otherwise default hyperparameters were kept. Input spans were interpreted as trigger spans and argument spans specific to trade-off relations.",
            "transfer_success": "Partially to largely successful: SCIIE substantially outperformed the simple Rule-Based System on FOBIE. Reported metrics: Relation Extraction F1 on development = 69.60 (P=69.60, R=69.60) and test = 69.04 (P=68.28, R=69.82). Span boundary F1: dev = 82.40 (P=84.50, R=80.40), test = 81.90 (P=84.26, R=79.67). The model performed better at extracting TRADE-OFF relations than ARGUMENT-MODIFIER relations, indicating some limitations for modifier-specific classes.",
            "barriers_encountered": "Challenges included longer sentences and longer multi-word argument spans typical of full-text biology papers (requiring span-length adjustment), high syntactic variability of trade-off expressions, and lower performance on ARGUMENT-MODIFIER relations—suggesting domain-specific attachment and modifier phenomena that the model had difficulty with.",
            "facilitating_factors": "Availability of the manually annotated FOBIE dataset for supervised training, pre-trained contextual embeddings (ELMo) that provide robustness to syntactic variance, and the span-based multi-task architecture that naturally handles multi-word expressions.",
            "contextual_requirements": "Required a domain-expert annotated training set (FOBIE), adequate compute for training a bi-LSTM with ELMo, and hyperparameter adjustment (max span length) to match the longer keyphrases in biology texts.",
            "generalizability": "Likely generalizable to other scientific domains provided domain-specific annotated data and minor hyperparameter tuning (e.g., max span length); pretrained contextual embeddings and the span-based architecture afford cross-domain flexibility, but per-domain annotation is still required for best performance.",
            "knowledge_type": "explicit procedural / technical (computational method and implementation details) combined with representational artifacts (pretrained embeddings) and applied empirical know-how (hyperparameter tuning for span length).",
            "uuid": "e370.0"
        },
        {
            "name_short": "RBS (simple)",
            "name_full": "Simple Rule-Based System inspired by Open Information Extraction",
            "brief_description": "A handcrafted rule-based extractor using a curated list of trade-off trigger words and dependency-parse traversal to find argument subtrees; used to pre-select and bootstrap annotation of biological sentences expressing trade-offs.",
            "citation_title": "here",
            "mention_or_use": "use",
            "procedure_name": "Rule-Based Dependency-parse Traversal Extraction (RBS)",
            "procedure_description": "The RBS stems and matches a curated list of trigger words (derived from an analysis of 200 biology papers) and, when a trigger is found, traverses the sentence dependency parse tree to identify subtrees corresponding to argument phrases and modifiers. Heuristics handle prepositional phrases and nested modifiers; the RBS does not classify relations but flags candidate TRADE-OFF expressions for manual correction.",
            "procedure_type": "computational method / rule-based information extraction",
            "source_domain": "natural language processing / Open Information Extraction (computer science)",
            "target_domain": "biology / biomimetics (extraction of TRADE-OFF relations from biological texts)",
            "transfer_type": "adapted/modified for new context",
            "modifications_made": "Compiled domain-specific trigger vocabulary from 200 biology papers (e.g., association, balance, conflict, correlation, compromise, interaction, interplay, optimization, ratio, relationship, tradeoff), stemmed triggers, and created dependency-traversal heuristics and PP-handling rules and heuristics for nested modifiers tailored to the syntactic patterns observed in biology full-text sentences. The system was explicitly designed to produce candidates for subsequent manual correction rather than fully automated extraction.",
            "transfer_success": "Partially successful as a bootstrapping/annotation aid but insufficient as a stand-alone extractor. Quantitative boundary detection performance was low: boundaries P/R/F1 on dev ~45.17 / 35.84 / 39.97 and test ~44.31 / 35.32 / 39.31. The RBS struggled with many real-sentence phenomena and was not used as the final extractor.",
            "barriers_encountered": "Problems included negation handling, long and syntactically complex sentences, pronoun subjects, abbreviations used as adjectives, prepositional phrase attachment ambiguity, co-reference, and wide lexical/syntactic variation in how trade-offs are expressed (e.g., 'negative correlation', 'balance'). Many trigger occurrences did not actually indicate a trade-off and required domain reasoning to disambiguate.",
            "facilitating_factors": "Availability of dependency parses (spaCy), a curated trigger-word list derived from domain papers, and the ability to use RBS outputs as high-quality candidates for domain-expert manual annotation (saving annotation time).",
            "contextual_requirements": "Relied on quality dependency parses, domain-expert analysis to produce the trigger list and correction of outputs, and bespoke heuristics for PP and nested modifier handling; insufficient without manual relabeling.",
            "generalizability": "Limited: while the approach can be ported to other domains by building a domain-specific trigger vocabulary and new heuristics, coverage of the long tail of syntactic patterns is poor and extensive rule engineering plus domain expertise are required for each target domain.",
            "knowledge_type": "explicit procedural rules combined with tacit domain know-how (selection of trigger vocabulary and heuristic exceptions).",
            "uuid": "e370.1"
        },
        {
            "name_short": "ELMo (used)",
            "name_full": "ELMo (Deep Contextualized Word Representations)",
            "brief_description": "Pretrained deep contextualized word embeddings used as token-level inputs to SCIIE, providing context-sensitive lexical representations that help handle syntactic variability in biological texts.",
            "citation_title": "Deep Contextualized Word Representations",
            "mention_or_use": "use",
            "procedure_name": "ELMo contextualized embeddings (pretrained language model embeddings)",
            "procedure_description": "ELMo produces contextualized token vectors from a pretrained bidirectional language model; vectors are concatenated with word and character embeddings as token representations fed into the sentence encoder (bi-LSTM) to produce span representations and support span and relation classification.",
            "procedure_type": "computational method / representation learning / pretrained embeddings",
            "source_domain": "natural language processing / deep learning",
            "target_domain": "scientific biology information extraction (TRADE-OFF extraction)",
            "transfer_type": "direct application with integration into the target model",
            "modifications_made": "No algorithmic modification reported; ELMo vectors were concatenated with word and character embeddings as in the original SCIIE architecture and used unchanged as pretrained inputs.",
            "transfer_success": "Successful as a facilitating component: authors state that pretrained embeddings provide reliable flexibility with respect to syntactic variance and contributed to the neural model (SCIIE) outperforming the RBS. No isolated quantitative ablation was reported in this paper, but overall SCIIE results demonstrate improved performance.",
            "barriers_encountered": "Potential domain mismatch between ELMo pretraining corpora and full-text biology language is possible but not reported as a major impediment; handling long multi-word keyphrases still required span-length hyperparameter adjustment.",
            "facilitating_factors": "Availability of pretrained models and their ease of integration into SCIIE; embeddings capture contextual usage patterns that transfer across domains to some extent.",
            "contextual_requirements": "Computational resources to load and use ELMo vectors; compatible tokenization and integration into the span-based model pipeline; supervised labeled data for downstream fine-tuning/classification.",
            "generalizability": "Likely highly generalizable to other scientific domains; pretrained contextual embeddings have broad applicability, though domain-adaptive pretraining or fine-tuning may improve results further for highly specialized corpora.",
            "knowledge_type": "explicit technical artifact (representational knowledge) and instrumental/technical skill (integration into ML pipelines).",
            "uuid": "e370.2"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Multi-Task Identification of Entities, Relations, and Coreference for Scientific Knowledge Graph Construction",
            "rating": 2,
            "sanitized_title": "multitask_identification_of_entities_relations_and_coreference_for_scientific_knowledge_graph_construction"
        },
        {
            "paper_title": "Open information extraction from the web",
            "rating": 2,
            "sanitized_title": "open_information_extraction_from_the_web"
        },
        {
            "paper_title": "Open information extraction: The second generation",
            "rating": 1,
            "sanitized_title": "open_information_extraction_the_second_generation"
        },
        {
            "paper_title": "Computer-aided biomimetics",
            "rating": 2,
            "sanitized_title": "computeraided_biomimetics"
        },
        {
            "paper_title": "Towards a Design Process for Computer-Aided Biomimetics",
            "rating": 2,
            "sanitized_title": "towards_a_design_process_for_computeraided_biomimetics"
        },
        {
            "paper_title": "Deep Contextualized Word Representations",
            "rating": 2,
            "sanitized_title": "deep_contextualized_word_representations"
        }
    ],
    "cost": 0.013825249999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>A Scientific Information Extraction Dataset for Nature Inspired Engineering</p>
<p>Ruben Kruiper 
Heriot-Watt University
Riccarton Campus EdinburghEH14 4ASUnited Kingdom</p>
<p>Julian F V Vincent 
Heriot-Watt University
Riccarton Campus EdinburghEH14 4ASUnited Kingdom</p>
<p>Jessica Chen-Burger 
Heriot-Watt University
Riccarton Campus EdinburghEH14 4ASUnited Kingdom</p>
<p>Marc P Y Desmulliez 
Heriot-Watt University
Riccarton Campus EdinburghEH14 4ASUnited Kingdom</p>
<p>Ioannis Konstas 
Heriot-Watt University
Riccarton Campus EdinburghEH14 4ASUnited Kingdom</p>
<p>A Scientific Information Extraction Dataset for Nature Inspired Engineering
Scientific Information ExtractionRelation ExtractionBiomimeticsTrade-Offs
Nature has inspired various ground-breaking technological developments in applications ranging from robotics to aerospace engineering and the manufacturing of medical devices. However, accessing the information captured in scientific biology texts is a time-consuming and hard task that requires domain-specific knowledge. Improving access for outsiders can help interdisciplinary research like Nature Inspired Engineering. This paper describes a dataset of 1,500 manually-annotated sentences that express domain-independent relations between central concepts in a scientific biology text, such as trade-offs and correlations. The arguments of these relations can be Multi Word Expressions and have been annotated with modifying phrases to form non-projective graphs. The dataset allows for training and evaluating Relation Extraction algorithms that aim for coarse-grained typing of scientific biological documents, enabling a high-level filter for engineers.</p>
<p>Introduction</p>
<p>Discovering relevant scientific literature is a hard and timeconsuming task that often requires domain expertise (Alper et al., 2004;El-Arini and Guestrin, 2011;Pain, 2016). This difficulty can lead to barriers in inter-disciplinary fields of study, where an expert in a target domain is often a novice in the source domain (Carr et al., 2018). A specific example of an inter-disciplinary field of study is Nature Inspired Engineering, also known as biomimetics (Kruiper et al., 2016). A well known example of biomimetics is Velcro R (Mestral, 1955), an 'adhesion' method that is inspired by nature -specifically the burrs of burdock plants.</p>
<p>In biomimetics an engineer is interested in learning from nature to solve a problem at hand (Hoeller et al., 2016). It has been shown that identifying, selecting and understanding relevant biological information is challenging for engineers (Vattam and Goel, 2013a). Information Extraction (IE) systems can partially ease these challenges by capturing the central concepts and relations in a text Gábor et al., 2018). A major issue in inter-disciplinary research is that search terms from a source domain may not retrieve relevant results in a target domain. As an example, in the biological domain the term 'bleaching' can refer to a separation process between the retina and opsin in vertebrate eyes (Grimm et al., 2000). A non-biologist may expect 'bleaching' to refer to cleaning, sterilizing, or whitening (Nagel, 2014). As a result, terminology from the engineering domain does not always provide a good starting point for the identification of relevant biological information (Fayemi et al., 2015;Kruiper et al., 2017). A more appropriate approach that allows for cross-domain search, without relying so much on domain-specific semantics, focuses on TRADE-OFF relations (Vincent, 2016;Kruiper et al., 2018). In biology, trade-offs express how fitness is constrained by functional requirements that are mutually exclusive, e.g., because they share a limited resource (Agrawal et al., 2010). Figure 1 provides an example of a trade-off between 'safety' and 'efficiency'. Trade-offs are important drivers for adapta-  Figure 1: Example of a TRADE-OFF relation between domain-independent abstract concepts, denoted as ARG1 and ARG2, extracted from (Burgess et al., 2006). tion and speciation, and underpin much of the research in various biology sub-domains (Stearns, 1989;Garland, 2014;Ferenci, 2016). TRADE-OFF relations are of interest to biomimetics because they are able to capture the problem space of a full-text biology document in highly abstract terms. Analyzing these trade-offs enables a domainindependent document classification. Crucially, trade-offs can direct an engineer to the mechanisms that biological systems employ to manipulate such problem spaces.</p>
<p>In this work we present the Focused Open Biology Information Extraction (FOBIE) dataset. FOBIE comprises 1500 manually-annotated sentences taken from full-text scientific biology documents. The dataset enables training and evaluation of Relation Extraction (RE) tools that extract trade-offs from scientific biology texts. Each sentence is annotated with a non-projective graph of n-ary relations between trigger words, argument phrases and modifying phrases. The relations are domain-independent and the argument phrases contain concepts that are central to the text. Most of these phrases are not available in standard knowledge bases, so they cannot be learned through distant supervision. This paper provides a comparison of FOBIE with regards to existing datasets for scientific Information Extraction (IE), a description of the collection and annotation processes, and the results of a strong scientific IE baseline. </p>
<p>. Computer-Aided biomimetics</p>
<p>Biomimetics is an engineering problem solving process during which one draws on analogous biological solutions. While biomimetics has led to the development of leapfrog innovations, the process remains adventitious. A major issue is that engineers know little biology or few details of plants or animals. Therefore, engineers have trouble identifying, selecting and understanding relevant biological information (Vattam and Goel, 2011;Vattam and Goel, 2013b). To overcome these challenges various computational tools have been developed, so-called Computer-Aided biomimetics (CAB) tools. Their biggest limitation is that they rely heavily on cross-domain mapping of information such as functional similarities, e.g., (Vandevenne et al., 2012;Vandevenne et al., 2016;Shu and Cheong, 2010;Cheong and Shu, 2014;Rugaber et al., 2016;Zhao et al., 2018). However, automatically identifying crossdomain relational similarities, requires substantial reasoning beyond what is currently computationally feasible. Two caveats are lexical variation and polysemy of concepts across domains . Thirdly, the biological and engineering domains are fundamentally different. Biological systems develop through evolution and natural selection, while engineering is based on conscious decision-making to meet functional requirements (Vincent et al., 2006). Consider again the example of 'bleaching': the purely biological term does not carry a notion of teleology, in contrast to the non-biologist interpretations. The active verbs that are associated to engineering functions are not always used in biological texts (Kaiser et al., 2012;Kaiser et al., 2014). As a result, each function of interest requires a separate classifier (Glier, 2013) or its own set of extraction rules that work for a specific domain of texts (Etzioni, 2007;Christensen et al., 2011). Training data for each function would accordingly require annotation by a domain expert (Luan et al., 2018). Instead, this work aims to extract trade-off relations that are central to many biological texts and capture information at an abstraction level that is domain-independent (Vincent, 2016). These trade-offs, and the abstract concepts captured in their arguments, provide an initial filter for information retrieval and support for within-domain search for biological information (Kruiper et al., 2018).</p>
<p>Scientific Information Extraction</p>
<p>Information Extraction (IE) from scientific text can (1) improve access to scientific information, beyond the possibilities of standard search engines (Gábor et al., 2018;Gupta and Manning, 2011), (2) provide valuable insight into research areas (Tsai et al., 2013;Luan et al., 2018), (3) enable to quickly learn facts on unknown concepts, as extractions can provide a summary view for readers (Mausam, 2016), and (4) augment existing Knowledge Bases (KB) from unlabeled text (Quirk and Poon, 2017). However, annotating scientific text is non-trivial, as it requires domainspecific knowledge from experts. Large-scale crowdsourcing (Tratz, 2019) or human-in-the-loop (He et al., 2016) efforts can be unreliable for such tasks.</p>
<p>To alleviate the manual labeling of FOBIE by a domain expert, we developed a simple Rule-Based System (RBS). Like traditional Relation Extraction (RE) systems this RBS relies on matching specific words to find a TRADE-OFF or similar relation (Sarawagi, 2007). Similar to Open IE (OIE) systems it relies on unlexicalized grammatical structures, e.g., syntactic patterns, to determine the argument phrases . It is expected that this enables flexibility of extracting trade-offs from a variety of domains (Etzioni et al., 2005;Banko et al., 2007). However, the handcrafted or learned syntactic patterns rely on how well input sentences are handled (Léchelle and Langlais, 2018;Niklaus et al., 2018). Sources of issues may include the length and complexity of sentences, the use of pronouns as subjects, the use of abbreviations as adjectives, handling prepositional phrases, and dealing with co-reference (Schneider et al., 2017;Groth et al., 2018). Machine learning approaches can improve recall for the long tail of patterns that will have to be identified (Mausam, 2016).</p>
<p>By manually relabeling the output of our RBS system we rectify errors in argument boundaries and determine the correct relation label. Only few similar datasets exist for scientific IE:</p>
<p>SCIENCEIE Semeval 2017 task 10 introduced the SCI-ENCEIE dataset, consisting of 500 paragraphs taken from full-text scientific documents in the domains of Computer Science, Material Science and Physics journal articles . It contains annotations of keyphrases that are classified as materials, processes or tasks. Furthermore, hyponym-and synonym-relations between the keyphrases are captured.</p>
<p>SEMEVAL 2018</p>
<p>The manually annotated Semeval 2018 task 7 dataset contains 6 relations types that are noted to occur regularly in scientific abstracts; usage, result, model, part-whole, topic and comparison (Gábor et al., 2018). It contains 500 abstracts from the domain of Computational Linguistics and draws on the ACL RD-TEC 2.0 corpus (Qasemizadeh and Schumann, 2016) for entity annotation; technology and method, tool and library, language resource, language resource product, measures and measurements, models and other.  found that the SCIENCEIE dataset contains a significantly higher proportion of long keyphrases in comparison to the ACL RD-TEC 2.0 corpus. This is likely due to the different characteristics of sentences taken from abstracts and those in the main body.</p>
<p>SCIERC The SCIERC dataset consists of 500 abstracts taken from Artificial Intelligence conference and workshop proceedings (Luan et al., 2018). It extends the entity and relation types of the Semeval 2018 task 7 dataset; the relation types are used-for, feature-of, hyponym-of, part-of, compare, conjunction and corefence, and the entity types are task, method, evaluation metric, material, other scientific terms, and generic terms that include anaphora and cataphora that are annotated for corefence resolution.</p>
<p>In this work we introduce the FOBIE dataset that targets sentences taken from full-text scientific publications in the Biology domain. </p>
<p>The FOBIE dataset</p>
<p>We collected a corpus of 10,000 open-access papers from the Journal of Experimental Biology (JEB) and three BioMed Central (BMC) journals: Biology, Systems Biology and Evolutionary Biology. We only retained the abstract, introduction, results, discussion and conclusion section. We used spaCy 1 to split the texts into sentences and tokens, and computed dependency parses 2 .</p>
<p>Rule-Based System</p>
<p>A set of 200 papers was analyzed to determine the types of verbatim expressions that indicate a TRADE-OFF relation (Kruiper et al., 2018). The paper subjects ranged from cell biology to bio-mechanics and trigger words include association, balance, conflict, correlation, compromise, interaction, interplay, optimization, ratio, relationship and tradeoff. We stem these trigger words and scan the sentences of the documents in our corpus for their presence. If a trigger word is found, we traverse the dependency parse tree to identify sub-trees that comprise argument phrases. The output of the RBS system indicates that it has difficulty dealing with negation, and that complex long sentences indeed lead to errors in extractions. Figure 2 shows two sentences that express a trade-off, where each sentence deals differently with phrase attachment and argument boundaries. Variance in argument and modifier arrangement com- plicate the definition of extraction rules that rely on a dependency parse tree. Therefore, an accurate RBS for the extraction of trade-offs from scientific text requires detailed extraction rules and exceptions. Figure 3 shows two examples of partial dependency parses taken from sentences that are near the average length of ±38 tokens. The main source of errors is due to the extraction rules themselves struggling with the large variety of verbatim trade-off expressions (e.g., 'negative correlation', 'balance'), rather than the quality of the dependency parser output. Improving the extraction rules of the simple RBS is expected to be a timeconsuming and complex task. Very often the presence of a trigger word does not automatically lead to the presence of a trade-off. Determining whether the sentence expresses a trade-off requires additional reasoning and often domainspecific knowledge. Considering the large variety of syntactic structures that do indicate a trade-off, as well as the required expertise in biology, a RBS is not suited for our task. Instead, the output of our simple RBS is used to speed up manual annotation.</p>
<p>Dataset annotation</p>
<p>Out of the 10,000 documents, we retain only the sentences that were annotated with a TRADE-OFF relation by the RBS. Using the BRAT 3 interface a biology expert manually corrected argument boundaries and relation types (Stenetorp et al., 2012). During manual annotation we correct the relation label for trigger words, handle negation and identify the boundaries of argument and modifier phrases. We annotate binary relations that constitute non-projective graphs of one or more n-ary relations in a sentence. Each binary relation is a triple <governor, relation, dependent> where:</p>
<p>• governor is either a trigger word or a modifying phrase.</p>
<p>• relation indicates the type of relation -TRADE-OFF, ARGUMENT-MODIFIER or NOT-A-TRADE-OFF.</p>
<p>• dependent is an argument phrase.</p>
<p>Three relation types were used: TRADE-OFF, ARGUMENT-MODIFIER and NOT-A-TRADE-OFF. The latter relation is used to indicate that a trigger word does not express a tradeoff. We retain these annotations because their expressions are syntactically similar and, therefore, can provide useful  training signal as negative samples. Furthermore, the trigger words to express these NOT-A-TRADEOFF relations may be contiguous with the trigger words that do express a TRADE-OFF. An example is a sentence that expresses a correlation, which often denotes a positive correlation between two arguments while a TRADE-OFF entails a negative correlation. Many argument phrases are found to be nested and can be broken down into an argument and a modifier, e.g., 'ontogenetic trajectories' modifies 'tolerance' and 'resistance' in Figure 2. We do not indicate specific types of modification, such as temporal expressions or phrases that indicate a location, used in Semantic Role Labeling (SRL). The reason is that trigger words can be either nouns or verbs, e.g., 'balance/NOUN' and 'trade-off /VERB' in Figure 3, hence the classes of modifier labels found in common SRL frameworks such as Propbank (Palmer et al., 2005) are not always appropriate. Instead, as a general rule we include the words that indicate the type of modifier during annotation of modifying phrases.</p>
<p>We adopt the heuristic that prepositional phrases (PPs) heading a coordinating clause, are treated as modifying phrases when they apply to word-level arguments of a trade-off, as in the top example in Figure 2. In the case of coordination of PPs that contain arguments of a trade-off, we consider each PP as a whole argument, as in the bottom example in Figure 2. Similarly, when nested phrases in an argument can be distinctly separated by punctuation, such phrases are treated as an argument-modifier pair. We do not annotate phrases that modify the relation directly, e.g., 'throughout plant development' modifies 'correlation' in the top of Figure 2. Regarding the direction of relations, the trigger words and modifying phrases are treated as governors of a relation.</p>
<p>Nevertheless, determining exact rules for the boundaries of arguments was found to be challenging. As an example, consider the second TRADE-OFF relation in Figure 3. In this sentence, 'immune activity' is a 'life-history function' that trades off with 'growth' and 'reproduction', two other examples of 'vital life-history functions'. Specifically, 'energetic and nutritional costs' need to be shared between these 'life-history functions'. The first argument 'immune activity [...] costs' is treated as a single phrase following the heuristics above. This verb phrase could also be split up, leaving the informative phrase 'entails energetic and nutritional costs' outside of the annotation scope. In such am-   biguous cases, we opted for always annotating the longest possible phrase spans, in order to capture more comprehensively the information in the sentence.</p>
<p>A random sample of 250 sentences (16.1%), which were annotated by using the RBS, was re-annotated by a second domain-expert. The inter-annotator agreement Cohen k for both relations and span boundaries was found to be 92.93.  </p>
<p>Dataset description</p>
<p>Baseline Evaluation</p>
<p>We train a state-of-the-art scientific RE system on FOBIE called SCIIE (Luan et al., 2018). The SCIIE model is developed for the SCIERC dataset to jointly extract the entities, relations and coreference annotations (Luan et al., 2018). Furthermore, the model achieves state-of-the-art performance on the SCIENCEIE dataset, which includes the tasks of span identification and keyphrase extraction. For FOBIE we only train SCIIE on entities and relations, where the entities are our annotated keyphrases; trigger spans and argument spans.</p>
<p>SCIIE is a span-based IE model that takes as input an unlabeled sentence, e.g., no POS-tags or dependency labels have to be provided. All sequences of consecutive words in the sentence -up to a given length -are considered as a candidate span, while only a few represent the gold annotated keyphrases. Each token is represented as the concatenation of its word, character and ELMo embedding (Peters et al., 2018). Each candidate span is represented as a concatenation of the bi-LSTM outputs for the first token in the span and the last token in the span, as well as an attention mechanism over the span that is thought to represent the syntactic head of span (Lee et al., 2017). Span classification determines whether a span is actually a span, where a dummy non-span class is assigned to incorrect candidate spans. Pairs of candidate spans are fed to the relation classifier, where a dummy non-relation class is introduced. This multi-task setup enables weight sharing that improves performance on both tasks. See (Luan et al., 2018) for more details on SCIIE. We compare RBS and SCIIE on detecting the correct boundaries of trigger words and argument phrases, see Table 3. As expected the neural approach outperforms the simple RBS by a large margin. We also evaluate how well SCIIE performs on FOBIE with regards to extracting relations. The Relation Extraction (RE) setting is evaluated as a joint task -the presence of spans has to be predicted correctly, as well as the relation types that may hold between them. We do not change the default hyper parameters, apart from setting the maximum span length to 14 tokens. This is required to deal with the longer keyphrases in FOBIE. Table 4 provides RE results per relation type. The model performs better on the test set with regards to extracting TRADE-OFF relations.</p>
<p>Due to the relatively large amount of NOT-A-TRADE-OFF (54.05%) and ARGUMENT-MODIFIER (29.73%) relations this difference becomes negligible in the overall RE setting, also see Table 2. The model performs notably worse on ARGUMENT-</p>
<p>Conclusions</p>
<p>We presented FOBIE, the first scientific IE dataset that focuses on the domain of biomimetics. FOBIE supports the extraction of TRADE-OFFS and syntactically similar relations from scientific biological texts. These relations enable cross-domain discovery of relevant scientific literature during biomimetics. However, the manners in which tradeoff are expressed, and their arguments modified, varies a lot. This large syntactic variation and the long sentences in scientific text decrease the accuracy of extraction rules. Therefore, Rule-Based Systems (RBS) may not be able to deal with the long tail of patterns. The alternative machine learning approach requires time-consuming manual annotation of datasets. Combining the two approaches, a simple RBS can speed up the annotation of a small dataset by a domain expert considerably. The use of pretrained embeddings provides reliable flexibility with regards to syntactic variance. The manual annotation of FOBIE instances enables the training of neural Relation Extraction systems. The size of FOBIE is comparable to existing dataset for scientific Information Extraction. Unlike existing datasets the keyphrases in FOBIE are not classified into entity types. We make FOBIE and the annotation guidelines publicly available at https://github.com/ rubenkruiper/FOBIE.</p>
<p>Figure 3 :
3Dependency parses of two sentences that are near the average length of 37.81 tokens. The TRADE-OFF indicators and arguments have been underlined as inFigure 2, as well as the single argument modifier "such as [...]". Defining extraction rules that can traverse a large variety of dependency trees correctly is a time-consuming and hard task that requires expertise in both the linguistics and biology domains.</p>
<p>Broad patterns of increasing 'safety' and decreasing 'e ciency' of xylem with increasing aridity are evident, and there is some evidence demonstrating safety-e ciency trade-o s within conifer species or individuals.Explicit Trade-O </p>
<p>ARG1 
ARG2 
INDICATOR </p>
<p>Table 1 provides an overview of the sizes RBS ARGUMENTS CORRECT ARG1: ontogenetic trajectories in tolerance ARG2: ontogenetic trajectories in resistance This [...] negative genetic correlation between ontogenetic trajectories in tolerance and resistance throughout plant development [...]. These [...] trade-o between avoidance of anti-parasitic immune responses and maintenance of the host's antimicrobial defences. Similar to SCIENCEIE the focus lies on extracting keyphrases, rather than entities. Different from the previously described datasets, the relation arguments are not classified into a type, also see section 3.2. FOBIE enables the training of IE systems that extract both a narrow set of relations between argument phrases and an unbounded set of modifying relations.INDICATOR 
ARG1 
ARGMOD 
ARG2 </p>
<p>RBS ARGUMENTS WRONG </p>
<p>ARG1: avoidance of parasitic immune responses 
ARG2: avoidance of maintenance </p>
<p>INDICATOR 
ARG1 
ARG2 </p>
<p>Figure 2: Two examples of sentences that express a trade-off. The indicator denotes the trigger word that connects two 
trade-off arguments -ARG1 and ARG2. ARGMOD denotes a modifying phrase. </p>
<h1></h1>
<p>FOBIE SCIERC SCIENCEIE SE '18 
Arguments 
5835 
8089 
9946 
7483 
Relations 
4788 
4716 
672 
1595 
Rel/doc 
3.1* 
9.4 
1.3 
3.2 </p>
<p>Table 1: Amount of arguments, relations and relations per 
instance for FOBIE, SCIERC, SCIENCEIE and SemEval 
2018 task 7. Rel/doc stands for relations per sentence* for 
FOBIE (per abstract or paragraph for the other datasets). </p>
<p>of FOBIE, SCIERC, SCIENCEIE and the Semeval 2018 
dataset. </p>
<p>Table 2 :
2The aggregated statistics for FOBIE.Relations 
Boundaries 
P 
R 
F1 
P 
R 
F1 </p>
<p>RBS 
dev 
-
-
-
45.17 35.84 39.97 
test 
-
-
-
44.31 35.32 39.31 </p>
<p>SCIIE 
dev 69.60 69.60 69.60 84.50 80.40 82.40 
test 68.28 69.82 69.04 84.26 79.67 81.90 </p>
<p>Table 3 :
3Overview of results on the development (dev) and test set of FOBIE for the RBS and SCIIE. The relations columns refers to the Relation Extraction (RE) setting. The RBS does not classify relations and is, therefore, not evaluated on this task. Boundaries refers to determining the correct boundaries of arguments and trigger words.</p>
<p>Table 2
276.92 74.07 75.47 75.45 81.01 78.13 53.60 47.18 50.19 test 89.71 84.72 87.14 72.08 72.08 72.08 52.05 57.58 54.68provides an overview of the statistics on FOBIE. 
The percentage of singleton keyphrases in FOBIE is only 
20.4%, a considerable difference with regard to SCIEN-
CEIE (31%) and ACL RD-TEC 2.0 (83%) (Augenstein 
and Søgaard, 2017). The number of single token entities in 
SCIERC is (31%), with an average token length of 2.36 in 
comparison to 3.46 in FOBIE. The reason is that arguments 
of trade-offs are often phrases or Multi-Word Expressions 
(MWE), such as 'immune response'. 
In FOBIE only 17.4% of the sentences is shorter than 25 
tokens, while in SCIERC the average sentence length is 
24.31 tokens. The much longer sentences in FOBIE is in-
fluenced by the presence of citations, but in general the sen-
tences in full-text documents are longer. The final dataset 
comprises 1548 single sentences taken from 1292 unique 
documents and is randomly split into 1248 training, 150 
development and 150 test instances. There is no source </p>
<p>Table 4 :
4Overview of SCIIE results for each of the relations in FOBIE. Note that the amount of gold relations for the development (dev) and test sets are not equal. document overlap between the training, development and test set.
https://brat.nlplab.org/
AcknowledgmentsThe authors would like to thank the reviewers for their useful comments, and gratefully acknowledge the financial support of the Engineering and Physical Sciences Research Council (EPSRC) Centre for Doctoral Training in Embedded Intelligence under grant reference EP/L014998/1 and the EPSRC Innovation Placement fund.
. A A Agrawal, J K Conner, S Rasmann, Agrawal, A. A., Conner, J. K., and Rasmann, S. (2010).</p>
<p>Tradeoff s and Negative Correlations in Evolutionary Ecology Why Are We Interested in Tradeoffs?. Evolution since Darwin: the first 150 years. Tradeoff s and Negative Correlations in Evolutionary Ecology Why Are We Interested in Tradeoffs? In Evolu- tion since Darwin: the first 150 years, chapter 10, pages 243-268.</p>
<p>How much effort is needed to keep up with the literature relevant for primary care. B S Alper, J A Hand, S G Elliott, S Kinkade, M J Hauan, D K Onion, B M Sklar, Journal of the Medical Library Association : JMLA. 924Alper, B. S., Hand, J. A., Elliott, S. G., Kinkade, S., Hauan, M. J., Onion, D. K., and Sklar, B. M. (2004). How much effort is needed to keep up with the literature relevant for primary care? Journal of the Medical Library Associa- tion : JMLA, 92(4):429-37, 10.</p>
<p>Multi-Task Learning of Keyphrase Boundary Classification. I Augenstein, A Søgaard, Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics. the 55th Annual Meeting of the Association for Computational LinguisticsStroudsburg, PA, USAAssociation for Computational Linguistics2Augenstein, I. and Søgaard, A. (2017). Multi-Task Learn- ing of Keyphrase Boundary Classification. In Proceed- ings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 341-346, Stroudsburg, PA, USA. Association for Computational Linguistics.</p>
<p>Scien-ceIE -Extracting Keyphrases and Relations from Scientific Publications. I Augenstein, M Das, S Riedel, L Vikraman, A Mccallum, Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017). the 11th International Workshop on Semantic Evaluation (SemEval-2017)Stroudsburg, PA, USA10Association for Computational LinguisticsAugenstein, I., Das, M., Riedel, S., Vikraman, L., and McCallum, A. (2017). SemEval 2017 Task 10: Scien- ceIE -Extracting Keyphrases and Relations from Sci- entific Publications. In Proceedings of the 11th Inter- national Workshop on Semantic Evaluation (SemEval- 2017), pages 546-555, Stroudsburg, PA, USA. Associ- ation for Computational Linguistics.</p>
<p>Open information extraction from the web. M Banko, M Cafarella, S Soderland, M J Broadhead, O Etzioni, Proceedings of the 20th International Joint Conference on Artificial Intelligence. the 20th International Joint Conference on Artificial IntelligenceBanko, M., Cafarella, M., Soderland, S., Broadhead, M. J., and Etzioni, O. (2007). Open information extraction from the web. Proceedings of the 20th International Joint Conference on Artificial Intelligence, pages 2670- 2676.</p>
<p>Hydraulic efficiency and safety of branch xylem increases with height in Sequoia sempervirens (D. Don) crowns. S S O Burgess, J Pittermann, T E Dawson, Plant, Cell and Environment. 292Burgess, S. S. O., Pittermann, J., and Dawson, T. E. (2006). Hydraulic efficiency and safety of branch xylem in- creases with height in Sequoia sempervirens (D. Don) crowns. Plant, Cell and Environment, 29(2):229-239, 2.</p>
<p>Gaining insight into interdisciplinary research and education programmes: A framework for evaluation. G Carr, D P Loucks, G Blöschl, Research Policy. 471Carr, G., Loucks, D. P., and Blöschl, G. (2018). Gaining insight into interdisciplinary research and education pro- grammes: A framework for evaluation. Research Policy, 47(1):35-48, 2.</p>
<p>Retrieving Causally Related Functions From Natural-Language Text for Biomimetic Design. H Cheong, L Shu, Journal of Mechanical Design. 136881008Cheong, H. and Shu, L. (2014). Retrieving Causally Related Functions From Natural-Language Text for Biomimetic Design. Journal of Mechanical Design, 136(8):081008.</p>
<p>An analysis of open information extraction based on semantic role labeling. J Christensen, Mausam, S Soderland, O Etzioni, Proceedings of the sixth international conference on Knowledge. the sixth international conference on Knowledge113Christensen, J., Mausam, Soderland, S., and Etzioni, O. (2011). An analysis of open information extraction based on semantic role labeling. In Proceedings of the sixth international conference on Knowledge capture - K-CAP '11, page 113.</p>
<p>Beyond keyword search. K El-Arini, C Guestrin, Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining -KDD '11. the 17th ACM SIGKDD international conference on Knowledge discovery and data mining -KDD '11New York, New York, USAACM Press439El-Arini, K. and Guestrin, C. (2011). Beyond keyword search. In Proceedings of the 17th ACM SIGKDD inter- national conference on Knowledge discovery and data mining -KDD '11, page 439, New York, New York, USA. ACM Press.</p>
<p>Unsupervised named-entity extraction from the Web: An experimental study. O Etzioni, M Cafarella, D Downey, A M Popescu, T Shaked, S Soderland, D S Weld, A Yates, Artificial Intelligence. 1651Etzioni, O., Cafarella, M., Downey, D., Popescu, A. M., Shaked, T., Soderland, S., Weld, D. S., and Yates, A. (2005). Unsupervised named-entity extraction from the Web: An experimental study. Artificial Intelligence, 165(1):91-134, 6.</p>
<p>Open information extraction: The second generation. O Etzioni, A Fader, J Christensen, S Soderland, Mausam , IJCAI International Joint Conference on Artificial Intelligence. 11Etzioni, O., Fader, A., Christensen, J., Soderland, S., and Mausam. (2011). Open information extraction: The sec- ond generation. In IJCAI International Joint Conference on Artificial Intelligence, volume 11, pages 3-10.</p>
<p>Machine reading of web text. O Etzioni, Proceedings of the 4th international conference on Knowledge capture -K-CAP '07. the 4th international conference on Knowledge capture -K-CAP '07New York, New York, USAACM PressEtzioni, O. (2007). Machine reading of web text. In Pro- ceedings of the 4th international conference on Knowl- edge capture -K-CAP '07, pages 1-4, New York, New York, USA. ACM Press.</p>
<p>Modeling Biological Systems to facilitate their Selection during a Bio-Inspired Design Process. P.-E Fayemi, N Maranzana, A Aoussat, T Chekchak, G Bersano, 15Milan, ItalyFayemi, P.-E., Maranzana, N., Aoussat, A., Chekchak, T., and Bersano, G. (2015). Modeling Biological Systems to facilitate their Selection during a Bio-Inspired Design Process. In ICED15, pages 225-234, Milan, Italy.</p>
<p>Trade-off Mechanisms Shaping the Diversity of Bacteria. T Ferenci, Trends in Microbiology. 243Ferenci, T. (2016). Trade-off Mechanisms Shaping the Di- versity of Bacteria. Trends in Microbiology, 24(3):209- 223, 3.</p>
<p>SemEval-2018 Task 7: Semantic Relation Extraction and Classification in Scientific Papers. K Gábor, D Buscaldi, A.-K Schumann, B Qasemizadeh, H Zargayouna, T Charnois, SemEval. Gábor, K., Buscaldi, D., Schumann, A.-K., Qasemizadeh, B., Zargayouna, H., and Charnois, T. (2018). SemEval- 2018 Task 7: Semantic Relation Extraction and Classifi- cation in Scientific Papers. In SemEval, pages 679-688.</p>
<p>Trade-offs. T Garland, Current Biology. 242Garland, T. (2014). Trade-offs. Current Biology, 24(2):R60-R61.</p>
<p>Machine Learning based classification of textual stimuli to promote ideation in BioInspired Design. M W Glier, Texas A&amp;M UniversityPh.D. thesisGlier, M. W. (2013). Machine Learning based classifica- tion of textual stimuli to promote ideation in BioInspired Design. Ph.D. thesis, Texas A&amp;M University.</p>
<p>Blue light's effects on rhodopsin: Photoreversal of bleaching in living rat eyes. C Grimm, C E Reme, P O Rol, T P Williams, Investigative Ophthalmology and Visual Science. 4112Grimm, C., Reme, C. E., Rol, P. O., and Williams, T. P. (2000). Blue light's effects on rhodopsin: Photoreversal of bleaching in living rat eyes. Investigative Ophthalmol- ogy and Visual Science, 41(12):3984-3990, 11.</p>
<p>Open Information Extraction on Scientific Text: An Evaluation. P Groth, M Lauruhn, A Scerri, R Daniel, Proceedings of the 27th International Conference on Computational Linguistics. the 27th International Conference on Computational LinguisticsAssociation for Computational Linguistics2Groth, P., Lauruhn, M., Scerri, A., and Daniel, R. (2018). Open Information Extraction on Scientific Text: An Evaluation. In Proceedings of the 27th Interna- tional Conference on Computational Linguistics, page 3414-3423. Association for Computational Linguistics, 2.</p>
<p>Analyzing the Dynamics of Research by Extracting Key Aspects of Scientific Papers. S Gupta, C D Manning, Proceedings of 5th international joint conference on natural language processing. 5th international joint conference on natural language processingGupta, S. and Manning, C. D. (2011). Analyzing the Dy- namics of Research by Extracting Key Aspects of Sci- entific Papers. In Proceedings of 5th international joint conference on natural language processing, pages 1-9.</p>
<p>Human-in-the-Loop Parsing. L He, J Michael, M Lewis, L Zettlemoyer, Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing. the 2016 Conference on Empirical Methods in Natural Language ProcessingStroudsburg, PA, USAAssociation for Computational LinguisticsHe, L., Michael, J., Lewis, M., and Zettlemoyer, L. (2016). Human-in-the-Loop Parsing. In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 2337-2342, Stroudsburg, PA, USA. Association for Computational Linguistics.</p>
<p>A Systems View of Bio-Inspiration: Bridging the Gaps. N Hoeller, M Farnsworth, S Jacobs, J Chirazi, T Mead, A Goel, F Salustri, INSIGHT. 191Hoeller, N., Farnsworth, M., Jacobs, S., Chirazi, J., Mead, T., Goel, A., and Salustri, F. (2016). A Systems View of Bio-Inspiration: Bridging the Gaps. INSIGHT, 19(1):36-40.</p>
<p>An approach to support searching for biomimetic solutions based on system characteristics and its environmental interactions. M K Kaiser, H Hashemi Farzaneh, U Lindemann, Proceedings of International Design Conference. International Design Conference70DSKaiser, M. K., Hashemi Farzaneh, H., and Lindemann, U. (2012). An approach to support searching for biomimetic solutions based on system characteristics and its environmental interactions. Proceedings of Interna- tional Design Conference, DESIGN, DS 70:969-978.</p>
<p>Bioscrabble -The role of different types of search terms when searching for biological inspiration in biological research articles. M K Kaiser, H Hashemi Farzaneh, U Lindemann, Proceedings of International Design Conference, DESIGN, volume 2014-Janua. International Design Conference, DESIGN, volume 2014-JanuaDubrovnik, CroatiaKaiser, M. K., Hashemi Farzaneh, H., and Lindemann, U. (2014). Bioscrabble -The role of different types of search terms when searching for biological inspira- tion in biological research articles. In Proceedings of In- ternational Design Conference, DESIGN, volume 2014- Janua, pages 241-250, Dubrovnik, Croatia.</p>
<p>Computer-aided biomimetics. R Kruiper, J Chen-Burger, M P Y Desmulliez, Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics). 9793Kruiper, R., Chen-Burger, J., and Desmulliez, M. P. Y. (2016). Computer-aided biomimetics. In Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinfor- matics), volume 9793, pages 131-143.</p>
<p>Towards Identifying Biological Research Articles in Computer-Aided Biomimetics. R Kruiper, J F V Vincent, J Chen-Burger, M P Y Desmulliez, Living Machines. Kruiper, R., Vincent, J. F. V., Chen-Burger, J., and Desmul- liez, M. P. Y. (2017). Towards Identifying Biological Research Articles in Computer-Aided Biomimetics. In Living Machines 2017., pages 242-254.</p>
<p>R Kruiper, J Vincent, E Abraham, R Soar, I Konstas, J Chen-Burger, M Desmulliez, Towards a Design Process for Computer-Aided Biomimetics. 36Kruiper, R., Vincent, J., Abraham, E., Soar, R., Konstas, I., Chen-Burger, J., and Desmulliez, M. (2018). To- wards a Design Process for Computer-Aided Biomimet- ics. Biomimetics, 3(3):14, 6.</p>
<p>Revisiting the Task of Scoring Open IE Relations. W Léchelle, P Langlais, LREC 2018 -11th International Conference on Language Resources and Evaluation. Léchelle, W. and Langlais, P. (2018). Revisiting the Task of Scoring Open IE Relations. In LREC 2018 -11th International Conference on Language Resources and Evaluation, pages 2052-2058.</p>
<p>End-to-end Neural Coreference Resolution. K Lee, L He, M Lewis, L Zettlemoyer, Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. the 2017 Conference on Empirical Methods in Natural Language ProcessingStroudsburg, PA, USA, 7Association for Computational LinguisticsLee, K., He, L., Lewis, M., and Zettlemoyer, L. (2017). End-to-end Neural Coreference Resolution. In Proceed- ings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 188-197, Strouds- burg, PA, USA, 7. Association for Computational Lin- guistics.</p>
<p>Multi-Task Identification of Entities, Relations, and Coreference for Scientific Knowledge Graph Construction. Y Luan, L He, M Ostendorf, H Hajishirzi, Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing. the 2018 Conference on Empirical Methods in Natural Language ProcessingStroudsburg, PA, USA, 8Association for Computational LinguisticsLuan, Y., He, L., Ostendorf, M., and Hajishirzi, H. (2018). Multi-Task Identification of Entities, Relations, and Coreference for Scientific Knowledge Graph Con- struction. In Proceedings of the 2018 Conference on Em- pirical Methods in Natural Language Processing, pages 3219-3232, Stroudsburg, PA, USA, 8. Association for Computational Linguistics.</p>
<p>Open Information Extraction Systems and Downstream Applications. Mausam, Proceedings of the 25th International Joint Conference on Artificial Intelligence. the 25th International Joint Conference on Artificial IntelligenceMausam. (2016). Open Information Extraction Systems and Downstream Applications. In Proceedings of the 25th International Joint Conference on Artificial Intel- ligence, pages 4074-4077.</p>
<p>Velvet type fabric and method of producing same. G D Mestral, US Patent Number. 2Mestral, G. D. (1955). Velvet type fabric and method of producing same. US Patent Number 2,717,437, pages 1- 3.</p>
<p>A Thesaurus for Bioinspired Engineering Design. J K Nagel, Biologically Inspired Design: Computational Methods and Tools. London; LondonSpringerNagel, J. K. (2014). A Thesaurus for Bioinspired Engi- neering Design. In Biologically Inspired Design: Com- putational Methods and Tools, number January 2014, pages 245-267. Springer London, London.</p>
<p>A Survey on Open Information Extraction. C Niklaus, M Cetto, A Freitas, S Handschuh, Proceedings of the 27th International Conference on Computational Linguistics. the 27th International Conference on Computational LinguisticsAssociation for Computational LinguisticsNiklaus, C., Cetto, M., Freitas, A., and Handschuh, S. (2018). A Survey on Open Information Extraction. In Proceedings of the 27th International Conference on Computational Linguistics, pages 3866-3878. Associa- tion for Computational Linguistics.</p>
<p>How to keep up with the scientific literature. E Pain, Science. 11Pain, E. (2016). How to keep up with the scientific litera- ture. Science, 11.</p>
<p>The proposition bank: An annotated corpus of semantic roles. M Palmer, P Kingsbury, D Gildea, Computational Linguistics. 311Palmer, M., Kingsbury, P., and Gildea, D. (2005). The proposition bank: An annotated corpus of semantic roles. Computational Linguistics, 31(1):71-105.</p>
<p>Deep Contextualized Word Representations. M Peters, M Neumann, M Iyyer, M Gardner, C Clark, K Lee, L Zettlemoyer, Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesStroudsburg, PA, USA, 7Association for Computational Linguistics1Peters, M., Neumann, M., Iyyer, M., Gardner, M., Clark, C., Lee, K., and Zettlemoyer, L. (2018). Deep Contextu- alized Word Representations. In Proceedings of the 2018 Conference of the North American Chapter of the Associ- ation for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), volume 19, pages 2227-2237, Stroudsburg, PA, USA, 7. Association for Computational Linguistics.</p>
<p>The ACL RD-TEC 2.0: A language resource for evaluating term extraction and entity recognition methods. B Qasemizadeh, A K Schumann, Proceedings of the 10th International Conference on Language Resources and Evaluation, LREC 2016. the 10th International Conference on Language Resources and Evaluation, LREC 2016Qasemizadeh, B. and Schumann, A. K. (2016). The ACL RD-TEC 2.0: A language resource for evaluating term extraction and entity recognition methods. In Proceed- ings of the 10th International Conference on Language Resources and Evaluation, LREC 2016, pages 1862- 1868.</p>
<p>Distant Supervision for Relation Extraction beyond the Sentence Boundary. C Quirk, H Poon, Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics. the 15th Conference of the European Chapter of the Association for Computational LinguisticsStroudsburg, PA, USA1Association for Computational LinguisticsQuirk, C. and Poon, H. (2017). Distant Supervision for Relation Extraction beyond the Sentence Boundary. In Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguis- tics: Volume 1, Long Papers, volume 1, pages 1171- 1182, Stroudsburg, PA, USA. Association for Compu- tational Linguistics.</p>
<p>Knowledge Extraction and Annotation for Cross-Domain Textual Case-Based Reasoning in Biologically Inspired Design. S Rugaber, S Bhati, V Goswami, E Spiliopoulou, S Azad, S Koushik, R Kulkarni, M Kumble, S Sarathy, A Goel, International Conference on Case-Based Reasoning, number November. SpringerRugaber, S., Bhati, S., Goswami, V., Spiliopoulou, E., Azad, S., Koushik, S., Kulkarni, R., Kumble, M., Sarathy, S., and Goel, A. (2016). Knowledge Extraction and Annotation for Cross-Domain Textual Case-Based Reasoning in Biologically Inspired Design. In Interna- tional Conference on Case-Based Reasoning, number November, pages 342-355. Springer.</p>
<p>Information Extraction. S Sarawagi, Foundations and Trends R in Databases. 13Sarawagi, S. (2007). Information Extraction. Foundations and Trends R in Databases, 1(3):261-377.</p>
<p>Analysing Errors of Open Information Extraction Systems. R Schneider, T Oberhauser, T Klatt, F A Gers, A Löser, Proceedings of the First Workshop on Building Linguistically Generalizable NLP Systems. the First Workshop on Building Linguistically Generalizable NLP Systems7Schneider, R., Oberhauser, T., Klatt, T., Gers, F. A., and Löser, A. (2017). Analysing Errors of Open Information Extraction Systems. In Proceedings of the First Work- shop on Building Linguistically Generalizable NLP Sys- tems, pages 11-18, 7.</p>
<p>A natural-language approach to biomimetic design. L H Shu, H Cheong, Artificial Intelligence for Engineering Design. 244Analysis and Manufacturing: AIEDAMShu, L. H. and Cheong, H. (2010). A natural-language approach to biomimetic design. Artificial Intelligence for Engineering Design, Analysis and Manufacturing: AIEDAM, 24(4):507-519.</p>
<p>Trade-Offs in Life-History Evolution. S C Stearns, Functional Ecology. 33Stearns, S. C. (1989). Trade-Offs in Life-History Evolu- tion. Functional Ecology, 3(3):259-268.</p>
<p>BRAT: a Web-based Tool for NLP-Assisted Text Annotation. P Stenetorp, S Pyysalo, G Topic, T Ohta, S Ananiadou, J Tsujii, 13th Conference of the European Chapter of the ACL, number Figure 1. Stenetorp, P., Pyysalo, S., Topic, G., Ohta, T., Ananiadou, S., and Tsujii, J. (2012). BRAT: a Web-based Tool for NLP-Assisted Text Annotation. In 13th Conference of the European Chapter of the ACL, number Figure 1, pages 102-107.</p>
<p>Dependency Tree Annotation with Mechanical Turk. S Tratz, Proceedings of the First Workshop on Aggregating and Analysing Crowdsourced Annotations for NLP. the First Workshop on Aggregating and Analysing Crowdsourced Annotations for NLPTratz, S. (2019). Dependency Tree Annotation with Me- chanical Turk. Proceedings of the First Workshop on Ag- gregating and Analysing Crowdsourced Annotations for NLP, pages 1-5.</p>
<p>Conceptbased analysis of scientific literature. C.-T Tsai, G Kundu, Roth , D , Proceedings of the 22nd ACM international conference on Conference on information &amp; knowledge management -CIKM '13. the 22nd ACM international conference on Conference on information &amp; knowledge management -CIKM '13New York, New York, USAACM PressTsai, C.-T., Kundu, G., and Roth, D. (2013). Concept- based analysis of scientific literature. In Proceedings of the 22nd ACM international conference on Conference on information &amp; knowledge management -CIKM '13, pages 1733-1738, New York, New York, USA. ACM Press.</p>
<p>Automated classification into the biomimicry taxonomy. D Vandevenne, P.-A Verhaegen, S Dewulf, J R Duflou, Proceedings of International Design Conference, DESIGN, volume DS 70. International Design Conference, DESIGN, volume DS 70Vandevenne, D., Verhaegen, P.-A., Dewulf, S., and Du- flou, J. R. (2012). Automated classification into the biomimicry taxonomy. In Proceedings of International Design Conference, DESIGN, volume DS 70, pages 1161-1166.</p>
<p>Enhancing novelty with knowledge-based support for Biologically-Inspired Design. D Vandevenne, T Pieters, J R Duflou, Design Studies. Vandevenne, D., Pieters, T., and Duflou, J. R. (2016). Enhancing novelty with knowledge-based support for Biologically-Inspired Design. In Design Studies.</p>
<p>Foraging for Inspiration: Understanding and Supporting the Online Information Seeking Practices of Biologically Inspired Designers. S Vattam, A Goel, Proceedings of the ASME 2011 International Design Engineering Technical Conferences &amp; Computers and Information in Engineering Conference IDETC/CIE 2011. the ASME 2011 International Design Engineering Technical Conferences &amp; Computers and Information in Engineering Conference IDETC/CIE 2011Vattam, S. and Goel, A. (2011). Foraging for Inspira- tion: Understanding and Supporting the Online Informa- tion Seeking Practices of Biologically Inspired Design- ers. Proceedings of the ASME 2011 International De- sign Engineering Technical Conferences &amp; Computers and Information in Engineering Conference IDETC/CIE 2011, pages 177-186.</p>
<p>An Information Foraging Model of Interactive Analogical Retrieval. S Vattam, A Goel, Proceedings of the Annual Meeting of the Cognitive Science Society. the Annual Meeting of the Cognitive Science SocietyVattam, S. and Goel, A. (2013a). An Information Forag- ing Model of Interactive Analogical Retrieval. In Pro- ceedings of the Annual Meeting of the Cognitive Science Society, pages 3651-3656.</p>
<p>Biological Solutions for Engineering Problems: A Study in Cross-Domain Textual Case-Based Reasoning. S S Vattam, A K Goel, International Conference on Case Based Reasoning. 7969Vattam, S. S. and Goel, A. K. (2013b). Biological So- lutions for Engineering Problems: A Study in Cross- Domain Textual Case-Based Reasoning. In Interna- tional Conference on Case Based Reasoning, volume 7969 LNAI, pages 343-357.</p>
<p>Biomimetics: its practice and theory. J F V Vincent, O A Bogatyreva, N R Bogatyrev, A Bowyer, A.-K Pahl, Journal of the Royal Society. 3Vincent, J. F. V., Bogatyreva, O. A., Bogatyrev, N. R., Bowyer, A., and Pahl, A.-K. (2006). Biomimetics: its practice and theory. Journal of the Royal Society, 3(April):471-482.</p>
<p>The trade-off: a central concept for biomimetics. J F V Vincent, Bioinspired, Biomimetic and Nanobiomaterials. 62Vincent, J. F. V. (2016). The trade-off: a central concept for biomimetics. Bioinspired, Biomimetic and Nanobio- materials, 6(2):67-76, 6.</p>
<p>Data Driven Techniques for Organizing Scientific Articles Relevant to Biomimicry. Y Zhao, I Baldini, P Sattigeri, I Padhi, Y K Lee, E Smith, Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society -AIES '18. the 2018 AAAI/ACM Conference on AI, Ethics, and Society -AIES '18New York, New York, USAACM PressZhao, Y., Baldini, I., Sattigeri, P., Padhi, I., Lee, Y. K., and Smith, E. (2018). Data Driven Techniques for Or- ganizing Scientific Articles Relevant to Biomimicry. In Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society -AIES '18, pages 347-353, New York, New York, USA. ACM Press.</p>            </div>
        </div>

    </div>
</body>
</html>