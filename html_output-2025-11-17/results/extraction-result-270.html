<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-270 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-270</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-270</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-14.html">extraction-schema-14</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic operations, including the types of arithmetic tasks, model properties, performance results, methods used, and any mechanistic insights about how the models solve arithmetic problems.</div>
                <p><strong>Paper ID:</strong> paper-259095472</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2306.04347v2.pdf" target="_blank">World Models for Math Story Problems</a></p>
                <p><strong>Paper Abstract:</strong> Solving math story problems is a complex task for students and NLP models alike, requiring them to understand the world as described in the story and reason over it to compute an answer. Recent years have seen impressive performance on automatically solving these problems with large pre-trained language models and innovative techniques to prompt them. However, it remains unclear if these models possess accurate representations of mathematical concepts. This leads to lack of interpretability and trustworthiness which impedes their usefulness in various applications. In this paper, we consolidate previous work on categorizing and representing math story problems and develop MathWorld, which is a graph-based semantic formalism specific for the domain of math story problems. With MathWorld, we can assign world models to math story problems which represent the situations and actions introduced in the text and their mathematical relationships. We combine math story problems from several existing datasets and annotate a corpus of 1,019 problems and 3,204 logical forms with MathWorld. Using this data, we demonstrate the following use cases of MathWorld: (1) prompting language models with synthetically generated question-answer pairs to probe their reasoning and world modeling abilities, and (2) generating new problems by using the world models as a design space.</p>
                <p><strong>Cost:</strong> 0.019</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e270.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e270.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic operations, including the types of arithmetic tasks, model properties, performance results, methods used, and any mechanistic insights about how the models solve arithmetic problems.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-3</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Generative Pre-trained Transformer 3</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A large pre-trained decoder-only transformer used in this work to probe arithmetic reasoning on math story problems via in-context prompting and synthetic intermediate question-answer pairs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Language Models are Few-Shot Learners</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>175B</td>
                        </tr>
                        <tr>
                            <td><strong>model_architecture</strong></td>
                            <td>decoder-only transformer</td>
                        </tr>
                        <tr>
                            <td><strong>arithmetic_operation_type</strong></td>
                            <td>addition, subtraction, multiplication, division, multi-step arithmetic arising in math story problems (TRANSFER, RATE, COMPARISON, PARTWHOLE concepts)</td>
                        </tr>
                        <tr>
                            <td><strong>number_range_or_complexity</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>method_or_intervention</strong></td>
                            <td>zero-shot and few-shot in-context prompting; synthetic question-answer (QA) subquestions added to prompts (two modes: all-at-once and sentence-by-sentence), comparison to original (no synthetic) prompts; connection to chain-of-thought-style guidance</td>
                        </tr>
                        <tr>
                            <td><strong>performance_result</strong></td>
                            <td>On combined test sets the paper reports baseline accuracies in the high-60s to low-70s percent range depending on prompt type (example reported prompt-level numbers ~69–71% for original and synthetic settings; sentence-by-sentence synthetic QAs gave the largest boost). When GPT-3 answered the final MSP correctly it answered only 64% of intermediate synthetic subquestions. Joint correctness matrix (synthetic vs original) reported: Synthetic correct & Original correct 46.0%; Synthetic wrong & Original correct 25.7%; Synthetic correct & Original wrong 11.0%; Synthetic wrong & Original wrong 17.3%.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_insight</strong></td>
                            <td>No low-level mechanistic (attention/head-level) analysis provided; behavioral insight: GPT-3 often attains correct final answers without correctly answering intermediate world-model subquestions, suggesting reliance on heuristics/shortcuts rather than building faithful internal world models; synthetic intermediate QAs can guide the model's reasoning trace (analogous to chain-of-thought prompting) and improve performance.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_scaling</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>Frequently fails to answer intermediate (sentence-level) questions even when final answer is correct (indicates partial/shortcut reasoning); sensitive to prompt design (placement of synthetic QAs matters); other observed errors include reliance on dataset priors/heuristics rather than explicit world modeling.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared three prompting strategies (synth QA all-at-once, synth QA sentence-by-sentence, and no synthetic QA), and compared to other model families (GPT-2, BART, Codex, T5, NT5).</td>
                        </tr>
                        <tr>
                            <td><strong>key_finding</strong></td>
                            <td>GPT-3 performance on math story problems improves when given structured intermediate synthetic QAs (especially when injected at the relevant sentence), but behavioral probes reveal GPT-3 often does not form faithful world models and instead uses heuristics to obtain final answers.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'World Models for Math Story Problems', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e270.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e270.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic operations, including the types of arithmetic tasks, model properties, performance results, methods used, and any mechanistic insights about how the models solve arithmetic problems.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Codex (code-davinci-002)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Codex (code-davinci-002) - a code-trained large language model</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A code-trained decoder-only language model used here as a few-shot semantic parser to map sentences to MATHWORLD logical forms; outputs were converted to world models and solved by a deterministic symbolic reasoner.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Evaluating large language models trained on code</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Codex (code-davinci-002)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_architecture</strong></td>
                            <td>decoder-only transformer (code-trained)</td>
                        </tr>
                        <tr>
                            <td><strong>arithmetic_operation_type</strong></td>
                            <td>addition, subtraction, multiplication, division and multi-step arithmetic as expressed via MATHWORLD relations (TRANSFER, RATE, COMPARISON, PARTWHOLE)</td>
                        </tr>
                        <tr>
                            <td><strong>number_range_or_complexity</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>method_or_intervention</strong></td>
                            <td>few-shot supervised in-context semantic parsing (prompt contained 50 ground-truth examples); deterministic decoding (temperature=0); parsed sentence-by-sentence into linearized logical forms, then converted to world models and solved with a deterministic symbolic reasoner.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_result</strong></td>
                            <td>End-to-end answer accuracy: MAWPS 33.8%, ASDIV-A 26.9%, SVAMP 11.1%. Fraction of predicted world models that were complete (i.e., produced an answer): MAWPS 50.7%, ASDIV-A 43.3%, SVAMP 33.3%. Average weak-smatch and strong-smatch (graph similarity) varied by dataset (weak smatch ~0.76/0.68/0.59; strong smatch ~0.76/0.60/0.38 for MAWPS/ASDIV-A/SVAMP respectively).</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_insight</strong></td>
                            <td>Code-pretrained models (Codex) are relatively better at structured-output prediction tasks (semantic parsing to logical forms) compared to generic LMs, but errors are predominantly in producing correct/complete world-model structure (e.g., misorienting relations, swapping sender/recipient in TRANSFER). The pipeline shows parsing (structure prediction) is the primary bottleneck rather than symbolic solving.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_scaling</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>Incomplete or ill-formed world models (missing reference variable or underdetermined equation systems), incorrect relation orientation (sender/recipient swaps), low accuracy on PARTWHOLE problems, worst performance on the adversarial/challenge SVAMP set. Small syntactic errors in logical form lead to failure in downstream reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared against a rule-based baseline (derived from Hosseini et al., 2014) which got nearly no problems correct; Codex substantially outperformed the rule baseline but end-to-end accuracy remained low.</td>
                        </tr>
                        <tr>
                            <td><strong>key_finding</strong></td>
                            <td>When asked to parse MSPs into explicit world models, Codex (few-shot) produces many incomplete or incorrect logical forms; even when it produces plausible structure, only roughly one-third of problems are solved end-to-end, showing semantic parsing to world models is the main barrier to correct arithmetic reasoning in LLM pipelines.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'World Models for Math Story Problems', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e270.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e270.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic operations, including the types of arithmetic tasks, model properties, performance results, methods used, and any mechanistic insights about how the models solve arithmetic problems.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-3.5-Turbo (generation)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-3.5 Turbo (gpt-3.5-turbo-0301)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An instruction-tuned large language model used here to generate natural-language math story problems from MATHWORLD logical-form world models (constrained generation).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Training language models to follow instructions with human feedback</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>gpt-3.5-turbo-0301</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_architecture</strong></td>
                            <td>decoder-only transformer (instruction-tuned)</td>
                        </tr>
                        <tr>
                            <td><strong>arithmetic_operation_type</strong></td>
                            <td>generation conditioned on world models that include addition, subtraction, multiplication (rates), division and PARTWHOLE relations; not used as a primary arithmetic solver in these experiments</td>
                        </tr>
                        <tr>
                            <td><strong>number_range_or_complexity</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>method_or_intervention</strong></td>
                            <td>constrained generation using 30-shot prompt of logical-form→text pairs; temperature set to 0; generation of paraphrases and augmented logical forms to produce new MSPs.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_result</strong></td>
                            <td>Qualitatively high faithfulness to provided logical forms; reported automatic metrics for paraphrases included SacreBLEU (paper reports a SacreBLEU score of approximately 66 for paraphrasing task) and high BERTScores; generated problems were more concise and less linguistically complex than originals.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_insight</strong></td>
                            <td>No mechanistic claims about arithmetic computation; model reliably maps world-model structure to natural language but sometimes changes relation orientation or relation type when world model was augmented (e.g., switched TRANSFER ↔ RATE or swapped sender/recipient), indicating generation sometimes drifts from the strict logical constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_scaling</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>Occasional mismatch between augmented world model and generated text (swapped roles or changed relation types), conservative outputs (due to temperature=0) that are shorter and simpler than originals.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_finding</strong></td>
                            <td>GPT-3.5-Turbo can generate MSP text faithful to world-model logical forms and thus serves well as a generator in the MATHWORLD design space, but generation can alter relation orientation/type in some augmentations, showing imperfect fidelity to symbolic constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'World Models for Math Story Problems', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e270.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e270.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic operations, including the types of arithmetic tasks, model properties, performance results, methods used, and any mechanistic insights about how the models solve arithmetic problems.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Other LMs (GPT-2/BART/T5/NT5)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-2, BART, T5 and NT5 (various pretrained language models)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Several non-GPT-3 family models evaluated as baselines; overall performed poorly on the MSP tasks but showed improvements when provided with synthetic intermediate QA examples.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-2 / BART / T5 / NT5</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_architecture</strong></td>
                            <td>GPT-2: decoder-only transformer; BART: encoder-decoder denoising transformer; T5/NT5: encoder-decoder text-to-text transformer</td>
                        </tr>
                        <tr>
                            <td><strong>arithmetic_operation_type</strong></td>
                            <td>addition, subtraction, multiplication, division, multi-step arithmetic in MSPs (same conceptual coverage as MATHWORLD)</td>
                        </tr>
                        <tr>
                            <td><strong>number_range_or_complexity</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>method_or_intervention</strong></td>
                            <td>zero-shot and few-shot prompting; evaluated with/without synthetic QA augmentation in prompts</td>
                        </tr>
                        <tr>
                            <td><strong>performance_result</strong></td>
                            <td>Reported as 'overall perform poorly' relative to GPT-3; precise numeric accuracies not reported in main text, but all models benefit from synthetic QA examples with sentence-by-sentence insertion yielding larger gains.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_insight</strong></td>
                            <td>No detailed mechanistic analysis; like GPT-3, these models appear to benefit from structured intermediate supervision but do not reliably construct faithful world models.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_scaling</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>Low absolute accuracy on MSPs; poor at producing well-formed world-model logical forms; improved but still weak when given synthetic QAs.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared across prompting variants (synthetic QA placements) and contrasted with GPT-3 and Codex behavior.</td>
                        </tr>
                        <tr>
                            <td><strong>key_finding</strong></td>
                            <td>Smaller or differently-architected LMs (GPT-2, BART, T5, NT5) struggle more than GPT-3 on MSP arithmetic reasoning, though they too benefit from structured intermediate supervision; overall they are insufficient for reliable MSP solving without stronger semantic parsing.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'World Models for Math Story Problems', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Language Models are Few-Shot Learners <em>(Rating: 2)</em></li>
                <li>Evaluating large language models trained on code <em>(Rating: 2)</em></li>
                <li>Training language models to follow instructions with human feedback <em>(Rating: 2)</em></li>
                <li>Chain of thought prompting elicits reasoning in large language models <em>(Rating: 2)</em></li>
                <li>Solving quantitative reasoning problems with language models <em>(Rating: 2)</em></li>
                <li>Are NLP models really able to solve simple math word problems? <em>(Rating: 2)</em></li>
                <li>A neural network solves, explains, and generates university math problems by program synthesis and few-shot learning at human level <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-270",
    "paper_id": "paper-259095472",
    "extraction_schema_id": "extraction-schema-14",
    "extracted_data": [
        {
            "name_short": "GPT-3",
            "name_full": "Generative Pre-trained Transformer 3",
            "brief_description": "A large pre-trained decoder-only transformer used in this work to probe arithmetic reasoning on math story problems via in-context prompting and synthetic intermediate question-answer pairs.",
            "citation_title": "Language Models are Few-Shot Learners",
            "mention_or_use": "use",
            "model_name": "GPT-3",
            "model_size": "175B",
            "model_architecture": "decoder-only transformer",
            "arithmetic_operation_type": "addition, subtraction, multiplication, division, multi-step arithmetic arising in math story problems (TRANSFER, RATE, COMPARISON, PARTWHOLE concepts)",
            "number_range_or_complexity": null,
            "method_or_intervention": "zero-shot and few-shot in-context prompting; synthetic question-answer (QA) subquestions added to prompts (two modes: all-at-once and sentence-by-sentence), comparison to original (no synthetic) prompts; connection to chain-of-thought-style guidance",
            "performance_result": "On combined test sets the paper reports baseline accuracies in the high-60s to low-70s percent range depending on prompt type (example reported prompt-level numbers ~69–71% for original and synthetic settings; sentence-by-sentence synthetic QAs gave the largest boost). When GPT-3 answered the final MSP correctly it answered only 64% of intermediate synthetic subquestions. Joint correctness matrix (synthetic vs original) reported: Synthetic correct & Original correct 46.0%; Synthetic wrong & Original correct 25.7%; Synthetic correct & Original wrong 11.0%; Synthetic wrong & Original wrong 17.3%.",
            "mechanistic_insight": "No low-level mechanistic (attention/head-level) analysis provided; behavioral insight: GPT-3 often attains correct final answers without correctly answering intermediate world-model subquestions, suggesting reliance on heuristics/shortcuts rather than building faithful internal world models; synthetic intermediate QAs can guide the model's reasoning trace (analogous to chain-of-thought prompting) and improve performance.",
            "performance_scaling": null,
            "failure_modes": "Frequently fails to answer intermediate (sentence-level) questions even when final answer is correct (indicates partial/shortcut reasoning); sensitive to prompt design (placement of synthetic QAs matters); other observed errors include reliance on dataset priors/heuristics rather than explicit world modeling.",
            "comparison_baseline": "Compared three prompting strategies (synth QA all-at-once, synth QA sentence-by-sentence, and no synthetic QA), and compared to other model families (GPT-2, BART, Codex, T5, NT5).",
            "key_finding": "GPT-3 performance on math story problems improves when given structured intermediate synthetic QAs (especially when injected at the relevant sentence), but behavioral probes reveal GPT-3 often does not form faithful world models and instead uses heuristics to obtain final answers.",
            "uuid": "e270.0",
            "source_info": {
                "paper_title": "World Models for Math Story Problems",
                "publication_date_yy_mm": "2023-06"
            }
        },
        {
            "name_short": "Codex (code-davinci-002)",
            "name_full": "Codex (code-davinci-002) - a code-trained large language model",
            "brief_description": "A code-trained decoder-only language model used here as a few-shot semantic parser to map sentences to MATHWORLD logical forms; outputs were converted to world models and solved by a deterministic symbolic reasoner.",
            "citation_title": "Evaluating large language models trained on code",
            "mention_or_use": "use",
            "model_name": "Codex (code-davinci-002)",
            "model_size": null,
            "model_architecture": "decoder-only transformer (code-trained)",
            "arithmetic_operation_type": "addition, subtraction, multiplication, division and multi-step arithmetic as expressed via MATHWORLD relations (TRANSFER, RATE, COMPARISON, PARTWHOLE)",
            "number_range_or_complexity": null,
            "method_or_intervention": "few-shot supervised in-context semantic parsing (prompt contained 50 ground-truth examples); deterministic decoding (temperature=0); parsed sentence-by-sentence into linearized logical forms, then converted to world models and solved with a deterministic symbolic reasoner.",
            "performance_result": "End-to-end answer accuracy: MAWPS 33.8%, ASDIV-A 26.9%, SVAMP 11.1%. Fraction of predicted world models that were complete (i.e., produced an answer): MAWPS 50.7%, ASDIV-A 43.3%, SVAMP 33.3%. Average weak-smatch and strong-smatch (graph similarity) varied by dataset (weak smatch ~0.76/0.68/0.59; strong smatch ~0.76/0.60/0.38 for MAWPS/ASDIV-A/SVAMP respectively).",
            "mechanistic_insight": "Code-pretrained models (Codex) are relatively better at structured-output prediction tasks (semantic parsing to logical forms) compared to generic LMs, but errors are predominantly in producing correct/complete world-model structure (e.g., misorienting relations, swapping sender/recipient in TRANSFER). The pipeline shows parsing (structure prediction) is the primary bottleneck rather than symbolic solving.",
            "performance_scaling": null,
            "failure_modes": "Incomplete or ill-formed world models (missing reference variable or underdetermined equation systems), incorrect relation orientation (sender/recipient swaps), low accuracy on PARTWHOLE problems, worst performance on the adversarial/challenge SVAMP set. Small syntactic errors in logical form lead to failure in downstream reasoning.",
            "comparison_baseline": "Compared against a rule-based baseline (derived from Hosseini et al., 2014) which got nearly no problems correct; Codex substantially outperformed the rule baseline but end-to-end accuracy remained low.",
            "key_finding": "When asked to parse MSPs into explicit world models, Codex (few-shot) produces many incomplete or incorrect logical forms; even when it produces plausible structure, only roughly one-third of problems are solved end-to-end, showing semantic parsing to world models is the main barrier to correct arithmetic reasoning in LLM pipelines.",
            "uuid": "e270.1",
            "source_info": {
                "paper_title": "World Models for Math Story Problems",
                "publication_date_yy_mm": "2023-06"
            }
        },
        {
            "name_short": "GPT-3.5-Turbo (generation)",
            "name_full": "GPT-3.5 Turbo (gpt-3.5-turbo-0301)",
            "brief_description": "An instruction-tuned large language model used here to generate natural-language math story problems from MATHWORLD logical-form world models (constrained generation).",
            "citation_title": "Training language models to follow instructions with human feedback",
            "mention_or_use": "use",
            "model_name": "gpt-3.5-turbo-0301",
            "model_size": null,
            "model_architecture": "decoder-only transformer (instruction-tuned)",
            "arithmetic_operation_type": "generation conditioned on world models that include addition, subtraction, multiplication (rates), division and PARTWHOLE relations; not used as a primary arithmetic solver in these experiments",
            "number_range_or_complexity": null,
            "method_or_intervention": "constrained generation using 30-shot prompt of logical-form→text pairs; temperature set to 0; generation of paraphrases and augmented logical forms to produce new MSPs.",
            "performance_result": "Qualitatively high faithfulness to provided logical forms; reported automatic metrics for paraphrases included SacreBLEU (paper reports a SacreBLEU score of approximately 66 for paraphrasing task) and high BERTScores; generated problems were more concise and less linguistically complex than originals.",
            "mechanistic_insight": "No mechanistic claims about arithmetic computation; model reliably maps world-model structure to natural language but sometimes changes relation orientation or relation type when world model was augmented (e.g., switched TRANSFER ↔ RATE or swapped sender/recipient), indicating generation sometimes drifts from the strict logical constraints.",
            "performance_scaling": null,
            "failure_modes": "Occasional mismatch between augmented world model and generated text (swapped roles or changed relation types), conservative outputs (due to temperature=0) that are shorter and simpler than originals.",
            "comparison_baseline": null,
            "key_finding": "GPT-3.5-Turbo can generate MSP text faithful to world-model logical forms and thus serves well as a generator in the MATHWORLD design space, but generation can alter relation orientation/type in some augmentations, showing imperfect fidelity to symbolic constraints.",
            "uuid": "e270.2",
            "source_info": {
                "paper_title": "World Models for Math Story Problems",
                "publication_date_yy_mm": "2023-06"
            }
        },
        {
            "name_short": "Other LMs (GPT-2/BART/T5/NT5)",
            "name_full": "GPT-2, BART, T5 and NT5 (various pretrained language models)",
            "brief_description": "Several non-GPT-3 family models evaluated as baselines; overall performed poorly on the MSP tasks but showed improvements when provided with synthetic intermediate QA examples.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "GPT-2 / BART / T5 / NT5",
            "model_size": null,
            "model_architecture": "GPT-2: decoder-only transformer; BART: encoder-decoder denoising transformer; T5/NT5: encoder-decoder text-to-text transformer",
            "arithmetic_operation_type": "addition, subtraction, multiplication, division, multi-step arithmetic in MSPs (same conceptual coverage as MATHWORLD)",
            "number_range_or_complexity": null,
            "method_or_intervention": "zero-shot and few-shot prompting; evaluated with/without synthetic QA augmentation in prompts",
            "performance_result": "Reported as 'overall perform poorly' relative to GPT-3; precise numeric accuracies not reported in main text, but all models benefit from synthetic QA examples with sentence-by-sentence insertion yielding larger gains.",
            "mechanistic_insight": "No detailed mechanistic analysis; like GPT-3, these models appear to benefit from structured intermediate supervision but do not reliably construct faithful world models.",
            "performance_scaling": null,
            "failure_modes": "Low absolute accuracy on MSPs; poor at producing well-formed world-model logical forms; improved but still weak when given synthetic QAs.",
            "comparison_baseline": "Compared across prompting variants (synthetic QA placements) and contrasted with GPT-3 and Codex behavior.",
            "key_finding": "Smaller or differently-architected LMs (GPT-2, BART, T5, NT5) struggle more than GPT-3 on MSP arithmetic reasoning, though they too benefit from structured intermediate supervision; overall they are insufficient for reliable MSP solving without stronger semantic parsing.",
            "uuid": "e270.3",
            "source_info": {
                "paper_title": "World Models for Math Story Problems",
                "publication_date_yy_mm": "2023-06"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Language Models are Few-Shot Learners",
            "rating": 2,
            "sanitized_title": "language_models_are_fewshot_learners"
        },
        {
            "paper_title": "Evaluating large language models trained on code",
            "rating": 2,
            "sanitized_title": "evaluating_large_language_models_trained_on_code"
        },
        {
            "paper_title": "Training language models to follow instructions with human feedback",
            "rating": 2,
            "sanitized_title": "training_language_models_to_follow_instructions_with_human_feedback"
        },
        {
            "paper_title": "Chain of thought prompting elicits reasoning in large language models",
            "rating": 2,
            "sanitized_title": "chain_of_thought_prompting_elicits_reasoning_in_large_language_models"
        },
        {
            "paper_title": "Solving quantitative reasoning problems with language models",
            "rating": 2,
            "sanitized_title": "solving_quantitative_reasoning_problems_with_language_models"
        },
        {
            "paper_title": "Are NLP models really able to solve simple math word problems?",
            "rating": 2,
            "sanitized_title": "are_nlp_models_really_able_to_solve_simple_math_word_problems"
        },
        {
            "paper_title": "A neural network solves, explains, and generates university math problems by program synthesis and few-shot learning at human level",
            "rating": 1,
            "sanitized_title": "a_neural_network_solves_explains_and_generates_university_math_problems_by_program_synthesis_and_fewshot_learning_at_human_level"
        }
    ],
    "cost": 0.018908,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>World Models for Math Story Problems
26 Feb 2025</p>
<p>Andreas Opedal andreas.opedal@inf.ethz.ch 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Niklas Stoehr niklas.stoehr@inf.ethz.ch 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Abulhair Saparov 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Mrinmaya Sachan mrinmaya.sachan@inf.ethz.ch 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Eth Zürich 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Laura Banarescu 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Claire Bonial 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Shu Cai 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Max Planck ETH Center for Learning Systems
New York University</p>
<p>Madalina Georgescu 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Kira Griffitt 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Ulf Hermjakob 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Kevin 2013 Knight 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Max Planck ETH Center for Learning Systems
New York University</p>
<p>Philipp Koehn 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Martha Palmer 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Nathan 2013 Schneider 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Tom Brown 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Benjamin Mann 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Nick Ryder 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Max Planck ETH Center for Learning Systems
New York University</p>
<p>Melanie Subbiah 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Jared D Kaplan 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Prafulla Dhariwal 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Arvind Neelakantan 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Pranav Shyam 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Girish Sastry 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Amanda Askell 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Sandhini Agarwal 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Ariel Herbert-Voss 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Max Planck ETH Center for Learning Systems
New York University</p>
<p>Gretchen Krueger 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Max Planck ETH Center for Learning Systems
New York University</p>
<p>Tom Henighan 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Rewon Child 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Max Planck ETH Center for Learning Systems
New York University</p>
<p>Aditya Ramesh 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Daniel Ziegler 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Jeffrey Wu 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Clemens Winter 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Max Planck ETH Center for Learning Systems
New York University</p>
<p>Christopher Hesse 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Max Planck ETH Center for Learning Systems
New York University</p>
<p>Max Planck ETH Center for Learning Systems
New York University</p>
<p>Mark Chen 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Max Planck ETH Center for Learning Systems
New York University</p>
<p>Eric Sigler 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Ma- Teusz Litwin 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Scott Gray 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Max Planck ETH Center for Learning Systems
New York University</p>
<p>Benjamin Chess 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Jack Clark 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Christopher Berner 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Sam Mccandlish 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Max Planck ETH Center for Learning Systems
New York University</p>
<p>Alec Radford 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Max Planck ETH Center for Learning Systems
New York University</p>
<p>Ilya Sutskever 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Max Planck ETH Center for Learning Systems
New York University</p>
<p>Dario 2020 Amodei 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Max Planck ETH Center for Learning Systems
New York University</p>
<p>Smatch 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Jerry Tworek 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Heewoo Jun 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Qiming Yuan 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Henrique Ponde 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Oliveira Pinto 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Jared Ka- Plan 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Harri Edwards 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Yuri Burda 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Nicholas Joseph 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Greg Brockman 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Alex Ray 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Raul Puri 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Michael Petrov 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Heidy Khlaaf 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Girish Sas- Try 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Pamela Mishkin 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Brooke Chan 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Mikhail Pavlov 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Alethea Power 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Lukasz Kaiser 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Mohammad Bavarian 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Max Planck ETH Center for Learning Systems
New York University</p>
<p>Philippe Tillet 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Felipe Petroski Such 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Dave Cum- Mings 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Matthias Plappert 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Fotios Chantzis 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Eliza- Beth Barnes 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>William Hebgen Guss 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Alex Nichol 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Alex Paino 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Nikolas Tezak 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Jie Tang 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Igor Babuschkin 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Suchir Balaji 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Shantanu Jain 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>William Saunders 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Andrew N Carr 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Jan Leike 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Josh Achiam 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Vedant Misra 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Max Planck ETH Center for Learning Systems
New York University</p>
<p>Evan Morikawa 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Matthew Knight 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Miles Brundage 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Mira Murati 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Katie Mayer 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Peter Welinder 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Bob Mcgrew 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Wojciech 2021 Zaremba 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Evaluating 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Aakanksha Chowdhery 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Sharan Narang 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Jacob Devlin 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Maarten Bosma 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Gaurav Mishra 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Adam Roberts 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>HyungPaul Barham 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Won Chung 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Charles Sutton 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Sebastian Gehrmann 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Parker Schuh 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Kensen Shi 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Sasha Tsvyashchenko 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Joshua Maynez 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Abhishek Rao 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Parker Barnes 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Yi Tay 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Noam Shazeer 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Vin- Odkumar Prabhakaran 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Emily Reif 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Nan Du 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Ben Hutchinson 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Reiner Pope 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>James Bradbury 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Jacob Austin 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Michael Isard 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Guy Gur-Ari 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Pengcheng Yin 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Toju Duke 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Anselm Levskaya 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Sanjay Ghemawat 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Sunipa Dev 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Henryk Michalewski 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Xavier Garcia 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Kevin Robinson 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Liam Fedus 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Denny Zhou 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Daphne Ippolito 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>David Luan 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Hyeontaek Lim 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Barret Zoph 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Alexander Spiridonov 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Ryan Sepassi 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>David Dohan 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Shivani Agrawal 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Mark Omernick 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>An- Drew M Dai 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Thanumalayan Sankaranarayana 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Marie Pellat 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Aitor Lewkowycz 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Erica Moreira 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Oleksandr Polozov 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Katherine Lee 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Zongwei Zhou 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Xuezhi Wang 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Brennan Saeta 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Mark Diaz 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Orhan Firat 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Michele Catasta 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Jason Wei 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Kathy Meier-Hellstern 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Douglas Eck 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Jeff Dean 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Slav Petrov 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Karl Cobbe 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Vineet Kosaraju 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Jacob Hilton 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>Reiichiro Nakano 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>John 2021 Schulman 
Max Planck ETH Center for Learning Systems
New York University</p>
<p>World Models for Math Story Problems
26 Feb 20250F2DBE2A0ACEE736A8D3176B6BF07A01arXiv:2306.04347v2[cs.CL]
Solving math story problems is a complex task for students and NLP models alike, requiring them to understand the world as described in the story and reason over it to compute an answer.Recent years have seen impressive performance on automatically solving these problems with large pre-trained language models and innovative techniques to prompt them.However, it remains unclear if these models possess accurate representations of mathematical concepts.This leads to lack of interpretability and trustworthiness which impedes their usefulness in various applications.In this paper, we consolidate previous work on categorizing and representing math story problems and develop MATHWORLD, which is a graph-based semantic formalism specific for the domain of math story problems.With MATHWORLD, we can assign world models to math story problems which represent the situations and actions introduced in the text and their mathematical relationships.We combine math story problems from several existing datasets and annotate a corpus of 1, 019 problems and 3, 204 logical forms with MATHWORLD.Using this data, we demonstrate the following use cases of MATHWORLD: (1) prompting language models with synthetically generated questionanswer pairs to probe their reasoning and world modeling abilities, and (2) generating new problems by using the world models as a design space.</p>
<p>Introduction</p>
<p>Math story problems (MSPs) are short narrative texts that describe a dynamic situation in the world consisting of entities, actions and states, followed by a quantitative question about the world, as displayed in in NLP.While earlier models for solving MSPs (Hosseini et al., 2014;Kushman et al., 2014;Roy and Roth, 2015) focused on extracting various features from text to learn probabilistic models, recent efforts have used pre-trained large language models (LLMs) (Yang et al., 2021;Drori et al., 2022;Lewkowycz et al., 2022, inter alia).Although they display high performance on benchmarks, it has been shown that such neural models tend to rely heavily on shallow heuristics (Patel et al., 2021;Stolfo et al., 2023), raising questions about whether the models can indeed "understand" MSPs and robustly solve them.</p>
<p>From the human side, solving MSPs requires a wide set of skills.A student must not only perform a set of given computations, but first be able to process the text and map it into a corresponding world model that represents the situation described in text (Cummins et al., 1988;Stern, 1993).Inspired by this, we take a step towards developing more interpretable solvers and introduce MATHWORLD, a semantic world model framework for MSPs.</p>
<p>MATHWORLD can be viewed as a formalism for reasoning in dynamical problem settings (McCarthy, 1963;Reiter, 1991), specific to the domain of MSPs.It represents each problem as a directed graph called a world model ( § 3).The nodes in a world model are containers ( § 3.1) representing entities' possession of some quantity (Hosseini et al., 2014) and the edges represent various types of mathematical relations between the quantities ( § 3.2).The relations correspond to mathematical concepts that have been previously shown to cover a vast majority of MSPs (Mitra and Baral, 2016;Roy and Roth, 2018).We annotate a MATHWORLD dataset consisting of 1, 019 English MSPs from various widely-used datasets (Koncel-Kedziorski et al., 2016b;Miao et al., 2020;Patel et al., 2021), which we make publicly available.</p>
<p>There are several potential use cases of MATH-WORLD, of which we discuss three.First, one natural application is that of developing interpretable MSP solvers.A solver using MATHWORLD follows two steps: (i) semantic parsing and (ii) reasoning.The semantic parser takes an MSP text and outputs a world model based on the explicit information in the text.The reasoner then takes the world model and solves the problem based on the quantities and their relations.Our experiments show that LLMs struggle to build accurate and well-formed world models; we encourage future work to develop stronger semantic parsers for MATHWORLD.</p>
<p>Another use case of MATHWORLD is as a tool to study the reasoning capabilities of existing solvers.For instance, we can use the world model annotations to automatically generate synthetic subquestions for the MSPs.Using such subquestions, we give empirical evidence that GPT-3 (Brown et al., 2020) benefits from the structured knowledge derived by world models in its ability to solve MSPs.We further use our synthetic questions to understand if GPT-3 can indeed answer these intermediate questions about the world described in the MSPs, and not just the final question.We find that for problems where GPT-3 answers the final question correctly, it can only answer 64% of the intermediate questions.This suggests that GPT-3 is not accurately building world models for these problems but might be relying on reasoning shortcuts.</p>
<p>Finally, MATHWORLD can be considered as a design space for generating interesting new MSPs.We illustrate the usefulness of MATHWORLD for the task of generating MSPs by prompting an LLM using the world model annotations.</p>
<p>Related Work</p>
<p>Math story problems in NLP.Although the problem of automatically solving MSPs has gathered substantial interest in NLP (Roy and Roth, 2015;Kushman et al., 2014;Huang et al., 2017;Amini et al., 2019;Xie and Sun, 2019;Drori et al., 2022), the focus has traditionally been on improving answer accuracy rather than providing didactic human-interpretable solutions (Shridhar et al., 2022).Some approaches map the text to expression trees (Koncel-Kedziorski et al., 2015;Yang et al., 2022;Roy and Roth, 2017) or explicitly model arithmetic concepts (Mitra and Baral, 2016;Roy and Roth, 2018).However, few if any computational works have attempted to solve MSPs by using mental models (Johnson-Laird, 1983), which is a common framework for analyzing how humans solve MSPs (Kintsch and Greeno, 1985).Taking inspiration from mental models of MSPs, we offer MATHWORLD as a computational model (fully expressible in first-order logic, App.D) which represents reasoning steps, arithmetic concepts and fictional elements in a human-readable graph format.We hope that such an approach can support intelligent tutoring systems (Anderson et al., 1995), e.g., by delivering feedback and hints (Zhou et al., 1999;Fossati, 2008) or generating new MSPs (Polozov et al., 2015;Koncel-Kedziorski et al., 2016a;Srivastava and Goodman, 2021).</p>
<p>In particular, we draw inspiration from Hosseini et al. (2014), who propose a symbolic approach that maps the text to container-based states.However, their symbolic representation is purely extracted from syntactic rules without human annotation.Further, their approach only covers problems that involve a transfer of some quantity between some actors (although they do not use that terminology), requiring addition and/or subtraction.In contrast, MATHWORLD is more closely tied to the MSP's semantics.It covers a strictly larger set of problem types, involving more concepts and all four basic arithmetic operators (+, −, ×, ÷).See Table 1 for a comparison between MATHWORLD and Hosseini et al. (2014), as well as Mitra and Baral (2016) and Roy and Roth (2018) from which we adopt the taxonomy over arithmetic concepts.</p>
<p>Reasoning with large language models.LLMs have displayed impressive performance on numerical reasoning tasks (Brown et al., 2020;Chowdhery et al., 2022), particularly by the help of careful prompt engineering (Wei et al., 2022;Shridhar et al., 2023;Zhou et al., 2023).While language models have been argued to be intrinsically limited in their ability to perform human-like rea- soning (Bender and Koller, 2020), the mechanism by which they find answers in complex reasoning tasks is currently an active area of research (Tafjord et al., 2021;Saparov and He, 2023).MATHWORLD provides ground truth world model annotations, which is valuable in such studies (as demonstrated in § 5.2).One other aspect of LLMs that may limit them when applied to reasoning is that they produce natural language text, which may be ambiguous and diverse.These considerations motivate us to study MSPs as structured representations of meaning, which can in turn be used to generate natural language (Saparov and Mitchell, 2022).</p>
<p>Semantic parsing.MATHWORLD can be viewed as a domain-specific semantic formalism.Our work thus also relates closely to semantic parsing, particularly of graph-based structures (Banarescu et al., 2013;Cai and Lam, 2019;Zhang et al., 2019;Bai et al., 2022).However, while most other formalisms consider meaning only at the sentence level, our world model graphs span the meaning across multiple sentences.</p>
<p>MATHWORLD</p>
<p>In this section, we present our world model formalism MATHWORLD.We formalize an MSP as a sequence of n sentences s = s 1 • • • • • s n .It can be separated into a body b and a question q, such that s = b • q.The body is further partitioned into a sequence of n − 1 declarative sentences b = s 1 • • • • • s n−1 and the question consists of a single interrogative sentence q = s n .</p>
<p>World models in MATHWORLD are directed and labelled graphs, denoted g.1 We refer to the nodes of the graph as containers ( § 3.1) and the edges of the graph as relations ( § 3.2).Each container and relation is labelled with a set of properties.One such property is the quantity, which may be either an explicit number mentioned in text or a variable representing an unknown number.The containers and relations along with their properties specify the equations induced by the MSP.In addition, each g is associated with a reference variable r, which points to the variable in g that holds the correct answer to the question as stated in q.We consider each s to be associated with some structure (g, r).</p>
<p>We say that g is faithful if it represents the semantics of the problem text according to the framework of MATHWORLD.Further, g is complete if r can be solved with the equations induced by g.A complete world model is correct if, when evaluated, r gives the correct answer to the problem.See Fig. 1 for an example of a world model.</p>
<p>In order to allow for incremental parsing, we segment the world models into sentence-level logical forms m i , i = 1, . . ., n.The logical form is a sequence that represents the containers and/or relations associated with the corresponding sentence. 2e can convert (m 1 , . . ., m n ) to a world model graph, and vice versa.The two representations are nearly equivalent, with the exception of a few caveats (see App. F for details).There is no bound on the problem length and, by extension, the number of logical forms.MATHWORLD is thus able to represent problems of any arbitrary number of reasoning steps.The assignment of logical forms may be ambiguous in the sense that there may be multiple faithful logical forms for a given sentence (discussed in App.B).</p>
<p>We consider subgraphs g i , for sentence i, of the final graph g.A subgraph g i corresponds to the logical forms up to sentence i, i.e., (m 1 , . . ., m i ) → g i .We refer to the subgraph for some sentence index i as the state of i.As an example of how world models are built incrementally with states, consider Fig. 1.The first sentence maps to the container for label Will holding the entity money of quantity 83 with unit dollar.The second sentence provides information on an update to Will's possessed money, a TRANSFER relation ( § 3.2.1).Finally, the question sentence introduces rate information, a RATE relation ( § 3.2.2), between money and toys.</p>
<p>In the next sections, we describe the details of containers and relations in depth.</p>
<p>Containers</p>
<p>We adopt and modify the containers described in the model of Hosseini et al. (2014).Semantically, containers represent containment/possession.We refer to the possessor in the text as the label of the container. 3In Fig. 1, the container label is Will for all containers (although in general the label can vary across containers).The label must be a noun plus any associated noun adjuncts (like elementary school).In addition to label, a container may have the following four properties:</p>
<p>Entity:</p>
<p>The entity is what is possessed in the container.It is a noun, for which there may be an associated count.When expressed in a problem text, it must be the head of a noun phrase.In Fig. 1, money and toy are entities. 4uantity: The quantity is the number associated with the entity.It may be known, in which case it will be a positive real number, or unknown, in which case it will be a variable.</p>
<p>Attribute:</p>
<p>The attribute is a modifier for the entity.It is often an adjective, but may take other forms as well.The attribute is an optional property.</p>
<p>Unit:</p>
<p>The unit is the unit of measurement for the entity.A unit property must exist if the entity is a mass noun, but may exist in other cases as well.For example, "liter of water" and "kg of apples" will both be assigned to containers with units.The unit is an optional property.</p>
<p>Entity, attribute and unit are written in their lemmatized forms.The label is not, in order to be able to distinguish between a set (plural: friends) and an element of some set (singular: friend).</p>
<p>Note that the containers take a variable number of properties; having arity 3, 4 or 5. Two containers are equal if they have the same arity and the same properties.We refer to a container's structure as its container label, entity, attribute (if exists) and unit (if exists).Two containers are structurally equal if they have the same structure.</p>
<p>Relations</p>
<p>Relations are the edges in g.They represent the interactions between the various parts of the world model, from which the equations of the MSP are induced.The relations are directed, and the direction encodes semantics of the relation depending on the type of relation.Like containers, relations have properties.The properties and their arity also depend on the type of relation.</p>
<p>There are four types of relations: TRANSFER, RATE, COMPARISON and PARTWHOLE.Together they span all four basic arithmetic operators (+, −, ×, ÷).Next, we give a detailed description of each of these relation types.Examples of world models with each relation type are provided in App. A.</p>
<p>TRANSFER</p>
<p>TRANSFER relations model that a transfer of some quantity of an entity has occurred.A given container structure will either gain or lose quantity from a TRANSFER relation.For example, "Alice ate 3 apples" will correspond to a TRANSFER with a loss of 3 apples for the container labeled Alice.A TRANSFER is always between two containers of the same structure.The direction of the edge describes order: The source container will hold the quantity before the transfer event occurred, and the target container will hold the quantity after the transfer event occurred.</p>
<p>In addition to quantity, TRANSFER takes the following two properties:</p>
<p>Recipient: The label of the container structure where the quantity of the given entity is gained.</p>
<p>Sender: The label of the container structure where the quantity of the given entity is lost.</p>
<p>A recipient, a sender or both must exist.TRANS-FER thus has arity 2 or 3.The TRANSFER relation either adds or subtracts the relation quantity to/from the source container quantity, depending on whether the relation connects the recipient containers or sender containers.</p>
<p>RATE</p>
<p>The RATE relation models mathematical rate between two quantities.These two quantities are held in two separate containers with the same label, and the ratio quantity of the rate is given as a property to the relation.RATE has this one single property.The direction of the edge determines the relationship: The source container holds the numerator of the rate, and the target container holds the denominator of the rate.In the example in Fig. 1, the source container holds the entity money and the target container holds the entity toy, indicating that the rate quantity concerns money per toy.Mathematically, RATE implies that the source quantity divided by the relation quantity equals the target quantity.</p>
<p>COMPARISON</p>
<p>COMPARISON is invoked when there is an explicit relationship between two quantities in the MSP.For example, "Alice is twice as old as Bob".The COMPARISON relation may be either between containers with different labels, such as "Alice has 3 more apples than Bob", or between containers with the same label, such as "Alice has 3 more red apples than she has green apples".It takes two properties; quantity and type:</p>
<p>Type: The arithmetic operation type COMPARI-SON.It can take one of the two values; add (indicating addition) or mul (indicating multiplication).</p>
<p>The quantity held in the source container is the one that is combined with the quantity of the COM-PARISON relation under the arithmetic operator, the output of which will be the quantity held in the target container.</p>
<p>PARTWHOLE</p>
<p>PARTWHOLE relations model set partitions.The set represented by some container is partitioned into subsets, each of which is represented by another container.For each of the subset containers (the parts), there is an outgoing edge to the container with the superset (the whole).Thus, PARTWHOLE implies that for a given container that has ingoing PARTWHOLE edges, the sum over the quantities in the source containers of those edges equals the quantity in the target container.Note that PARTWHOLE differs from the other relations in that it requires multiple edges to induce an equation. 5In most cases, all containers involved in a PARTWHOLE relation will have the same label.The relation can then be viewed as a relation between entities possessed by a specific label.For instance, "Alice has 3 red apples and 6 green apples, how many apples does she have in total?" would be represented by PARTWHOLE.PARTWHOLE relations have no properties.PARTWHOLE relations may represent meaning that is not explicit in text.Parsing the text of a problem that requires PARTWHOLE might thus lead to an incomplete ( § 3) world model, which may require additional assumptions.In addition, orienting PARTWHOLE relations might require commonsense knowledge.For instance, a problem might introduce a quantity for tables and a quantity for chairs, and ask about the total number of furniture.</p>
<p>World model equivalence and similarity</p>
<p>One of the principal utilities of MATHWORLD is to allow for evaluating models on their reasoning ability.For that we need consistent equivalence notions and similarity metrics between world models, which we provide here.</p>
<p>Let g and g ′ be isomorphic if there exists an isomorphism on the underlying graphs that additionally preserves relation types.We consider two forms of equivalence notions between world models, which we call strong and weak equivalence.Weak equivalence deems two world models to be equal if they are isomorphic.Strong equivalence additionally requires all properties of the containers and relations to be equal. 6In addition, we create two similarity scores based on the AMR metric smatch (Cai and Knight, 2013): Weak smatch considers graph topology in the same way as our isomorphism equivalence, and strong smatch additionally considers all properties of the world models.We give details on these similarity scores in App. C.</p>
<p>Comparison to other logical formalisms</p>
<p>MATHWORLD can be fully expressed in first-order logic (FOL).We provide a constructive proof in the form of a conversion in App.D, which enables comparison of the expressive power of MATHWORLD with that of other formalisms.Both AMR and MATHWORLD restrict the expressivity of full FOL in different ways.AMR provides a way to express negation (the polarity relation) but does not provide a way to directly express universal quantification 7 (Bos, 2016).MATHWORLD represents sets of objects as containers and enables universal quantification over those sets.This is restricted, however, as MATHWORLD does not allow the definition of sets of sets, or nested universal quantification.8Negation is not directly expressible in MATHWORLD, as it is designed for the domain of MSPs where negation is quite rare.</p>
<p>MATHWORLD is more comparable to situation calculus (McCarthy, 1963), where each relation can be modeled as an action that changes the state of the world.Like situation calculus, the changing world state over time is implicitly represented in MATHWORLD (via the TRANSFER relation), whereas in FOL, an explicit description of the time of each event is necessary.</p>
<p>Data Collection</p>
<p>In order to study how models are able to answer MSPs, convert them to logical form, perform world modeling, and reason mathematically to find the answer, we require a diverse dataset of labeled MSPs that spans all concepts covered by MATHWORLD.To ensure diversity and wide variety in the examples, we collect them from numerous sources:</p>
<p>1.The math word repository MAWPS (Koncel-Kedziorski et al., 2016b) gathers several datasets (Hosseini et al., 2014;Kushman et al., 2014;Koncel-Kedziorski et al., 2015;Roy and Roth, 2015), thus providing a wide variety of MSPs. 2. To complement with more challenging problems, we also adopt problems from ASDIV-A (Miao et al., 2020), which was designed for linguistic diversity and math concept diversity.3. We also annotate a subset of the SVAMP dataset (Patel et al., 2021), which was introduced as a challenge set to test robustness to data artifacts.This enables future work to test the robustness of MATHWORLD parsers.</p>
<p>We randomly sample a subset from each of these three datasets,9 and annotate them with world models.We obtain 1, 019 MSPs, which corresponds to 3, 204 logical forms, which we partition into 80/20 train/test splits.Table 2 provides more details.We hire external workers for annotation.Annotation follows three phases: A first training phase where annotators are given several small sets at a time with follow-up discussion sessions, an agreement phase in which all annotators are given the same problems and a final scale-up phase.We use an annotation tool created specifically for this work (shown in App.E.2).The problems are annotated incrementally sentence-by-sentence, in order to match logical forms to sentences as described in § 3. Questions are hidden from annotators until all preceding sentences are completed, in order to avoid bias stemming from having read the question-MATHWORLD is meant to capture the world model of the problem irrespective of what is asked in the question.Within sentences, we ask annotators to add containers and relations according to the order in which they occur in text.This allows us to write the logical forms according to within-sentence order when creating training data for semantic parsing.We maintain this order with integer IDs that are incremented automatically in the annotation tool.</p>
<p>We performed an agreement analysis of 125 overlapping MSPs, revealing a high agreement rate considering the complexity of the annotation task.Concretely, 61 out of these 125 were strongly equivalent ( § 3.3) across annotators, and 107 were weakly equivalent ( § 3.3).Many of the only weakly equivalent annotations were due to ambiguity in the properties (App.B.1), and almost half of the 18 non-agreed problems were due to ambiguity in relation type (App.B.2).The strong and weak smatch scores were 0.91 and 0.97 respectively.These can be interpreted as approximate upper bounds on the smatch scores achievable by any model, due to the ambiguity in the dataset.Many of the annotation errors, also outside of the overlapping set, could be either corrected or discarded ex post.Further details on annotation are given in App.E.</p>
<p>Applications of MATHWORLD</p>
<p>In this section we showcase some applications of MATHWORLD: solving ( § 5.1), probing of reasoning ( § 5.2) and generation of new MSPs ( § 5.3).</p>
<p>Parsing and Reasoning</p>
<p>We spell out a framework for solving MSPs using MATHWORLD.The framework consists of two components: A parser and a reasoner.The parser is tasked with assigning a faithful world model g to an input problem s, along with a reference variable r.The reasoner is then queried with r and computes an answer based on the induced equations of g.We also present a set of initial experiments, meant to introduce the task of MATHWORLD parsing to the community.</p>
<p>Parser</p>
<p>Given an MSP s, the task is to assign a world model g.The first step is to predict the sequence of logical forms m 1 , . . ., m n .We model this as a conditional distribution
p(m 1 , . . . , m n | s) = n i=1 p(m i | s 1 , . . . , s i ). (1)
With this factorization, we can parse the graph incrementally one sentence at a time.The factorization is based on two assumptions: m i ⊥ s j , ∀i &lt; j and m i ⊥ m j , ∀i ̸ = j.Both are aligned with MATHWORLD as outlined in § 3: the first assumption means that a logical form is independent of the sentences in subsequent steps, and the second assumption means that logical forms are independent of each other.Dependencies of logical forms on preceding sentences are kept due to coreferences, elliptical constructions and other inter-sentence dependencies.</p>
<p>As explained in § 3, the logical forms are linearized representations of the world model graphs.Thus, our pipeline (as well as applications like those demonstrated in § 5) requires that we are able to convert from one representation to the other: World model graphs must be converted to logical forms in order to create training data for a semantic parser, and the predicted logical forms must be converted to world model graphs and reference variables for visualization and reasoning.The details of this conversion are given in App.F.</p>
<p>Reasoner</p>
<p>Once we have a world model graph, we apply a reasoning algorithm over the graph to compute an answer.The reasoner takes a world model and a reference variable, and outputs a numeric value for the reference variable r.Our implementation is deterministic and follows two steps.First, it extracts all equations induced by the world model (as described in § 3.2 and illustrated in App.A).Second, it solves for r using a recursive algorithm.Full pseudocode along with a discussion is presented in App.H.10</p>
<p>Baseline solving experiments</p>
<p>We demonstrate our proposed modeling framework with a baseline semantic parser, in the form of a large language model that is supervised incontext.We use Codex (Chen et al., 2021), as language models trained on code have been previously shown to perform well on structured prediction tasks (Madaan et al., 2022;Drozdov et al., 2023).The prompt contains 50 ground truth examples from MAWPS and ASDIV-A, and we evaluate the model on the test sets of MAWPS, ASDIV-A and SVAMP.We also implement a rule-based baseline system, based on Hosseini et al. (2014).</p>
<p>Our results corroborate that this is a challenging task; for the least difficult dataset the model gets roughly one third of the problems correct, and predicts a complete world model for only slightly more than half of the problems.The rule-based baseline gets nearly no problems correct.Indeed, a model must, for each sentence, produce well-formed logical forms that exhaustively and correctly capture the semantics in MATHWORLD, combine these into a world model and query the reasoner with the correct reference variable.One mistake in any of these steps may lead to an incorrect answer.With much progress and research interest in semantic parsing in recent years (Shin et al., 2021;Qiu et al., 2022) there are several promising directions for improvement.Further details on the setup and results can be found in App.I.1.</p>
<p>Probing LLMs' partial knowledge</p>
<p>World models enable us to study the reasoning ability of LLMs: Beyond just testing whether a model outputs the correct solution to an MSP, we can test whether the model follows a correct reasoning path and accurately builds world model representations.</p>
<p>Setup.We design question and answer templates that are automatically filled based on information in the world model.Two examples of such templates are given in Fig. 2 and a list of all templates is given in App.I.3.By courtesy of the world model we know the true answer to each of these synthetic questions, enabling us to create prompts with question-answer pairs.</p>
<p>We experiment with three types of prompts, all displayed with full-length examples in Table 8: (1) synth QA (all at once).We first include the complete problem text, followed by synthetic question and answer pairs related to some part of the from x MSPs QA type 0 1 (1) synth QAs (all at once) 70.8 71.8 (2) synth QAs (sent by sent) 71.3 78.6</p>
<p>(3) original MSP QAs 69.4 70.8</p>
<p>Table 3: Results obtained by GPT-3 in answering math story problems reported in accuracy percent.A larger increase in performance is observed when the synthetic question-answer pairs are presented at the relevant part of the text, rather than at the end.</p>
<p>text.We randomly sample two such pairs;</p>
<p>(2) synth QA (sentence-by-sentence).We again sample two question-answer pairs at random, but in this setting they are imputed right after the sentence in which the answer to the question is given;</p>
<p>(3) original MSP QA.Under this setting we do not include any synthetic question-answer pairs, only the original text.All prompts end with the MSP question that we aim to solve followed by "A:".We study both whether the synthetic questions help the model answer the MSP correctly, and how well the model answers the synthetic questions themselves.</p>
<p>Results.We report results obtained by GPT-3 (Brown et al., 2020) on the combined test set of all three datasets in Table 3.The number of incontext examples is either 0 or 1.We observe increased performance when including synthetic question-answer pairs, particularly in setting (2) where the questions are imputed at the relevant part of the MSP text.We hypothesize that doing so helps guide the reasoning trace of the model, in a similar vein as chain-of-thought prompting (Wei et al., 2022).Further, we find that GPT-2 (Radford et al., 2019), BART (Lewis et al., 2020), Codex (Chen et al., 2021), T5 (Raffel et al., 2020) and NT5 (Yang et al., 2021) overall perform poorly, but benefit from an increase in performance when synthetic question-answer pairs are provided.We further compare the ability of GPT-3 to answer the intermediate synthetic questions to its ability to answer the original final question.For each MSP, we first select a container or relation uniformly at random and then create a synthetic question.We then ask both the synthetic question and the original question at the end of two separate prompts in a zero-shot setting.tion wrong (top right cell).Overall it also shows a higher accuracy on the original questions (top row) than the synthetic intermediate questions (left column).While some of these results could be explained by the nature of the templated questions, it does seem to indicate that the model makes use of heuristics rather than human-like reasoning when solving MSPs (Patel et al., 2021).</p>
<p>Generation of MSPs</p>
<p>MATHWORLD can be considered as a space under which a practitioner can design new MSPs with certain desired features.For instance, a teacher may be interested in generating variations of an MSP to test a specific mathematical concept with a specific unknown variable.To demonstrate the potential for such applications we provide a small proof-of-concept experiment.</p>
<p>Setup.We use GPT 3.5 Turbo (Ouyang et al., 2022) with a prompt of 30 examples from the train sets of MAWPS and ASDIV-A.One example consists of the logical forms for a full MSP world model (source) followed by the text of the MSP (target).We separate sentence-aligned logical forms in the source as well as the sentences in the target by a marker, so that the model can pick up the alignment patterns.The ground truth examples are sampled randomly.To generate a new MSP conditioned on a world model, we append the logical form corresponding to the world model to the end of the prompt.We try generating new MSPs both based on (i) world models present in our annotated test sets (paraphrasing) and (ii) manual augmentations of annotated world models.We perform evaluation for setting (i) using SacreBLEU (Post, 2018) and BERTScore (Zhang et al., 2020), comparing all MSPs in the test sets to their paraphrases. 11</p>
<p>Results.We obtain SacreBLEU scores of 66. SVAMP respectively.Qualitatively we observe that the generated MSPs mostly stay faithful to the logical forms but tend to be shorter and less linguistically complex than the original problems, which would explain the comparatively low SacreBLEU scores in comparison to the BERTScores.Further, we give the first six examples we generated according to the described setup.One of them is shown in Fig. 3.The model generates an output MSP very similar to the original, having only accessed the original's ground truth logical forms.We further augment the original world model by changing the TRANSFER to a RATE.Note how the generated MSP is faithful to the augmented world model.The other five examples are shown in Table 6.</p>
<p>Conclusion</p>
<p>In this work, we have presented a novel formalism, MATHWORLD, for expressing the semantics of math story problems.We have annotated a MATH-WORLD corpus consisting of 1, 019 problems and 3, 204 logical forms.A world model derived from MATHWORLD exposes the structure of the reasoning process needed to solve the problem, which benefits several applications as we have demonstrated in § 5.As such, we hope that MATHWORLD will promote use cases beyond just improved MSP solving, ranging from automated chain-of-thought prompting to math problem generation.</p>
<p>Limitations</p>
<p>MATHWORLD is limited to cover math story problems using the four basic arithmetic operators.Fur-thermore, within the space of such problems, it does not cover "second-order" MSPs (as discussed in § 3.4).Neither does it cover negation nor inequalities.</p>
<p>We only consider datasets with MSPs written in English in this work.However, MATHWORLD should in principle be able to cover the same type of problems formulated in other languages as well.</p>
<p>An obvious limitation of this work is the low performance on the task of solving MSPs.The focus of this work is to introduce the world model formalism and its use cases, and we leave for future work to build stronger MATHWORLD parsers.</p>
<p>Ethics Statement</p>
<p>We foresee no major ethical concerns with this work.The introduction of MATHWORLD is aimed at improving the interpretability and robustness of existing and future models for math story problem solving.On this account, we hope to contribute to identifying (and hopefully reducing) existing biases in pre-trained language models, or any future alternatives.However, we would like to caution that the formalism could be used to generate inappropriate math story problems.</p>
<p>The school cafeteria had 14 apples.If they used 13 to make lunch for the students and then bought 49 more, how many apples would they have?The school cafeteria had 14 apples.If they used 13 to make lunch for the students and then bought 49 more, how many apples would they have?</p>
<p>We display the corresponding world model in Fig. 4. The first sentence will correspond to a container for school cafeteria that holds 14 of entity apple.The second sentence describes two transfers: a first one where the school cafeteria is the sender of 13 apples, and a second one where the school cafeteria is the recipient of 49 apples.We get two equations:
14 − 13 = x 1 (2) x 1 + 49 = x 2(3)
The question asks for how many apples the school cafeteria has in the end, which matches the container holding the variable x 2 in the world model.Although the TRANSFER relation always connects two containers of the same structure in the graph, a transfer event may occur between two containers of different structure.For example, "Alice gives 3 apples to Bob" describes a transfer event with Alice losing 3 apples and Bob gaining 3 apples.In these cases, we need two edges with the same properties in the world model; one for Alice's containers and one for Bob's containers (see Fig. 5).Consider the following problem with a transfer event occurring between two different possessors:</p>
<p>Alice has 7 apples and Bob has 4 apples.Alice gives 3 apples to Bob.How many apples does Bob have now?</p>
<p>We show the corresponding world model in Fig. 5. Alice and Bob are represented by two separate containers, which are both updated by the same transfer event.</p>
<p>A.2 RATE</p>
<p>Consider the following problem:  Lansing has 25 elementary schools.There are 247 students in each school.How many elementary students are there altogether in Lansing?</p>
<p>This is a rate problem, as we get a rate on the number of students per elementary schools in the second sentence.The relation induces the following equation:
x 1 25 = 247(4)
The question asks for the total number of students in Lansing, which corresponds to the quantity in the container that holds the entity student.</p>
<p>A.3 COMPARISON</p>
<p>Consider the following problem:</p>
<p>James has 232 balloons.Amy has 101 balloons.How many more balloons does James have than Amy?</p>
<p>The first two sentences will correspond to two containers, representing the number of balloons possessed by James and Amy respectively.In the question sentence, we get information about an COMPARISON relation between these two containers, with properties x 1 and add.Since we need to add the balloons in Amy's container to get the number of balloons in James' container, the edge is directed outwards from Amy's container.This relation induces the following equation:
101 + x 1 = 232 (5)
The world model is displayed in Fig. 7.</p>
<p>A.4 PARTWHOLE</p>
<p>Consider the following problem:</p>
<p>Gavin has 23 shirts.6 are blue the rest are green.How many green shirts does Gavin have?</p>
<p>The first sentence will correspond to a container for Gavin holding the quantity of his shirts.The part-whole information is introduced in the second sentence, in which the 6 refers to shirts in the previous sentence (via an elliptical construction), and "the rest" tells us we have an additional complementing part of green shirts.Hence, the second sentence is assigned two new containers with attributes blue and green, as well as PARTWHOLE relations from both of these containers to the whole container introduced in the first sentence.This leads to the following equation:
6 + x 1 = 23 (6)
The reference variable is the quantity in the container holding Gavin's green shirts.See Fig. 8 for the world model.</p>
<p>B Ambiguity</p>
<p>Ambiguity occurs when the same problem text may be assigned multiple correct and faithful world models.We distinguish between two types of ambiguity for MATHWORLD: property ambiguity and structural ambiguity.</p>
<p>B.1 Property ambiguity</p>
<p>Property ambiguity concerns cases where there are multiple possible properties to containers and/or relations that yield a semantically faithful world model.For instance, it is ambiguous whether "carrot sticks" is to be interpreted as an entity carrot stick, as entity carrot with unit stick, or as entity stick with attribute carrot.Property ambiguity may also follow from syntactic ambiguity in the problem text.</p>
<p>B.2 Structural ambiguity</p>
<p>Structural ambiguity occurs when the topology, including relation types, differs between several correct and faithful world models for a given problem.</p>
<p>Consider the following example:</p>
<p>James ate 22 carrot sticks before dinner and 15 more after dinner.How many carrot sticks did he eat?</p>
<p>This problem could be modeled either with TRANSFER or PARTWHOLE.In the case of TRANSFER, we view James as possessing some quantity of carrot sticks to start with.He then eats 22 of these, which can be viewed as a TRANSFER where James is the sender.This TRANSFER relation will be an outgoing edge into a new updated container for James' carrots.Another TRANSFER occurs for the 15 carrot sticks he ate after dinner.The reference variable would then be the variable held in the first container -how many carrot sticks James had initially.See Fig. 9 for the world model.Note that such a world model is not sufficient for solving the problem without further assumptions, it requires defeasible reasoning (Koons, 2022).We must assume that James had no carrot sticks after having eaten the ones post dinner, corresponding to the third container holding quantity 0, in order for the world model to be complete.Another possibility would be with PARTWHOLE.With PARTWHOLE, we take the static view of James possessing 22 carrot sticks before dinner and 15 carrot sticks after dinner, assigning a container for each.The question statement gives us the information that we are asking for the total number of carrot sticks, which would be parsed with PARTWHOLE to a container with the total.The reference will refer to the variable in this latter container.In contrast to the TRANSFER interpretation, the PARTWHOLE interpretation does not require additional assumptions to create a complete world model.See Fig. 10.</p>
<p>C Similarity Scores</p>
<p>In this section, we describe how we adapt smatch (Cai and Knight, 2013) for measuring similarity between world model graphs.We express the world models as conjunctions over logical triples.We label all containers and relations with a unique variable, and denote that such a variable is an instance of a container or one of the five relation types with the triple instance(variable, type).Containers are represented as arguments to the relations in the form of source and destination, which are non-core roles in AMR. 13 For instance, a container c being the source node of relation r is represented as source(r, c).The topology smatch score of two world models is then computed by taking the maximum f-score over one-to-one variable mappings between the two world models, as in Cai and Knight (2013).</p>
<p>The full semantic smatch score is computed in the same way, with the addition of logical triples for all the container and relation properties.We define core argument roles for the containers and each of the relation types.For instance, ARG0 of a container will be its entity.The entity apple belonging to container c will be represented by two logical triples instance(e, apple) and ARG0(c, e).</p>
<p>D Conversion to First-order Logic</p>
<p>In this section, we define a function to convert world model graphs into an equivalent FOL expres-sion.</p>
<p>D.1 Describing quantities</p>
<p>Before introducing the conversion function, we first present a way in which quantities are described in FOL, as a preliminary.We define the Measure predicate, which is used to describe the "size" of a set.The set may contain countable entities such as "8 balloons" or uncountable entities such as "10 grams of coffee," and Measure is used to specify both types of quantities.</p>
<p>We introduce axioms to enable mathematical reasoning over the Measure predicate.If the measure of a set is a cardinal number (as in "8 balloons"), then it is the cardinality of that set:
∀x∀m(Measure(x, m) ∧ m ∈ {0, 1, . . .} ↔ Cardinality(x, m)).
For example, if a set x contains 8 elements, we write Measure(x, 8).We also define the additivity of measures:
∀x∀y∀m x ∀m y (x ∩ y = ∅ ∧ Measure(x, m x ) ∧ Measure(y, m y ) → Measure(x ∪ y, m x + m y )).
That is, for any disjoint sets, the measure of their union is equal to the sum of their measures.To describe the size of sets containing uncountable entities (as in "10 grams of coffee"), we use the Quantity predicate.For example, if a set x contains 10 grams, we write Measure(x, Quantity(10, Gram)).To enable reasoning over such measures, we define the following axiom:
∀x∀y∀u(Quantity(x, u) + Quantity(y, u) = Quantity(x + y, u)).
That is, quantities may be summed if they share the same units.Subtraction of quantities is defined similarly.Further axioms can be defined to allow conversions between units, such as: ∀x(Quantity(x, Milliliter) = Quantity(x/1000, Liter)).</p>
<p>D.2 Conversion function</p>
<p>Let g = (V, E) be world model graph consisting of a set of containers V (i.e.vertices) and relations E (i.e.edges).Let Ē ⊆ E be the subset of relations that do not have type PARTWHOLE (for which the semantics of the edges are not independent and thus need to be treated separately).Recall that the world model may also contain variables, which represent unknown quantities.Let U be the set of these variables.We can define a function ∥g∥ that converts g into an equivalent FOL expression.
∥g∥ = ∃v 1 . . . ∃v |V | ∃e 1 . . . ∃e | Ē| ∃u 1 . . . ∃u |U | ( ∥V 1 ∥ ∧ . . . ∧ ∥V |V | ∥ ∧ ∥ Ē1 ∥ ∧ . . . ∧ ∥ Ē| Ē| ∥).</p>
<p>D.2.1 Converting containers</p>
<p>Recall that each container in the world model V i ∈ V is labeled with a set of properties: the label (denote as L i ), entity (E i ), quantity (Q i ), attribute (A i ), and unit (U i ).Note that the unit property is optional depending on whether the entity E i is countable or not.If the entity is countable, the container is mapped to a definition of a set:
∥V i ∥ = Owner(v i , L i ) ∧ Measure(v i , ∥Q i ∥) ∧ ∀x ∈ v i (E i (x) ∧ A i (x)) ∧ ∥E PW,i ∥,
where E P W,i ⊆ E is the set of edges of type PARTWHOLE whose target vertex is i.Otherwise, if the entity is uncountable:
∥V i ∥ = Owner(v i , L i ) ∧ E i (v i ) ∧ A i (v i ) ∧ Measure(v i , Quantity(∥Q i ∥, U i )) ∧ ∥E PW,i ∥.
Note that the attribute and unit properties may be omitted, and if the container v i is missing a property, the corresponding conjunct is omitted as well (e.g., if the container is missing an attribute property, the conjunct A i (•) is omitted).Each quantity Q i is mapped as follows:
∥Q i ∥ = Q i , if Q i ∈ R, u j , if Q i = x j for some x j ∈ U.
Unlike other relations, the semantics of PARTWHOLE edges are not independent of each other, and so we define them here as a special case:
∥E PW,i ∥ = PartWhole({v s 1 , v s 2 , . . .}, v i ),
where s j is the index of the source vertex of the edge E PW,i j , and so {v s 1 , v s 2 , . ..} is the set of the source vertices of the PARTWHOLE edges with target vertex i.In section D.3, we provide axioms that define the semantics of each relation, including PartWhole.</p>
<p>D.2.2 Converting relations</p>
<p>Each relation Ēi ∈ Ē is also converted into a conjunction.Let s i be the index of the source vertex of Ēi , and similarly let t i be the index of the target vertex.</p>
<p>If the edge Ēi is labeled as TRANSFER, it may have the following properties: the sender (denote as S i ), recipient (R i ), entity (E i ), quantity (Q i ), attribute (A i ), and unit (U i ).Similarly to containers, the entities in relations may be countable or uncountable.For brevity, we only show the conversion for the case where the entities are countable, but the conversion of uncountable quantities mirrors that shown for containers above.In this case, the TRANSFER edge is converted:
∥ Ēi ∥ = Transfer(e i ) ∧ Source(e i , v s i ) ∧ Target(e i , v t i ) ∧ Time(v s i ) + 1 = Time(v t i ) ∧ Sender(e i , S i ) ∧ Recipient(e i , R i ) ∧ ∃r(Arg(e i , r) ∧ Measure(r, ∥Q i ∥) ∧ ∀x ∈ r(E i (x) ∧ A i (x))).
If the edge Ēi is labeled as RATE, it may have the following properties: the entity (E i ), quantity (Q i ), attribute (A i ), and unit (U).Then, the edge is converted:
∥ Ēi ∥ = Rate(e i ) ∧ Source(e i , v s i ) ∧ Target(e i , v t i ) ∧ Time(v s i ) = Time(v t i ) ∧ ∃r(Arg(e i , r) ∧ ∀y ∈ r(Measure(y, ∥Q i ∥) ∧ ∀x ∈ y(E i (x) ∧ A i (x)))).
Finally, if the edge Ēi is labeled as COMPARI-SON, it may have the following properties: the type (T i ∈ {Add, Mul}), quantity (Q i ), and unit (U i ).Then, the edge is converted:
∥ Ēi ∥ = ComparisonT i (e i ) ∧ Source(e i , v s i ) ∧ Target(e i , v t i ) ∧ Time(v s i ) = Time(v t i ) ∧ ∃r(Arg(e i , r) ∧ Measure(r, ∥Q i ∥) ∧ ∀x ∈ r(E i (x) ∧ A i (x))).
Note that in the above, the sender, recipient, attribute, and unit properties are optional.If the relation is missing any property, the corresponding conjunct is omitted (e.g., if the attribute property is missing, the corresponding term A i (x) is omitted).</p>
<p>See Figure 11 for an example application of the above conversion function.</p>
<p>Natural language representation: "James has 232 balloons.Amy has 101 balloons.How many more balloons does James have than Amy?"</p>
<p>MATHWORLD representation:</p>
<p>James has 232 balloons.Amy has 101 balloons.How many more balloons does James have than Amy?</p>
<p>Explicit(x1, balloon, add)</p>
<p>James</p>
<p>Entity: balloon Quantity: 232 Amy Entity: balloon Quantity: 101</p>
<p>First-order logic representation:
∃v1∃v2∃e1∃u1( Owner(v1, James) ∧ Measure(v1, 232) ∧ ∀x ∈ v1.balloon(x) ∧ Owner(v2, Amy) ∧ Measure(v2, 101) ∧ ∀x ∈ v2.balloon(x) ∧ ComparisonAdd(e1) ∧ Source(e1, v2) ∧ Target(e1, v1) ∧ Time(v2) = Time(v1) ∧ ∃r(Arg(e1, r) ∧ Measure(r, u1) ∧ ∀x ∈ r.balloon(x)))
Figure 11: Example of a math story problem with its equivalent representations as a world model graph and in first-order logic.</p>
<p>D.3 Semantics of relations and predicates</p>
<p>We define the semantics of each relation, starting with the RATE relation:</p>
<p>∀e∀v s ∀v t ∀r(Rate(e) ∧ Arg(e, r)
∧ Source(e, v s ) ∧ Target(e, v t ) → Partition(r, v s ) ∧ ∃m(Measure(r, m) ∧ Measure(v t , m))),
where Partition(r, v s ) denotes that r is a partition of the set v s : r is a set of disjoint subsets of v such that their union is equal to v s .More precisely:
∀x∀y Partition(x, y) ↔ ∀z, z ′ ∈ x(z ̸ = z ′ → z ∩ z ′ = ∅) ∧ y = z∈x z .
We also use the notion of a partition to define the semantics of the TRANSFER relation:</p>
<p>∀e∀v s ∀v t ∀r(Transfer(e) ∧ Arg(e, r)
∧ Source(e, v s ) ∧ Target(e, v t ) → ∃z(Owner(v s , z) ∧ Owner(v t , z) ∧ Recipient(e, z) ∧ Partition({r, v s }, v t )) ∨ ∃z(Owner(v s , z) ∧ Owner(v t , z) ∧ Sender(e, z) ∧ Partition({r, v t }, v s ))).
We define the semantics of COMPARISONADD:
∀e∀v s ∀v t ∀m s ∀m t ∀r( ComparisonAdd(e) ∧ Arg(e, r) ∧ Source(e, v s ) ∧ Target(e, v t ) ∧ Measure(v s , m s ) ∧ Measure(v t , m t ) → m s + r = m t ).
COMPARISONMUL is defined similarly.Finally, we define PARTWHOLE as a simple set partition:
∀v t ∀X( PartWhole(X, v t ) ↔ Partition(X, v t )).
We also need a theorem indicating the the containers in a PARTWHOLE relation have the same Time:
∀v t ∀X(PartWhole(X, v t ) → ∀v s ∈ X(Time(v s ) = Time(v t ))).</p>
<p>D.4 Additional theorems for reasoning</p>
<p>Additional theorems are required to enable reasoning about new containers from existing relations:</p>
<p>∀e∀r(Transfer(e) ∧ Arg(e, r)
∧ ∀x ∈ r(E(x) ∧ A(x)) → ∃v∃o∃q(Source(e, v) ∧ Owner(v, o) ∧ Measure(v, q) ∧ ∀x ∈ v(E(x) ∧ A(x)).
Note this is an axiom schema that is true for all entities E and attributes A. We define the theorem similarly for the Target of e, as well as the case where the entities are uncountable.We define similar theorems for the COMPARI-SON relation, omitted here for brevity.There is a minor difference in the theorem for the RATE relation, since its Arg is a set of sets: ∀e∀r(Rate(e) ∧ Arg(e, r)
∧ ∀x ∈ r.∀y ∈ x(E(y) ∧ A(y)) → ∃v∃o∃q(Source(e, v) ∧ Owner(v, o) ∧ Measure(v, q) ∧ ∀x ∈ v(E(x) ∧ A(x)).</p>
<p>E Annotation Details E.1 Data preprocessing</p>
<p>We segment all sentences into smaller independent clauses when possible.This is done in order to create simpler units of training data for a semantic parser.We use the Berkeley Neural Parser (Kitaev and Klein, 2018;Kitaev et al., 2019) for this task, splitting sentences recursively at the two coordinating conjunctions and and but. 14Over the three datasets we consider, 302 sentences are split in this way.Additionally, some question sentences start with a subordinate clause that introduces new information, like "If Alice bought 3 more apples today, how many apples did she end up with?".We split these into a declarative clause and an interrogative clause, and remove the leading subordinating conjunction.</p>
<p>E.2 Annotation scheme and tool</p>
<p>As mentioned in § 3, MATHWORLD considers logical forms at the sentence level.Hence, we must also annotate the world model graphs incrementally, sentence by sentence.This is done via a drag-and-drop annotation tool, ANT-NLP, built specifically for the purpose of this work. 15When annotating a problem in the tool, annotators get to build the graph incrementally one sentence at a time.Each sentence is given in a separate page, as shown in Fig. 12, and the graph from the previous sentence is carried over to the next.We save all incremental world models, as they set the basis for the sentence linearization described in App.F.1.</p>
<p>14 Some phrases with a trailing preposition are split erroneously in this way, like "Sally picked 7 lemons and Mary picked 9 lemons from the lemon tree" is split into "Sally picked 7 lemons" and "Mary picked 9 lemons from the lemon tree", pointing to the challenges of prepositional phrase attachment in neural constituency parsing (Sopena et al., 1998).We detect and correct such cases manually. 15Although the annotation tool is built specifically for annotating world models in MATHWORLD, we believe it could with relative ease be adapted to annotation of potential world models for other domains as well.The tool will be shared with other researchers by request.</p>
<p>The incremental world models are stored in json graph format. 16e want annotators to include all information included in the text that fits MATHWORLD, irrespective of the relevance to the question.Therefore, in order not to create any bias stemming from the question, we hide the question sentence until all other preceding parts have been annotated.</p>
<p>We ask annotators to follow the ordering that information is given within each sentence when adding containers and relations.For instance, a sentence "Alice has 3 apples and 4 oranges" should first be assigned a container for apples and then be assigned a container for oranges.This allows us to preserve the ordering of the text when linearizing logical forms for training data.To capture this ordering we annotate IDs for the containers and relations.The space of IDs is the set of natural numbers, and is shared between containers and relations.Ids are incremented automatically in the tool as annotators add new containers or relations.</p>
<p>The tool includes options to flag problems that require background knowledge, or where the annotator is uncertain about their annotation.They can additionally add a free text comment about their annotation for a particular problem.</p>
<p>E.3 Procedure</p>
<p>Annotation is performed by external workers, who are taught to be familiar with the semantics of MATHWORLD.We employ two annotators, hired from a small annotation company in India.17At the time of annotation, both of them were undergraduate students in technical universities.As support material, annotators are given a comprehensive guideline document, a set of example annotations and a video showcasing how annotation is performed using the tool.We follow three phases for annotation:</p>
<ol>
<li>Training phase.This phase is for annotators to learn the formalism.They are given batches of 5−7 problems at a time to annotate independently.These annotations are then discussed and, if needed, corrected in a follow-up meeting.The initial batches consist of simple problems, both conceptually and linguistically.</li>
</ol>
<p>Figure 12: Snapshot of the annotation tool interface of ANT-NLP for a particular sentence.The annotator has the option to add nodes (containers), add edges (relations) between an existing pair of nodes, navigate between text spans, navigate between math story problems, add comments and flags associated with the math story problem, and export the math story problem when its annotation is completed.A problem is considered completed when all text spans have been annotated and a variable referencing the answer has been added for the final text span.Only then can the problem be marked in the top-right corner and be exported to json format.Furthermore, a central dashboard (not shown here) allows the annotator to get an overview over the progress and navigate between problems.Question sentences are not shown in the central dashboard in order to alleviate bias.</p>
<p>After the annotators can successfully annotate these simple problems, they are gradually given more challenging ones.This phase ends when all annotators can successfully annotate most problems across all datasets.</p>
<ol>
<li>
<p>Agreement phase.Here, annotators are given the same set of 90 problems, with 30 from each dataset.They are asked to annotate these independently.This set is used to measure agreement between annotators.</p>
</li>
<li>
<p>Scale-up phase.Here, annotators are given separate datasets to annotate on their own.Some of these problems are overlapping in order to allow for agreement analysis.</p>
</li>
</ol>
<p>E.4 Agreement analysis</p>
<p>We give further details on the agreement analysis of the 125 overlapping problems discussed in § 4. As mentioned, there were 18 isomorphic disagreements between the two annotators (i.e., not weakly equivalent).Out of these, 7 were due to structural ambiguity (App.B.2), 1 was due to a type of error that was fixed during annotation check (see below), 8 due to a type of error for which a problem would be discarded during annotation check, and 2 less serious errors that would not be detected during the annotation check.Most errors were attributed to the same annotator.Ground truth data for overlapping annotations were thus taken from the annotated set of the annotator with the higher performance on the overlapping problems.There were 46 problems that had a weak equivalence agreement, but not a strong equivalence agreement.Some of these were due to errors and some were due to property ambiguity (App.B.1).The errors were mostly incurred from entering an incorrect property, seemingly by carelessness.Several such cases could be detected and corrected as they led to errors when parsing the world model json file or when applying the reasoner to the world model (App.H).Cases of property ambiguity were often due to the attribute property.</p>
<p>We additionally stratified agreement across relation type.Problems with COMPARISON relations seemed to have the lowest weak equivalence agreement, followed by RATE and TRANSFER.For strong equivalence agreement on the other hand, RATE problems had the lowest agreement, followed by TRANSFER and then PARTWHOLE.</p>
<p>E.5 Annotation check and correction</p>
<p>We performed the following checks of the annotations: whether the json could be parsed into a well-formed world model, whether applying the deterministic reasoner (App.H) would produce the correct answer and whether the annotator had flagged the problem with low confidence or provided a free text comment.Based on these we were able to detect and correct several faulty annotations.Some common errors were: entering the wrong number, entering the wrong reference variable, forgetting to the enter the reference variable, orienting the edge in the wrong direction and misspelling label names.Such errors could easily be corrected.Other more fundamental errors that could not be easily fixed led to discarding the annotation.We also spotted some cases of wrong annotated answers stemming from the original dataset, which were corrected.</p>
<p>F Conversion between World Model Graph and Logical Form</p>
<p>As mentioned in § 5.1, an integral part of our proposed MATHWORLD solver framework, and working with MATHWORLD more generally as in § 5, is the conversion between world models g and logical forms m.In this appendix section we provide details of both directions of this conversion.Both directions of the conversion are lossy to some small degree, as is mentioned in footnote 18.</p>
<p>F.1 World model graph to logical form</p>
<p>Each logical form can be viewed as a incremental graph update that consists of containers and relations based on a sentence in the problem text, which is represented as a text sequence.Containers and relations have varying arity, depending on which properties are present.This opens two possibilities.We may either split them into forms for each set of properties and have the property names explicit in the signatures (e.g., containers would have one representation each with arity 3 and 5, and two representations with arity 4), or keep the property ordering consistent and give a default null token for missing properties.We opt for the latter, and set the default null token to be none.</p>
<p>We define the following predicates:</p>
<p>• container(label, quantity, entity, attribute, unit)</p>
<p>• transfer(recipient label, sender label, quantity, entity, attribute, unit)</p>
<p>• rate(label, quantity, source entity, source attribute, source unit, target entity, target attribute, target unit)</p>
<p>• difference(target label, source label, quantity, target entity, target attribute, target unit, source entity, source attribute, source unit)</p>
<p>• explicit(target label, source label, quantity, target entity, target attribute, target unit, source entity, source attribute, source unit)</p>
<p>• part(whole label, whole entity, whole attribute, whole unit, part1 label, part1 entity, part1 attribute, part1 unit, . . ., partn label, partn entity, partn attribute, partn unit)</p>
<p>Note that for COMPARISON, the "type" property is lifted out and its value replaces "comparison" as the name of the predicates.We replace "add" and "times" by "difference" and "explicit", respectively, for practical reasons: We do not want the name of the operator that might be required to solve the problem to be confounded with the name of the predicate.Further note that the above predicates are overloaded in comparison to the ones mentioned in § 3. The reason for that is that we require additional information in order to match the linearization to existing incremental graphs (the other direction of the conversion, described in App.F.2).For instance, consider two disconnected containers in a world model graph.If one wished to present them as connected with RATE, it would be sufficient to provide the quantity property to the rate.See, e.g., how in Fig. 1, quantity is provided as the only property in the RATE relation.The other properties given above would be redundant as they are already given in the containers.For a model to be able to orient that rate, however, it needs the additional information to match to the two existing containers.</p>
<p>Note that in the case of TRANSFER, there may be two associated edges in the graph if the properties "recipient label" and "sender label" both take values other than none.However, these are both represented by a single transfer predicate as above.PARTWHOLE is the only relation whose arity varies, reflecting the number of subsets present in the PARTWHOLE construction.An alternative would have been to have one predicate per edge, but that would have introduced redundancy. 18 A sentence-level logical form often contains multiple components of the above.In these cases, we follow the ordering as introduced in text, in line with the annotated IDs.If a relation is added together with its source and/or target containers, then the containers must always precede the relation in the ordering.We enforce that the source container always precedes the target container.</p>
<p>As an example, the logical form of the sentence "In a friend group there are 5 football players and 3 tennis players" is: container(friend group, 5, player, football, none) container(friend group, 3, player, tennis, none)</p>
<p>Finally, a world model graph may have containers that have not been explicitly introduced in text.For instance, the two sentences "Alice has 5 apples.She ate 2 of them." will be represented by a world model with two containers and a TRANS-FER edge, but only the source container is explicitly mentioned in text (in the first sentence).When writing the world model graph as a logical form, we therefore discard the target container in this case.In general, this is done by discarding all containers that do not hold an explicit quantity, unless the sentence is interrogative.For interrogative sentences we want the logical form to represent the reference variable.</p>
<p>F.2 Logical form to world model graph</p>
<p>We now consider the other direction, namely that we have a sequence of logical forms m 1 , . . ., m n on the form described in the previous section and wish to convert them to a world model graph g.</p>
<p>For m 1 , we can trivially convert the logical form to a graph.Note that the relation predicates specify the properties needed to match the relation to 18 However, a drawback of our PARTWHOLE representation is that it assumes that all the part-whole edges are always introduced together in the same sentence.While this is mostly the case for the data we observe, we found the following exception: "Next on her list are the homeless people where she spent a total of $900.00.She gave $325.00 to the first set of homeless families and $260.00 to the second set of families.How much did she give to the last set of homeless families?".This is one example showing that the conversion is slightly lossy.containers as well, so if there is a relation predicate in the logical form but no source and/or target container, we can simply create those.For subsequent logical forms, we match the logical form to the graph created from preceding sentences.For relations, we must make sure that we do not create new containers linked by that relation, if any or both of those containers are already existing in the world model.We thus first match the properties corresponding to the source and target containers in the relation predicate to any possibly existing containers, and only create new ones if none are found.In addition, some sentences will just supply an update of an unknown quantity to a known value.In these cases, we do not create a new container, but match the quantity to one already existing so that we can preserve the structural information of that container.We remark that in case that the matching with already existing containers in the world model returns multiple options, we default to the most recently created one.This turns out to work well for most cases, but could be one source of loss.</p>
<p>The reference variable corresponds to the logical form of the last sentence: Interrogative sentences are mapped to logical forms the same way as declarative sentences, and the reference variable is taken as the variable in the container or relation that matches the question's logical form.</p>
<p>Finally, for predicted logical forms, we first check the logical forms for syntactic wellformedness, keeping only the parts of the logical form that are well-formed.An additional (weak) check for semantic well-formedness may match the properties to the vocabulary of the MSP, along with special tokens like "none", "world" etc.</p>
<p>G Difficult Cases to Parse</p>
<p>We estimate a high coverage of our formalism among MSPs.However, although a problem might be within semantic and conceptual coverage of MATHWORLD, the text itself might prove challenging for a parser to interpret.Here, we present two problems that are captured by MATHWORLD that put a high burden on the parser.First, consider the following problem:</p>
<p>The teacher distributes 4 candies to 2 students.Student A now has 2 more candies than Student B. Both students had 0 candies to begin with.How many candies does Student A have?</p>
<p>In this problem there is a transfer involved in the first sentence.The recipient of the transfer is not a single independent container however, but a set of two students.We have no information on how many candies these two students have individually, but we know that they collectively got 4 more than they had before.To capture this, we may represent both students as a container with a PARTWHOLE relation to the individual students, which will be the recipient of the TRANSFER.The whole problem is assigned the world model in Fig. 13.This is a faithful and correct world model, but the first sentence puts a high burden on the semantic parser: It must add 8 containers and 6 relations.Next, consider the following problem (adapted from GSM8K):</p>
<p>Zack decided to give his 3 friends 20 marbles each and kept 5. How many marbles did he initially have?</p>
<p>The first sentence conveys a lot of information.We must add a container for the total number of marbles that Zack possesses, with PARTWHOLE relations representing how many marbles Zack has left and how many his friends have.In addition, we know that there are three friends, which we represent with a RATE.See the world model in Fig. 14.However, the fact that Zack already possesses marbles is implicit from the text, and would be challenging for a parser to detect.As a partial remedy, we could introduce a "TransferEvenly" relation, which would represent a transfer of 20 to each container in a set.In this case, Zack's friends would each be represented in a container.</p>
<p>H Reasoner</p>
<p>The recursive solver takes as input a target variable and a set of visited equations.It takes all the equations containing the target variable and sorts them in increasing order of number of unknowns.Next, it iterates over the equations in this order.</p>
<p>Zack decided to give his 3 friends 20 marbles each and kept 5.</p>
<p>marbles did he initially have?If the equation only has one unknown, that unknown must be the target variable.The function then solves for the target variable and outputs the numeric value.Otherwise, it goes over the other free variables in the equation and applies the recursive function to those as target, with the equation added to the set of visited equations in order to prevent loops.Having solved for the other free variable, it substitutes its numeric value in the equation and solves for the target variable, if possible.We present pseudo-code for the deterministic reasoner in Alg. 1.</p>
<p>Note that this solver assumes a certain structure of the equations, namely, that a solution can be reached by solving a sequence of equations with one unknown.Such is indeed the case for the simple MSPs we consider.However, in the case of a general system of linear equations, this algorithm would fail as it cannot handle equations of more than one unknown.We opt for our recursive solution rather than Gaussian elimination due to runtime gains: for a system of n equations with n unknowns, Gaussian elimination runs in O(n 3 ), while our solution has worst-case complexity O(n 2 ).</p>
<p>Further note that if we extend r to be a set of variables, we can store the intermediate results in a table and get a dynamic program.This is not necessary in our case as we do not have overlapping sub-problems.</p>
<p>I Experimental Details</p>
<p>I.1 Solving pipeline Setup.As our LLM we use Codex code-davinci-002.We design a prompt with 50 ground truth examples from MAWPS and ASDIV-A.One example consists of the source sentence, the target linearized logical form, as well as the source and target of the previous sentence in the same MSP, in order to allow the model to account for dependencies between sentences.These examples are handpicked to be representative of MATHWORLD.</p>
<p>For every MSP, we then feed each sentence following the same pattern excluding the target as a suffix to the prompt, and sample the target output from Codex.The experiments were performed on the 18th of January 2023.The parameters used for sampling were the following: temperature is set to 0, max tokens is 200, frequency and presence penalty are both left at 0 and we add an additional new line stop token (which is used in the prompt to end the ground truth logical forms.World models are built incrementally using the method described in App.F.2.We apply the deterministic reasoner (App.H) to produce an answer.</p>
<p>Results.We show the results in Table 5. Observe that on average less than half of the predicted world models result in an answer (i.e. are complete).The rest of the times the reasoner is either unable to solve for the reference variable (the system of equations induced by the world model is underdetermined) or the world model lacks a reference variable.Incorrect answers are often caused by slight permutations of the correct logical forms (e.g., Codex having swapped the sender and recipient in a TRANSFER relation).If we stratify the problems by relation type, we observe that the model has the highest answer accuracy for TRANSFER and RATE, while PARTWHOLE problems have the lowest answer accuracy.This is to be expected given that the information associated with PARTWHOLE problem is not often made explicit in text ( § 3.2.4).</p>
<p>I.2 Details on constrained generation</p>
<p>The GPT 3.5 Turbo generation experiments were performed on the 24th of May 2023.The model used was gpt-3.5-turbo-0301.The sampling parameters are the same as those used during parsing (App.I.1).</p>
<p>We display the results of the other five MSPs as mentioned in § 5.3 in Table 6.Observe that in all cases, the model is able to generate problems that are faithful to the concept, number and properties of the original world model (comparing the left column and the middle column).Further note that with a temperature parameter of 0, the generated problems are rather conservative.We leave for future work to explore the implications of the sampling parameters for the generated outputs.Finally, consider the right column, where we display the MSPs generated from augmented world models.Three of the generated examples are not completely faithful to how we augmented the world models.In the first example from the top, "Lexie's brother" is provided as the recipient property in the TRANSFER relation, but in the generated example Lexie's brother is the sender.In the third example from the top, we augment the world model with a RATE, but the model instead generates a transfer type MSP.In the last example, Bob is provided as sender while Josh is provided as recipient, but the model generates a problem with these values being swapped.The other two are faithful.</p>
<p>Figure 1 :
1
Figure 1: An example of a world model in MATH-WORLD.MATHWORLD can be used to develop interpretable MSP solvers, to study the reasoning of LLMs and as a design space for generation of new MSPs.</p>
<p>Figure 4 :
4
Figure 4: Example of a world model using TRANSFER.</p>
<p>Figure 6 :
6
Figure 6: Example of a world model using RATE.</p>
<p>Figure 9 :
9
Figure 9: World model with a Transfer interpretation.</p>
<p>Figure 10 :
10
Figure 10: World model with a part-whole interpretation.</p>
<p>Figure 14 :
14
Figure 14: Hypothetical world model associated with a problem text that compresses a lot of information within a single sentence.</p>
<p>Table 1 :
1
Comparison between MATHWORLD and other MSP works that use a more fine-grained symbolics than equations alone."Annotations" refers to whether those symbolics are explicitly provided in the dataset.</p>
<p>Table 2 :
2
Size of annotated dataset in terms of number of MSPs and number of sentence-aligned logical forms (LFs), stratified by dataset of origin and split.</p>
<p>Figure2: Synthetically created question-answer pairs based on templates.Note that the quantity in the container or relation does not need to be expressed in text, but could be a variable.Such cases test the model's ability to reason over intermediate quantities.
svamp-71 Kelly has 160 nintendo games.label: kelly quantity: 160ent: gameSynthetic Container Questionattr: nintendoQ: How many {attr} {ent}s does{label} have? A: {quantity}transfer quantity: 64ent: gameHow many will she have left if sheattr: nintendogives away 64 games?sender: kellySynthetic Relation Questionlabel: kellyQ: How many {ent}s are transferredquantity: x1from {sender}?ent: gameA: {quantity}attr: nintendo</p>
<p>Table 4 displays the results.Interestingly, in more than one third of the cases that the model gets the original question right (top row), it gets the intermediate synthetic ques-
Synthetic QuestionOriginal Question Correct WrongCorrect46.0%25.7%Wrong11.0%17.3%</p>
<p>Table 4 :
4
We test whether the model gets synthetic questions about parts of the world model right and compare it against its performance on the original question.</p>
<p>Figure 5: Example of a world model using TRANSFER.
AliceAliceEntity: appleEntity: appleQuantity: 7Transfer(4, Bob, Alice)Quantity: x1BobTransfer(4, Bob, Alice)BobEntity: appleEntity: appleQuantity: 3Quantity: x2Lansing has 25 elementary schools. There are 247 students in each schomany elementary students are there altogether in Lansing?LansingLansingEntity: elem school Quantity: 25Rate(247, student,Entity: student Quantity: x1elementaryschool)</p>
<p>12
Transfer(22,Transfer(15,carrot stick,carrot stick,JamesJames)JamesJames)JamesEntity: carrot stickEntity: carrot stickEntity: carrot stickQuantity: x1Quantity: x2Quantity: x3</p>
<p>Algorithm 1: Deterministic recursive reasoner.′ ∈ eq, x ′ ̸ = x
1 function recursiveReasoner(x, visited)/<em> Prepare equations containing x thathave not been visited </em>/2eqs ← {equations containing x} \ visited/<em> Sort in increasing order of number ofunknowns </em>/3eqs ← sort(eqs, # of unknowns, increasing)4for eq ∈ eqs/<em> Go over equations in order </em>/5if solvable(x, eq)/<em> Solve for x if possible </em>/6xval ← solve(x, eq)7else /<em> Otherwise, solve recursively </em>//<em> Go over other unknowns </em>/9x ′ val ← recursiveReasoner(x, visited + eq)/<em> Substitute unknown for value </em>/10eq ← substitute(eq, x ′ , x ′ val )11if solvable(x, eq)
8 for x 12 xval ← solve(x, eq) 13 return xval 14 return xval</p>
<p>Table 5 :
5
Results on our test sets for the Codex few-shot learning model.Smatch scores (App.C) are averaged across all MSPs, including those where Codex produced an incomplete world model.
MAWPS ASDIV-A SVAMPAnswer Acc (%)33.826.911.1Complete WM (%)50.743.333.3Weak Smatch (avg.)0.760.680.59Strong Smatch (avg.) 0.760.600.38
The graphs may be cyclic. Although in practice, they tend to be acyclic.
A logical form may be empty. Such will be the case for text outside the coverage of MATHWORLD.
There may not always be an explicit possessor expressed in text. In such cases, we use the label World.
Note how the term money is not actually expressed in the problem text. Similarly, the word time will seldom be expressed in MSPs involving reasoning about time.
Note that a PARTWHOLE relation can be equivalently represented as a hyperedge.
In practice, we lemmatize all properties before performing this equivalence check.
It is possible to do so indirectly, as in ¬∃x.¬ϕ(x) ≡ ∀x.ϕ(x), but this can only be done once per sentence.
This disallows higher-order expressions, e.g., COMPAR-ISON relations between quantities expressed in TRANSFER relations. It also disallows nested possession outside of what is made possible under RATE, e.g., structures like "Alice has a house that has a shelf that has a book that has 200 pages."
We also considered the larger GSM8K dataset(Cobbe  et al., 2021), which contains problems with more reasoning steps. However, although we found MATHWORLD to cover many of its MSPs, annotation workers were unable to reliably annotate these problems. Future work may aim to augment the data to assign ground truth world model structures to longer MSPs, using techniques similar to those demonstrated in § 5.3.
We note that annotated world models are not necessarily complete (def. in § 3). Annotators were requested to only build world models that represent what is made explicit in the text. Some problems may require additional background knowledge to build a complete world model.
An alternative would be to augment r to handle expressions, giving r = 22+15. This would involve a more complex linarization scheme than that described in App. F.1 however.
We refer to the AMR guidelines for more information: https://github.com/amrisi/amr-guidelines
https://jsongraphformat.info/
There was initially a third annotator involved. However, this annotator dropped out during phase 3 as described below. At that time, it would have required a considerable time investment to hire and train yet another annotator, and so instead, we had one of the two other annotators cover up.
AcknowledgementsWe thank Arnav Mishra, Aryaman Kolhe, Devraj Thakur, Gaurav Saini and Soham Bopardikar for help with annotation work.We further thank Jakub Macina, Kumar Shridhar and Menna El-Assady for input in the early stages of the project, Ethan Wilcox and Ying Jiao for helpful feedback, and Yixiong Wang for help in implementation of a symbolic baseline solver.Andreas Opedal is partially supported by the Max Planck ETH Center for Learning Systems.Niklas Stoehr acknowledges funding from the Swiss Data Science Center.Language models are few-shot learners.In Advances in Neural Information Processing Systems, volume 33, pages 1877-1901.Curran Associates, Inc. Deng Cai and Wai Lam.2019.Core semantic first: A top-down approach for AMR parsing.In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 3799-3809, Hong Kong, China.Association for Computational Linguistics.Lexie's younger brother helped pick up all the paper clips in Lexie's room.He was able to collect 81 paper clips.If he wants to distribute the paper clips in 9 boxes, how many paper clips will each box contain?Lexie's brother has 81 paper clips.He wants to put them in 9 boxes.How many paper clips will he put in each box?RATE → TRANSFER Lexie's brother had 81 paper clips.He gave 21 to Lexie.How many paper clips does Lexie's brother have now?Kevin collected toys to use as prizes at the fair.He collected 14 stuffed animals.He also collected 18 frisbees and several yo-yos.Kevin has 50 prizes in all.How many yo-yos did Kevin collect?Kevin won 50 prizes at the fair.He won 14 stuffed animals, 18 frisbees, and some yo-yos.How many yo-yos did he win?PARTWHOLE → TRANSFER Kevin has 14 stuffed animals.He gave 5 of them to his friend.How many stuffed animals does Kevin have now?Mrs. Hilt wants to make a border around her garden.She needs 125 rocks to complete the border.She has 64 rocks.How many more rocks does she need to complete the border?Mrs. Hilt was making a rock border around her garden.She had 125 rocks to use.She used 64 rocks to make the border.How many rocks did she have left?I.3 Details on prompting using synthetic questionsThe GPT-3 probing experiments were performed on the 18th of January 2023.The model used was text-davinci-003.The sampling parameters used are the same as those used for Codex during parsing (App.I.1).In Table7, we present the templates used to create synthetic question-answer pairs for prompting large language models.Table 8: We experiment with three different types of prompts.They are displayed for the one-shot case in which one MSP in addition to the one we are trying to solve is provided in the prompt.In the above case, the model is tasked with making inference on the problem "Baker made 43 cakes and 114 pastries.If he sold 154 pastries and 78 cakes.How many more pastries than cakes did baker sell?".
MathQA: Towards interpretable math word problem solving with operation-based formalisms. Aida Amini, Saadia Gabriel, Shanchuan Lin, Rik Koncel-Kedziorski, Yejin Choi, Hannaneh Hajishirzi, 10.18653/v1/N19-1245Proceedings of the 2019 Conference of the North American Chapter. the Association for Computational Linguistics: Human Language Technologies. the 2019 Conference of the North American ChapterMinneapolis, MinnesotaAssociation for Computational Linguistics20191Long and Short Papers</p>
<p>. John R Anderson, Albert T Corbett, Kenneth R Koedinger, Ray Pelletier, 10.1207/s15327809jls0402_21995Cognitive tutors</p>
<p>The role of understanding in solving word problems. Denise Dellarosa Cummins, Walter Kintsch, Kurt Reusser, Rhonda Weimer, 10.1016/0010-0285(88)90011-4Cognitive Psychology. 2041988</p>
<p>A neural network solves, explains, and generates university math problems by program synthesis and few-shot learning at human level. Iddo Drori, Sarah Zhang, Reece Shuttleworth, Leonard Tang, Albert Lu, Elizabeth Ke, Kevin Liu, Linda Chen, Sunny Tran, Newman Cheng, Roman Wang, Nikhil Singh, Taylor L Patti, Jayson Lynch, Avi Shporer, Nakul Verma, Eugene Wu, Gilbert Strang, 10.1073/pnas.21234331192022Proceedings of the National Academy of Sciences119e2123433119</p>
<p>Compositional semantic parsing with large language models. Andrew Drozdov, Nathanael Schärli, Ekin Akyürek, Nathan Scales, Xinying Song, Xinyun Chen, Olivier Bousquet, Denny Zhou, The Eleventh International Conference on Learning Representations. 2023</p>
<p>The role of positive feedback in Intelligent Tutoring Systems. Davide Fossati, Proceedings of the ACL-08: HLT Student Research Workshop. the ACL-08: HLT Student Research WorkshopColumbus, OhioAssociation for Computational Linguistics2008</p>
<p>Learning to solve arithmetic word problems with verb categorization. Mohammad Javad Hosseini, Hannaneh Hajishirzi, Oren Etzioni, Nate Kushman, 10.3115/v1/D14-1058Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP). the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)Doha, QatarAssociation for Computational Linguistics2014</p>
<p>Learning fine-grained expressions to solve math word problems. Danqing Huang, Shuming Shi, Chin-Yew Lin, Jian Yin, 10.18653/v1/D17-1084Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. the 2017 Conference on Empirical Methods in Natural Language ProcessingCopenhagen, DenmarkAssociation for Computational Linguistics2017</p>
<p>Mental models: Towards a cognitive science of language, inference and consciousness. Philip Nicholas, Johnson-Laird , Cognitive science series. 61983Harvard University Press</p>
<p>Understanding and solving word arithmetic problems. Walter Kintsch, James G Greeno, 10.1037/0033-295x.92.1.109Psychological Review. 9211985</p>
<p>Multilingual constituency parsing with self-attention and pre-training. Nikita Kitaev, Steven Cao, Dan Klein, 10.18653/v1/P19-1340Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. the 57th Annual Meeting of the Association for Computational LinguisticsFlorence, ItalyAssociation for Computational Linguistics2019</p>
<p>Constituency parsing with a self-attentive encoder. Nikita Kitaev, Dan Klein, 10.18653/v1/P18-1249Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics. Long Papers. the 56th Annual Meeting of the Association for Computational LinguisticsMelbourne, AustraliaAssociation for Computational Linguistics20181</p>
<p>Parsing algebraic word problems into equations. Rik Koncel-Kedziorski, Hannaneh Hajishirzi, Ashish Sabharwal, Oren Etzioni, Siena Dumas, Ang , 10.1162/tacl_a_00160Transactions of the Association for Computational Linguistics. 32015</p>
<p>A themerewriting approach for generating algebra word problems. Rik Koncel-Kedziorski, Ioannis Konstas, Luke Zettlemoyer, Hannaneh Hajishirzi, 10.18653/v1/D16-1168Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing. the 2016 Conference on Empirical Methods in Natural Language ProcessingAustin, TexasAssociation for Computational Linguistics2016a</p>
<p>MAWPS: A math word problem repository. Rik Koncel-Kedziorski, Subhro Roy, Aida Amini, Nate Kushman, Hannaneh Hajishirzi, 10.18653/v1/N16-1136Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesSan Diego, CaliforniaAssociation for Computational Linguistics2016b</p>
<p>Defeasible reasoning. Robert Koons, The Stanford Encyclopedia of Philosophy. Edward N Zalta, 2022Metaphysics Research Lab, Stanford UniversitySummer 2022 edition</p>
<p>Learning to automatically solve algebra word problems. Nate Kushman, Yoav Artzi, Luke Zettlemoyer, Regina Barzilay, 10.3115/v1/P14-1026Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics. Long Papers. the 52nd Annual Meeting of the Association for Computational LinguisticsBaltimore, MarylandAssociation for Computational Linguistics20141</p>
<p>BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, Luke Zettlemoyer, 10.18653/v1/2020.acl-main.7032020</p>
<p>Solving quantitative reasoning problems with language models. Aitor Lewkowycz, Anders Johan Andreassen, David Dohan, Ethan Dyer, Henryk Michalewski, Vinay Venkatesh Ramasesh, Ambrose Slone, Cem Anil, Imanol Schlag, Theo Gutman-Solo, Yuhuai Wu, Behnam Neyshabur, Guy Gur-Ari, Vedant Misra, Advances in Neural Information Processing Systems. 2022</p>
<p>Language models of code are few-shot commonsense learners. Aman Madaan, Shuyan Zhou, Uri Alon, Yiming Yang, Graham Neubig, Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing. the 2022 Conference on Empirical Methods in Natural Language ProcessingAbu Dhabi, United Arab EmiratesAssociation for Computational Linguistics2022</p>
<p>Situations, actions, and causal laws. John Mccarthy, 1963In Stanford Artificial Intelligence Laboratory and Memo (Stanford Artificial Intelligence Laboratory</p>
<p>A diverse corpus for evaluating and developing English math word problem solvers. Chao-Chun Shen-Yun Miao, Keh-Yih Liang, Su, 10.18653/v1/2020.acl-main.92Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. the 58th Annual Meeting of the Association for Computational LinguisticsOnline. Association for Computational Linguistics2020</p>
<p>Learning to use formulas to solve simple arithmetic problems. Arindam Mitra, Chitta Baral, 10.18653/v1/P16-1202Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics. Long Papers. the 54th Annual Meeting of the Association for Computational LinguisticsBerlin, GermanyAssociation for Computational Linguistics20161</p>
<p>Training language models to follow instructions with human feedback. Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul Christiano, Jan Leike, and Ryan Lowe. 2022</p>
<p>Are NLP models really able to solve simple math word problems?. Arkil Patel, Satwik Bhattamishra, Navin Goyal, 10.18653/v1/2021.naacl-main.168Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesOnline. Association for Computational Linguistics2021</p>
<p>Personalized mathematical word problem generation. Oleksandr Polozov, O' Eleanor, Adam M Rourke, Luke Smith, Sumit Zettlemoyer, Zoran Gulwani, Popovic, International Joint Conference on Artificial Intelligence. 2015</p>
<p>A call for clarity in reporting BLEU scores. Matt Post, 10.18653/v1/W18-6319Proceedings of the Third Conference on Machine Translation: Research Papers. the Third Conference on Machine Translation: Research PapersBrussels, BelgiumAssociation for Computational Linguistics2018</p>
<p>Improving compositional generalization with latent structure and data augmentation. Linlu Qiu, Peter Shaw, Panupong Pasupat, Pawel Nowak, Tal Linzen, Fei Sha, Kristina Toutanova, 10.18653/v1/2022.naacl-main.323Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesSeattle, United StatesAssociation for Computational Linguistics2022</p>
<p>Language Models are Unsupervised Multitask Learners. Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, 2019</p>
<p>Exploring the limits of transfer learning with a unified text-to-text transformer. Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, Peter J Liu, Journal of Machine Learning Research. 211402020</p>
<p>The Frame Problem in Situation the Calculus: A Simple Solution (Sometimes) and a Completeness Result for Goal Regression. Raymond Reiter, 10.5555/132218.1322391991Academic Press Professional, IncUSA</p>
<p>Solving general arithmetic word problems. Subhro Roy, Dan Roth, 10.18653/v1/D15-1202Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing. the 2015 Conference on Empirical Methods in Natural Language ProcessingLisbon, PortugalAssociation for Computational Linguistics2015</p>
<p>Unit dependency graph and its application to arithmetic word problem solving. Subhro Roy, Dan Roth, 10.5555/3298483.3298682Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence, AAAI'17. the Thirty-First AAAI Conference on Artificial Intelligence, AAAI'17AAAI Press2017</p>
<p>Mapping to declarative knowledge for word problem solving. Subhro Roy, Dan Roth, 10.1162/tacl_a_00012Transactions of the Association for Computational Linguistics. 20186</p>
<p>Language models are greedy reasoners: A systematic formal analysis of chain-of-thought. Abulhair Saparov, He He, International Conference on Learning Representations (ICLR). 2023</p>
<p>Towards general natural language understanding with probabilistic worldbuilding. Abulhair Saparov, Tom M Mitchell, 10.1162/tacl_a_00463Transactions of the Association for Computational Linguistics. 102022</p>
<p>Constrained language models yield few-shot semantic parsers. Richard Shin, Christopher Lin, Sam Thomson, Charles Chen, Subhro Roy, Emmanouil Antonios Platanios, Adam Pauls, Dan Klein, Jason Eisner, Benjamin Van Durme, 10.18653/v1/2021.emnlp-main.608Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. the 2021 Conference on Empirical Methods in Natural Language ProcessingDominican Republic. Association for Computational Linguistics2021Online and Punta Cana</p>
<p>Automatic generation of socratic subquestions for teaching math word problems. Kumar Shridhar, Jakub Macina, Mennatallah El-Assady, Tanmay Sinha, Manu Kapur, Mrinmaya Sachan, Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing. the 2022 Conference on Empirical Methods in Natural Language ProcessingAbu Dhabi, United Arab EmiratesAssociation for Computational Linguistics2022</p>
<p>Distilling reasoning capabilities into smaller language models. Kumar Shridhar, Alessandro Stolfo, Mrinmaya Sachan, Findings of the Association for Computational Linguistics: ACL 2023. Toronto, Canada2023</p>
<p>A connectionist approach to prepositional phrase attachment for real world texts. M Josep, Agusti Sopena, Joan L Lloberas, Moliner, 10.3115/980691.98077036th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics. Montreal, Quebec, CanadaAssociation for Computational Linguistics19982</p>
<p>Question generation for adaptive education. Megha Srivastava, Noah Goodman, 10.18653/v1/2021.acl-short.88Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing. the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language ProcessingOnline. Association for Computational Linguistics20212Short Papers)</p>
<p>What makes certain arithmetic word problems involving the comparison of sets so difficult for children. Elsbeth Stern, Journal of Educational Psychology. 851993</p>
<p>Bernhard Schölkopf, and Mrinmaya Sachan. 2023. A causal framework to quantify the robustness of mathematical reasoning with language models. Alessandro Stolfo, Zhijing Jin, Kumar Shridhar, Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics. the 61st Annual Meeting of the Association for Computational LinguisticsToronto, Canada</p>
<p>ProofWriter: Generating implications, proofs, and abductive statements over natural language. Oyvind Tafjord, Bhavana Dalvi, Peter Clark, 10.18653/v1/2021.findings-acl.317Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021. Online. Association for Computational Linguistics2021</p>
<p>Chain of thought prompting elicits reasoning in large language models. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed Chi, Quoc Le, Denny Zhou, 10.48550/ARXIV.2201.11903arXiv2022220111903</p>
<p>A goal-driven tree-structured neural model for math word problems. Zhipeng Xie, Shichao Sun, 10.24963/ijcai.2019/736Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI-19. the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI-192019</p>
<p>Peng-Jian Yang, Ying Ting Chen, Yuechan Chen, Daniel Cer, arXiv, 2104.07307NT5?! Training T5 to perform numerical reasoning. 2021</p>
<p>LogicSolver: Towards interpretable math word problem solving with logical prompt-enhanced learning. Zhicheng Yang, Jinghui Qin, Jiaqi Chen, Liang Lin, Xiaodan Liang, Findings of the Association for Computational Linguistics: EMNLP 2022. Abu Dhabi, United Arab EmiratesAssociation for Computational Linguistics2022</p>
<p>AMR parsing as sequence-tograph transduction. Sheng Zhang, Xutai Ma, Kevin Duh, Benjamin Van Durme, 10.18653/v1/P19-1009Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. the 57th Annual Meeting of the Association for Computational LinguisticsFlorence, ItalyAssociation for Computational Linguistics2019</p>
<p>Bertscore: Evaluating text generation with bert. Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q Weinberger, Yoav Artzi, International Conference on Learning Representations. 2020</p>
<p>Leastto-most prompting enables complex reasoning in large language models. Denny Zhou, Nathanael Schärli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schuurmans, Olivier Bousquet, Quoc Le, Ed Chi, International Conference on Learning Representations (ICLR). 2023</p>
<p>Delivering hints in a dialogue-based intelligent tutoring system. Yujian Zhou, Reva Freedman, Michael Glass, Joel A Michael, Allen A Rovick, Martha W Evens, Proceedings of the Sixteenth National Conference on Artificial Intelligence and the Eleventh Innovative Applications of Artificial Intelligence Conference Innovative Applications of Artificial Intelligence, AAAI '99/IAAI '99. the Sixteenth National Conference on Artificial Intelligence and the Eleventh Innovative Applications of Artificial Intelligence Conference Innovative Applications of Artificial Intelligence, AAAI '99/IAAI '99USAAmerican Association for Artificial Intelligence1999</p>            </div>
        </div>

    </div>
</body>
</html>