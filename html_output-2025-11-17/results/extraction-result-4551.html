<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-4551 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-4551</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-4551</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-100.html">extraction-schema-100</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems, methods, or approaches that use large language models (LLMs) to extract information from, synthesize, or generate theories from multiple scientific papers.</div>
                <p><strong>Paper ID:</strong> paper-b1b45a5cd4532411bcbbcb9150e6efc55e72f9a6</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/b1b45a5cd4532411bcbbcb9150e6efc55e72f9a6" target="_blank">ORKG ASK: a Neuro-symbolic Scholarly Search and Exploration System</a></p>
                <p><strong>Paper Venue:</strong> International Conference on Semantic Systems</p>
                <p><strong>Paper TL;DR:</strong> This work takes a neuro-symbolic approach to scholarly search and exploration by leveraging state-of-the-art components, including semantic search, Large Language Models (LLMs), and Knowledge Graphs (KGs), and composes a set of relevant articles.</p>
                <p><strong>Paper Abstract:</strong> Purpose: Finding scholarly articles is a time-consuming and cumbersome activity, yet crucial for conducting science. Due to the growing number of scholarly articles, new scholarly search systems are needed to effectively assist researchers in finding relevant literature. Methodology: We take a neuro-symbolic approach to scholarly search and exploration by leveraging state-of-the-art components, including semantic search, Large Language Models (LLMs), and Knowledge Graphs (KGs). The semantic search component composes a set of relevant articles. From this set of articles, information is extracted and presented to the user. Findings: The presented system, called ORKG ASK (Assistant for Scientific Knowledge), provides a production-ready search and exploration system. Our preliminary evaluation indicates that our proposed approach is indeed suitable for the task of scholarly information retrieval. Value: With ORKG ASK, we present a next-generation scholarly search and exploration system and make it available online. Additionally, the system components are open source with a permissive license.</p>
                <p><strong>Cost:</strong> 0.014</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e4551.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e4551.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems, methods, or approaches that use large language models (LLMs) to extract information from, synthesize, or generate theories from multiple scientific papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ORKG ASK</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ORKG ASK (Assistant for Scientific Knowledge)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A production-ready neuro-symbolic scholarly search and exploration system that combines semantic (neural) search, a large language model for question answering and information extraction, and knowledge graphs for fine-grained extraction and curation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>ORKG ASK</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A pipeline combining (1) semantic neural search (vector embeddings + Qdrant) to retrieve relevant documents from the CORE dataset, (2) an LLM-based information extraction and question-answering component prompted with the retrieved context (RAG-style), and (3) symbolic KG components (entity linking via DBpedia Spotlight and Knowledge Graphs) for fine-grained extraction, filtering and curation. The interface supports user-formulated research questions, filtering, caching of LLM results to reduce calls, export features, entity linking for concept-based filtering, and configurable columns for extracted properties (e.g., summary, materials, methods, results).</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td>Mistral Instruct 7B v0.2</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_technique</strong></td>
                            <td>Retrieval-Augmented Generation (RAG)-style: embedding-based retrieval (Nomic embeddings + Qdrant) to obtain top-n relevant articles, then LLM prompting over that retrieved context to extract structured properties (summary, materials, methods, results) and to answer the research question; symbolic entity linking (DBpedia Spotlight) and KG-based curation augment extraction.</td>
                        </tr>
                        <tr>
                            <td><strong>synthesis_technique</strong></td>
                            <td>LLM synthesizes answers from the context of multiple retrieved papers (prompted on top-n documents; defaults to synthesizing from the first five displayed results for a concise answer). The Knowledge Graph and entity links are used to structure, filter, and curate aggregated information.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td>Configurable top-n retrieved documents; the UI shows synthesized answer of the first five displayed results (default synthesis uses 5), and information extraction operates over the top-n retrieved articles.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_topic</strong></td>
                            <td>General scholarly literature (multidisciplinary), using the CORE dataset (metadata, abstracts, and full text where available).</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Synthesized answers to research questions, per-article extracted properties (summary, materials, methods, results), entity-linked structured results, exportable CSV/ORKG CSV and bibliographic exports.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Usability-oriented metrics: 5-point user satisfaction questionnaire and UMUX-Lite (usability) score; no automated extraction/factuality metrics reported in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Usability results: 30 participants; general user satisfaction reported as 'relatively satisfied'; UMUX-Lite overall score = 65.2. No quantitative metrics reported for extraction accuracy, factuality, or synthesis quality.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>No baseline system comparison reported (no direct comparisons to other extraction/synthesis systems).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Not applicable (no baseline comparisons provided).</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Combining semantic search, LLMs, and knowledge graphs yields a usable, production-ready scholarly search tool; the neuro-symbolic pipeline enables extraction of structured properties and synthesized answers; caching LLM outputs reduces resource usage; entity linking and KGs support fine-grained filtering and curation.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>Preliminary evaluation only (limited to usability); the system does not always meet some users' requirements (some user queries are invalid or unanswerable); provenance for extracted information is not yet provided (planned future work); need to expand KG growth and perform more comprehensive evaluations. Authors also critique closed-source competitor systems for lack of reproducibility but do not provide extraction-quality comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>scaling_behavior</strong></td>
                            <td>No empirical scaling study reported; design includes caching to reduce LLM calls and plans to grow the KG automatically while the system is used, but no measured trends with respect to number of papers or model size are given.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'ORKG ASK: a Neuro-symbolic Scholarly Search and Exploration System', 'publication_date_yy_mm': '2024-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4551.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e4551.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems, methods, or approaches that use large language models (LLMs) to extract information from, synthesize, or generate theories from multiple scientific papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RAG</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Retrieval-Augmented Generation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A pipeline for knowledge-intensive NLP tasks where relevant documents are retrieved (typically via vector retrieval), the user query is augmented with that context, and a generative model produces the final response conditioned on the retrieved context.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Retrieval-augmented generation for knowledge-intensive nlp tasks</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Retrieval-Augmented Generation (RAG)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Three-step paradigm: (1) Retrieval: retrieve relevant documents (often via vector embeddings and a vector store); (2) Augmentation: augment the query or build a prompt with retrieved context; (3) Generation: use an LLM to generate the answer conditioned on that context. In ORKG ASK the pipeline is implemented using Nomic embeddings + Qdrant for retrieval and Mistral Instruct 7B for generation, applied to top-n scholarly articles.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td>Model-agnostic in concept; in this paper implemented with Mistral Instruct 7B v0.2</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_technique</strong></td>
                            <td>Embedding-based retrieval for context followed by LLM generation (question-answering and property extraction) over the retrieved passages; caching of generated outputs is used to avoid repeated LLM calls.</td>
                        </tr>
                        <tr>
                            <td><strong>synthesis_technique</strong></td>
                            <td>LLM conditions on multiple retrieved documents to synthesize answers; synthesis performed by concatenating or otherwise supplying retrieved contexts to the LLM prompt (RAG-style).</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td>Variable; depends on retrieval. In ORKG ASK the system uses top-n retrieved documents and synthesizes concise answers using the first five displayed results by default.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_topic</strong></td>
                            <td>General knowledge-intensive NLP tasks; here applied to scholarly literature (multidisciplinary CORE dataset).</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Generated answers, structured extracted properties, summaries derived from multiple documents.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Not specified in this paper for RAG performance (paper references original RAG literature for method).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Not compared within this paper (RAG cited as the common approach used by similar systems).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Not applicable (no within-paper baseline comparisons).</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>RAG is a common and appropriate approach for enabling LLMs to use external document context when extracting or synthesizing information across multiple papers; ORKG ASK adopts a RAG-like pipeline for scholarly extraction.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>Paper notes general concerns about reproducibility for closed-source systems that also use RAG; resource usage of LLM calls is discussed (mitigated by caching), but no empirical RAG-specific failure modes (e.g., hallucination rates) are measured here.</td>
                        </tr>
                        <tr>
                            <td><strong>scaling_behavior</strong></td>
                            <td>Not empirically evaluated in this paper; authors note design choices (caching, configurable top-n) that affect resource scaling but provide no measured scaling curves.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'ORKG ASK: a Neuro-symbolic Scholarly Search and Exploration System', 'publication_date_yy_mm': '2024-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4551.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e4551.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems, methods, or approaches that use large language models (LLMs) to extract information from, synthesize, or generate theories from multiple scientific papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Neuro-symbolic approach</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Neuro-symbolic Scholarly Search and Exploration (neuro-symbolic AI)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An approach combining neural components (semantic/embedding-based retrieval and LLMs) with symbolic components (entity linking and Knowledge Graphs) to extract, synthesize, and curate knowledge from scholarly documents.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Neuro-symbolic approach (semantic search + LLM + KG)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Integrated architecture where neural modules perform semantic search and LLM-based extraction/synthesis, while symbolic modules (entity linking via DBpedia Spotlight and Knowledge Graphs) provide structured representations, fine-grained extraction, filtering and curation. The symbolic layer is built offline for entity linking and stored in the data store to support filtering and KG population.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td>Mistral Instruct 7B v0.2 (as the neural-generation component within the neuro-symbolic pipeline described in this paper).</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_technique</strong></td>
                            <td>Embedding-based retrieval to gather context, LLM prompting for extraction, plus symbolic entity linking for structure and curation (hybrid extraction).</td>
                        </tr>
                        <tr>
                            <td><strong>synthesis_technique</strong></td>
                            <td>LLM-based synthesis over retrieved multi-document context; Knowledge Graph integration to structure and filter synthesized/extracted content.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td>Configurable top-n retrieval; defaults and UI syntheses use five displayed results for concise answers, but the pipeline is designed to operate over larger retrieved sets.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_topic</strong></td>
                            <td>Scholarly literature broadly (CORE dataset, multidisciplinary).</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Synthesized answers, structured extracted properties, KG entries / curated entity-linked outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Usability-focused metrics used in paper (5-point satisfaction and UMUX-Lite); no automated extraction or synthesis correctness metrics reported for the neuro-symbolic pipeline.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Usability: UMUX-Lite score = 65.2; users relatively satisfied. No quantitative extraction/synthesis accuracy results provided.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>No comparative baseline provided for the neuro-symbolic approach in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Not applicable (no baseline comparisons).</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Neuro-symbolic integration yields a usable system for scholarly search; KGs and entity linking improve fine-grained retrieval and curation; caching and selective LLM prompting reduce resource consumption; further extensions (provenance, larger KG population) are planned.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>Limited evaluation focused on usability rather than extraction fidelity; provenance of extracted statements not yet implemented; need for more comprehensive evaluation to better match user expectations; scalability and factuality under larger document sets not empirically measured here.</td>
                        </tr>
                        <tr>
                            <td><strong>scaling_behavior</strong></td>
                            <td>No empirical scaling analysis reported; authors plan to grow the KG automatically as usage increases but provide no measured scaling behaviour.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'ORKG ASK: a Neuro-symbolic Scholarly Search and Exploration System', 'publication_date_yy_mm': '2024-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4551.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e4551.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems, methods, or approaches that use large language models (LLMs) to extract information from, synthesize, or generate theories from multiple scientific papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Elicit</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Elicit (AI-assisted literature review system)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An AI-supported scholarly search system that provides active assistance via automatic information extraction for literature reviews (system is closed-source; specifics of model/data are not disclosed in this paper).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Elicit</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Mentioned as an example of AI-supported scholarly search systems that provide active assistance by automatically extracting information from articles; the paper notes details (model and dataset) are not open/available, making reproducibility harder.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>extraction_technique</strong></td>
                            <td>Not specified in this paper; authors state such systems commonly use RAG-like approaches but do not provide confirmed technical details for Elicit.</td>
                        </tr>
                        <tr>
                            <td><strong>synthesis_technique</strong></td>
                            <td>Not specified in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_topic</strong></td>
                            <td>Scholarly literature / literature review assistance (general).</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Likely synthesized literature-review assistance (not specified in this paper).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Authors cite Elicit as an example of systems that actively assist literature exploration, but indicate a lack of open-source transparency makes reproducibility and systematic-review suitability challenging.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>Closed-source nature and undisclosed models/datasets reduces reproducibility; further details are not provided in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>scaling_behavior</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'ORKG ASK: a Neuro-symbolic Scholarly Search and Exploration System', 'publication_date_yy_mm': '2024-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4551.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e4551.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems, methods, or approaches that use large language models (LLMs) to extract information from, synthesize, or generate theories from multiple scientific papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Consensus</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Consensus (AI-supported scholarly search system)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An AI-supported literature search system cited as an example that provides active assistance by extracting information automatically from scholarly articles; details not disclosed in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Consensus</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Mentioned among examples of commercial/closed-source AI-supported scholarly search systems that provide automatic information extraction and active assistance; the authors note these systems are not open-source and details are unknown.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>extraction_technique</strong></td>
                            <td>Not specified here; authors suggest such systems typically employ retrieval + generative approaches (RAG-style) but do not confirm for Consensus.</td>
                        </tr>
                        <tr>
                            <td><strong>synthesis_technique</strong></td>
                            <td>Not specified in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_topic</strong></td>
                            <td>Scholarly literature (general).</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Likely synthesized answers/summaries (not specified).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Cited as an example of non-open-source systems that provide active assistance; authors emphasize reproducibility concerns due to lack of transparency.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>Closed-source limits reproducibility; no further technical details available in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>scaling_behavior</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'ORKG ASK: a Neuro-symbolic Scholarly Search and Exploration System', 'publication_date_yy_mm': '2024-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4551.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e4551.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems, methods, or approaches that use large language models (LLMs) to extract information from, synthesize, or generate theories from multiple scientific papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Scispace</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Scispace (AI-supported scholarly search system)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An AI-assisted document understanding/search platform cited as an example of systems that actively extract and summarize information from scholarly literature; technical details are not provided in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Scispace</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Mentioned alongside other commercial AI-assisted literature tools (Elicit, Consensus) that provide automatic information extraction and active assistance; paper notes lack of open-source details prevents reproducibility assessment.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>extraction_technique</strong></td>
                            <td>Not specified here; authors imply such systems often use retrieval-augmented generation approaches but do not confirm specifics for Scispace.</td>
                        </tr>
                        <tr>
                            <td><strong>synthesis_technique</strong></td>
                            <td>Not specified in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_topic</strong></td>
                            <td>Scholarly literature and document understanding (general).</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Presumably synthesized summaries/answers (not specified).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Included as part of a set of AI-assisted literature tools; lack of openness in these systems is highlighted as a reproducibility concern.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>Details of models and datasets not disclosed; reproducibility issues noted.</td>
                        </tr>
                        <tr>
                            <td><strong>scaling_behavior</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'ORKG ASK: a Neuro-symbolic Scholarly Search and Exploration System', 'publication_date_yy_mm': '2024-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Retrieval-augmented generation for knowledge-intensive nlp tasks <em>(Rating: 2)</em></li>
                <li>Artificial Intelligence for Literature Reviews: Opportunities and Challenges <em>(Rating: 2)</em></li>
                <li>Improving access to scientific literature with knowledge graphs <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-4551",
    "paper_id": "paper-b1b45a5cd4532411bcbbcb9150e6efc55e72f9a6",
    "extraction_schema_id": "extraction-schema-100",
    "extracted_data": [
        {
            "name_short": "ORKG ASK",
            "name_full": "ORKG ASK (Assistant for Scientific Knowledge)",
            "brief_description": "A production-ready neuro-symbolic scholarly search and exploration system that combines semantic (neural) search, a large language model for question answering and information extraction, and knowledge graphs for fine-grained extraction and curation.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "ORKG ASK",
            "system_description": "A pipeline combining (1) semantic neural search (vector embeddings + Qdrant) to retrieve relevant documents from the CORE dataset, (2) an LLM-based information extraction and question-answering component prompted with the retrieved context (RAG-style), and (3) symbolic KG components (entity linking via DBpedia Spotlight and Knowledge Graphs) for fine-grained extraction, filtering and curation. The interface supports user-formulated research questions, filtering, caching of LLM results to reduce calls, export features, entity linking for concept-based filtering, and configurable columns for extracted properties (e.g., summary, materials, methods, results).",
            "llm_model_used": "Mistral Instruct 7B v0.2",
            "extraction_technique": "Retrieval-Augmented Generation (RAG)-style: embedding-based retrieval (Nomic embeddings + Qdrant) to obtain top-n relevant articles, then LLM prompting over that retrieved context to extract structured properties (summary, materials, methods, results) and to answer the research question; symbolic entity linking (DBpedia Spotlight) and KG-based curation augment extraction.",
            "synthesis_technique": "LLM synthesizes answers from the context of multiple retrieved papers (prompted on top-n documents; defaults to synthesizing from the first five displayed results for a concise answer). The Knowledge Graph and entity links are used to structure, filter, and curate aggregated information.",
            "number_of_papers": "Configurable top-n retrieved documents; the UI shows synthesized answer of the first five displayed results (default synthesis uses 5), and information extraction operates over the top-n retrieved articles.",
            "domain_or_topic": "General scholarly literature (multidisciplinary), using the CORE dataset (metadata, abstracts, and full text where available).",
            "output_type": "Synthesized answers to research questions, per-article extracted properties (summary, materials, methods, results), entity-linked structured results, exportable CSV/ORKG CSV and bibliographic exports.",
            "evaluation_metrics": "Usability-oriented metrics: 5-point user satisfaction questionnaire and UMUX-Lite (usability) score; no automated extraction/factuality metrics reported in this paper.",
            "performance_results": "Usability results: 30 participants; general user satisfaction reported as 'relatively satisfied'; UMUX-Lite overall score = 65.2. No quantitative metrics reported for extraction accuracy, factuality, or synthesis quality.",
            "comparison_baseline": "No baseline system comparison reported (no direct comparisons to other extraction/synthesis systems).",
            "performance_vs_baseline": "Not applicable (no baseline comparisons provided).",
            "key_findings": "Combining semantic search, LLMs, and knowledge graphs yields a usable, production-ready scholarly search tool; the neuro-symbolic pipeline enables extraction of structured properties and synthesized answers; caching LLM outputs reduces resource usage; entity linking and KGs support fine-grained filtering and curation.",
            "limitations_challenges": "Preliminary evaluation only (limited to usability); the system does not always meet some users' requirements (some user queries are invalid or unanswerable); provenance for extracted information is not yet provided (planned future work); need to expand KG growth and perform more comprehensive evaluations. Authors also critique closed-source competitor systems for lack of reproducibility but do not provide extraction-quality comparisons.",
            "scaling_behavior": "No empirical scaling study reported; design includes caching to reduce LLM calls and plans to grow the KG automatically while the system is used, but no measured trends with respect to number of papers or model size are given.",
            "uuid": "e4551.0",
            "source_info": {
                "paper_title": "ORKG ASK: a Neuro-symbolic Scholarly Search and Exploration System",
                "publication_date_yy_mm": "2024-12"
            }
        },
        {
            "name_short": "RAG",
            "name_full": "Retrieval-Augmented Generation",
            "brief_description": "A pipeline for knowledge-intensive NLP tasks where relevant documents are retrieved (typically via vector retrieval), the user query is augmented with that context, and a generative model produces the final response conditioned on the retrieved context.",
            "citation_title": "Retrieval-augmented generation for knowledge-intensive nlp tasks",
            "mention_or_use": "use",
            "system_name": "Retrieval-Augmented Generation (RAG)",
            "system_description": "Three-step paradigm: (1) Retrieval: retrieve relevant documents (often via vector embeddings and a vector store); (2) Augmentation: augment the query or build a prompt with retrieved context; (3) Generation: use an LLM to generate the answer conditioned on that context. In ORKG ASK the pipeline is implemented using Nomic embeddings + Qdrant for retrieval and Mistral Instruct 7B for generation, applied to top-n scholarly articles.",
            "llm_model_used": "Model-agnostic in concept; in this paper implemented with Mistral Instruct 7B v0.2",
            "extraction_technique": "Embedding-based retrieval for context followed by LLM generation (question-answering and property extraction) over the retrieved passages; caching of generated outputs is used to avoid repeated LLM calls.",
            "synthesis_technique": "LLM conditions on multiple retrieved documents to synthesize answers; synthesis performed by concatenating or otherwise supplying retrieved contexts to the LLM prompt (RAG-style).",
            "number_of_papers": "Variable; depends on retrieval. In ORKG ASK the system uses top-n retrieved documents and synthesizes concise answers using the first five displayed results by default.",
            "domain_or_topic": "General knowledge-intensive NLP tasks; here applied to scholarly literature (multidisciplinary CORE dataset).",
            "output_type": "Generated answers, structured extracted properties, summaries derived from multiple documents.",
            "evaluation_metrics": "Not specified in this paper for RAG performance (paper references original RAG literature for method).",
            "performance_results": null,
            "comparison_baseline": "Not compared within this paper (RAG cited as the common approach used by similar systems).",
            "performance_vs_baseline": "Not applicable (no within-paper baseline comparisons).",
            "key_findings": "RAG is a common and appropriate approach for enabling LLMs to use external document context when extracting or synthesizing information across multiple papers; ORKG ASK adopts a RAG-like pipeline for scholarly extraction.",
            "limitations_challenges": "Paper notes general concerns about reproducibility for closed-source systems that also use RAG; resource usage of LLM calls is discussed (mitigated by caching), but no empirical RAG-specific failure modes (e.g., hallucination rates) are measured here.",
            "scaling_behavior": "Not empirically evaluated in this paper; authors note design choices (caching, configurable top-n) that affect resource scaling but provide no measured scaling curves.",
            "uuid": "e4551.1",
            "source_info": {
                "paper_title": "ORKG ASK: a Neuro-symbolic Scholarly Search and Exploration System",
                "publication_date_yy_mm": "2024-12"
            }
        },
        {
            "name_short": "Neuro-symbolic approach",
            "name_full": "Neuro-symbolic Scholarly Search and Exploration (neuro-symbolic AI)",
            "brief_description": "An approach combining neural components (semantic/embedding-based retrieval and LLMs) with symbolic components (entity linking and Knowledge Graphs) to extract, synthesize, and curate knowledge from scholarly documents.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "Neuro-symbolic approach (semantic search + LLM + KG)",
            "system_description": "Integrated architecture where neural modules perform semantic search and LLM-based extraction/synthesis, while symbolic modules (entity linking via DBpedia Spotlight and Knowledge Graphs) provide structured representations, fine-grained extraction, filtering and curation. The symbolic layer is built offline for entity linking and stored in the data store to support filtering and KG population.",
            "llm_model_used": "Mistral Instruct 7B v0.2 (as the neural-generation component within the neuro-symbolic pipeline described in this paper).",
            "extraction_technique": "Embedding-based retrieval to gather context, LLM prompting for extraction, plus symbolic entity linking for structure and curation (hybrid extraction).",
            "synthesis_technique": "LLM-based synthesis over retrieved multi-document context; Knowledge Graph integration to structure and filter synthesized/extracted content.",
            "number_of_papers": "Configurable top-n retrieval; defaults and UI syntheses use five displayed results for concise answers, but the pipeline is designed to operate over larger retrieved sets.",
            "domain_or_topic": "Scholarly literature broadly (CORE dataset, multidisciplinary).",
            "output_type": "Synthesized answers, structured extracted properties, KG entries / curated entity-linked outputs.",
            "evaluation_metrics": "Usability-focused metrics used in paper (5-point satisfaction and UMUX-Lite); no automated extraction or synthesis correctness metrics reported for the neuro-symbolic pipeline.",
            "performance_results": "Usability: UMUX-Lite score = 65.2; users relatively satisfied. No quantitative extraction/synthesis accuracy results provided.",
            "comparison_baseline": "No comparative baseline provided for the neuro-symbolic approach in this paper.",
            "performance_vs_baseline": "Not applicable (no baseline comparisons).",
            "key_findings": "Neuro-symbolic integration yields a usable system for scholarly search; KGs and entity linking improve fine-grained retrieval and curation; caching and selective LLM prompting reduce resource consumption; further extensions (provenance, larger KG population) are planned.",
            "limitations_challenges": "Limited evaluation focused on usability rather than extraction fidelity; provenance of extracted statements not yet implemented; need for more comprehensive evaluation to better match user expectations; scalability and factuality under larger document sets not empirically measured here.",
            "scaling_behavior": "No empirical scaling analysis reported; authors plan to grow the KG automatically as usage increases but provide no measured scaling behaviour.",
            "uuid": "e4551.2",
            "source_info": {
                "paper_title": "ORKG ASK: a Neuro-symbolic Scholarly Search and Exploration System",
                "publication_date_yy_mm": "2024-12"
            }
        },
        {
            "name_short": "Elicit",
            "name_full": "Elicit (AI-assisted literature review system)",
            "brief_description": "An AI-supported scholarly search system that provides active assistance via automatic information extraction for literature reviews (system is closed-source; specifics of model/data are not disclosed in this paper).",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "Elicit",
            "system_description": "Mentioned as an example of AI-supported scholarly search systems that provide active assistance by automatically extracting information from articles; the paper notes details (model and dataset) are not open/available, making reproducibility harder.",
            "llm_model_used": null,
            "extraction_technique": "Not specified in this paper; authors state such systems commonly use RAG-like approaches but do not provide confirmed technical details for Elicit.",
            "synthesis_technique": "Not specified in this paper.",
            "number_of_papers": null,
            "domain_or_topic": "Scholarly literature / literature review assistance (general).",
            "output_type": "Likely synthesized literature-review assistance (not specified in this paper).",
            "evaluation_metrics": null,
            "performance_results": null,
            "comparison_baseline": null,
            "performance_vs_baseline": null,
            "key_findings": "Authors cite Elicit as an example of systems that actively assist literature exploration, but indicate a lack of open-source transparency makes reproducibility and systematic-review suitability challenging.",
            "limitations_challenges": "Closed-source nature and undisclosed models/datasets reduces reproducibility; further details are not provided in the paper.",
            "scaling_behavior": null,
            "uuid": "e4551.3",
            "source_info": {
                "paper_title": "ORKG ASK: a Neuro-symbolic Scholarly Search and Exploration System",
                "publication_date_yy_mm": "2024-12"
            }
        },
        {
            "name_short": "Consensus",
            "name_full": "Consensus (AI-supported scholarly search system)",
            "brief_description": "An AI-supported literature search system cited as an example that provides active assistance by extracting information automatically from scholarly articles; details not disclosed in this paper.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "Consensus",
            "system_description": "Mentioned among examples of commercial/closed-source AI-supported scholarly search systems that provide automatic information extraction and active assistance; the authors note these systems are not open-source and details are unknown.",
            "llm_model_used": null,
            "extraction_technique": "Not specified here; authors suggest such systems typically employ retrieval + generative approaches (RAG-style) but do not confirm for Consensus.",
            "synthesis_technique": "Not specified in this paper.",
            "number_of_papers": null,
            "domain_or_topic": "Scholarly literature (general).",
            "output_type": "Likely synthesized answers/summaries (not specified).",
            "evaluation_metrics": null,
            "performance_results": null,
            "comparison_baseline": null,
            "performance_vs_baseline": null,
            "key_findings": "Cited as an example of non-open-source systems that provide active assistance; authors emphasize reproducibility concerns due to lack of transparency.",
            "limitations_challenges": "Closed-source limits reproducibility; no further technical details available in this paper.",
            "scaling_behavior": null,
            "uuid": "e4551.4",
            "source_info": {
                "paper_title": "ORKG ASK: a Neuro-symbolic Scholarly Search and Exploration System",
                "publication_date_yy_mm": "2024-12"
            }
        },
        {
            "name_short": "Scispace",
            "name_full": "Scispace (AI-supported scholarly search system)",
            "brief_description": "An AI-assisted document understanding/search platform cited as an example of systems that actively extract and summarize information from scholarly literature; technical details are not provided in this paper.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "Scispace",
            "system_description": "Mentioned alongside other commercial AI-assisted literature tools (Elicit, Consensus) that provide automatic information extraction and active assistance; paper notes lack of open-source details prevents reproducibility assessment.",
            "llm_model_used": null,
            "extraction_technique": "Not specified here; authors imply such systems often use retrieval-augmented generation approaches but do not confirm specifics for Scispace.",
            "synthesis_technique": "Not specified in this paper.",
            "number_of_papers": null,
            "domain_or_topic": "Scholarly literature and document understanding (general).",
            "output_type": "Presumably synthesized summaries/answers (not specified).",
            "evaluation_metrics": null,
            "performance_results": null,
            "comparison_baseline": null,
            "performance_vs_baseline": null,
            "key_findings": "Included as part of a set of AI-assisted literature tools; lack of openness in these systems is highlighted as a reproducibility concern.",
            "limitations_challenges": "Details of models and datasets not disclosed; reproducibility issues noted.",
            "scaling_behavior": null,
            "uuid": "e4551.5",
            "source_info": {
                "paper_title": "ORKG ASK: a Neuro-symbolic Scholarly Search and Exploration System",
                "publication_date_yy_mm": "2024-12"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Retrieval-augmented generation for knowledge-intensive nlp tasks",
            "rating": 2
        },
        {
            "paper_title": "Artificial Intelligence for Literature Reviews: Opportunities and Challenges",
            "rating": 2
        },
        {
            "paper_title": "Improving access to scientific literature with knowledge graphs",
            "rating": 2
        }
    ],
    "cost": 0.01431,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>ORKG ASK: a Neuro-symbolic Scholarly Search and Exploration System</h1>
<p>Allard Oelen ${ }^{1}$, Mohamad Yaser Jaradeh ${ }^{2}$ and Sren Auer ${ }^{1,2}$<br>${ }^{1}$ TIB - Leibniz Information Centre for Science and Technology, Hannover, Germany<br>${ }^{2}$ L3S Research Center, Leibniz University of Hannover, Hannover, Germany</p>
<h4>Abstract</h4>
<dl>
<dd>Purpose: Finding scholarly articles is a time-consuming and cumbersome activity, yet crucial for conducting science. Due to the growing number of scholarly articles, new scholarly search systems are needed to effectively assist researchers in finding relevant literature. Methodology: We take a neuro-symbolic approach to scholarly search and exploration by leveraging state-of-the-art components, including semantic search, Large Language Models (LLMs), and Knowledge Graphs (KGs). The semantic search component composes a set of relevant articles. From this set of articles, information is extracted and presented to the user. Findings: The presented system, called ORKG ASK (Assistant for Scientific Knowledge), provides a production-ready search and exploration system. Our preliminary evaluation indicates that our proposed approach is indeed suitable for the task of scholarly information retrieval. Value: With ORKG ASK, we present a next-generation scholarly search and exploration system and make it available online. Additionally, the system components are open source with a permissive license.</dd>
</dl>
<h2>Keywords</h2>
<p>Neuro-symbolic AI, Large Language Models, Scholarly Knowledge Graphs, Scholarly Search System</p>
<h2>1. Introduction</h2>
<p>Finding scholarly articles and exploring the body of scholarly literature consumes a significant share of a researcher's time. Due to the growing number of scholarly articles, this issue only becomes more apparent [1]. Current scholarly search systems passively assist users with their information needs by providing a list of relevant articles. If instead active assistance were provided, the users' information needs, such as a research question, would be answered for them. We present ORKG ASK (Assistant for Scientific Knowledge), a new generation scholarly search and exploration system ${ }^{1}$. ORKG ASK helps researchers find relevant literature and automatically extract knowledge from the retrieved literature, actively supporting researchers with their information needs. The approach consists of three main components: 1) Semantic Search, 2) a Large Language Model (LLM), and 3) Knowledge Graphs (KGs). First, the semantic search addresses the previously discussed challenge of retrieving articles based on their relevance to a specific information need. In ORKG ASK users can formulate their information need as a</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: Design of the search result page of the ORKG ASK application.
research question, which is entered as a search query. Second, an LLM is leveraged to answer the research question by prompting with the context of the set of relevant articles. In addition to answers to the research question, a set of properties is extracted, among others, a summary, materials, methods, and results of the contributions described in the articles. Third, KGs are used to provide more fine-grained information extraction as well as for curating extraction results. This includes results filtering based on mentioned concepts in scholarly articles.</p>
<h1>2. Background</h1>
<p>There are various established, large, and multidisciplinary scholarly search systems, among others, Google Scholar, Semantic Scholar, and Scopus [2]. Other systems, such as PubMed and ACM Digital Library, are domain-specific. These search systems take a similar approach where articles are ranked based on relevance, but where users have to manually extract relevant information from articles. A new approach provides active support via automatic information extraction by systems such as Elicit, Consensus, and Scispace [3]. These systems are not opensource, leaving details about their approach, such as the model and dataset, to be unknown, in turn making results harder to reproduce. This makes such systems less suitable for systematic literature reviews where reproducibility is a key aspect of the approach [4].</p>
<p>To extract knowledge from a large set of scholarly documents, a Retrieval-Augmented Generation (RAG) approach can be used to provide the LLM with relevant context [5]. The Retrieval aspect retrieves a set of documents, commonly done using vector databases. The Augmented aspect, augments the user query with the found context. Finally, the Generation aspect creates the response. To our knowledge, the previously mentioned AI-supported scholarly search systems use this approach and are thus similar to the approach we propose with ORKG ASK.</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: ORKG ASK system workflow integrating neuro-symbolic components.</p>
<h1>3. System Overview</h1>
<p>We now discuss the ORKG ASK system in more detail. The service is designed and developed in such a way that it provides a solid foundation for a sustainable service. Additionally, we focus on accessibility by providing a dark mode (for low-light conditions), a responsive interface (for mobile usage, or high zoom levels for visually impaired users), and implementing ARIA accessibility attributes where necessary. The ORKG ASK code base is published as open source under an MIT license and available online. ${ }^{2}$ Figure 1 depicts the design of the search result page for a specific research question.</p>
<h3>3.1. User-Oriented Features</h3>
<p>The Question Answering feature as depicted in Node 1 in Figure 1 illustrates the input field for the research question. Nodes 2 and 4 present the answers to the question. Node 2 shows a synthesized answer of the first five displayed results. The Information Extraction feature extracts additional information from an article (node 4). There are several default columns displayed, but users can customize the extracted information to their needs (node 3). The Filtering feature enables users to filter articles based on user-provided criteria (node 5). This includes the ability to filter based on year, language, words that appear in the title or abstract, the number of citations, author names, etc. The Bibliography Managing featured called "My Library" provides a bibliography manager where users can store and curate a list of articles. Articles are added by clicking on the bookmark icon in the interface (node 8) or added manually via the My Library page (via DOI, title, or BibTeX). Articles from My Library can be manually added to a search query, which prepends the manually selected articles to the search results.</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3: Results for user satisfaction evaluation indicating relatively satisfied users.</p>
<p>The Data Reuse feature supports citing articles in APA, Vancouver, Harvard, citation styles, and exports to BibTeX, RIS, and CLS-JSON (node 7). The export button is displayed in node 8. Furthermore, there is an option to export the entire search result table to CSV and ORKG [6] CSV (node 6). Finally, the Entity Linking feature links entities in article abstracts to their respective DBpedia entries. This provides the ability to filter articles based on semantically identical concepts, providing an additional means to more targeted information retrieval.</p>
<h1>3.2. System Workflow</h1>
<p>Figure 2 depicts the system workflow. It starts with a user asking a research question. A set of relevant documents for this question is retrieved. The neural search component uses vectorized representations of the query and articles via the Nomic embeddings model to retrieve a set of relevant documents. Optionally, the search space can be narrowed down by filtering specific metadata or linked entities. Qdrant ${ }^{3}$ is used as a vector and data store. The symbolic component processed article abstracts offline and stored these linked entities in the data store. The entity linking is conducted using DBpedia Spotlight [7]. The CORE dataset [8], containing article metadata, abstracts, and full-text (in the case of open-access articles), is used as a data source for the vector store. Next, knowledge is extracted using an LLM from the top $n$ articles, resembling the RAG approach. Currently, we use the Mistral Instruct 7B v0.2 model for the information extraction. To reduce system resource usage, the LLM is only prompted if the answer does not yet exist in the cache. Finally, the information is presented to the user.</p>
<h2>4. Evaluation</h2>
<p>As a preliminary system evaluation, we aim to assess the usability of the system. We did this using a 5-point user satisfaction assessment and the Usability Metric for User Experience lite (UMUX-lite) [9] evaluation. Participants were recruited via the ORKG ASK production system, via a non-intrusive tooltip asking real-world system users for their opinion. To keep participation efforts as low as possible, no participant demographics were requested from users. In total, 30 participants took part in this evaluation. As Figure 3 shows, users are relatively satisfied with ORKG ASK. The UMUX-Lite evaluation displayed in Figure 4 results in an overall score of 65.2. As the individual results show, most participants agree that ORKG ASK is easy to use, but the system does not always meet their requirements. This could be explained by users' search behavior, as logs of asked questions revealed that not all questions are valid and answerable, leaving the user's specific search requirement unmet. Further evaluation is needed to determine what is needed to understand the user's expectations and needs better.</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 4: Results for UMUX-Lite evaluation with a total score of 65.2 .</p>
<h1>5. Conclusion</h1>
<p>The introduction of ORKG ASK serves as a starting point for a neuro-symbolic approach to finding and exploring scholarly articles. The preliminary evaluation indicates that our approach is easy to use. In the future, we plan to extend the system by providing provenance information to highlight the source of extracted information. Furthermore, we plan to extend the KG part significantly, growing the KG automatically while the system is being used.</p>
<h2>References</h2>
<p>[1] E. Landhuis, Scientific literature: Information overload, Nature 535 (2016) 457-458.
[2] M. Gusenbauer, N. R. Haddaway, Which academic search systems are suitable for systematic reviews or meta-analyses? Evaluating retrieval qualities of Google Scholar, PubMed, and 26 other resources, Research Synthesis Methods 11 (2020) 181-217. doi:10.1002/jrsm. 1378.
[3] F. Bolanos, A. Salatino, F. Osborne, E. Motta, Artificial Intelligence for Literature Reviews: Opportunities and Challenges, arXiv preprint arXiv:2402.08565 (2024). arXiv:2402.08565.
[4] A. MacFarlane, T. Russell-Rose, F. Shokraneh, Search strategy formulation for systematic reviews: Issues, challenges and opportunities, Intelligent Systems with Applications 15 (2022) 200091. doi:10.1016/j.iswa.2022.200091.
[5] P. Lewis, E. Perez, A. Piktus, F. Petroni, V. Karpukhin, N. Goyal, H. Kttler, M. Lewis, W.-t. Yih, T. Rocktschel, et al., Retrieval-augmented generation for knowledge-intensive nlp tasks, Advances in Neural Information Processing Systems 33 (2020) 9459-9474.
[6] S. Auer, A. Oelen, M. Haris, M. Stocker, J. D'Souza, K. E. Farfar, L. Vogt, M. Prinz, V. Wiens, M. Y. Jaradeh, Improving access to scientific literature with knowledge graphs, Bibliothek Forschung und Praxis 44 (2020) 516-529.
[7] P. N. Mendes, M. Jakob, A. Garca-Silva, C. Bizer, DBpedia spotlight: Shedding light on the web of documents, in: 7th International Conference on Semantic Systems, 2011, pp. 1-8.
[8] P. Knoth, D. Herrmannova, M. Cancellieri, L. Anastasiou, N. Pontika, S. Pearce, B. Gyawali, D. Pride, CORE: A global aggregation service for open access papers, Nature Scientific Data 10 (2023) 366.
[9] J. R. Lewis, B. S. Utesch, D. E. Maher, UMUX-LITE: When there's no time for the SUS, in: SIGCHI Conference on Human Factors in Computing Systems, 2013, pp. 2099-2102.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{3}$ https://qdrant.tech&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>