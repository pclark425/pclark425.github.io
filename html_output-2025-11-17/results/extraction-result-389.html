<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-389 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-389</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-389</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-16.html">extraction-schema-16</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <p><strong>Paper ID:</strong> paper-9466011</p>
                <p><strong>Paper Title:</strong> <a href="https://arxiv.org/pdf/2104.07778v1.pdf" target="_blank">Domain Adaptation for the Classification of Remote Sensing Data: An Overview of Recent Advances</a></p>
                <p><strong>Paper Abstract:</strong> The success of the supervised classification of remotely sensed images acquired over large geographical areas or at short time intervals strongly depends on the representativity of the samples used to train the classification algorithm and to define the model. When training samples are collected from an image or a spatial region that is different from the one used for mapping, spectral shifts between the two distributions are likely to make the model fail. Such shifts are generally due to differences in acquisition and atmospheric conditions or to changes in the nature of the object observed. To design classification methods that are robust to data set shifts, recent remote sensing literature has considered solutions based on domain adaptation (DA) approaches. Inspired by machine-learning literature, several DA methods have been proposed to solve specific problems in remote sensing data classification. This article provides a critical review of the recent advances in DA approaches for remote sensing and presents an overview of DA methods divided into four categories: 1) invariant feature selection, 2) representation matching, 3) adaptation of classifiers, and 4) selective sampling. We provide an overview of recent methodologies, examples of applications of the considered techniques to real remote sensing images characterized by very high spatial and spectral resolution as well as possible guidelines for the selection of the method to use in real application scenarios.</p>
                <p><strong>Cost:</strong> 0.018</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e389.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e389.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CV-to-RS DA (illustrative)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Domain adaptation of visual category models to remote sensing</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Illustrative example of transferring domain adaptation methods developed for visual object recognition (e.g., adapting Amazon product images → webcam images) to remote sensing image classification problems, highlighting the general concept of adapting classifiers across different acquisition conditions and data distributions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Adapting visual category models to new domains.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>Visual-domain domain adaptation (illustrative)</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>Methods originally developed to adapt object-recognition classifiers across photographic domains (e.g., commercial product photos to webcam photos) by aligning distributions, reweighting samples, or finding invariant feature representations so that a classifier trained on one domain can be used on another where data relationships differ. Techniques include feature-space alignment, reweighting, and discriminative transforms.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>computational method / transfer learning technique</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>computer vision / visual object recognition</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>remote sensing image classification</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>analogical transfer (conceptual import of DA techniques)</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>The paper discusses conceptual adaptation rather than specific algorithmic reimplementation; it emphasizes mapping the DA concepts (distribution shift, feature invariance, sample reweighting) to RS problems (illumination/viewing-angle/sensor differences) and suggests algorithmic families appropriate for RS data characteristics.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>mention — presented as motivating analogy; no quantitative outcome in this paper for this specific illustrative transfer.</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>Differences in feature meaning (spectral bands vs. RGB), multi-sensor/dimensionality mismatches, non-coregistered acquisitions, and physically driven shifts (illumination/atmosphere) that are different from photographic domain shifts.</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>Shared statistical formulation of dataset shift and availability of machine-learning DA literature; conceptual match of objectives (same classes, different distributions).</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>Requires redefinition of features (spectral/contextual features) and careful selection of DA method family suitable for RS (e.g., methods handling different dimensionality or unpaired data).</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>High at conceptual level — DA principles generalize across domains; algorithmic details require RS-specific modification.</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>theoretical principles and explicit procedural frameworks</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Domain Adaptation for the Classification of Remote Sensing Data: An Overview of Recent Advances', 'publication_date_yy_mm': '2021-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e389.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e389.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Invariant feature selection (Bruzzone & Persello)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>A novel approach to the selection of spatially invariant features for the classification of hyperspectral images with improved generalization capability</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A multi-objective feature-selection procedure that jointly optimizes discriminative power and invariance across source and target domains, implemented with a genetic algorithm and applied to hyperspectral data.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>A novel approach to the selection of spatially invariant features for the classification of hyperspectral images with improved generalization capability.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>Multi-objective invariant feature selection</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>Select a subset F of input features that maximizes discrimination (∆) and minimizes dataset shift (P) between source and target domains by solving argmin_|F|=l (−∆(F), P(F)). ∆ measures dependency with labels; P measures feature distribution shift across domains. The multi-objective problem is solved with a genetic multi-objective optimizer producing a Pareto front of trade-off solutions; a chosen subset is used to train an SVM classifier.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>data analysis technique / feature-selection algorithm</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>statistical machine learning / feature selection</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>remote sensing (hyperspectral image classification)</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>adapted/modified for new context</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>Introduced a domain-invariance term P into the usual discriminative feature-selection criterion; used parametric (Gaussian) and nonparametric (kernel-based) estimators suited to hyperspectral signatures; solved as multi-objective optimization via genetic algorithms to avoid specifying weighting between terms.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>successful — applied to Hyperion hyperspectral Okavango dataset: selected 6 features produced Overall Accuracy (OA) = 91.0% on source test set and 80.7% on target test set, whereas selecting features by relevance only gave OA = 92.7% (source) but only 64.4% (target), demonstrating improved cross-domain generalization.</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>High spectral dimensionality and sensitivity of hyperspectral signatures to acquisition conditions; need to estimate distribution-shift metric P robustly; selection of subset size l and computational cost of multi-objective genetic optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>Availability of labeled source data and some labeled/validation target samples (for evaluation), kernel-based nonparametric estimators for P, and genetic optimization to explore trade-offs.</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>Requires computation of feature-wise discrimination and shift measures (possible need for label information and assumptions for parametric estimators or enough samples for nonparametric ones); computational resources for optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>Moderate — approach is applicable to other high-dimensional remote sensing sensors (e.g., other hyperspectral datasets) and in principle to other domains with analogous feature-shift problems, but requires domain-specific definitions of ∆ and P.</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>explicit procedural steps and algorithmic/technical know-how</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Domain Adaptation for the Classification of Remote Sensing Data: An Overview of Recent Advances', 'publication_date_yy_mm': '2021-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e389.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e389.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SSMA</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Semisupervised Manifold Alignment (SSMA)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A discriminative manifold-alignment method that projects multiple (possibly multimodal) domains into a common space using available labels to align semantic classes, enabling a single classifier to operate across domains.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Semisupervised manifold alignment of multimodal remote sensing images.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>Semisupervised manifold alignment</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>Constructs projections that preserve within-domain manifold geometry while bringing semantically equivalent samples across domains closer in a common latent space; leverages labels in all domains (semisupervised) and optionally spatial regularization; once projected, a classifier trained on combined projected data generalizes across domains.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>computational method / feature-representation alignment</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>machine learning (manifold learning / multiview alignment)</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>remote sensing (multi-angular VHR image classification)</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>adapted/modified for new context</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>Integrated spatial regularization terms and discriminative constraints adapted to remote sensing imagery; applied to non-coregistered multi-angular sequences by using labels from all domains (50 labeled pixels/class in targets in the experiment) to learn a single projection for multisource alignment.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>successful — in the Rio de Janeiro multi-angular experiment SSMA produced the best alignment among tested methods (PCA, KPCA, Graph Matching) yielding a near-flat prediction performance across different off-nadir angles, i.e., consistent classification accuracy regardless of angular configuration (qualitative; SSMA showed particularly good performance in the study).</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>Requires labeled samples in all domains (costly), computational complexity of manifold alignment on large RS datasets, and sensitivity to the choice of regularization and graph-construction parameters.</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>Availability of labels in source and target domains, manifold structure of RS data, ability to incorporate spatial priors and to align multiple domains jointly (multisource).</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>Needs semisupervised labels across domains (labels in s and partial labels in t for best performance), graph construction for manifold geometry, and sufficient memory/computation for eigenproblems.</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>Good for other remote sensing scenarios where labels can be obtained in multiple domains (multisensor, multitemporal, multi-angular), less applicable when target labels are unavailable.</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>algorithmic/technical skills and explicit procedural steps</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Domain Adaptation for the Classification of Remote Sensing Data: An Overview of Recent Advances', 'publication_date_yy_mm': '2021-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e389.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e389.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PCA/KPCA/GM (representation alignment)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Principal Component Analysis, Kernel PCA, Graph Matching representation-alignment methods</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A set of representation-alignment preprocessing techniques (linear PCA, nonlinear KPCA, and graph-matching) used to reduce or realign feature distributions between source and target domains before classification.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>Representation alignment via PCA / KPCA / Graph Matching</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>PCA and KPCA transform features to lower-dimensional spaces that can reduce domain differences (unsupervised projection), while graph-matching (GM) formulates domains as graphs and aligns their structures to reduce mismatch; after transformation, classifiers trained on source projections are applied to target projections.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>data analysis technique / feature extraction / representation learning</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>statistical data analysis / machine learning</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>remote sensing (multi-angular VHR classification and other DA tasks)</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>direct application with adaptation (choice of unsupervised projection for RS data)</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>Applied unsupervised PCA/KPCA projections computed from the RS data; for GM the graph formulation was adapted to RS by representing spectral/spatial relationships and solving a graph alignment problem between domains.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>partially successful — in the Rio angular experiments PCA/KPCA/GM improved over naive application of source-trained classifier but underperformed SSMA; PCA/KPCA/GM produced unsupervised alignment helpful when shifts were moderate but less effective for strong nonlinear angular-induced shifts.</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>Unsupervised methods cannot correct strong nonlinear or class-conditional shifts; PCA/KPCA limited to two-domain pairwise alignment; GM can be computationally heavy and may need careful graph design.</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>Unpaired-data applicability, modest computational requirements for PCA, and graph representations that capture RS geometry helped in scenarios with limited labels.</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>Sufficient unlabeled data to estimate projections/graphs; for GM, design of adjacency and matching criteria appropriate to RS spectral/spatial structure.</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>Moderate — widely applicable preprocessing but effectiveness depends on shift magnitude and whether labels are available for discriminative alignment.</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>explicit procedural steps and technical know-how</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Domain Adaptation for the Classification of Remote Sensing Data: An Overview of Recent Advances', 'publication_date_yy_mm': '2021-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e389.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e389.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>TrAdaBoost + AL (KSC experiment)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Transfer AdaBoost reweighting combined with Active Learning for domain adaptation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Combination of the TrAdaBoost reweighting domain-adaptation algorithm with active learning sample selection to adapt a classifier trained in one geographic area to another spatially disjoint area using a limited number of target labels.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>TrAdaBoost with Active Learning (iterative reweighting + targeted labeling)</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>Start from an SVM trained on source labeled data; iteratively query the most informative unlabeled target samples (active learning), label them, and retrain using TrAdaBoost which downweights source samples that conflict with new target samples and upweights relevant target samples; iterate until convergence.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>computational method / active sampling + ensemble reweighting</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>machine learning (active learning, boosting)</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>remote sensing (hyperspectral land-cover mapping across spatially disjoint areas)</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>adapted/modified for new context (combination of known algorithms)</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>Applied Breaking Ties active learning strategy tailored to hyperspectral SVM decision boundaries; used TrAdaBoost to progressively forget misleading source samples in RS context; selection of query budget and SVM hyperparameters adapted for KSC AVIRIS dataset.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>successful — experimental results on KSC hyperspectral data: source-only SVM produced <65% OA, an SVM trained on target labeled examples reached 90% OA (best case). Random target sampling improved slowly; TrAdaBoost alone improved learning; Active Learning + TrAdaBoost reached comparable performance to 500 random target queries using only 250 active queries (i.e., substantially faster convergence), and the model progressively increased reliance on target support vectors while reducing relative importance of some source samples (source SV share stabilized at ~40%).</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>Strong domain shift between spatially disjoint areas (spectral signature differences), costly labeling in the field, need to select informative samples efficiently, and potential presence of classes unseen in source.</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>Availability of an initial labeled source set, effective active learning strategy (Breaking Ties), and TrAdaBoost's ability to downweight misleading source samples enabled faster adaptation.</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>Capability to obtain labels for queried target samples (field or photo-interpretation), computational resources for iterative retraining, and sufficient unlabeled target samples for AL selection.</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>High within RS tasks involving spatial transfer where limited target labeling is possible; approach generalizes to other sensor types and domains with analogous sample-selection costs.</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>procedural/tacit know-how (active sampling strategies) and algorithmic implementation details</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Domain Adaptation for the Classification of Remote Sensing Data: An Overview of Recent Advances', 'publication_date_yy_mm': '2021-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e389.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e389.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DASVM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Domain Adaptation Support Vector Machine (DASVM)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A domain-adaptation variant of SVM that iteratively incorporates unlabeled target samples into training while de-emphasizing some source samples to adapt the decision boundary to the target domain.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Domain adaptation problems: a DASVM classification technique and a circular validation strategy.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>DASVM iterative semisupervised adaptation</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>Begin with a supervised SVM trained on source data, then iteratively add subsets of unlabeled target samples to the cost function (with heuristic selection/labeling) and gradually remove (or downweight) source samples so that the decision boundary adapts toward low-density regions of the target distribution.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>computational method / semisupervised classifier adaptation</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>machine learning (SVM-based semisupervised learning)</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>remote sensing image classification</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>adapted/modified for new context (semisupervised DA applied to RS)</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>Methods adapted to RS include selection heuristics for which target unlabeled points to include, and validation strategies (circular validation) tailored for situations with few/no target labels.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>mention — reviewed as an established approach in RS literature; the paper cites DASVM as part of the toolkit but does not present a primary experimental evaluation of DASVM itself.</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>Risk of reinforcing erroneous pseudo-labels in target, sensitivity to initialization from source, and requirement for careful selection of target samples to include.</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>Shared feature spaces and assumed common class set between domains; graph-based regularization or MMD terms can be combined to stabilize adaptation.</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>Access to unlabeled target samples and some mechanism for validating adaptation (e.g., circular validation or limited labeled target samples).</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>Moderate — applicable across many RS DA tasks where unlabeled target data are plentiful and class sets are shared.</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>explicit procedural algorithmic knowledge</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Domain Adaptation for the Classification of Remote Sensing Data: An Overview of Recent Advances', 'publication_date_yy_mm': '2021-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e389.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e389.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Data augmentation (invariance encoding)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Encoding invariances in remote sensing image classification with SVM (data augmentation)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Augmenting the training set with synthetic, physically plausible variations of existing labeled samples (e.g., illumination, rotation, scale) to encode invariances and increase robustness to dataset shifts.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Encoding invariances in remote sensing image classification with svm.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>Synthetic data augmentation for invariance encoding</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>Generate additional labeled training examples by applying transformations (illumination changes, geometric transforms, size variations) consistent with RS physics to the support vectors of an SVM trained on source data; retrain or adapt the classifier with the enriched training set to better represent intra-class variability across domains.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>experimental procedure / data-preprocessing augmentation</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>machine learning / computer vision (data augmentation techniques)</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>remote sensing image classification (hyperspectral/multispectral)</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>adapted/modified for new context</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>Transformations selected to reflect physically plausible RS variations (e.g., illumination/atmospheric effects), and augmentation was targeted at support vectors to limit dataset size increase.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>partially successful — cited as helpful for addressing sample selection bias; presented as a component in RS pipelines (studied in referenced works) but no specific quantitative results provided in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>Need to ensure synthetic variations are physically realistic; expanded training sets increase computational cost; may not capture all forms of sensor-induced shifts.</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>Knowledge of plausible physical perturbations in RS (illumination, view angle), ability to identify support vectors to limit augmentation, and SVM robustness to augmented training.</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>Domain expertise to design realistic augmentations and compute resources to retrain models on enriched datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>Good — conceptually applicable across RS modalities and other sensing domains if domain-appropriate transformations are used.</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>tacit/practical know-how (constructing physically consistent augmentations) and explicit procedural steps</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Domain Adaptation for the Classification of Remote Sensing Data: An Overview of Recent Advances', 'publication_date_yy_mm': '2021-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Adapting visual category models to new domains. <em>(Rating: 2)</em></li>
                <li>A novel approach to the selection of spatially invariant features for the classification of hyperspectral images with improved generalization capability. <em>(Rating: 2)</em></li>
                <li>Semisupervised manifold alignment of multimodal remote sensing images. <em>(Rating: 2)</em></li>
                <li>Graph matching for adaptation in remote sensing. <em>(Rating: 2)</em></li>
                <li>Domain adaptation problems: a DASVM classification technique and a circular validation strategy. <em>(Rating: 2)</em></li>
                <li>SVM-based boosting of active learning strategies for efficient domain adaptation. <em>(Rating: 1)</em></li>
                <li>Encoding invariances in remote sensing image classification with svm. <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-389",
    "paper_id": "paper-9466011",
    "extraction_schema_id": "extraction-schema-16",
    "extracted_data": [
        {
            "name_short": "CV-to-RS DA (illustrative)",
            "name_full": "Domain adaptation of visual category models to remote sensing",
            "brief_description": "Illustrative example of transferring domain adaptation methods developed for visual object recognition (e.g., adapting Amazon product images → webcam images) to remote sensing image classification problems, highlighting the general concept of adapting classifiers across different acquisition conditions and data distributions.",
            "citation_title": "Adapting visual category models to new domains.",
            "mention_or_use": "mention",
            "procedure_name": "Visual-domain domain adaptation (illustrative)",
            "procedure_description": "Methods originally developed to adapt object-recognition classifiers across photographic domains (e.g., commercial product photos to webcam photos) by aligning distributions, reweighting samples, or finding invariant feature representations so that a classifier trained on one domain can be used on another where data relationships differ. Techniques include feature-space alignment, reweighting, and discriminative transforms.",
            "procedure_type": "computational method / transfer learning technique",
            "source_domain": "computer vision / visual object recognition",
            "target_domain": "remote sensing image classification",
            "transfer_type": "analogical transfer (conceptual import of DA techniques)",
            "modifications_made": "The paper discusses conceptual adaptation rather than specific algorithmic reimplementation; it emphasizes mapping the DA concepts (distribution shift, feature invariance, sample reweighting) to RS problems (illumination/viewing-angle/sensor differences) and suggests algorithmic families appropriate for RS data characteristics.",
            "transfer_success": "mention — presented as motivating analogy; no quantitative outcome in this paper for this specific illustrative transfer.",
            "barriers_encountered": "Differences in feature meaning (spectral bands vs. RGB), multi-sensor/dimensionality mismatches, non-coregistered acquisitions, and physically driven shifts (illumination/atmosphere) that are different from photographic domain shifts.",
            "facilitating_factors": "Shared statistical formulation of dataset shift and availability of machine-learning DA literature; conceptual match of objectives (same classes, different distributions).",
            "contextual_requirements": "Requires redefinition of features (spectral/contextual features) and careful selection of DA method family suitable for RS (e.g., methods handling different dimensionality or unpaired data).",
            "generalizability": "High at conceptual level — DA principles generalize across domains; algorithmic details require RS-specific modification.",
            "knowledge_type": "theoretical principles and explicit procedural frameworks",
            "uuid": "e389.0",
            "source_info": {
                "paper_title": "Domain Adaptation for the Classification of Remote Sensing Data: An Overview of Recent Advances",
                "publication_date_yy_mm": "2021-04"
            }
        },
        {
            "name_short": "Invariant feature selection (Bruzzone & Persello)",
            "name_full": "A novel approach to the selection of spatially invariant features for the classification of hyperspectral images with improved generalization capability",
            "brief_description": "A multi-objective feature-selection procedure that jointly optimizes discriminative power and invariance across source and target domains, implemented with a genetic algorithm and applied to hyperspectral data.",
            "citation_title": "A novel approach to the selection of spatially invariant features for the classification of hyperspectral images with improved generalization capability.",
            "mention_or_use": "use",
            "procedure_name": "Multi-objective invariant feature selection",
            "procedure_description": "Select a subset F of input features that maximizes discrimination (∆) and minimizes dataset shift (P) between source and target domains by solving argmin_|F|=l (−∆(F), P(F)). ∆ measures dependency with labels; P measures feature distribution shift across domains. The multi-objective problem is solved with a genetic multi-objective optimizer producing a Pareto front of trade-off solutions; a chosen subset is used to train an SVM classifier.",
            "procedure_type": "data analysis technique / feature-selection algorithm",
            "source_domain": "statistical machine learning / feature selection",
            "target_domain": "remote sensing (hyperspectral image classification)",
            "transfer_type": "adapted/modified for new context",
            "modifications_made": "Introduced a domain-invariance term P into the usual discriminative feature-selection criterion; used parametric (Gaussian) and nonparametric (kernel-based) estimators suited to hyperspectral signatures; solved as multi-objective optimization via genetic algorithms to avoid specifying weighting between terms.",
            "transfer_success": "successful — applied to Hyperion hyperspectral Okavango dataset: selected 6 features produced Overall Accuracy (OA) = 91.0% on source test set and 80.7% on target test set, whereas selecting features by relevance only gave OA = 92.7% (source) but only 64.4% (target), demonstrating improved cross-domain generalization.",
            "barriers_encountered": "High spectral dimensionality and sensitivity of hyperspectral signatures to acquisition conditions; need to estimate distribution-shift metric P robustly; selection of subset size l and computational cost of multi-objective genetic optimization.",
            "facilitating_factors": "Availability of labeled source data and some labeled/validation target samples (for evaluation), kernel-based nonparametric estimators for P, and genetic optimization to explore trade-offs.",
            "contextual_requirements": "Requires computation of feature-wise discrimination and shift measures (possible need for label information and assumptions for parametric estimators or enough samples for nonparametric ones); computational resources for optimization.",
            "generalizability": "Moderate — approach is applicable to other high-dimensional remote sensing sensors (e.g., other hyperspectral datasets) and in principle to other domains with analogous feature-shift problems, but requires domain-specific definitions of ∆ and P.",
            "knowledge_type": "explicit procedural steps and algorithmic/technical know-how",
            "uuid": "e389.1",
            "source_info": {
                "paper_title": "Domain Adaptation for the Classification of Remote Sensing Data: An Overview of Recent Advances",
                "publication_date_yy_mm": "2021-04"
            }
        },
        {
            "name_short": "SSMA",
            "name_full": "Semisupervised Manifold Alignment (SSMA)",
            "brief_description": "A discriminative manifold-alignment method that projects multiple (possibly multimodal) domains into a common space using available labels to align semantic classes, enabling a single classifier to operate across domains.",
            "citation_title": "Semisupervised manifold alignment of multimodal remote sensing images.",
            "mention_or_use": "use",
            "procedure_name": "Semisupervised manifold alignment",
            "procedure_description": "Constructs projections that preserve within-domain manifold geometry while bringing semantically equivalent samples across domains closer in a common latent space; leverages labels in all domains (semisupervised) and optionally spatial regularization; once projected, a classifier trained on combined projected data generalizes across domains.",
            "procedure_type": "computational method / feature-representation alignment",
            "source_domain": "machine learning (manifold learning / multiview alignment)",
            "target_domain": "remote sensing (multi-angular VHR image classification)",
            "transfer_type": "adapted/modified for new context",
            "modifications_made": "Integrated spatial regularization terms and discriminative constraints adapted to remote sensing imagery; applied to non-coregistered multi-angular sequences by using labels from all domains (50 labeled pixels/class in targets in the experiment) to learn a single projection for multisource alignment.",
            "transfer_success": "successful — in the Rio de Janeiro multi-angular experiment SSMA produced the best alignment among tested methods (PCA, KPCA, Graph Matching) yielding a near-flat prediction performance across different off-nadir angles, i.e., consistent classification accuracy regardless of angular configuration (qualitative; SSMA showed particularly good performance in the study).",
            "barriers_encountered": "Requires labeled samples in all domains (costly), computational complexity of manifold alignment on large RS datasets, and sensitivity to the choice of regularization and graph-construction parameters.",
            "facilitating_factors": "Availability of labels in source and target domains, manifold structure of RS data, ability to incorporate spatial priors and to align multiple domains jointly (multisource).",
            "contextual_requirements": "Needs semisupervised labels across domains (labels in s and partial labels in t for best performance), graph construction for manifold geometry, and sufficient memory/computation for eigenproblems.",
            "generalizability": "Good for other remote sensing scenarios where labels can be obtained in multiple domains (multisensor, multitemporal, multi-angular), less applicable when target labels are unavailable.",
            "knowledge_type": "algorithmic/technical skills and explicit procedural steps",
            "uuid": "e389.2",
            "source_info": {
                "paper_title": "Domain Adaptation for the Classification of Remote Sensing Data: An Overview of Recent Advances",
                "publication_date_yy_mm": "2021-04"
            }
        },
        {
            "name_short": "PCA/KPCA/GM (representation alignment)",
            "name_full": "Principal Component Analysis, Kernel PCA, Graph Matching representation-alignment methods",
            "brief_description": "A set of representation-alignment preprocessing techniques (linear PCA, nonlinear KPCA, and graph-matching) used to reduce or realign feature distributions between source and target domains before classification.",
            "citation_title": "",
            "mention_or_use": "use",
            "procedure_name": "Representation alignment via PCA / KPCA / Graph Matching",
            "procedure_description": "PCA and KPCA transform features to lower-dimensional spaces that can reduce domain differences (unsupervised projection), while graph-matching (GM) formulates domains as graphs and aligns their structures to reduce mismatch; after transformation, classifiers trained on source projections are applied to target projections.",
            "procedure_type": "data analysis technique / feature extraction / representation learning",
            "source_domain": "statistical data analysis / machine learning",
            "target_domain": "remote sensing (multi-angular VHR classification and other DA tasks)",
            "transfer_type": "direct application with adaptation (choice of unsupervised projection for RS data)",
            "modifications_made": "Applied unsupervised PCA/KPCA projections computed from the RS data; for GM the graph formulation was adapted to RS by representing spectral/spatial relationships and solving a graph alignment problem between domains.",
            "transfer_success": "partially successful — in the Rio angular experiments PCA/KPCA/GM improved over naive application of source-trained classifier but underperformed SSMA; PCA/KPCA/GM produced unsupervised alignment helpful when shifts were moderate but less effective for strong nonlinear angular-induced shifts.",
            "barriers_encountered": "Unsupervised methods cannot correct strong nonlinear or class-conditional shifts; PCA/KPCA limited to two-domain pairwise alignment; GM can be computationally heavy and may need careful graph design.",
            "facilitating_factors": "Unpaired-data applicability, modest computational requirements for PCA, and graph representations that capture RS geometry helped in scenarios with limited labels.",
            "contextual_requirements": "Sufficient unlabeled data to estimate projections/graphs; for GM, design of adjacency and matching criteria appropriate to RS spectral/spatial structure.",
            "generalizability": "Moderate — widely applicable preprocessing but effectiveness depends on shift magnitude and whether labels are available for discriminative alignment.",
            "knowledge_type": "explicit procedural steps and technical know-how",
            "uuid": "e389.3",
            "source_info": {
                "paper_title": "Domain Adaptation for the Classification of Remote Sensing Data: An Overview of Recent Advances",
                "publication_date_yy_mm": "2021-04"
            }
        },
        {
            "name_short": "TrAdaBoost + AL (KSC experiment)",
            "name_full": "Transfer AdaBoost reweighting combined with Active Learning for domain adaptation",
            "brief_description": "Combination of the TrAdaBoost reweighting domain-adaptation algorithm with active learning sample selection to adapt a classifier trained in one geographic area to another spatially disjoint area using a limited number of target labels.",
            "citation_title": "",
            "mention_or_use": "use",
            "procedure_name": "TrAdaBoost with Active Learning (iterative reweighting + targeted labeling)",
            "procedure_description": "Start from an SVM trained on source labeled data; iteratively query the most informative unlabeled target samples (active learning), label them, and retrain using TrAdaBoost which downweights source samples that conflict with new target samples and upweights relevant target samples; iterate until convergence.",
            "procedure_type": "computational method / active sampling + ensemble reweighting",
            "source_domain": "machine learning (active learning, boosting)",
            "target_domain": "remote sensing (hyperspectral land-cover mapping across spatially disjoint areas)",
            "transfer_type": "adapted/modified for new context (combination of known algorithms)",
            "modifications_made": "Applied Breaking Ties active learning strategy tailored to hyperspectral SVM decision boundaries; used TrAdaBoost to progressively forget misleading source samples in RS context; selection of query budget and SVM hyperparameters adapted for KSC AVIRIS dataset.",
            "transfer_success": "successful — experimental results on KSC hyperspectral data: source-only SVM produced &lt;65% OA, an SVM trained on target labeled examples reached 90% OA (best case). Random target sampling improved slowly; TrAdaBoost alone improved learning; Active Learning + TrAdaBoost reached comparable performance to 500 random target queries using only 250 active queries (i.e., substantially faster convergence), and the model progressively increased reliance on target support vectors while reducing relative importance of some source samples (source SV share stabilized at ~40%).",
            "barriers_encountered": "Strong domain shift between spatially disjoint areas (spectral signature differences), costly labeling in the field, need to select informative samples efficiently, and potential presence of classes unseen in source.",
            "facilitating_factors": "Availability of an initial labeled source set, effective active learning strategy (Breaking Ties), and TrAdaBoost's ability to downweight misleading source samples enabled faster adaptation.",
            "contextual_requirements": "Capability to obtain labels for queried target samples (field or photo-interpretation), computational resources for iterative retraining, and sufficient unlabeled target samples for AL selection.",
            "generalizability": "High within RS tasks involving spatial transfer where limited target labeling is possible; approach generalizes to other sensor types and domains with analogous sample-selection costs.",
            "knowledge_type": "procedural/tacit know-how (active sampling strategies) and algorithmic implementation details",
            "uuid": "e389.4",
            "source_info": {
                "paper_title": "Domain Adaptation for the Classification of Remote Sensing Data: An Overview of Recent Advances",
                "publication_date_yy_mm": "2021-04"
            }
        },
        {
            "name_short": "DASVM",
            "name_full": "Domain Adaptation Support Vector Machine (DASVM)",
            "brief_description": "A domain-adaptation variant of SVM that iteratively incorporates unlabeled target samples into training while de-emphasizing some source samples to adapt the decision boundary to the target domain.",
            "citation_title": "Domain adaptation problems: a DASVM classification technique and a circular validation strategy.",
            "mention_or_use": "mention",
            "procedure_name": "DASVM iterative semisupervised adaptation",
            "procedure_description": "Begin with a supervised SVM trained on source data, then iteratively add subsets of unlabeled target samples to the cost function (with heuristic selection/labeling) and gradually remove (or downweight) source samples so that the decision boundary adapts toward low-density regions of the target distribution.",
            "procedure_type": "computational method / semisupervised classifier adaptation",
            "source_domain": "machine learning (SVM-based semisupervised learning)",
            "target_domain": "remote sensing image classification",
            "transfer_type": "adapted/modified for new context (semisupervised DA applied to RS)",
            "modifications_made": "Methods adapted to RS include selection heuristics for which target unlabeled points to include, and validation strategies (circular validation) tailored for situations with few/no target labels.",
            "transfer_success": "mention — reviewed as an established approach in RS literature; the paper cites DASVM as part of the toolkit but does not present a primary experimental evaluation of DASVM itself.",
            "barriers_encountered": "Risk of reinforcing erroneous pseudo-labels in target, sensitivity to initialization from source, and requirement for careful selection of target samples to include.",
            "facilitating_factors": "Shared feature spaces and assumed common class set between domains; graph-based regularization or MMD terms can be combined to stabilize adaptation.",
            "contextual_requirements": "Access to unlabeled target samples and some mechanism for validating adaptation (e.g., circular validation or limited labeled target samples).",
            "generalizability": "Moderate — applicable across many RS DA tasks where unlabeled target data are plentiful and class sets are shared.",
            "knowledge_type": "explicit procedural algorithmic knowledge",
            "uuid": "e389.5",
            "source_info": {
                "paper_title": "Domain Adaptation for the Classification of Remote Sensing Data: An Overview of Recent Advances",
                "publication_date_yy_mm": "2021-04"
            }
        },
        {
            "name_short": "Data augmentation (invariance encoding)",
            "name_full": "Encoding invariances in remote sensing image classification with SVM (data augmentation)",
            "brief_description": "Augmenting the training set with synthetic, physically plausible variations of existing labeled samples (e.g., illumination, rotation, scale) to encode invariances and increase robustness to dataset shifts.",
            "citation_title": "Encoding invariances in remote sensing image classification with svm.",
            "mention_or_use": "mention",
            "procedure_name": "Synthetic data augmentation for invariance encoding",
            "procedure_description": "Generate additional labeled training examples by applying transformations (illumination changes, geometric transforms, size variations) consistent with RS physics to the support vectors of an SVM trained on source data; retrain or adapt the classifier with the enriched training set to better represent intra-class variability across domains.",
            "procedure_type": "experimental procedure / data-preprocessing augmentation",
            "source_domain": "machine learning / computer vision (data augmentation techniques)",
            "target_domain": "remote sensing image classification (hyperspectral/multispectral)",
            "transfer_type": "adapted/modified for new context",
            "modifications_made": "Transformations selected to reflect physically plausible RS variations (e.g., illumination/atmospheric effects), and augmentation was targeted at support vectors to limit dataset size increase.",
            "transfer_success": "partially successful — cited as helpful for addressing sample selection bias; presented as a component in RS pipelines (studied in referenced works) but no specific quantitative results provided in this paper.",
            "barriers_encountered": "Need to ensure synthetic variations are physically realistic; expanded training sets increase computational cost; may not capture all forms of sensor-induced shifts.",
            "facilitating_factors": "Knowledge of plausible physical perturbations in RS (illumination, view angle), ability to identify support vectors to limit augmentation, and SVM robustness to augmented training.",
            "contextual_requirements": "Domain expertise to design realistic augmentations and compute resources to retrain models on enriched datasets.",
            "generalizability": "Good — conceptually applicable across RS modalities and other sensing domains if domain-appropriate transformations are used.",
            "knowledge_type": "tacit/practical know-how (constructing physically consistent augmentations) and explicit procedural steps",
            "uuid": "e389.6",
            "source_info": {
                "paper_title": "Domain Adaptation for the Classification of Remote Sensing Data: An Overview of Recent Advances",
                "publication_date_yy_mm": "2021-04"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Adapting visual category models to new domains.",
            "rating": 2,
            "sanitized_title": "adapting_visual_category_models_to_new_domains"
        },
        {
            "paper_title": "A novel approach to the selection of spatially invariant features for the classification of hyperspectral images with improved generalization capability.",
            "rating": 2,
            "sanitized_title": "a_novel_approach_to_the_selection_of_spatially_invariant_features_for_the_classification_of_hyperspectral_images_with_improved_generalization_capability"
        },
        {
            "paper_title": "Semisupervised manifold alignment of multimodal remote sensing images.",
            "rating": 2,
            "sanitized_title": "semisupervised_manifold_alignment_of_multimodal_remote_sensing_images"
        },
        {
            "paper_title": "Graph matching for adaptation in remote sensing.",
            "rating": 2,
            "sanitized_title": "graph_matching_for_adaptation_in_remote_sensing"
        },
        {
            "paper_title": "Domain adaptation problems: a DASVM classification technique and a circular validation strategy.",
            "rating": 2,
            "sanitized_title": "domain_adaptation_problems_a_dasvm_classification_technique_and_a_circular_validation_strategy"
        },
        {
            "paper_title": "SVM-based boosting of active learning strategies for efficient domain adaptation.",
            "rating": 1,
            "sanitized_title": "svmbased_boosting_of_active_learning_strategies_for_efficient_domain_adaptation"
        },
        {
            "paper_title": "Encoding invariances in remote sensing image classification with svm.",
            "rating": 1,
            "sanitized_title": "encoding_invariances_in_remote_sensing_image_classification_with_svm"
        }
    ],
    "cost": 0.01762025,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Recent Advances in Domain Adaptation for the Classification of Remote Sensing Data
15 Apr 2021</p>
<p>Senior Member, IEEEDevis Tuia devis.tuia@geo.uzh.ch 
Member, IEEEClaudio Persello c.persello@utwente.nl 
Fellow, IEEELorenzo Bruzzone lorenzo.bruzzone@disi.unitn.it </p>
<p>Department of Geography
University of Zurich
8057ZurichSwitzerland</p>
<p>faculty of Geo-Information Science and Earth Observation (ITC)
University of Twente
The Netherlands</p>
<p>Dipartimento di Ingegneria e Scienza dell'Informazione
University of Trento
Italy</p>
<p>Recent Advances in Domain Adaptation for the Classification of Remote Sensing Data
15 Apr 202112B5EE02E00584FB853E22516B1A32DB10.1109/MGRS.2016.2548504arXiv:2104.07778v1[cs.CV]Manuscript received 2015;
This is the pre-acceptance version, to read the final version published in 2016 in the IEEE Geoscience and Remote Sensing Magazine, please go to: 10.1109/MGRS.2016.2548504The success of supervised classification of remotely sensed images acquired over large geographical areas or at short time intervals strongly depends on the representativity of the samples used to train the classification algorithm and to define the model.When training samples are collected from an image (or a spatial region) different from the one used for mapping, spectral shifts between the two distributions are likely to make the model fail.Such shifts are generally due to differences in acquisition and atmospheric conditions or to changes in the nature of the object observed.In order to design classification methods that are robust to data-set shifts, recent remote sensing literature has considered solutions based on domain adaptation (DA) approaches.Inspired by machine learning literature, several DA methods have been proposed to solve specific problems in remote sensing data classification.This paper provides a critical review of the recent advances in DA for remote sensing and presents an overview of methods divided into four categories: i) invariant feature selection; ii) representation matching; iii) adaptation of classifiers and iv) selective sampling.We provide an overview of recent methodologies, as well as examples of application of the considered techniques to real remote sensing images characterized by very high spatial and spectral resolution.Finally, we propose guidelines to the selection of the method to use in real application scenarios.</p>
<p>I. INTRODUCTION</p>
<p>With the advent of the new generation of satellite missions, which are often made up of constellations of satellites with short revisit time and very high resolution sensors, the amount of remote sensing images available has increased significantly.Nowadays, monitoring of dynamic processes has become possible [1], [2], as well as the use of several data sources to address biophysical parameter estimation and classification problems [3]- [6].As a consequence, analysts have the opportunity to use multitemporal and multisource images for tasks such as repetitive monitoring of the territory, change detection, image mosaicking and large scale processing (i.e.processing involving many image tiles) [7].</p>
<p>Remote sensing is therefore facing new opportunities.However, such opportunities cannot be seized, unless they come with the capability to provide accurate products in a timely manner.</p>
<p>A bottleneck of supervised image processing-based pipelines is the need of training the model on reference points that are specific to every acquisition: to be accurate, most models need to be trained on known samples coming from the image under study.Since obtaining new ground samples of high quality for each image acquisition is not realistic, to retrain/adapt an existing model without such ground samples becomes mandatory.Figure 1 illustrates situations where adaptive models might be of great use: in these situations (which correspond to those considered in this paper) only one image -the one in red in the figure -has sufficient reference labels (e.g.obtained in an extensive ground campaign) whereas the others have no labeled samples or have them only in an insufficient number.This setting is more realistic, since, on the one hand, extensive labeling cannot follow the pace of image acquisitions and, on the other hand, repetitive ground campaigns are often simply not an option, mainly for economic and manpower reasons.Indeed, gathering ground information is costly and cannot always be performed by photointerpretation: this is particularly true when the task concerns very large areas or considers quantities that cannot be photointerpreted by an analyst, such as chlorophyll concentrations [8], plant water stress [9] or tree species [10].</p>
<p>A possible solution would be to bypass the problem and assume that the model already available is robust enough to process the new images accurately.Despite the fact that this is only possible in cases where the new image is acquired by the same sensor as the previous one, it is well known that the direct application of a pre-trained model on a new dataset often provides</p>
<p>Model extension on wide surfaces</p>
<p>Mosaicking</p>
<p>Model extension on wide and asynchronous scenes Fig. 1.Examples of cases where domain adaptation is necessary to extend a model to new image acquisitions.In all three cases, the images can be of different sensors and only the image in red has extensive reference labels (i.e. can be used for training an accurate supervised model).</p>
<p>poor results.This is because the spectra observed in the new scene, even though representing the same types of objects, are different from those of the scene used for training.The differences can be related to a series of deformations, or shifts, related to a variety of effects such as a biased sampling in the spatial domain (typically if the ground sampling has been focused on a region non-representative of the new scene), changes in the acquisition conditions (including illumination or acquisition angle), or seasonal changes.When the new data are acquired by a different sensor, the strategy above is simply not applicable, as most models require that all images (or domains) provide samples of the same dimensionality (and where each dimension has the same meaning) at test time.In this case, fusion strategies exist, but generally apply only to certain combination of sensors and use only the bands that these sensors have in common (or that are reasonably similar) [3].This prevents to reuse models already trained on the first image of the region that becomes available (which can be crucial, for example, in post-catastrophe interventions) and to exploit sensors synergies in multi-sensorial schemes.</p>
<p>From these examples it is clear that, to process efficiently and accurately remote sensing images, modern processing systems must be designed to be robust to changes in acquisition conditions, temporal shifts and (ideally) be adaptive to sensors differences.The need for adapting existing models has been acknowledged since many years, as shown by the signature extension community [11], [12], but the change in the amounts and nature of data -as well as their resolutions -created the need for a new research direction.In this paper, we advocate that the solution can be found in domain adaptation (DA) strategies, a field deeply rooted in statistical and machine learning [13], [14].</p>
<p>Domain adaptation basically aims at adapting models trained to solve a specific task to a new-but-yet-related task, for which the knowledge of the initial model is sufficient, although not perfect.As a traditional example in computer vision, DA method have been deployed to adapt classifiers recognizing objects in pictures from commercial websites to the recognition of objects photographed form simple webcameras [15].In this example, the classifier is presented a problem with the same objective (classifying pictures into a limited set of object classes) and the same features, but where the data relations are slightly different (for example, in Amazon.com the pictures have no background and the object is mostly in the centre of the image, while in the case of the webcam images this is not the case).Domain adaptation is therefore used to adapt the classifier that is accurate on Amazon.com to the new data distribution.Of course, this is just one example: in the domain adaptation literature, models are modified to adapt to new data spaces (multimodal), related tasks (multitask) or subtle changes in probability distributions (see a recent review in [16]).The connections to multi-temporal, multi-sensor and multi-resolution image classification tasks above are strong [7].</p>
<p>The aim of this review paper is to provide an introduction to the domain adaptation field and</p>
<p>to provide examples of application of DA techniques in remote sensing.With this in mind, we draw a taxonomy of the DA strategies that have been proposed in recent remote sensing literature and discuss their strengths and weaknesses.We also provide a series of practical examples about the use of DA in high to very-high resolution image processing tasks.We will not enter into the technical details of specific DA literature: for readers interested in these, we refer to the recent surveys published in [13], [14], [16], [17].</p>
<p>The remainder of the paper is organized as follows: Section II is an overview of the DA problem and fixes the terminology and notations that will be used throughout the paper.Section III draws a taxonomy of DA approaches in four families, respectively based on i) invariant feature selection; ii) matching of data representation; iii) adaptation of the classifier used and iv) limited, but effective sampling in the new domain(s).These families are described together with recent references and key examples of remote sensing applications.Section V concludes the paper.</p>
<p>II. TRANSFER LEARNING AND DOMAIN ADAPTATION</p>
<p>Transfer learning problems arise when inference has to be made on processes which are not stationary over time or space.As we have discussed in the introduction, this is the case in the analysis of remote sensing images, where different acquisitions are typically subject to different conditions (e.g., illumination, viewing angle, soil moisture, topography).Such differences affect the observed spectral signatures of the land-cover types and therefore the distribution of the information classes in the feature space [18].Different transfer learning problems (and techniques to tackle them) have been considered in the literature: domain adaptation, multi-task learning, domain generalization, sample selection bias, covariate shift [14].In this paper we will focus on DA, which is a particular form of transfer learning.</p>
<p>Let us consider two domains, called source and target domain, associated with two images acquired on different geographical areas (but with similar land-cover characteristics) or on the same area at different time instants.Figure 2 sketches the DA problem in the context of remote sensing image classification.The source and target domains are associated with the joint probability distributions P s (X, Y ) and P t (X, Y ), respectively.The two joint probabilities define the classification problems on the two domains, where X is the input (vector) variable (spectral bands of the source image with possible additional features used to characterize the contextual information of the single pixel) and Y is the output variable associated with a set of classes (land-cover or land-use information).The aim of DA methods is to adapt a classifier trained on the source domain to make predictions on the target domain.</p>
<p>Supervised DA assumes that labeled samples are available for both domains.The labeled sets This DA setting is more challenging than the supervised case and requires important assumptions on the relationship between source and target domains to make the algorithm converge to a consistent solution on the target domain.All DA methods are based on the assumption that P s (X, Y ) and P t (X, Y ) are different, but close enough to ensure that the source-domain information can be of help for solving the target-domain learning problem.On the one hand, if source and target domain are arbitrarily different, there is no hope that the source-domain information will provide an advantage in solving the task in the target domain.On the other hand, if P s (X, Y ) = P t (X, Y ), no adaptation is necessary and the model trained on the source can be readily applied to the target.Semisupervised DA methods are effective in situations that lie in between these two extreme cases.
T s = {(x
Unsupervised DA methods are the last family, which assumes that two unlabeled domains have to be matched.This is the most difficult case, because label information is not available for any domain.In this situation, DA methods aim at matching the marginal distributions of the two domains P s (X) and P t (X) without knowledge on the learning task (classification or regression).</p>
<p>Unsupervised methods can be used as preprocessing of any analysis task (clustering, density estimation), but they imperatively need to have datasets with similar structural properties before adaptation.Unsupervised DA models are generally feature extractors or matching algorithms that exploit the geometrical structure of the data.Related problems are sample selection bias and covariate shift [23]- [25].Sample selection bias originates when the available training samples are not independently and randomly selected from the underlying distribution (i.e., the training set in not a random sample of the population).</p>
<p>This situation is very likely to occur in remote sensing problems where training points are usually selected and labeled through photo-interpretation or field surveys.Covariate shift is a particular case of sample selection bias where the bias depends only on the input variable X (and not on Y ).Different operational conditions that result in biased training samples are discussed in [26].Clearly, a training set T = {(x 1 , y 1 ), . . ., (x n , y n )} obtained under sample selection bias leads to skewed estimation of the true underlying distribution of the classes, resulting in an estimated P (X, Y ) = P (X, Y ).For this reason, the effect of a sample selection bias is similar to the DA problem described above.The covariate shift problem is generally not as severe as the general sample selection bias and the DA problem.Let us consider that both training sets on the source and target are samples with bias (bias depending on X only, i.e., covariate shift) from the same joint distribution.The joint probabilities on the two domains can be factorized as follows: P s (X, Y ) = P s (X)P s (Y |X) and P t (X, Y ) = P t (X)P t (Y |X).In this particular case of covariate shift, the estimated conditional probabilities will be approximately equal, while the marginal distributions will in general be different, i.e., P s (Y |X) ≈ P t (Y |X) and P s (X) = P t (X).In this situation, training samples of the source domain can be misleading for the classification of the target domain [27], [28].In the case of sample selection bias, source and target-domain samples are drawn (with bias) from the same underlying distribution, resulting in general in a milder type of shift with respect to DA (the problem of cross-domain class overlap is not likely to occur in sample selection bias problems).</p>
<p>Source domain</p>
<p>Domain adaptation</p>
<p>Sample selection bias</p>
<p>Target domain Fig. 3. Explanatory examples of domain adaptation and sample selection bias problems.The plots represent labeled samples in a bi-dimensional feature space on the source and target domain.A four-classes classification problem is considered.In the case of DA, the class-conditional densities may vary from the source to the target domain, resulting in a significantly different classification problem (the green circle corresponds to the location of the green class in the source domain).In the case of sample selection bias, the aforementioned issue will not occur resulting in a milder type of shift from the source domain.</p>
<p>In real RS problems, it is expected that the two aforementioned issues may occur at the same time and can be profoundly entangled.This means that: 1) the two (theoretical) underlying distributions P s (X, Y ) and P t (X, Y ) associated with source and target domains, respectively, may differ because of changes in the image acquisition conditions (e.g., radiometric conditions), and 2) the available training samples could be not fully representative of the statistical populations in their respective domains and will therefore lead to biased estimations of the class probabilities and to inaccurate classification models.In remote sensing literature, several techniques have been presented aiming at solving the transfer learning problem irrespectively of the cause of the dataset shift between source and target domains.The next section will present the different families of techniques that have been proposed in remote sensing image processing.</p>
<p>III. A TAXONOMY OF ADAPTATION METHODS</p>
<p>Adapting a model trained on one image to another (or a series of new images) can be performed in different ways.In this section, we detail recent approaches proposed in the remote sensing literature by grouping them in four categories:</p>
<p>• Selection of invariant features, where a set of the input features (original bands or additional features extracted from the remote sensing image) which are not affected by the shifting factors are identified and selected before training the classification algorithm.Accordingly, the features affected by the most severe data-set shift are removed and the classifier considers a feature space showing higher stability across domains.An alternative approach is to encode invariance by including additional synthetic labeled samples in the training set in order to extract features that better model the intra-class variability across the domains.</p>
<p>• Adaptation of the data distributions, where the data distributions of the target and source domains are made as similar as possible in order to keep the classifier unchanged.With respect to the previous family, these methods work on the original input spaces and try to extract a common space, where all domains can be treated equally.This is generally achieved by means of joint feature extraction.</p>
<p>• Adaptation of the classifier, where the classification model defined by training on the source domain is adapted to the target domain by considering unlabeled samples of the target domain.In this case, the data distributions remain unchanged and the classifier is adapted to the target data distribution using strategies based on semi-supervised learning.</p>
<p>• Adaptation of the classifier by active learning, where the adaptation is performed by providing a limited amount of well-chosen labeled samples from the target domain.This is a special case of the previous family, where we allow some new labeled examples to be sampled in the target domain in order to retrain the model iteratively.Due to their acquisition cost, these samples need to be selected well according to their potential to lead the model towards the desired target classifier.</p>
<p>The rest of this section details recent advances for these four families.We will limit the discussion to approaches specific to remote sensing literature and invite the interested reader to consult the specialized machine learning and computer vision literature in Â [13], [14], [16].</p>
<p>A. Selecting invariant features</p>
<p>The first family of DA methods is based on the selection of invariant features.Invariant features are usually a subset of the original set of features, which are the most robust to changes from the source to the target domain.The main idea of the approach is to select features in order to reduce the difference between P s (X, Y ) and P t (X, Y ).An alternative strategy to encode invariance is based on the inclusion of additional (synthetic) labeled samples in the training set, a procedure known in machine learning as data augmentation.A method adopting this strategy was studied in [29], where sample selection bias problems are addressed by enriching Let us consider the first strategy, and focus on the analysis of hyperspectral images as an application of particular interest.Hyperspectral sensors are capable to capture hundreds of narrow spectral bands from a wide range of the electromagnetic spectrum.For this reason, they are particularly sensitive to subtle changes in the image acquisition conditions, leading to a nonstationary behavior of the spectral signature of the classes and therefore to problems that should be solved by transfer learning and DA approaches.An example of shift in the signature of an hyperspectral image acquired by the Hyperion sensor over two areas of the Okavango Delta in Botswana is provided in Fig. 4.</p>
<p>In [30], the authors propose an approach for selecting subsets of features that are both 1) discriminative of the land-cover classes and 2) invariant between the source and the target domain.</p>
<p>The main idea of this approach is to explicitly consider two distinct terms in the criterion function for evaluating both 1) the discrimination capability ∆ of the feature subset, and 2) the data-set shift P of the features between source and target domain.The first term is standard in filter methods for feature selection and provides high scores when the features selected show some kind of dependency with the desired output (e.g. the classes to be predicted).The second term has been introduced to evaluate the invariance of the feature subset between the two domains.</p>
<p>The subset of features F is selected by jointly optimizing the two terms ∆ and P , i.e., by solving April 19, 2021 DRAFT the following multi-objective optimization problem:
argmin |F |=l (−∆(F ), P (F )),(1)
where l is the size of the feature subset.Both ∆ and P are treated as functions of the subset of considered features F .The specific definition for the terms ∆ and P are reported in [30] considering their parametric estimation (assuming Gaussian distribution of the classes) in both the supervised and semisupervised DA setting.In [31], the two terms are defined considering kernel-based dependence estimators and kernel embedding of conditional distributions resulting in a nonparametric approach, which does not require the estimation of the class distributions as an intermediate step.Problem ( 1) is solved by adopting a genetic multi-objective optimization algorithm.The solution results in features with high capability to discriminate classes (small value of −∆) and high stability on the two domains (small data set shift P ).Adopting a multiobjective optimization approach instead of considering a linear combination of the two terms frees the user from specifying in advance the relative importance of the two terms ∆ and P .The solution of the multi-objective problem allows one to find the solutions that represent the best trade-offs of discriminative and stable feature subsets for the specific transfer learning problem at hand.</p>
<p>In the following, we report the experimental results obtained on a hyperspectral image acquired by the Hyperion sensor of the Earth Observation 1 satellite in an area of the Okavango Delta, Botswana [32] (see Fig. 4).For more information about the experimental setting and the obtained results we refer the reader to [30].The labeled reference samples were collected on two spatially disjoint areas with slightly different characteristics, thus representing two different domains.The samples taken on the first area (considered as source domain) were partitioned into a training set T s and a test set T s by a random sampling.Samples taken on the second area (target domain) were used to derive a training set T t and test set T t according to the same procedure.</p>
<p>The estimated Pareto front for the selection of 6 features is reported in Fig. 5.Each point in the graphs corresponds to a different feature subset F selected (i.e., a feature set minimizing Eq. ( 1)).</p>
<p>In panel a), the color of the points indicates the Overall Accuracy (OA) obtained on the sourcedomain test set T s using an SVM classifier trained using T s (according to the reported color scale bar).In panel b), the color indicates the OA obtained by the same SVM classifier on the  target-domain test set T t .The results show that the solutions with higher relevance ∆ result in better classification accuracies on the source domain.However, relevance only is not sufficient for selecting features that are stable for the classification on the target domain.We observe that the most accurate solutions on the target domain T t are those that exhibit a good tradeoff between the relevance and invariance terms.This confirms the importance of the invariance term and shows that the P measure is able to capture the information of feature stability.In order to select the subset of features that leads to good generalization capabilities on different domains, tradeoff solutions between the two competing objectives should be identified.The selected subset of features results in an OA of 91.0% on the source domain and 80.7% on the target.The set of features selected according to the optimization of ∆ resulted in an OA of 92.7% on the source, but only of 64.4% on the target.This result shows that the features selected by accounting for the dataset shift between the domains can significantly improve the generalization capability on the target domain.according to the reported color scale bar (adapted from [30]).</p>
<p>B. Adapting data distributions</p>
<p>The second family reviewed considers DA methods aiming at adapting the representation of the original data, regardless of the model that will process them afterwards.A review of the methods proposed in computer vision and machine learning can be found in [16].Here we will focus on the approaches proposed in remote sensing literature.This type of adaptation is often done by relative normalization methods, i.e., methods that do not provide physical units as an output, rather similarly distributed digital numbers.Their aim is to make the data distributions more similar across the domains in order to train a single model that can classify simultaneously the source and target domain(s).</p>
<p>In general, a data representation transformation with the aim of making data sources more similar should have the following desirable properties.</p>
<p>-The method should be able to align unpaired data (Unpaired): this allows to align non coregistered data (not even imaging the same location), or data with different spatial resolutions.</p>
<p>-The method should be able to align data of different dimensionality (∆ dim.) to allow multisource classification.</p>
<p>-The method should be able to align several domains at the same time (Multisource), to enhance multitemporal adaptation, instead of pairwise adaptation.</p>
<p>-The method should be able to align in a nonlinear way (Nonlinear), since the transformation between domains can be nonlinear because of atmospheric or illumination effects.</p>
<p>-The method should be able to use labeled information from the source domain, when available (Labels in s).A discriminative transform tends to align better the datasets, since it aligns the data according to the semantic classes required by the user.</p>
<p>-The method should avoid to be forced to use labeled information in all domains (No labels in t), as labels might not be available in all domains or their acquisition would have a high cost (typically through terrestrial campaigns, see Section III-D).</p>
<p>Several methods have been proposed in recent remote sensing literature.We provide a brief review below and a summary in Table I.Depending on the specific situation, the analyst can use this table to select the most suitable approach.</p>
<p>Most of the recent literature focuses on feature extraction strategies, where the extracted features align the data spaces to each other.In that space, the same classifier (or regressor) can be applied to all the domains.Beyond works dealing with traditional or multidimensional histogram matching [33] or data alignment with PCA or kPCA [34], in [35] authors propose to minimize the statistical distance between domains, which is assessed through a kernel-based dependence estimator, the Maximum Mean Discrepancy (MMD [18]).Other studies still focus on feature extraction, but based on multiview models: in [36], Nielsen aligns domains with canonical correlation analysis (CCA) and performs change detection therein.The approach is extended to a kernel and semisupervised version in [37], where the authors perform change detection with different sensors.In [38], the domains are matched in a latent space defined through an eigenproblem aiming at preserving label (dis)similarities and the geometric structure of the single manifolds.A nonlinear (kernelized) version of the algorithm has been also proposed in [39].This approach is particularly appealing, since it can align an arbitrary number of domains of different dimensionality (as (k)CCA), but without requiring paired examples.However, it has the disadvantage of requiring labeled samples in all domains.In [40], the authors relax this requirement by working on semantic ties, i.e. samples issued from the same object, but whose class is unknown.This last method therefore requires at least a partial overlap between the images in order to find the ties, either manually or by stereo matching, as in [41].Authors in [42] regularize the manifold alignment solution with spatial information, leading to a more stable feature representation transfer.In [43] they propose a multiscale approach considering the preservation of both local and global geometric characteristics and relying on clustering pairs, rather than labeled correspondences.Other recent methods rely on eigendecompositions, such as those proposed in [44], [45].In [44] two PCA eigensystems (one for the source and another for the target domain) are aligned by minimizing their divergence.In [45], authors consider a sparse representation approach, where they reduce the difference between domains again by minimizing the MMD.In both papers [44], [45], the authors aim at transferring categories models learned on landscape views to aerial views from VHR remote sensing images.In [46], the authors propose a set of techniques based on sample reweighing and transformation to address different DA situations.The study offers also a causal interpretation of the different forms of domain shift.</p>
<p>The adaptation strategies are developed on the basis of the embedding of sample distributions in the reproducing kernel Hilbert space.</p>
<p>Beyond classical feature extraction, authors in [47] align multitemporal sequences based on a measure of similarity between sequences barycenters, which corresponds to a global alignment of the spectra in a time series of images.In [48], authors consider spatial shifts in large image acquisitions: the spectra are spatially detrended using Gaussian processes to avoid shifts related to localized class variability.In [49], authors perform anomaly detection by a sparse × SSMA [38] × × KEMA [39] ×
GM [50] × × × ×
discriminative transform that i) maximizes the distance between the anomaly class and the background classes (defined as a set of endmembers) and ii) minimizes the distance between the source and target distributions after reduction by PCA.In [50] the authors consider the domains as multidimensional graphs and propose to align the domains by solving a graph matching problem.</p>
<p>Finally, authors in [51] find a multispectral mapping between source and target spectra, in order to project the labeled pixels of the source into the target domain: tie points are found between the labeled source pixels and the pixels in the target by registration and then the mapping between source and target is learned by regression between the corresponding pairs.Then, the labeled pixels are projected into the target domain and are used to train a classifier therein.As for [40], partial overlap between the images is required.</p>
<p>As one can see in Table I, some methods will be more suitable than others depending on the problem: for example canonical correlation-based methods can be used only for coregistered data, while non-multiview methods ((k)PCA, (SS)TCA) cannot align more than two domains at a time.</p>
<p>In the following we compare a series of methods on the challenging problem of transferring a classifier over a multiangular sequence of images over Rio de Janeiro [52] illustrated in Fig. 6.More details on this example can be found in [38].The images are not coregistered, but are all acquired over a single pass of the WorldView2 sensor.For this reason, the only shifts observed are due to angular effects.The problem is a 11-classes problem, and a separate ground truth is Fig. 6.The five images of the Rio de Janeiro angular sequence [52].</p>
<p>provided per each image (Table II).</p>
<p>The adaptation experiment is designed as follows: we take the nadir image (off-nadir angle θ = 6.09• ) as the source one and use all the other as target ones.We apply the PCA, KPCA, GM and SSMA transforms and then train a classifier using 100 labeled pixels from the source domain and predict all the target domains using that classifier, without further modifications.For PCA, KPCA and GM, the adaptation is done for each target domain separately, while for SSMA a single adaptation projection is obtained for all domains at once.For SSMA we also used 50 labeled pixels per class from each target domain.To be fair in the evaluation, the projections for the PCA, KPCA and GM methods are obtained in an unsupervised way, but then the classifier is trained using the original training points from the nadir acquisition, stacked to the transformed labeled pixels of the domain to be tested.We also add a best case, where we directly use labeled samples from the target domains for the classification.LDA SVM Fig. 7. Classification results over the five Rio acquisitions (adapted from [38]). 100 labeled samples per class from the nadir image are used to train a classifier then used to test on the others.In the SSMA experiment, 50 labeled pixels per class are used from the other acquisitions.</p>
<p>The results are illustrated in Fig. 7: predicting in the off-nadir images using the original training samples from the nadir image leads to poor results, especially for strong off-nadir angles.All the methods considered leverage the decrease in performance and lead to a quasi-flat prediction surface (meaning that the model can predict correctly, regardless of the angular configuration), with particular good performances for SSMA method, which seems to align at best the data distributions.This is not surprising, since among the tested methods SSMA is the only one with a clear discriminative component (it uses labels in all domains to define the projections).</p>
<p>C. Adapting classifiers with semisupervised approaches</p>
<p>A widely used approach to DA is based on the adaptation of the model of the classifier derived on the source domain to the target domain.In the literature the approach is defined semisupervised if this adaptation is based only on unlabeled samples of the target domain, i.e.</p>
<p>no target training samples are used.The rationale of semisupervised adaptation is to use the relations between the distributions of the source and target domains in order to infer a reliable solution to the problem described in the target domain.The common assumption of most of the methods is that the source and target domains share the same set of classes and features.</p>
<p>The first attempts to address semisupervised domain adaptation in remote sensing image classification have been presented in [53], where a domain adaptation technique is proposed that updates the parameters of an already trained parametric maximum-likelihood (ML) classifier on the basis of the distribution of a new image for which no labeled samples are available.</p>
<p>In [54], the ML-based domain adaptation technique is extended to the framework of the Bayesian rule for cascade classification (i.e., the classification process is performed by jointly considering information contained in the source and the target domains).The basic idea in both the methods is modeling the observed spaces by a mixture of distributions, whose components can be estimated by the use of unlabeled target data.This is achieved by using the EM algorithm with finite Gaussian Mixture Model.In [55], [56], The semisupervised problem has also been extensively studied in the framework of kernel methods with Support Vector Machine (SVM) classifiers.This has been done especially for addressing sample selection bias problems (see Section II).Most of the semisupervised techniques proposed with SVM exploit the cluster assumption, i.e., adapt the position of the hyperplane estimated on the source domain to the target domain assuming that it should be located in low density regions of the feature space.In [58], authors employ the Transductive SVM, a method that iteratively moves the decision boundary of the SVM classifier towards low-density areas of the (unlabeled) target domain.Other semi-supervised approaches are imported in remote sensing in [59], where the SVM semisupervised learning is addressed in the primal formulation of the cost function.In [60], authors regularize the support vector machine solution by adding a new term in the optimization accounting for the divergence between source and target domain (the MMD discussed in Section III-B).By doing so, the decision function selected depends on a kernel that both projects in a discriminative space and minimizes the shift between training and test data.</p>
<p>In [61], authors cast the domain adaptation problem as a multi-task learning problem, where each source-domain pair (each task) is solved by deforming the kernel by sharing information among the tasks.The Laplacian SVM technique applied to the classification of multispectral remote sensing images is presented [62].It exploits an additional regularization term on the geometry of both the labeled and the unlabeled samples by using the graph Laplacian.In [63], authors also use a manifold-regularized classifier in a semisupervised setting, where the adaptation is performed by adding semilabeled examples from the target domain.</p>
<p>A specific semisupervised SVM defined for addressing DA problems is presented in [64].The Domain Adaptation SVM (DASVM) starts from a standard supervised learning on the training samples of the source domain that is followed by an iterative procedure.At each iteration it includes in the learning cost function a subset of unlabeled samples of the target domain adequately selected, while gradually removes the training samples of the source domain.At convergence the DASVM can classify accurately the samples of the target domain.</p>
<p>D. Adaptation of the classifier by active learning</p>
<p>In most of the above-mentioned approaches, it is assumed that no label information can be obtained in the newly acquired (target) domains (semisupervised DA).This assumption may hinder the success of classification in the case of very strong deformations or when new classes, unseen during training, appear in the test data.A small amount of labeled data issued form the target domain may solve this problem efficiently.However, since the acquisition is timely and can be costly, it becomes mandatory to chose the samples well.Active learning strategies have been proposed to tackle this challenging tasks and guide the DA process with the selection of the most informative target samples [19], [27], [28], [65]- [67].</p>
<p>Active learning is the name of a set of methodologies aiming at the interaction between a user and a prediction model, where the first provides labels by his / her knowledge of the task to be solved and the second performs the prediction and highlights samples, for which it has the highest uncertainty [68].By focusing on these samples, the user provides the labels where they help the most and thus allows the classifier to migrate in a fast way towards the optimal model.Surveys on active learning methods applied to remote sensing can be found in [69]- [71].</p>
<p>In the case of domain adaptation, the user provides examples coming from the target domain only and the optimal classifier is the one that would have been obtained with several examples in the target domain.The process starts for a classifier that is optimal for the source domain, and gradually evolves to model the data distribution in the target domain.Figure 8 summarizes the AL process for domain adaptation.</p>
<p>One could apply classical active learning strategies in transfer learning problems (under the sample selection bias assumption) with successful results, since classical AL will point out samples close to the current decision boundaries and the user, by the labels provided, will disclose the shifted areas, where the next iterations will focus.However, depending on the degree of transformation between the domains, one can use more sophisticated strategies that take into account measures of the deformation between the domains.In this respect, the following problems have driven DA-related research in active learning:</p>
<p>• When it is expected that new classes appear in the target domain, active learning can be used to highlight the areas of the feature space where these classes could be.By using the reasoning of sample selection bias, in [19], the feature space in the target domain is screened using clustering, and dense clusters with no labeled samples are presented to the user, who can then provide labels if new classes are present.In [72], the detection of new classes is set as a change detection problem, where uncertainty of changes is assessed with an information theoretic criterion.Image time series are analyzed in [21].</p>
<p>• When significant differences between source and target domains are expected (i.e., the sample selection bias assumption does not hold), the presence of labeled source samples (although beneficial at the beginning of the process), can be harmful for the classification of the target domain [27], [28].Refer to the example discussed in Section II, page 7: if the distributions of the classes in the target domain overlaps with those of different classes in the source domain, relying on the labels from the source will lead to errors of the classifier.</p>
<p>Accordingly, approaches in [27], [28], [67] consider reweighting of the samples in the training set enriched by AL: when samples from the source domain become less relevant or misleading for the correct classification of the target domain, they are downweighted in the adapted classifier or completely removed.Accordingly, the classifier specializes to the target domain through the inclusion of target samples and gradually forgets the initial source domain.</p>
<p>• When the areas to be processed become very large, specific solutions must be designed to avoid too many iterations of the AL process.In this respect, solutions based on selection of clusters [73], compressed sensing [74] or on geographically distributed search strategies [75]- [78] have been considered.</p>
<p>In the following, we focus on one example related to the second point above (the reweighting of source samples).This example is adapted from [67].We study the feasibility of the migration of a model optimized for landcover mapping in a geographical area to another spatially disjoint region.To do so, we consider the well-known Kennedy Space Center (KSC) hyperspectral image acquired by the AVIRIS spectrometer (top line of Fig. 9) and try to adapt the model learned therein to be accurate in a spatially disjoint section of the same flightline (bottom line of Fig. 9).</p>
<p>We consider only the 10 classes present in both images.The starting model is learnt using a training set composed of 50 labeled pixels per class and is then enriched by new samples either added randomly or using the Breaking Ties active learning strategy [79].The classifier is an SVM, either standard (when no other mention is done) or adaptive using the TrAdaBoost model, a domain adaptation method based on the reweighting of the SVM sample weights after the inclusion of the new labeled points from the target domain [66].</p>
<p>Source image</p>
<p>Source GT Target image Target GT (NOT AVAILABLE) When using the source SVM without adaptation, we reach an overall accuracy lower than 65%, while the results obtained by a SVM trained directly on the target labeled samples (which are available for testing) would provide an accuracy of 90% (Fig. 10).Here the shift is clearly visible and relates to a loss in accuracy of 25%.Using a random sampling in the target domain, we get a constant increase in performance (green line with * markers), but after 300 queries, we are still 5% away from the classifier learnt using only 500 samples from the target domain.</p>
<p>Moreover, the learning rate is slow and the gain is almost linear with the number of queries.We then assess different domain adaptation strategies.First TrAdaBoost is applied to the set enriched by the random samples (brown line with × markers): by forgetting the source domain (i.e. by downweighting the source samples that are contradictory with respect to the new samples from the target domain), we already see a significant improvement that fills half of the gap between the best case and the random sampling.But when using AL (blue line with diamond markers) and even more when using it in conjunction with the TrAdaBoost model (black line with circle markers), the learning rate is much higher in the first iterations (meaning that the first queries are much more effective than in the random sampling experiments) and the model converges to the result obtained with 500 random target queries (solid blue line) with only 250 active queries (corresponding to a total of 750 samples in the model, since we still have the 500 initial samples from the source).The right panel of Fig. 10 shows that the percentage of the support vectors from each domain with nonzero weights: in the target domain, this share increases constantly (solid blue line), while it stabilizes for the samples from the source (to 40% of the original training samples -dashed red line).This means that the importance of the source in the model is strongly reduced in the first iterations and then remains constant, while each new sample from the target becomes immediately important and receives a strong weight from the boosted SVM classifier.</p>
<p>IV. GUIDELINES FOR THE CHOICE OF THE ADAPTATION STRATEGY</p>
<p>In this section, we will first provide guidelines for the selection of the most appropriate adaptation strategy and then discuss the issue of the validation of the adapted models.</p>
<p>A. How to chose the adaptation strategy</p>
<p>In the previous sections, we presented different approaches to domain adaptation, grouped in four families.Depending on the problem considered, an analyst can favor one or the other.</p>
<p>However, there are some guidelines that should be taken into account.They will depend mainly on the data available (for instance the sensors to be used) and on the effort already provided by the analyst (for instance, whether a classifier is already available, or if labels in the target domain are available or can be acquired easily):</p>
<p>• If the data to be used are acquired by different sensors, they are associated with different feature spaces.In this case, only heterogeneous domain adaptation (i.e.methods that allow to align spaces of different dimensionality) should be considered.Accordinagly, multiview feature-representation-transfer methods such as (k)CCA or manifold alignment (see Section III-B) are the recommended choice.</p>
<p>• If a classifier trained on the source is already available -and the effort of training is considerable -methods of the third (adaptation of classifier) and fourth (adaptation by selective sampling) family should be preferred.These methods build on the model already defined on the source domain, while those of the two other families imply the definition of a new classifier that is successful in all domains.</p>
<p>• Whenever it is possible to acquire new labeled samples in the target, it should be done.</p>
<p>There is no better way for correcting for a dataset shift than having examples of the classconditional distribution in the target.Active learning and manifold alignment methods are to be preferred in that case.</p>
<p>• The level of dataset shift the methods can cope with goes along with their level of flexibility: representation methods relying on labeled samples from the target can cope with strong nonlinear deformations (since they allow for a kind of features registration between the domains), while those that do not use target samples (e.g., PCA, TCA, GM) are successful only if the data distributions are already pre-aligned and have not undergone drastic shifts (such as cases where the signature of a target class becomes identical of the one of another in the source).Among the unlabeled methods, the differences in their flexibility should be considered, going from linear global methods (e.g.PCA representation transfer) to local methods (e.g. based on clustering: GM, MA).If the first can address only rotations, translations and, to some extents, scalings of the data clouds, the others can model the per-sample transformation and allow more flexibility of the transform.The same type of reasoning holds for semisupervised methods: they will be able to correct for smaller shifts than methods based on active learning.When deployed in a domain adaptation setting, active learning mehtods collect target labeled samples that provide evidence of the real target class distributions, while the semisupervised method use only unlabeled data in the target and therefore cannot discover easily drastic changes in the distributions of the classes.</p>
<p>• The combination of methods of the different families is also possible.Selecting invariant features can be a preprocessing step to kernel manifold alignment, where the labels in the target domain have been acquired by active learning using the labels from the source domain.</p>
<p>With these simple guidelines in mind, the analyst can select the most appropriate strategy (or combine a series of them) according to the considered data and application.</p>
<p>B. How to validate</p>
<p>A typical bottleneck for the employment of an adaptation strategy is the validation of the adaptation process itself, since it is assumed that no (or only few) labeled data are available for the target domain.Nonetheless, one should assess whether the adaptation was successful in the processing of the target image, even though no labeled samples are available for such validation.To address this crucial issue, a circular validation strategy is presented and applied to remote sensing images in [64].The strategy is based on the idea that an intrinsic structure relates the solutions consistent with the source and the target domains.A solution for the target domain (for which no prior information is available) is assumed to be consistent if the solution obtained by applying the same domain adaptation algorithm in the reverse sense (i.e., by using the classification labels in place of missing prior knowledge for target-domain instances) to sourcedomain data (considered as unlabeled in the reverse domain adaptation learning) is associated with an acceptable accuracy (which can be evaluated due to the available true labels for sourcedomain samples).This strategy can be effective for both understanding if the adaptation is feasible in the considered data set and selecting the most effective strategy.</p>
<p>V. CONCLUSIONS</p>
<p>In this paper, we reviewed the recent advances in domain adaptation for remote sensing image analysis.Domain adaptation is a rising field of investigation in remote sensing, as it answers the need of re-using available ground reference samples to classify (or further process) new image acquisitions that may be covering different areas, at different time instants and possibly with different sensors.The increasing satellite data availability trend observed in the last years (in particular thanks to satellite constellations such as the Sentinels or the NASA A-train), as well as the commericalization of drone-mounted cameras pushed these problems at the forefront of researchers and analyst priorities.</p>
<p>We have reviewed the recent models proposed in the literature, grouped in four main families: i) the approaches based on the selection of invariant features, ii) those based on the matching of the data representation, iii) those based on the adaptation of the classifier trained on the source domain and iv) those based on limited, but effective sampling of labeled samples in the target domain.With practical examples, we have provided to the reader a thorough introduction to the field and some guidelines for the selection of the approaches to use in real application scenarios.</p>
<p>We believe that domain adaptation is of the highest importance to future Earth Observation, since multimodality and repeated imaging have become unavoidable [7].The data are already there and new challenging problems can now be tackled with remote sensing.The discipline has succeeded in entering many new sectors of society and it is now time to provide the tools to the users to perform a trustable monitoring that can be obtained in different sensor configuration or modalities.We think that domain adaptation and, more in general, machine learning can contribute to provide an answer to this call.</p>
<p>Figure 3
3
Figure 3 illustrates the two different issues of DA and sample selection bias with two explanatory examples.The plots report the distributions of the labeled samples from two domains in a bi-dimensional feature space.A four-classes classification problem is considered.In the case of DA, the class-conditional densities may change from the source to the target domain, (possibly) resulting in a significantly different classification problem.Note that the distribution of the classes in the target domain may overlap with different classes on the source domain (see the green circle in the target domain, representing the location of the green class in the source).</p>
<p>the training set with artificial examples that correspond to physical consistent variations of the training samples (illumination, size, rotation).To limit the number of additional examples to be used by the SVM, variations are generated only for training samples considered as support vectors by the classifier trained on the source domain only.</p>
<p>Fig. 4 .
4
Fig. 4. a) False color composition of a portion of the hyperspectral data set.b) Mean spectral signature of the classes on the source domain.c) Mean spectral signature of the classes on the target domain.</p>
<p>Fig. 5 .
5
Fig.5.Pareto front estimated using a multi-objective genetic algorithm for the selection of ten features.Each dot corresponds to a feature set minimizing Eq. (1).The color indicates the overall accuracy on a) source test set T s and b) target test set T t according to the reported color scale bar (adapted from[30]).</p>
<p>domain adaptation approaches based on multiple-classifier and multiple-cascade-classifier architectures have been defined.As base classifiers Gaussian ML classifiers, radial basis function neural-networks and hybrid cascade classifiers are used.Decision trees update and randomization are used for domain adaptation in [57]: a set of decision trees is made robust to dataset shift either by training it with the EM using density functions from the target domain (similarly to [54]) or by randomizing the decision trees (but in this case without control on the adaptation objective); authors also propose a semisupervised extension, where the classifiers performing poorly on the (few) labeled samples in the target domain are downweighted in the final decision.Finally, the domain adaptation technique proposed in [20] for multitemporal images addresses the challenging situation where source and target domains have a different set of classes.The sets of classes of the target and the source domains are automatically identified in the DA step by the joint use of unsupervised change detection and Jeffreys-Matusita statistical distance measure.This process results in the detection of classes that appeared or disappeared between the domains.</p>
<p>Fig. 8 .
8
Fig. 8. Flowchart of the active learning paradigm for domain adaptation.</p>
<p>Fig. 9 .
9
Fig. 9. Kennedy Space Center data used in the AL domain adaptation experiment.</p>
<p>2 Fig. 10 .
210
Fig.10.AL results over the KSC data of Fig.9(adapted from[67]).Left: learning rates (Overall accuracy) for different methods.Right: percentage of source (dashed red line) and target (solid blue line) α weights larger than 0.02 (source) and 0.2 (target) along the iterative AL process in the 'TrAdaBoost + AL' experiment (black line in the left panel).</p>
<p>Semisupervised DA methods assume that a training set is available only for the source domain, whereas target-domain information is limited to a set of unlabeled samples U t = {x 1 , . . ., x m }.Fig. 2. Graphical representation of the domain adaptation problem in the context of remote sensing image classification.Source and target images can be acquired on different geographical areas (but with similar land cover characteristics) or on the same area at different time.The two images are associated with two different joint distributions, which characterize the two classification problems.The two distributions can differ because of different acquisition conditions, e.g., illumination, viewing angle, soil moisture, topography.
Source imageTarget imageDomainAdaptationP s (X, Y ) = P s (X)P s (Y |X)6 =P t (X, Y ) = P t (X)P t (Y |X)to solve the target problem. Most of the works in DA assume that source and target domainsshare the same set of classes. Only few papers address DA considering differences in the set ofclasses between source and target [19]-[22].
1 , y 1 ), . . ., (x n , y n )} and T t = {(x 1 , y 1 ), . . ., (x m , y m )} are the source and the targetdomain training sets, respectively.Supervised DA methods focus on challenging situations where labeled target-domain samples are less numerous than those available in the source domain, i.e., m &lt;&lt; n.In such conditions, the proper usage of source-domain information is very important</p>
<p>TABLE I .
I
REPRESENTATION ALIGNMENT METHODS USED IN REMOTE SENSING.
MethodLabels in s No labels in t Multisource Unpaired ∆ dim. NonlinearPCA kPCA [34] (SS)TCA [35] CCA [36] kCCA [37] MA [43]× × × × ×× ×× × ×× ×× × ×× ×</p>
<p>TABLE II .
II
NUMBER OF LABELED PIXELS AVAILABLE FOR EACH DATASET IN THE MULTIANGULAR EXPERIMENTS (θ = OFF-NADIR ANGLE).−29.16 • 6.09 • 26.76 • 39.5 •
H Class H H −38.79 • Water H H θ 8326079937 66084 63492 54769Grass812781278127 8127 8127Pools244244223195195Trees423140743066 3046 3046Concrete707719719719696Bare soil790790790790811Asphalt294929492949 2827 2827Grey buildings629160615936 4375 4527Red buildings114710801070 1046 1042White buildings168316831571 1571 1571Shadows18291056705512525Tarmac517951795179 2166 2758−38.79 •−29.16 •6.09 •26.76 •39.5 •
April 19, 2021 DRAFT</p>
<p>Analysis of monotonic greening and browning trends from global ndvi time-series. R Jong, S De Bruin, A De Wit, M E Schaepman, D L Dent, Remote Sens. Enviro. 1152011</p>
<p>The importance of physical quantities for the analysis of multitemporal and multiangular optical very high spatial resolution images. F Pacifici, N Longbotham, W Emery, IEEE Trans. Geosci. Remote Sens. 52102014</p>
<p>Evaluation of Landsat and MODIS data fusion products for analysis of dryland forest phenology. J J Walker, K M De Beurs, R H Wynne, F Gao, Remote Sens. Enviro. 1172012</p>
<p>Processing of thermal hyperspectral and digital color cameras: outcome of the 2014 data fusion contest. W Liao, X Huang, F Van Collie, A Gautama, W Philips, H Liu, T Zhu, M Shimoni, G Moser, D Tuia, IEEE J. Sel. Topics Appl. Earth Observ. 862015</p>
<p>Multitemporal fusion of Landsat/TM and ENVISAT/MERIS for crop monitoring. J Amorós-López, L Gómez-Chova, L Alonso, L Guanter, R Zurita-Milla, J Moreno, G Camps-Valls, Int. J. Applied Earth Obs. Geoinfo. 23Aug 2013</p>
<p>From land cover-graphs to urban structure types. I Walde, S Hese, C Berger, C Schmullius, Int. J. Geogr. Info. Sci. 2832014</p>
<p>Multimodal classification of remote sensing images: A review and future directions. L Gómez-Chova, D Tuia, G Moser, G Camps-Valls, Proceedings of the IEEE. 10392015</p>
<p>Gaussian Process retrieval of chlorophyll content from imaging spectroscopy data. J Verrelst, L Alonso, J P R Caicedo, J Moreno, G Camps-Valls, IEEE J. Sel. Topics Appl. Earth Observ. 622013</p>
<p>Detection of early plant stress responses in hyperspectral images. J Behmann, J Steinrücken, L Plümer, ISPRS J. Int. Soc. Photo. Remote Sens. 932014</p>
<p>Tree species classification in the Southern Alps based on the fusion of very high geometrical resolution multispectral/hyperspectral images and LiDAR data. M Dalponte, L Bruzzone, D Gianelle, Remote Sens. Enviro. 1232012</p>
<p>Computer-aided analysis of LANDSAT-I MSS data: a comparison of three approaches, including a "modified clustering" approach. M D Fleming, J S Berkebile, R M Hoffer, LARS information note 072475. 1975Purdue University</p>
<p>Signature extension through space for northern landcover classification: A comparison of radiometric correction methods. I Olthof, C Butson, R Fraser, Remote Sens. Environ.. 9532005</p>
<p>J Quiñonero-Candela, M Sugiyama, A Schwaighofer, N D Lawrence, Dataset Shift in Machine Learning. MIT Press2009</p>
<p>A survey on transfer learning. S J Pan, Q Yang, IEEE Trans. Know. Data Eng. 2210October 2010</p>
<p>Adapting visual category models to new domains. K Saenko, B Kulis, M Fritz, T Darrell, Proc. ECCV, 2010. ECCV, 2010</p>
<p>Visual domain adaptation: a survey of recent advances. V M Patel, R Gopalan, R Li, R Chellappa, IEEE Signal Proc. Mag. 3232015</p>
<p>Machine learning in non-stationary environments. M Sugiyama, M Kawanabe, 2012MIT press</p>
<p>Understanding angular effects in VHR imagery and their significance for urban land-cover model portability: a study of two multi-angle in-track image sequences. G Matasci, N Longbotham, F Pacifici, M Kanevski, D Tuia, ISPRS J. Int. Soc. Photo. Remote Sens. 1072015</p>
<p>Using active learning to adapt remote sensing image classifiers. D Tuia, E Pasolli, W J Emery, Remote Sens. Environ. 11592011</p>
<p>A novel domain adaptation Bayesian classifier for updating land-cover maps with class differences in source and target domains. K Bahirat, F Bovolo, L Bruzzone, S Chaudhuri, IEEE Trans. Geosci. Remote Sens. 5072012</p>
<p>Updating land-cover maps by classification of image time series: A novel change-detection-driven transfer learning approach. B Demir, F Bovolo, L Bruzzone, IEEE Trans. Geosci. Remote Sens. 5112013</p>
<p>Semisupervised learning of hyperspectral data with unknown land-cover classes. G Jun, J Ghosh, IEEE Trans. Geosci. Remote Sens. 5112013</p>
<p>Sample selection bias as a specification error. J J Heckman, Econometrica. 4711979</p>
<p>Learning and evaluating classifiers under sample selection bias. B Zadrozny, Proc. ICML. ICML2004</p>
<p>Correcting sample selection bias by unlabeled data. J Huang, A Gretton, B Schölkopf, A J Smola, K M Borgwardt, Proc. NIPS. NIPSMIT Press2007</p>
<p>Active and semisupervised learning for the classification of remote sensing images. C Persello, L Bruzzone, IEEE Trans. Geosci. Remote Sens. 52112014</p>
<p>Active learning for domain adaptation in the supervised classification of remote sensing images. C Persello, L Bruzzone, IEEE Trans. Geosci. Remote Sens. 50112012</p>
<p>Interactive domain adaptation for the classification of remote sensing images using active learning. C Persello, IEEE Geoscience and Remote Sensing Letters. 1042013</p>
<p>Encoding invariances in remote sensing image classification with svm. E Izquierdo-Verdiguier, V Laparra, L Gómez-Chova, G Camps-Valls, IEEE Geosci. Remote Sens. Lett. 1052013</p>
<p>A novel approach to the selection of spatially invariant features for the classification of hyperspectral images with improved generalization capability. L Bruzzone, C Persello, IEEE Trans. on Geosci. Remote Sens. 4792009</p>
<p>Kernel-based domain invariant feature selection in hyperspectral images for transfer learning. C Persello, L Bruzzone, IEEE Trans. Geosci. Remote Sens. 992016</p>
<p>Investigation of the random forest framework for classification of hyperspectral data. J Ham, Y Chen, M M Crawford, J Ghosh, IEEE Trans. Geosci. Remote Sens. 4332005</p>
<p>Multidimensional probability density function matching for preprocessing of multitemporal remote sensing images. S Inamdar, F Bovolo, L Bruzzone, S Chaudhuri, IEEE Trans. Geosci. Remote Sens. 4642008</p>
<p>Kernel principal component and maximum autocorrelation factor analyses for change detection. A Nielsen, M J Canty, Proc. SPIE. SPIEBerlin, Germany2009</p>
<p>Semisupervised transfer component analysis for domain adaptation in remote sensing image classification. G Matasci, M Volpi, M Kanevski, L Bruzzone, D Tuia, IEEE Trans. Geosci. Remote Sens. 5372015</p>
<p>The regularized iteratively reweighted MAD method for change detection in multi-and hyperspectral data. A A Nielsen, IEEE Trans. Im. Proc. 1622007</p>
<p>Spectral alignment of cross-sensor images with automated kernel canonical correlation analysis. M Volpi, G Camps-Valls, D Tuia, ISPRS J. Int. Soc. Photo. Remote Sens. 1072015</p>
<p>Semisupervised manifold alignment of multimodal remote sensing images. D Tuia, M Volpi, M Trolliet, G Camps-Valls, IEEE Trans. Geosci. Remote Sens. 52122014</p>
<p>Kernel manifold alignment for domain adaptation. D Tuia, G Camps-Valls, PLoS One. 11e01486552016</p>
<p>Weakly supervised alignment of multisensor images. D Marcos Gonzalez, G Camps-Valls, D Tuia, Proc. IGARSS. IGARSSMilan, Italy2015</p>
<p>Semantic tie points. J Montoya-Zegarra, C Leistner, K Schindler, Proc. IEEE WACV. IEEE WACVClearwater Beach, FL2013</p>
<p>Spectral and spatial proximity-based manifold alignment for multitemporal hyperspectral image classification. H L Yang, M M Crawford, IEEE Trans. Geosci. Remote Sens. 5412016</p>
<p>Domain adaptation with preservation of manifold geometry for hyperspectral image classification. H L Yang, M M Crawford, IEEE J. Sel. Topics Appl. Earth Observ. 992016</p>
<p>Unsupervised cross-view semantic transfer for remote sensing image classification. H Sun, S Liu, S Zhou, H Zou, IEEE Geosci. Remote Sens. Lett. 992016</p>
<p>Transfer sparse subspace analysis for unsupervised cross-view scene model adaptation. H Sun, S Liu, S Zhou, H Zou, IEEE J. Sel. Topics Appl. Earth Observ. 992016</p>
<p>Single-source domain adaptation with target and conditional shift. K Zhang, B Schölkopf, K Muandet, Z Wang, Z Zhou, C Persello, Regularization, Optimization, Kernels, and Support Vector Machines. CRC Press2014</p>
<p>A global averaging method for dynamic time warping, with applications to clustering. F Petitjean, J Inglada, P Gancarski, Pattern Recogn. 4432011</p>
<p>Spatially adaptive classification of land cover with remote sensing data. G Jun, J Ghosh, IEEE Trans. Geosci. Remote Sens. 4972011</p>
<p>Sparse transfer manifold embedding for hyperspectral target detection. Lefei Zhang, Liangpei Zhang, Dacheng Tao, Xin Huang, IEEE Trans. Geosci. Remote Sens. 5222014</p>
<p>Graph matching for adaptation in remote sensing. D Tuia, J Muñoz-Marí, L Gómez-Chova, J Malo, IEEE Trans. Geosci. Remote Sens. 5112013</p>
<p>Three-layer convex network for domain adaptation in multitemporal VHR images. E Othman, Y Bazi, N Alajlan, H Alhichri, IEEE Geosci. Remote Sens. Lett. 992016</p>
<p>2011 GRSS Data Fusion Contest: Exploiting WorldView-2 multi-angular acquisitions. F Pacifici, J Chanussot, Q Du, Proc. IGARSS. IGARSSVancouver, CA2011</p>
<p>Unsupervised retraining of a maximum-likelihood classifier for the analysis of multitemporal remote-sensing images. L Bruzzone, D Fernández-Prieto, IEEE Trans. Geosci. Remote Sens. 3922001</p>
<p>A partially unsupervised cascade classifier for the analysis of multitemporal remote-sensing images. L Bruzzone, D Fernández-Prieto, Pattern Rec. Letters. 2392002</p>
<p>A multiple cascade-classifier system for a robust a partially unsupervised updating of land-cover maps. L Bruzzone, R Cossu, IEEE Trans. Geosci. Remote Sens. 4092002</p>
<p>Combining parametric and non-parametric algorithms for a partially unsupervised classification of multitemporal remote-sensing images. L Bruzzone, R Cossu, G Vernazza, Info. Fusion. 32002</p>
<p>Exploiting class hierarchy for knowledge transfer in hyperspectral data. S Rajan, J Ghosh, M Crawford, IEEE Trans. Geosci. Remote Sens. 44112006</p>
<p>A novel transductive SVM for semisupervised classification of remote-sensing images. L Bruzzone, M Chi, M Marconcini, IEEE Trans. Geosci. Remote Sens. 44112006</p>
<p>Semi-supervised classification of hyperspectral images by SVMs optimized in the primal. M Chi, L Bruzzone, IEEE Trans. Geosci. Remote Sens. 4562007</p>
<p>Learn multiple-kernel SVMs for domain adaptation in hyperspectral data. Z Sun, C Wang, H Wang, J Li, IEEE Geosci. Remote Sens. Lett. 1052013</p>
<p>Multitask remote sensing data classification. J M Leiva-Murillo, L Gómez-Chova, G Camps-Valls, IEEE Trans. Geosci. Remote Sens. 5112013</p>
<p>Semi-supervised image classification with Laplacian support vector machines. L Gómez-Chova, G Camps-Valls, J Muñoz-Marí, J Calpe-Maravilla, IEEE Geosci. Remote Sens. Letters. 532008</p>
<p>Adaptive classification for hyperspectral image data using manifold regularization kernel machines. W Kim, M M Crawford, IEEE Trans. Geosci. Remote Sens. 48112010</p>
<p>Domain adaptation problems: a DASVM classification technique and a circular validation strategy. L Bruzzone, M Marconcini, IEEE Trans. Patt. Anal. Mach. Intel. 3252010</p>
<p>An efficient active learning algorithm with knowledge transfer for hyperspectral data analysis. G Jun, J Ghosh, Proc. IGARSS. IGARSSBoston, MA2008</p>
<p>An active learning approach to hyperspectral data classification. S Rajan, J Ghosh, M Crawford, IEEE Trans. Geosci. Remote Sens. 4642008</p>
<p>SVM-based boosting of active learning strategies for efficient domain adaptation. G Matasci, D Tuia, M Kanevski, IEEE J. Sel. Topics Appl. Earth Observ. 552012</p>
<p>Active Learning. B Settles, 2012Morgan and Claypool Publishers</p>
<p>A survey of active learning algorithms for supervised remote sensing image classification. D Tuia, M Volpi, L Copa, M Kanevski, J Muñoz-Marí, IEEE J. Sel. Topics Signal Proc. 532011</p>
<p>Active learning: Any value for classification of remotely sensed data?. M M Crawford, D Tuia, L H Hyang, Proceedings of the IEEE. 10132013</p>
<p>Active learning methods in classification of remote sensing images. L Bruzzone, C Persello, B Demir, Signal and Image Processing for Remote Sensing. C Chen, CRC Press2012</p>
<p>Detection of land-cover transitions in multitemporal remote sensing images with active learning based compound classification. B Demir, F Bovolo, L Bruzzone, IEEE Trans. Geosci. Remote Sens. 5052012</p>
<p>Active learning in the spatial-domain for landslide mapping in remote sensing images. A Stumpf, N Lachiche, J P Malet, N Kerle, A Puissant, Proc. ECML, workshop "Active Learning in Real Applications. ECML, workshop "Active Learning in Real ApplicationsEdinbrough, Scotland2012</p>
<p>Land-cover classification of remotely sensed images using compressive sensing having severe scarcity of labeled patterns. M Roy, F Melgani, A Ghosh, E Blanzieri, S Ghosh, IEEE Geosci. Remote Sens. Lett. 1262015</p>
<p>Large-scale image classification using active learning. N Alajlan, E Pasolli, F Melgani, A Franzoso, DRAFT Geosci. Remote Sens. Letters. 111April 19. 2021. 2014IEEE</p>
<p>Pattern retrieval in large image databases using multiscale coarse-to-fine cascaded active learning. P Blanchart, M Ferecatu, Shiyong Cui, M Datcu, IEEE J. Sel. Topics Appl. Earth Observ. 742014</p>
<p>Definition of effective training sets for supervised classification of remote sensing images by a novel cost-sensitive active learning approach. B Demir, L Minello, L Bruzzone, IEEE Trans. Geosci. Remote Sens. 522014</p>
<p>Cost-sensitive active learning with lookahead: optimizing field surveys for remote sensing data classification. C Persello, A Boularis, M Dalponte, T Gobakken, E Naesset, B Schölkopf, IEEE Trans. Geosci. Remote Sens. 52102014</p>
<p>Active learning to recognize multiple types of plankton. T Luo, K Kramer, D B Goldgof, L O Hall, S Samson, A Remsen, T Hopkins, J. Mach. Learn. Res. 62005</p>            </div>
        </div>

    </div>
</body>
</html>