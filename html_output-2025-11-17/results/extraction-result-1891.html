<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1891 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1891</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1891</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-38.html">extraction-schema-38</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how different evaluation metrics (citations, peer review, journal prestige, automated systems) perform when assessing scientific discoveries of varying novelty or transformational nature, including comparisons between early/proxy metrics and later ground-truth impact measures.</div>
                <p><strong>Paper ID:</strong> paper-282138806</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2510.14327v1.pdf" target="_blank">What is missing from this picture? Persistent homology and mixup barcodes as a means of investigating negative embedding space</a></p>
                <p><strong>Paper Abstract:</strong> Recent work in the information sciences, especially informetrics and scientometrics, has made substantial contributions to the development of new metrics that eschew the intrinsic biases of citation metrics. This work has tended to employ either network scientific (topological) approaches to quantifying the disruptiveness of peer-reviewed research, or topic modeling approaches to quantifying conceptual novelty. We propose a combination of these approaches, investigating the prospect of topological data analysis (TDA), specifically persistent homology and mixup barcodes, as a means of understanding the negative space among document embeddings generated by topic models. Using top2vec, we embed documents and topics in n-dimensional space, we use persistent homology to identify holes in the embedding distribution, and then use mixup barcodes to determine which holes are being filled by a set of unobserved publications. In this case, the unobserved publications represent research that was published before or after the data used to train top2vec. We investigate the extent that negative embedding space represents missing context (older research) versus innovation space (newer research), and the extend that the documents that occupy this space represents integrations of the research topics on the periphery. Potential applications for this metric are discussed.</p>
                <p><strong>Cost:</strong> 0.016</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1891.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1891.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how different evaluation metrics (citations, peer review, journal prestige, automated systems) perform when assessing scientific discoveries of varying novelty or transformational nature, including comparisons between early/proxy metrics and later ground-truth impact measures.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>This_paper_mixup_empirical</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Empirical analysis of mixup barcodes and persistent homology on UF publications (this paper)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An empirical study using top2vec embeddings, persistent homology and mixup barcodes to test whether documents published before (Class A: 2001-2007) or after (Class B: 2021-2023) the training period (2008-2020) are more likely to 'fill' negative embedding space (holes) in topic embeddings; includes permutation tests and localized analyses of persistent holes.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>study_type</strong></td>
                            <td>empirical analysis of embedding-based novelty proxies using TDA</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_metrics_studied</strong></td>
                            <td>total mixup (mixup barcodes), occupancy of negative embedding space (mixup simplex counts), topic-level embedding proximity (top2vec-derived topics)</td>
                        </tr>
                        <tr>
                            <td><strong>ground_truth_measure</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type_classification</strong></td>
                            <td>temporal proxy: Class A (pre-training publications, 2001-2007) vs Class B (post-training publications, 2021-2023); interpreted as 'missing context' vs 'innovation/recombinant' respectively</td>
                        </tr>
                        <tr>
                            <td><strong>sample_characteristics</strong></td>
                            <td>All peer-reviewed UF-affiliated articles indexed in dimensions.ai, 2001-2023; training set 2008-2020 (73,302 docs); Class A 2001-2007 (20,139 docs); Class B 2021-2023 (20,139 docs). Embeddings: top2vec → UMAP to 5D → 692 topic clusters; analysis in 5D.</td>
                        </tr>
                        <tr>
                            <td><strong>key_quantitative_findings</strong></td>
                            <td>Total mixup (100 iterations, 10% random subsamples): mean total mixup Class A = 193.2258, Class B = 187.8991, observed mean difference = 5.3267; permutation test (10,000 permutations) p < 0.0001. Persistent-holes analysis: 252 one-dimensional holes detected overall; 11 holes with persistence > 0.2; in 4 of those 11 persistent holes Class B had greater average mixup than Class A. Iterative subsampling: 100 iterations per class, 10% sample size per iteration.</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_truth_gap_magnitude</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>temporal_pattern</strong></td>
                            <td>Documents published before the training period (Class A) statistically more frequently 'fill' negative space (higher total mixup), suggesting embeddings infer missing historical context; however, a minority of long-persistent holes (4 of 11 with persistence >0.2) were filled more by post-training documents (Class B), indicating some instances where later publications occupy innovation spaces.</td>
                        </tr>
                        <tr>
                            <td><strong>field_specific_findings</strong></td>
                            <td>Localized analyses of specific holes revealed disciplinary mixes; e.g., hole index 9 (filled more by Class B) combined life sciences, physical sciences, agriculture/environment, and medicine; hole index 11 (filled more by Class A) included medicine, engineering, life sciences, social science. No broad field-level statistical stratification beyond these localized examples.</td>
                        </tr>
                        <tr>
                            <td><strong>relationship_shape</strong></td>
                            <td>Not formalized into a mathematical curve; pattern is heterogeneous (majority effect favoring pre-training docs filling holes, with exceptions among persistent holes).</td>
                        </tr>
                        <tr>
                            <td><strong>automated_system_performance</strong></td>
                            <td>top2vec embeddings + mixup detect pre-training historical/contextual documents occupying negative space; post-training (novel) documents are detected less often unless they fill specific persistent holes. No conventional classification metrics (precision/recall) reported for novelty detection.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanism_identified</strong></td>
                            <td>Primary mechanism: truncation of embedding model training data (2008-2020) causes the model to (a) infer 'missing context' as negative space which is often occupied by earlier (pre-training) documents, and (b) ignore or omit words not seen during training for truly novel post-training documents (top2vec ignores unseen words), so novel works may not be fitted into existing embedding topology unless the model is retrained or pre-trained on larger corpora.</td>
                        </tr>
                        <tr>
                            <td><strong>correction_approaches</strong></td>
                            <td>Proposed: pre-train on larger corpora (e.g., Wikipedia, Web of Science, dimensions.ai) and then fine-tune (BERT-style) to reduce omitted words and better represent generalized scientific structure; re-training embeddings to incorporate new documents so novel pieces 'fit' the puzzle.</td>
                        </tr>
                        <tr>
                            <td><strong>counterexamples_or_exceptions</strong></td>
                            <td>Yes — some persistent holes (4 of 11 with persistence >0.2) showed higher mixup for post-training documents (Class B), i.e., certain long-lived cavities were preferentially filled by later, potentially innovative work.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_or_challenges_theory</strong></td>
                            <td>Mixed: challenges a simplistic expectation that negative embedding space will primarily indicate future innovation; instead shows negative space often represents historical 'missing context' inferred by the model (supporting model-bias / training-data-truncation explanations of proxy failure), while also showing exceptions where later publications occupy some persistent innovation-like cavities.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1891.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e1891.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how different evaluation metrics (citations, peer review, journal prestige, automated systems) perform when assessing scientific discoveries of varying novelty or transformational nature, including comparisons between early/proxy metrics and later ground-truth impact measures.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Mixup_TDA_methods</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Mixup barcodes and persistent homology (topological data analysis methods)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Persistent homology identifies multi-scale topological holes in embeddings; mixup barcodes (image persistence) quantify how adding points from a second distribution causes earlier death of homological features, summarised as total mixup to measure how new data fill negative embedding space.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>study_type</strong></td>
                            <td>method development / methodological application (TDA applied to topic embeddings)</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_metrics_studied</strong></td>
                            <td>total mixup (sum of per-feature mixup = (d - d')/(d - b)), representative cycles / hole birth-death values</td>
                        </tr>
                        <tr>
                            <td><strong>ground_truth_measure</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type_classification</strong></td>
                            <td>Not an explicit novelty classification method per se; operationalized in this study as 'documents that cause earlier death of holes' indicating occupancy of negative space (interpreted as missing context or interdisciplinarity/innovation depending on temporal origin).</td>
                        </tr>
                        <tr>
                            <td><strong>sample_characteristics</strong></td>
                            <td>Applied to 692 topic centroid embeddings from UF corpus (UMAP 5D projection) with class documents (Class A, Class B) mixed in via iterative 10% subsamples (100 iterations) to compute total mixup per class.</td>
                        </tr>
                        <tr>
                            <td><strong>key_quantitative_findings</strong></td>
                            <td>Detected 252 one-dimensional holes in topic embeddings; total mixup comparisons showed mean Class A > Class B (193.2258 vs 187.8991; diff 5.3267; permutation p < 0.0001). For persistent holes (persistence>0.2), 11 holes identified and 4 showed greater mixup for Class B.</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_truth_gap_magnitude</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>temporal_pattern</strong></td>
                            <td>Mixup reveals that historical (pre-training) documents more often fill holes inferred from later-topic embeddings, indicating models' negative space can correspond to missing past context rather than future innovation; minority temporal exceptions exist in persistent holes.</td>
                        </tr>
                        <tr>
                            <td><strong>field_specific_findings</strong></td>
                            <td>When applied to specific holes, mixup identified interdisciplinary documents spanning multiple subject classifications; method reveals topical composition of holes but does not by itself provide general field-level bias quantification.</td>
                        </tr>
                        <tr>
                            <td><strong>relationship_shape</strong></td>
                            <td>Not framed as a smooth functional relationship; mixup is an additive summary over homological features.</td>
                        </tr>
                        <tr>
                            <td><strong>automated_system_performance</strong></td>
                            <td>Method successfully quantifies interactions between two point clouds (training topics vs added documents); computationally expensive for large batches, mitigated here by iterative subsampling.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanism_identified</strong></td>
                            <td>Mixup detects homological interactions by finding mixup simplices (simplices from P ∪ Q that kill features born in P earlier than in P alone), hence highlighting which new data points fill holes and at what filtration values.</td>
                        </tr>
                        <tr>
                            <td><strong>correction_approaches</strong></td>
                            <td>Mixup itself is presented as a diagnostic; suggested corrective step is to re-train or pre-train embeddings so that genuinely novel documents are integrated rather than ignored.</td>
                        </tr>
                        <tr>
                            <td><strong>counterexamples_or_exceptions</strong></td>
                            <td>Yes — some persistent holes are preferentially filled by newer documents (Class B), showing mixup can detect both historical and innovative fillings depending on hole structure.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_or_challenges_theory</strong></td>
                            <td>Supports the idea that topological diagnostics can reveal differences between proxy indicators (embedding-derived negative space) and notions of innovation; shows that proxy measures (mixup) may reflect training-data structure (historical gaps) rather than purely future-transformational novelty.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1891.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e1891.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how different evaluation metrics (citations, peer review, journal prestige, automated systems) perform when assessing scientific discoveries of varying novelty or transformational nature, including comparisons between early/proxy metrics and later ground-truth impact measures.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Citation_metrics_bias</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Citation-based metrics (citation counts, impact factor, h-index and similar)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Traditional bibliometric/proxy metrics widely used to evaluate research impact, but noted to have intrinsic biases (disciplinary, format exclusions like books) and limitations for assessing conceptual novelty or interdisciplinarity.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>study_type</strong></td>
                            <td>critical literature discussion of citation metrics</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_metrics_studied</strong></td>
                            <td>citation counts, impact factor, H-index, journal-based metrics</td>
                        </tr>
                        <tr>
                            <td><strong>ground_truth_measure</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type_classification</strong></td>
                            <td>Implicitly: disruptive/developing or conventional/novel work — concern that citation metrics misrepresent novelty and interdisciplinary outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>sample_characteristics</strong></td>
                            <td>General critique drawing on prior literature; no new empirical sample in this paper for citation-based measures.</td>
                        </tr>
                        <tr>
                            <td><strong>key_quantitative_findings</strong></td>
                            <td>No original quantitative reanalysis provided in this paper; qualitative points: citation metrics often exclude books/book chapters (hurting arts/humanities and some social sciences), and have known biases referenced in literature.</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_truth_gap_magnitude</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>temporal_pattern</strong></td>
                            <td>Paper does not quantify citation temporal dynamics here, but references literature (e.g., delayed recognition phenomena) in SciSci context.</td>
                        </tr>
                        <tr>
                            <td><strong>field_specific_findings</strong></td>
                            <td>Explicit: arts, humanities, and social sciences are disadvantaged because books/book chapters are often not indexed in Web of Science and thus not counted in typical citation-based metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>relationship_shape</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>automated_system_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>mechanism_identified</strong></td>
                            <td>Mechanisms mentioned: indexing coverage bias (books not indexed), disciplinary publication norms (monographs vs articles), and structural differences in citation practices leading to biased metric outcomes.</td>
                        </tr>
                        <tr>
                            <td><strong>correction_approaches</strong></td>
                            <td>Referencing broader SciSci work that proposes alternative metrics that account for conceptual novelty (topic-modeling, network/disruptiveness measures) rather than raw citation counts; no empirical correction tested in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>counterexamples_or_exceptions</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>supports_or_challenges_theory</strong></td>
                            <td>Supports the assertion in the Proxy-to-Ground-Truth Gap Theory that citation proxies can systematically misrepresent impact across fields and for novel work, motivating development of alternative measures that capture conceptual novelty.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1891.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e1891.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how different evaluation metrics (citations, peer review, journal prestige, automated systems) perform when assessing scientific discoveries of varying novelty or transformational nature, including comparisons between early/proxy metrics and later ground-truth impact measures.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Network_disruptiveness_measures</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Network/topological disruptiveness measures (citation DAG analyses)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Approaches that build citation networks (directed acyclic graphs) to quantify disruptiveness: disruptive work tends to be cited without citation to prior art, while developing/review work cites prior literature alongside new work; these measures aim to capture conceptual novelty beyond citation counts.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>study_type</strong></td>
                            <td>literature-described metric class (network-based disruptiveness measures)</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_metrics_studied</strong></td>
                            <td>network disruptiveness indices derived from citation graphs (patterns of exclusive citation vs co-citation with predecessors), topological/network statistics of citation DAGs</td>
                        </tr>
                        <tr>
                            <td><strong>ground_truth_measure</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type_classification</strong></td>
                            <td>disruptive vs developing research based on citation-citation patterns</td>
                        </tr>
                        <tr>
                            <td><strong>sample_characteristics</strong></td>
                            <td>Mentioned as used in prior SciSci studies (no new sample here); applied in literature to broad corpora of scholarly citations spanning fields.</td>
                        </tr>
                        <tr>
                            <td><strong>key_quantitative_findings</strong></td>
                            <td>This paper cites prior work qualitatively: disruptive research tends to be cited exclusively (original, high-impact work), whereas developing/review articles are cited together with preceding work. No new quantitative metrics computed in this paper for these measures.</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_truth_gap_magnitude</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>temporal_pattern</strong></td>
                            <td>Implied: disruptiveness metrics capture a particular citation pattern that may emerge over time as citations accumulate; not quantified here.</td>
                        </tr>
                        <tr>
                            <td><strong>field_specific_findings</strong></td>
                            <td>Not detailed here; prior literature indicates variation across fields but this paper does not quantify it.</td>
                        </tr>
                        <tr>
                            <td><strong>relationship_shape</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>automated_system_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>mechanism_identified</strong></td>
                            <td>Mechanism: citation behavior (exclusive citation of disruptive work vs combined citation for developing work) used as an operational proxy for disruptiveness/novelty.</td>
                        </tr>
                        <tr>
                            <td><strong>correction_approaches</strong></td>
                            <td>Network-based measures are presented as alternatives to raw citation-metrics to better capture novelty and disruption, but no empirical comparison to ground-truth long-term impact is performed here.</td>
                        </tr>
                        <tr>
                            <td><strong>counterexamples_or_exceptions</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>supports_or_challenges_theory</strong></td>
                            <td>Supports the idea that alternative proxies (network/topological measures) can capture aspects of novelty overlooked by citation counts, aligning with the Proxy-to-Ground-Truth concern that some proxies systematically mismeasure transformational contributions.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1891.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e1891.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how different evaluation metrics (citations, peer review, journal prestige, automated systems) perform when assessing scientific discoveries of varying novelty or transformational nature, including comparisons between early/proxy metrics and later ground-truth impact measures.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Embedding_models_limitations</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Embedding-based automated assessment systems (top2vec and BERT-based topic models)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Automated topic/embedding models used as proxies for conceptual content and novelty; this paper uses top2vec and discusses limitations (omitting unseen words, training-data truncation) and potential improvements via BERT-style pretraining/fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>study_type</strong></td>
                            <td>automated system evaluation / methodological discussion with applied usage (top2vec used in experiments)</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_metrics_studied</strong></td>
                            <td>embedding-derived proxies such as topic positions, negative embedding space occupancy, and mixup interactions computed on top2vec embeddings; UMAP/HDBSCAN pipeline for topic detection</td>
                        </tr>
                        <tr>
                            <td><strong>ground_truth_measure</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type_classification</strong></td>
                            <td>Temporal/operational classification: documents that predate training set (interpreted as containing 'missing context') vs documents postdating training set (interpreted as candidate novel/recombinant works).</td>
                        </tr>
                        <tr>
                            <td><strong>sample_characteristics</strong></td>
                            <td>Applied to UF corpus (2001-2023) with top2vec hyperparameters: doc2vec vector size 300, window 15, UMAP neighbors=50 embedding dim=5, HDBSCAN min cluster size=15; resulting 692 topic clusters.</td>
                        </tr>
                        <tr>
                            <td><strong>key_quantitative_findings</strong></td>
                            <td>Empirical: top2vec-derived embeddings plus mixup analysis found pre-training Class A documents had higher mean total mixup (193.2258) than Class B (187.8991), suggesting embedding pipeline tends to represent historical missing context more than novel post-training innovations. No classification performance metrics (precision/recall) reported for novelty detection.</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_truth_gap_magnitude</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>temporal_pattern</strong></td>
                            <td>Embedding models trained on truncated time windows may encode a conceptual landscape that treats earlier (pre-training) material as filling inferred negative spaces; truly novel later work may not register because unseen tokens/phrases are ignored by the model until retraining/pretraining occurs.</td>
                        </tr>
                        <tr>
                            <td><strong>field_specific_findings</strong></td>
                            <td>Authors note potential under-detection risk for subfields with low publication rates (low topic cluster counts), but argue top2vec's min cluster size (15) reduces—but does not eliminate—this risk; no empirical cross-field comparison provided.</td>
                        </tr>
                        <tr>
                            <td><strong>relationship_shape</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>automated_system_performance</strong></td>
                            <td>Observed systematic behavior: top2vec (and similar shallow embedding methods) can omit or ignore words absent from training set, leading to under-representation of novel works; proposed remedy: use BERT-style pretraining/fine-tuning to reduce omissions and better integrate novel documents.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanism_identified</strong></td>
                            <td>Training-data truncation and vocabulary omission (top2vec ignores words not seen during training) cause embeddings to (1) infer missing historical context as negative space and (2) fail to integrate novel post-training documents unless model is re-trained or pre-trained on larger corpora.</td>
                        </tr>
                        <tr>
                            <td><strong>correction_approaches</strong></td>
                            <td>Suggested: pre-train embedding models on large general corpora and then fine-tune on the target corpus (e.g., BERTopic / BERT), which would (a) reduce omitted tokens and (b) provide a more generalized embedding topology so new novel pieces can be accommodated without disassembling the learned structure.</td>
                        </tr>
                        <tr>
                            <td><strong>counterexamples_or_exceptions</strong></td>
                            <td>Yes — authors note that some later publications did fill persistent holes (4 of 11), indicating that not all innovation is missed by the embedding pipeline.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_or_challenges_theory</strong></td>
                            <td>Supports the view that automated proxy systems can systematically mis-evaluate novel/transformational work due to training-data and vocabulary biases, reinforcing Proxy-to-Ground-Truth concerns about machine-based early proxies.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Large teams develop and small teams disrupt science and technology <em>(Rating: 2)</em></li>
                <li>Unsupervised word embeddings capture latent knowledge from materials science literature <em>(Rating: 2)</em></li>
                <li>Mixup barcodes: Quantifying geometric-topological interactions between point clouds <em>(Rating: 2)</em></li>
                <li>Top2vec: Distributed representations of topics <em>(Rating: 2)</em></li>
                <li>The diversity-innovation paradox in science <em>(Rating: 1)</em></li>
                <li>Quantifying the evolution of individual scientific impact <em>(Rating: 2)</em></li>
                <li>Bertopic: Neural topic modeling with a class-based tf-idf procedure <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1891",
    "paper_id": "paper-282138806",
    "extraction_schema_id": "extraction-schema-38",
    "extracted_data": [
        {
            "name_short": "This_paper_mixup_empirical",
            "name_full": "Empirical analysis of mixup barcodes and persistent homology on UF publications (this paper)",
            "brief_description": "An empirical study using top2vec embeddings, persistent homology and mixup barcodes to test whether documents published before (Class A: 2001-2007) or after (Class B: 2021-2023) the training period (2008-2020) are more likely to 'fill' negative embedding space (holes) in topic embeddings; includes permutation tests and localized analyses of persistent holes.",
            "citation_title": "here",
            "mention_or_use": "use",
            "study_type": "empirical analysis of embedding-based novelty proxies using TDA",
            "proxy_metrics_studied": "total mixup (mixup barcodes), occupancy of negative embedding space (mixup simplex counts), topic-level embedding proximity (top2vec-derived topics)",
            "ground_truth_measure": null,
            "discovery_type_classification": "temporal proxy: Class A (pre-training publications, 2001-2007) vs Class B (post-training publications, 2021-2023); interpreted as 'missing context' vs 'innovation/recombinant' respectively",
            "sample_characteristics": "All peer-reviewed UF-affiliated articles indexed in dimensions.ai, 2001-2023; training set 2008-2020 (73,302 docs); Class A 2001-2007 (20,139 docs); Class B 2021-2023 (20,139 docs). Embeddings: top2vec → UMAP to 5D → 692 topic clusters; analysis in 5D.",
            "key_quantitative_findings": "Total mixup (100 iterations, 10% random subsamples): mean total mixup Class A = 193.2258, Class B = 187.8991, observed mean difference = 5.3267; permutation test (10,000 permutations) p &lt; 0.0001. Persistent-holes analysis: 252 one-dimensional holes detected overall; 11 holes with persistence &gt; 0.2; in 4 of those 11 persistent holes Class B had greater average mixup than Class A. Iterative subsampling: 100 iterations per class, 10% sample size per iteration.",
            "proxy_truth_gap_magnitude": null,
            "temporal_pattern": "Documents published before the training period (Class A) statistically more frequently 'fill' negative space (higher total mixup), suggesting embeddings infer missing historical context; however, a minority of long-persistent holes (4 of 11 with persistence &gt;0.2) were filled more by post-training documents (Class B), indicating some instances where later publications occupy innovation spaces.",
            "field_specific_findings": "Localized analyses of specific holes revealed disciplinary mixes; e.g., hole index 9 (filled more by Class B) combined life sciences, physical sciences, agriculture/environment, and medicine; hole index 11 (filled more by Class A) included medicine, engineering, life sciences, social science. No broad field-level statistical stratification beyond these localized examples.",
            "relationship_shape": "Not formalized into a mathematical curve; pattern is heterogeneous (majority effect favoring pre-training docs filling holes, with exceptions among persistent holes).",
            "automated_system_performance": "top2vec embeddings + mixup detect pre-training historical/contextual documents occupying negative space; post-training (novel) documents are detected less often unless they fill specific persistent holes. No conventional classification metrics (precision/recall) reported for novelty detection.",
            "mechanism_identified": "Primary mechanism: truncation of embedding model training data (2008-2020) causes the model to (a) infer 'missing context' as negative space which is often occupied by earlier (pre-training) documents, and (b) ignore or omit words not seen during training for truly novel post-training documents (top2vec ignores unseen words), so novel works may not be fitted into existing embedding topology unless the model is retrained or pre-trained on larger corpora.",
            "correction_approaches": "Proposed: pre-train on larger corpora (e.g., Wikipedia, Web of Science, dimensions.ai) and then fine-tune (BERT-style) to reduce omitted words and better represent generalized scientific structure; re-training embeddings to incorporate new documents so novel pieces 'fit' the puzzle.",
            "counterexamples_or_exceptions": "Yes — some persistent holes (4 of 11 with persistence &gt;0.2) showed higher mixup for post-training documents (Class B), i.e., certain long-lived cavities were preferentially filled by later, potentially innovative work.",
            "supports_or_challenges_theory": "Mixed: challenges a simplistic expectation that negative embedding space will primarily indicate future innovation; instead shows negative space often represents historical 'missing context' inferred by the model (supporting model-bias / training-data-truncation explanations of proxy failure), while also showing exceptions where later publications occupy some persistent innovation-like cavities.",
            "uuid": "e1891.0"
        },
        {
            "name_short": "Mixup_TDA_methods",
            "name_full": "Mixup barcodes and persistent homology (topological data analysis methods)",
            "brief_description": "Persistent homology identifies multi-scale topological holes in embeddings; mixup barcodes (image persistence) quantify how adding points from a second distribution causes earlier death of homological features, summarised as total mixup to measure how new data fill negative embedding space.",
            "citation_title": "",
            "mention_or_use": "use",
            "study_type": "method development / methodological application (TDA applied to topic embeddings)",
            "proxy_metrics_studied": "total mixup (sum of per-feature mixup = (d - d')/(d - b)), representative cycles / hole birth-death values",
            "ground_truth_measure": null,
            "discovery_type_classification": "Not an explicit novelty classification method per se; operationalized in this study as 'documents that cause earlier death of holes' indicating occupancy of negative space (interpreted as missing context or interdisciplinarity/innovation depending on temporal origin).",
            "sample_characteristics": "Applied to 692 topic centroid embeddings from UF corpus (UMAP 5D projection) with class documents (Class A, Class B) mixed in via iterative 10% subsamples (100 iterations) to compute total mixup per class.",
            "key_quantitative_findings": "Detected 252 one-dimensional holes in topic embeddings; total mixup comparisons showed mean Class A &gt; Class B (193.2258 vs 187.8991; diff 5.3267; permutation p &lt; 0.0001). For persistent holes (persistence&gt;0.2), 11 holes identified and 4 showed greater mixup for Class B.",
            "proxy_truth_gap_magnitude": null,
            "temporal_pattern": "Mixup reveals that historical (pre-training) documents more often fill holes inferred from later-topic embeddings, indicating models' negative space can correspond to missing past context rather than future innovation; minority temporal exceptions exist in persistent holes.",
            "field_specific_findings": "When applied to specific holes, mixup identified interdisciplinary documents spanning multiple subject classifications; method reveals topical composition of holes but does not by itself provide general field-level bias quantification.",
            "relationship_shape": "Not framed as a smooth functional relationship; mixup is an additive summary over homological features.",
            "automated_system_performance": "Method successfully quantifies interactions between two point clouds (training topics vs added documents); computationally expensive for large batches, mitigated here by iterative subsampling.",
            "mechanism_identified": "Mixup detects homological interactions by finding mixup simplices (simplices from P ∪ Q that kill features born in P earlier than in P alone), hence highlighting which new data points fill holes and at what filtration values.",
            "correction_approaches": "Mixup itself is presented as a diagnostic; suggested corrective step is to re-train or pre-train embeddings so that genuinely novel documents are integrated rather than ignored.",
            "counterexamples_or_exceptions": "Yes — some persistent holes are preferentially filled by newer documents (Class B), showing mixup can detect both historical and innovative fillings depending on hole structure.",
            "supports_or_challenges_theory": "Supports the idea that topological diagnostics can reveal differences between proxy indicators (embedding-derived negative space) and notions of innovation; shows that proxy measures (mixup) may reflect training-data structure (historical gaps) rather than purely future-transformational novelty.",
            "uuid": "e1891.1"
        },
        {
            "name_short": "Citation_metrics_bias",
            "name_full": "Citation-based metrics (citation counts, impact factor, h-index and similar)",
            "brief_description": "Traditional bibliometric/proxy metrics widely used to evaluate research impact, but noted to have intrinsic biases (disciplinary, format exclusions like books) and limitations for assessing conceptual novelty or interdisciplinarity.",
            "citation_title": "",
            "mention_or_use": "mention",
            "study_type": "critical literature discussion of citation metrics",
            "proxy_metrics_studied": "citation counts, impact factor, H-index, journal-based metrics",
            "ground_truth_measure": null,
            "discovery_type_classification": "Implicitly: disruptive/developing or conventional/novel work — concern that citation metrics misrepresent novelty and interdisciplinary outputs.",
            "sample_characteristics": "General critique drawing on prior literature; no new empirical sample in this paper for citation-based measures.",
            "key_quantitative_findings": "No original quantitative reanalysis provided in this paper; qualitative points: citation metrics often exclude books/book chapters (hurting arts/humanities and some social sciences), and have known biases referenced in literature.",
            "proxy_truth_gap_magnitude": null,
            "temporal_pattern": "Paper does not quantify citation temporal dynamics here, but references literature (e.g., delayed recognition phenomena) in SciSci context.",
            "field_specific_findings": "Explicit: arts, humanities, and social sciences are disadvantaged because books/book chapters are often not indexed in Web of Science and thus not counted in typical citation-based metrics.",
            "relationship_shape": null,
            "automated_system_performance": null,
            "mechanism_identified": "Mechanisms mentioned: indexing coverage bias (books not indexed), disciplinary publication norms (monographs vs articles), and structural differences in citation practices leading to biased metric outcomes.",
            "correction_approaches": "Referencing broader SciSci work that proposes alternative metrics that account for conceptual novelty (topic-modeling, network/disruptiveness measures) rather than raw citation counts; no empirical correction tested in this paper.",
            "counterexamples_or_exceptions": null,
            "supports_or_challenges_theory": "Supports the assertion in the Proxy-to-Ground-Truth Gap Theory that citation proxies can systematically misrepresent impact across fields and for novel work, motivating development of alternative measures that capture conceptual novelty.",
            "uuid": "e1891.2"
        },
        {
            "name_short": "Network_disruptiveness_measures",
            "name_full": "Network/topological disruptiveness measures (citation DAG analyses)",
            "brief_description": "Approaches that build citation networks (directed acyclic graphs) to quantify disruptiveness: disruptive work tends to be cited without citation to prior art, while developing/review work cites prior literature alongside new work; these measures aim to capture conceptual novelty beyond citation counts.",
            "citation_title": "",
            "mention_or_use": "mention",
            "study_type": "literature-described metric class (network-based disruptiveness measures)",
            "proxy_metrics_studied": "network disruptiveness indices derived from citation graphs (patterns of exclusive citation vs co-citation with predecessors), topological/network statistics of citation DAGs",
            "ground_truth_measure": null,
            "discovery_type_classification": "disruptive vs developing research based on citation-citation patterns",
            "sample_characteristics": "Mentioned as used in prior SciSci studies (no new sample here); applied in literature to broad corpora of scholarly citations spanning fields.",
            "key_quantitative_findings": "This paper cites prior work qualitatively: disruptive research tends to be cited exclusively (original, high-impact work), whereas developing/review articles are cited together with preceding work. No new quantitative metrics computed in this paper for these measures.",
            "proxy_truth_gap_magnitude": null,
            "temporal_pattern": "Implied: disruptiveness metrics capture a particular citation pattern that may emerge over time as citations accumulate; not quantified here.",
            "field_specific_findings": "Not detailed here; prior literature indicates variation across fields but this paper does not quantify it.",
            "relationship_shape": null,
            "automated_system_performance": null,
            "mechanism_identified": "Mechanism: citation behavior (exclusive citation of disruptive work vs combined citation for developing work) used as an operational proxy for disruptiveness/novelty.",
            "correction_approaches": "Network-based measures are presented as alternatives to raw citation-metrics to better capture novelty and disruption, but no empirical comparison to ground-truth long-term impact is performed here.",
            "counterexamples_or_exceptions": null,
            "supports_or_challenges_theory": "Supports the idea that alternative proxies (network/topological measures) can capture aspects of novelty overlooked by citation counts, aligning with the Proxy-to-Ground-Truth concern that some proxies systematically mismeasure transformational contributions.",
            "uuid": "e1891.3"
        },
        {
            "name_short": "Embedding_models_limitations",
            "name_full": "Embedding-based automated assessment systems (top2vec and BERT-based topic models)",
            "brief_description": "Automated topic/embedding models used as proxies for conceptual content and novelty; this paper uses top2vec and discusses limitations (omitting unseen words, training-data truncation) and potential improvements via BERT-style pretraining/fine-tuning.",
            "citation_title": "",
            "mention_or_use": "use",
            "study_type": "automated system evaluation / methodological discussion with applied usage (top2vec used in experiments)",
            "proxy_metrics_studied": "embedding-derived proxies such as topic positions, negative embedding space occupancy, and mixup interactions computed on top2vec embeddings; UMAP/HDBSCAN pipeline for topic detection",
            "ground_truth_measure": null,
            "discovery_type_classification": "Temporal/operational classification: documents that predate training set (interpreted as containing 'missing context') vs documents postdating training set (interpreted as candidate novel/recombinant works).",
            "sample_characteristics": "Applied to UF corpus (2001-2023) with top2vec hyperparameters: doc2vec vector size 300, window 15, UMAP neighbors=50 embedding dim=5, HDBSCAN min cluster size=15; resulting 692 topic clusters.",
            "key_quantitative_findings": "Empirical: top2vec-derived embeddings plus mixup analysis found pre-training Class A documents had higher mean total mixup (193.2258) than Class B (187.8991), suggesting embedding pipeline tends to represent historical missing context more than novel post-training innovations. No classification performance metrics (precision/recall) reported for novelty detection.",
            "proxy_truth_gap_magnitude": null,
            "temporal_pattern": "Embedding models trained on truncated time windows may encode a conceptual landscape that treats earlier (pre-training) material as filling inferred negative spaces; truly novel later work may not register because unseen tokens/phrases are ignored by the model until retraining/pretraining occurs.",
            "field_specific_findings": "Authors note potential under-detection risk for subfields with low publication rates (low topic cluster counts), but argue top2vec's min cluster size (15) reduces—but does not eliminate—this risk; no empirical cross-field comparison provided.",
            "relationship_shape": null,
            "automated_system_performance": "Observed systematic behavior: top2vec (and similar shallow embedding methods) can omit or ignore words absent from training set, leading to under-representation of novel works; proposed remedy: use BERT-style pretraining/fine-tuning to reduce omissions and better integrate novel documents.",
            "mechanism_identified": "Training-data truncation and vocabulary omission (top2vec ignores words not seen during training) cause embeddings to (1) infer missing historical context as negative space and (2) fail to integrate novel post-training documents unless model is re-trained or pre-trained on larger corpora.",
            "correction_approaches": "Suggested: pre-train embedding models on large general corpora and then fine-tune on the target corpus (e.g., BERTopic / BERT), which would (a) reduce omitted tokens and (b) provide a more generalized embedding topology so new novel pieces can be accommodated without disassembling the learned structure.",
            "counterexamples_or_exceptions": "Yes — authors note that some later publications did fill persistent holes (4 of 11), indicating that not all innovation is missed by the embedding pipeline.",
            "supports_or_challenges_theory": "Supports the view that automated proxy systems can systematically mis-evaluate novel/transformational work due to training-data and vocabulary biases, reinforcing Proxy-to-Ground-Truth concerns about machine-based early proxies.",
            "uuid": "e1891.4"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Large teams develop and small teams disrupt science and technology",
            "rating": 2
        },
        {
            "paper_title": "Unsupervised word embeddings capture latent knowledge from materials science literature",
            "rating": 2
        },
        {
            "paper_title": "Mixup barcodes: Quantifying geometric-topological interactions between point clouds",
            "rating": 2
        },
        {
            "paper_title": "Top2vec: Distributed representations of topics",
            "rating": 2
        },
        {
            "paper_title": "The diversity-innovation paradox in science",
            "rating": 1
        },
        {
            "paper_title": "Quantifying the evolution of individual scientific impact",
            "rating": 2
        },
        {
            "paper_title": "Bertopic: Neural topic modeling with a class-based tf-idf procedure",
            "rating": 1
        }
    ],
    "cost": 0.01563775,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>What is missing from this picture? Persistent homology and mixup barcodes as a means of investigating negative embedding space
16 Oct 2025</p>
<p>Himanshu Yadav yadav.himanshu@ufl.edu 
Department of Mathematics
University of Florida
32611GainesvilleFloridaUSA</p>
<p>Thomas Bryan Smith tbsmit10@olemiss.edu 
Department of Criminal Justice and Legal Studies
University of Mississippi
38677OxfordMississippiUSA</p>
<p>Peter Bubenik peter.bubenik@ufl.edu 
Department of Mathematics
University of Florida
32611GainesvilleFloridaUSA</p>
<p>Christopher Mccarty 
Bureau of Economic and Business Research
University of Florida
32611GainesvilleFloridaUSA</p>
<p>What is missing from this picture? Persistent homology and mixup barcodes as a means of investigating negative embedding space
16 Oct 202507BFB81113AC3497E667C5227A13E6A5arXiv:2510.14327v1[cs.SI]Persistent homologyMixup barcodesTopological data analysis (TDA)Science of Science (SciSci)
Recent work in the information sciences, especially informetrics and scientometrics, has made substantial contributions to the development of new metrics that eschew the intrinsic biases of citation metrics.This work has tended to employ either network scientific (topological) approaches to quantifying the disruptiveness of peer-reviewed research, or topic modeling approaches to quantifying conceptual novelty.We propose a combination of these approaches, investigating the prospect of topological data analysis (TDA), specifically persistent homology and mixup barcodes, as a means of understanding the negative space among document embeddings generated by topic models.Using top2vec, we embed documents and topics in n-dimensional space, we use persistent homology to identify 'holes' in the embedding distribution, and then use mixup barcodes to determine which holes are being filled by a set of unobserved publications.In this case, the unobserved publications represent research that was published before or after the data used to train top2vec.We investigate the extent that negative embedding space represents missing context (older research) versus innovation space (newer research), and the extend that the documents that occupy</p>
<p>Introduction</p>
<p>Science policy and innovation studies have long pursued methods for quantifying and studying innovation and scientific impact.[38,53,50].Produced primarily by scholars working within sociology of knowledge and information sciences (scientometrics, informetrics, among others), much of the research in this area replicates and extends analyses of individual productivity, established innovation metrics (e.g., citation impact), and their predictors [2].However, the recent advancement of a 'Science of Science' (SciSci) as an emerging subfield has coincided with a flurry of advancements in the measurement of innovation and disruption [64,27].SciSci is a transdisciplinary approach that leverages data science and advanced computational methods to study the mechanisms of 'doing science' [21].Recent research has utilized topological (network) methods to distinguish disruptive and developing research.This is achieved by constructing directed acyclic graphs of academic research citation networks and measuring the tendency of scholars to cite disruptive research excusively (original articles, nobel prize work, etc.), but cite developing articles (e.g., review articles) in tandem with preceding work [64].Subsequent research further supports this notion, quantifying innovation as both the introduction of new concepts and the novel combination of existing concepts (e.g., cross-disciplinary integration) [27,31].This research, among other work, highlight a growing concern with the development of new scientific innovation metrics that eschew the intrinsic biases of citation metrics by accounting for conceptual novelty.For example, citation metrics have long been recognized as problematic for the arts, humanities, and social sciences, where books and book chapters remain a normal outlet for knowledge dissemination [54].Since neither books or book chapters appear in the Web of Science, they do not feature in the calculation of many impact factor and similar metrics [15,6].We investigate the prospect of topological data analysis (TDA) [41], including persistent homology [16] and mixup barcodes [59], as a means of understanding the negative space among document embeddings and the prospect that documents occupying this space represent innovative, interdisciplinary scholarship.</p>
<p>Word and Document Embedding</p>
<p>Responding to the rapidly increasing growth of scientific knowledge and a perceived challenges of 'information overload' [29], SciSci scholars have begun "Science Mapping", the application of techniques from network science and, more recently, computational linguistics to scientific literature with the goal of summarizing and understanding the 'landscape' of a given field [11].Earlier research in this area has focused heavily on the construction, visualization, and interpretation of citation and coauthorship networks [4].However, rapid development in natural language processing (NLP) and machine learning have afforded scholars a wealth of text summarization algorithms, many of which rely on word and document embeddings.Conceptually, word and document embedding (and topic modeling, more broadly) can be understood as an assortative process wherein each document set (corpus) and the words therein are placed in n-dimensional space such that substantively similar documents and words are proximal, while dissimilar documents are distal [48,3,24].Thus, to some extent, word and document embeddings can be understood as a conceptual landscape.</p>
<p>Structural linguistics and conceptual landscapes</p>
<p>There are some notable limitations in representing words, documents, and topics as embeddings or 'conceptual landscapes.' The meaning of text is not completely represented by a relational framework arising from traditional structural linguistics [13].Some words are 'embodied' in that they represent sensory information, others might vary substantially based on the context of the author (i.e., each word is not universally coherent), and many words are not static over time [5].Absent the capacity to 'embody' information, given that language models do not have the capacity to understand the words themselves, it is important that we investigate the concepts and meaning that embeddings fail to directly capture.Practically speaking, information and meaning are lost when a language model is trained on data collected from a specific point or period of time, creating a truncated training set.Missing data that precede the first training data point might represent potentially important missing context, while missing data beyond the last training data point might more frequently represent innovative, novel recombinations of established ideas [62,32].To use an analogy, let us say that we have a disassembled jigsaw puzzle with missing pieces and duplicate pieces, and each piece of the jigsaw puzzle is a document.Topic embedding models assemble the puzzle, presenting us with the complete 'picture' of the conceptual landscape, which then allows us to (1) identify dense clusters of duplicate puzzle pieces, and (2) identify incomplete areas of the puzzle.Topic models are only intended to identify dense clusters; they effectively disregard negative space.We propose the application of topological data analysis (TDA) -specifically persistent homology and mixup barcodes -as a means of examining the negative space amid embedded words, documents, and topics.In other words, we propose the application of TDA to identify and examine the missing puzzle pieces.Just as TDA has been used to map geographical space in geographical information science [12], there is potential for similar applications in conceptual space, moving beyond one constraint imposed by a rigid structural linguistic framework.</p>
<p>Applications of Topological Data Analysis</p>
<p>TDA has been applied in various fields and subfields, including but not limited to geographic information systems [18], resource allocation [25], neuroscience [55], environmental science [58], and material science [26].Nontheoretical applications of topology have proven valuable to many domains of science, and one method that has been particularly valuable is TDA [23].Among these applications, TDA has been used to find topological features for high-dimensional data and then find lower-dimensional projections preserving these structures [60,46,40].Due to the efficacy of TDA tools to deal with high-dimensional data, some research has employed TDA in the study of topological structures in textual data, per the aforementioned structural linguistic underpinnings of work in this domain [57].Recently, Dragnaov et al. [14] used TDA to demonstrate that topological features for word embeddings for different languages vary significantly.Gholizadeh et al. [22] also found that topological structure in word embeddings on long textual documents provides a more accurate linguistic representation than conventional text mining features.This work, among others, showcases the interesting topological features that underpin word embeddings.It follows that TDA techniques designed to identify and examine the birth, death, and mixup of cavities could also help to examine and better understand the negative embedding space among embedded words, documents, and topics.</p>
<p>Background</p>
<p>Top2vec</p>
<p>Top2vec is an extension of word2vec and doc2vec that applies dimension reduction and hierarchical clustering to word and document embeddings with the goal of detecting coherent themes and topics in a given body of text [3].The underlying models, word2vec and doc2vec, are trained using the distributed bag-of-words (DBOW) architecture, with the goal of generating joint embeddings for words and documents [30].As such, top2vec takes the input word matrix W n,d and the word context matrix W ′ n,d , then uses each word vector − → w ∈ W n,d for word w to predict the context vector
− → w ∈ W ′ n,d of a given context word w c . With the sof tmax( − → w ∈ W ′ n,d
) activation function, backpropagation, and stochastic gradient descent, top2vec then estimates the probability distribution of a given context vector conditional on a given word vector,
P ( − → w c | − → w ) [3]
. This process results in a set of k embeddings (i.e.</p>
<p>the context vectors W ′ ) which are closer together for semantically similar words, and distant for semantically dissimilar words.Per the DBOW doc2vec framework, top2vec learns document embeddings by following a very similar process, but taking the document matrix D c,d as input, rather than a word matrix, producing an equivalent set of k embeddings that are proximal for documents containing similar words, and distal for documents containing dissimilar words [30,3].Taking jointly embedded words and documents as input, uniform manifold approximation and projection (UMAP) is used for dimension reduction while preserving the local and global structure of the embeddings [3].UMAP uses components of TDA to generate fuzzy topological representations of embedded words and documents, and finds a set of low-dimensional embeddings that produce an approximately equivalent fuzzy topological representation [40].Following dimension reduction, hierarchical density-based clustering (HDBSCAN) is applied to the reduced embeddings, identifying sufficiently dense clusters of reduced document vectors while eliminating noise [39,3,10].The result is a set of embedded words and documents that have been clustered into a collection of topics that represent coherent themes in the corpus.</p>
<p>Persistent homology</p>
<p>Topological data analysis follows the premise that the shape of data (and the conceptual, spatial information that encodes this shape) contains substantive information.Assuming that the shape of the conceptual landscape inferred by top2vec is meaningful, it follows that the negative space between clusters of words, documents, and topics is meaningful.We thus aim to identify persistent holes in the conceptual landscape using persistent homology [16].</p>
<p>Spatial information is encoded as homology groups [42] in topology.The homology group for dimension k informally describes the number of k-dimensional holes (k-dimensional cycles which are not boundary).The rank of the k th homology group is also the k th Betti number.An element of the k th homology group is often called the degree-k topological feature.Homology groups capture topological information for a single choice of scale, whereas persistent homology captures the multi-scale topological structure of the data.</p>
<p>The main idea of persistent homology is to track topological features as they appear and disappear as we build up our geometric object through a filtration.Given a point-cloud data set in an ambient space with a distance metric, we can recover the topology with the help of growing balls around each data point.For a fixed radius, the collections of balls is a cover of the union of balls.Then, per the nerve theorem [7], the nerve of this cover is homotopy-equivalent to the union of the cover.This guarantees that the homology of the nerve and the union of the ball are both the same.As calculating homology of the nerve is much simpler than finding homology of a general space, this extra construction reduces computational cost.The nerve of a cover gives a combinatorial representation of the union of balls, called a simplicial complex.This is the geometric object which we use for our data, see fig. 1.</p>
<p>We construct a simplicial complex for a sequence of increasing radii to get a filtered simplicial complex fig.2a.Then we take the homology of these filtered simplicial complexes with coefficients in Z 2 , this gives us a persistence module.A persistence module consists of homology groups for every step, and induced maps between two consecutive steps.We can track topological features across these homological groups using the images and kernels of these induced maps to precisely encode which features are born, which die, and which persist.</p>
<p>Per structure theorem [8], one can decompose persistence modules and represent them as persistence barcodes.Every bar in the persistence barcode has a starting and ending value called birth and death respectively.These values correspond to when a topological feature is born and dies.We define persistence as the difference of death and birth values, which captures how long a feature persists in the filtration.Each topological feature which If three balls have a common intersection, fill the triangle between the three edges arising from the pairwise intersections.Similarly, add higher-dimensional simplices for higherorder intersections.Right: the simplicial complex (consisting of vertices, edges, triangles, and higher-order simplices) obtained from this construction.</p>
<p>persists across multiple scales can be represented by a representative cycle, a concrete geometric object that exemplifies the feature.The birth value for a topological feature corresponds to the step when a representative cycle first emerges, this occurs when the last simplex which forms the structure of the cycle emerges.The death value corresponds to the step when this representative cycle becomes a boundary of a higher dimensional simplex, due to the addition of a new simplex.The new simplex whose addition allows representative cycle to become a boundary, is called the death simplex.</p>
<p>For instance, take a 1-dimensional hole in the data.This is represented by a loop that bounds the hole; this is its representative cycle.The largest weight of the edges (1-dimensional simplex) in the representative cycle is birth, when the representative cycle completely appears in the filtration.This representative cycle is later filled by a combination of triangles (2-dimensional simplices); the largest weighted triangle is the death simplex, which appears in the end to fill the hole.</p>
<p>We plot birth-death in the x-y plane as a multi-set of points called a persistence diagram.In fig. 2 we use persistent homology to recover the 1st homology group for the point cloud which resembles the figure eight.In fig. 2 (c), we visualize a 1-dimensional hole by its representative cycle.We will only compute persistent homology for dimension one in this paper.</p>
<p>Mixup Barcodes</p>
<p>Standard persistent homology captures the topology of a point cloud which has one group or classification of data points, say from a distribution P .If we add more points into this point cloud from a different distribution Q, the k-dimensional holes made by points P in some cases will fill up earlier because of points in Q.In fig.3, an example of a topological interaction is visualized in which a 1-dimensional hole for the point cloud P fills up earlier after inclusion of points Q.This is the interaction that we use to capture using mixup barcodes, a summary statistic developed by Wagner et al. [59] to quantify topological interactions between two different points in a point cloud.Mixup barcodes are computed using image persistence and standard persistent homology.</p>
<p>First, using standard persistent homology for the point cloud P , birth and death simplices are identified for topological features.Then, using image persistence, we track when topological features which appear in the point cloud P die when these new simplices from the point cloud P ∪Q are included into the filtration as well.We will call this simplex from the point cloud P ∪Q -which kills a topological feature in the point cloud P -the mixup simplex.This mixup simplex for a topological feature will always have filtration value less than or equal to the filtration value for the corresponding death simplex obtained from the point cloud P .Thus, for a homological feature in the point cloud P , we can obtain birth, mixup, and death simplex with filtration values, say b, d ′ , and d respectively, such that b ≤ d ′ ≤ d.If d ′ = d, then adding additional points from the distribution Q doesn't have any effect on the corresponding topological feature for the point cloud P .However, if d ′ &lt; d, then it means that the homological feature was filled up earlier when points from the distribution Q were included in the point cloud.A statistic which can capture this interaction for a homological feature is the mixup given by d−d ′ d−b .The total mixup for k-dimensional homology is defined as the sum of the mixup for all features in k-dimensional homology.We will only use total mixup for the 1-dimensional homology group in the analysis of our data.We calculate mixup using Ripserer [66], which is a Julia library.</p>
<p>Method</p>
<p>Data</p>
<p>We used dimensions.aipublication data, which contained every peerreviewed article published between 2001 and 2023 by researchers indicated to be affiliated with the University of Florida (UF) circa 2023.The data include the author's name and dimensions.aiidentifier, the university department and college, the discipline, the year of publication, and the abstract of the article.These data were downloaded using the dimensions.aiAPI via rdimensions, an R package developed by the UF Clinical and Translational Science Institute (CTSI) Network Science team [28].Publications with missing abstracts were removed from the data prior to model training.The final dataset consisted of 114822 publications indexed by dimensions.ai with a minimum of one UF-affiliated author.</p>
<p>Top2vec Specification</p>
<p>Given the goal of analyzing the conceptual landscape (and negative space) produced by research at the UF, we used top2vec to construct an embedding space based on the aforementioned data.This embedding space approximates the conceptual landscape.Using a proximity measure (cosine similarity), top2vec was used to further categorize publications into topics, obtaining 692 clusters of publications.These mutually disjoint clusters represent the broader research topics within which each publication is categorized.This was intended to condense the corpus into a more concise representation of the conceptual landscape that can be analyzed using TDA techniques.</p>
<p>The algorithms underlying top2vec require the specification of a number of hyperparameters.We opted to follow the conventions established by Angelov (2020) when training the model [3].Doc2vec requires the specification of vector size (aka embedding dimension) and window size hyper-parametersthese hyperparameters were set to 300 and 15 respectively, with hierarchical softmax but no negative sampling.UMAP requires the specification of the n nearest neighbors and embedding dimension hyper-parameters -these were set to 50 and 5, respectively.HDBSCAN requires the specification of a minimum cluster size hyper-parameter, which was set to 15.</p>
<p>Analytical Procedure</p>
<p>Our data lies in 5 dimensions after projection by UMAP.We will do our analysis in 5 dimensions.We present 2-dimensional approximations alongside our 5-dimensional findings for ease of interpretation.In fig.4b, the 2-dimensional projection is visualized, where topics were not uniformly distributed in the conceptual space.There were negative spaces with regions of variable densities.Our goal was to understand this negative space under the assumption that the shape of the data contains substantive information.In   order to understand these negative spaces, which we refer to as "holes" or "cavities", we followed a two-step process.First, we identified holes in the topics embedding space (conceptual landscape) using persistent homology.Second, we used mixup barcodes to identify holes that were filled by a subset of test documents.Persistent homology requires a filtered simplicial complex as input.One popular semimetric to use for higher-dimensional embedding space is cosine (dis)similarity, which is particularly useful for high dimensions, where these vectors can have widely different amplitudes.Given that our conceptual landscape is an embedding space of high-dimensional vectors, we built a filtered simplicial complex using a symmetric matrix of cosine (dis)similarity between vectors.Using persistent homology, we identified a total of 252 onedimensional holes in the topic embedding.Consider the hole represented as a red dot in fig. 4 (a).This hole corresponds to a hole in the conceptual landscape shown in fig. 4 (b).A hole is formed when there are topics on the perimeter that form a closed loop around negative space.All holes, including those not visualized, contain negative space.As a reminder, given that we are identifying holes in the embedded topics, not documents (or words), these negative spaces can also represent a low-density region in the underlying document distribution.This means that negative spaces may contain publications that are not coherent enough to form a single topic.</p>
<p>To better understand the nature of the work that tends to occupy negative space, we compare research published after the training data (2021 -2023) with documents published before the training data (2001 -2007).We introduce documents from these periods into the model without retraining to accommodate the new documents and new words, as doing so would result in a re-arrangement of the embedding space.As noted above, documents from periods of time preceding the training data should contain contextual information omitted from the training data, where documents from periods following the training data should include some amount of recombinant innovation in the form of interdisciplinary scholarship.Our assumption is that the documents occupying these holes will combine the topics around the periphery of the hole, and that these documents will represent one or both of missing context and innovative interdisciplinarity.Measuring the extent that Class A and Class B documents filled holes identified via persistent homology required an appropriate summary statistic.Using persistent homology we can find the representative cycle of a hole.This representative cycle forms the boundary of the hole (peripheral topics), as in fig. 4. In 2-dimensions, the centroid will be inside a hole, provided the boundary forms a convex polygon.Thus, if one can find documents close to the centroid, in some special cases those documents will also be inside the hole.However, if the boundary of the hole is not a convex polygon, as will often be the case in higher dimensions, then the centroid could not be used to find documents filling a hole.Consequently, we opted to utilize total mixup (section 2.3).As noted above, mixup is a method specifically intended to assess the extent that new data points added to a distribution fill holes identified via persistent homology.The total mixup summary statistic assesses the overall extent that a set of new data points, in our case documents in the Class A and Class B sets, fill the holes in the distribution.The total mixup statistic is defined as the sum of all mixup d−d ′ d−b for 1-dimensional features.Thus, we are able to observe the birth and death of holes in the topics embedding, and then assess the extent that additional publications drawn from Class A and B alter the death of these holes.Documents that prompt the early death of holes in the distribution are more likely to occupy negative space [59].A mixup simplex is the simplex which causes earlier death of a hole.This mixup simplex contains 3 points, among these 3 points at least 1 point will be a document from the class that we added, while remaining points are topics.</p>
<p>Adding all the publications in the Class A and Class B sets at once and calculating total mixup is computationally expensive.Moreover, not all publications in a class will fill holes; some of these publications will necessarily fall outside the holes.To reduce computational cost, we iteratively added smaller, randomly sampled subsets of documents, each consisting of 10% of the Class A and B corpora, then calculated total mixup.We performed 100 iterations for each of the two corpora, producing 100 measurements of total mixup for each of the two experimental conditions.Using permutation test [47], we compare the distribution of total mixups across two experimental conditions to test whether they were drawn from substantively different populations.</p>
<p>Results</p>
<p>In the section 4.1, we provide results from a mean difference test comparing embedding location relative to negative space by time of publication.This section analyzes distributions of total mixup derived of 100 subsample iterations.As a reminder, total mixup is a global measure of the extent that documents added into the embeddings space during mixup fill negative space.In the section 4.2, we provide a localized, descriptive analysis of specific, noteworthy holes and the documents that "filled" these holes during mixup.In this section, we instead use mixup to identify documents filling the negative space of specific holes.</p>
<p>Total mixup</p>
<p>In fig. 5, we performed analyses comparing Class A and Class B. We observed a consistent result: Class A publications are more likely to fill holes compared to Class B publications.That is, publications preceding the training data are more likely to fill up the holes in topic embeddings space than publications proceeding the training data.</p>
<p>Average total mixup for publications in Class A is 193.2258 and Class B is 187.8991.The observed difference between their average is 5.3267.To determine whether our observed difference is statistically significant, we performed a permutation test.We merged total mixups for both the classes together and then randomly permuted the data 10000 times.Each time, we recorded the absolute difference between average total mixup and then compared it with our observed difference of 5.3267.There were less than 0.01 % cases where the absolute difference between average total mixup was higher than the observed difference, giving us a p-value less than 0.0001.This implies that Class A and Class B objects are highly likely to have consistent, statistically different total mixups.Put simply, articles from Class A are more likely to fill up holes made by the topics compared to Class B.</p>
<p>Mixup</p>
<p>In the preceding subsection, we employed total mixup to capture the association between documents' time of publication and embedding relative to negative embedding space.However, another approach to utilizing mixup is to investigate how distinct classes of documents are located relative to specific, substantive cavities in the embedding space.There are numerous holes in the embedding space we can examine, but the most significant holes are those that persist for longer periods in the filtration (i.e., longer period of time between birth and death).We use a persistence value of 0.2 to filter out intermittent cavities.This will allow us to analyze specific effect of additional documents to individual holes.</p>
<p>In fig.6, there are eleven points on the persistence diagram with persistence greater than 0.2, representing eleven persistent holes in the topic embeddings space.Contrary to our previous analysis of the total mixup, which observes a consistent trend where total mixup for Class A documents is more likely to be significantly greater than the total mixup for Class B documents, we observed greater mixup for Class B than Class A in four of these persistent holes.This is an interesting observation, as it indicates that a sizable proportion of persistent holes in the topic embeddings space are being filled more by documents published after the training data (rather than before).</p>
<p>Documents permeating the ninth representative cycle</p>
<p>In fig.6b, the index 9 hole in the table exhibits a higher average mixup for Class B compared to Class A. This implies that documents belonging to Class B are on average more likely to occupy the hole than those belonging to Class A. This observation is further strengthened by the comparison of the underlying distribution of mixup values.In fig. 7, we compared the mixup distributions for both classes A and B mixup documents and observed a statistically significant difference.</p>
<p>Interpreting the topics included in the representative cycle of this hole, as well as some of the documents that fill the hole, it is much easier to understand this phenomenon.In total, there are 12 topics in the representative cycles.These topics can be further classified into five subject classifications: life sciences &amp; biology, physical sciences &amp; engineering, agricultural &amp; environmental and medicine &amp; healthcare.Each classification contains 6, 3, 2 and 1 topics, respectively, from the representative cycle.</p>
<p>During our analysis of incorporating mixup document classes A and B into the embedding space (refer to fig.8), the negative space of the focal hole was populated with 154 and 123 documents belonging to classes A and B, respectively.Although Class A contained 31 more documents within the hole, the average mixup was lower compared to Class B. This observation underscores a key advantage of using mixup techniques when assessing the suffusion of negative space, rather than relying on the count of points that are located within that space.This is, of course, in addition to the aforemen-   tioned benefit wherein mixup does not require convex representative cycles, as would be the case for assessing proximity to a centroid.The Class B mixup documents that fill the focal hole span multiple established topic areas.The titles of a small selection of documents, as well as short descriptions of their interdisciplinary themes, are reported in table 1.</p>
<p>Documents permeating the eleventh representative cycle</p>
<p>The eleventh hole reported in fig.6b exhibits a higher average mixup for Class A compared to Class B. This implies that documents published before the training set are, on average, more likely to occupy this hole than those published after the training set.As before, we compared the mixup distributions for both classes A and B documents and observed a significant statistical difference between them (see fig. 9.) In total, there were 10 topics in the representative cycle.These topics were classified into five subjects: medicine &amp; healthcare, physical sciences &amp; engineering, life sciences &amp; biology, social science and agricultural extension.Each classification contains 4, 3, 1, 1 and 1 topics, respectively, from the representative cycle.</p>
<p>During our analysis of the mixup documents introduced into the embedding space (see fig. 10), we found that the negative space of the focal hole</p>
<p>Discussion and Conclusions</p>
<p>Informed by literature in science policy and innovation studies and structural linguistics, this paper presented a prospective approach to identifying and measuring the interdisciplinarity of scientific articles based on their content (or the content of their abstracts).Findings imply a complex relationship between the mixup scores of documents and their time of publication.Mixup scores are ascertained based on their placement respective to negative space (i.e., 'holes') when introduced into an embedding distribution learned by a topic model [59].Given that we observe evidence that publications located in the negative space betwixt topics tended to integrate those topics, and are dependent on the time of publication with respect to the training set, we conclude that negative embedding space is meaningful and merits further study.Diverse fields of research can sometimes struggle to identify points of integration among divergent subfields [52].The application of TDA and mixup to embedded scientific publication data represents an opportunity to better understand the conceptual landscape of a given field or collection of fields.</p>
<p>Our initial assumption was that interdisciplinary research that bridges different topics would be more likely to occupy the negative space between those topics.It followed that more recent publications would be more likely to integrate multiple subfields when establishing new ideas, per the theory of recombinant innovation [62,20,32].However, a more complex picture emerged.Publications following the training data occupied negative embedding space less frequently than publications preceding the training data.It appears likely that the negative embedding space may represent what we have referred to as the 'missing context' of publications that precede the training data.This lends further support to research finding that unsupervised embeddings capture latent information that has not been directly observed by the model [56]; that is, historical information, not hints of future discovery.This observation can be better explained by returning to the jigsaw puzzle analogy.Given that unobserved publications that precede the training set occupy negative embedding space more frequently, the 'holes' in the jigsaw puzzle are, quite literally, missing pieces of the puzzle that are inferred by the language model based on the puzzle pieces it can access (the training set).</p>
<p>On the other hand, innovative publications that follow the training set are new puzzle pieces that do not "fit" the current configuration of the puzzle.That is to say, they contain information that the embedding model does not know how to appraise and therefore ignores (recall that top2vec ignores words that it has not learned).The jigsaw puzzle would need to be disassembled and rearranged to "fit" these new pieces, meaning that the model would need to be re-trained to accommodate truly innovative, unobserved information.Granted, this analogy is imperfect given that we needed to operate at the topic-level in order to make the analysis computationally feasible.As such, the negative space in distributed topics might represent low-density regions of the underlying documents, rather than an absence of documents.When applied in this way, our approach still runs the risk of masking the influence of subfields that publish at a reduced rate, thereby generating fewer document clusters that rise to the level of becoming a topic [44].However, given that the default hyperparameter specification of top2vec only requires clusters of at least 15 papers to recognize a coherent topic [3], it is unlikely this approach would disfavor humanities and social scientific scholarship to the same degree as traditional metrics (impact factor, H-index, etc.)</p>
<p>In this initial work, we opted to employ the top2vec topic embedding model, a popular model at the time the project was conceived.Since conception, BERTopic has developed as an extension of top2vec, utilizing bidirectional encoder representations from transformers (BERT), rather than the shallow neural networks from which top2vec inherits its name [24].BERTopic includes a host of features that would support the further testing and implementation of mixup as a means of identifying interdisciplinary research.</p>
<p>Primarily, the capacity of BERT to continue pre-training from a 'checkpoint' would allow future research to pre-train the underlying topic model on a larger corpus, and then further pre-train (or 'fine-tune') on a training corpus, like the one presented in this paper.In theory, the additional context offered by the larger corpus would ensure that the structure of the underlying embeddings space better represents a generalized (structural) understanding of science.Moreover, fewer words would be omitted since words that do not appear in the training set (e.g., University of Florida publications) could appear in the pre-training set (e.g., Wikipedia, Web of Science, or dimensions.ai).Put simply, pre-training on a larger corpus (e.g., Wikipedia, Web of Science, or dimensions.ai)would be similar to providing the embedding model with a reference photo of the completed puzzle, including information on holes that exist in the conceptual space of the overarching, comprehensive knowledge base.Given our contention that the negative space in embedded documents represents missing context that a model infers based on the content of later publications, pre-training on a more exhaustive corpus and fine-tuning on the training set may produce results more in line with our initial assumptions.</p>
<p>Nevertheless, negative embedding space derived of these data will necessarily reflect more than just integrative opportunities or unobserved gaps between existing research topics.When examining individual documents, we noted that publications located in the negative conceptual space between topics were often interdisciplinary, integrating those topics.However, negative space might also reflect a lack of expertise within a given field or subfield or at a given institution, given that universities tend to maintain (and intentionally curate) research specializations [9,45].We recognize that performing this analysis on an exhaustive selection of publications from a single, smaller subfield would reduce opportunity for confounding by administrative factors.However, a corollary to this is that mixup might be utilized in aid of understanding what is 'missing' from a research institute, university, department, or funding mechanism.It is widely recognized that faculty hires are subject to biases, especially by race and sex [19,61].This hiring process can be broken down into four phases, during which bias can affect decision-making: (1) forming a search committee and determining the specialty of the prospective hire; (2) recruitment and marketing the position; (3) evaluating the candidates; (4) final decisions [43].Assuming the goal is to identify candidates who offer a complementary expertise and skillset [51], this metric might offer unique insights subject to fewer human biases when tailoring job searches, determining recruitment strategies, and evaluating candidates for "fit".</p>
<p>This similarly applies to research funding agencies: identify negative space in a given field, or among their own funded projects, decide if that negative space is meaningful (a divide between astrophysics and social science is to be expected, and would not merit 'filling'), then solicit appropriate applications.Alternatively, within grants intended to promote interdisciplinary research and determine 'unmet needs' (e.g., translational science institutes funded by the National Institutes of Health's National Center for Advancing Translational Sciences), this metric could be used to identify research areas that might merit further development.Ultimately, persistent homology and mixup represent an important opportunity to further understand conceptual landscapes and, by extension, better understand the embeddings underpinning a rapidly growing number of language models.</p>
<p>Funding</p>
<p>Research reported in this publication was supported by the University of Florida Clinical and Translational Science Institute, which is supported in part by the NIH National Center for Advancing Translational Sciences under award number UL1TR001427.The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Institutes of Health.</p>
<p>Figure 1 :
1
Figure1: Left: the collection of black dots is called a point cloud.Middle: consider balls of a fixed radius centered at each point.If two balls intersect, join them by an edge.If three balls have a common intersection, fill the triangle between the three edges arising from the pairwise intersections.Similarly, add higher-dimensional simplices for higherorder intersections.Right: the simplicial complex (consisting of vertices, edges, triangles, and higher-order simplices) obtained from this construction.</p>
<p>Figure 2 :
2
Figure 2: In (a), we recovered the homological information of a point cloud data which resembles an 8-figure with persistent homology.The two colored bars correspond to two holes surrounded by a 1-dimensional boundary.In (b), the persistence barcode is represented as a multi-set of points called a persistence diagram.For the green point in the persistence barcode, a representative cycle is visualized as the green cycle in (c).</p>
<p>Figure 3 :
3
Figure 3: Point cloud P contains the black dots, and point cloud Q contains the red crosses.(a) Point cloud P .(b) Point clouds P and Q.Using standard persistent homology we can find holes in dimension 1 for point cloud P .In (c), persistence barcode with the two longest bars for the 1st homology group of point cloud P is visualized.In (d), representative cycle of the longest bar (green color) is visualized in point cloud P and Q.Now, we consider how the inclusion of point cloud Q effect the hole visualized by the representative cycle in green color.(e) Growing balls around point cloud P and Q fills the hole visualized by the green representative cycle earlier compared to when we just have point cloud P .(f) The yellow bar represents how the inclusion of point cloud Q into point cloud P has reduced the length of the original green bar.</p>
<p>Figure 4 :
4
Figure 4: (a) Persistence diagram in degree 1 with a feature highlighted in red for topics embeddings obtained after projection into 2d using UMAP.(b) Extracted representative cycles plotted on the topics embedding for the highlighted feature in red.(c) Representative cycle with topic index.(d) Subject classification for different topics.(e) Topic information for topic indices which are part of the representative cycle.</p>
<p>To test this, we split the corpus into a training dataset (2008 -2020) and two mutually disjoint conditions: a pre-training set (2001 -2007) aka Class A and a post-training set (2021 -2023) aka Class B. Class A (2001 -2007) consisted of 20,139 documents, Class B (2021 -2023) consisted of 20,139 documents, and the training set (2008 -2020) consisted of 73,302 documents.</p>
<p>Histogram of total mixups (c) Box plot of total mixups</p>
<p>Figure 5 :
5
Figure 5: In (a), training data are the articles which were used to generate topics.Classes A and B are the articles, some of which were added later for analysis.Total mixup is calculated in 100 iterations for each class.In one iteration, 10 percent of randomly sampled points from a class are added to topics embedding, and total mixup was recorded.Histogram (b) of total mixups.Box plot (c) represents the distribution of total mixup for each class.P-value is calculated using permutation test, where the observed test statistics (absolute difference between means) was compared with 10,000 random permutations of the dataset.</p>
<p>Figure 6 :
6
Figure 6: (a) Points above the dotted red line has persistence greater than 0.2.There are 11 such points above the dotted red line.(b) Average mixup information for these 11 points when documents from classes A and B are added into the embedding space.</p>
<p>Figure 7 :
7
Figure 7: (a) Histogram for mixup distribution for holes indexed by 9. (b) Box plot of the two mixup distribution for class A and B visualizing the statistical difference between them using observed difference between means and applying permutation test for 10000 iterations.</p>
<p>Figure 8 :Figure 9 :
89
Figure 8: (a) Persistence diagram with index 9 hole.Since our data is in 5 dimensions, we use a polygon representation for visualization.(b) and (c) Topics labeled with their corresponding subject classification.(d) and (e) Representation of Classes A and B documents filling the negative space made by index 9 hole.</p>
<p>Figure 10 :
10
Figure 10: (a) Persistence diagram with index 11 hole.Since our data is in 5 dimensions, we use a polygon representation for visualization.(b) and (c) Topics labeled with their corresponding subject classification.(d) and (e) Representation of Classes A and B documents filling the negative space made by index 11 hole.</p>
<p>Table 1 :
1
Table describing different documents from class B which were filling up the hole index by 9.These are interdisciplinary research combining multiple fields including transplant medicine, pediatric oncology, critical care, and pulmonary medicine with various biological sciences.
InterdisciplinaryResearch TitleDescriptionAreaTransplant Medicine"A novel injuryCombines transplant+ Vascular Biologysite-natural antibodymedicine with vasculartargeted complementbiology and complementinhibitor protectssystem researchagainst lung transplantinjury"[34]Transplant Medicine"Resolution of post-lungBridges transplant surgery+ Cellular Biologytransplantwith cellular stress responseischemia-reperfusionand signaling mechanismsinjury is modulated viaResolvin D1-FPR2 andMaresin 1-LGR6signaling"[33]</p>
<p>Table 2 :
2
Examples of these documents, categorized by interdisciplinary themes, are provided in table 2.Table describing different documents from class A which were filling up the hole index by 11.These documents represent highly specialized molecular neuroscience research that integrates multiple biological systems, creating interdisciplinary connections across neuroscience, cell biology, materials science, and metabolism.
InterdisciplinaryResearch TitleDescriptionAreaNeuroscience +"Chibby PromotesBridges Cellular/MolecularMetabolism + CellAdipocyteBiology withSignalingDifferentiation throughMetabolism/AppetiteInhibition of β-CateninRegulation andSignaling"[35]developmental signalingpathwaysGene Therapy +"Polyethylenimine-Bridges Materials ScienceNeuroscience +mediated NGF genewith Neurology and CellularMaterials Sciencedelivery protectsBiologytransected septalcholinergic neurons"[63]Endocrinology +"Estrogen effects onCombinesNeuroscience +cognition andPsychology/PersonalityPsychologyhippocampalResearch with Neurologytranscription inand endocrinologymiddle-aged mice"[1]</p>
<p>Estrogen effects on cognition and hippocampal transcription in middle-aged mice. Ashok Kristina K Aenlle, Li Kumar, Travis C Cui, Thomas C Jackson, Foster, Neurobiology of aging. 3062009</p>
<p>The routinization of innovation research: a constructively critical review of the state-of-the-science. Neil Anderson, K W Carsten, Bernard A De Dreu, Nijstad, Journal of Organizational Behavior. 2522004</p>
<p>Dimo Angelov, Top2vec: Distributed representations of topics. 2020</p>
<p>bibliometrix: An r-tool for comprehensive science mapping analysis. Massimo Aria, Corrado Cuccurullo, Journal of Informetrics. 1142017</p>
<p>Theoretical foundations and limits of word embeddings: What types of meaning can they capture?. Alina Arseniev, - Koehler, Sociological Methods &amp; Research. 5342024</p>
<p>The application of bibliometrics to research evaluation in the humanities and social sciences: An exploratory study using normalized google scholar data for the publications of a research institute. Andreas Lutz Bornmann, Werner Thor, Hermann Marx, Schier, Journal of the Association for Information Science and Technology. 67112016</p>
<p>On the imbedding of systems of compacta in simplicial complexes. Karol Borsuk, Fundamenta Mathematicae. 3511948</p>
<p>Decomposition of persistence modules. Magnus Botnan, William Crawley-Boevey, Proceedings of the American Mathematical Society. 148112020</p>
<p>Specialization of regions and universities: The new versus the old. Pontus Braunerhjelm, Industry and Innovation. 1532008</p>
<p>Hierarchical density estimates for data clustering, visualization, and outlier detection. J G B Ricardo, Davoud Campello, Arthur Moulavi, Jörg Zimek, Sander, ACM Trans. Knowl. Discov. Data. 101July 2015</p>
<p>Science mapping: A systematic review of the literature. Chaomei Chen, Journal of Data and Information Science. 222017</p>
<p>Topological data analysis for geographical information science using persistent homology. Padraig Corcoran, Christopher B Jones, International Journal of Geographical Information Science. 3732023</p>
<p>Ferdinand De, Saussure , General Linguistics. Duckworth, London1983Translated by Roy Harris</p>
<p>Ondřej Draganov, Steven Skiena, The shape of word embeddings: Quantifying non-isometry with topological data analysis. Findings of the Association for Computational Linguistics: EMNLP 2024. ACL042024</p>
<p>Integrating metrics to measure research performance in social sciences and humanities: The case of the spanish csic. A Adrián, María Díaz-Faes, Thed N Bordons, Van Leeuwen, Research Evaluation. 25410 2016</p>
<p>Computational topology: an introduction. Herbert Edelsbrunner, John Harer, 2010American Mathematical Soc</p>
<p>Polygenic ara-c response score identifies pediatric patients with acute myeloid leukemia in need of chemotherapy augmentation. Xueyuan Abdelrahman H Elsayed, Cao, Huiyun Amit K Mitra, Susana Wu, Christopher Raimondi, Zeina Cogle, Raul C Al-Mansour, Alan Ribeiro, Edward Anders Gamis, Kolb, Journal of Clinical Oncology. 4072022</p>
<p>Persistent homology of geospatial data: A case study with voting. Michelle Feng, Mason A Porter, SIAM Review. 631January 2021</p>
<p>Taking the measure of faculty diversity. Martin J Finkelstein, Valerie M Conley, Jack H Schuster, 2016. October 2025TIAA InstituteTechnical report</p>
<p>Collaborative brokerage, generative creativity, and creative success. Lee Fleming, Santiago Mingo, David Chen, Administrative Science Quarterly. 5232007</p>
<p>. Santo Fortunato, Carl T Bergstrom, Katy Börner, James A Evans, Dirk Helbing, Staša Milojević, Alexander M Petersen, Filippo Radicchi, Roberta Sinatra, Brian Uzzi, Alessandro Vespignani, Ludo Waltman, Dashun Wang, Albert-László Barabási, Science of science. 35963791852018Science</p>
<p>A novel method of extracting topological features from word embeddings. Shafie Gholizadeh, Armin Seyeditabari, Wlodek Zadrozny, 2020</p>
<p>DONUT: Database of Original &amp; Non-Theoretical Uses of Topology. Barbara Giunti, Jānis Lazovskis, Bastian Rieck, 2022</p>
<p>Bertopic: Neural topic modeling with a classbased tf-idf procedure. Maarten Grootendorst, 2022</p>
<p>Persistent homology for resource coverage: A case study of access to polling sites. Abigail Hickok, Benjamin Jarman, Michael Johnson, Jiajie Luo, Mason A Porter, SIAM Review. 663May 2024</p>
<p>Hierarchical structures of amorphous solids characterized by persistent homology. Yasuaki Hiraoka, Takenobu Nakamura, Akihiko Hirata, Emerson G Escolar, Kaname Matsue, Yasumasa Nishiura, Proceedings of the National Academy of Sciences. 11326June 2016</p>
<p>The diversity-innovation paradox in science. Bas Hofstra, V Vivek, Sebastian Kulkarni, Munoz-Najar, Bryan Galvez, Dan He, Daniel A Jurafsky, Mcfarland, Proceedings of the National Academy of Sciences. 117172020</p>
<p>. Till Krenz. tilltnet/rdimensions. None. 92023</p>
<p>Scientific literature: Information overload. Esther Landhuis, Nature. 5357612Jul 2016</p>
<p>Distributed representations of sentences and documents. V Quoc, Tomas Le, Mikolov, 2014</p>
<p>What types of novelty are most disruptive?. Erin Leahey, Jina Lee, Russell J Funk, American Sociological Review. 8832023</p>
<p>Sociological innovation through subfield integration. Erin Leahey, James Moody, Social Currents. 132014</p>
<p>Resolution of post-lung transplant ischemiareperfusion injury is modulated via resolvin d1-fpr2 and maresin 1-lgr6 signaling. Victoria Leroy, Jun Cai, Zhenxiao Tu, Alexander Mcquiston, Simrun Sharma, Amir Emtiazjoo, Carl Atkinson, Gilbert R UpchurchJr, Ashish K Sharma, The Journal of Heart and Lung Transplantation. 4252023</p>
<p>A novel injury site-natural antibody targeted complement inhibitor protects against lung transplant injury. Changhai Li, Kunal Patel, Zhenxiao Tu, Xiaofeng Yang, Liudmila Kulik, Ali Alawieh, Patterson Allen, Qi Cheng, Caroline Wallace, Jane Kilkenny, American Journal of Transplantation. 2162021</p>
<p>Chibby promotes adipocyte differentiation through inhibition of β-catenin signaling. Feng-Qian Li, M Amar, Adaobi Singh, Damon Mofunanya, Naohiro Love, Randall T Terada, Ken-Ichi Moon, Takemaru, Molecular and Cellular Biology. 27122007</p>
<p>A computational model for functional mapping of genes that regulate intra-cellular circadian rhythms. Tian Liu, Xueli Liu, Yunmei Chen, Rongling Wu, Theoretical Biology and Medical Modelling. 4152007</p>
<p>Samhd1 single nucleotide polymorphisms impact outcome in children with newly diagnosed acute myeloid leukemia. Richard J Marrero, Xueyuan Cao, Huiyun Wu, Abdelrahman H Elsayed, Jeffery M Klco, Raul C Ribeiro, Jeffrey E Rubnitz, Xiaotu Ma, Soheil Meshinchi, Richard Aplenc, Blood advances. 7112023</p>
<p>The evolution of science policy and innovation studies. Ben R Martin, Research Policy. 4172012Exploring the Emerging Knowledge Base of</p>
<p>hdbscan: Hierarchical density based clustering. Leland Mcinnes, John Healy, Steve Astels, Journal of Open Source Software. 2112052017</p>
<p>Umap: Uniform manifold approximation and projection for dimension reduction. Leland Mcinnes, John Healy, James Melville, 2020</p>
<p>A user's guide to topological data analysis. Elizabeth Munch, Journal of Learning Analytics. 422017</p>
<p>Elements of algebraic topology. James R Munkres, 2018CRC press</p>
<p>Nudging toward diversity: Applying behavioral design to faculty hiring. Dawn Kerryann O'meara, Lindsey L Culpepper, Templeton, Review of Educational Research. 9032020</p>
<p>Dynamics of co-authorship and productivity across different fields of scientific research. Austin J Parish, Kevin W Boyack, John P A Ioannidis, PLOS ONE. 1312018</p>
<p>The determinants of the research output of universities: Specialization, quality and inefficiencies. José Manuel, Pastor , Lorenzo Serrano, Scientometrics. 1092Aug 2016</p>
<p>Dreimac: Dimensionality reduction with eilenberg-maclane coordinates. Jose A Perea, Luis Scoccola, Christopher J Tralie, Journal of Open Source Software. 89157912023</p>
<p>Significance tests which may be applied to samples from any populations. J G Edwin, Pitman, Supplement to the Journal of the Royal Statistical Society. 411937</p>
<p>Automatic Information Organization and Retrieval. Mc-Graw Hill Text. Gerard, Salton, 1968</p>
<p>Lipoxin a4 mitigates ferroptosis via fpr2 signaling during lung ischemia-reperfusion injury. Ashish Kumar Sharma, Jun Cai, Victoria Leroy, Zhenxiao Tu, Alejandro Gonzalez, Joseph Hartman, Jennifer Mulligan, Carl Atkinson, Gilbert UpchurchJr, The Journal of Immunology. 208Supplement_12022</p>
<p>Quantifying the evolution of individual scientific impact. Roberta Sinatra, Dashun Wang, Pierre Deville, Chaoming Song, Albert-László Barabási, Science. 354631252392016</p>
<p>Great minds think alike, or do they often differ? research topic overlap and the formation of scientific teams. Thomas Bryan, Smith , Raffaele Vacca, Till Krenz, Christopher Mc-Carty, Journal of Informetrics. 1511011042021</p>
<p>Luca Mantegazza, and Ilaria Capua. Natural language processing and network analysis provide novel insights on policy and scientific discourse around sustainable development goals. Thomas Bryan, Smith , Raffaele Vacca, Scientific Reports. 111Nov 2021</p>
<p>Quantifying the impact and relevance of scientific research. William J Sutherland, David Goulson, Simon G Potts, Lynn V Dicks, PLOS ONE. 6112011</p>
<p>Arts and humanities research evaluation: no metrics please, just data. Mike Thelwall, Maria M Delgado, Journal of Documentation. 7142015</p>
<p>Topological data analysis of c. elegans locomotion and behavior. Ashleigh Thomas, Kathleen Bates, Alex Elchesen, Iryna Hartsock, Hang Lu, Peter Bubenik, Frontiers in Artificial Intelligence. 4June 2021</p>
<p>Unsupervised word embeddings capture latent knowledge from materials science literature. John Vahe Tshitoyan, Leigh Dagdelen, Alexander Weston, Ziqin Dunn, Olga Rong, Kristin A Kononova, Gerbrand Persson, Anubhav Ceder, Jain, Nature. 5717763Jul 2019</p>
<p>Unveiling topological structures in text: A comprehensive survey of topological data analysis applications in nlp. Adaku Uchendu, Thai Le, 2024</p>
<p>A primer on topological data analysis to support image analysis tasks in environmental science. Lander Ver, Hoef , Henry Adams, Emily J King, Imme Ebert-Uphoff, Artificial Intelligence for the Earth Systems. 21January 2023</p>
<p>Hubert Wagner, Nickolas Arustamyan, Matthew Wheeler, Peter Bubenik, Mixup barcodes: Quantifying geometric-topological interactions between point clouds. 2024</p>
<p>Branching and circular features in high dimensional data. Bei Wang, Brian Summa, Mikael Valerio Pascucci, Vejdemo-Johansson, IEEE Transactions on Visualization and Computer Graphics. 17122011</p>
<p>Degrees of difference: Gender segregation of u.s. doctorates by field and program prestige. Kim A Weeden, Sarah Thébaud, Dafna Gelbgiser, Sociological Science. 462017</p>
<p>Recombinant growth*. Martin L Weitzman, The Quarterly Journal of Economics. 113205 1998</p>
<p>Polyethylenimine-mediated ngf gene delivery protects transected septal cholinergic neurons. Ke Wu, Craig A Meyers, Jennifer A Bennett, Michael A King, Edwin M Meyer, Jeffrey A Hughes, Brain research. 100822004</p>
<p>Large teams develop and small teams disrupt science and technology. Lingfei Wu, Dashun Wang, James A Evans, Nature. 5667744Feb 2019</p>
<p>Derivation of adipocytes from human embryonic stem cells. Chen Xiong, Chang-Qing Xie, Li Zhang, Jifeng Zhang, Kefeng Xu, Mingui Fu, Winston E Thompson, Li-Jun Yang, Yuqing E Chen, Stem cells and development. 1462005</p>
<p>jl: flexible and efficient persistent homology computation in julia. Matija Čufar, Ripserer, Journal of Open Source Software. 55426142020</p>            </div>
        </div>

    </div>
</body>
</html>