<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2202 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2202</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2202</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-58.html">extraction-schema-58</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of validation approaches in automated or AI-driven scientific research systems, including experimental validation, computational validation, simulation-based validation, and comparisons between these approaches.</div>
                <p><strong>Paper ID:</strong> paper-276450350</p>
                <p><strong>Paper Title:</strong> NeuroDISK: An AI Approach to Automate Continuous Inquiry-Driven Discoveries in Neuroimaging Genetics</p>
                <p><strong>Paper Abstract:</strong> ABSTRACT Collaborative and multi-site neuroimaging studies have greatly accelerated the rate at which new and existing data can be aggregated to answer a neuroscientific question. New research initiatives are continuously collecting more data, allowing opportunities to refine previous published findings through continuous and dynamic updates. Yet, we lack a practical framework for researchers to systematically, automatically, and continuously update published findings. We developed NeuroDISK, an automated artificial intelligence based framework that: 1) performs automated and inquiry-driven analyses, and 2) continuously updates these analyses as new data becomes available. NeuroDISK was evaluated using published results from the ENIGMA consortium’s work on the genetic architecture of the cerebral cortex. We incorporate both meta-analysis and meta-regression options to showcase our framework on the effect of specific genotypes and moderators on select brain regions. Initial NeuroDISK meta-analysis results replicate the original publication, and we show result updates after adding new data. The NeuroDISK framework can be generalized for users to define question(s), run corresponding workflow(s) and access results interactively and continuously.</p>
                <p><strong>Cost:</strong> 0.021</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2202.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2202.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of validation approaches in automated or AI-driven scientific research systems, including experimental validation, computational validation, simulation-based validation, and comparisons between these approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>NeuroDISK</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>NeuroDISK (an AI framework for continuous inquiry-driven discoveries in neuroimaging genetics)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An AI system built on the DISK framework that encodes 'lines of inquiry' to automatically find, analyze, and continuously re-run meta-analytic and meta-regression workflows on neuroimaging genetics summary results as new data arrive.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_or_method_name</strong></td>
                            <td>NeuroDISK</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>neuroimaging genetics / computational neuroscience</td>
                        </tr>
                        <tr>
                            <td><strong>validation_type</strong></td>
                            <td>computational validation</td>
                        </tr>
                        <tr>
                            <td><strong>validation_description</strong></td>
                            <td>Validation is performed by reproducing published ENIGMA GWAS meta-analysis results (Grasby et al., 2020) via NeuroDISK's meta-analysis workflow: effect sizes from cohorts are combined using inverse-variance weighting, forest plots and associated statistics (effect size, standard error, p-value) are generated, and results are compared to the published figures/tables. Additional validation includes meta-regression analyses (effect size vs cohort mean age) weighted by sample size. The system also performs continuous-update tests by re-running analyses as simulated or newly uploaded cohort-level summary results (including an independently computed ABCD cohort upload) are added to the repository.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_fidelity</strong></td>
                            <td>Not physics/chemistry simulation. Where simulation is used it is resampling/subsampling of cohort lists to emulate incremental data arrival (low-fidelity simulation of data availability rather than modeling of biological processes). No numerical accuracy metrics for simulation fidelity are reported.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation_performed</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_simulation_vs_experiment</strong></td>
                            <td>No direct comparison between physics/experimental simulations and experiments is reported. The computational meta-analyses are compared to the original published computational results (Grasby et al., 2020); near-identical effect sizes are reported without UK Biobank and small significance differences are noted when UK Biobank is included due to different aggregation ordering.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_validation_standards</strong></td>
                            <td>Uses standard meta-analytic statistical practice (inverse-variance weighted meta-analysis, forest plots, meta-regression with cohort weighting) and reproducibility practices (provenance capture, semantic metadata, FAIR principles). Successful replication of published ENIGMA results is presented as the validation standard in this domain.</td>
                        </tr>
                        <tr>
                            <td><strong>when_simulation_sufficient</strong></td>
                            <td>Paper indicates resampling/subsampling simulations are sufficient to test the framework's continuous-update behavior and demonstrate how results evolve as cohorts are added, but does not claim simulation alone suffices to validate scientific (biological/genetic) hypotheses.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_failures</strong></td>
                            <td>No explicit simulation failures reported; authors note that meta-regression results hover near nominal significance and that trends are unstable, indicating that simulated incremental data addition did not produce a stable validated scientific effect.</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>Uses standard meta-analytic uncertainty measures: per-cohort effect sizes with standard errors, inverse-variance weighting, p-values, (authors state workflows can produce confidence intervals), forest plots and -log10(p) visualizations; meta-regression reports beta and p-values. No additional uncertainty propagation metrics or Bayesian credible intervals reported.</td>
                        </tr>
                        <tr>
                            <td><strong>fabrication_detection</strong></td>
                            <td>Not discussed; no methods for detecting fabricated or AI-generated data/results are described.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_cost_time</strong></td>
                            <td>No quantitative cost/time metrics provided. Authors assert automation reduces human time and effort and speeds re-execution of analyses (qualitative statement only).</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_validation_approach</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>validation_limitations</strong></td>
                            <td>Validation limited to available summary-level cohort results (no individual-subject analyses performed in this implementation). Slight discrepancies versus the original publication when combining UK Biobank are attributed to different meta-analysis aggregation order. Authors note need for more data to obtain stable trends in meta-regression results.</td>
                        </tr>
                        <tr>
                            <td><strong>acceptance_credibility</strong></td>
                            <td>Paper argues that reproducing published results and providing provenance/explanations increases credibility; successful replication of Grasby et al. is offered as evidence that NeuroDISK's computational validation is trustworthy for the domain community.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_gold_standard</strong></td>
                            <td>Direct comparison to the published ENIGMA analysis (Grasby et al., 2020): NeuroDISK reproduces effect sizes nearly identically when using the same cohorts (slight p-value differences when differing aggregation approaches are used). No numeric 'accuracy' percent given, but reported results are qualitatively the same.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2202.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2202.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of validation approaches in automated or AI-driven scientific research systems, including experimental validation, computational validation, simulation-based validation, and comparisons between these approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DISK</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>DISK framework (general domain-independent framework for hypothesis evolution and automated inquiry)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>General-purpose software and ontology framework that represents scientific questions, lines of inquiry, and provenance to enable automated execution and explanation of scientific analyses.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_or_method_name</strong></td>
                            <td>DISK</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>general scientific workflow automation / knowledge representation</td>
                        </tr>
                        <tr>
                            <td><strong>validation_type</strong></td>
                            <td>computational validation</td>
                        </tr>
                        <tr>
                            <td><strong>validation_description</strong></td>
                            <td>DISK provides provenance capture (PROV), ontology-driven question representations (SQO), and APIs/adapters; validation within this paper consists of using DISK to store provenance, trigger LOIs, and generate explanations for the NeuroDISK runs. Validation is computational (re-execution reproducibility) rather than experimental.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_fidelity</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation_performed</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_simulation_vs_experiment</strong></td>
                            <td>Not applicable; validation is measured by DISK's ability to reproduce and explain computational runs.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_validation_standards</strong></td>
                            <td>Relies on semantic web standards (RDF, OWL, SPARQL) and PROV for reproducibility and traceability; follows FAIR data principles to meet domain expectations for reproducibility.</td>
                        </tr>
                        <tr>
                            <td><strong>when_simulation_sufficient</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>simulation_failures</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>DISK itself records provenance and results including the uncertainty measures produced by workflows (e.g., standard errors, p-values) but does not compute additional uncertainty metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>fabrication_detection</strong></td>
                            <td>Not addressed.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_cost_time</strong></td>
                            <td>No quantitative costs provided.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_validation_approach</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_limitations</strong></td>
                            <td>Effectiveness depends on richness of metadata and availability of workflow adapters; in NeuroDISK, subject-level analyses were not performed because of data-sharing constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>acceptance_credibility</strong></td>
                            <td>Argued to increase acceptance by enabling standardization of methods, provenance, and re-execution; no empirical evidence beyond the NeuroDISK demonstration is provided.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_gold_standard</strong></td>
                            <td>No explicit comparison to a different gold-standard framework; DISK's validation demonstrated by reproducing analyses in NeuroDISK.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2202.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2202.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of validation approaches in automated or AI-driven scientific research systems, including experimental validation, computational validation, simulation-based validation, and comparisons between these approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Meta-analysis workflow</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>NeuroDISK meta-analysis workflow (inverse-variance weighted meta-analysis)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A workflow component that aggregates cohort-level summary statistics (effect sizes and standard errors) using inverse-variance weighting to compute overall effect sizes, p-values and forest plots for visualization.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_or_method_name</strong></td>
                            <td>meta-analysis workflow (inverse-variance weighting)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>statistical genetics / meta-analysis</td>
                        </tr>
                        <tr>
                            <td><strong>validation_type</strong></td>
                            <td>computational validation</td>
                        </tr>
                        <tr>
                            <td><strong>validation_description</strong></td>
                            <td>Aggregates cohort effect sizes using inverse-variance weighting, outputs forest plots and summary statistics. Validation comprised comparing resulting effect sizes/p-values to those in the published ENIGMA GWAS (Grasby et al., 2020); near-identical results were obtained except for minor differences due to aggregation ordering for UK Biobank inclusion.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_fidelity</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation_performed</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_simulation_vs_experiment</strong></td>
                            <td>Comparison is computational: workflow output compared to published computational results; agreement is reported as strong (effect sizes nearly identical without UK Biobank; minor p-value differences with UKB).</td>
                        </tr>
                        <tr>
                            <td><strong>validation_success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_validation_standards</strong></td>
                            <td>Follows standard meta-analysis practice (inverse-variance weighting, forest plots); reproduction of a canonical ENIGMA meta-analysis is treated as the validation standard.</td>
                        </tr>
                        <tr>
                            <td><strong>when_simulation_sufficient</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>simulation_failures</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>Uses per-cohort standard errors and p-values, and inverse-variance weighting propagates these uncertainties into the combined estimate; confidence intervals are available from the workflow output (explicit numeric CI values not listed in the paper).</td>
                        </tr>
                        <tr>
                            <td><strong>fabrication_detection</strong></td>
                            <td>Not discussed.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_cost_time</strong></td>
                            <td>No specific cost/time metrics; workflow is automated to reduce manual effort.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_validation_approach</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>validation_limitations</strong></td>
                            <td>Relies on availability of cohort-level summary stats; method-of-aggregation differences (e.g., meta-analyzing discovery cohorts first then adding replication cohorts vs pooling all cohorts) can produce small discrepancies.</td>
                        </tr>
                        <tr>
                            <td><strong>acceptance_credibility</strong></td>
                            <td>Replication of a published, high-profile meta-analysis is presented as evidence supporting the workflow's credibility to domain researchers.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_gold_standard</strong></td>
                            <td>Directly compared to Grasby et al. (ENIGMA) meta-analysis; outcomes are essentially concordant (qualitative agreement; no numeric error rate provided).</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2202.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2202.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of validation approaches in automated or AI-driven scientific research systems, including experimental validation, computational validation, simulation-based validation, and comparisons between these approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Meta-regression workflow</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>NeuroDISK meta-regression workflow (weighted regression of cohort effect sizes on moderators)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A meta-regression meta-workflow that regresses per-cohort effect sizes (weighted by sample size or inverse variance) against cohort-level moderators (e.g., mean age) to test for moderator effects driving heterogeneity.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_or_method_name</strong></td>
                            <td>meta-regression workflow</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>statistical genetics / meta-analysis</td>
                        </tr>
                        <tr>
                            <td><strong>validation_type</strong></td>
                            <td>computational validation</td>
                        </tr>
                        <tr>
                            <td><strong>validation_description</strong></td>
                            <td>Implements a weighted regression of cohort-level effect sizes on cohort covariates (mean age). Validation shown via meta-regression runs across increasing numbers of cohorts; outputs include scatterplots, regression beta and p-values. Demonstrated that with >=40 cohorts the association reaches nominal significance (p≈0.02) but authors caution instability and need for more data.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_fidelity</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation_performed</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_simulation_vs_experiment</strong></td>
                            <td>No experimental benchmarks; comparison is across reruns with different cohort inclusion (subsampling/added cohorts) showing how p-values change.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_validation_standards</strong></td>
                            <td>Uses weighted regression practices common in meta-analysis and reports p-values and regression betas; authors treat multiple runs and convergence/stability across data additions as indicators of validation.</td>
                        </tr>
                        <tr>
                            <td><strong>when_simulation_sufficient</strong></td>
                            <td>Used to explore behavior of moderator detection under simulated incremental data addition; authors note simulation suffices to evaluate system update behavior but not to establish definitive scientific claims.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_failures</strong></td>
                            <td>Result instability reported (trend hovers around nominal threshold), indicating meta-regression results may fail to reach robust significance until more data are available.</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>Regression outputs include beta coefficients and p-values; cohort point sizes reflect sample size in plots; no formal heterogeneity metrics (e.g., I^2) are reported in the paper text for these specific runs.</td>
                        </tr>
                        <tr>
                            <td><strong>fabrication_detection</strong></td>
                            <td>Not discussed.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_cost_time</strong></td>
                            <td>No quantitative costs provided.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_validation_approach</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>validation_limitations</strong></td>
                            <td>Moderator analyses depend on cohort-level covariate availability and adequate sample representation; authors warn that nominal significance is not necessarily stable and requires more data.</td>
                        </tr>
                        <tr>
                            <td><strong>acceptance_credibility</strong></td>
                            <td>Authors suggest that the ability to investigate moderators and show how effects change with added data enhances interpretability and trust, but emphasize cautious interpretation when results are borderline significant.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_gold_standard</strong></td>
                            <td>No direct comparison to alternative meta-regression tools; validation is internal (consistency across iterative data additions) rather than benchmarked against external gold standards.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2202.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2202.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of validation approaches in automated or AI-driven scientific research systems, including experimental validation, computational validation, simulation-based validation, and comparisons between these approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Continuous-update simulation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Subsampling-based continuous-update simulation (simulating incremental cohort arrival)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A low-fidelity simulation strategy used to emulate how NeuroDISK updates findings as new cohorts are added by subsampling cohort sets (10->20->30->40->48->49->50) and re-running LOIs to visualize evolution of p-values and effect estimates.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_or_method_name</strong></td>
                            <td>subsampling-based continuous-update simulation</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>computational validation / software testing</td>
                        </tr>
                        <tr>
                            <td><strong>validation_type</strong></td>
                            <td>low-fidelity simulation</td>
                        </tr>
                        <tr>
                            <td><strong>validation_description</strong></td>
                            <td>Authors randomly subsampled the cohort list in increments (10, 20, 30, 40, 48), then added UK Biobank and an external ABCD cohort to simulate new data arrivals and re-ran meta-analysis/meta-regression workflows to track changes in statistics (e.g., -log10 p). This demonstrates system behavior under incremental data growth.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_fidelity</strong></td>
                            <td>Low-fidelity: resampling of existing cohort-level summary statistics; does not model biological mechanisms or measurement processes. No numerical fidelity metrics provided.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation_performed</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_simulation_vs_experiment</strong></td>
                            <td>Simulation used for system-behavior validation only; not compared to physical experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_validation_standards</strong></td>
                            <td>Used as a pragmatic test to show continuous update functionality rather than a domain-level validation standard.</td>
                        </tr>
                        <tr>
                            <td><strong>when_simulation_sufficient</strong></td>
                            <td>Sufficient to test software-level continuous update and to illustrate sensitivity of meta-analytic results to incremental cohort additions; insufficient to replace empirical validation of scientific hypotheses.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_failures</strong></td>
                            <td>No explicit failures of the simulation mechanism reported, but results showed unstable trends requiring more real data for conclusive findings.</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>Tracked p-values and -log10(p) across runs; no formal error bars reported for the simulation process itself.</td>
                        </tr>
                        <tr>
                            <td><strong>fabrication_detection</strong></td>
                            <td>Not applicable.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_cost_time</strong></td>
                            <td>No cost/time data provided; simulation is computational and therefore relatively low-cost compared to real data collection.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_validation_approach</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>validation_limitations</strong></td>
                            <td>Artificial ordering/subsampling may not represent realistic cohort arrival patterns; does not account for differences in data quality or measurement heterogeneity beyond the available cohort metadata.</td>
                        </tr>
                        <tr>
                            <td><strong>acceptance_credibility</strong></td>
                            <td>Serves as demonstrative evidence that the system can continuously re-evaluate findings; authors caution about overinterpreting simulated trends without more data.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_gold_standard</strong></td>
                            <td>No comparison to other continuous-update simulation methods presented.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2202.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e2202.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of validation approaches in automated or AI-driven scientific research systems, including experimental validation, computational validation, simulation-based validation, and comparisons between these approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>WINGS</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>WINGS (intelligent workflow system)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An intelligent workflow system used by NeuroDISK to execute computational workflows and propagate semantic constraints, and to export provenance records used for explanation and replication.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_or_method_name</strong></td>
                            <td>WINGS workflow system</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>computational workflows / reproducible computing</td>
                        </tr>
                        <tr>
                            <td><strong>validation_type</strong></td>
                            <td>computational validation</td>
                        </tr>
                        <tr>
                            <td><strong>validation_description</strong></td>
                            <td>WINGS enforces semantic constraints on inputs, sets workflow parameters appropriate for datasets, executes workflows, and exports provenance for DISK. Validation is operational: workflows executed through WINGS produced the meta-analytic outputs used for reproducing the ENIGMA results.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_fidelity</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation_performed</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_simulation_vs_experiment</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_validation_standards</strong></td>
                            <td>WINGS' constraint propagation and provenance capture align with reproducibility best practices; used as the execution engine rather than a validation benchmark.</td>
                        </tr>
                        <tr>
                            <td><strong>when_simulation_sufficient</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>simulation_failures</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>WINGS records provenance and outputs uncertainties produced by analyses but does not itself define uncertainty quantification.</td>
                        </tr>
                        <tr>
                            <td><strong>fabrication_detection</strong></td>
                            <td>Not discussed.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_cost_time</strong></td>
                            <td>Not quantified.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_validation_approach</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_limitations</strong></td>
                            <td>Depends on accurate semantic annotations and correct workflow models; not discussed in depth.</td>
                        </tr>
                        <tr>
                            <td><strong>acceptance_credibility</strong></td>
                            <td>Providing provenance exports and constraint-driven execution is presented as improving trust and reproducibility of computational analyses.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_gold_standard</strong></td>
                            <td>No direct comparison to other workflow engines in this paper.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2202.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e2202.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of validation approaches in automated or AI-driven scientific research systems, including experimental validation, computational validation, simulation-based validation, and comparisons between these approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Provenance & FAIR practices</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Provenance capture and FAIR data/methods practices (RDF/OWL/SPARQL/PROV)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Use of semantic web standards and provenance (RDF/OWL/SPARQL/PROV) and FAIR principles to describe datasets, question templates, and method provenance to support reproducibility and validation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_or_method_name</strong></td>
                            <td>Provenance capture and FAIR metadata practices</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>data management / reproducibility</td>
                        </tr>
                        <tr>
                            <td><strong>validation_type</strong></td>
                            <td>computational validation</td>
                        </tr>
                        <tr>
                            <td><strong>validation_description</strong></td>
                            <td>Datasets and questions are represented using RDF/OWL ontologies (SDO, DSO, SQO) and queries via SPARQL; provenance of workflow executions recorded with PROV. These artifacts are used to validate which data and methods were used and to generate explanations to support reproducibility.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_fidelity</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation_performed</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_simulation_vs_experiment</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_validation_standards</strong></td>
                            <td>Aligns with community best practices (FAIR) for reproducibility; authors reference reproducibility literature and container-based replication.</td>
                        </tr>
                        <tr>
                            <td><strong>when_simulation_sufficient</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>simulation_failures</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>Provenance records include the analytical outputs that contain uncertainty metrics (SE, p-values); provenance itself does not quantify uncertainty.</td>
                        </tr>
                        <tr>
                            <td><strong>fabrication_detection</strong></td>
                            <td>Not addressed directly; provenance is implied as a tool to make fabrication or alteration easier to detect but no methods are described.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_cost_time</strong></td>
                            <td>Not quantified.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_validation_approach</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_limitations</strong></td>
                            <td>Effectiveness depends on the completeness of metadata and honesty/completeness of provenance records; does not prevent misuse or misinterpretation of analyses.</td>
                        </tr>
                        <tr>
                            <td><strong>acceptance_credibility</strong></td>
                            <td>Authors argue that semantic provenance and FAIR metadata increase community acceptance by enabling re-execution, transparency, and method reuse.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_gold_standard</strong></td>
                            <td>No explicit numeric comparison to other provenance systems; approach is presented as consistent with community standards.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2202.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e2202.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of validation approaches in automated or AI-driven scientific research systems, including experimental validation, computational validation, simulation-based validation, and comparisons between these approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>A-lab (Szymanski et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>A-lab (autonomous laboratory for solid-state synthesis)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Mentioned as a related example where AI, machine learning, and robotics are combined to propose, optimize, and physically execute materials synthesis experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_or_method_name</strong></td>
                            <td>A-lab (autonomous lab integrating LLMs, ML, and robotics)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>materials science / experimental chemistry (related work mention)</td>
                        </tr>
                        <tr>
                            <td><strong>validation_type</strong></td>
                            <td>hybrid</td>
                        </tr>
                        <tr>
                            <td><strong>validation_description</strong></td>
                            <td>Paper cites A-lab as an example of an autonomous system that uses LLMs to propose experiments, ML to optimize, and a robotic platform to execute experiments, implying experimental validation is performed in that system; NeuroDISK references this work only in related-work context and does not use it.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_fidelity</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation_performed</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_simulation_vs_experiment</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_validation_standards</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>when_simulation_sufficient</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>simulation_failures</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fabrication_detection</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_cost_time</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_validation_approach</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_limitations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>acceptance_credibility</strong></td>
                            <td>Mentioned as demonstrating advances in automation that include experimental execution, but NeuroDISK does not evaluate A-lab's validation results.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_gold_standard</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2202.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e2202.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of validation approaches in automated or AI-driven scientific research systems, including experimental validation, computational validation, simulation-based validation, and comparisons between these approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Pyzer-Knapp prototype</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>AI prototype for materials discovery with simulators and robotic chemistry platforms (Pyzer-Knapp et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Referenced related work combining literature extraction, simulation-based optimization, and robotic execution for materials discovery; cited as an example where computational/simulation and experimental components are combined.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_or_method_name</strong></td>
                            <td>AI + simulators + robotic chemistry platform (prototype)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>materials science / computational materials discovery (related work mention)</td>
                        </tr>
                        <tr>
                            <td><strong>validation_type</strong></td>
                            <td>hybrid</td>
                        </tr>
                        <tr>
                            <td><strong>validation_description</strong></td>
                            <td>Mentioned as performing simulation-driven optimization followed by robotic experimental execution in the related-work discussion; NeuroDISK only cites this work and does not use it.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_fidelity</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation_performed</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_simulation_vs_experiment</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_validation_standards</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>when_simulation_sufficient</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>simulation_failures</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fabrication_detection</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_cost_time</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_validation_approach</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_limitations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>acceptance_credibility</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_gold_standard</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2202.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e2202.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of validation approaches in automated or AI-driven scientific research systems, including experimental validation, computational validation, simulation-based validation, and comparisons between these approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Coscientist</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Coscientist (AI system designing and planning chemical reaction experiments)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Cited as a proof-of-concept system that designs and plans chemical experiments and generates code for execution in cloud laboratories, illustrating AI-assisted experimental planning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_or_method_name</strong></td>
                            <td>Coscientist (LLM-based experiment planner)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>chemistry / automated experimentation (related work mention)</td>
                        </tr>
                        <tr>
                            <td><strong>validation_type</strong></td>
                            <td>other</td>
                        </tr>
                        <tr>
                            <td><strong>validation_description</strong></td>
                            <td>Included in related work to illustrate AI-driven experiment planning; NeuroDISK does not use or validate Coscientist. The paper notes that such systems can generate executable protocols but that results may not be guaranteed correct.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_fidelity</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation_performed</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_simulation_vs_experiment</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_validation_standards</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>when_simulation_sufficient</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>simulation_failures</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fabrication_detection</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_cost_time</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_validation_approach</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_limitations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>acceptance_credibility</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_gold_standard</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2202.10">
                <h3 class="extraction-instance">Extracted Data Instance 10 (e2202.10)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of validation approaches in automated or AI-driven scientific research systems, including experimental validation, computational validation, simulation-based validation, and comparisons between these approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>XLuminA (Rodríguez et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>XLuminA (automated experimental design for super-resolution microscopy)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Mentioned related work that automates experimental design for microscopy using AI to accelerate experimental optimization compared to traditional numerical optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_or_method_name</strong></td>
                            <td>XLuminA (AI-driven experimental design)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>microscopy / experimental imaging (related work mention)</td>
                        </tr>
                        <tr>
                            <td><strong>validation_type</strong></td>
                            <td>hybrid</td>
                        </tr>
                        <tr>
                            <td><strong>validation_description</strong></td>
                            <td>Cited as evidence that AI can accelerate experimental design and execution in laboratory settings; NeuroDISK references this work in context but does not use it.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_fidelity</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation_performed</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_simulation_vs_experiment</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_validation_standards</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>when_simulation_sufficient</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>simulation_failures</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fabrication_detection</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_cost_time</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_validation_approach</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_limitations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>acceptance_credibility</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_gold_standard</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>The genetic architecture of the human cerebral cortex <em>(Rating: 2)</em></li>
                <li>An autonomous laboratory for the accelerated synthesis of novel materials <em>(Rating: 2)</em></li>
                <li>Accelerating materials discovery using artificial intelligence, high performance computing and robotics <em>(Rating: 2)</em></li>
                <li>Autonomous chemical research with large language models <em>(Rating: 2)</em></li>
                <li>Automated discovery of experimental designs in super-resolution microscopy with XLuminA <em>(Rating: 2)</em></li>
                <li>Conceptual understanding through efficient automated design of quantum optical experiments <em>(Rating: 2)</em></li>
                <li>Neurodesk: an accessible, flexible and portable data analysis environment for reproducible neuroimaging <em>(Rating: 1)</em></li>
                <li>Towards Automated Hypothesis Testing in Neuroscience <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2202",
    "paper_id": "paper-276450350",
    "extraction_schema_id": "extraction-schema-58",
    "extracted_data": [
        {
            "name_short": "NeuroDISK",
            "name_full": "NeuroDISK (an AI framework for continuous inquiry-driven discoveries in neuroimaging genetics)",
            "brief_description": "An AI system built on the DISK framework that encodes 'lines of inquiry' to automatically find, analyze, and continuously re-run meta-analytic and meta-regression workflows on neuroimaging genetics summary results as new data arrive.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_or_method_name": "NeuroDISK",
            "scientific_domain": "neuroimaging genetics / computational neuroscience",
            "validation_type": "computational validation",
            "validation_description": "Validation is performed by reproducing published ENIGMA GWAS meta-analysis results (Grasby et al., 2020) via NeuroDISK's meta-analysis workflow: effect sizes from cohorts are combined using inverse-variance weighting, forest plots and associated statistics (effect size, standard error, p-value) are generated, and results are compared to the published figures/tables. Additional validation includes meta-regression analyses (effect size vs cohort mean age) weighted by sample size. The system also performs continuous-update tests by re-running analyses as simulated or newly uploaded cohort-level summary results (including an independently computed ABCD cohort upload) are added to the repository.",
            "simulation_fidelity": "Not physics/chemistry simulation. Where simulation is used it is resampling/subsampling of cohort lists to emulate incremental data arrival (low-fidelity simulation of data availability rather than modeling of biological processes). No numerical accuracy metrics for simulation fidelity are reported.",
            "experimental_validation_performed": false,
            "comparison_simulation_vs_experiment": "No direct comparison between physics/experimental simulations and experiments is reported. The computational meta-analyses are compared to the original published computational results (Grasby et al., 2020); near-identical effect sizes are reported without UK Biobank and small significance differences are noted when UK Biobank is included due to different aggregation ordering.",
            "validation_success_rate": null,
            "domain_validation_standards": "Uses standard meta-analytic statistical practice (inverse-variance weighted meta-analysis, forest plots, meta-regression with cohort weighting) and reproducibility practices (provenance capture, semantic metadata, FAIR principles). Successful replication of published ENIGMA results is presented as the validation standard in this domain.",
            "when_simulation_sufficient": "Paper indicates resampling/subsampling simulations are sufficient to test the framework's continuous-update behavior and demonstrate how results evolve as cohorts are added, but does not claim simulation alone suffices to validate scientific (biological/genetic) hypotheses.",
            "simulation_failures": "No explicit simulation failures reported; authors note that meta-regression results hover near nominal significance and that trends are unstable, indicating that simulated incremental data addition did not produce a stable validated scientific effect.",
            "uncertainty_quantification": "Uses standard meta-analytic uncertainty measures: per-cohort effect sizes with standard errors, inverse-variance weighting, p-values, (authors state workflows can produce confidence intervals), forest plots and -log10(p) visualizations; meta-regression reports beta and p-values. No additional uncertainty propagation metrics or Bayesian credible intervals reported.",
            "fabrication_detection": "Not discussed; no methods for detecting fabricated or AI-generated data/results are described.",
            "validation_cost_time": "No quantitative cost/time metrics provided. Authors assert automation reduces human time and effort and speeds re-execution of analyses (qualitative statement only).",
            "hybrid_validation_approach": false,
            "validation_limitations": "Validation limited to available summary-level cohort results (no individual-subject analyses performed in this implementation). Slight discrepancies versus the original publication when combining UK Biobank are attributed to different meta-analysis aggregation order. Authors note need for more data to obtain stable trends in meta-regression results.",
            "acceptance_credibility": "Paper argues that reproducing published results and providing provenance/explanations increases credibility; successful replication of Grasby et al. is offered as evidence that NeuroDISK's computational validation is trustworthy for the domain community.",
            "comparison_to_gold_standard": "Direct comparison to the published ENIGMA analysis (Grasby et al., 2020): NeuroDISK reproduces effect sizes nearly identically when using the same cohorts (slight p-value differences when differing aggregation approaches are used). No numeric 'accuracy' percent given, but reported results are qualitatively the same.",
            "uuid": "e2202.0"
        },
        {
            "name_short": "DISK",
            "name_full": "DISK framework (general domain-independent framework for hypothesis evolution and automated inquiry)",
            "brief_description": "General-purpose software and ontology framework that represents scientific questions, lines of inquiry, and provenance to enable automated execution and explanation of scientific analyses.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_or_method_name": "DISK",
            "scientific_domain": "general scientific workflow automation / knowledge representation",
            "validation_type": "computational validation",
            "validation_description": "DISK provides provenance capture (PROV), ontology-driven question representations (SQO), and APIs/adapters; validation within this paper consists of using DISK to store provenance, trigger LOIs, and generate explanations for the NeuroDISK runs. Validation is computational (re-execution reproducibility) rather than experimental.",
            "simulation_fidelity": null,
            "experimental_validation_performed": false,
            "comparison_simulation_vs_experiment": "Not applicable; validation is measured by DISK's ability to reproduce and explain computational runs.",
            "validation_success_rate": null,
            "domain_validation_standards": "Relies on semantic web standards (RDF, OWL, SPARQL) and PROV for reproducibility and traceability; follows FAIR data principles to meet domain expectations for reproducibility.",
            "when_simulation_sufficient": null,
            "simulation_failures": null,
            "uncertainty_quantification": "DISK itself records provenance and results including the uncertainty measures produced by workflows (e.g., standard errors, p-values) but does not compute additional uncertainty metrics.",
            "fabrication_detection": "Not addressed.",
            "validation_cost_time": "No quantitative costs provided.",
            "hybrid_validation_approach": null,
            "validation_limitations": "Effectiveness depends on richness of metadata and availability of workflow adapters; in NeuroDISK, subject-level analyses were not performed because of data-sharing constraints.",
            "acceptance_credibility": "Argued to increase acceptance by enabling standardization of methods, provenance, and re-execution; no empirical evidence beyond the NeuroDISK demonstration is provided.",
            "comparison_to_gold_standard": "No explicit comparison to a different gold-standard framework; DISK's validation demonstrated by reproducing analyses in NeuroDISK.",
            "uuid": "e2202.1"
        },
        {
            "name_short": "Meta-analysis workflow",
            "name_full": "NeuroDISK meta-analysis workflow (inverse-variance weighted meta-analysis)",
            "brief_description": "A workflow component that aggregates cohort-level summary statistics (effect sizes and standard errors) using inverse-variance weighting to compute overall effect sizes, p-values and forest plots for visualization.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_or_method_name": "meta-analysis workflow (inverse-variance weighting)",
            "scientific_domain": "statistical genetics / meta-analysis",
            "validation_type": "computational validation",
            "validation_description": "Aggregates cohort effect sizes using inverse-variance weighting, outputs forest plots and summary statistics. Validation comprised comparing resulting effect sizes/p-values to those in the published ENIGMA GWAS (Grasby et al., 2020); near-identical results were obtained except for minor differences due to aggregation ordering for UK Biobank inclusion.",
            "simulation_fidelity": null,
            "experimental_validation_performed": false,
            "comparison_simulation_vs_experiment": "Comparison is computational: workflow output compared to published computational results; agreement is reported as strong (effect sizes nearly identical without UK Biobank; minor p-value differences with UKB).",
            "validation_success_rate": null,
            "domain_validation_standards": "Follows standard meta-analysis practice (inverse-variance weighting, forest plots); reproduction of a canonical ENIGMA meta-analysis is treated as the validation standard.",
            "when_simulation_sufficient": null,
            "simulation_failures": null,
            "uncertainty_quantification": "Uses per-cohort standard errors and p-values, and inverse-variance weighting propagates these uncertainties into the combined estimate; confidence intervals are available from the workflow output (explicit numeric CI values not listed in the paper).",
            "fabrication_detection": "Not discussed.",
            "validation_cost_time": "No specific cost/time metrics; workflow is automated to reduce manual effort.",
            "hybrid_validation_approach": false,
            "validation_limitations": "Relies on availability of cohort-level summary stats; method-of-aggregation differences (e.g., meta-analyzing discovery cohorts first then adding replication cohorts vs pooling all cohorts) can produce small discrepancies.",
            "acceptance_credibility": "Replication of a published, high-profile meta-analysis is presented as evidence supporting the workflow's credibility to domain researchers.",
            "comparison_to_gold_standard": "Directly compared to Grasby et al. (ENIGMA) meta-analysis; outcomes are essentially concordant (qualitative agreement; no numeric error rate provided).",
            "uuid": "e2202.2"
        },
        {
            "name_short": "Meta-regression workflow",
            "name_full": "NeuroDISK meta-regression workflow (weighted regression of cohort effect sizes on moderators)",
            "brief_description": "A meta-regression meta-workflow that regresses per-cohort effect sizes (weighted by sample size or inverse variance) against cohort-level moderators (e.g., mean age) to test for moderator effects driving heterogeneity.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_or_method_name": "meta-regression workflow",
            "scientific_domain": "statistical genetics / meta-analysis",
            "validation_type": "computational validation",
            "validation_description": "Implements a weighted regression of cohort-level effect sizes on cohort covariates (mean age). Validation shown via meta-regression runs across increasing numbers of cohorts; outputs include scatterplots, regression beta and p-values. Demonstrated that with &gt;=40 cohorts the association reaches nominal significance (p≈0.02) but authors caution instability and need for more data.",
            "simulation_fidelity": null,
            "experimental_validation_performed": false,
            "comparison_simulation_vs_experiment": "No experimental benchmarks; comparison is across reruns with different cohort inclusion (subsampling/added cohorts) showing how p-values change.",
            "validation_success_rate": null,
            "domain_validation_standards": "Uses weighted regression practices common in meta-analysis and reports p-values and regression betas; authors treat multiple runs and convergence/stability across data additions as indicators of validation.",
            "when_simulation_sufficient": "Used to explore behavior of moderator detection under simulated incremental data addition; authors note simulation suffices to evaluate system update behavior but not to establish definitive scientific claims.",
            "simulation_failures": "Result instability reported (trend hovers around nominal threshold), indicating meta-regression results may fail to reach robust significance until more data are available.",
            "uncertainty_quantification": "Regression outputs include beta coefficients and p-values; cohort point sizes reflect sample size in plots; no formal heterogeneity metrics (e.g., I^2) are reported in the paper text for these specific runs.",
            "fabrication_detection": "Not discussed.",
            "validation_cost_time": "No quantitative costs provided.",
            "hybrid_validation_approach": false,
            "validation_limitations": "Moderator analyses depend on cohort-level covariate availability and adequate sample representation; authors warn that nominal significance is not necessarily stable and requires more data.",
            "acceptance_credibility": "Authors suggest that the ability to investigate moderators and show how effects change with added data enhances interpretability and trust, but emphasize cautious interpretation when results are borderline significant.",
            "comparison_to_gold_standard": "No direct comparison to alternative meta-regression tools; validation is internal (consistency across iterative data additions) rather than benchmarked against external gold standards.",
            "uuid": "e2202.3"
        },
        {
            "name_short": "Continuous-update simulation",
            "name_full": "Subsampling-based continuous-update simulation (simulating incremental cohort arrival)",
            "brief_description": "A low-fidelity simulation strategy used to emulate how NeuroDISK updates findings as new cohorts are added by subsampling cohort sets (10-&gt;20-&gt;30-&gt;40-&gt;48-&gt;49-&gt;50) and re-running LOIs to visualize evolution of p-values and effect estimates.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_or_method_name": "subsampling-based continuous-update simulation",
            "scientific_domain": "computational validation / software testing",
            "validation_type": "low-fidelity simulation",
            "validation_description": "Authors randomly subsampled the cohort list in increments (10, 20, 30, 40, 48), then added UK Biobank and an external ABCD cohort to simulate new data arrivals and re-ran meta-analysis/meta-regression workflows to track changes in statistics (e.g., -log10 p). This demonstrates system behavior under incremental data growth.",
            "simulation_fidelity": "Low-fidelity: resampling of existing cohort-level summary statistics; does not model biological mechanisms or measurement processes. No numerical fidelity metrics provided.",
            "experimental_validation_performed": false,
            "comparison_simulation_vs_experiment": "Simulation used for system-behavior validation only; not compared to physical experiments.",
            "validation_success_rate": null,
            "domain_validation_standards": "Used as a pragmatic test to show continuous update functionality rather than a domain-level validation standard.",
            "when_simulation_sufficient": "Sufficient to test software-level continuous update and to illustrate sensitivity of meta-analytic results to incremental cohort additions; insufficient to replace empirical validation of scientific hypotheses.",
            "simulation_failures": "No explicit failures of the simulation mechanism reported, but results showed unstable trends requiring more real data for conclusive findings.",
            "uncertainty_quantification": "Tracked p-values and -log10(p) across runs; no formal error bars reported for the simulation process itself.",
            "fabrication_detection": "Not applicable.",
            "validation_cost_time": "No cost/time data provided; simulation is computational and therefore relatively low-cost compared to real data collection.",
            "hybrid_validation_approach": false,
            "validation_limitations": "Artificial ordering/subsampling may not represent realistic cohort arrival patterns; does not account for differences in data quality or measurement heterogeneity beyond the available cohort metadata.",
            "acceptance_credibility": "Serves as demonstrative evidence that the system can continuously re-evaluate findings; authors caution about overinterpreting simulated trends without more data.",
            "comparison_to_gold_standard": "No comparison to other continuous-update simulation methods presented.",
            "uuid": "e2202.4"
        },
        {
            "name_short": "WINGS",
            "name_full": "WINGS (intelligent workflow system)",
            "brief_description": "An intelligent workflow system used by NeuroDISK to execute computational workflows and propagate semantic constraints, and to export provenance records used for explanation and replication.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_or_method_name": "WINGS workflow system",
            "scientific_domain": "computational workflows / reproducible computing",
            "validation_type": "computational validation",
            "validation_description": "WINGS enforces semantic constraints on inputs, sets workflow parameters appropriate for datasets, executes workflows, and exports provenance for DISK. Validation is operational: workflows executed through WINGS produced the meta-analytic outputs used for reproducing the ENIGMA results.",
            "simulation_fidelity": null,
            "experimental_validation_performed": false,
            "comparison_simulation_vs_experiment": null,
            "validation_success_rate": null,
            "domain_validation_standards": "WINGS' constraint propagation and provenance capture align with reproducibility best practices; used as the execution engine rather than a validation benchmark.",
            "when_simulation_sufficient": null,
            "simulation_failures": null,
            "uncertainty_quantification": "WINGS records provenance and outputs uncertainties produced by analyses but does not itself define uncertainty quantification.",
            "fabrication_detection": "Not discussed.",
            "validation_cost_time": "Not quantified.",
            "hybrid_validation_approach": null,
            "validation_limitations": "Depends on accurate semantic annotations and correct workflow models; not discussed in depth.",
            "acceptance_credibility": "Providing provenance exports and constraint-driven execution is presented as improving trust and reproducibility of computational analyses.",
            "comparison_to_gold_standard": "No direct comparison to other workflow engines in this paper.",
            "uuid": "e2202.5"
        },
        {
            "name_short": "Provenance & FAIR practices",
            "name_full": "Provenance capture and FAIR data/methods practices (RDF/OWL/SPARQL/PROV)",
            "brief_description": "Use of semantic web standards and provenance (RDF/OWL/SPARQL/PROV) and FAIR principles to describe datasets, question templates, and method provenance to support reproducibility and validation.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_or_method_name": "Provenance capture and FAIR metadata practices",
            "scientific_domain": "data management / reproducibility",
            "validation_type": "computational validation",
            "validation_description": "Datasets and questions are represented using RDF/OWL ontologies (SDO, DSO, SQO) and queries via SPARQL; provenance of workflow executions recorded with PROV. These artifacts are used to validate which data and methods were used and to generate explanations to support reproducibility.",
            "simulation_fidelity": null,
            "experimental_validation_performed": false,
            "comparison_simulation_vs_experiment": null,
            "validation_success_rate": null,
            "domain_validation_standards": "Aligns with community best practices (FAIR) for reproducibility; authors reference reproducibility literature and container-based replication.",
            "when_simulation_sufficient": null,
            "simulation_failures": null,
            "uncertainty_quantification": "Provenance records include the analytical outputs that contain uncertainty metrics (SE, p-values); provenance itself does not quantify uncertainty.",
            "fabrication_detection": "Not addressed directly; provenance is implied as a tool to make fabrication or alteration easier to detect but no methods are described.",
            "validation_cost_time": "Not quantified.",
            "hybrid_validation_approach": null,
            "validation_limitations": "Effectiveness depends on the completeness of metadata and honesty/completeness of provenance records; does not prevent misuse or misinterpretation of analyses.",
            "acceptance_credibility": "Authors argue that semantic provenance and FAIR metadata increase community acceptance by enabling re-execution, transparency, and method reuse.",
            "comparison_to_gold_standard": "No explicit numeric comparison to other provenance systems; approach is presented as consistent with community standards.",
            "uuid": "e2202.6"
        },
        {
            "name_short": "A-lab (Szymanski et al.)",
            "name_full": "A-lab (autonomous laboratory for solid-state synthesis)",
            "brief_description": "Mentioned as a related example where AI, machine learning, and robotics are combined to propose, optimize, and physically execute materials synthesis experiments.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_or_method_name": "A-lab (autonomous lab integrating LLMs, ML, and robotics)",
            "scientific_domain": "materials science / experimental chemistry (related work mention)",
            "validation_type": "hybrid",
            "validation_description": "Paper cites A-lab as an example of an autonomous system that uses LLMs to propose experiments, ML to optimize, and a robotic platform to execute experiments, implying experimental validation is performed in that system; NeuroDISK references this work only in related-work context and does not use it.",
            "simulation_fidelity": null,
            "experimental_validation_performed": null,
            "comparison_simulation_vs_experiment": null,
            "validation_success_rate": null,
            "domain_validation_standards": null,
            "when_simulation_sufficient": null,
            "simulation_failures": null,
            "uncertainty_quantification": null,
            "fabrication_detection": null,
            "validation_cost_time": null,
            "hybrid_validation_approach": null,
            "validation_limitations": null,
            "acceptance_credibility": "Mentioned as demonstrating advances in automation that include experimental execution, but NeuroDISK does not evaluate A-lab's validation results.",
            "comparison_to_gold_standard": null,
            "uuid": "e2202.7"
        },
        {
            "name_short": "Pyzer-Knapp prototype",
            "name_full": "AI prototype for materials discovery with simulators and robotic chemistry platforms (Pyzer-Knapp et al.)",
            "brief_description": "Referenced related work combining literature extraction, simulation-based optimization, and robotic execution for materials discovery; cited as an example where computational/simulation and experimental components are combined.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_or_method_name": "AI + simulators + robotic chemistry platform (prototype)",
            "scientific_domain": "materials science / computational materials discovery (related work mention)",
            "validation_type": "hybrid",
            "validation_description": "Mentioned as performing simulation-driven optimization followed by robotic experimental execution in the related-work discussion; NeuroDISK only cites this work and does not use it.",
            "simulation_fidelity": null,
            "experimental_validation_performed": null,
            "comparison_simulation_vs_experiment": null,
            "validation_success_rate": null,
            "domain_validation_standards": null,
            "when_simulation_sufficient": null,
            "simulation_failures": null,
            "uncertainty_quantification": null,
            "fabrication_detection": null,
            "validation_cost_time": null,
            "hybrid_validation_approach": null,
            "validation_limitations": null,
            "acceptance_credibility": null,
            "comparison_to_gold_standard": null,
            "uuid": "e2202.8"
        },
        {
            "name_short": "Coscientist",
            "name_full": "Coscientist (AI system designing and planning chemical reaction experiments)",
            "brief_description": "Cited as a proof-of-concept system that designs and plans chemical experiments and generates code for execution in cloud laboratories, illustrating AI-assisted experimental planning.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_or_method_name": "Coscientist (LLM-based experiment planner)",
            "scientific_domain": "chemistry / automated experimentation (related work mention)",
            "validation_type": "other",
            "validation_description": "Included in related work to illustrate AI-driven experiment planning; NeuroDISK does not use or validate Coscientist. The paper notes that such systems can generate executable protocols but that results may not be guaranteed correct.",
            "simulation_fidelity": null,
            "experimental_validation_performed": null,
            "comparison_simulation_vs_experiment": null,
            "validation_success_rate": null,
            "domain_validation_standards": null,
            "when_simulation_sufficient": null,
            "simulation_failures": null,
            "uncertainty_quantification": null,
            "fabrication_detection": null,
            "validation_cost_time": null,
            "hybrid_validation_approach": null,
            "validation_limitations": null,
            "acceptance_credibility": null,
            "comparison_to_gold_standard": null,
            "uuid": "e2202.9"
        },
        {
            "name_short": "XLuminA (Rodríguez et al.)",
            "name_full": "XLuminA (automated experimental design for super-resolution microscopy)",
            "brief_description": "Mentioned related work that automates experimental design for microscopy using AI to accelerate experimental optimization compared to traditional numerical optimization.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_or_method_name": "XLuminA (AI-driven experimental design)",
            "scientific_domain": "microscopy / experimental imaging (related work mention)",
            "validation_type": "hybrid",
            "validation_description": "Cited as evidence that AI can accelerate experimental design and execution in laboratory settings; NeuroDISK references this work in context but does not use it.",
            "simulation_fidelity": null,
            "experimental_validation_performed": null,
            "comparison_simulation_vs_experiment": null,
            "validation_success_rate": null,
            "domain_validation_standards": null,
            "when_simulation_sufficient": null,
            "simulation_failures": null,
            "uncertainty_quantification": null,
            "fabrication_detection": null,
            "validation_cost_time": null,
            "hybrid_validation_approach": null,
            "validation_limitations": null,
            "acceptance_credibility": null,
            "comparison_to_gold_standard": null,
            "uuid": "e2202.10"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "The genetic architecture of the human cerebral cortex",
            "rating": 2
        },
        {
            "paper_title": "An autonomous laboratory for the accelerated synthesis of novel materials",
            "rating": 2
        },
        {
            "paper_title": "Accelerating materials discovery using artificial intelligence, high performance computing and robotics",
            "rating": 2
        },
        {
            "paper_title": "Autonomous chemical research with large language models",
            "rating": 2
        },
        {
            "paper_title": "Automated discovery of experimental designs in super-resolution microscopy with XLuminA",
            "rating": 2
        },
        {
            "paper_title": "Conceptual understanding through efficient automated design of quantum optical experiments",
            "rating": 2
        },
        {
            "paper_title": "Neurodesk: an accessible, flexible and portable data analysis environment for reproducible neuroimaging",
            "rating": 1
        },
        {
            "paper_title": "Towards Automated Hypothesis Testing in Neuroscience",
            "rating": 1
        }
    ],
    "cost": 0.0212795,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>NeuroDISK: An AI Approach to Automate Continuous Inquiry-Driven Discoveries in Neuroimaging Genetics</p>
<p>Daniel Garijo 
Information Sciences Institute
Marina del Rey
University of Southern California
CaliforniaUSA</p>
<p>Ontology Engineering Group
Universidad Politécnica de Madrid
MadridSpain</p>
<p>Qifan Yang qifan.yang@usc.edu 
Mark and Mary Stevens Neuroimaging and Informatics Institute
Marina del Rey
Laboratory of Brain eScience
Keck School of Medicine of USC
University of Southern California
CaliforniaUnited States</p>
<p>Hernán Vargas hvargas@isi.edu 
Information Sciences Institute
Marina del Rey
University of Southern California
CaliforniaUSA</p>
<p>Shruti P Gadewar gadewar@usc.edu 
Mark and Mary Stevens Neuroimaging and Informatics Institute
Marina del Rey
Laboratory of Brain eScience
Keck School of Medicine of USC
University of Southern California
CaliforniaUnited States</p>
<p>Kevin Low kevinlow@usc.edu 
Mark and Mary Stevens Neuroimaging and Informatics Institute
Marina del Rey
Laboratory of Brain eScience
Keck School of Medicine of USC
University of Southern California
CaliforniaUnited States</p>
<p>Varun Ratnakar varunr@isi.edu 
Information Sciences Institute
Marina del Rey
University of Southern California
CaliforniaUSA</p>
<p>Maximiliano Osorio mosorio@isi.edu 
Information Sciences Institute
Marina del Rey
University of Southern California
CaliforniaUSA</p>
<p>Alyssa H Zhu alyssahz@usc.edu 
Mark and Mary Stevens Neuroimaging and Informatics Institute
Marina del Rey
Laboratory of Brain eScience
Keck School of Medicine of USC
University of Southern California
CaliforniaUnited States</p>
<p>Department of Biomedical Engineering
Viterbi School of Engineering
Marina del Rey
University of Southern California
CaliforniaUSA</p>
<p>Agnes Mcmahon maryagnesmcmahon@gmail.com 
Mark and Mary Stevens Neuroimaging and Informatics Institute
Marina del Rey
Laboratory of Brain eScience
Keck School of Medicine of USC
University of Southern California
CaliforniaUnited States</p>
<p>PhDYolanda Gil gil@isi.edu 
Information Sciences Institute
Marina del Rey
University of Southern California
CaliforniaUSA</p>
<p>PhDNeda Jahanshad neda.jahanshad@usc.edu 
Mark and Mary Stevens Neuroimaging and Informatics Institute
Marina del Rey
Laboratory of Brain eScience
Keck School of Medicine of USC
University of Southern California
CaliforniaUnited States</p>
<p>Department of Neurology
Marina del Rey
Keck School of Medicine of USC
University of Southern California
CaliforniaUSA</p>
<p>Department of Biomedical Engineering
Viterbi School of Engineering
Marina del Rey
University of Southern California
CaliforniaUSA</p>
<p>Computer Science Director
USC Center on AI Research for Health Director of AI and Data Science Initiatives Information Sciences Institute Viterbi School of Engineering University of Southern California
4676 Admiralty Way Suite 1001 Marina del Rey90292CA</p>
<p>Neurology and Biomedical Engineering Information Sciences Institute Director
LoBeS: Laboratory of Brain eScience Associate Director
ENIGMA Consortium Imaging Genetics Center Stevens Neuroimaging &amp; Informatics Institute Keck School of Medicine of USC University of Southern California
4676 Admiralty Way Suite 200 Marina del Rey90292CA</p>
<p>NeuroDISK: An AI Approach to Automate Continuous Inquiry-Driven Discoveries in Neuroimaging Genetics
943E5029FE08B858312932289103EA5410.1101/2025.02.14.638360
Collaborative and multi-site neuroimaging studies have greatly accelerated the rate at which new and existing data can be aggregated to answer a neuroscientific question.New research initiatives are continuously collecting more data, allowing opportunities to refine previous published findings through continuous and dynamic updates.Yet, we lack a practical framework for researchers to systematically, automatically, and continuously update published findings.We developed NeuroDISK, an automated artificial intelligence based framework that: 1) performs automated and inquiry-driven analyses, and 2) continuously updates these analyses as new data becomes available.NeuroDISK was evaluated using published results from the ENIGMA consortium's work on the genetic architecture of the cerebral cortex.We incorporate both meta-analysis and meta-regression options to showcase our framework on the effect of specific genotypes and moderators on select brain regions.Initial NeuroDISK meta-analysis results replicate the original publication, and we show result updates after adding new data.The NeuroDISK framework can be generalized for users to define question(s), run corresponding workflow(s) and access results interactively and continuously.</p>
<p>Introduction</p>
<p>Sample sizes for studies involving human subjects are often limited by the costs of collecting data.Unfortunately, in these studies, variables of interest that have small to moderate effect sizes have been particularly susceptible to spurious findings that do not replicate.Recent efforts have recognized these concerns in neuroimaging-heavy fields of psychological and neurological sciences (Button et al., 2013), (Boekel et al., 2015), (Bowring et al., 2019), (Poldrack et al., 2020), (Hodge et al., 2020), and even more specifically, neuroimaging genetics (Medland et al., 2014;Smith &amp; Nichols, 2018).A driving factor in this reproducibility and replication crisis has been a lack of sufficiently well-powered studies, (Button et al., 2013;Ioannidis, 2005) so larger scale efforts are of growing interest.</p>
<p>Merging data from multiple sources has paved a way for larger sample sizes and reproducible findings.Individual multi-site studies such as the disorder-specific Alzheimer's Disease Neuroimaging Initiative (ADNI) (Weiner et al., 2010) and the population-based UK Biobank (Miller et al., 2016) have aimed to collect both neuroimaging and genetic data across individuals from multiple locations for larger and more efficient data collection efforts.Multi-study consortia such as the Enhancing NeuroImaging Genetics through Meta Analysis (ENIGMA) consortium (Thompson et al., 2020) have also been established to coordinate analyses and pool data across tens of thousands of brain imaging datasets from hundreds of independent studies around the world.ENIGMA has over 35 active working groups with targeted clinical, biological or methodological interests.These working groups, including one dedicated to neuroimaging genetics, pool data from independent existing studies from around the world.Consortia that are built on existing and available data resources not only ensure large sample sizes for well-powered analyses, but also include diverse samples and heterogeneous study designs to allow for robust and generalizable findings.Multi-study efforts in ENIGMA ensure adequate sample sizes for genome-wide association studies (GWAS) on brain imaging derived traits (Medland et al., 2022) and have led to the identification of numerous genetic variants that influence brain structure through some of the largest studies to date.</p>
<p>Figure 1: As more and more data become available for collaborative efforts, including neuroimaging genetics studies, a hypothesis can be tested with more data to increase confidence.In the above graphic, we show the evolution of results related to the genetic associations with MRI-derived hippocampal volume.The most significant genetic association with hippocampal volume in the first ENIGMA consortium study (ENIGMA1) (Stein et al., 2012), which performed a genome-wide association study (GWAS) meta-analysis of the hippocampus and the brain's intracranial volume with data for almost 8,000 individuals across 17 cohorts, was in a locus on chromosome 12.In the second ENIGMA GWAS (ENIGMA2) (Hibar et al., 2015), which evaluated hippocampal volume along with 6 other structures in a pooled sample of over 13,000 individuals from 28 cohorts, the same locus (middle panel) emerged as significant with greater confidence (smaller p-value).When the results of ENIGMA2 were then meta-analyzed with those from the CHARGE consortium in an extended analysis of 9 subcortical structures using a total sample of over 26,000 individuals from 46 discovery cohorts (ENIGMA+CHARGE) (Satizabal et al., 2019), again the same genetic locus showed significant association with the hippocampal volume with greater confidence.The thickness of the red circle indicates the strength of the association, highlighting the greater significance as the dataset is expanded (bottom to top).Specifically, blue points reflect the ENIGMA1 study from 2012 (Stein et al., 2012); yellow points correspond to the ENIGMA2 study from 2015 (Hibar et al., 2015), and burgundy points represent the ENIGMA+CHARGE joint analysis from 2017 (Hibar et al., 2017) (thickest red circle).We show the extent to which the significance changed from study to study.The same locus was then separately shown to be significant in independent data from over 8,000 individuals in the UK Biobank dataset (Elliott et al., 2018), which had not been used in any of the initial three ENIGMA or ENIGMA-CHARGE publications.</p>
<p>As ENIGMA studies are being conducted, new neuroimaging genetics initiatives and new studies with relevant data continue to be funded and collected.These efforts may eventually be incorporated into other mutli-site and multi-study initiatives, further empowering larger and more representative studies.For example, in 2012 a multi-study GWAS of hippocampal volume was published by the ENIGMA consortium (Stein et al., 2012).Interest soon grew in the consortium, and a follow up study that again included a GWAS of the hippocampal volume was conducted with nearly twice the sample size (Hibar et al., 2015).The same inquiry was then posed jointly by ENIGMA and another multi-study consortium, CHARGE (Cohorts for Heart and Aging Research in Genomic Epidemiology), more than doubling the sample size once again (Satizabal et al., 2019).These studies have iteratively shown the progression of insights into the genetic architecture of regional brain volumes, including that of the increasing confidence in the effect of a genetic locus on chromosome 12 on the volume of the hippocampus (Figure 1).This was the only locus to show a genome-wide significant effect in the first analysis, and confidence of this finding only grew in subsequent analyses.The evolution of scientific knowledge is captured by repeatedly making the same inquiry, yet with more or different data.Artificial intelligence (AI) systems that can automatically generate these updates as more data become available, with minimal human intervention, can greatly facilitate research efficiency and accelerate scientific advances.</p>
<p>These AI systems would conduct continuous monitoring to detect new data and re-execute analyses to update findings.Intelligent automation can further be used to interrogate the data as more and more of the population becomes represented in the available data.For example, if the support for an association becomes stronger or weaker once more data is added and the sample becomes more diverse, an intelligent system may be able to identify aspects of the populations that were driving the changes in the association strength.We have previously found that the mean age of a study's participants may drive key associations between neuroimaging and genetic markers, including the association between hippocampal volume and one of the strongest genetic risk factors for Alzheimer's disease and related dementias (Brouwer et al., 2022;Garijo et al., 2019); here associations were only identified in cohorts, or datasets, of studies where the average age was over 60 years.</p>
<p>This work presents a two-fold AI approach to: 1) perform automated and inquiry-driven analyses, and 2) continuously update these analyses as new data becomes available.We have designed and implemented NeuroDISK, an AI system built on the DISK framework for assessing hypotheses evolution.(Garijo et al., 2017;Gil et al., 2016) NeuroDISK currently focuses on queries using a pilot set of neuroimaging genetics tasks given a structured data ontology and specific analytical workflows with added constraint reasoning.</p>
<p>Our work demonstrates automation of inquiry-driven data analysis in science, demonstrating that AI can reason about data and methods to automate this process for neuroimaging.AI has been investigated for a long time to automate data analysis and discovery processes in other fields of science (Bradshaw, Gary L., Zytkow, Jan M., 1988).Recent work uses workflows and reasoning to create automated machine learning systems (De Bie et al., 2022) and automated statisticians (Steinruecken et al., 2019).Other work has investigated the use of AI-based algorithms to accelerate experiment design and other scientific tasks.Rodriguez and colleagues (Rodríguez et al., 2024) demonstrate the use of AI to accelerate optical microscopy experiments over traditional numerical optimization techniques.Krenn and colleagues (Krenn et al., 2021) describe Theseus, a system that automates the design of quantum optics experiments based on a graph of known experiments.Furthermore, Erps and colleagues (Erps et al., 2021) describe an approach to automate the experimental design of formulations for mixed polymer formulations for additive manufacturing through multiobjective optimization.</p>
<p>AI automation of science processes has led to many advances in chemistry and materials science.In addition to the design and planning of experiments, there are approaches that add an execution component through AI and robotics (Angelopoulos et al., 2024).For example, Szymanski and team (Szymanski et al., 2023) introduce A-lab, a system to synthesize novel materials, specifically solid-state synthesis of inorganic powders.A-lab uses LLMs to propose new experiments, machine learning to optimize them, and a robotic platform to execute them.Pyzer-Knapp and colleagues (Pyzer-Knapp et al., 2022) describe an AI prototype for materials discovery, including natural language tools to extract information from the literature, simulators to optimize molecule choices, and a robotic chemistry platform to execute the experiments.</p>
<p>The use of large language models can accelerate research tasks, from literature search to code generation.For example, Coscientist (Boiko et al., 2023) was developed as a proof-of-concept system that designs and plans Suzuki and Sonogashira chemical reaction experiments and generates code that can be executed in cloud laboratories.In other work, Lu and colleagues (Lu et al., 2024) describe a system that uses large language models to generate ideas for papers, design the experiment, find the data and code needed to execute the experiment, and then write the article.The articles generated are useful for exploring new ideas and their feasibility, however the articles are not guaranteed to contain correct statements.</p>
<p>Related work in neuroimaging has focused on reproducibility of data analysis.This includes using software containers to ensure accurate replication (Renton et al., 2024), articulating requirements for data repositories to support reproducibility (Wagner et al., 2022), and infrastructure to access and integrate data and tools (Poline et al., 2023).Our work builds on these kinds of efforts by assuming the data and tools are shared, and extends them to demonstrate the use of AI to automate neuroimaging analyses.</p>
<p>We demonstrate the value of NeuroDISK by using and building on published data from the large-scale multi-study GWAS meta-analysis of MRI-derived cortical structure (Grasby et al., 2020).We catalog the published data and meta-data from all cohort studies that contributed to that work, and automate the statistical meta-analysis to demonstrate a successful replication of the available original findings.NeuroDISK then identifies newly cataloged data that match the requirements for the specific neuroimaging genetic inquiry and incorporates it into the analysis, ultimately updating the findings of the original paper.We further demonstrate the capabilities of NeuroDISK by asking additional questions about the data beyond what was originally proposed; in this demonstration, we inquire whether study specific effects are driven by particular aspects of the study cohort, in particular, mean age.</p>
<p>The contributions of this paper include:</p>
<p>1.A new AI approach to scientific problem solving designed to capture the strategies that a scientist follows to answer a question or test a hypothesis, including finding data, analyzing it, and extracting findings.2. A novel concept of lines of inquiry that can automate hypothesis-driven discovery processes using AI knowledge representation and reasoning techniques that include ontologies, constraint reasoning, and workflows.</p>
<ol>
<li>An implementation of this approach in NeuroDISK, an extension of the general domain-independent DISK framework (Gil et al., 2017), is extended with hypothesis ontologies and lines of inquiry for multi-site neuroimaging genetics.4. A demonstration of this framework as a reproduction of a published paper, with explicit questions and hypotheses driving the system, and an extension of the published results to demonstrate its use for continuous updates.</li>
</ol>
<p>In the following sections, we motivate the requirements for achieving the desired capabilities of automation and continuous updates, and describe the approach and its implementation.</p>
<p>Methods and Materials</p>
<p>NeuroDISK is designed to mimic how human scientists pursue a scientific question or hypothesis.Generally scientists pose questions or hypotheses and consider different approaches to answer their questions, which typically involve finding relevant data, and identifying appropriate analytical methods.For example, if MRI data is available it would be analyzed using computational imaging methods, while genomics data would be analyzed using genomics workflows.Finally, the results would be consolidated and placed in context.</p>
<p>NeuroDISK demonstrates how to automate this inquiry-driven discovery process for neuroimaging genomics.NeuroDISK uses AI representations and reasoning to test and revise hypotheses based on automatic analysis of scientific data repositories that grow over time (Figure 2).Two key features of NeuroDISK are: 1) Inquiry-driven automated analysis: Given an input hypothesis or scientific question, NeuroDISK is able to automatically search for relevant data in shared repositories and apply appropriate methods to test it; 2) Continuous automated updates of findings: NeuroDISK checks if new data becomes available so it can reconsider prior analyses and revise its findings.NeuroDISK is designed to automate the processes that scientists follow to answer questions using existing datasets.A scientific question (1) is mapped into a structured form that is machine-readable (2) that enables NeuroDISK to select a general approach (3) to answer that question.The approach typically involves formulating a query that will access existing data sources to find relevant datasets (4), setting up and running analyses for the data available (5), consolidating the results for different datasets (6), and explaining (7) and presenting (8) the findings.</p>
<p>When new data become available (9), NeuroDISK revisits the original question and re-runs its analyses so that the findings can be updated (10).</p>
<p>Scientific methods as lines of inquiry</p>
<p>NeuroDISK uses a line of inquiry (LOI) to represent the approach that a scientist would follow to pursue a general type of question in their discipline, including steps to get data from a shared data source and to analyze it with computational workflows (Figure 3).An LOI has several key components:</p>
<p>• Hypothesis or question template: a general question containing variables that are matched against the specific question posed by a scientist.</p>
<p>• Data query template: indicates how a data source should be queried in order to obtain data that is relevant to the question.The data query template includes the variables that appear in the question template, as well as additional variables that characterize the data requirements in detail for the approach being pursued.• Workflows: specify the multi-step methods to be used to analyze the data retrieved.The workflows use variables to indicate how to take the data retrieved as input.Workflows also represent the computational steps of the analysis method.</p>
<p>• Meta-workflows: specify the meta-method to combine results from multiple analyses (i.e., multiple workflow executions) in order to derive an answer to the user's question.Meta-workflows combine results from other workflows and may generate overall statistics such as an effect size, confidence interval, p-value, or a refinement of the original question or hypothesis, as well as visualizations of results and findings.</p>
<p>The individual LOI components are described in more detail in this section.</p>
<p>Figure 3 illustrates the main components of an LOI for investigating if the effect size of a particular genotype on a specific brain region is associated with a demographic attribute of the cohorts, while allowing the cohorts to be filtered by another attribute (in this case genetic ancestry).This process is a meta-regression on the effect sizes of the individual cohorts retrieved from the data sources.</p>
<p>NeuroDISK captures knowledge in machine-readable representations that use Semantic Web standards, in particular the W3C Resource Description Framework (RDF)(RDF 1.1 Concepts and Abstract Syntax), the W3C Web Ontology Language (OWL) (Dean &amp; McGuinness), and the W3C Semantic Protocol and RDF Query Language (SPARQL) (Harris et al., 2013).</p>
<p>Specifying inquiries: hypotheses and questions</p>
<p>NeuroDISK is an inquiry-driven system that expects users to provide a structured hypothesis or scientific question that will drive its reasoning and data analysis.Users are guided through pre-defined question templates and select one to specify an inquiry in a structured, machine-readable representation.Once that selection is made, the user's question is matched against the query template of the available LOIs, which will trigger an appropriate one.(2) a question template that will be matched against the user's question; (3) a data query template that specifies how to retrieve data that is relevant to answering the question; (4) workflows that specify how to analyze the data retrieved; and (5) meta-workflows that indicate how to combine the results of all the workflows executions.In this example, an LOI is set up to investigate if the effect size of a particular genotype on a specific brain region is associated with a demographic attribute of the cohorts, while allowing the cohorts to be filtered by another attribute (in this case genetic ancestry).This process is a meta-regression on the effect sizes of the individual cohorts retrieved from the data sources.</p>
<p>As our running example, we use results published as part of the 2020 ENIGMA cortical structure GWAS paper (Grasby et al., 2020).The paper, among its top findings, found an association between the genetic variant rs108066 on the surface area of the precentral gyrus after meta analyzing genome-wide association results from 48 discovery cohorts of individuals of European ancestry, replicated the findings in the UK Biobank, and generalized the findings in datasets of non-European individuals.We use this particular finding (i.e., the genetic variant association with regional brain area) as our running example.Using this example, we continue to build on the result by including independent data and formulate a novel scientific question to be asked of the available data.The novel question presented in NeuroDISK is to use available meta-data and individual cohort results to determine whether the strength of the particular genetic variant's (rs108066) association with the specific regional brain metric (surface area of the precentral cortex) is associated with a demographic property of the cohorts (the mean age); we further allow filtering of the cohorts by specific properties (genetic ancestry).The user would start by selecting from a set of question templates.In this example, they would select: "Is the effect size of «Genotype» in «Brain Imaging Trait» of «Region» associated with «Demographic Attribute» for cohorts of «Genetic Ancestry»?", with the brackets indicating variables.Then the user would be offered choices to select the desired variable values.The result would be the user question.</p>
<p>Question templates are expressed as a machine-readable question pattern that consists of RDF triples of the form {subject predicate object}.For our running example, this would be an RDF triple in a question pattern:</p>
<p>effectSize isAssociatedWith DemographicAttribute</p>
<p>To specify question patterns, we follow a principled approach by using a Scientific Questions Ontology (SQO) that organizes question templates and variables (Garijo et al., 2023).This allows us to relate different scientific questions and to connect the user questions to LOIs.The SQO ontology is extended to create a Scientific Domain Ontology (SDO) with additional terms from any new domain that can be used to specify question variables and choices.The data source also uses a metadata ontology to describe datasets, which we refer to as the Data Source Ontology (DSO).DSO should be designed to extend SDO, or at least should be well mapped to it in order to support the specification of the data queries needed to support the anticipated user queries.In NeuroDISK, the SDO is the SDO-ENIGMA ontology and the DSO is the Organic Data Science (ODS)-ENIGMA ontology, which will be described in detail in Section 2.3.</p>
<p>Figure 4 illustrates the key concepts in the SQO and how they are used to create questions in the SDO in NeuroDISK.We describe these SQO concepts first and then provide examples.Key SQO concepts include:</p>
<p>• Question Category which helps organize all the question templates into broad types of scientific inquiries such as association, counterfactual, prediction, etc. • Question: The class of user questions.Each question class includes:</p>
<p>○ A Template, which consists of a text in natural language containing slots for question variables to be specified by a user.○ Variables that are filled by the user to express their question.In the example above, a variable can be the demographic which can be used to express user questions about age.○ Constraints, which are logical expressions that represent the valid combinations of variable values.These are used to ensure that candidate questions make scientific sense.○ A Pattern, which is a collection of RDF triples that combines the pattern fragments for all the question variables as described below.• Question Variable: Each question variable is represented by: ○ Variable Name:Denotes the name of the variable, e.g «Demographic» ○ Option: Indicates the values that the question variables can take.The possible values can be indicated in several ways: ■ Static options: A list of options pre-defined on the SDO.In our running example, the SDO-ENIGMA ontology has a variable «BrainImagingTrait» that has options 'Surface Area', 'Thickness', etc. ■ Dynamic options: A list of options generated at run time by querying the data source, which would return terms from DSO.This query will use the question's Constraints.For example, to generate options for a «Region» variable, the DSO for the data source would return the brain regions that are covered in the datasets available, such as the cortical regions used in this work: 'Precentral', 'Insula', etc. ■ User input options: Allows the user to specify new variable values directly through the user interface as free form input. Users can only do this if they are very familiar with the domain and the datasets.○ Min/max Cardinality: Minimum/maximum number of options that can be selected by the user for the variable.By default each variable accepts and requires only one option (cardinality of 1).○ Pattern Fragment: The semantic expression (RDF triple) about this particular question variable, and that is part of the question pattern for a question.</p>
<p>Question patterns are expressed as a set of triples using terms from the SQO as well as the SDO.For our running example, the question template has the following question pattern: Each LOI has an LOI question template expressed similarly as the user question templates above.The LOI question pattern of each LOI is matched against the user question pattern through logical unification (Baader &amp; Ghilardi, 2010).All LOIs that match are triggered and their methods are executed.The user's question variables set up the LOI to find data and run computational workflows, as we describe in Section 2.4.</p>
<p>The question templates currently defined in NeuroDISK for investigating questions about the brain with neuroimaging genomics data in ENIGMA are:</p>
<p>• What is the effect size of «Genotype» on «Region» «Brain Imaging Trait»?</p>
<p>• Is the effect size of «Genotype» on «Brain Imaging Trait» of «Region» associated with «Demographic Attribute»?</p>
<p>We have also implemented the same questions with the addition of a filter, in this case filtering by specific ancestry labels of the cohorts:</p>
<p>• What is the effect size of «Genotype» on «Brain Imaging Trait» of «Region» for cohorts of «Genetic Ancestry»?• Is the effect size of «Genotype» on «Brain Imaging Trait» of «Region» associated with «Demographic Attribute» for cohorts of «Genetic Ancestry»?</p>
<p>These question templates can be generalized further.For example we used genetic ancestry as a filtering criterion to replicate the discovery analysis of the original paper.However, the ontology can be easily extended to support other demographic characteristics or cohort level meta-data, for example, filtering by cohorts that use MRIs with a particular magnetic field strength or a particular genotyping chip.</p>
<p>Figure 5 illustrates how users specify their questions in the NeuroDISK user interface and the question pattern that results from it.Users do not need to be familiar with the ontologies or the structure of the data repository to pose their questions to NeuroDISK.Note that the genetic ancestry options are dynamically obtained from the data source and come from ODS-ENIGMA.</p>
<p>NeuroDISK can be extended with new question patterns and associated LOIs by users with advanced knowledge about the NeuroDISK framework.Section 2.8 discusses different types of users and their interactions with NeuroDISK.</p>
<p>Organizing datasets through ontologies</p>
<p>Before we show how LOIs are triggered and executed, we describe in more detail how the ontologies are used to describe the datasets in the data sources queried by NeuroDISK.</p>
<p>The data should be described with semantic metadata that is rich enough to capture the terms that a scientist would use to identify what data they would consider relevant to a question or hypothesis.Many data sources have semantic annotations, using metadata vocabularies to describe characteristics of the data.In the case of NeuroDISK, the data source represents the available information from clinical research studies that collect data from a cohort of participants according to a specific study design with some inclusion/exclusion criteria, for example age range or clinical diagnosis.The inclusion criteria and other characteristics of the participants and the study design may be important for the user's question.This description of the datasets is often obtained through semantic metadata, defined as part of one of several ontologies.and the W3C semantic standard PROV (Gil et al., 2012) for provenance recording.</p>
<p>In the ODS-ENIGMA ontology, a central concept is a Working Group that represents how several organizations in the ENIGMA consortium work together to analyze datasets on a particular topic of common interest.Each working group uses multiple Cohorts (defined as data from the set of participants who participated in a specific research study collected and maintained by a particular set of investigators); select data from these cohorts have been contributed by the working group members for collaborative analyses and projects, such as for the ENIGMA Cortical GWAS project.</p>
<p>Metadata about cohorts include the Principal Investigator, any Covariates, and Brain Scan Data Type, as well as relevant aspects of data collection, design type, and other statistical information such as the mean age of participants.Cohorts can also include subsets of the entire cohort to better define the data contributed to an individual project, or to better define different inclusion and exclusion criteria used in the same study (for different sets of participants).</p>
<p>Each working group organizes its members to collaborate in one or more Projects.A project uses data and information from multiple cohorts contributed by the collaborators.For example, the ENIGMA Cortical GWAS Project involves multiple cohorts and their associated data properties for the GWAS analysis of cortical measures.A cohort can be used in multiple projects and multiple working groups, but does not need to participate in all projects within any one group.</p>
<p>A project often uses the subset of a cohort that meets specific inclusion criteria, called a Cohort Group.A cohort can have multiple cohort groups, each with specific inclusion and/or exclusion criteria that defines them.For example, a cohort group may be the subset of a cohort considered "controls" or those without any neurological or psychiatric conditions.This distinction helps describe the different assessments that may be applied to particular subsets of the cohort; for example, "controls" may not have been asked to fill out questionnaires regarding medication use or have follow-up data, whereas the subset of individuals with a diagnosis of interest would have that information.A Cohort Project Group would then be considered the subset of the cohort group included for a particular project that meet all project inclusion criteria and pass quality control, such that exact statistics on included participants can be retained (e.g., N= 117, mean age=39.5).This can also be extended for different analyses within a project.</p>
<p>This representation for projects has the ability to capture provenance by maintaining descriptions of the cohort specifics that were used in a project at a specific point in time.This system allows for conserving cohort versions that were undertaken under certain cohort conditions.For example, the cohort ABCD can have a cohort project ABCD_proj_ENIGMA3_Cortical_GWAS, which contains all baseline cohort information available at the time of, and relevant to, the ENIGMA3 Cortical GWAS project.As more information is added to ABCD (such as new participants, covariates, assessments, etc.), this original Cohort Project remains untouched for its associated analyses.This makes documentation for past studies readily accessible.</p>
<p>To retrieve datasets described with this vocabulary, we express the queries using the W3C SPARQL semantic query standard.(Harris et al., 2013) For example, the following statements are used to create the query to retrieve all cohorts and their respective cohort projects and types of brain scans:</p>
<p>?cohort a ods-e:Cohort ?cohort ods-e:HasCohortProject ?cohortProject ?cohort ods-e:HasBrainScanDataType ?ScanDataType</p>
<p>The ODS-ENIGMA ontology is modular and composed of several smaller ontologies.Table 1 gives an overview of these ontologies, which are documented online https://w3id.org/enigma.The data query will be used to retrieve datasets from the data source that are relevant to a user's question.</p>
<p>Finding data</p>
<p>Once a LOI is matched with a user's question, the variables in the question are used to set up the LOI.The first step is to set up the data query to send to the data source in order to retrieve relevant datasets.Recall that the LOI has a data query template.To set up the LOI data query, LOIs have pre-defined LOI variable mappings between the LOI question template and the LOI data query template through their variables (Figure 7).</p>
<p>The LOI data query template has many variables that reflect how the data source is organized.</p>
<p>In the case of ENIGMA, datasets are contributed by members who participate in ENIGMA working groups, where each member contributes data collected in their own clinical studies.Analogous to user questions and LOI questions, LOI data query templates have a data query pattern as a collection of triples that express the characteristics of the datasets sought.The LOI variable mappings are used to incorporate the variable choices in the user question pattern into the LOI data query pattern to form the data query issued to the data source.</p>
<p>Figure 8 shows the data query in SPARQL for our running example, highlighting the LOI variable mappings that appeared in Figure 7.</p>
<p>Once the data query is executed, the data source returns several datasets.The LOI indicates which variables in the LOI data query template would be useful for a user to see about those datasets.Figure 9 shows the results of the data query for the running example.</p>
<p>Analyzing data</p>
<p>NeuroDISK LOIs can analyze data in two stages: analysis and meta-analysis.Analysis typically refers to a method applied to a particular study (i.e, cohort).Meta-analysis typically refers to consolidating the results from individual analyses.This is done because the data within a study is often analyzed on site for privacy reasons.We represent them as workflows and meta-workflows respectively.</p>
<p>Workflows specify the steps and data dependencies needed to carry out a computational analysis, while meta-workflows capture the steps to aggregate the results from one or multiple workflows.When the execution of a workflow is completed, the provenance of all workflow execution results is captured, including the input and intermediate datasets as well as the software components used.Meta-workflows have access to all the outputs generated by the workflows, as well as to all the datasets retrieved by the LOI data query in case they are needed for the meta-analysis.(3) those variables are used to set up a query to retrieve relevant data; (4) the data is then analyzed with workflows; and (5) the LOI is re-executed every time that additional data is retrieved from the data source, and the user can see how the results change.On the left is the user's view of the hypothesis and the results over time.In this case we show the -log10 of the p-value against the iterations, and overall highlight smaller p-values or an increase in confidence (higher points on the plot) with added data points.Users can ask for details on each run, and can request to see the LOI as shown on the right.</p>
<p>ENIGMA working groups often have projects that conduct meta-analysis, as individual subject information may not always be sharable.In this case, a statistical analysis such as a genome-wide association study (GWAS) is carried out locally at each of the sites that has stewardship over its own data, and only summary results are shared for meta-analysis.For our running example based on a project within the ENIGMA Genetics Working Group, NeuroDISK conducts the meta-analysis to combine the partial set of results of the individual site(cohort)-level analyses, and therefore, the currently implemented LOIs do not conduct any subject-wise analysis.In other words, the data source for the current examples includes a partial set of the results of the individual cohort analyses; when the data query retrieves these results, the LOI variable mappings pass the information to the meta-analysis workflow (Figure 10).The results of running NeuroDISK for a user question are highlighted in Figure 11, explaining the LOI used, the datasets retrieved, and the results obtained.These explanations are generated from the provenance records that DISK keeps, including provenance records for the workflow executions that the workflow execution system provides as described below.</p>
<p>Continuously updating results</p>
<p>NeuroDISK continuously checks for new information that could be used to answer an active query; new information may be new cohort data added to the data source or new workflows to reflect new analysis methods.In such cases, NeuroDISK re-runs the LOI to update the findings.Therefore, there may be several runs of the same LOI in response to a standing user query, all of which are captured and saved.</p>
<p>Figure 12 illustrates how users see this process.In this case, initially 10 datasets are available, and eventually up to 50 cohorts' datasets become available in the data source.</p>
<p>Implementation of NeuroDISK</p>
<p>An integrated overview of the components of NeuroDISK is shown in Figure 13.We distinguish among users who formulate questions and receive the results, advanced users who define the types of questions and corresponding lines of inquiry, and developers who integrate new data sources and workflow software into the framework.</p>
<p>In NeuroDISK, the data source is implemented in the Organic Data Science (ODS) framework (Gil et al., 2015), an extension of Semantic MediaWiki (Krötzsch et al., 2007).This enables users to view metadata of different datasets and to add new metadata as needed.In NeuroDISK, we set up a separate ODS site per ENIGMA working group, since each group operates largely independently, although these largely share the same ontologies.The ODS data source we make available as part of this publication is one which contains published information (Grasby et al., 2020) from the cortical GWAS project of the Genomics Working Group.</p>
<p>In NeuroDISK, workflows and meta workflows are executed through WINGS (Gil et al., Jan.-Feb 2011, 2011), an intelligent workflow system that propagates semantic constraints to ensure that the analysis is valid for the data at hand, and to set up parameter values that are appropriate for the input datasets.WINGS exports provenance information to DISK, so that it is accessible to its users.</p>
<p>The architecture of DISK is modular, and other data sources and workflow systems can be integrated.Figure 14 shows the data adapters and APIs defined for DISK.</p>
<p>NeuroDISK is fully implemented, and links to a web portal, system software, ontologies, and other materials are included as Supplementary Materials.The system can be installed as a software container or building from source code.The system is documented in detail with guides for users, developers, and system administrators.DISK provides abstract classes to implement both data adapters (for data sources) and method adapters (for workflow systems).The current implementation of DISK includes method adapters for two workflow systems, WINGS and AirFlow, and one data adapter for the Semantic MediaWiki platform.</p>
<p>Results</p>
<p>We demonstrate the use of NeuroDISK to simulate hypothesis-driven discovery and continuous result updates using and extending a well-known ENIGMA publication (Grasby et al., 2020), in which researchers from institutions around the world participated in this study by following specific standardized protocols to: 1) extract neuroimaging derived traits from the cortical brain surface; 2) impute the genotyping data 3) quality control all the data; and 4) run a series of linear association models (or mixed effects models depending on population structure) to identify genome-wide associations with cortical brain imaging measures.70 total brain imaging traits were assessed genome-wide (~18,000,000 genetic variants).The results from cohorts of European ancestry were meta-analyzed together using an inverse-variance based weighting.Replication analysis was performed by meta-analyzing results from the ENIGMA cohorts with that of a single large cohort, UK Biobank, with over 10,000 individuals.These final meta-analyzed results were then used to demonstrate generalizability in other cohorts of individuals from non-European ancestry.</p>
<p>While final meta-analyzed results are available for the full genome-wide and image-wide set of variables on the ENIGMA website, it has been suggested that raw cohort level results can be used to identify an individual participant (Cai et al., 2015;Homer et al., 2008).Therefore, here we work only with a subset of results.The subset of statistics includes the effect size, standard error, and p-value calculated for 14 of the significant associations discussed in the paper between specific single nucleotide polymorphisms (SNP) and surface area or thickness for cortical regions of interest.The individual cohort-level results were made available as part of the Forest plots in the supplementary materials of the original publication.The set of results per cohort were uploaded into NeuroDISK as a single file, with the results of each SNP as an individual row, allowing the set of findings made available to easily be extended in the future.While all 14 associations are available for users to peruse, our running example uses the most significant association identified in the original publication -the SNP rs1080066 and the surface area of the precentral cortex.We also capture meta-data related to the sample size, sex distribution, mean age, and ancestry information available from participating cohorts.</p>
<p>We first reproduce the results of the Grasby et al (Grasby et al., 2020) publication with a meta-analysis of all effect-sizes as weighted by the inverse variance of the effects.Next, we show how cohort-specific meta-data can be integrated to ask a novel question of the data, which may help identify discrepancies in results across cohorts.Finally, we add data from the Adolescent Brain Cognitive Development Study (https://nda.nih.gov/abcd)(Jernigan et al., 2018) a cohort that was not available as part of the original 2020 paper, and highlight how incrementally adding data can change results, altering confidence in the original meta-analysis and the novel meta-data based analyses.We detail these results below.</p>
<p>Replicating the published ENIGMA GWAS meta-analysis</p>
<p>In Grasby et al., (Grasby et al., 2020) we and over 300 co-authors performed a standardized genome-wide association study meta analysis as described above.Here, we show that when the individual level cohort summary results for the SNP of interest are stored in the ODS database, we can query the association with NeuroDISK and trigger a meta-analysis workflow.</p>
<p>The query specifically searches for association results of SNP rs10810066 on the precentral surface area, filters for cohorts of European ancestry, and performs a meta-analysis.Our meta-analysis workflow also generates a Forest plot for visual comparison of effect sizes per cohort.Users are presented with the individual datasets that the query returns and have the option to remove individual cohorts.Here we show that a meta-analysis of all discovery ENIGMA cohorts and the UK Biobank results yields results very similar to that of the published work (Figure 15).The slight discrepancy is due to the fact that in the publication the ENIGMA cohorts were meta analyzed together first, then UK Biobank was meta-analyzed with those results, where as here we meta-analyze results from all cohorts (including UKBiobank) together.</p>
<p>We show this by comparing the results of two associations (rs10810066 on the precentral surface area) from both the original publication and that of NeuroDISK's reassessment with and without UK Biobank (Table 2).We show that the resultant effects are nearly identical without UK Biobank, but differ slightly in significance with UK Biobank due to the difference in how the cohort was included, as the Grasby et al paper meta-analyzed the result of all 48 ENIGMA cohorts (considered discovery) with that of UK Biobank (considered replication), while here we meta-analyze all 49 cohorts simultaneously.</p>
<p>Figure 15.Meta analysis workflow results to validate the NeuroDISK framework can reproduce the published meta analysis results (Grasby et al., 2020).Left: Published Forest plot for the effect size of SNP loci rs1080066 on the precentral surface area and from supplements of published results (Grasby et al., 2020).Right: Forest plot using the NeuroDISK meta analysis workflow highlights successful replication.Figure 16.Meta regression workflow results show a scatter plot displaying the association between the effect size of an association of interest, here being the effect of SNP rs1080066 on precentral surface area (y-axis), against the mean age of each cohort (x-axis).The visualization is based on R Shiny (https://www.rstudio.com/products/shiny/)and is interactive such that users can click any point to check the cohort information.Clicking the regression line shows the beta value and p value of association.The size of each point is a reflection of the sample size of the cohort.(Right) Users can also adjust the demographic variable of interest to selectively display cohorts that fall within a specified range, ie., the mean age between 0-60 years old.</p>
<p>Asking and answering novel questions</p>
<p>When working across such diverse cohorts and performing meta-analyses, researchers may be interested to know whether there are aspects of particular datasets that are driving the associations.For example, is the effect of a genetic association a function of the age of a specific cohort?We can ask and answer such questions within the NeuroDISK framework.Specific association results and covariates are retrieved from the ODS, and meta analysis or meta regression workflows are provided as options.In the case of rs1080066 and precentral surface area, the meta regression workflow corresponds to 'Is the effect size of rs1080066 on Precentral SA associated with mean age of the cohort?'We performed a meta-regression to determine whether there was an association between the effect size of the SNP's association with the cortical structure and mean age of each cohort.Our meta-regression workflow weighs the effects of the cohort by its sample size and regresses the effects against the cohort-specific factor, in this case for mean age.The workflow includes a scatterplot as a visual output and allows the user the option to filter cohorts by limits on the factor.For example, in Figure 16 we show results of the meta-regression across the full set of cohorts (left) and after filtering to only include cohorts with mean age under 60 years (right).Although not shown, filtering can also be done as part of the meta-analysis in section 3.1.</p>
<p>Continuous updates of results</p>
<p>The NeuroDISK framework can re-execute queries as more data becomes available.We demonstrate this re-execution through continuous retrieval of data and updating of results by artificially simulating the availability of new data over time.We subsampled the available data, starting with 10 cohorts (N = 10) and then iteratively adding 10 more cohorts at a time (N = 20, 30, 40, 48) until we reached 48 total cohorts, equal to the total number of cohorts in the original ENIGMA discovery cohort (not including UK Biobank).We then added UK Biobank, which was analyzed separately in the original paper (N = 49).Lastly, we added a new external cohort, the Adolescent Behavioral Cognitive Development (ABCD) dataset, which was not in the original publication, so associations were calculated separately and uploaded onto the ODS (N = 50 cohorts).</p>
<p>ABCD is the largest longitudinal neuroimaging study for child health in the United States, which has recruited more than 10,000 children around 9 to 10 years old (Casey et al., 2018) with deep genotyping using the Affymetrix Axiom Smokescreen Array.We extracted demographic information such as age, sex, and scanner information (SIEMENS/GE/Philips) for the baseline (N = 11,362) data.T1 weighted MRI from ABCD 4.0 release data were processed by the ABCD group (Hagler et al., 2019) and baseline cortical surface area or thickness measures were extracted using Freesurfer version 7.1.1available in release 4.0.We calculated the first four components of MDS using the ENIGMA protocol and followed the ENIGMA genetic imputation protocol and QC criteria (Minor Allele Frequency &lt; 0.01; Genotype Call Rate &lt; 95%; Hardy-Weinberg Equilibrium &lt; 1x10 -6 ).We filtered for individuals of European ancestry as in the ENIGMA Genetics Imputation protocol available online (https://github.com/ENIGMA-git/Genetics/tree/main/ENIGMA2/Imputation),where a radius of 0.0066 was set around the first, second and third MDS components of the CEU centroid, resulting in a sample size of N = 5,202.The distance was calculated by covering 95% of the first, second and third MDS components of the European centroid data.We used GCTA (Yang et al., 2011) to estimate the genetic relationship matrix (GRM) from 452,544 SNPs, which was subsequently used in a linear mixed model regression of the specific SNPs of interest on the brain regions of interest using GCTA-MLMA (Yang et al., 2014) and including age, sex, and scanner manufacturer (Siemens, GE, or Philips) as fixed covariates along with the first four genetic components derived from multidimensionality scaling, as performed in the original ENIGMA publication (Grasby et al., 2020).</p>
<p>As ABCD was not used in the original publication, these genetic association tests were run separately before corresponding genotype-phenotype association results were uploaded onto the ODS for follow-up continuous meta-analysis and meta-regressions.</p>
<p>Figure 17 shows the meta-regression results of the consecutive runs with increasing sample sizes and shows the trend of the outputs mapped against the number of data inputs.On the UI itself, users can see the final p-value of the association and access the plots (Figure 16) to help visualize the individual data points.As the number of cohorts increase to 40 or more, the effect of mean age on the effect of the SNP on the cortex appears to reach nominal significance (p=0.02),showing a trend towards younger cohorts having a greater genetic effect.We do note that no stable trend is being observed, and more data will be needed to establish greater confidence in the significance of the association.</p>
<p>Figure 17.Continuously updated findings.The NeuroDISK user interface shows results across all runs in one location for ease of comparison.We display the meta-regression results of continuous runs of the effect of SNP rs1080066 on the precentral surface area versus mean age of the cohort.To demonstrate a continuously growing database of cohort data, the first 10, 20, 30, and 40 samples were taken at random from the initial list of 48 cohorts of European ancestry involved in the original ENIGMA cortical GWAS publication (Grasby et al., 2020).The 49th cohort was the UK Biobank dataset which served as a meta-analysis replication in the original publication, and the 50th included cohort was ABCD, a cohort not involved in the original publication.We notice that as the number of cohorts increase, the effect of mean age on the effect of the SNP appears to reach nominal significance, although as the result hovers around the nominal p=0.05 threshold, more data will be needed to ensure stability of the effect.The -log(10) of the p-value is plotted on the y-axis, so points higher along the y-axis are more significant.</p>
<p>In summary, our results show that NeuroDISK can perform data analysis continuously and automatically, and our methods yield results that replicate the original publication and allow users to delve deeper with the data and ask additional questions of summary results that were not answered in the original study.NeuroDISK is ideal for meta-analytical studies, as demonstrated in this work, but can also be extended to large-scale coordinated analyses using individual subject level data points.</p>
<p>Discussion and Conclusion</p>
<p>We have presented a novel AI approach to scientific problem solving that captures how scientists pursue inquiry-driven discoveries through explicit knowledge structures called lines of inquiry.We use AI techniques to represent how scientists pose questions or hypotheses, how they characterize the data needed to address a given question, and what methods are appropriate to analyze the data found.We use AI reasoners to execute expression matching, variable assignments, constraint propagation, and other forms of problem solving needed to set up and run lines of inquiry.Our approach is implemented in NeuroDISK, which extends the general-purpose DISK framework with lines of inquiry for multi-site imaging genetics, including datasets with descriptive metadata and workflows for analysis.We demonstrated NeuroDISK by reproducing the results of a well-known publication following our approach, and showed how the results can be updated automatically when new data becomes available.</p>
<p>NeuroDISK has demonstrated important capabilities for the automation of inquiry-driven discovery, specifically:</p>
<p>• Guiding scientists to specify neuroimaging genetics inquiries that can be tested with available datasets.NeuroDISK can guide scientists to specify an inquiry (question or hypothesis) by selecting from possible questions that can be answered using available datasets.This is possible because NeuroDISK uses question patterns that are tied to ontologies representing the kinds of terms in questions that could be answered with the data available.The underlying DISK framework provides a general ontology of scientific questions and hypotheses that provides overarching concepts that guided the design of the neuroimaging genetics question ontology in NeuroDISK.NeuroDISK generates explanations of how a result was generated based on the provenance records of the execution of a triggered line of inquiry and its associated queries and workflows.When new datasets are added, NeuroDISK summarizes the differences among all the triggered lines of inquiry so that the changes in findings can be tracked.</p>
<p>Our system has certain limitations given that NeuroDISK was designed with a specific scope based on the select ENIGMA projects that we targeted.We designed NeuroDISK with modularity in mind so that it can be easily extended for other datasets, projects, and studies.For example, new ontologies and workflows would need to be created for other neuroimaging data of different modalities (diffusional MRI, functional MRI etc.).</p>
<p>NeuroDISK is designed to support scientists to explore questions and hypotheses.Rather than executing the above steps and processes manually, scientists can rely on NeuroDISK to automate the process and present the results in context.This may save scientists significant time and effort.It also has assurances that the analysis is valid, since it uses proven methods as represented in NeuroDISK.In addition, NeuroDISK reconsiders a scientist's question whenever new relevant data becomes available.This would add a novel dimension to scientific research, namely obtaining updates of published findings as more data is collected in various neuroimaging studies over time.This could help increase the confidence of published findings or lead to revisiting previously explored questions to refine the scope of a past investigation.As new datasets are incorporated into the analysis, a scientist can consider more specific questions such as filtering by a demographic characteristic where enough data is now available.Finally, NeuroDISK could be extended to automatically generate visualizations that highlight the results in different populations so that scientists can consider potential future investigations.</p>
<p>Beyond individual users, there are many benefits of a framework like NeuroDISK for use in scientific collaborations such as the ENIGMA consortium.First, method validity: lines of inquiry and workflows in NeuroDISK would be used for many analyses and reviewed by multiple users.This would be in contrast with current practices where individual researchers establish their own methods and software.Second, dissemination of new methods and method reuse: Our system makes it easy to run existing methods as there would be no prior learning needed to apply them.Third, transparency and reproducibility of the analyses: Everyone can access the provenance traces for any analyses in the collaboration.Fourth, promoting FAIR data and FAIR method practices: AI reasoners need explicit metadata and representations that are also useful for human scientists.Fifth, comparison of experimental results would be facilitated as the provenance and lines of inquiry would be comparable side by side.</p>
<p>Adopting a framework such as NeuroDISK could raise concerns about stifling scientific creativity, since the framework would run the same workflows and methods for all data while human-driven analyses would naturally include many variants (using different software, different order in the steps, etc).We argue that the current human-driven processes have resisted creativity and innovation.Each researcher has a tendency to use software that they have used before, since using new algorithms and methods can have a significant learning curve.With NeuroDISK, it would be easy to replace workflow fragments with new methods that become available in the literature.Scientists could easily compare and contrast new methods and see the results of re-running previous analyses using the new methods.We believe our system would stimulate more creativity in terms of exploring new combinations of methods and incorporation of new algorithms.</p>
<p>Intelligent generation of visualizations is also an area of future work.Different types of visualizations may be more useful depending on the scientific question at hand.For example, a visualization may focus on the distribution of the input data for statistical analysis and significance, while others may focus on domain-specific illustrations-like 3D brain images-to aid in exploration.Including these visualizations in our workflows requires domain-specific knowledge from researchers.Visualization is a key aspect for understanding the outcome of an analysis, and easing data exploration may lead to additional scientific questions or prompt researchers to create new datasets to fill in existing gaps.</p>
<p>Because all the scientific questions in NeuroDISK are machine readable, our approach can easily be extended to retrieve semantically similar questions and datasets that have been posed by other investigators and may be related to a new question.NeuroDISK can group similar questions so that their results can be compared.Improving this support for comparing scientific questions may provide researchers with new insights.</p>
<p>NeuroDISK automates many key steps and processes for discovery that are mostly carried out manually today.This is a crucial contribution to the development of AI scientists that can automate scientific exploration and discovery.Today, these steps and processes are typically described as part of the methods section of publications.However, they are not in a machine-readable representation.Moreover, the descriptions of methods are often partial or incomplete (Garijo et al., 2013) which makes it difficult for AI systems to access this information.</p>
<p>In contrast, NeuroDISK makes these steps and processes machine-readable and therefore accessible to AI reasoners.</p>
<p>NeuroDISK demonstrates the automation of sophisticated reasoning involved in scientific discovery processes including data retrieval and analysis through planning, reasoning, and execution techniques, leading the way for AI scientists.</p>
<p>Scientific practice would be fundamentally transformed through these developing AI scientists.Scientific advances would be greatly accelerated through the automation of analyses.Pursuing new investigations could potentially be completed in a matter of hours or days rather than months or years.In addition, new results would be more reliable, as they would come with some guarantees of correctness by using lines of inquiry that reflect well known methods and best practices, rather than be prone to human error and misunderstandings.Extensive provenance and explanation would be available for examination, rather than the limited documentation provided in scientific publications.We imagine a future where, once a scientific article is published, its findings are continuously updated when new evidence comes to light, opening the way to fully digital and comprehensively computational paradigms for science.</p>
<p>Acknowledgments</p>
<p>We are grateful to past and current members of this project for their work on earlier versions of NeuroDISK, particularly Iyad Ba Gari, Joanna Bright, Michael Bornstein, Josh Boyd, Haripriya Dharmala, Vedant Diwanji, Hanna Endrias, Ryan Espiritu, Shobeir Fakhraei, MiHyun Jang, Yibo Ma, Naomi Perez, Abishek Prakash, Wesley Surento, Rosna Thomas, and Regina Wang.We are also grateful to ENIGMA consortium researchers and participants for making this work possible.This work was supported by NIH awards R01AG059874 (PI: Jahanshad) and R01MH134004 (PI: Jahanshad), ONR award N00014-21-1-2437 (PI: Gil), NSF awards IIS-1344272 (PI: Gil) and ICER-1541029 (PI: Gil), and pilot funding from the Kavli Foundation.</p>
<p>Supplementary Materials / Data Availability</p>
<p>In this section we provide links to web resources, datasets, and workflows developed in our work to date in NeuroDISK and the underlying DISK system:</p>
<p>• Data availability statement: All data and code used in this work are publicly available.</p>
<p>The individual cohort results are available as part of the supplementary files of the Grasby et al 2020 publication, and also made available on NeuroDISK.The ABCD dataset, the only one not used in the original Grasby publication, may be accessed at https://nda.nih.gov/abcd.Summary statistics of the genotype-phenotype associations tested here can be accessed through the available NeuroDISK platform.</p>
<p>Figure 2 .
2
Figure 2.NeuroDISK is designed to automate the processes that scientists follow to answer questions using existing datasets.A scientific question (1) is mapped into a structured form that is machine-readable (2) that enables NeuroDISK to select a general approach (3) to answer that question.The approach typically involves formulating a query that will access existing data sources to find relevant datasets (4), setting up and running analyses for the data available (5), consolidating the results for different datasets (6), and explaining(7) and presenting (8) the findings.When new data become available (9), NeuroDISK revisits the original question and re-runs its analyses so that the findings can be updated (10).</p>
<p>Figure 3 .
3
Figure 3. NeuroDISK uses Lines of Inquiry (LOIs) to represent the approach that a scientist would follow to answer different types of questions.An LOI consists of: (1) documentation about the LOI, which can include literature citations that introduce the approach;(2) a question template that will be matched against the user's question; (3) a data query template that specifies how to retrieve data that is relevant to answering the question; (4) workflows that specify how to analyze the data retrieved; and (5) meta-workflows that indicate how to combine the results of all the workflows executions.In this example, an LOI is set up to investigate if the effect size of a particular genotype on a specific brain region is associated with a demographic attribute of the cohorts, while allowing the cohorts to be filtered by another attribute (in this case genetic ancestry).This process is a meta-regression on the effect sizes of the individual cohorts retrieved from the data sources.</p>
<p>Figure 4 .
4
Figure 4.An overview of the ontologies in NeuroDISK.The Scientific Questions Ontology (SQO) at the top illustrates the main concepts and terms.Question templates in NeuroDISK have variables that users will fill out based on the options specified in the Scientific Domain Ontology (SDO) with additional options that are dynamically retrieved from the data source and expressed in a Data Source Ontology (DSO), as shown in the lower section of the figure.In NeuroDISK, the SDO is the SDO-ENIGMA ontology and the DSO is the ODS-ENIGMA ontology.Each ontology is grouped within a dashed box, where concepts are shown in different colors with labeled arrows indicating concept properties, and arrows across ontologies indicating subclasses.</p>
<p>Figure 5 .
5
Figure 5.The NeuroDISK user interface for specifying questions.(1) A user chooses among a set of pre-defined question templates, which can be specific hypotheses with a posited outcome or simply exploratory questions.These templates contain variables and their possible instantiations.(2) The user chooses values for each of the question variables through pull-down menus.(3) The user's question is turned into a question pattern consisting of RDF triples.</p>
<p>Figure 6 .
6
Figure 6.An overview of the main concepts in the NeuroDISK ODS-ENIGMA ontology (the DSO in NeuroDISK) that describe how cohorts and subsets of cohorts are used for specific projects.</p>
<p>Figure 6
6
Figure6illustrates the main concepts in the ODS-ENIGMA ontology.It represents useful entities in the ENIGMA collaboration such as datasets, cohorts, organizations, protocols, instruments, software, working groups, projects, and persons, together with the relationships among them.It extends popular vocabularies for describing entities and actions(GuhaR, 2016) and the W3C semantic standard PROV(Gil et al., 2012) for provenance recording.</p>
<p>Figure 7 .
7
Figure 7.The LOI variable mappings between the variables in the question template and the variables in the LOI data query template indicate to NeuroDISK how to retrieve appropriate datasets from the data source.The data query template is a SPARQL query, and the actual data query will be completely specified once the user choices for the user question variables replace the corresponding LOI query template variables according to the variable mappings.</p>
<p>Figure 8 .
8
Figure8.The data query generated from the user's question, highlighting the relevant LOI variable mappings.The data query will be used to retrieve datasets from the data source that are relevant to a user's question.</p>
<p>Figure 9 .
9
Figure 9.The cohort data that are retrieved, showing for each cohort the demographics and other information that appeared in the user's question.</p>
<p>Figure 10 .
10
Figure10.The LOI's meta-analysis is done through a meta-workflow, in this case for meta-regression.The LOI variable mappings are used to take the results of the data query and set the inputs to the meta-workflow.</p>
<p>Figure 11 .
11
Figure11.NeuroDISK captures the provenance of all execution results of the analysis and meta-analysis workflows and uses it to generate explanations for users.In this case: (1) the original question or hypothesis is shown along with the name of the selected LOI; (2) the datasets retrieved corresponding to several cohorts; (3) datasets and dataset characteristics that were input to the meta-analysis; (4) the results of the meta-analysis, which include a confidence value as well as visualizations of the results.</p>
<p>Figure 12 .
12
Figure 12.NeuroDISK continuously checks if the results for a user question have changed due to new data becoming available or due to workflow or meta-workflow updates.(1) The standing user question continuously triggers the matched LOI; (2) the user hypothesis contains variables;(3) those variables are used to set up a query to retrieve relevant data; (4) the data is then analyzed with workflows; and (5) the LOI is re-executed every time that additional data is retrieved from the data source, and the user can see how the results change.On the left is the user's view of the hypothesis and the results over time.In this case we show the -log10 of the p-value against the iterations, and overall highlight smaller p-values or an increase in confidence (higher points on the plot) with added data points.Users can ask for details on each run, and can request to see the LOI as shown on the right.</p>
<p>Figure 13 .
13
Figure 13.A diagram of the architecture components of DISK.Users specify hypotheses or questions that conform to pre-defined templates.Advanced users have added pre-defined LOIs that are triggered when they match the user's question.The LOIs generate queries to retrieve data from a data source, and the data is analyzed through workflows and meta-workflows.A developer can set up new data sources and new workflows in the DISK back-end.</p>
<p>Figure 14 .
14
Figure 14.A diagram of the DISK APIs and adapters that enable interoperability with other data sources and workflow systems.DISK provides abstract classes to implement both data adapters (for data sources) and method adapters (for workflow systems).The current implementation of DISK includes method adapters for two workflow systems, WINGS and AirFlow, and one data adapter for the Semantic MediaWiki platform.</p>
<p>Surface Area for BrainImagingTrait, these are the triples that represent those choices in the user question:
sdo:effectSizesdo:sourceGeneods:rs1080066sdo:effectSizesdo:targetCharacteristicods:SurfaceAreasdo:effectSizesdo:targetCharacteristicods:PrecentralCortexsdo:effectSizesdo:isAssociatedWithods:Mean_Agesdo:effectSizesdo:collectedFromods:EuropeanAncestrysdo:effectSizesdo:sourceGenesdo:Genotypesdo:effectSizesdo:targetCharacteristicsdo:BrainImagingTraitsdo:effectSizesdo:targetCharacteristicsdo:Regionsdo:effectSizesdo:isAssociatedWithsdo:DemographicAttributesdo:effectSizesdo:collectedFromsdo:GeneticAncestry
When a user specifies their question and chooses variable values, the user question pattern is instantiated with the corresponding variable values (using the 'ods:' prefix for the values extracted dynamically from the data source and that are in the ODS-ENIGMA ontology).For example, when a user chooses rs1080066 for Genotype, Precentral Cortex for Region, and</p>
<p>Table 1 .
1
Overview of the current ODS-ENIGMA ontologies in NeuroDISK.
NameDescriptionCore OntologyMain concepts of ODS-ENIGMA, elaborated further in other ontologiesOrganization OntologyOrganizations (institutions) of investigators that contribute to ENIGMACohort OntologyCohorts of study participants selected based on inclusion criteriaDemographic OntologyDemographics for cohort datasetsWorking Group OntologyDedicated working groups within the ENIGMA consortiumProject OntologyProjects undertaken by ENIGMA working groupsPerson OntologyResearchers that participate in ENIGMA working groups and projects</p>
<p>Table 2 .
2
Reproduced genetic association results for precentral surface area and rs1080066 for ENIGMA discovery cohorts with and without UK Biobank.
Precentral surfaceENIGMA Discovery CohortsENIGMA Discovery + UK Biobankareaandrs1080066-A allelePublishedReplicatedPublishedReplicatedEffectsize-110.56-110.51-111.78-116.32(unstandardizedbeta)</p>
<p>•</p>
<p>(Wilkinson et al., 2016)among possible approaches that represent how to answer common types of neuroimaging genetics inquiries with existing datasets.NeuroDISK contains lines of inquiry that express the general approaches that a scientist would pursue for a given inquiry, including what kinds of datasets to use and how to analyze them.NeuroDISK lines of inquiry provide the basis for taking a scientific question and automatically generating a query to a data repository, then setting up and running analyses for the data found, and finally consolidating the results to answer the question.•Automaticallyfindingdatabygeneratingdataqueries that describe characteristics of datasets from existing neuroimaging cohorts that make them useful for different types of scientific questions.NeuroDISK includes ontologies to describe cohorts datasets collected in neuroimaging studies and to describe subsets of those cohorts that have been used in ENIGMA projects.Dataset characteristics include genotypic, phenotypic, and other demographic information.These representations enable NeuroDISK to automatically retrieve and reuse available datasets.This approach is consistent with the FAIR data principles(Wilkinson et al., 2016)by providing a descriptive metadata to find, access, integrate, and reuse datasets.For NeuroDISK, metadata about project cohorts is in the data repository (the ODS Wiki), in a machine readable format and accessible through APIs.•Automatically apply methods by elaborating and executing appropriate steps to analyzethe available data to investigate an inquiry posed by users.NeuroDISK reasons the representations of scientific questions and the representations of lines of inquiry in order to automate this process.In this way, NeuroDISK generates data queries to retrieve appropriate datasets and set up executable workflows for analyzing that data with the required inputs.This may be decomposed into analysis, done with workflows, and meta-analysis done with meta-workflows.•Updatingresults by continuously monitoring the available data sources and triggeringnew runs on the relevant lines of inquiry.NeuroDISK considers standing user inquiries to reconsider lines of inquiry that query data sources for new datasets.When new data is returned, the analyses are executed again and the results are updated.• Presenting the findings through explanations and summaries of the analyses conducted.</p>
<p>• DISK: ○ DISK software: https://doi.org/10.5281/zenodo.10931904○ DISK system user guide and documentation: https://disk.readthedocs.io/○ DISK's Scientific Questions Ontology (SQO): https://w3id.org/sqo○ DISK project web site: https://w3id.org/disk• NeuroDISK: ○ NeuroDISK user portal: https://w3id.org/neurodisk○ NeuroDISK Scientific Domain Ontology (SDO): https://w3id.org/enigma○ NeuroDISK data source: https://w3id.org/neurodisk/data○ NeuroDISK project website: https://w3id.org/neurodisk/site</p>
<p>Author informationDaniel Garijo: ORCID: 0000-0003-0454-7145 (daniel.garijo@upm.es) 1
Transforming science labs into automated factories of discovery. A References Angelopoulos, J F Cahoon, R Alterovitz, Science Robotics. 99569912024</p>
<p>Unification in modal and description logics. F Baader, S Ghilardi, Logic Journal of the IGPL / Interest Group in Pure and Applied Logics. 1962010</p>
<p>A purely confirmatory replication study of structural brain-behavior correlations. W Boekel, E.-J Wagenmakers, L Belay, J Verhagen, S Brown, B U Forstmann, Cortex; a Journal Devoted to the Study of the Nervous System and Behavior. 662015</p>
<p>Autonomous chemical research with large language models. D A Boiko, R Macknight, B Kline, G Gomes, Nature. 62479922023</p>
<p>Exploring the impact of analysis software on task fMRI results. A Bowring, C Maumet, T E Nichols, Human Brain Mapping. 40112019</p>
<p>Scientific discovery: Computational explorations of the creative processes. Gary L Bradshaw, Zytkow, Applied Cognitive Psychology. 23Jan M. 1988. 1987MIT Pressof pages: 357. ISBN 0 262 12116 6</p>
<p>Genetic variants associated with longitudinal changes in brain structure across the lifespan. R M Brouwer, M Klein, K L Grasby, H G Schnack, N Jahanshad, J Teeuw, S I Thomopoulos, E Sprooten, C E Franz, N Gogtay, W S Kremen, M S Panizzon, L M Olde Loohuis, C D Whelan, M Aghajani, C Alloza, D Alnaes, E Artiges, R Ayesa-Arriola, H E Hulshoff Pol, Nature Neuroscience. 2542022</p>
<p>Power failure: why small sample size undermines the reliability of neuroscience. K S Button, J P A Ioannidis, C Mokrysz, B A Nosek, J Flint, E S J Robinson, M R Munafò, Nature Reviews. Neuroscience. 1452013</p>
<p>Deterministic identification of specific individuals from GWAS results. R Cai, Z Hao, M Winslett, X Xiao, Y Yang, Z Zhang, S Zhou, Bioinformatics. 31112015</p>
<p>The Adolescent Brain Cognitive Development (ABCD) study: Imaging acquisition across 21 sites. B J Casey, T Cannonier, M I Conley, A O Cohen, D M Barch, M M Heitzeg, M E Soules, T Teslovich, D V Dellarco, H Garavan, C A Orr, T D Wager, M T Banich, N K Speer, M T Sutherland, M C Riedel, A S Dick, J M Bjork, K M Thomas, … Abcd, Developmental Cognitive Neuroscience. 322018Imaging Acquisition Workgroup.</p>
<p>OWL web ontology language reference. M Dean, D L Mcguinness, April 3, 2024</p>
<p>Automating data science. T De Bie, L De Raedt, J Hernández-Orallo, H H Hoos, P Smyth, C K I Williams, Communications of the ACM. 6532022</p>
<p>Genome-wide association studies of brain imaging phenotypes in UK Biobank. L T Elliott, K Sharp, F Alfaro-Almagro, S Shi, K L Miller, G Douaud, J Marchini, S M Smith, Nature. 56277262018</p>
<p>Accelerated discovery of 3D printing materials using data-driven multiobjective optimization. T Erps, M Foshey, M K Luković, W Shou, H H Goetzke, H Dietsch, K Stoll, B Vacano, W Matusik, Science Advances. 74274352021</p>
<p>D Garijo, S Fakhraei, V Ratnakar, Q Yang, H Endrias, Y Ma, R Wang, M Bornstein, J Bright, Y Gil, N Jahanshad, Towards Automated Hypothesis Testing in Neuroscience. Heterogeneous Data Management, Polystores, and Analytics for Healthcare. 2019</p>
<p>The DISK hypothesis ontology: Capturing hypothesis evolution for automated discovery. D Garijo, Y Gil, V Ratnakar, 2017</p>
<p>Quantifying reproducibility in computational biology: the case of the tuberculosis drugome. D Garijo, S Kinnings, L Xie, L Xie, Y Zhang, P E Bourne, Y Gil, PloS One. 811e802782013</p>
<p>D Garijo, H Vargas, Y Gil, The scientific questions ontology. 2023, October 24</p>
<p>Automated hypothesis testing with large scientific data repositories. Y Gil, D Garijo, R Mayani, R Adusumilli, H Boyce, S Edu, P Mallick, Advances in Cognitive Systems. 2016. 2016</p>
<p>Towards Continuous Scientific Data Analysis and Hypothesis Evolution. Y Gil, D Garijo, V Ratnakar, R Mayani, R Adusumilli, H Boyce, A Srivastava, P Mallick, 10.1609/aaai.v31i1.11157Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence201731</p>
<p>A semantic framework for automatic generation of computational workflows using distributed data and component catalogues. Y Gil, P A González-Calero, J Kim, J Moody, V Ratnakar, Journal of Experimental &amp; Theoretical Artificial Intelligence: JETAI. 2342011</p>
<p>Y Gil, F Michel, V Ratnakar, J Read, M Hauder, C Duffy, P Hanson, H Dugan, Supporting Open Collaboration in Science Through Explicit and Linked Semantic Description of Processes. The Semantic Web. Latest Advances and New Domains. 2015</p>
<p>Y Gil, S Miles, K Belhajjame, H F Deus, D Garijo, G Klyne, P Missier, S Soiland-Reyes, S Zednik, PROV Model Primer. W3C Working Group Note. 2012. 192014</p>
<p>Wings: Intelligent Workflow-Based Design of Computational Experiments. Y Gil, V Ratnakar, J Kim, P Gonzalez-Calero, P Groth, J Moody, E Deelman, IEEE Intelligent Systems. 261Jan.-Feb 2011</p>
<p>… Enhancing NeuroImaging Genetics through Meta-Analysis Consortium (ENIGMA)-Genetics working group. K L Grasby, N Jahanshad, J N Painter, L Colodro-Conde, J Bralten, D P Hibar, P A Lind, F Pizzagalli, C R K Ching, M A B Mcmahon, N Shatokhina, L C P Zsembik, S I Thomopoulos, A H Zhu, L T Strike, I Agartz, S Alhusaini, M A A Almeida, D Alnaes, 10.1126/science.aay6690Science. 64843672020The genetic architecture of the human cerebral cortex</p>
<p>V Guhar, 10.1145/2844544Schema.org. Communications of the ACM. 2016</p>
<p>Image processing and analysis methods for the Adolescent Brain Cognitive Development Study. D J Hagler, Jr, S Hatton, M D Cornejo, C Makowski, D A Fair, A S Dick, M T Sutherland, B J Casey, D M Barch, M P Harms, R Watts, J M Bjork, H P Garavan, L Hilmer, C J Pung, C S Sicat, J Kuperman, H Bartsch, F Xue, A M Dale, NeuroImage. 1160912019</p>
<p>SPARQL 1.1 query language. W3C Recommendation. S Harris, A Seaborne, E Prud'hommeaux, 201321778</p>
<p>Novel genetic loci associated with hippocampal volume. D P Hibar, H H H Adams, N Jahanshad, G Chauhan, J L Stein, E Hofer, M E Renteria, J C Bis, A Arias-Vasquez, M K Ikram, S Desrivières, M W Vernooij, L Abramovic, S Alhusaini, N Amin, M Andersson, K Arfanakis, B S Aribisala, N J Armstrong, Ikram, Nature Communications. 8136242017</p>
<p>Common genetic variants influence human subcortical brain structures. D P Hibar, J L Stein, M E Renteria, A Arias-Vasquez, S Desrivières, N Jahanshad, R Toro, K Wittfeld, L Abramovic, M Andersson, Others, Nature. 52075462242015</p>
<p>An assessment of the autism neuroimaging literature for the prospects of re-executability. S M Hodge, C Haselgrove, L Honor, D N Kennedy, J A Frazier, 2020. F1000Research, 9, 1031</p>
<p>Resolving individuals contributing trace amounts of DNA to highly complex mixtures using high-density SNP genotyping microarrays. N Homer, S Szelinger, M Redman, D Duggan, W Tembe, J Muehling, J V Pearson, D A Stephan, S F Nelson, D W Craig, PLoS Genetics. 48e10001672008</p>
<p>Why most published research findings are false. J P A Ioannidis, PLoS Medicine. 28e1242005</p>
<p>. T L Jernigan, &amp; ABCD Consortium Coordinators.S A Brown, &amp; ABCD Consortium Coordinators.Introduction. Developmental Cognitive Neuroscience. 322018</p>
<p>Scientific Tests and Continuous Integration Strategies to Enhance Reproducibility in the Scientific Software Context. Proceedings of the 2nd International Workshop on Practical Reproducible Evaluation of Computer Systems. M Krafczyk, A Shi, A Bhaskar, D Marinov, V Stodden, 2019</p>
<p>Conceptual understanding through efficient automated design of quantum optical experiments. M Krenn, J S Kottmann, N Tischler, A Aspuru-Guzik, 10.1103/physrevx.11.031044Physical Review. X. 3112021</p>
<p>M Krötzsch, D Vrandečić, M Völkel, H Haller, R Studer, Semantic Wikipedia. 20075</p>
<p>Towards exploratory hypothesis testing and analysis. G Liu, M Feng, Y Wang, L Wong, S.-K Ng, T L Mah, E J D Lee, IEEE 27th International Conference on Data Engineering. 2011. 2011</p>
<p>The AI Scientist: Towards fully automated open-ended scientific discovery. C Lu, C Lu, R T Lange, J Foerster, J Clune, D Ha, arXiv [cs.AI]. arXiv2024</p>
<p>Ten years of enhancing neuro-imaging genetics through meta-analysis: An overview from the ENIGMA Genetics Working Group. S E Medland, K L Grasby, N Jahanshad, J N Painter, L Colodro-Conde, J Bralten, D P Hibar, P A Lind, F Pizzagalli, S I Thomopoulos, J L Stein, B Franke, N G Martin, P M Thompson, Enigma, Genetics Working Group. 4312022Human Brain Mapping</p>
<p>Whole-genome analyses of whole-brain data: working within an expanded search space. S E Medland, N Jahanshad, B M Neale, P M Thompson, Nature Neuroscience. 1762014</p>
<p>Multimodal population brain imaging in the UK Biobank prospective epidemiological study. K L Miller, F Alfaro-Almagro, N K Bangerter, D L Thomas, E Yacoub, J Xu, A J Bartsch, S Jbabdi, S N Sotiropoulos, J L R Andersson, L Griffanti, G Douaud, T W Okell, P Weale, I Dragonu, S Garratt, S Hudson, R Collins, M Jenkinson, S M Smith, Nature Neuroscience. 19112016</p>
<p>Introduction to the special issue on reproducibility in neuroimaging. R A Poldrack, K Whitaker, D Kennedy, NeuroImage. 2181163572020</p>
<p>. J B Poline, S Das, T Glatard, C Madjar, E W Dickie, X Lecours, N Beck, B Behan, S T Brown, D Bujold, M Beauvais, B Caron, C Czech, M Dharsee, M Dugré, K Evans, T Gee, G Ippoliti, G Kiar, A C Evans, 2023Data and Tools Integration in the Canadian Open Neuroscience Platform. Scientific Data</p>
<p>Accelerating materials discovery using artificial intelligence, high performance computing and robotics. E O Pyzer-Knapp, J W Pitera, P W J Staar, S Takeda, T Laino, D P Sanders, J Sexton, J R Smith, A Curioni, 10.1038/s41524-022-00765-zNpj Computational Materials. 812022. April 3, 2024concepts and abstract syntax</p>
<p>Neurodesk: an accessible, flexible and portable data analysis environment for reproducible neuroimaging. A I Renton, T T Dao, T Johnstone, O Civier, R P Sullivan, D J White, P Lyons, B M Slade, D F Abbott, T J Amos, S Bollmann, A Botting, M E J Campbell, J Chang, T G Close, M Dörig, K Eckstein, G F Egan, S Evas, S Bollmann, Nature Methods. 2152024</p>
<p>Automated discovery of experimental designs in super-resolution microscopy with XLuminA. C Rodríguez, S Arlt, L Möckl, M Krenn, J Sanz-Robinson, A Jahanpour, N Phillips, T Glatard, J.-B Poline, NeuroCI: Continuous Integration of Neuroimaging Results Across Software Pipelines and Datasets. 2022 IEEE 18th International Conference on E-Science. 2024. 202215e-Science</p>
<p>Genetic architecture of subcortical brain structures in 38,851 individuals. C L Satizabal, H H H Adams, D P Hibar, C C White, M J Knol, J L Stein, M Scholz, M Sargurupremraj, N Jahanshad, G V Roshchupkin, A V Smith, J C Bis, X Jian, M Luciano, E Hofer, A Teumer, S J Van Der Lee, J Yang, L R Yanek, M A Ikram, Nature Genetics. 51112019</p>
<p>Statistical Challenges in "Big Data" Human Neuroimaging. S M Smith, T E Nichols, Neuron. 9722018</p>
<p>Identification of common variants associated with human hippocampal and intracranial volumes. J L Stein, S E Medland, A A Vasquez, D P Hibar, R E Senstad, A M Winkler, R Toro, K Appel, R Bartecek, Ø Bergmann, M Bernard, A A Brown, D M Cannon, M M Chakravarty, A Christoforou, M Domin, O Grimm, M Hollinshead, A J Holmes, … Enhancing Neuro Imaging Genetics through Meta-Analysis Consortium. 201244</p>
<p>The automatic statistician. C Steinruecken, E Smith, D Janz, J Lloyd, Z Ghahramani, Automated Machine Learning. Springer International Publishing2019</p>
<p>An autonomous laboratory for the accelerated synthesis of novel materials. N J Szymanski, B Rendy, Y Fei, R E Kumar, T He, D Milsted, M J Mcdermott, M Gallant, E D Cubuk, A Merchant, H Kim, A Jain, C J Bartel, K Persson, Y Zeng, G Ceder, Nature. 62479902023</p>
<p>ENIGMA and global neuroscience: A decade of large-scale studies of the brain in health and disease across more than 40 countries. P M Thompson, … ENIGMA Consortium.N Jahanshad, … ENIGMA Consortium.C R K Ching, … ENIGMA Consortium.L E Salminen, … ENIGMA Consortium.S I Thomopoulos, … ENIGMA Consortium.J Bright, … ENIGMA Consortium.B T Baune, … ENIGMA Consortium.S Bertolín, … ENIGMA Consortium.J Bralten, … ENIGMA Consortium.W B Bruin, … ENIGMA Consortium.R Bülow, … ENIGMA Consortium.J Chen, … ENIGMA Consortium.Y Chye, … ENIGMA Consortium.U Dannlowski, … ENIGMA Consortium.C G F De Kovel, … ENIGMA Consortium.G Donohoe, … ENIGMA Consortium.L T Eyler, … ENIGMA Consortium.S V Faraone, … ENIGMA Consortium.P Favre, … ENIGMA Consortium.Translational Psychiatry. 1011002020</p>
<p>FAIRly big: A framework for computationally reproducible processing of large-scale data. A S Wagner, L K Waite, M Wierzba, F Hoffstaedter, A Q Waite, B Poldrack, S B Eickhoff, M Hanke, Scientific Data. 91802022</p>
<p>The Alzheimer's disease neuroimaging initiative: progress report and future plans. M W Weiner, P S Aisen, C R Jack, Jr, W J Jagust, J Q Trojanowski, L Shaw, A J Saykin, J C Morris, N Cairns, L A Beckett, A Toga, R Green, S Walter, H Soares, P Snyder, E Siemers, W Potter, P E Cole, M Schmidt, Alzheimer's &amp; Dementia: The Journal of the Alzheimer's Association. 632010Alzheimer's Disease Neuroimaging Initiative</p>
<p>The FAIR Guiding Principles for scientific data management and stewardship. M D Wilkinson, M Dumontier, I J J Aalbersberg, G Appleton, M Axton, A Baak, N Blomberg, J.-W Boiten, L B Da Silva Santos, P E Bourne, J Bouwman, A J Brookes, T Clark, M Crosas, I Dillo, O Dumon, S Edmunds, C T Evelo, R Finkers, B Mons, 2016Scientific Data, 3, 160018</p>
<p>GCTA: a tool for genome-wide complex trait analysis. J Yang, S H Lee, M E Goddard, P M Visscher, American Journal of Human Genetics. 8812011</p>
<p>Advantages and pitfalls in the application of mixed-model association methods. J Yang, N A Zaitlen, M E Goddard, P M Visscher, A L Price, Nature Genetics. 4622014</p>            </div>
        </div>

    </div>
</body>
</html>