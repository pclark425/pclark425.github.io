<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-489 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-489</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-489</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-17.html">extraction-schema-17</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <p><strong>Paper ID:</strong> paper-266998835</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2401.07744v2.pdf" target="_blank">C OMBINING M ACHINE L EARNING AND O NTOLOGY : A S YSTEMATIC L ITERATURE R EVIEW</a></p>
                <p><strong>Paper Abstract:</strong> ,</p>
                <p><strong>Cost:</strong> 0.025</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e489.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e489.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Holmes</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Holmes (Hybrid Ontological and Learning MEdical System)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A medical decision-support hybrid system that embeds machine learning (Adaboost) inside an ontology-backed expert system to impute missing values and support patient treatment decisions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Validation of an Ontological Medical Decision Support System for Patient Treatment Using a Repository of Patient Data: Insights into the Value of Machine Learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Holmes (Hybrid Ontological and Learning MEdical System)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>An expert-system style clinical decision support application that integrates an ontology (knowledge base + inference engine) with an embedded supervised learner (Adaboost). Machine learning is used as a subsystem to estimate missing clinical inputs or to provide evidence used by the symbolic reasoning module, allowing the expert system to perform deductive inference for treatment recommendations.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Ontology-based expert system: domain ontology (TBox/ABox), rule-driven inference engine (classic expert-system architecture / OWL-backed knowledge base).</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Supervised ensemble learner (Adaboost) used procedurally to impute or classify input cases prior to symbolic reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Modular/embedded integration: the learner runs as a sub-module whose outputs (imputed values / classifications) are injected into the ontology's ABox so that the inference engine can perform deduction; system-level pipeline coupling (ML -> ABox -> symbolic reasoning).</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Enables the expert system to operate when data are missing or noisy (increased robustness), combines statistical estimation with rule-based explanations from the ontology, and supports end-to-end decision support that neither component alone would perform (automatic imputation + deductive recommendation).</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Clinical decision support / patient treatment recommendation (evaluation on a patient-data repository).</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Paper reports improved practical robustness to missing data by using ML to fill gaps; no quantitative OOD/generalization metrics presented.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Because the core decision process remains an ontology/expert system, the symbolic component can provide rule-based explanations for final recommendations; ML component is used to supply inputs rather than to obfuscate decisions.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Relies on quality of imputations; if ML imputation is wrong, symbolic reasoning can still produce incorrect recommendations; the SLR notes embedded learning can yield reduced performance if ML submodule fails but does not provide measured failure modes.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Division-of-labor / modular hybridization: ML used for perception/data-estimation, symbolic module for explanation and deduction (design pattern aligned to Van Bekkum design pattern 12 / Symbolic[Neuro]).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'C OMBINING M ACHINE L EARNING AND O NTOLOGY : A S YSTEMATIC L ITERATURE R EVIEW', 'publication_date_yy_mm': '2024-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e489.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e489.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>OpenCityDataPipeline</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Open City Data Pipeline (imputation pipeline)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A city-data integration pipeline that uses PCA for preprocessing and then chooses among multiple ML imputation algorithms (MLR, k-NN, Random Forest) to fill missing values before publishing linked open data.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Enriching integrated statistical open city data by combining equational knowledge and missing value imputation</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Open City Data Pipeline</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A hybrid data-publishing pipeline for urban statistical data that integrates an ontology-driven data model and ML-based imputation: PCA is used to preprocess and detect patterns, then one of several ML algorithms imputes missing values; outputs are aligned with an ontology for subsequent publication as linked data.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Ontology for data modelling / ABox/TBox structures used to represent and publish city statistical datasets as linked data.</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Procedural ML pipeline: PCA for feature reduction + multiple imputation algorithms (multiple logistic regression, k-NN, Random Forest) chosen based on performance.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Pipeline integration: ML operates on data preprocessing/imputation stage; resulting completed data are semantically annotated and aligned to the ontology for publication (ML -> ontology population).</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Enables large-scale publishing of coherent linked city data despite missing entries; ML imputation combined with ontology-based coherence checks yields more complete and interoperable datasets than either approach alone.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Missing-value imputation and semantic enrichment of open city statistical datasets (data integration/publishing use-case).</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Improved practical applicability to heterogeneous municipal datasets through ML imputation; no formal OOD experiments reported.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Ontology component supports semantic validation and interpretability of published data; ML choices are selected empirically though not deeply interpretable in the paper's summary.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Quality of semantic output depends on imputation accuracy; consistency management and formal guarantees about ontology coherence after imputation are noted as open challenges in the SLR.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Practical modular hybridization (ML for data completion + ontology for semantic publication) without formal theoretical guarantees reported.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'C OMBINING M ACHINE L EARNING AND O NTOLOGY : A S YSTEMATIC L ITERATURE R EVIEW', 'publication_date_yy_mm': '2024-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e489.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e489.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>HERAKLES</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>HERAKLES (reasoning broker / automatic reasoner selection)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A reasoning broker architecture that uses machine learning classifiers (Naive Bayes, k-NN, SVM, Decision Trees) to select the best OWL reasoner for a given ontology/reasoning task; Decision Tree performed best in reported experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Automatic Reasoner Selection Using Machine Learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>HERAKLES (reasoning broker)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A meta-reasoning broker that predicts which deductive reasoner will perform best on a target ontology and task by extracting features from the ontology and training ML classifiers to choose between reasoners; acts as an orchestrator between symbolic reasoners and a predictive ML selector.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Set of standard OWL/DL inference engines (symbolic reasoners such as Pellet, HermiT) performing full logical deduction.</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Supervised ML classifiers (Naive Bayes, k-NN, SVM, Decision Tree) trained to predict reasoner choice given ontology features.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Meta-modular integration: ML prediction layer selects and dispatches symbolic reasoner; the ML model does not change reasoning internals but chooses the procedural symbolic component best suited for a particular input.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Faster end-to-end reasoning in practice by avoiding worst-case reasoner choices; improved scalability/throughput when a correct reasoner selection is made compared to blind use of a single reasoner.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Reasoner selection for OWL-DL reasoning tasks (meta-reasoning on ontologies).</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Classifier generalizes across ontologies to the extent that features capture ontology complexity; chosen features and classifier determine cross-ontology transfer but detailed OOD metrics are not reported in the SLR.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Decision tree selector was reported to outperform others and is inherently interpretable; symbolic reasoners remain the source of final derivations so explanations remain available from the declarative side.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Prediction errors can select suboptimal reasoners leading to performance loss; requires representative training corpora of ontologies for robust selection; no formal guarantees of selection optimality.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Empirical meta-reasoning approach: treat reasoner choice as a supervised learning problem (feature-based mapping between ontology properties and reasoner performance).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'C OMBINING M ACHINE L EARNING AND O NTOLOGY : A S YSTEMATIC L ITERATURE R EVIEW', 'publication_date_yy_mm': '2024-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e489.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e489.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Predict-Reasoner (Pan et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Predicting Reasoner Performance on ABox Intensive OWL 2 EL Ontologies</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An approach that uses Random Forest with Boruta feature selection to predict runtime performance of OWL reasoners on ABox-intensive ontologies, improving planning and detection of scalability issues.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Predicting Reasoner Performance on ABox Intensive OWL 2 EL Ontologies</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Reasoner Performance Predictor (Random Forest + Boruta)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A predictive model that estimates reasoning time for OWL reasoners on given ontologies by extracting a feature vector representing ontology complexity and training a Random Forest classifier/regressor with Boruta-based feature selection to forecast performance.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>OWL 2 EL ontologies (ABox-heavy) and standard symbolic reasoners whose runtime is being predicted.</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Random Forest machine learning model with Boruta feature-selection pre-processing.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Measurement-and-prediction loop: symbolic reasoners are profiled to produce labels (runtimes), then ML learns mapping from ontology features to runtimes so future scheduling/selection decisions can be made before invoking a reasoner.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Enables preemptive detection of scalability problems and better orchestration of reasoning resources; reduces wasted computation by predicting heavy reasoning tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Prediction of reasoner runtime on ABox-intensive OWL 2 EL ontologies.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Claims improved prediction accuracy for ABox-intensive ontologies using selected features; cross-domain generalization depends on feature representativeness and training set diversity (no numeric OOD results provided in SLR).</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Feature selection (Boruta) identifies influential ontology features, aiding interpretability of what drives reasoner cost; final predictions are ML outputs (less transparent than rules).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Relies on the quality of selected features and training corpus; predictions may fail for ontologies with novel structural properties not seen in training data.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Empirical performance modeling: treat reasoner runtime as predictable function of ontology features using feature selection and ensemble learners.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'C OMBINING M ACHINE L EARNING AND O NTOLOGY : A S YSTEMATIC L ITERATURE R EVIEW', 'publication_date_yy_mm': '2024-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e489.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e489.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Mehri-Opt</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Machine learning-assisted heuristic optimization for OWL reasoners (Mehri et al. 2021)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A method that applies PCA-based feature reduction and SVM classifiers to optimize heuristic choices inside OWL reasoners, aiming to speed up reasoning by reducing complexity and picking heuristics suited to the ontology instance.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>A machine learning approach for optimizing heuristic decisionmaking in Web Ontology Language reasoners</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>ML-assisted Heuristic Optimization for OWL Reasoners</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Uses feature reduction (PCA) to transform ontology features and an SVM (binary classification) to guide heuristic decision-making inside OWL reasoners; goal is to reduce reasoning time by selecting heuristics tuned to an ontology's transformed feature representation.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>OWL ontologies and classical symbolic reasoners whose internal heuristic branches are chosen based on ML predictions.</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Feature reduction (PCA) and an SVM classifier that recommends heuristic settings.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Internal-guidance modular integration: ML decides heuristic settings that alter the procedural reasoning algorithm; not end-to-end differentiable—ML influences symbolic procedure runtime behavior.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Faster practical reasoning on many ontologies by choosing better heuristics than default; better handling of high-dimensional ontology features via PCA preprocessing.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Optimize OWL reasoner heuristic choices to reduce runtime on ontologies (practical performance improvement use-case).</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Empirically effective when ontology features lie in distribution of training data; no formal generalization guarantees presented.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>PCA reduces feature dimensionality (less interpretable) but SVM decisions can be inspected; final inferences remain produced by symbolic reasoner enabling explanation of logical outcomes.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Potential loss of interpretability from PCA; ML-guided heuristics may mislead reasoner for ontologies unlike training set, causing slowdowns.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Heuristic-selection-as-classification: treat internal reasoner choices as labels predicted from ontology-derived features.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'C OMBINING M ACHINE L EARNING AND O NTOLOGY : A S YSTEMATIC L ITERATURE R EVIEW', 'publication_date_yy_mm': '2024-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e489.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e489.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RRN</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Recursive Reasoning Network (RRN)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A neural architecture proposed to perform deductive reasoning by learning to emulate inference steps over ontology-style facts; presented as a means for neural models to perform logic-like deduction.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Ontology Reasoning with Deep Neural Networks</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Recursive Reasoning Network (RRN)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A neural architecture trained on (ontology, entailment) pairs to predict deductive consequences: the RRN recursively composes representations to emulate the process of logical inference and output entailed facts without invoking a symbolic reasoner at runtime.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Encodings of ontology axioms and facts (used as training targets); the system aims to reproduce outputs equivalent to logical deduction but does not execute a symbolic engine at test time.</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Deep neural network architecture (Recursive/recursive-like network) trained to predict logical entailments.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Learning-to-replace integration: neural model is trained on symbolic reasoning outputs and then used as an approximate replacement for the deductive step (Neuro:Symbolic→Neuro pattern).</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Much faster approximate deduction at inference time and resilience to noisy or incomplete inputs compared to exact symbolic reasoners; enables scaling to large knowledge sets where exact reasoning is costly.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Deductive ontology reasoning / entailment prediction tasks (semantic web/ontology datasets).</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Reported to generalize to new inference queries of similar form; SLR notes this approach reduces computational time with large ontologies but does not provide OOD metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Neural predictions are less interpretable than stepwise symbolic proofs; however, training on symbolic outputs ties neural behavior to logical semantics even if internal steps are opaque.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Does not produce formal proofs or guarantees; approximate reasoning may violate logical soundness/complete guarantees and may fail on queries outside training distribution.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Empirical neural emulation of symbolic inference; cast as supervised learning of mapping from facts+axioms to entailed conclusions (no formal decidability guarantees).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'C OMBINING M ACHINE L EARNING AND O NTOLOGY : A S YSTEMATIC L ITERATURE R EVIEW', 'publication_date_yy_mm': '2024-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e489.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e489.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RNN RDFS (Makni & Hendler)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Deep learning for noise-tolerant RDFS reasoning (RNN-based)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A recurrent neural network approach designed to perform RDFS-style reasoning robust to noisy or incomplete input, enabling reasoning in environments where symbolic reasoning struggles with imperfect data.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Deep learning for noise-tolerant RDFS reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>RNN-based Noise-tolerant RDFS Reasoner</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>An RNN trained to perform RDFS inference in the presence of noisy triples; aims to provide robust entailment decisions when raw knowledge bases contain errors or omissions that hinder classical reasoners.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>RDFS ontological schemas and intended entailment relations used as ground-truth for training and evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Recurrent Neural Network (RNN) architecture trained to predict entailments under noise.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Train-to-approximate: the RNN is trained on symbolic inferences (possibly with noisy perturbations) so that the network can produce entailment outputs directly without invoking a symbolic reasoner at test time.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Noise tolerance: the hybrid/neural approach remains functional on corrupted KBs where symbolic reasoners would fail; improved robustness for real-world noisy data.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>RDFS reasoning / entailment under noisy knowledge-bases.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Empirical robustness to noisy inputs; no formal completeness/soundness guarantees and no numeric generalization reported in SLR.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Final entailment outputs can be compared to symbolic expectations, but internal RNN states are opaque; symbolic component can still be used for explanations when available.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Approximate behavior may produce unsound or incomplete inferences; lacks formal logical guarantees and depends on noise distributions seen during training.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Pragmatic robustness approach: replace brittle symbolic reasoning with learned approximations better suited to noisy data.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'C OMBINING M ACHINE L EARNING AND O NTOLOGY : A S YSTEMATIC L ITERATURE R EVIEW', 'publication_date_yy_mm': '2024-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e489.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e489.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LTN</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Logic Tensor Networks (LTN)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A framework integrating fuzzy logical constraints into deep learning by encoding logical formulas as differentiable t-norm-based constraints used within the loss function to guide neural training.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Learning and Reasoning in Logic Tensor Networks: Theory and Application to Semantic Image Interpretation</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Logic Tensor Networks (LTN)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>An architecture that embeds first-order (fuzzy) logical predicates into deep networks by turning logical clauses into continuous loss terms (using t-norm semantics) so that neural weights are learned subject to logical constraints; supports joint learning and reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Fuzzy first-order logic (logical clauses expressed with t-norm semantics) serving as soft constraints / prior knowledge.</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Deep neural networks whose outputs are constrained by additional differentiable logical-loss terms; typical architectures for perceptual tasks (CNNs etc.) are used as the neural backbone.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>End-to-end differentiable integration: logical constraints are converted to continuous losses (via t-norm-based semantics) and combined with standard prediction loss, enabling gradient-based training that enforces logical priors.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Neural models that respect domain logical constraints, improved consistency with symbolic knowledge, enhanced performance on structured output tasks and potential gains in interpretability because predictions must satisfy explicit logical formulas.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Semantic image interpretation and other tasks combining perception with symbolic constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>LTN enforces prior knowledge which can improve generalization when training data are limited or when logic encodes invariant structure; SLR notes potential for better generalization but provides no numeric OOD results.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Logical constraints are explicit and human-understandable, enabling reasoning about why a neural prediction is consistent/inconsistent with domain rules; still, internal neural representations remain opaque.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Trade-offs between constraint strength and learnability; fuzzy relaxation may lead to soft satisfaction of rules (no strict guarantees); scaling to complex logics/large rule sets may be difficult.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Differentiable fuzzy-logic embedding: use t-norm semantics to make logic amenable to gradient-based learning, merging symbolic constraints and neural optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'C OMBINING M ACHINE L EARNING AND O NTOLOGY : A S YSTEMATIC L ITERATURE R EVIEW', 'publication_date_yy_mm': '2024-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e489.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e489.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Terminological DTs (Rizzo et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Terminological decision trees / tree-based inductive models for Semantic Web reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Use of decision-tree based models (e.g., Random Forest) to assist or drive terminological classification and inductive tasks on Web-of-Data entities, enabling inductively derived conceptual classifiers compatible with ontological schemas.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Tree-based models for inductive classification on the Web Of Data</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Terminological Decision Trees / Tree-based Inductive Classification</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>An approach that constructs decision-tree ensembles that operate over Web-of-Data features to perform inductive classification aligned with ontological concepts (terminologies), producing classifiers that can augment or complement deductive reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Ontology terminology / TBox structure used as target labels and to interpret classification outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Decision tree classifiers and Random Forest ensembles trained on web-of-data features.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Symbolic labels / ontology classes are used as supervision for tree-based learning; learned classifiers then provide ABox assertions or concept assignments which can be consumed by symbolic reasoning engines (ML -> ABox -> symbolic).</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Fast inductive classification over large web datasets, ability to propose candidate ABox assertions at scale that can feed into symbolic workflows, and explainable decision paths from trees that correspond to concept membership.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Inductive classification on Web-of-Data / semantic web datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Tree ensembles give robust predictive performance across seen categories; generalization to unseen ontological concepts depends on labeled training coverage.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Decision-tree-based classifiers provide human-readable paths which aid inspection and linking to ontological concepts; supports traceability of inductive assignments.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Inductive classifiers require labeled examples for each concept; they may propose noisy ABox assertions that require consistency checking when integrated into ontologies.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'C OMBINING M ACHINE L EARNING AND O NTOLOGY : A S YSTEMATIC L ITERATURE R EVIEW', 'publication_date_yy_mm': '2024-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e489.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e489.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Hybrid Application (Design Pattern 12)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Hybrid application systems (Modular Design Pattern 12)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A modular hybrid AI design pattern where multiple interconnected modules (learning and symbolic) communicate (coroutines) to solve applied tasks by combining perception (ML) and symbolic problem solving (ontologies/inference).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Modular Design Patterns for Hybrid Learning and Reasoning Systems: a taxonomy, patterns and use cases</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Hybrid Application Systems (Design Pattern 12)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A class of applied systems composed of separate learning modules (e.g., neural networks for perception, classifiers) and symbolic modules (ontologies/inference engines) that exchange data (often ML outputs added to ontology ABox) and coordinate to perform tasks such as event detection, planning, or decision support; exemplified by smart-city, NLP, and vision applications in the SLR.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Ontologies and rule-based inference engines (TBox/ABox representations, OWL/SWRL where used) providing structured domain knowledge and deductive reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Various procedural ML components (CNNs, RNNs, LSTMs, YOLO, Random Forests, SVMs) used for perception, classification, or imputation.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Modular pipeline / coroutine-based interaction: ML modules produce structured outputs inserted into ontologies (ABox population), symbolic module performs deduction/semantic processing, and results may feedback to retrain or constrain ML components (bidirectional interaction in some cases).</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Synergy between perceptual robustness of ML and explainability/consistency checking of symbolic reasoning, enabling practical, explainable hybrid applications (e.g., video surveillance anomaly detection with YOLO + ontology reasoning).</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Applied tasks across domains: NLP (ATC message translation), computer vision (traffic control, anomaly detection), smart-city data integration, etc.; no single benchmark is universal.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Hybrid modular systems claim better reliability across heterogeneous, noisy real-world data and improved reusability across domains; no uniform quantitative comparison provided in SLR.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Symbolic module enables explanations, constraints, and semantic validation of ML outputs; post-hoc explainability benefits from ontology structure (global and local explainability examples cited).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Integration complexity, synchronization of heterogeneous modules, consistency management during ontology population, and lack of formal expressiveness/decidability guarantees for learned extensions are highlighted as major challenges.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Design-pattern-based taxonomy (Van Bekkum et al. mappings + Kautz neuro-symbolic taxonomy) framing hybrid systems as modular compositions of learning and reasoning components with division-of-labor.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'C OMBINING M ACHINE L EARNING AND O NTOLOGY : A S YSTEMATIC L ITERATURE R EVIEW', 'publication_date_yy_mm': '2024-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Ontology Reasoning with Deep Neural Networks <em>(Rating: 2)</em></li>
                <li>Deep learning for noise-tolerant RDFS reasoning <em>(Rating: 2)</em></li>
                <li>Learning and Reasoning in Logic Tensor Networks: Theory and Application to Semantic Image Interpretation <em>(Rating: 2)</em></li>
                <li>Automatic Reasoner Selection Using Machine Learning <em>(Rating: 2)</em></li>
                <li>Predicting Reasoner Performance on ABox Intensive OWL 2 EL Ontologies <em>(Rating: 2)</em></li>
                <li>A machine learning approach for optimizing heuristic decisionmaking in Web Ontology Language reasoners <em>(Rating: 2)</em></li>
                <li>Validation of an Ontological Medical Decision Support System for Patient Treatment Using a Repository of Patient Data: Insights into the Value of Machine Learning <em>(Rating: 2)</em></li>
                <li>Enriching integrated statistical open city data by combining equational knowledge and missing value imputation <em>(Rating: 2)</em></li>
                <li>Tree-based models for inductive classification on the Web Of Data <em>(Rating: 1)</em></li>
                <li>Modular Design Patterns for Hybrid Learning and Reasoning Systems: a taxonomy, patterns and use cases <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-489",
    "paper_id": "paper-266998835",
    "extraction_schema_id": "extraction-schema-17",
    "extracted_data": [
        {
            "name_short": "Holmes",
            "name_full": "Holmes (Hybrid Ontological and Learning MEdical System)",
            "brief_description": "A medical decision-support hybrid system that embeds machine learning (Adaboost) inside an ontology-backed expert system to impute missing values and support patient treatment decisions.",
            "citation_title": "Validation of an Ontological Medical Decision Support System for Patient Treatment Using a Repository of Patient Data: Insights into the Value of Machine Learning",
            "mention_or_use": "mention",
            "system_name": "Holmes (Hybrid Ontological and Learning MEdical System)",
            "system_description": "An expert-system style clinical decision support application that integrates an ontology (knowledge base + inference engine) with an embedded supervised learner (Adaboost). Machine learning is used as a subsystem to estimate missing clinical inputs or to provide evidence used by the symbolic reasoning module, allowing the expert system to perform deductive inference for treatment recommendations.",
            "declarative_component": "Ontology-based expert system: domain ontology (TBox/ABox), rule-driven inference engine (classic expert-system architecture / OWL-backed knowledge base).",
            "imperative_component": "Supervised ensemble learner (Adaboost) used procedurally to impute or classify input cases prior to symbolic reasoning.",
            "integration_method": "Modular/embedded integration: the learner runs as a sub-module whose outputs (imputed values / classifications) are injected into the ontology's ABox so that the inference engine can perform deduction; system-level pipeline coupling (ML -&gt; ABox -&gt; symbolic reasoning).",
            "emergent_properties": "Enables the expert system to operate when data are missing or noisy (increased robustness), combines statistical estimation with rule-based explanations from the ontology, and supports end-to-end decision support that neither component alone would perform (automatic imputation + deductive recommendation).",
            "task_or_benchmark": "Clinical decision support / patient treatment recommendation (evaluation on a patient-data repository).",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Paper reports improved practical robustness to missing data by using ML to fill gaps; no quantitative OOD/generalization metrics presented.",
            "interpretability_properties": "Because the core decision process remains an ontology/expert system, the symbolic component can provide rule-based explanations for final recommendations; ML component is used to supply inputs rather than to obfuscate decisions.",
            "limitations_or_failures": "Relies on quality of imputations; if ML imputation is wrong, symbolic reasoning can still produce incorrect recommendations; the SLR notes embedded learning can yield reduced performance if ML submodule fails but does not provide measured failure modes.",
            "theoretical_framework": "Division-of-labor / modular hybridization: ML used for perception/data-estimation, symbolic module for explanation and deduction (design pattern aligned to Van Bekkum design pattern 12 / Symbolic[Neuro]).",
            "uuid": "e489.0",
            "source_info": {
                "paper_title": "C OMBINING M ACHINE L EARNING AND O NTOLOGY : A S YSTEMATIC L ITERATURE R EVIEW",
                "publication_date_yy_mm": "2024-01"
            }
        },
        {
            "name_short": "OpenCityDataPipeline",
            "name_full": "Open City Data Pipeline (imputation pipeline)",
            "brief_description": "A city-data integration pipeline that uses PCA for preprocessing and then chooses among multiple ML imputation algorithms (MLR, k-NN, Random Forest) to fill missing values before publishing linked open data.",
            "citation_title": "Enriching integrated statistical open city data by combining equational knowledge and missing value imputation",
            "mention_or_use": "mention",
            "system_name": "Open City Data Pipeline",
            "system_description": "A hybrid data-publishing pipeline for urban statistical data that integrates an ontology-driven data model and ML-based imputation: PCA is used to preprocess and detect patterns, then one of several ML algorithms imputes missing values; outputs are aligned with an ontology for subsequent publication as linked data.",
            "declarative_component": "Ontology for data modelling / ABox/TBox structures used to represent and publish city statistical datasets as linked data.",
            "imperative_component": "Procedural ML pipeline: PCA for feature reduction + multiple imputation algorithms (multiple logistic regression, k-NN, Random Forest) chosen based on performance.",
            "integration_method": "Pipeline integration: ML operates on data preprocessing/imputation stage; resulting completed data are semantically annotated and aligned to the ontology for publication (ML -&gt; ontology population).",
            "emergent_properties": "Enables large-scale publishing of coherent linked city data despite missing entries; ML imputation combined with ontology-based coherence checks yields more complete and interoperable datasets than either approach alone.",
            "task_or_benchmark": "Missing-value imputation and semantic enrichment of open city statistical datasets (data integration/publishing use-case).",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Improved practical applicability to heterogeneous municipal datasets through ML imputation; no formal OOD experiments reported.",
            "interpretability_properties": "Ontology component supports semantic validation and interpretability of published data; ML choices are selected empirically though not deeply interpretable in the paper's summary.",
            "limitations_or_failures": "Quality of semantic output depends on imputation accuracy; consistency management and formal guarantees about ontology coherence after imputation are noted as open challenges in the SLR.",
            "theoretical_framework": "Practical modular hybridization (ML for data completion + ontology for semantic publication) without formal theoretical guarantees reported.",
            "uuid": "e489.1",
            "source_info": {
                "paper_title": "C OMBINING M ACHINE L EARNING AND O NTOLOGY : A S YSTEMATIC L ITERATURE R EVIEW",
                "publication_date_yy_mm": "2024-01"
            }
        },
        {
            "name_short": "HERAKLES",
            "name_full": "HERAKLES (reasoning broker / automatic reasoner selection)",
            "brief_description": "A reasoning broker architecture that uses machine learning classifiers (Naive Bayes, k-NN, SVM, Decision Trees) to select the best OWL reasoner for a given ontology/reasoning task; Decision Tree performed best in reported experiments.",
            "citation_title": "Automatic Reasoner Selection Using Machine Learning",
            "mention_or_use": "mention",
            "system_name": "HERAKLES (reasoning broker)",
            "system_description": "A meta-reasoning broker that predicts which deductive reasoner will perform best on a target ontology and task by extracting features from the ontology and training ML classifiers to choose between reasoners; acts as an orchestrator between symbolic reasoners and a predictive ML selector.",
            "declarative_component": "Set of standard OWL/DL inference engines (symbolic reasoners such as Pellet, HermiT) performing full logical deduction.",
            "imperative_component": "Supervised ML classifiers (Naive Bayes, k-NN, SVM, Decision Tree) trained to predict reasoner choice given ontology features.",
            "integration_method": "Meta-modular integration: ML prediction layer selects and dispatches symbolic reasoner; the ML model does not change reasoning internals but chooses the procedural symbolic component best suited for a particular input.",
            "emergent_properties": "Faster end-to-end reasoning in practice by avoiding worst-case reasoner choices; improved scalability/throughput when a correct reasoner selection is made compared to blind use of a single reasoner.",
            "task_or_benchmark": "Reasoner selection for OWL-DL reasoning tasks (meta-reasoning on ontologies).",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": true,
            "generalization_properties": "Classifier generalizes across ontologies to the extent that features capture ontology complexity; chosen features and classifier determine cross-ontology transfer but detailed OOD metrics are not reported in the SLR.",
            "interpretability_properties": "Decision tree selector was reported to outperform others and is inherently interpretable; symbolic reasoners remain the source of final derivations so explanations remain available from the declarative side.",
            "limitations_or_failures": "Prediction errors can select suboptimal reasoners leading to performance loss; requires representative training corpora of ontologies for robust selection; no formal guarantees of selection optimality.",
            "theoretical_framework": "Empirical meta-reasoning approach: treat reasoner choice as a supervised learning problem (feature-based mapping between ontology properties and reasoner performance).",
            "uuid": "e489.2",
            "source_info": {
                "paper_title": "C OMBINING M ACHINE L EARNING AND O NTOLOGY : A S YSTEMATIC L ITERATURE R EVIEW",
                "publication_date_yy_mm": "2024-01"
            }
        },
        {
            "name_short": "Predict-Reasoner (Pan et al.)",
            "name_full": "Predicting Reasoner Performance on ABox Intensive OWL 2 EL Ontologies",
            "brief_description": "An approach that uses Random Forest with Boruta feature selection to predict runtime performance of OWL reasoners on ABox-intensive ontologies, improving planning and detection of scalability issues.",
            "citation_title": "Predicting Reasoner Performance on ABox Intensive OWL 2 EL Ontologies",
            "mention_or_use": "mention",
            "system_name": "Reasoner Performance Predictor (Random Forest + Boruta)",
            "system_description": "A predictive model that estimates reasoning time for OWL reasoners on given ontologies by extracting a feature vector representing ontology complexity and training a Random Forest classifier/regressor with Boruta-based feature selection to forecast performance.",
            "declarative_component": "OWL 2 EL ontologies (ABox-heavy) and standard symbolic reasoners whose runtime is being predicted.",
            "imperative_component": "Random Forest machine learning model with Boruta feature-selection pre-processing.",
            "integration_method": "Measurement-and-prediction loop: symbolic reasoners are profiled to produce labels (runtimes), then ML learns mapping from ontology features to runtimes so future scheduling/selection decisions can be made before invoking a reasoner.",
            "emergent_properties": "Enables preemptive detection of scalability problems and better orchestration of reasoning resources; reduces wasted computation by predicting heavy reasoning tasks.",
            "task_or_benchmark": "Prediction of reasoner runtime on ABox-intensive OWL 2 EL ontologies.",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": true,
            "generalization_properties": "Claims improved prediction accuracy for ABox-intensive ontologies using selected features; cross-domain generalization depends on feature representativeness and training set diversity (no numeric OOD results provided in SLR).",
            "interpretability_properties": "Feature selection (Boruta) identifies influential ontology features, aiding interpretability of what drives reasoner cost; final predictions are ML outputs (less transparent than rules).",
            "limitations_or_failures": "Relies on the quality of selected features and training corpus; predictions may fail for ontologies with novel structural properties not seen in training data.",
            "theoretical_framework": "Empirical performance modeling: treat reasoner runtime as predictable function of ontology features using feature selection and ensemble learners.",
            "uuid": "e489.3",
            "source_info": {
                "paper_title": "C OMBINING M ACHINE L EARNING AND O NTOLOGY : A S YSTEMATIC L ITERATURE R EVIEW",
                "publication_date_yy_mm": "2024-01"
            }
        },
        {
            "name_short": "Mehri-Opt",
            "name_full": "Machine learning-assisted heuristic optimization for OWL reasoners (Mehri et al. 2021)",
            "brief_description": "A method that applies PCA-based feature reduction and SVM classifiers to optimize heuristic choices inside OWL reasoners, aiming to speed up reasoning by reducing complexity and picking heuristics suited to the ontology instance.",
            "citation_title": "A machine learning approach for optimizing heuristic decisionmaking in Web Ontology Language reasoners",
            "mention_or_use": "mention",
            "system_name": "ML-assisted Heuristic Optimization for OWL Reasoners",
            "system_description": "Uses feature reduction (PCA) to transform ontology features and an SVM (binary classification) to guide heuristic decision-making inside OWL reasoners; goal is to reduce reasoning time by selecting heuristics tuned to an ontology's transformed feature representation.",
            "declarative_component": "OWL ontologies and classical symbolic reasoners whose internal heuristic branches are chosen based on ML predictions.",
            "imperative_component": "Feature reduction (PCA) and an SVM classifier that recommends heuristic settings.",
            "integration_method": "Internal-guidance modular integration: ML decides heuristic settings that alter the procedural reasoning algorithm; not end-to-end differentiable—ML influences symbolic procedure runtime behavior.",
            "emergent_properties": "Faster practical reasoning on many ontologies by choosing better heuristics than default; better handling of high-dimensional ontology features via PCA preprocessing.",
            "task_or_benchmark": "Optimize OWL reasoner heuristic choices to reduce runtime on ontologies (practical performance improvement use-case).",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": true,
            "generalization_properties": "Empirically effective when ontology features lie in distribution of training data; no formal generalization guarantees presented.",
            "interpretability_properties": "PCA reduces feature dimensionality (less interpretable) but SVM decisions can be inspected; final inferences remain produced by symbolic reasoner enabling explanation of logical outcomes.",
            "limitations_or_failures": "Potential loss of interpretability from PCA; ML-guided heuristics may mislead reasoner for ontologies unlike training set, causing slowdowns.",
            "theoretical_framework": "Heuristic-selection-as-classification: treat internal reasoner choices as labels predicted from ontology-derived features.",
            "uuid": "e489.4",
            "source_info": {
                "paper_title": "C OMBINING M ACHINE L EARNING AND O NTOLOGY : A S YSTEMATIC L ITERATURE R EVIEW",
                "publication_date_yy_mm": "2024-01"
            }
        },
        {
            "name_short": "RRN",
            "name_full": "Recursive Reasoning Network (RRN)",
            "brief_description": "A neural architecture proposed to perform deductive reasoning by learning to emulate inference steps over ontology-style facts; presented as a means for neural models to perform logic-like deduction.",
            "citation_title": "Ontology Reasoning with Deep Neural Networks",
            "mention_or_use": "mention",
            "system_name": "Recursive Reasoning Network (RRN)",
            "system_description": "A neural architecture trained on (ontology, entailment) pairs to predict deductive consequences: the RRN recursively composes representations to emulate the process of logical inference and output entailed facts without invoking a symbolic reasoner at runtime.",
            "declarative_component": "Encodings of ontology axioms and facts (used as training targets); the system aims to reproduce outputs equivalent to logical deduction but does not execute a symbolic engine at test time.",
            "imperative_component": "Deep neural network architecture (Recursive/recursive-like network) trained to predict logical entailments.",
            "integration_method": "Learning-to-replace integration: neural model is trained on symbolic reasoning outputs and then used as an approximate replacement for the deductive step (Neuro:Symbolic→Neuro pattern).",
            "emergent_properties": "Much faster approximate deduction at inference time and resilience to noisy or incomplete inputs compared to exact symbolic reasoners; enables scaling to large knowledge sets where exact reasoning is costly.",
            "task_or_benchmark": "Deductive ontology reasoning / entailment prediction tasks (semantic web/ontology datasets).",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Reported to generalize to new inference queries of similar form; SLR notes this approach reduces computational time with large ontologies but does not provide OOD metrics.",
            "interpretability_properties": "Neural predictions are less interpretable than stepwise symbolic proofs; however, training on symbolic outputs ties neural behavior to logical semantics even if internal steps are opaque.",
            "limitations_or_failures": "Does not produce formal proofs or guarantees; approximate reasoning may violate logical soundness/complete guarantees and may fail on queries outside training distribution.",
            "theoretical_framework": "Empirical neural emulation of symbolic inference; cast as supervised learning of mapping from facts+axioms to entailed conclusions (no formal decidability guarantees).",
            "uuid": "e489.5",
            "source_info": {
                "paper_title": "C OMBINING M ACHINE L EARNING AND O NTOLOGY : A S YSTEMATIC L ITERATURE R EVIEW",
                "publication_date_yy_mm": "2024-01"
            }
        },
        {
            "name_short": "RNN RDFS (Makni & Hendler)",
            "name_full": "Deep learning for noise-tolerant RDFS reasoning (RNN-based)",
            "brief_description": "A recurrent neural network approach designed to perform RDFS-style reasoning robust to noisy or incomplete input, enabling reasoning in environments where symbolic reasoning struggles with imperfect data.",
            "citation_title": "Deep learning for noise-tolerant RDFS reasoning",
            "mention_or_use": "mention",
            "system_name": "RNN-based Noise-tolerant RDFS Reasoner",
            "system_description": "An RNN trained to perform RDFS inference in the presence of noisy triples; aims to provide robust entailment decisions when raw knowledge bases contain errors or omissions that hinder classical reasoners.",
            "declarative_component": "RDFS ontological schemas and intended entailment relations used as ground-truth for training and evaluation.",
            "imperative_component": "Recurrent Neural Network (RNN) architecture trained to predict entailments under noise.",
            "integration_method": "Train-to-approximate: the RNN is trained on symbolic inferences (possibly with noisy perturbations) so that the network can produce entailment outputs directly without invoking a symbolic reasoner at test time.",
            "emergent_properties": "Noise tolerance: the hybrid/neural approach remains functional on corrupted KBs where symbolic reasoners would fail; improved robustness for real-world noisy data.",
            "task_or_benchmark": "RDFS reasoning / entailment under noisy knowledge-bases.",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Empirical robustness to noisy inputs; no formal completeness/soundness guarantees and no numeric generalization reported in SLR.",
            "interpretability_properties": "Final entailment outputs can be compared to symbolic expectations, but internal RNN states are opaque; symbolic component can still be used for explanations when available.",
            "limitations_or_failures": "Approximate behavior may produce unsound or incomplete inferences; lacks formal logical guarantees and depends on noise distributions seen during training.",
            "theoretical_framework": "Pragmatic robustness approach: replace brittle symbolic reasoning with learned approximations better suited to noisy data.",
            "uuid": "e489.6",
            "source_info": {
                "paper_title": "C OMBINING M ACHINE L EARNING AND O NTOLOGY : A S YSTEMATIC L ITERATURE R EVIEW",
                "publication_date_yy_mm": "2024-01"
            }
        },
        {
            "name_short": "LTN",
            "name_full": "Logic Tensor Networks (LTN)",
            "brief_description": "A framework integrating fuzzy logical constraints into deep learning by encoding logical formulas as differentiable t-norm-based constraints used within the loss function to guide neural training.",
            "citation_title": "Learning and Reasoning in Logic Tensor Networks: Theory and Application to Semantic Image Interpretation",
            "mention_or_use": "mention",
            "system_name": "Logic Tensor Networks (LTN)",
            "system_description": "An architecture that embeds first-order (fuzzy) logical predicates into deep networks by turning logical clauses into continuous loss terms (using t-norm semantics) so that neural weights are learned subject to logical constraints; supports joint learning and reasoning.",
            "declarative_component": "Fuzzy first-order logic (logical clauses expressed with t-norm semantics) serving as soft constraints / prior knowledge.",
            "imperative_component": "Deep neural networks whose outputs are constrained by additional differentiable logical-loss terms; typical architectures for perceptual tasks (CNNs etc.) are used as the neural backbone.",
            "integration_method": "End-to-end differentiable integration: logical constraints are converted to continuous losses (via t-norm-based semantics) and combined with standard prediction loss, enabling gradient-based training that enforces logical priors.",
            "emergent_properties": "Neural models that respect domain logical constraints, improved consistency with symbolic knowledge, enhanced performance on structured output tasks and potential gains in interpretability because predictions must satisfy explicit logical formulas.",
            "task_or_benchmark": "Semantic image interpretation and other tasks combining perception with symbolic constraints.",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "LTN enforces prior knowledge which can improve generalization when training data are limited or when logic encodes invariant structure; SLR notes potential for better generalization but provides no numeric OOD results.",
            "interpretability_properties": "Logical constraints are explicit and human-understandable, enabling reasoning about why a neural prediction is consistent/inconsistent with domain rules; still, internal neural representations remain opaque.",
            "limitations_or_failures": "Trade-offs between constraint strength and learnability; fuzzy relaxation may lead to soft satisfaction of rules (no strict guarantees); scaling to complex logics/large rule sets may be difficult.",
            "theoretical_framework": "Differentiable fuzzy-logic embedding: use t-norm semantics to make logic amenable to gradient-based learning, merging symbolic constraints and neural optimization.",
            "uuid": "e489.7",
            "source_info": {
                "paper_title": "C OMBINING M ACHINE L EARNING AND O NTOLOGY : A S YSTEMATIC L ITERATURE R EVIEW",
                "publication_date_yy_mm": "2024-01"
            }
        },
        {
            "name_short": "Terminological DTs (Rizzo et al.)",
            "name_full": "Terminological decision trees / tree-based inductive models for Semantic Web reasoning",
            "brief_description": "Use of decision-tree based models (e.g., Random Forest) to assist or drive terminological classification and inductive tasks on Web-of-Data entities, enabling inductively derived conceptual classifiers compatible with ontological schemas.",
            "citation_title": "Tree-based models for inductive classification on the Web Of Data",
            "mention_or_use": "mention",
            "system_name": "Terminological Decision Trees / Tree-based Inductive Classification",
            "system_description": "An approach that constructs decision-tree ensembles that operate over Web-of-Data features to perform inductive classification aligned with ontological concepts (terminologies), producing classifiers that can augment or complement deductive reasoning.",
            "declarative_component": "Ontology terminology / TBox structure used as target labels and to interpret classification outputs.",
            "imperative_component": "Decision tree classifiers and Random Forest ensembles trained on web-of-data features.",
            "integration_method": "Symbolic labels / ontology classes are used as supervision for tree-based learning; learned classifiers then provide ABox assertions or concept assignments which can be consumed by symbolic reasoning engines (ML -&gt; ABox -&gt; symbolic).",
            "emergent_properties": "Fast inductive classification over large web datasets, ability to propose candidate ABox assertions at scale that can feed into symbolic workflows, and explainable decision paths from trees that correspond to concept membership.",
            "task_or_benchmark": "Inductive classification on Web-of-Data / semantic web datasets.",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Tree ensembles give robust predictive performance across seen categories; generalization to unseen ontological concepts depends on labeled training coverage.",
            "interpretability_properties": "Decision-tree-based classifiers provide human-readable paths which aid inspection and linking to ontological concepts; supports traceability of inductive assignments.",
            "limitations_or_failures": "Inductive classifiers require labeled examples for each concept; they may propose noisy ABox assertions that require consistency checking when integrated into ontologies.",
            "uuid": "e489.8",
            "source_info": {
                "paper_title": "C OMBINING M ACHINE L EARNING AND O NTOLOGY : A S YSTEMATIC L ITERATURE R EVIEW",
                "publication_date_yy_mm": "2024-01"
            }
        },
        {
            "name_short": "Hybrid Application (Design Pattern 12)",
            "name_full": "Hybrid application systems (Modular Design Pattern 12)",
            "brief_description": "A modular hybrid AI design pattern where multiple interconnected modules (learning and symbolic) communicate (coroutines) to solve applied tasks by combining perception (ML) and symbolic problem solving (ontologies/inference).",
            "citation_title": "Modular Design Patterns for Hybrid Learning and Reasoning Systems: a taxonomy, patterns and use cases",
            "mention_or_use": "mention",
            "system_name": "Hybrid Application Systems (Design Pattern 12)",
            "system_description": "A class of applied systems composed of separate learning modules (e.g., neural networks for perception, classifiers) and symbolic modules (ontologies/inference engines) that exchange data (often ML outputs added to ontology ABox) and coordinate to perform tasks such as event detection, planning, or decision support; exemplified by smart-city, NLP, and vision applications in the SLR.",
            "declarative_component": "Ontologies and rule-based inference engines (TBox/ABox representations, OWL/SWRL where used) providing structured domain knowledge and deductive reasoning.",
            "imperative_component": "Various procedural ML components (CNNs, RNNs, LSTMs, YOLO, Random Forests, SVMs) used for perception, classification, or imputation.",
            "integration_method": "Modular pipeline / coroutine-based interaction: ML modules produce structured outputs inserted into ontologies (ABox population), symbolic module performs deduction/semantic processing, and results may feedback to retrain or constrain ML components (bidirectional interaction in some cases).",
            "emergent_properties": "Synergy between perceptual robustness of ML and explainability/consistency checking of symbolic reasoning, enabling practical, explainable hybrid applications (e.g., video surveillance anomaly detection with YOLO + ontology reasoning).",
            "task_or_benchmark": "Applied tasks across domains: NLP (ATC message translation), computer vision (traffic control, anomaly detection), smart-city data integration, etc.; no single benchmark is universal.",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Hybrid modular systems claim better reliability across heterogeneous, noisy real-world data and improved reusability across domains; no uniform quantitative comparison provided in SLR.",
            "interpretability_properties": "Symbolic module enables explanations, constraints, and semantic validation of ML outputs; post-hoc explainability benefits from ontology structure (global and local explainability examples cited).",
            "limitations_or_failures": "Integration complexity, synchronization of heterogeneous modules, consistency management during ontology population, and lack of formal expressiveness/decidability guarantees for learned extensions are highlighted as major challenges.",
            "theoretical_framework": "Design-pattern-based taxonomy (Van Bekkum et al. mappings + Kautz neuro-symbolic taxonomy) framing hybrid systems as modular compositions of learning and reasoning components with division-of-labor.",
            "uuid": "e489.9",
            "source_info": {
                "paper_title": "C OMBINING M ACHINE L EARNING AND O NTOLOGY : A S YSTEMATIC L ITERATURE R EVIEW",
                "publication_date_yy_mm": "2024-01"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Ontology Reasoning with Deep Neural Networks",
            "rating": 2,
            "sanitized_title": "ontology_reasoning_with_deep_neural_networks"
        },
        {
            "paper_title": "Deep learning for noise-tolerant RDFS reasoning",
            "rating": 2,
            "sanitized_title": "deep_learning_for_noisetolerant_rdfs_reasoning"
        },
        {
            "paper_title": "Learning and Reasoning in Logic Tensor Networks: Theory and Application to Semantic Image Interpretation",
            "rating": 2,
            "sanitized_title": "learning_and_reasoning_in_logic_tensor_networks_theory_and_application_to_semantic_image_interpretation"
        },
        {
            "paper_title": "Automatic Reasoner Selection Using Machine Learning",
            "rating": 2,
            "sanitized_title": "automatic_reasoner_selection_using_machine_learning"
        },
        {
            "paper_title": "Predicting Reasoner Performance on ABox Intensive OWL 2 EL Ontologies",
            "rating": 2,
            "sanitized_title": "predicting_reasoner_performance_on_abox_intensive_owl_2_el_ontologies"
        },
        {
            "paper_title": "A machine learning approach for optimizing heuristic decisionmaking in Web Ontology Language reasoners",
            "rating": 2,
            "sanitized_title": "a_machine_learning_approach_for_optimizing_heuristic_decisionmaking_in_web_ontology_language_reasoners"
        },
        {
            "paper_title": "Validation of an Ontological Medical Decision Support System for Patient Treatment Using a Repository of Patient Data: Insights into the Value of Machine Learning",
            "rating": 2,
            "sanitized_title": "validation_of_an_ontological_medical_decision_support_system_for_patient_treatment_using_a_repository_of_patient_data_insights_into_the_value_of_machine_learning"
        },
        {
            "paper_title": "Enriching integrated statistical open city data by combining equational knowledge and missing value imputation",
            "rating": 2,
            "sanitized_title": "enriching_integrated_statistical_open_city_data_by_combining_equational_knowledge_and_missing_value_imputation"
        },
        {
            "paper_title": "Tree-based models for inductive classification on the Web Of Data",
            "rating": 1,
            "sanitized_title": "treebased_models_for_inductive_classification_on_the_web_of_data"
        },
        {
            "paper_title": "Modular Design Patterns for Hybrid Learning and Reasoning Systems: a taxonomy, patterns and use cases",
            "rating": 2,
            "sanitized_title": "modular_design_patterns_for_hybrid_learning_and_reasoning_systems_a_taxonomy_patterns_and_use_cases"
        }
    ],
    "cost": 0.024611749999999998,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Combining Machine Learning and Ontology: A Systematic Literature Review
February 19, 2024</p>
<p>Sarah Ghidalia sarah.ghidalia@u-bourgogne.fr 
Ouassila Labbani Narsis ouassila.narsis@u-bourgogne.fr 
Aurélie Bertaux aurelie.bertaux@u-bourgogne.fr 
Christophe Nicolle christophe.nicolle@u-bourgogne.fr 
A Preprint </p>
<p>UMR 7533
CIAD</p>
<p>Université de Bourgogne
F-21000DijonUBFrance</p>
<p>UMR 7533
CIAD</p>
<p>Université de Bourgogne
F-21000DijonUBFrance</p>
<p>UMR 7533
CIAD</p>
<p>Université de Bourgogne
F-21000DijonUBFrance</p>
<p>UMR 7533
CIAD</p>
<p>Université de Bourgogne
F-21000DijonUBFrance</p>
<p>Combining Machine Learning and Ontology: A Systematic Literature Review
February 19, 2024DFCE61E1896912DEDCAC0FAF328097A5arXiv:2401.07744v2[cs.AI]machine learningontologyartificial reasoninghybrid reasoning
Motivated to explore the process of combining inductive and deductive reasoning, we conducted a systematic literature review of articles investigating the integration of machine learning and ontologies.The objective was to identify diverse techniques incorporating inductive reasoning (performed by machine learning) and deductive reasoning (performed by ontologies) into artificial intelligence systems.Our review, which included the analysis of 128 studies, allowed us to identify three main categories of hybridization between machine learning and ontologies: learning-enhanced ontologies, semantic data mining, and learning and reasoning systems.We provide a comprehensive examination of all these categories, emphasizing the various machine learning algorithms utilized in the studies.Furthermore, we compared our classification with similar recent work in the field of hybrid AI and neuro-symbolic approaches.</p>
<p>Introduction</p>
<p>Artificial intelligence (AI) has become part of our daily lives, transforming every economic sector, from industry 4.0 to healthcare and smart cities.However, there is still a lack of consensus among researchers regarding the precise definition of AI, a term coined more than half a century ago [Nilsson, 2009, Wang, 2019].For example, Minsky [1986] suggests that AI refers to the capability of machines to solve complex problems.Dobrev [2012] compares AI to human beings, defining it as a program which in an arbitrary world will cope not worse than a human, which recalls the original definition of McCarthy et al. [1955].On the other hand, Kaplan and Haenlein [2019] defines AI as a system's ability to correctly interpret external data, to learn from such data, and to use those learnings to achieve specific goals and tasks through flexible adaptation, potentially narrowing AI to the realm of machine learning.Alternatively, Wang [2019] emphasizes AI's capability to adapt to its environment, even with limited knowledge and resources.Another perspective, similar to Russell and Norvig [2009]'s, suggests defining AI as the scientific field that enables machines to perceive, understand, and interact with the real world in a way that is very close to human beings.</p>
<p>To understand this perspective, we can call upon the allegory of the cave exposed by Plato [1888].Like the prisoners chained to the bottom of the cave, who only perceive shadows and echoes of the intelligible world, machines have a perception of our world limited to the data they are provided.How can we enable machines to have an impact on the tangible world if they can't make sense of the various aspects, complexities, and nuances of the real world?Gradually, we would have to get machines out of the cave in which they are chained.The initial step involves imparting problem-solving thinking abilities to machines.In this endeavor, the human cognitive process primarily relies on two forms of reasoning: induction and deduction.Inductive reasoning facilitates the discovery of general knowledge (such as laws, theorems, correlations, etc.) from specific observations.Deductive reasoning, on the other hand, permits the application of pre-existing general knowledge to specific instances [Rafanelli et al., 2022].In the 19th century, Charles Sanders Peirce identified a third type of reasoning called abduction, which is employed to generate hypotheses that explain specific observations [Roudaut, 2017, Rafanelli et al., 2022].Abduction holds substantial scientific significance as it pertains to issues of causality, explainable artificial intelligence (XAI), and potentially even trustworthiness.However, this study will not focus on abduction, but rather on the combination of inductive and deductive reasoning for problem-solving purposes.Nevertheless, the matter of explainability remains intriguing and will be addressed in the study's conclusion.</p>
<p>Socrates, Plato's disciple, defines induction as a way of reasoning that consists in drawing a general conclusion from several particular cases.Inductive reasoning is a form of ampliative reasoning, i.e. one draws conclusions that go beyond the information contained in the premises [Roudaut, 2017].Inductive reasoning is close to mechanisms of machine learning: establishing a reasoning (model) from explicit facts (experiments).Thus, the model is not explicitly written, on the contrary, it is deduced from the input data in order to extract information (general laws).In the opposite, deductive reasoning is based on syllogism defined by Aristotle such as a speech (logos) in which, certain things having been supposed, something different from those supposed results of necessity because of their being so1 .In other words, deductive reasoning is the ability to draw conclusions about individual facts (experiences) from generic knowledge (general law).When Aristotle writes things supposed this corresponds to the premise of the argument, and when he writes results of necessity this corresponds to the conclusion of the argument [Smith, 2020].Within the field of AI, deductive reasoning is primarily associated with symbolic approaches, commonly referred to as Good Old-Fashioned AI (GOFAI) [Haugeland, 1989].GOFAI encompasses a range of techniques including knowledge-based systems (e.g., expert systems), multi-agent systems, and constraint-based reasoning systems.These approaches leverage symbolic tools such as knowledge graphs, logical rules, ontologies and algebraic computation to facilitate deductive reasoning.We have placed particular focus on ontologies due to their ability to formalize knowledge by establishing associations between a knowledge graph and logic rules using inference engines.These deductive reasoning engines can use the axioms describing the concepts in the TBox (Terminology Box -general laws) to deduce new knowledge on the ABox (Assertional Box -specific facts) part of the ontology.In modern information systems, ontologies, such as formal and explicit specifications of shared conceptualizations [Guarino et al., 2009], prove to be highly valuable.They address the need for data interoperability and the formalization of business rules, which are essential aspects of contemporary information systems.</p>
<p>The exploration of the fusion between machine learning and ontologies arises from the aim to investigate the mechanisms that facilitate the integration of inductive reasoning with deductive reasoning.Unlike recent advancements in neurosymbolic approaches [Hitzler and Sarker, 2022, Garcez and Lamb, 2020, Henry Kautz, 2020, van Bekkum et al., 2021], our study did not exclusively focus on neural networks.Therefore, we chose to concentrate on the study of ontologies, as they encompass two vital categories of symbolic methods: knowledge graphs and logic rules.In our review, we ensured to highlight these two concepts to assist readers interested in either subject in navigating the research more effectively.</p>
<p>The main question addressed in this systematic literature review is whether it is possible to combine these two paradigms, and if so, how?The objective is to study how machine learning methods and ontologies can be effectively combined.In this study, our focus is on providing an overview of techniques that integrate learning and reasoning to realize a hybrid AI system capable of learning, building knowledge, and performing reasoning to tackle complex tasks and simulate the human cognitive process.</p>
<p>The Systematic Literature Review (SLR) is a research method based on the identification, evaluation, and interpretation of all relevant research results related to a particular topic area.It is a very popular analysis tool in the medical field, and was then adapted in computer science by Kitchenham et al. [2010] who define it as a form of secondary study that uses a well-defined methodology to identify, analyze and interpret all available evidence related to a specific research question in a way that is unbiased and (to a degree) repeatable [Kitchenham and Charters, 2007].By secondary study, the authors mean a study that reviews all the primary studies relating to a specific research question with the aim of integrating/synthesizing evidence related to a specific research question.In this context, a primary study describes new original research and aims to answer questions that haven't been answered or even asked before.The main objectives of this SLR are: (a) providing an overview of existing approaches combining ontology and machine learning, (b) understanding the motivations of each research work and addressed issues, (c) identifying the weaknesses and difficulties encountered, and (d) facilitating the positioning of new studies in this field.</p>
<p>To the best of our knowledge, a comprehensive overview encompassing the combination of ontology and machine learning techniques has not been previously conducted.While there have been studies focusing on specific aspects such as ontology learning [Al-Aswadi et al., 2020, Khadir et al., 2021], semantic data mining [Dou et al., 2015, Sirichanya andKraisak, 2021], and more recently, neuro-symbolic [Hitzler and Sarker, 2022, Garcez and Lamb, 2020, Henry Kautz, 2020, van Bekkum et al., 2021] 2 .There is no systematic review providing a holistic mapping of the different approaches that integrate ontologies and machine learning.Therefore, this study aims to fill this gap by providing a comprehensive overview of the combinations of ontology and machine learning, shedding light on the potential synergies and insights gained from their integration.This document is structured as follows.Section 2 describes the used methodology to conduct this systematic literature review.Section 3 presents the overview results, and sections 4, 5 and 6 detail each of the three major groups combining ontologies and machine learning.Finally, section 7 presents the conclusions and a discussion of challenges and research directions.</p>
<p>Methodology</p>
<p>The conducted SLR methodology is mainly inspired by Kitchenham et al. [2010], and is depicted in Figure 1.The first step is to plan the review after identifying the need to conduct it.We start by specifying the research questions.Then, we elaborate the adopted protocol to conduct the review by identifying keywords and selecting inclusion and exclusion criteria.The second step is performing the review by conducting the activities planned in the protocol and selecting primary studies to be included in the review, as well as the actions related to their evaluation.The final step is the reporting step, which consists of documenting, explaining, and summarizing the results to answer each research question.Once the research questions are defined, we identify the scientific databases and search keywords that will be used to select primary studies.This SLR uses three scientific databases to cover a large panel of articles: Web Of Science4 , ACM Digital Library5 and Science Direct6 .These three search engines are recommended by Gusenbauer and Haddaway [2020].They satisfy the reproducibility criteria of the searches, as well as the use of boolean terms in the query.Google Scholar is not used because it does not guarantee good reproducibility [Gusenbauer and Haddaway, 2020].</p>
<p>Plan the review</p>
<p>Perform the review</p>
<p>Report the review</p>
<p>To query selected scientific databases, a combination of the two main keywords, ontology and machine learning is used.However, the number of articles obtained was too large and all of these studies are not relevant to our review.Then, we refined the query by restricting the search of these same keywords in title, abstract, and keywords, which gave a much smaller number of articles that seem more relevant.</p>
<p>After a first analysis, we find that the term deep learning is often used instead of machine learning, even though it is a subset of this technique.We, therefore, decided to add the deep learning keyword to our query, with the same restrictions applied to the machine learning term.Also, some authors use directly the term neural network (in particular for the most recent articles) without explicitly mentioning the machine learning or deep learning terms.We, therefore, decided to add this keyword to our query, even if it concerns a minority of articles (10 to 15%) in each query.</p>
<p>For the ontology keyword, we decided to use only this term and not combine it with other keywords representing different semantic techniques, such as taxonomy, knowledge modeling, or knowledge graph.In this review, we are mainly interested in the use of ontologies, and the possibility to perform logical reasoning.</p>
<p>Finally, we have also included in our query the artificial intelligence keyword.This allows us to restrict obtained results to our research domain.Unlike previous keywords, the presence of this term is looked for anywhere in the article to be less restrictive.</p>
<p>Based on our search and selected keywords, we obtain the following query:</p>
<p>"ontology" AND ("machine learning" OR "deep learning" OR "neural network") AND "artificial intelligence" This query allows targeting primary studies concerned by our research questions.</p>
<p>Definition of inclusion and exclusion criteria</p>
<p>To filter the returned articles from the keyword search and keep relevant papers that will be used to answer our research questions, we defined a set of inclusion and exclusion criteria.</p>
<p>Inclusion criteria</p>
<p>InC1: The paper describes an approach that combines at least one ontology with at least one machine learning technique.InC2: The paper does not use ontologies and machine learning only to compare them.</p>
<p>Exclusion criteria</p>
<p>ExC1: Posters or demonstrations that do not provide enough details about their contribution.ExC2: Duplicate papers returned from various search engines.ExC3: Papers that are not written in English.ExC4: Non-accessible papers that can not be online recovered.ExC5: Books (or book chapters) detailing previously collected papers.ExC6: Extended paper by the same authors.In this case, the most recent paper is kept.ExC7: Existing survey or not a primary study (it may be a secondary or tertiary study).</p>
<p>Definition of quality criteria</p>
<p>The quality of an SLR depends on the quality of the reviewed articles.It is then important to rigorously assess the papers included in our SLR by considering the following quality criteria: (a) studies are conducted in higher research institutions (b) studies are published in good quality international revues and conferences and referenced by well-known electronics libraries (c) motivations and contributions are clearly defined.</p>
<p>To evaluate the quality of our SLR, we used the Quality Assessment Instrument for Software Engineering systematic literature Reviews (QAISER) developed by Usman et al. [2021].</p>
<p>Performing the review</p>
<p>This section describes how we performed the review according to the defined protocol.We follow four steps: (i) collecting articles according to the chosen keywords, (ii) applying the inclusion and exclusion criteria, (iii) applying the quality criteria, and (iv) analyzing selected articles.</p>
<p>Collecting articles</p>
<p>In this step, we query the selected scientific databases with the set of defined keywords by adapting our basic query to each scientific database, as presented in table 1.The first search was carried out at the end of May 2021, and a total of 373 studies were collected to be analyzed.A second search was conducted in February 2022 with the objective of updating our analysis report with all new studies published since the first search.By limiting ourselves to studies published in 2021 and 2022 on the selected scientific databases, we were able to add 70 articles to our initial collection.</p>
<p>Applying inclusion, exclusion, and quality criteria</p>
<p>The different steps for applying the inclusion and exclusion criteria are summarized in Figure 2.After collecting the set of 443 articles, we applied the first four exclusion criteria using Zotero7 , a reference management tool, to remove posters, demonstrations, duplicated and inaccessible papers.The remaining 351 articles are all written in English.In the second step, we read the titles and the abstracts of the obtained studies and apply the last three exclusion criteria to eliminate books, extended papers, and existing surveys.In this step, we also remove studies that did not meet both inclusion criteria based on title and abstract.We obtain 153 studies that we read to verify if they respect our two inclusion criteria.As a result, we selected 128 studies that correspond to the scope of our review.We also applied the quality criteria defined previously to evaluate the selected primary studies.We assume that the quality of used scientific databases ensures the quality of selected studies, and the relevance of each included article was discussed and validated by all authors of this SLR.</p>
<p>Analysis</p>
<p>To answer our research questions, we extracted from each primary study the different attributes described in the table 2.</p>
<p>Based on the extracted data, we performed some statistical analysis that we present in section 3.</p>
<p>3 Overview of included studies combining ontologies and machine learning techniques</p>
<p>In addition to the main analysis for answering the research questions, we performed a demographic analysis of the studies.Figure 3 presents the number of published papers concerning the combination of ontologies and machine learning techniques.The first paper present in this SLR dates from the year 2000, voluntarily we did not put any restriction on the publication date in our query (cf 2.1.2).Consequently, this SLR allows us to make a state of the art on the combination between ontologies and machine learning for more than 20 years.Since 2010 the number of studies has   The most represented continents are Europe, Asia, and North America.In Europe, leaders are Italy and Spain, each with a dozen papers in the study, but it is above all the multiplicity of contributing countries (United Kingdom, France, Germany, Austria, Poland, Greece, Bulgaria, Romania, Belgium, Lithuania, or Serbia) that allow Europe to come out on top of the most contributing continents.In Asia, it is mostly China that contributes to the second position of our ranking.In North America, the USA provides a large part of the studies.</p>
<p>These data are interesting if we cross them with those presenting the world public budgets of research and development (R&amp;D)8 .The presence of China and the USA at the top of our ranking correlates with the budget invested in R&amp;D each year.The large contributions of Italy and Spain, on the other hand, are more difficult to explain in terms of their R&amp;D spending.However, these two countries are present in the Investment Monitor top 40 countries ranking9 .In Italy, we note that several studies come from Trento University, which also has an interest in more specific neuro-symbolic field.This demographic study allows us to highlight some university teams that are actively engaged in conducting research in the combination of ontologies and machine learning.After reading the 128 selected articles, we could distinguish three groups of different ontology and machine learning combinations: Learning-Enhanced Ontology, Semantic Data Mining, and Learning and reasoning system.These three main groups and their subgroups have been partially named thanks to recent work that focuses on different forms of combination between inductive learning and deductive reasoning [von Rueden et al., 2021].This explains why we sometimes find the term semantic instead of ontology, whereas in this SLR we only deal with papers that use an ontology for the symbolic part.This will make it easier for the reader to make the connection with other articles dealing with learning and reasoning architecture (such as neuro-symbolic).We detail these three main groups and their subgroups, presented in Figure 5, in the paragraphs 4, 5 and 6 in order to be able to answer research questions RQ1, RQ2, and RQ3 in detail.</p>
<p>Figure 5: Overview of the combination of ontologies and machine learning techniques</p>
<p>Machine learning techniques (RQ2)</p>
<p>To answer RQ2, we identified the different machine learning algorithms used in each of the selected articles.All the machine learning algorithms used are listed in the "learning algorithm" column of Tables 3, 4 and 5, while the "learning type" column indicates whether they are supervised or otherwise.</p>
<p>Selected articles are divided into the three main learning approaches as follows:</p>
<p>• Supervised learning: 107 • Unsupervised learning: 37 of which 13 are self-supervised learning • Reinforcement learning: 1</p>
<p>As presented in Figure 3, neural networks are very common in the selected studies.Neural networks are well involved in the supervised and self-supervised categories and less present in the unsupervised category since their application to clustering problems is more recent.The authors often prefer other more classical clustering algorithms such as k-means, hierarchical ascending classification, principal component analysis, or latent Dirichlet allocation (LDA).</p>
<p>Ontology not only subsumption reasoning (RQ3)</p>
<p>It is interesting to note that a majority of articles (see Figure 6) only use subsumption rules for deductive reasoning.By deductive reasoning, we mean here ontological reasoning, i.e. the deduction of new facts from general rules.In this review, most of the papers use only the semantic contribution, in particular hierarchical relations, of ontologies and do not focus on the discovery of new facts based on ontological reasoning.Thus, only 37% of the reviewed articles describe a form of combination between inductive learning and deductive reasoning with non-hierarchical rules.These articles are identified by a check mark in the "Reasoning" column of the tables 3, 4 and 5.</p>
<p>It appears that many authors use ontologies as improved taxonomies (with non-heuristic relations between concepts) but do not use more complex rules for the inference part.ACM Computing Classification System10 defines several main themes involved in artificial intelligence like: Natural Language Processing (NLP), Computer vision, Multi-agents system, Time series and Planning and scheduling.Some of the selected articles are dedicated to an application in one of these themes.</p>
<p>The most present approach is NLP, including articles dealing with ontology learning and informed machine learning (cf. Figure 7) as detailed in sections 4.1 and 5. Some articles deal with Computer vision, in particular for image recognition.Few articles are involved in Multi-agents system and Time series.Only one article is concerned by Planning and scheduling.All relevant AI themes, not only the five main themes, are listed in the "AI Theme" column of Tables 3, 4 and 5.</p>
<p>Application domains (RQ5)</p>
<p>Figure 8 shows that 43% of the papers do not focus on a single application domain.Indeed, the authors have chosen to solve a particular problem by basing their work on either generalist or interchangeable datasets in order to allow the reuse of their work in various application domains.However, the application domain the most encountered is Health (26% of the studies), notably because medical ontologies such as SNOMED11 or biological ontologies such as GeneOnto12 are often used in this domain.It is also a domain that has very strong constraints in terms of the explainability of results.The use of semantic data and ontological reasoning are quite appropriate for this kind of problematic [Rubin et al., 2008].The other domains present in this review are much more anecdotal, as shown in Figure 8.The other domains own less than 10 papers, or even just one.All application domains are listed in the "Application domain" column of Tables 3, 4  and 5.</p>
<p>Learning-Enhanced Ontology</p>
<p>There are several ways to improve the use of ontologies through machine learning.First, ontology creation and maintenance can be (partly) automated thanks to machine learning techniques.In this case, we speak about ontology learning [Wong et al., 2012], in which ontologies can be learned from various resources.Second, ontology mapping groups together the categories that allow the use of ontologies to be improved thanks to machine learning (i.e., guaranteeing interoperability).Finally, learning-based reasoning presents the set of techniques to facilitate deductive ontological reasoning thanks to machine learning.</p>
<p>The comprehensive details of all papers within this category are outlined in Table 3, where they are meticulously categorized by their respective field of application, AI themes they explore, and the machine learning algorithms employed.</p>
<p>Ontology learning</p>
<p>Ontology learning is the process through which ontologies are automatically generated or enriched from various sources of data and knowledge [Maedche and Staab, 2001].This concept has already been studied in many recent reviews due to its potential to provide valuable assistance in the creation of ontologies, a traditionally time-and resource-intensive task [Al-Aswadi et al., 2020, Khadir et al., 2021, Asim et al., 2018].</p>
<p>The ontology learning process involves collecting and sometimes analyzing data from diverse sources such as texts, databases, web documents, and even existing ontologies.Using machine learning algorithms, information extracted from these data is then utilized in identifying concepts, relationships, and properties that could potentially be integrated into an ontology.Figure 9 illustrates this mechanism, showing that data is processed by a machine learning algorithm, symbolized by a funnel, before being transformed into elements of the TBox or ABox of an ontology, represented by the annotated polygon "A/T Box" associated with a cogwheel.The cogwheel symbolizes the final ontology created, upon which inferences can now be made.Automatic Taxonomy Construction (ATC) is the computer process of systematically generating a hierarchical classification system for entities or concepts based on inherent relationships, attributes, or similarities.</p>
<p>The ATC process comprises several distinct stages, each of which is identified and carefully described by Getahun and Woldemariyam [2017].Firstly, the pre-processing stage involves preparing the raw data, usually text, by cleaning, tokenizing, and normalizing it to facilitate subsequent analysis.Next, the concept extraction phase focuses on identifying key concepts or terms in the pre-processed data, using techniques such as NLP and pattern recognition.Concept extraction can employ various techniques, ranging from conventional approaches like TF-IDF [Ghoniem et al., 2019] to topic modeling methods such as LDA [Rani et al., 2017], or advanced deep learning techniques using Word2vec, including CBOW or Skip-G [Albukhitan et al., 2017].These extracted concepts are then mapped to specific domains or topics in the concept-domain matching phase, where they are ranked according to their relevance, often using a similarity score Albukhitan et al.</p>
<p>[2017], Getahun and Woldemariyam [2017], Ghoniem et al. [2019].Next, the concept-pair extraction phase aims to discover relationships between concept pairs, often using semantic analysis and graph-based algorithms to identify associations.Finally, the taxonomic relationship extraction phase aims to establish taxonomic relationships between identified concepts, such as hierarchical relationships like "is-a" or "part-of", thus completing the taxonomy construction.The concluding phase, serving as the core of ATC, encompasses the utilization of machine learning techniques such as formal concept analysis (FCA) [Jurkevičius and Vasilecas, 2010], hierarchical agglomerative clustering (HAC) Getahun and Woldemariyam [2017], and, more recently, recurrent neural networks [Petrucci et al., 2018] .Additionally, methods involving Markov networks, such as Markov Logic Networks (MLN) [Wu and Weld, 2008] or Conditional Random Field (CRF) [Song et al., 2016, Jia et al., 2018], are also employed in this crucial stage.</p>
<p>Together, these integrated steps form a comprehensive framework for the automatic generation of taxonomies from unstructured data.Studies frequently leverage a combination of at least three of the four mentioned steps to achieve this process.</p>
<p>While numerous papers employ unstructured data, such as text corpora, as the input for ATC, it's important to recognize that ATC can also be applied to structured data, as demonstrated by the research conducted by [Jia et al., 2018].</p>
<p>Learning non-hierarchical relations</p>
<p>Learning non-hierarchical relations in ontology learning involves identifying and comprehending semantic connections between entities that do not follow a hierarchical structure, typically focusing on association, correlation, or analogybased methods to discover and label these relations.Incorporating these non-taxonomic relations elevates the achieved taxonomies to the status of ontologies.To accomplish this, Albukhitan et al. [2017] employs an undisclosed clustering algorithm, while Getahun and Woldemariyam [2017] utilizes both a correlation-based method and a concept analogybased approach leveraging Word2Vec.In contrast, Petrucci et al. [2018] utilizes a Seq2Seq algorithm to convert a natural language sentence like "A bee is an insect that produces honey" into its formalized logical description, expressed as "bee ⊆ insect ∩ ∃produces.honey".</p>
<p>Rule discovery</p>
<p>Rule discovery or rule mining aims to discover actionable and interpretable rules that capture interesting patterns or dependencies within the data, aiding in decision-making and knowledge extraction.It facilitates the representation of complex relationships and inferences within ontologies (such as IF-THEN rules), often expressed in a formalized set of machine-readable rules, such as SWRL.</p>
<p>The study by Jurkevičius and Vasilecas [2010] mentions the use of an artificial neural network (ANN) for rule generation, although details on this aspect are limited in the article.McGlinn et al. [2017] adopt a mix of intelligent rule generation techniques, employing both ANNs and genetic algorithms (GA), as well as data mining rules using decision tree techniques on historical sensor data.Ko et al. [2021] focus on the construction of design rules for additive manufacturing (AM) using the machine learning algorithm CART (Classification and Regression Tree) on measurement data.In their study in the financial domain, Yang [2020] use the Apriori algorithm to discover association rules between data items in transactions.This algorithm is particularly suitable for inferring situational elements of risky events such as time and place through the analysis of transaction data.</p>
<p>These first three areas: automatic taxonomy construction, learning non-hierarchical relations, and rule discovery are TBox statements.</p>
<p>Ontology population</p>
<p>Ontology population is the process of enriching the TBox within an ontology by adding a substantial base of factual knowledge or instances.This involves inserting concrete data or instances into the ontology's conceptual framework, thus constituting the ABox part of the ontology.The automatic populating of an ontology is an important issue, as it enables the deductive reasoning mechanism to be used rapidly on a sometimes heterogeneous database.</p>
<p>In the study by Craven et al. [2000], the focus is on populating the ontology by extracting new instances from web pages using the Naive Bayes algorithm.The algorithm is used to classify and identify instances, providing a method for populating the ontology with factual information gathered from web sources.Kordjamshidi and Moens [2015] focus on populating the ontology with spatial information extraction.They use the Support Vector Machine (SVM) algorithm to efficiently populate the ontology with spatial information by extracting relevant details from different sources, helping to enrich the knowledge base.Markievicz et al. [2015] extend the application of SVMs to the field of robotics.The study focuses on the classification of actions described in a corpus of texts relating to chemistry experiments.The ultimate goal is to translate these actions into a robot executable format.In the healthcare field, Rubrichi et al. [2013] propose a methodology for the automatic recognition of drug-related entities in textual descriptions of drugs.They use the CRF (Conditional Random Field) algorithm, derived from Markov methods, to populate the ontology with this drug-related information.Packer and Embley [2015] use hidden Markov models (HMMs) for the ontology population in the historical domain.They present ListReader, a method for training the structure and parameters of an HMM without the need for labeled training data.This approach is particularly beneficial for dealing with OCR errors in historical documents.Kuang et al. [2018] address large-scale visual recognition in the context of computer vision.They propose a multi-level deep learning algorithm that combines deep convolutional neural networks (CNNs) and tree classifiers.</p>
<p>In the field of biochemistry, Ayadi et al. [2019] introduces a new approach to automatically populate the ontology of biomolecular networks.They rely on artificial neural networks (ANNs), in particular deep learning, and preprocessing techniques with Word2Vec.</p>
<p>Ontology enrichment</p>
<p>While the terminology section of the ontology, captured by the TBox, tends to be less dynamic than the instances in the ABox, regular maintenance is essential to prevent the ontology from becoming outdated.Ontology enrichment refers to the process of enhancing an ontology by updating its content through the addition or modification of concepts, properties, and relationships [Messaoud et al., 2015].This process aims to expand the ontology's knowledge representation to accommodate new information and ensure its relevance to evolving domains or applications.Indeed, it is unrealistic to anticipate the inclusion of all domain and expert knowledge in an initial ontology due to various factors.These may include experts' limitations in formalizing their knowledge comprehensively from the beginning or the possibility that certain problems or required knowledge have not yet been identified [Thomopoulos et al., 2013].</p>
<p>In the biomedical study by Valarakos et al. [2006], a dataset from a domain-specific corpus (PubMed abstracts) is used.Djellali [2013] propose a semi-automatic approach using truncated singular value decomposition (TSVD) and Fuzzy ART clustering for ontology enrichment.The method involves variable selection and clustering to identify candidate changes, reducing noise and improving clustering accuracy.</p>
<p>Ontology mapping</p>
<p>Ontology mapping, also known as ontology alignment, aims to discover correspondences between terms with similar meanings in two distinct ontologies while ensuring the overall structure coherence of the ontology KALFOGLOU and SCHORLEMMER [2003].The primary goal of ontology mapping is to establish a semantic correspondence between elements of ontologies to facilitate interoperability and extend their terminological scope by aligning concepts, properties, and instances.</p>
<p>Concept alignment involves finding equivalences between similar concepts, such as "housing" and "dwelling"; property alignment matches relationships between concepts, such as "has owner" and "owned by"; and instance alignment associates specific individuals from different ontologies representing the same reality.This process, depicted in Figure 10, begins with the preparation of source ontologies, represented by annotated polygons "A/T Box," including selecting relevant features in the TBox and ABox.Then, a machine learning model, symbolized again by a funnel shape, is trained, either supervised (with known correspondences) or unsupervised (automatically discovering potential correspondences).This model is then used to predict correspondences between common elements in both ontologies, as illustrated by the final "A/T Box" polygon situated between the two starting ontologies.These correspondences are often subjected to quality evaluation, particularly for coherence, and integrated to enhance interoperability between source ontologies.Finally, post-processing may be applied to refine the results.</p>
<p>Figure 10: Ontology mapping mechanism</p>
<p>The use of machine learning in ontology mapping automates the process of discovering semantic correspondences, particularly valuable in environments where heterogeneous ontologies need integration.To achieve this goal, ensemble methods are sometimes employed, such as Random Forest (using bagging) [Rico et al., 2018, Annane et al., 2018] or an approach involving three classifiers [Fanizzi et al., 2011].However, neural networks, particularly the multilayer perceptron (MLP) [Rubiolo et al., 2012, Shannon et al., 2021], and more recently, recurrent neural networks (RNNs) like LSTM [Chakraborty et al., 2021], or transformer models such as BERT [Mohan et al., 2021], or specific design architectures like IAC [Mao et al., 2010], are the prevailing choices.Neural networks also contribute to data pre-processing through techniques like Word2Vec [Zhou and El-Gohary, 2021].</p>
<p>Ontology mapping is an essential process for harmonizing distinct ontologies and promoting data and knowledge interoperability.The use of machine learning techniques, including neural networks and ensemble methods, facilitates the ontology alignment process, making it applicable to large datasets.Ultimately, this contributes to fostering the efficient exchange of information in a dynamically evolving digital environment.</p>
<p>Learning-based reasoning</p>
<p>In the field of learning-based reasoning, the papers focus on the integration of machine learning techniques to improve ontological reasoning.Indeed, the main challenge facing ontological reasoning is its slow execution, particularly when deployed in real-life scenarios.In our fast-moving society, especially for real-time systems, machine learning algorithms offer a promising solution to enhance the efficiency of inference engines.They can also provide significantly faster alternatives to traditional inference engines such as Pellet [Sirin et al., 2007] or HermiT [Shearer et al., 2008].</p>
<p>Diverse strategies for harnessing machine learning in ontological reasoning depend on the capability of machine learning algorithms to recognize intricate patterns, associations, and relationships within input ontologies.Figure 11   Optimizing reasoning can be achieved through various methods, including selecting a deductive reasoner appropriate for the application context, predicting reasoner performance to detect scalability issues, or enhancing the performance of deductive reasoners themselves by incorporating machine learning.</p>
<p>Selecting a reasoner involves choosing an appropriate inference engine or reasoning tool to perform deductive reasoning.Capabilities, efficiency, and compatibility with specific languages or ontology formats may vary from one reasoner to another.The choice of reasoner depends on factors such as ontology complexity, the desired level of reasoning support, and available computing resources.In the study by Bock et al. [2012], the focus is on selecting an appropriate reasoner for ontological reasoning tasks.The authors, recognizing that no reasoning algorithm universally excels in all description logic and reasoning tasks, implemented an approach within the framework of a reasoning broker called HERAKLES.In HERAKLES, machine learning techniques such as Naive Bayes, k-NN, Support Vector Machine (SVM), and Decision Tree are compared with each other.Through their experimentation, they found that the Decision Tree algorithm outperformed the others, demonstrating superior performance in choosing an appropriate inference engine.</p>
<p>Predicting reasoner performance involves estimating the duration required for a given reasoning task within a specified ontology.Essentially, it involves forecasting the time needed for a reasoner to complete its tasks, facilitating better planning and management of ontology-related projects and applications.Pan et al. [2018] use a combination of the Random Forest (RF) classifier and the Boruta algorithm for feature selection to predict reasoner performance.The challenge is to capture the complexity of ontologies, particularly as ABox intensity increases.The features proposed in the research contribute to greater accuracy in predicting time consumption for ontological reasoning tasks.</p>
<p>Using machine learning techniques can also accelerate the performance of OWL reasoners by reducing the complexity of reasoning tasks.In the Mehri et al. [2021] study, the aim is to improve the performance of reasoning systems by applying heuristic optimization techniques assisted by machine learning (ML).The authors use feature reduction techniques, in particular principal component analysis (PCA), to transform features into a set of new non-linearly correlated features.In addition, they use the support vector machine (SVM), well-suited to binary classification in high-dimensional feature spaces.</p>
<p>Perform reasoning</p>
<p>The capacity to perform deductive reasoning through a learning model, of logic-based symbolic formalisms, is a recent area of research [Hohenecker and Lukasiewicz, 2020].The two most recent papers reviewed in this study utilize neural networks to accomplish this task.</p>
<p>The first approach proposed by Rizzo et al. [2017] integrates the use of decision trees, in particular Random Forest (RF), enabling the construction of terminological decision trees to help reasoning processes in the Semantic Web environment.</p>
<p>In the study by Hohenecker and Lukasiewicz [2020], a new model architecture called Recursive Reasoning Network (RRN) is developed to perform this deductive reasoning task.Makni and Hendler [2019] focus on noise-tolerant reasoning in ontologies, recognizing the challenge of noise tolerance as a major bottleneck in deductive reasoning.To address this, they employ a recurrent neural network (RNN) to achieve noise-tolerant reasoning capabilities in ontology, this work is particularly interesting for dealing with noisy data commonly encountered in real-world applications.5 Semantic Data Mining</p>
<p>In this section, we present Semantic Data Mining using knowledge from ontology to improve the performance of machine learning algorithms [Lawrynowicz and Potoniec, 2014].Semantic data mining is a particular form of Informed Machine Learning defined by von Rueden et al. [2021] and means "using hybrid information source that consists of data and prior knowledge in machine learning" 13 .The term informed machine learning is particularly present in the field of physics [Karniadakis et al., 2021], where the concern is to embed physics into machine learning to improve the results and better adapt the algorithms to the complexity of physical problems.</p>
<p>In other words, semantic data mining is a combination of data-driven and ontology-driven approaches.This knowledge can be added to machine learning at different stages of the machine learning pipeline [von Rueden et al., 2021], like during the training data stage (Ontology-based feature engineering), the hypothesis set stage (Ontology-based algorithm design), the learning algorithm stage (Ontology-based algorithm training) or at final hypothesis stage (Ontology-based explanation).</p>
<p>The comprehensive details of all papers within this category are outlined in Table 4, where they are meticulously categorized by their respective field of application, AI themes they explore, and the machine learning algorithms employed.</p>
<p>Ontology-based feature engineering</p>
<p>At the first step of machine learning processes (i.e.training data), Ontology-based feature engineering allows mixing raw data with prior knowledge in several ways according to feature engineering definition [Duboue, 2020]: feature augmentation, feature selection, feature extraction or semantic embedding.</p>
<p>In the context of this review, studies categorized in this domain utilize a hybrid source of data, incorporating one or more ontologies, symbolized by the annotated polygon "A/T Box," to produce final results in the form of data, as illustrated in Figure 12.</p>
<p>Feature augmentation</p>
<p>Feature augmentation involves adding new variables (features) derived from the prior knowledge present in the ontology to the original dataset.This process does not always involve logical reasoning; the ontology's semantic structure alone  4, the addition of new features using ontology can be integrated with a wide range of machine learning algorithms.</p>
<p>Feature selection</p>
<p>Feature selection aims at reducing the number of variables to keep only the most relevant without changing the initial variables [Gomathi and Karlekar, 2019].Unlike traditional feature selection methods, ontology-based feature selection exploits the semantic relationships and structures defined in an ontology to identify and prioritize features for inclusion or exclusion.This approach aims to improve the selection process by incorporating domain-specific semantics, ensuring that selected features align with underlying ontological concepts.Note that this technique can sometimes be useful when faced with the curse of dimensionality [Bellman, 1961].</p>
<p>Feature extraction</p>
<p>Feature extraction is the process of transforming raw data into a reduced, relevant representation, highlighting important features for subsequent analysis.Ontology-based feature extraction involves modifying the original variables based on the prior knowledge provided by the ontology to obtain relevant features.This process aims to derive relevant features by exploiting the semantic information embedded in the ontology and allows input variables to be tailored to improve analysis and model performance.</p>
<p>Feature extraction often involves textual data, implying the use of NLP techniques, especially in sentiment analysis where neural networks are frequently employed [Kumar et al., 2020, Sabra et al., 2020, Ahani et al., 2021].In computer vision, leveraging ontology can assist in extracting meaningful features from images.Typically, a pre-processing step is employed to transform images into information effectively used by the ontology.Next, the data is often processed by a neural network.Akila et al. [2021] used ANN for sports image feature extraction, and [Zhao et al., 2021] for industrial vision inspection.Messaoudi et al. [2021] applied convolutional neural networks (CNN) to healthcare for MRI data classification, while Rinaldi et al. [2021] employed the VGG16 model for feature extraction from both textual documents and pre-classified images.The feature extraction process can also help reveal meaningful patterns and temporal relationships in time series, facilitating predictions made on this kind of data.In the study conducted by Liu et al. [2021] on photovoltaic time series data, the authors used managed recurrent units (GRUs) for feature extraction.GRUs, a type of recurrent neural network (RNN), are particularly effective at capturing temporal dependencies in sequential data.</p>
<p>Semantic embedding</p>
<p>In Semantic embedding, raw data is refined by semantic knowledge and then transformed into vectors to be exploited mainly by neural networks.This explains the prevalence of neural networks in this category since the data is specifically transformed for them.However, it is noteworthy that Mabrouk et al. [2020] employs semantic embedding for an SVM, while Zhang et al. [2021] utilizes it for XGBoost.The oldest paper in this SLR that uses this technique is from 2018, we can therefore assume that research in this field is recent.</p>
<p>This category encompasses numerous papers that leverage ontology to create knowledge graph embeddings (KGE) [Chen et al., 2021].KGE employs models like TransE, TransR, DistMult, etc., each with a score function to convert the graph's knowledge into vectors usable by machine learning algorithms.In our study, the primary applications of this technique are in automatic text processing and time series analysis.These transformations are conducted with meticulous consideration for preserving the links between different entities within the KGE.Ontology embedding expands upon this representation, encompassing a broader scope of ontological knowledge, including aspects like existential rules.In their work, Benarab et al. [2019] employs autoencoders for the implementation of ontology embedding.Word2Vec is also frequently used to pre-process plain text before the semantic embedding stage [Jang et al., 2018, Ali et al., 2021, Amador-Domínguez et al., 2021].</p>
<p>Ontology-based algorithm design</p>
<p>In the second stage of the machine learning process (i.e. the hypothesis set), ontology-based algorithm design contributes to the incorporation of ontological knowledge into the design and development of machine learning algorithms.</p>
<p>Ontology-based decision tree</p>
<p>Ontology-based decision trees refer to an algorithmic design approach that incorporates ontological principles into the construction and use of decision trees.In this context, decision trees, such as random forests, are developed and used in a way that incorporates ontological knowledge.Emele et al. [2012] introduced an ontology-based decision tree called STree, derived from C4.5 and enhanced with ontological reasoning, applied to military dialogues.</p>
<p>Ontology-based probabilistic graphical model</p>
<p>An ontology-based probabilistic graphical model refers to an algorithmic design approach that incorporates ontological principles into the construction and use of probabilistic graphical models, such as Bayesian networks or Markov models.-Sarmiento et al. [2019] proposed an ontology-based probabilistic graphical model, specifically Ontology-based Conditional Random Fields (obCRFs), for robotics in computer vision tasks.This model enhances standard Conditional Random Fields (CRFs) with additional nodes and relations based on a multi-level ontology structure, aligning with the subsumption ordering of ontologies, to improve object recognition in robot environments.</p>
<p>Ruiz</p>
<p>Ontology-based neural topology</p>
<p>Ontology-based neural topology entails an algorithmic design approach that incorporates ontological principles into the selection or creation of the architectural design for neural networks.This methodology involves integrating ontological insights to guide the structure and configuration of neural networks, aligning them with domain-specific knowledge and semantic relationships.Gabriel et al. [2014] facilitate the choice of an appropriate ANN model structure thanks to an ontology.Rather than going through a grid-search step which is sometimes too time-consuming in complex systems, a model topology (e.g. the number of hidden layers and the number of neurons in the hidden layers for a neural network) can be approximated by prior knowledge.Huang et al. [2019] introduced OntoLSTM, an ontology-based long-term memory neural network (LSTM), wherein dense layers are encoded using ontology-derived information.This approach is specifically designed for time series analysis within the context of Industry 4.0.Kuang et al. [2021] addressed large-scale fashion recognition using a hierarchical deep learning approach called Augmented Hierarchical Deep Learning (AHDL).</p>
<p>The proposed hierarchical knowledge distillation method facilitates knowledge transfer between tree node classifiers of hierarchical deep networks, thus improving fashion image representation and classification.Fu et al. [2015] focused on personal photo tagging using transfer learning with a Convolutional AutoEncoderS (CAES) to which they added a Fully Connected layer with Ontology priors (FCO).Their approach exploits ontology priors in the last layer of a fully connected network to improve personal photo tagging performance.</p>
<p>Ontology-based algorithm training</p>
<p>At the third step of the machine learning process (i.e.learning algorithm), ontology-based algorithm training integrated prior knowledge into the machine learning algorithm, typically via a loss function.</p>
<p>In their work, Serafini et al. [2017] introduced ontology-based algorithm training through the application of a Logical Tensor Network (LTN).The LTN framework integrates logical reasoning into deep learning architectures using t-norms derived from fuzzy logic.This innovative approach allows logical constraints to be added to the inductive reasoning process.</p>
<p>Ontology-based explanation</p>
<p>In the realm of artificial intelligence research, neural networks are frequently regarded as "black boxes", where the explicit input-output behavior of the algorithm is observable, but the underlying reasoning mechanism remains opaque.Therefore, the development of explainable artificial intelligence (XAI) becomes crucial.The explainability of an algorithmic model pertains to its ability to present a coherent sequence of interconnected steps that can be interpreted by humans as causes or reasons behind the decision-making process [Donís Ebri, 2021].This capability allows for the clarification of the algorithm or its outputs, enhancing the understanding of how and why certain decisions are made.In addition to the issue of trust, the lack of explainability in AI models has also given rise to legal challenges in various domains such as military defense, healthcare, insurance, and autonomous vehicles.The inability to provide clear and understandable explanations for AI-driven decisions poses legal complications in these areas.The global explainability of a model aids in identifying the key variables that contribute to the model's output.It enables the determination of the specific role played by a particular variable in the model's final decision or prediction.Global explainability is used to assess the importance of a model's features.The SHAPE algorithm [Lundberg and Lee, 2017] is commonly employed to identify variables with the most significant impact in a machine learning model.Conversely, the local explainability of a model focuses on the process leading to decisions made for a specific individual [Ribeiro et al., 2016, Lundberg andLee, 2017].It aims to highlight the impact of each variable on the outcome, thereby making the decision more interpretable and understandable for that particular case.</p>
<p>When prior knowledge is not integrated, explanations are primarily based on mathematical correlations between data and results, which does not always guarantee the robustness and reliability of indicators.Black-box explanation through an ontology relies on the idea of using a formal and explicit knowledge structure to clarify the internal workings of a considered AI model, often viewed as a "black box."This means that when a prediction is generated by a conventional machine learning model, as represented by a funnel in Figure 13, the ontology is then used to provide explanations for that prediction as shown in the same figure.</p>
<p>Figure 13: Ontology-based explanation mechanism For a comprehensive explanation of the model, the ontology can be used to demonstrate how concepts and entities in the ontology are related to the features or input data of the model, thereby describing the overall reasoning process of the model.For a local explanation, the ontology can be employed to highlight how specific concepts or entities in the ontology contributed to the particular prediction for a given individual.In this SLR, two studies use ontologies to enhance the explainability of models: one of these studies aimed to provide a global explanation of the model [Confalonieri et al., 2021], while the other focused on delivering local explanations [Panigutti et al., 2020].</p>
<p>These studies demonstrate the usefulness of ontologies in augmenting the interpretability of AI models, both at the global and local levels.The integration of prior knowledge through ontologies helps establish a logical and coherent framework for the model's explanations, aligning them with existing domain knowledge.This not only enhances the trustworthiness of the explanations but also provides a deeper understanding of the reasoning process employed by the model.</p>
<p>Table 4 presents machine learning algorithms used in Ontology-based explanation category.Only neural networks are presented here, Panigutti et al. [2020] specifies that it is a Gated Recurrent Unit network (GRU), a special type of Recurrent Neural Network.CAES, FCO [Fu et al., 2015] Ontology-based algorithm training</p>
<p>Computer Vision -Supervised LTN [Serafini et al., 2017] Ontology-based explanation -Healthcare Supervised GRU [Panigutti et al., 2020] --ANN [Confalonieri et al., 2021] 6 Learning and Reasoning Systems</p>
<p>This category represents the set of complete applications that use machine learning and ontologies to operate.The application is a computer program capable of performing one or more specific tasks in the same field, e.g. a decision support system for the management of cardiac pathology [Ali et al., 2020].Studies in this category, shown in Figure 5, describe complete application systems, not only some specific mechanisms (e.g.ontology learning, semantic feature engineering, etc.).</p>
<p>Expert System Embedded Learning</p>
<p>The first sub-category covers ontology-based expert systems that exploit machine learning for execution.An expert system comprises various components, including a knowledge base, an inference engine, and an interface [Liebowitz, 1997].In Expert System Embedded Learning, the machine learning component, represented in Figure 14 by a funnel, is integrated into an expert system, here represented by a cogwheel symbolizing an ontology.The integrated learning model(s) can be considered as sub-modules of the expert system and the produced results mainly consist of new inferred by the expert system, represented by an annotated polygon "ABox".This is why we have chosen to use the term "embedded", which is an equivalent of "integrated" because the proper functioning of the expert system is closely linked to the machine learning part.The two articles in this category use machine learning to find missing values in an expert system, enabling it to perform deductive reasoning.They therefore perform a task similar to that performed by Makni and Hendler [2019], which enables noise-tolerant deductive reasoning.However, their approach is different, as they don't use a machine learning algorithm to perform the reasoning, but rather to impute missing values.Moreover, in both instances, the decisionmaking system could theoretically operate without an external learning module, although with reduced performance.This distinction justifies their classification in the Expert System Embedded Learning category.</p>
<p>In the first study, Khan et al. [2013] introduced Holmes (Hybrid Ontological and Learning MEdical System), a medical system integrating ontology and machine learning for decision-making in patient treatment.Holmes employs Adaboost as its primary learning algorithm, enabling the creation of a semantic decision support system resilient to noise.Specifically, it addresses decision-making scenarios related to the administration of sleeping pills.In the second study, Bischof et al. [2018] presented the Open City Data Pipeline, which aims to collect, integrate, and enrich statistical data from various cities around the world for republication as machine-readable linked data.To handle missing values in the dataset, their imputation pipeline employs principal component analysis (PCA) as a pre-processing step.Subsequently, the authors apply different algorithms, including multiple logistic regression (MLR), k-nearest neighbors (k-NN), or random forest (RF), based on the performance obtained during the preprocessing phase.</p>
<p>Hybrid application</p>
<p>This second sub-category represents the set of hybrid application systems that use machine learning and ontologies in a more complex way, often by communicating the two types of reasoning (inductive and deductive) within the AI system.Figure 15 clearly illustrates the hybridization mechanism by symbolizing the fusion between machine learning (funnel) and ontology (cogwheel), enabling result prediction.Through the integration of multiple modules, these systems can capitalize on the advantages of learning-based approaches, such as machine learning, while leveraging symbolic reasoning techniques, such as ontologies.</p>
<p>Similar to the Expert System Embedded Learning category, hybrid applications leverage both learning and deductive reasoning.They uses machine learning for tasks such as data recognition, shape analysis, or event detection and subsequently employ deductive reasoning based on the information acquired earlier.These works go beyond populating an ontology, even though the initial process may be similar.After processing raw data through learning, they incorporate it into the ABox of the ontology, enabling the utilization of deductive reasoning or (at least) semantic processing.The inclusion of some articles in this category is also justified by the incorporation of at least two distinct forms of Two studies investigate messages related to aviation.In the first paper, Wang et al. [2010] focused on the analysis of aviation-related messages and failure analysis.They used a Back-Propagation Neural Network (BPNN) algorithm, a type of artificial neural network (ANN).The ontology played a crucial role in preparing the variables for the neural network, subsequently facilitating the extraction of knowledge and its representation as rules.In the second paper, Wang et al. [2021b] studied natural language processing (NLP) in the context of aviation, in particular Air Traffic Control (ATC).They used a long-term memory network (LSTM), a type of recurrent neural network (RNN), and integrated an ontology to facilitate the translation of aeronautical messages.This approach enabled efficient language processing and understanding in the aviation context.</p>
<p>Two papers can be identified as being in the Smart City domain.Keyarsalan and Montazer [2011] focus on fuzzy ontology for traffic light control in a smart city context.They use the radial basis function neural network (RBFNN) for image recognition tasks, such as traffic density estimation.Then, the ontology is used as a decision aid to regulate traffic based on the results returned in real time by the images.[Patel et al., 2021] deal with video surveillance in a smart city scenario, in particular for the detection of abnormal events in a parking zone.They use the You Only Look Once (YOLO) algorithm for object detection in video images, enabling efficient feature extraction.The detected objects are then processed by an ontology to perform semantic reasoning on the images and identify anomalies.Design pattern number 3b represents systems capable of learning not only from data, but also from symbols, as is the case for Ontology-based feature engineering.</p>
<p>Design pattern number 7 specifically addresses informed learning with prior knowledge, aligning with our designated categories of Ontology-based algorithm design and Ontology-based algorithm training.The core principle underlying this design pattern is the inclusion of prior knowledge within the pipeline of the machine learning model.By incorporating relevant awareness, the objective is to enhance the performance and generalization capabilities of the model.As observed in our SLR, the integration of knowledge can occur at various stages within the learning pipeline.These include incorporating knowledge into the training data, incorporating it into the model architecture, incorporating it during the learning process of the model, and even incorporating it post-hoc after the learning phase.</p>
<p>Design pattern number 10 is dedicated to harnessing the power of machine learning, specifically neural networks, to enable logical reasoning.In this design pattern, a neural network is trained to perform logical reasoning tasks, aligning closely with our designated category of Learning-based Reasoning This approach offers notable advantages, including enhanced scalability compared to traditional logical reasoning methods that may encounter bottlenecks when dealing with large ontologies.Moreover, learning-based reasoning exhibits greater resilience to noisy or missing data, thus improving the overall robustness of the reasoning process.</p>
<p>Design pattern number 12 focuses on the design of hybrid AI systems that closely resemble real-life applications.In contrast to a single monolithic component, hybrid AI systems are composed of multiple interconnected modules that communicate with each other.This design pattern aligns with the Learning and Reasoning system category identified in our systematic literature review.The objective of these hybrid AI systems is to leverage the synergies between learning and symbolic modules, aiming to produce more reliable models with enhanced transparency and reproducibility.By integrating multiple modules, these systems can benefit from the strengths of both learning-based approaches, such as machine learning, and symbolic reasoning techniques.</p>
<p>Another well-recognized subgroup within Hybrid AI is neuro-symbolic, which concentrates on the integration of symbolic methods with neural networks, especially deep neural networks Henry Kautz [2020] has introduced a comprehensive taxonomy that classifies the diverse neuro-symbolic approaches, providing a structured framework for understanding and categorizing them.Indeed, in a similar manner, the categories identified in our SLR align with the groups outlined in Henry Kautz [2020]'s taxonomy, specifically when the ML algorithm employed is a neural network.To further aid readers in their mapping efforts, we have included this alignment in table 6, allowing for a clearer understanding of the correspondence between the SLR categories and Kautz's taxonomy.</p>
<p>Category Ontology-based feature engineering corresponds to approach Symbolic Neuro symbolic, which involves transforming raw data using symbolic integration.This technique is commonly used in NLP tasks, where data is converted into vectors using methods such as Word2vec and GloVe.</p>
<p>The Neuro_{Symbolic} architecture, on the other hand, is more complex: it facilitates the conversion of symbolic rules into neural network models (Ontology-based algorithm design or Ontology-based algorithm design), as illustrated by the logical tensor networks [Serafini et al., 2017] discussed in this systematic literature review.</p>
<p>The Symbolic[Neuro] architecture combines neural pattern recognition with a symbolic problem-solving framework, resulting in enhanced problem-solving capabilities.This architecture is specifically applied in the category of Expert System Embedded Learning.</p>
<p>The Neuro|Symbolic architecture is prominently featured in our study, encompassing the categories of ontology learning, ontology mapping, ontology-based explanation, and hybrid application.This architecture closely resembles the Symbolic[Neuro] architecture but utilizes coroutines instead of subroutines.It emphasizes the communication between a symbolic system and a neural system, which is particularly relevant to our hybrid application category.</p>
<p>We have chosen to place the other three categories within this architecture because it best aligns with their respective functionalities, even though the communication between the two systems may be more limited compared to hybrid applications.</p>
<p>Lastly, the Learning-based reasoning category is analogous to the Neuro:Symbolic→Neuro architecture, which involves training a neural network on symbolic rules.In learning-based reasoning, the network learns logical rules to perform deductive reasoning on new inputs.The advantage of this approach is that the neural network does not perform reasoning by explicitly following step-by-step rules; instead, it makes predictions based on the expected outcome of deductive reasoning.As mentioned earlier, this approach significantly reduces computational time, particularly when dealing with large ontologies.</p>
<p>Three challenges for the future</p>
<p>We have identified three main challenges using ontologies combined with machine learning.The first is the formal proof of the expressiveness and decidability of the ontology.The second is the ability to explain the results of a machine learning algorithm.The third concerns the management of consistency during ontology learning and ontology mapping.Between taxonomy and formal ontology, this semantic representation of knowledge is a balance between expressiveness and decidability.Description logics are used to formalize ontology and determine this level of expressiveness/decidability.Each description logic represents a formal, axiomatized language describing the level of constraints supported.Since 2012, OWL2 language, recommended by the W3C14 , allows the expressiveness of SROIQ(D) logic.</p>
<p>Inference engines can interpret this logic and check consistency, reorganize the structuration of concepts in the TBox, or, thanks to rule-based language (e.g.SWRL) infer new knowledge into the ABox.A large majority of articles studied make no mention of deductive reasoning beyond subsumption links made possible by ontologies and inference engines.Many of them use an ontology for its contribution at the semantic level.Ontology is used as an improved taxonomy since it has the advantage of also representing non-hierarchical relationships between the different terms of a domain.This corresponds, at best, to S description logic language.</p>
<p>eXplainable Artificial Intelligence (XAI)</p>
<p>In recent times, AI systems have made significant progress in perceiving, learning, decision-making, and even autonomous action.Nevertheless, there remains a level of distrust among humans towards these systems, largely due to their inability to provide explanations for the reasoning behind their decisions [Gunning and Aha, 2019].</p>
<p>Over the past two decades, the research domain of eXplainable Artificial Intelligence (XAI) has experienced significant growth.This attribute holds critical importance in sensitive industrial sectors such as healthcare, finance, insurance, and defense.Achieving explainability in AI systems has been explored through various techniques, including Local Interpretable Model-agnostic Explanations (LIME) [Ribeiro et al., 2016], SHapley Additive exPlanations (SHAP) [Lundberg and Lee, 2017], as well as symbolic reasoning.Two papers, outlined in section 6.2, have specifically explored this subject by incorporating ontology [Confalonieri et al., 2021, Panigutti et al., 2020].These papers propose interesting approaches for obtaining either a global [Confalonieri et al., 2021] or local explanation [Panigutti et al., 2020].</p>
<p>In these works, a domain-specific ontology pertaining to the targeted field of explanation is employed to enhance the explanatory quality.These studies highlight the role of ontologies in augmenting the interpretability of AI models, both at the global and local levels.By integrating prior knowledge through ontologies, a logical and cohesive framework is established for the model's explanations, ensuring their alignment with existing domain knowledge.This integration not only enhances the credibility of the explanations but also facilitates a deeper comprehension of the model's reasoning process.</p>
<p>Consistency checking</p>
<p>Change management in ontology during ontology learning process or ontology mapping requires consistency checking.Consistency management allows guaranteeing the reasoning validity of the different ontology releases.This study of consistency is well carried out by Mitchell et al. [2018] which is interested in the enrichment of an ontology, as well as by del Rincon et al. [2013] and Donadello and Serafini [2016], classified in the category ontology population (as explained in paragraph 4.1).However, these three works represent 6% of the papers which should be concerned by the consistency management.Furthermore, we did not find any paper mentioning the study of consistency in the other categories present in this literature review.</p>
<p>Conclusion</p>
<p>We conduct a SLR to explore the integration of inductive reasoning and deductive reasoning in systems that combine machine learning and ontologies.The aim of this study was to determine whether hybrid AI techniques could improve the ability of machines to perceive the complexity and nuances of our real world in order to improve their interactions with it.In our SLR, we reviewed a total of 128 papers that explore the combination of machine learning and ontologies across various domains and with diverse objectives.Through this comprehensive analysis, we identified and highlighted different categories of combinations of machine learning and ontologies that address distinct problems.We also provide a comprehensive examination of all these categories, emphasizing the various machine learning algorithms utilized in the studies.Additionally, we have established the connections between our categorization and van Bekkum et al.</p>
<p>[2021]'s design pattern as well as Henry Kautz [2020]'s neuro-symbolic classification to provide insights to interested readers.</p>
<p>How can we enable machines to have an impact on the tangible world if they can't make sense of the various aspects, complexities, and nuances of the real world?The question remains, but according to this SLR, from Plato to today, the work is still in progress.</p>
<p>Figure 1 :
1
Figure 1: Systematic Literature Review (SLR) methodology</p>
<p>Figure 2 :
2
Figure 2: Selection of articles</p>
<p>Figure 3 :
3
Figure 3: Evolution of the number of publications about the combination of ontologies and machine learning.</p>
<p>Figure 4
4
Figure4present the geographical distribution of contributors, considering the location of the first author of each article.The most represented continents are Europe, Asia, and North America.In Europe, leaders are Italy and Spain, each with a dozen papers in the study, but it is above all the multiplicity of contributing countries (United Kingdom, France, Germany, Austria, Poland, Greece, Bulgaria, Romania, Belgium, Lithuania, or Serbia) that allow Europe to come out on top of the most contributing continents.In Asia, it is mostly China that contributes to the second position of our ranking.In North America, the USA provides a large part of the studies.</p>
<p>Figure 4 :
4
Figure 4: Country where the first author is based</p>
<p>Figure 6 :
6
Figure 6: Proportion of subsumption and not only subsumption ontology reasoning in studies</p>
<p>Figure 7 :
7
Figure 7: Artificial intelligence themes</p>
<p>Figure 8 :
8
Figure 8: Application domains</p>
<p>Figure 9 :
9
Figure 9: Ontology learning mechanism</p>
<p>illustrates this process, showing how machine learning, represented by a funnel, acquires the ability to perform deductive reasoning based on ontologies represented here by the annotated "A/T Box" polygon.The final deductive reasoning capability is symbolized by the cogwheel next to the "A/T Box" polygon.</p>
<p>Figure 11 :
11
Figure 11: Learning-based reasoning mechanism</p>
<p>Figure 12 :
12
Figure 12: Ontology-based feature engineering mechanism</p>
<p>Figure 14 :
14
Figure 14: Expert System Embedded Learning mechanism</p>
<p>Figure 15 :
15
Figure 15: Hybrid application mechanism</p>
<p>Table 1 :
1
Final request for each search engine
Scientific databaseRequest</p>
<p>Table 2 :
2
Extracted data from final studies Over the years, we see that neural networks are being used more and more.The neural networks group includes algorithms range from the simple perceptron to the most recent techniques such as Transformers.As we see in more detail in the section 3.2 neural networks are present in the majority of the papers studied.
AttributeDescriptionYearYear of publicationCountryCountries where the first author is locatedMachine learning algorithmThe machine learning algorithm(s) used in the paper.Ontology reasoningPresence of deductive reasoning, at least of formal rules allowing de-ductive reasoning.Artificial intelligence themesIf the studies explore a known theme of Artificial Intelligence as de-scribed by the ACM Computing Classification SystemCategoryCategory of the article according to our classification of machine learn-ing and ontologies combinationsincreased, and a strong acceleration is taking place in recent years. Indeed, 57% of the analyzed studies were publishedafter 2018.</p>
<p>Meroño-Peñuela et al. [2021]2018] ontology enrichment in the context of the food industry.They use classification algorithms such as CART and C4.5 to extract new knowledge, including concepts and relationships, from a food dataset.Note that all new propositions are validated by a domain expert before being incorporated into the ontology.Messaoud et al. [2015]contribute to the enrichment of a medical ontology through causal discovery.Their method, SemCaDo (Semantic Causal Discovery), uses causal Bayesian networks (CBNs) to learn causal discoveries from gene expression datasets and gene ontology.The new knowledge found by the CBN is then used to evolve the ontology.Song et al. [2016]apply conditional random fields (CRFs) to discover Q&amp;A from collaborative engineering tasks.The discovered Q&amp;A are transformed into ontological concepts and relations by a semantic mapping step.[Mihindukulasooriyaetal., 2018]focus on knowledge base (KB) quality assessment.They use the Random Forest (RF) algorithm to add integrity constraints to the KB, thereby improving its quality.The work ofHong et al. [2021]in the field of brain areas and autism uses natural language processing (NLP) techniques.BiLSTM and CRF are used for entity extraction, then BiLSTM is used again for relation extraction.Finally, instances with high confidence scores are manually reviewed by experts.Meroño-Peñuela et al. [2021]target ontology evolution and concept drift detection in Web vocabularies.They exploit several algorithms provided by the WEKA API and use strings of RDF vocabulary versions as datasets.</p>
<p>Hidden Markov Models (HMM) are used to extract relevant tokens from the dataset.Next, the COmpression-based CLUstering (COCLU) algorithm is applied for ontology enrichment, focusing on non-taxonomic lexical-semantic relations.</p>
<p>Table 3 :
3
Details of articles in the Learning-Enhanced Ontology category
CategorySub-categoryAI ThemeApplication domainLearning typeLearning algorithmReasoningPaperOntology learningAutomatic taxonomy con-NLPWikipediaSupervisedMarkov Logic Net-[Wu and Weld, 2008]structionworkNLPTechnologyCRF[Song et al., 2016]NLPCybersecurityCRF[Jia et al., 2018]NLP, Translation-RNN (Seq2Seq)[Petrucci et al., 2018]NLPBiomedicalRNN, Naive Bayes[Zhao and Zhang, 2018]NLPBiomedicalSVM[Ghoniem et al., 2019]NLP-UnsupervisedFCA[Jurkevičius and Vasilecas, 2010]NLPTourismHAC[Getahun and Woldemariyam, 2017]NLP-LDA, LSI, SVD[Rani et al., 2017]NLPLinguisticSelf-supervisedWord2Vec<a href="CBOW">Albukhitan et al., 2017</a>NLPTourismWord2Vec[Getahun and Woldemariyam, 2017]Learning non-hierarchical re-NLP, Translation-SupervisedRNN (Seq2Seq)[Petrucci et al., 2018]lationsNLPTourismSelf-supervisedWord2Vec[Getahun and Woldemariyam, 2017]NLPLinguisticUnsupervisedClustering[Albukhitan et al., 2017]Rule discoveryNLP-SupervisedANN[Jurkevičius and Vasilecas, 2010]-Building EnergyM5, ANN, GA,[McGlinn et al., 2017]ManagementSystem-Additive Manufac-CART[Ko et al., 2021]turing-FinanceUnsupervisedAPRIORI[Yang, 2020]Ontology populationNLPWebSupervisedNaïve Bayes[Craven et al., 2000]-HealthcareCRF[Rubrichi et al., 2013]NLP, Spatial infor--SVM[Kordjamshidi and Moens, 2015]mation extractionNLPRoboticsSVM[Markievicz et al., 2015]-HistoryHMM[Packer and Embley, 2015]Computer vision,-Decision tree, CNN[Kuang et al., 2018]Large-scale visualrecognitionNLPBiochemistryANN[Ayadi et al., 2019]NLPBiochemistrySelf-supervisedWord2Vec[Ayadi et al., 2019]Ontology enrichment-BiomedicalSupervisedHMM[Valarakos et al., 2006]-Food industryCART, C4.5[Thomopoulos et al., 2013]Causal discoveryHealthcareCBN (SemCaDo)[Messaoud et al., 2015]-TechnologyCRF[Song et al., 2016]KB quality assess--RF[Mihindukulasooriya et al., 2018]mentNLPHealthcarebiLSTM, CRF[Hong et al., 2021]-Web vocabulariesMultiple algorithm[Meroño-Peñuela et al., 2021]-BiomedicalUnsupervisedCOCLU[Valarakos et al., 2006]NLP-TSVD, Fuzzy ART[Djellali, 2013]Ontology mappingConstraint satisfac-WebSupervisedIAC[Mao et al., 2010]tion problem</p>
<p>Table 3 :
3
Details of articles in the Learning-Enhanced Ontology category
CategorySub-categoryAI ThemeApplication domainLearning typeLearning algorithmReasoningPaper--Ensemble classifier[Fanizzi et al., 2011]--MLP[Rubiolo et al., 2012]Anchoring-RF[Annane et al., 2018]--ANN[Gao et al., 2018]-WikipediaRF, MLP, SMO[Rico et al., 2018]NLPHealthcareMLP[Shannon et al., 2021]-BiomedicalSelf-supervisedBERT[Mohan et al., 2021]-BuildingWord2Vec[Zhou and El-Gohary, 2021]-WikipediaUnsupervisedPCA[Rico et al., 2018]-WebLSTM[Chakraborty et al., 2021]Competitive learn-Sensor, IoTANN[Xue et al., 2021]ingLearning-based rea-Optimizing reasoning--SupervisedNaive Bayes, k-NN,[Bock et al., 2012]soningSVM, Decision tree--RF (and Boruta al-[Pan et al., 2018]gorithm)--SVM[Mehri et al., 2021]--UnsupervisedPCA[Mehri et al., 2021]Perform reasoningInductiveLogicSemantic WebDecision Tree, RF[Rizzo et al., 2017]ProgrammingNoise-toleranceWebSupervisedRNN[Makni and Hendler, 2019]--RRN[Hohenecker and Lukasiewicz, 2020]</p>
<p>Table 4 :
4
Details of articles in the Semantic Data Mining category
CategorySub-categoryAI ThemeApplication domainLearning typeLearning algorithmReasoningPaperOntology-basedFeature augmenta-Automatic Task De-TechnologySupervisedJ48[Rath et al., 2009]feature engineer-tiontectioningNLPCybersecurityBayesian network<a href="Spam detection">Santos et al., 2012</a>Pattern discovery-RF[Lawrynowicz and Potoniec, 2014]--ANN[Pancerz and Lewicki, 2014]NLP, TALPersian textHMM[Pozveh et al., 2018]-BiomedicalSVM[Wan and Mak, 2018]Activity recogni-Smart environmentsSVM[Salguero et al., 2019]tionNLPHealthcareRNN, CNN, HAN[Abdollahi et al., 2021]-HealthcareANN[Wang et al., 2021a]Activity recogni-Smart homeUnsupervisedk-means[Ye et al., 2015a]tionRecommendationWineFarthest First (k-[Oliveira et al., 2021]systemmeans)Feature selection-HealthcareSupervisedANN, SVM[Gomathi and Karlekar, 2019]Feature extractionMAS, PlanningTourismSupervisedC4.5, k-NN[Castillo et al., 2008]Semantic annota--Bayesian network[Rajput and Haider, 2011]tion-HealthcareBayesian networks,[Hsieh et al., 2013]ANN, SVM, regres-sion (WEKA)NLP,Sentiment-SVM[Agarwal et al., 2015, Manuja and Garg, 2015]analysisMASContexte-awareANN[Yilmaz, 2017]NLPFinance, CorporateNaïve Bayes[Evert et al., 2019]disclosuresUser InterfaceHealthcareSVM[Greenbaum et al., 2019]NLPSpam filteringRF, SVM, C4.5,[Mendez et al., 2019]Naïve Bayes, LR,Adaboost, bagging-HealthcareLR[Radovanovic et al., 2019]NLP,Sentiment-CNN[Kumar et al., 2020]analysisNLP,SentimentHealthcareMLP, SVM, ensem-[Sabra et al., 2020]analysisble classifierNLP,SentimentHealthcarek-NN, ANFIS[Ahani et al., 2021]analysisComputer VisionSportANN[Akila et al., 2021]Time seriesPhotovoltaicGRU[Liu et al., 2021]Computer VisionHealthcareCNN[Messaoudi et al., 2021]NLPHealthcareLSTM[Nayak et al., 2021]Computer Vision,-VGG16[Rinaldi et al., 2021]NLPComputer VisionIndustry (IndustrialANN[Zhao et al., 2021]vision)-Industry 4.0 (Condi-LSTM[Zhou et al., 2021]tion monitoring)NLP-ANN[Deepak et al., 2022]NLP-Self-supervisedWord2Vec[Kumar et al., 2020]</p>
<p>Table 4 :
4
Details of articles in the Semantic Data Mining category
CategorySub-categoryAI ThemeApplication domainLearning typeLearning algorithmReasoningPaper-BiomedicalUnsupervisedFCA[Akand et al., 2007]MAS, Planning-Clustering, EM[Castillo et al., 2008]NLP-HAC[Radinsky et al., 2012]NLPFinance, CorporateLDA, LSI[Evert et al., 2019]disclosuresNLP,SentimentHealthcareEM, LDA, Hot-[Ahani et al., 2021]analysisDeckComputer Vision-k-means[Akila et al., 2021]NLPBiomedicalk-means[Pérez-Pérez et al., 2021]Semantic embed-NLPDialog state track-Supervisedbi-LSTM[Jang et al., 2018]dingingNLP,SentimentTransportSVM, LR, MLP,[Ali et al., 2019]analysiskNN, Naïve Bayes,Decision tree, DNNNLPHealthcareCNN[Gaur et al., 2019]NLPLinguisticbi-LSTM[Moussallem et al., 2019]NLPHealthcareMLP[Hassanzadeh et al., 2020]NLP-SVM[Mabrouk et al., 2020]NLPBuildingRNN[Ren et al., 2020]NLP-bi-LSTM[Alexandridis et al., 2021]NLPHealthcarebi-LSTM[Ali et al., 2021]Time series, con-Smart CityLR, RF, ASHT,[Chen et al., 2021]cept driftleveraging bagging,SGDTime seriesHealthcareGRU[Niu et al., 2022]NLP-Self-supervisedWord2Vec[Jang et al., 2018]NLP,SentimentTransportTopic2Vec[Ali et al., 2019]analysis-BiomedicalAutoencoders<a href="multipleneuralnetworks">Benarab et al., 2019</a>NLPGeoscienceGloVe, Word2Vec,[Qiu et al., 2019]Doc2VecNLPHealthcareWord2Vec (skip-[Ali et al., 2021]gram)NLP-Word2Vec[Amador-Domínguez et al., 2021]NLP,SentimentTransportUnsupervisedLDA[Ali et al., 2019]analysisNLPHealthcareLDA, Information[Ali et al., 2021]GainOntology-basedOntology-based de-NLP (Dialogue)MilitarySupervisedC4.5[Emele et al., 2012]algorithm designcision treeOntology-basedComputer VisionRoboticsSupervisedCRF[Ruiz-Sarmiento et al., 2019]probabilisticgraphical modelOntology-basedTime seriesIndustry 4.0SupervisedLSTM[Huang et al., 2019]neural topologyComputer VisionFashionCNN[Kuang et al., 2021]MASVideo GameReinforcementANN[Gabriel et al., 2014]Computer Vision,Personal PhotosSelf-supervisedTagging(Transferlearning)</p>
<p>Table 5 :
5
Details of articles in the Learning and Reasoning Systems category
CategoryAI ThemeApplication domainLearning typeML algorithmReasoningPaperExpert System Em--HealthcareSupervisedAdaboost[Khan et al., 2013]bedded Learning-Smart CityMLR, k-NN, RF[Bischof et al., 2018]-Smart CityUnsupervisedPCA[Bischof et al., 2018]Hybrid applicationMAS-SupervisedANN[Rosaci, 2007]NLP, knowledge ac-Aviation, Failure analy-BPNN[Wang et al., 2010]quisitionsisComputer Vision,Smart City, TrafficRBFNN[Keyarsalan and Montazer, 2011]Fuzzy ontologyLight Control</p>
<p>Table 5 :
5
Bekkum et al. [2021]in the Learning and Reasoning Systems categoryAs demonstrated in this study, the integration of ontology and machine learning represents a significant challenge that also brings forth new possibilities.It is important to recognize that the fusion of ontology and machine learning falls within a broader paradigm called AI hybridization, which aims to combine different types of reasoning.vanBekkumetal.[2021]hasdescribed several design patterns for hybrid AI, consisting of seven elementary patterns that characterize the types of input and output data, as well as the mechanisms employed for data processing (prediction, deduction, training, etc.).These elementary patterns are further combined to form more intricate design patterns that delineate various hybridization scenarios.In order to facilitate the utilization of this classification, we have associated each category from this SLR with the corresponding design pattern.The outcomes of this mapping are presented in table6.Notably, design pattern number 4 emerges as the most suitable for describing Ontology Learning and Ontology Mapping.Design pattern number 4 is specifically utilized for learning with symbolic output and consists of a primary block that learns from textual data and a secondary block capable of deducing insights from a new semantic model.Design pattern number 5 is dedicated to the specific objective of mitigating the widely recognized 'black-box" phenomenon inherent in some machine learning algorithms, especially deep neural networks.Within this design pattern, a symbolic model is employed following the training of a learning model to elucidate the obtained results by leveraging prior knowledge.This aligns closely with our designated category of Ontology-based explanation where the emphasis lies on utilizing ontological resources to provide comprehensible explanations.
CategoryAI ThemeApplication domainLearning typeML algorithmReasoningPaperComputer Vision,-SVM[del Rincon et al., 2013]Activity recognitionComputer Vision-ANN[Zarchi et al., 2014]Computer Vision-CNN[Ye et al., 2015b]Computer Vision-R-CNN[Donadello and Serafini, 2016]Time SeriesSmart GridsShapelet[Patri et al., 2016]MASWebRF[Mitchell et al., 2018]-Industry (alarm system)Bayesian network[Silva et al., 2018]NLPTechnologyRocchio algorithm[Shi et al., 2019]NLPFinanceLSTM[Zhang et al., 2019]Signal analysisIndustryHMM[Zhou et al., 2019]-HealthcareLogitBoost, ANN[Ali et al., 2020]Indoor localizationHealthcare, Smart envi-Decision tree (C5.0)[Woensel et al., 2020]ronmentNLPTransportMLP, GRU[Cheng and Chen, 2021]Computer Vision-R-CNN[Foo et al., 2021]ComputerVi--Bayesian networks ,[Palazzo et al., 2021]sion (fine-grainedCNNclassification)NLPAviationLSTM[Wang et al., 2021b]AmIHealthcareANN[Chung et al., 2020]Computer VisionSmart City (videoYOLO[Patel et al., 2021]surveillance)Fraud DetectionInsuranceEnsemblemethods,[Zhang et al., 2021]XGBoostComputer Vision-Unsupervisedk-means[del Rincon et al., 2013]Computer Vision-PWCA[Donadello and Serafini, 2016]MASWebk-means[Mitchell et al., 2018]AmIHealthcareAPRIORI[Chung et al., 2020]Indoor localizationHealthcare, Smart envi-PCA[Woensel et al., 2020]ronmentHuman-robot inter-RoboticsSOM[Russo et al., 2021]actionNLPFinanceSelf-supervisedWord2Vec[Zhang et al., 2019]NLPTransportWord2Vec[Cheng and Chen, 2021]7 Conclusion: challenges and research directions7.1 Hybrid AI: Design Pattern and Taxonomy</p>
<p>Table 6 :
6
Alignment of our Hybridization Categories with Van Bekkum's Design Patterns and Kautz's Taxonomy
Categoryvan Bekkum et al.Henry Kautz [2020][2021]Learning-enhanced ontologyOntology LearningDesign Pattern 4Neuro|SymbolicOntology MappingDesign Pattern 4Neuro|SymbolicLearning-based reasoningDesign Pattern 10Neuro:Symbolic→NeuroSemantic data miningOntology-based feature engineeringDesign Pattern 3bSymbolic Neuro symbolicOntology-based algorithm designDesign Pattern 7Neuro_{Symbolic}Ontology-based algorithm trainingDesign Pattern 7Neuro_{Symbolic}Ontology-based explanationDesign Pattern 5Neuro|SymbolicLearning and Reasoning systemExpert System Embedded LearningDesign Pattern 12Symbolic[Neuro]Hybrid applicationDesign Pattern 12Neuro|Symbolic7.2.1 Improve expressiveness and decidability of the ontology
Prior Analytics I.2,
24b18-20 <br />
Note that neuro-symbolic methods are not limited to ontologies
https://dl.acm.org/ccs
https://clarivate.com/webofsciencegroup/solutions/web-of-science/
https://dl.acm.org/
https://www.sciencedirect.com/
https://www.zotero.org/
http://uis.unesco.org/apps/visualisations/research-and-development-spending/
https://www.investmentmonitor.ai/ai/ai-index-us-china-artificial-intelligence
https://dl.acm.org/ccs
https://bioportal.bioontology.org/ontologies/SNOMEDCT
http://geneontology.org/docs/download-ontology/
Dedicated terms to reference articles about informed machine learning in the literature. Defines here as The prior knowledge comes from an independent source, is given by formal representations, and is explicitly integrated into the machine learning pipeline[von Rueden et al., 2021].
https://www.w3.org</p>
<p>The Quest for Artificial Intelligence. Nils J Nilsson, 10.1017/CBO97805118193462009Cambridge University Press1 edition</p>
<p>On Defining Artificial Intelligence. Pei Wang, 10.2478/jagi-2019-0002Journal of Artificial General Intelligence. 1946-016310January 2019</p>
<p>The Society of Mind. Marvin Minsky, Dimiter Dobrev. A definition of artificial intelligence. January 1986. 2012Simon and Schuster</p>
<p>M L Mccarthy, Minsky, I Rochester, C E B M Corporation, Shannon, A PROPOSAL FOR THE DARTMOUTH SUMMER RESEARCH PROJECT ON ARTIFICIAL INTELLIGENCE. AI Magazine. 1955</p>
<p>in my hand: Who's the fairest in the land? On the interpretations, illustrations, and implications of artificial intelligence. Andreas Kaplan, Michael Haenlein, Siri, Siri, 10.1016/j.bushor.2018.08.004Business Horizons. 0007-6813621February 2019</p>
<p>Artificial Intelligence: A Modern Approach. Stuart Russell, Peter Norvig, 2009Pearson3rd edition edition</p>
<p>The Republic of Plato. Plato, 1888Oxford University Press</p>
<p>Position paper: On the role of abductive reasoning in semantic image segmentation. Andrea Rafanelli, Stefania Costantini, Andrea Omicini, 2022</p>
<p>Comment on invente les hypothèses : Peirce et la théorie de l'abduction. Frédéric Roudaut, Cahiers philosophiques. 0241-2799. 00002 Bibliographie_available: 0 Cairndomain: www.cairn.info Cite Par_available: 0 Publisher1503December 2017Vrin</p>
<p>Aristotle's Logic. Robin Smith, The Stanford Encyclopedia of Philosophy. Edward N Zalta, 2020Metaphysics Research Lab, Stanford Universityfall 2020 edition</p>
<p>Artificial Intelligence: The Very Idea. John Haugeland, ; Nicola Guarino, Daniel Oberle, Steffen Staab, 10.1007/978-3-540-92673-3_0doi:10.1007/978-3-540-92673-3_0Handbook on Ontologies, International Handbooks on Information Systems. Steffen Staab, Rudi Studer, Berlin, HeidelbergSpringer1989. 2009What Is an Ontology?</p>
<p>Neuro-Symbolic Artificial Intelligence: The State of the Art. P Hitzler, M K Sarker, 2022IOS Press</p>
<p>Artur , Avila Garcez, Luis C Lamb, arXiv:2012.05876Henry Kautz. The Third AI Summer, Henry Kautz, AAAI 2020 Robert S. Engelmore Memorial Award Lecture. December 2020. February 2020Neurosymbolic AI: The 3rd Wave</p>
<p>Modular Design Patterns for Hybrid Learning and Reasoning Systems: a taxonomy, patterns and use cases. Maaike Michael Van Bekkum, Frank De Boer, André Van Harmelen, Annette Meyer-Vitali, Ten Teije, arXiv:2102.11965March 2021</p>
<p>Systematic literature reviews in software engineering -A tertiary study. Barbara Kitchenham, Rialette Pretorius, O Pearl David Budgen, Mark Brereton, Mahmood Turner, Stephen Niazi, Linkman, 10.1016/j.infsof.2010.03.006Information and Software Technology. 0950-5849528August 2010</p>
<p>Guidelines for performing systematic literature reviews in software engineering. Barbara Kitchenham, Stuart Charters, 200701Technical report</p>
<p>Automatic ontology construction from text: a review from shallow to deep learning trend. Fatima N Al-Aswadi, Huah Yong Chan, Keng Hoon Gan, 10.1007/s10462-019-09782-9Artificial Intelligence Review. 1573-7462536August 2020</p>
<p>Ontology learning: Grand tour and challenges. Ahlem Chérifa Khadir, Hassina Aliane, Ahmed Guessoum, 10.1016/j.cosrev.2020.100339Computer Science Review. 1574-0137391003392021</p>
<p>Semantic data mining: A survey of ontology-based approaches. Dejing Dou, Hao Wang, Haishan Liu, 10.1109/ICOSC.2015.7050814Proceedings of the 2015 IEEE 9th International Conference on Semantic Computing (IEEE ICSC 2015). the 2015 IEEE 9th International Conference on Semantic Computing (IEEE ICSC 2015)February 2015</p>
<p>Semantic data mining in the information age: A systematic review. Chanmee Sirichanya, Kesorn Kraisak, 10.1002/int.22443International Journal of Intelligent Systems. 1098-111X3682021</p>
<p>Which academic search systems are suitable for systematic reviews or meta-analyses? Evaluating retrieval qualities of Google Scholar, PubMed, and 26 other resources. Michael Gusenbauer, Neal R Haddaway, 10.1002/jrsm.1378Research Synthesis Methods. 1759-28871122020</p>
<p>Muhammad Usman, arXiv:2109.10134Nauman bin Ali, and Claes Wohlin. A Quality Assessment Instrument for Systematic Literature Reviews in Software Engineering. September 2021</p>
<p>Informed Machine Learning -A Taxonomy and Survey of Integrating Knowledge into Learning Systems. Sebastian Laura Von Rueden, Katharina Mayer, Bogdan Beckh, Sven Georgiev, Raoul Giesselbach, Birgit Heese, Julius Kirsch, Annika Pfrommer, Rajkumar Pick, Michal Ramamurthy, Jochen Walczak, Christian Garcke, Jannis Bauckhage, Schuecker, 10.1109/TKDE.2021.3079836IEEE Transactions on Knowledge and Data Engineering. 1041-4347, 1558-21912021</p>
<p>Biomedical ontologies: a functional perspective. L Daniel, Rubin, H Nigam, Natalya F Shah, Noy, 10.1093/bib/bbm059Briefings in Bioinformatics. 1467-546391January 2008</p>
<p>Ontology learning from text: A look back and into the future. Wilson Wong, Wei Liu, Mohammed Bennamoun, 10.1145/2333112.2333115ACM Computing Surveys. 0360-030044436September 2012</p>
<p>Ontology learning for the Semantic Web. A Maedche, S Staab, 10.1109/5254.920602Conference Name: IEEE Intelligent Systems. March 200116</p>
<p>A survey of ontology learning techniques and applications. Muhammad Nabeel, Asim , Muhammad Wasim, Muhammad Usman Ghani Khan, Waqar Mahmood, Hafiza Mahnoor, Abbasi , 10.1093/database/bay101Database. 1758-0463bay1012018. January 2018</p>
<p>Integrated Ontology Learner: Towards Generic Semantic Annotation Framework. Fekade Getahun, Kidane Woldemariyam, 10.1145/3167020.3167042Proceedings of the 9th International Conference on Management of Digital EcoSystems, MEDES '17. the 9th International Conference on Management of Digital EcoSystems, MEDES '17New York, NY, USAAssociation for Computing Machinery2017</p>
<p>A Novel Hybrid Genetic-Whale Optimization Model for Ontology Learning from Arabic Text. Rania M Ghoniem, Nawal Alhelwa, Khaled Shaalan, 10.3390/a12090182ALGORITHMS. 129September 2019Article</p>
<p>Semi-automatic terminology ontology learning based on topic modeling. Monika Rani, Amit Kumar Dhar, O P Vyas, 10.1016/j.engappai.2017.05.006Place: THE BOULEVARD. LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND PublisherArticleAugust 201763</p>
<p>Arabic Ontology Learning Using Deep Learning. Tarek Saeed Albukhitan, Ahmed Helmy, Alnazer, 10.1145/3106426.3109052Proceedings of the International Conference on Web Intelligence, WI '17. the International Conference on Web Intelligence, WI '17New York, NY, USAAssociation for Computing Machinery2017</p>
<p>Ontology Creation Using Formal Concepts Approach. Darius Jurkevičius, Olegas Vasilecas, 10.1145/1839379.1839392Proceedings of the 11th International Conference on Computer Systems and Technologies and Workshop for PhD Students in Computing on International Conference on Computer Systems and Technologies, CompSysTech '10. the 11th International Conference on Computer Systems and Technologies and Workshop for PhD Students in Computing on International Conference on Computer Systems and Technologies, CompSysTech '10New York, NY, USAAssociation for Computing Machinery2010</p>
<p>Expressive ontology learning as neural machine translation. Giulio Petrucci, Marco Rospocher, Chiara Ghidini, 10.1016/j.websem.2018.10.002JOURNAL OF WEB SEMANTICS. 1570-8268October 2018. 1000Article</p>
<p>Automatically Refining the Wikipedia Infobox Ontology. Fei Wu, Daniel S Weld, 10.1145/1367497.1367583Proceedings of the 17th International Conference on World Wide Web, WWW '08. the 17th International Conference on World Wide Web, WWW '08New York, NY, USAAssociation for Computing Machinery2008</p>
<p>Automated experiential engineering knowledge acquisition through Q&amp;A contextualization and transformation. ADVANCED ENGINEERING INFORMATICS. Bo Song, Zuhua Jiang, Lijun Liu, 10.1016/j.aei.2016.06.002Place: THE BOULEVARD. LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND PublisherArticleAugust 201630</p>
<p>A Practical Approach to Constructing a Knowledge Graph for. Yan Jia, Yulu Qi, Huaijun Shang, Rong Jiang, Aiping Li, 10.1016/j.eng.2018.01.004Cybersecurity. Engineering. 2095-8099412018</p>
<p>Usability evaluation of a web-based tool for supporting holistic building energy management. Kris Mcglinn, Baris Yuce, Hendro Wicaksono, Shaun Howell, Yacine Rezgui, 10.1016/j.autcon.2017.08.033201784Automation in Construction</p>
<p>Machine learning and knowledge graph based design rule construction for additive manufacturing. Hyunwoong Ko, Paul Witherell, Yan Lu, Samyeon Kim, David W Rosen, 10.1016/j.addma.2020.101620Additive Manufacturing. 2214-8604371016202021</p>
<p>Construction of logistics financial security risk ontology model based on risk association and machine learning. Bo Yang, 10.1016/j.ssci.2019.08.005Safety Science. 0925-75351231044372020</p>
<p>Learning to construct knowledge bases from the World Wide Web. Mark Craven, Dan Dipasquo, Dayne Freitag, Andrew Mccallum, Tom Mitchell, Kamal Nigam, Seán Slattery, 10.1016/S0004-3702(00)00004-7S0004-3702(00)00004-7Artificial Intelligence. 0004-370211812000</p>
<p>Global machine learning for spatial ontology population. Parisa Kordjamshidi, Marie-Francine Moens, 10.1016/j.websem.2014.06.001JOURNAL OF WEB SEMANTICS. 1570-826830January 2015. 1043Article</p>
<p>Action Classification in Action Ontology Building Using Robot-Specific Texts. Irena Markievicz, Jurgita Kapociute-Dzikiene, Minija Tamosiunaite, Daiva Vitkute-Adzgauskiene, 10.5755/j01.itc.44.2.7322Place: KAUNAS UNIV TECHNOL, DEPT ELECTRONICS ENGINEERING, STUDENTU STR 50, KAUNAS, LT-51368, LITHUANIA Publisher: KAUNAS UNIV TECHNOLOGY Type. Article201544</p>
<p>A system for the extraction and representation of summary of product characteristics content. Stefania Rubrichi, Silvana Quaglini, Alex Spengler, Paola Russo, Patrick Gallinari, 10.1016/j.artmed.2012.08.004ARTIFICIAL INTELLIGENCE IN MEDICINE. 0933-3657571000February 2013</p>
<p>. Amsterdam Ae, Publisher, Article</p>
<p>Cost-Effective Information Extraction from Lists in OCRed Historical Documents. Thomas L Packer, David W Embley, 10.1145/2809544.2809547Proceedings of the 3rd International Workshop on Historical Document Imaging and Processing, HIP '15. the 3rd International Workshop on Historical Document Imaging and Processing, HIP '15New York, NY, USAAssociation for Computing Machinery2015</p>
<p>Integrating multi-level deep learning and concept ontology for large-scale visual recognition. Zhenzhong Kuang, Jun Yu, Zongmin Li, Baopeng Zhang, Jianping Fan, 10.1016/j.patcog.2018.01.027Place: THE BOULEVARD. LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND PublisherArticleJune 201878</p>
<p>Ontology population with deep learning-based NLP: a case study on the Biomolecular Network Ontology. Ali Ayadi, Ahmed Samet, 10.1016/j.procs.2019.09.212Procedia Computer Science. 1877-05091592019François de Bertrand de Beuvron, and Cecilia Zanni-Merk</p>
<p>SemCaDo: A serendipitous strategy for causal discovery and ontology evolution. Montassar Ben Messaoud, Philippe Leray, Nahla Ben Amor, 10.1016/j.knosys.2014.12.006201576Knowledge-Based Systems</p>
<p>An iterative approach to build relevant ontology-aware data-driven models. Rallou Thomopoulos, Sébastien Destercke, Brigitte Charnomordic, Iyan Johnson, Joël Abécassis, 10.1016/j.ins.2012.09.015Information Sciences. 0020-02552212013</p>
<p>Building an allergens ontology and maintaining it using machine learning techniques. Alexandros G Valarakos, Vangelis Karkaletsis, Dimitra Alexopoulou, Elsa Papadimitriou, Constantine D Spyropoulos, George Vouros, 10.1016/j.compbiomed.2005.09.007Computers in Biology and Medicine. 0010-482536102006</p>
<p>RDF Shape Induction Using Knowledge Base Profiling. Nandana Mihindukulasooriya, Mohammad Rifat, Ahmmad Rashid, Giuseppe Rizzo, Raúl García-Castro, Oscar Corcho, Marco Torchiano, 10.1145/3167132.3167341Proceedings of the 33rd Annual ACM Symposium on Applied Computing, SAC '18. the 33rd Annual ACM Symposium on Applied Computing, SAC '18New York, NY, USAAssociation for Computing Machinery2018</p>
<p>Constructing Ontology of Brain Areas and Autism to Support Domain Knowledge Exploration and Discovery. Liang Hong, Haoshuai Xu, Xiaoyue Shi, 10.2991/ijcis.d.210203.005INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS. 1875-68911412021ArticlePARIS</p>
<p>Multi-Domain and Explainable Prediction of Changes in Web Vocabularies. Albert Meroño-Peñuela, Romana Pernisch, Christophe Guéret, Stefan Schlobach, 10.1145/3460210.3493583Proceedings of the 11th on Knowledge Capture Conference, K-CAP '21. the 11th on Knowledge Capture Conference, K-CAP '21New York, NY, USA; USAVirtual Event2021</p>
<p>Using Hamming Similarity to Map Ontology Learning: A New Data Mining System. Choukri Djellali, 10.1145/2513228.2513232Proceedings of the 2013 Research in Adaptive and Convergent Systems, RACS '13. the 2013 Research in Adaptive and Convergent Systems, RACS '13New York, NY, USAAssociation for Computing Machinery2013</p>
<p>Ontology mapping: the state of the art. Yannis Kalfoglou, Marco Schorlemmer, 10.1017/S0269888903000651The Knowledge Engineering Review. 1812003</p>
<p>Predicting Incorrect Mappings: A Data-Driven Approach Applied to DBpedia. Mariano Rico, Nandana Mihindukulasooriya, Dimitris Kontokostas, Heiko Paulheim, Sebastian Hellmann, Asunción Gómez-Pérez, 10.1145/3167132.3167164Proceedings of the 33rd Annual ACM Symposium on Applied Computing, SAC '18. the 33rd Annual ACM Symposium on Applied Computing, SAC '18New York, NY, USAAssociation for Computing Machinery2018</p>
<p>Building an effective and efficient background knowledge resource to enhance ontology matching. Amina Annane, Zohra Bellahsene, Faical Azouaou, Clement Jonquet, 10.1016/j.websem.2018.04.001JOURNAL OF WEB SEMANTICS. 1570-826851August 2018. 1000Article</p>
<p>Composite Ontology Matching with Uncertain Mappings Recovery. Nicola Fanizzi, Claudia Amato, Floriana Esposito, 10.1145/1964144.1964148SIGAPP Appl. Comput. Rev. 1559-6915112March 2011Association for Computing Machinery</p>
<p>Knowledge discovery through ontology matching: An approach based on an Artificial Neural Network model. M Rubiolo, M L Caliusco, G Stegmayer, M Coronel, M Gareli, Fabrizi, 10.1016/j.ins.2011.08.008Information Sciences. 0020-02551942012</p>
<p>Comparative study using inverse ontology cogency and alternatives for concept recognition in the annotated National Library of Medicine database. George J Shannon, Naga Rayapati, Steven M Corns, Donald C Wunsch, 10.1016/j.neunet.2021.01.018Neural Networks. 0893-60801392021</p>
<p>OntoConnect: Unsupervised Ontology Alignment with Recursive Neural Network. Jaydeep Chakraborty, K Srividya, Luca Bansal, Krishanu Virgili, Beyza Konar, Yaman, Proceedings of the 36th Annual ACM Symposium on Applied Computing. the 36th Annual ACM Symposium on Applied ComputingNew York, NY, USAAssociation for Computing Machinery2021</p>
<p>Low Resource Recognition and Linking of Biomedical Concepts from a Large Ontology. Sunil Mohan, Rico Angell, Nicholas Monath, Andrew Mccallum, 10.1145/3459930.3469524Proceedings of the 12th ACM Conference on Bioinformatics, Computational Biology, and Health Informatics, BCB '21. the 12th ACM Conference on Bioinformatics, Computational Biology, and Health Informatics, BCB '21New York, NY, USA; Gainesville, FloridaAssociation for Computing Machinery2021</p>
<p>An adaptive ontology mapping approach with neural network based constraint satisfaction. Ming Mao, Yefei Peng, Michael Spring, 10.1016/j.websem.2009.11.002Journal of Web Semantics. 1570-8268812010</p>
<p>Semantic information alignment of BIMs to computer-interpretable regulations using ontologies and deep learning. Peng Zhou, Nora El-Gohary, 10.1016/j.aei.2020.101239Advanced Engineering Informatics. 1474-0346481012392021</p>
<p>Pellet: A practical owl-dl reasoner. Evren Sirin, Bijan Parsia, Bernardo Cuenca Grau, Aditya Kalyanpur, Yarden Katz, Journal of Web Semantics. 522007</p>
<p>Hermit: A highly-efficient owl reasoner. Boris Robert Dc Shearer, Ian Motik, Horrocks, Owled200843291</p>
<p>Automatic Reasoner Selection Using Machine Learning. Jürgen Bock, Uta Lösch, Hai Wang, 10.1145/2254129.2254159Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics, WIMS '12. the 2nd International Conference on Web Intelligence, Mining and Semantics, WIMS '12New York, NY, USAAssociation for Computing Machinery2012</p>
<p>Predicting Reasoner Performance on ABox Intensive OWL 2 EL Ontologies. Jeff Z Pan, Carlos Bobed, Isa Guclu, Fernando Bobillo, Martin J Kollingbaum, Eduardo Mena, Yuan-Fang Li, 10.4018/IJSWIS.2018010101INTERNATIONAL JOUR-NAL ON SEMANTIC WEB AND INFORMATION SYSTEMS. 1552-628314March 2018Place: 701 E CHOCOLATE AVE, STE 200, HERSHEY, PA 17033-1240 USA Publisher: IGI GLOBAL Type: Article; Proceedings Paper</p>
<p>A machine learning approach for optimizing heuristic decisionmaking in Web Ontology Language reasoners. Razieh Mehri, Hamidreza Volker Haarslev, Chinaei, 10.1111/coin.12404COMPUTATIONAL INTELLIGENCE. 0824-7935371February 2021Article</p>
<p>Ontology Reasoning with Deep Neural Networks. Patrick Hohenecker, Thomas Lukasiewicz, Place: USC INFORMATION SCIENCES INST, 4676 ADMIRALITY WAY. MARINA DEL REY, CAArticle20206890292-6695 USA Publisher: AI ACCESS FOUNDATION Type</p>
<p>Tree-based models for inductive classification on the Web Of Data. Giuseppe Rizzo, Claudia Amato, Nicola Fanizzi, Floriana Esposito, 10.1016/j.websem.2017.05.001JOURNAL OF WEB SEMANTICS. 1570-826845August 2017. 1043Article</p>
<p>Deep learning for noise-tolerant RDFS reasoning. Bassem Makni, James Hendler, 10.3233/SW-190363SEMANTIC WEB. 1570-08441052019. 1013Article</p>
<p>Domain-Specific Ontology Concept Extraction and Hierarchy Extension. Grace Zhao, Xiaowen Zhang, 10.1145/3278293.3278302Proceedings of the 2nd International Conference on Natural Language Processing and Information Retrieval. the 2nd International Conference on Natural Language Processing and Information RetrievalNew York, NY, USAAssociation for Computing Machinery2018. 2018</p>
<p>Ontology geometry distance computation using deep learning technology. Wei Gao, Yaojun Chen, Abdul Qudair Baig, Yunqing Zhang, 10.3233/JIFS-169770Place: NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS Publisher: IOS PRESS Type. Article201835</p>
<p>Matching sensor ontologies with unsupervised neural network with competitive learning. Xingsi Xue, Haolin Wang, Wenyu Liu, 10.7717/peerj-cs.763PEERJ COMPUTER SCIENCE. 7November 2021</p>
<p>Pattern Based Feature Construction in Semantic Data Mining. Agnieszka Lawrynowicz, Jedrzej Potoniec, 10.4018/ijswis.2014010102E CHOCOLATE AVE, STE 200, HERSHEY, PA 17033-1240 USA Publisher: IGI GLOBAL Type. Article201410</p>
<p>Physics-informed machine learning. George Em Karniadakis, Ioannis G Kevrekidis, Lu Lu, Paris Perdikaris, Sifan Wang, Liu Yang, 10.1038/s42254-021-00314-5Nature Reviews Physics. 2522-582036June 2021Nature Publishing Group</p>
<p>Pablo Duboue, ID: _BzhDwAAQBAJThe Art of Feature Engineering: Essentials for Machine Learning. Cambridge University PressJune 2020</p>
<p>FNLP-ONT: A feasible ontology for improving NLP tasks in Persian. Zahra Hosseini Pozveh, Amirhassan Monadjemi, Ali Ahmadi, 10.1111/exsy.12282EXPERT SYSTEMS. 0266-472035August 2018Article</p>
<p>Ontology and Hybrid Optimization Based SVNN for Privacy Preserved Medical Data Classification in Cloud. N Gomathi, Nandkishor P Karlekar, 10.1142/S021821301950009XSINGAPORE Publisher: WORLD SCIENTIFIC PUBL CO PTE LTD Type. ArticleMay 201928SINGAPORE</p>
<p>Richard E Bellman, 10.1515/9781400874668Adaptive Control Processes: A Guided Tour. Princeton University PressDecember 1961</p>
<p>Aspect-based sentiment analysis using deep networks and stochastic optimization. Ravindra Kumar, Husanbir Singh Pannu, Avleen Kaur Malhi, 10.1007/s00521-019-04105-zPlace: 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL. ArticleApril 202032</p>
<p>A hybrid knowledge and ensemble classification approach for prediction of venous thromboembolism. Susan Sabra, Mahmood Khalid, Muhammad Malik, Vian Afzal, Ahmad Sabeeh, Eddine Charaf, 10.1111/exsy.12388EXPERT SYSTEMS. 0266-4720371February 2020Article</p>
<p>Evaluating medical travelers' satisfaction through online review analysis. Ali Ahani, Mehrbakhsh Nilashi, Waleed Abdu Zogaan, Sarminah Samad, Nojood O Aljehane, Ashwaq Alhargan, Saidatulakmal Mohd, Hossein Ahmadi, Louis Sanzogni, 10.1016/j.jhtm.2021.08.005Journal of Hospitality and Tourism Management. 1447-6770482021</p>
<p>Ontology based multiobject segmentation and classification in sports videos. K Akila, S Indra Priyadharshini, P Pradheeba Ulaganathan, B Prempriya, T Suriya Yuvasri, Praba, Veeramuthuvenkatesh, 10.3233/JIFS-189862JOURNAL OF INTELLIGENT &amp; FUZZY SYSTEMS. 1064-12464152021</p>
<p>Adaptive vision inspection for multi-type electronic products based on prior knowledge. Delong Zhao, Dun Xue, Xiaoyao Wang, Fuzhou Du, 10.1016/j.jii.2021.100283Journal of Industrial Information Integration. 2452-414X1002832021</p>
<p>Ontology-Driven Approach for Liver MRI Classification and HCC Detection. Rim Messaoudi, Faouzi Jaziri, Achraf Mtibaa, Faiez Gargouri, Antoine Vacavant, 10.1142/S0218001421600077INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE. 0218-00143512September 2021</p>
<p>A semantic approach for document classification using deep neural networks and multimedia knowledge graph. Antonio M Rinaldi, Cristiano Russo, Cristian Tommasino, 10.1016/j.eswa.2020.114320Expert Systems with Applications. 0957-41741691143202021</p>
<p>Photovoltaic generation power prediction research based on high quality context ontology and gated recurrent neural network. Hongfei Liu, Qian Gao, Pengcheng Ma, 10.1016/j.seta.2021.101191Sustainable Energy Technologies and Assessments. 202145101191</p>
<p>Exploiting ontology information in fuzzy SVM social media profile classification. APPLIED INTELLIGENCE. Olfa Mabrouk, Lobna Hlaoua, Mohamed Nazih Omri, 10.1007/s10489-020-01939-23311 GZ DORDRECHT, NETHERLANDS Publisher: SPRINGER Type: Article; Early Access. November 2020</p>
<p>Auto Insurance Knowledge Graph Construction and Its Application to Fraud Detection. Long Zhang, Tianxing Wu, Xiuqi Chen, Bingjie Lu, Chongning Na, Guilin Qi, 10.1145/3502223.3502231The 10th International Joint Conference on Knowledge Graphs, IJCKG'21. New York, NY, USAAssociation for Computing Machinery2021</p>
<p>Knowledge graph embeddings for dealing with concept drift in machine learning. Jiaoyan Chen, Freddy Lecue, Jeff Z Pan, Shumin Deng, Huajun Chen, 10.1016/j.websem.2020.100625JOURNAL OF WEB SEMANTICS. 1570-826867February 2021. 1043Article</p>
<p>An Ontology Embedding Approach Based on Multiple Neural Networks. Achref Benarab, Fahad Rafique, Jianguo Sun, 10.1145/3318299.3318365Proceedings of the 2019 11th International Conference on Machine Learning and Computing, ICMLC '19. the 2019 11th International Conference on Machine Learning and Computing, ICMLC '19New York, NY, USAAssociation for Computing Machinery2019</p>
<p>Cross-Language Neural Dialog State Tracker for Large Ontologies Using Hierarchical Attention. Youngsoo Jang, Jiyeon Ham, Byung-Jun Lee, Kee-Eung Kim, 10.1109/TASLP.2018.2852492IEEE/ACM Trans. Audio, Speech and Lang. Proc. 2329-92902611November 2018</p>
<p>An intelligent healthcare monitoring framework using wearable sensors and social networking data. Farman Ali, Shaker El-Sappagh, S M Islam, Amjad Ali, Muhammad Attique, Muhammad Imran, Kyung-Sup Kwak, 10.1016/j.future.2020.07.047Future Generation Computer Systems. 0167-739X1142021</p>
<p>An ontology-based deep learning approach for triple classification with out-of-knowledge-base entities. Elvira Amador-Domínguez, Emilio Serrano, Daniel Manrique, Patrick Hohenecker, Thomas Lukasiewicz, 10.1016/j.ins.2021.02.018Information Sciences. 0020-02555642021</p>
<p>Learning strategies for task delegation in norm-governed environments. Chukwuemeka David Emele, Timothy J Norman, Murat Sensoy, Simon Parsons, ; Gz Dordrecht, Publisher, 10.1007/s10458-012-9194-9AUTONOMOUS AGENTS AND MULTI-AGENT SYSTEMS. 1387-253225November 2012Article</p>
<p>Ontology-based conditional random fields for object recognition. Jose-Raul Ruiz-Sarmiento, Cipriano Galindo, Javier Monroy, Francisco-Angel Moreno, Javier Gonzalez, -Jimenez , 10.1016/j.knosys.2019.01.005KNOWLEDGE-BASED SYSTEMS. 0950-7051168March 2019. 1043Article</p>
<p>Neuroevolution Based Multi-Agent System with Ontology Based Template Creation for Micromanagement in Real-Time Strategy Games. Iuhasz Gabriel, Viorel Negru, Daniela Zaharie, 10.5755/j01.itc.43.1.4600Place: KAUNAS UNIV TECHNOL, DEPT ELECTRONICS ENGINEERING, STUDENTU STR 50, KAUNAS, LT-51368, LITHUANIA Publisher: KAUNAS UNIV TECHNOLOGY Type. Article201443</p>
<p>Enhancing Deep Learning with Semantics: an application to manufacturing time series analysis. Xin Huang, Cecilia Zanni-Merk, Bruno Crémilleux, 10.1016/j.procs.2019.09.198Procedia Computer Science. 1877-05091592019</p>
<p>Deep embedding of concept ontology for hierarchical fashion recognition. Zhenzhong Kuang, Xin Zhang, Jun Yu, Zongmin Li, Jianping Fan, 10.1016/j.neucom.2020.04.085NEUROCOMPUTING. 0925-2312425February 2021. 1043Article</p>
<p>Tagging Personal Photos with Transfer Deep Learning. Jianlong Fu, Tao Mei, Kuiyuan Yang, Hanqing Lu, Yong Rui, 10.1145/2736277.2741112Proceedings of the 24th International Conference on World Wide Web, WWW '15. the 24th International Conference on World Wide Web, WWW '152015International World Wide Web Conferences Steering Committee</p>
<p>Learning and Reasoning in Logic Tensor Networks: Theory and Application to Semantic Image Interpretation. Luciano Serafini, Ivan Donadello, Artur D'avila Garcez, 10.1145/3019612.3019642Proceedings of the Symposium on Applied Computing, SAC '17. the Symposium on Applied Computing, SAC '17New York, NY, USAAssociation for Computing Machinery2017</p>
<p>Combining ontologies and Machine Learning for Explainable Artificial Intelligence. Pablo Donís, Ebri , 2021Master's thesis, E.T.S. de Ingenieros Informáticos (UPM</p>
<p>A Unified Approach to Interpreting Model Predictions. M Scott, Su-In Lundberg, Lee, Advances in Neural Information Processing Systems. Curran Associates, Inc201730</p>
<p>Why Should I Trust You?. Marco Tulio Ribeiro, Sameer Singh, Carlos Guestrin, arXiv:1602.04938arXiv: 1602.04938Explaining the Predictions of Any Classifier. August 20168107cs, stat</p>
<p>Using ontologies to enhance human understandability of global post-hoc explanations of black-box models. Roberto Confalonieri, Tillman Weyde, R Tarek, Fermín Moscoso Besold, Del Prado Martín, 10.1016/j.artint.2021.103471Artificial Intelligence. 0004-37022961034712021</p>
<p>Doctor XAI: An Ontology-Based Approach to Black-Box Sequential Data Classification Explanations. Cecilia Panigutti, Alan Perotti, Dino Pedreschi, 10.1145/3351095.3372855Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency, FAT<em> '20. the 2020 Conference on Fairness, Accountability, and Transparency, FAT</em> '20New York, NY, USAAssociation for Computing Machinery2020</p>
<p>UICO: An Ontology-Based User Interaction Context Model for Automatic Task Detection on the Computer Desktop. Andreas S Rath, Didier Devaurs, Stefanie N Lindstaedt, 10.1145/1552262.1552270Proceedings of the 1st Workshop on Context, Information and Ontologies, CIAO '09. the 1st Workshop on Context, Information and Ontologies, CIAO '09New York, NY, USAAssociation for Computing Machinery2009</p>
<p>Enhanced Topic-based Vector Space Model for semantics-aware spam filtering. Igor Santos, Carlos Laorden, Borja Sanz, Pablo G Bringas, 10.1016/j.eswa.2011.07.034Place: THE BOULEVARD, LANGFORD LANE, KIDLING-TON, OXFORD OX5 1GB, ENGLAND Publisher: PERGAMON-ELSEVIER SCIENCE LTD Type. ArticleJanuary 201239</p>
<p>Encoding symbolic features in simple decision systems over ontological graphs for PSO and neural network based classifiers. Krzysztof Pancerz, Arkadiusz Lewicki, 10.1016/j.neucom.2014.04.038NEUROCOMPUTING. 0925-2312144November 2014. 1000Article</p>
<p>Predicting subcellular localization of multi-location proteins by improving support vector machines with an adaptive-decision scheme. Shibiao Wan, Man-Wai Mak, 10.1007/s13042-015-0460-4INTERNATIONAL JOURNAL OF MACHINE LEARNING AND CYBERNETICS. 1868-80719March 2018Article</p>
<p>Methodology for improving classification accuracy using ontologies: application in the recognition of activities of daily living. A G Salguero, J Medina, P Delatorre, M Espinilla, 10.1007/s12652-018-0769-4JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING. 1868-5137June 2019Article</p>
<p>Substituting clinical features using synthetic medical phrases: Medical text data augmentation techniques. Mahdi Abdollahi, Xiaoying Gao, Yi Mei, Shameek Ghosh, Jinyan Li, Michael Narag, 10.1016/j.artmed.2021.102167Artificial Intelligence in Medicine. 0933-36571201021672021</p>
<p>Evaluating the Traditional Chinese Medicine (TCM) Officially Recommended in China for COVID-19 Using Ontology-Based Side-Effect Prediction Framework (OSPF) and Deep Learning. Zeheng Wang, Liang Li, Miao Song, Jing Yan, Junjie Shi, Yuanzhe Yao, 10.1016/j.jep.2021.113957Journal of Ethnopharmacology. 0378-87412721139572021a</p>
<p>USMART: An Unsupervised Semantic Mining Activity Recognition Technique. Juan Ye, Graeme Stevenson, Simon Dobson, 10.1145/266287010121-0701 USA Publisher: ASSOC COMPUTING MACHINERY Type: ArticleACM TRANSACTIONS ON INTERACTIVE INTELLIGENT SYSTEMS. 2160-6455701January 2015a4(4, SI</p>
<p>Wine Ontology Influence in a Recommendation System. Luis Oliveira, Rodrigo Rocha Silva, Jorge Bernardino, 10.3390/bdcc5020016BIG DATA AND COGNITIVE COMPUTING. 52June 2021</p>
<p>samap: An user-oriented adaptive system for planning tourist visits. Luis Castillo, Eva Armengol, Eva Onaindía, Laura Sebastiá, Jesús González-Boticario, Antonio Rodríguez, Susana Fernández, Juan D Arias, Daniel Borrajo, 10.1016/j.eswa.2006.12.029Expert Systems with Applications. 0957-41743422008</p>
<p>BNOSA: A Bayesian network and ontology based semantic annotation framework. Quratulain Rajput, Sajjad Haider, 10.1016/j.websem.2011.04.002Journal of Web Semantics. 1570-8268922011</p>
<p>The transformation of surgery patient care with a clinical research information system. Nan-Chen Hsieh, Kuo-Chen Lee, Wei Chen, 10.1016/j.eswa.2012.07.020Place: THE BOULEVARD. LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND PublisherArticleJanuary 201340</p>
<p>Concept-Level Sentiment Analysis with Dependency-Based Semantic Parsing: A Novel Approach. Basant Agarwal, Soujanya Poria, Namita Mittal, Alexander Gelbukh, Amir Hussain, 10.1007/s12559-014-9316-6Place: ONE NEW YORK PLAZA, SUITE 4600. NEW YORK, NY, UNITED STATES Publisher; TypeArticleAugust 20157</p>
<p>Intelligent text classification system based on self-administered ontology. Manoj Manuja, Deepak Garg, 10.3906/elk-1305-112TURKISH JOURNAL OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCES. 1300-06322352015Article</p>
<p>Matching points of interest with user context: an ANN approach. Ozgun Yilmaz, 10.3906/elk-1503-61TURKISH JOURNAL OF ELECTRI-CAL ENGINEERING AND COMPUTER SCIENCES. 1300-06322542017Article</p>
<p>Combining Machine Learning and Semantic Features in the Classification of Corporate Disclosures. Stefan Evert, Philipp Heinrich, Klaus Henselmann, Ulrich Rabenstein, Elisabeth Scherr, Martin Schmitt, Lutz Schroeder, ; Gz Dordrecht, Publisher, 10.1007/s10849-019-09283-6JOURNAL OF LOGIC LANGUAGE AND INFORMATION. 0925-8531282June 2019Article</p>
<p>Improving documentation of presenting problems in the emergency department using a domainspecific ontology and machine learning-driven user interfaces. Nathaniel R Greenbaum, Yacine Jernite, Yoni Halpern, Shelley Calder, Larry A Nathanson, David A Sontag, Steven Horng, 10.1016/j.ijmedinf.2019.103981International Journal of Medical Informatics. 1386-50561321039812019</p>
<p>A new semantic-based feature selection method for spam filtering. Jose R Mendez, Tomas R Cotos-Yanez, David Ruano-Ordas, 10.1016/j.asoc.2018.12.008APPLIED SOFT COMPUTING. 1568-494676March 2019. 1043Article</p>
<p>A Framework for Integrating Domain Knowledge in Logistic Regression with Application to Hospital Readmission Prediction. Sandro Radovanovic, Boris Delibasic, Milos Jovanovic, Milan Vukicevic, Milija Suknovic, 10.1142/S0218213019600066Place: 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE Publisher: WORLD SCIENTIFIC PUBL CO PTE LTD Type. ArticleSeptember 201928</p>
<p>Experience: Automated Prediction of Experimental Metadata from Scientific Publications. Stuti Nayak, Amrapali Zaveri, Pedro Hernandez Serrano, Michel Dumontier, 10.1145/3451219J. Data and Information Quality. 1936-1955134August 2021Association for Computing Machinery</p>
<p>SemML: Facilitating development of ML models for condition monitoring with semantics. Baifan Zhou, Yulia Svetashova, Andre Gusmao, Ahmet Soylu, Gong Cheng, Ralf Mikut, Arild Waaler, Evgeny Kharlamov, 10.1016/j.websem.2021.100664Journal of Web Semantics. 1570-8268711006642021</p>
<p>An artificially intelligent approach for automatic speech processing based on triune ontology and adaptive tribonacci deep neural networks. Gerard Deepak, Deepak Surya, Ishdutt Trivedi, Ayush Kumar, 10.1016/j.compeleceng.2022.107736Amrutha Lingampalli, and Santhana vijayan. 202298107736</p>
<p>Learning from Ontological Annotation: An Application of Formal Concept Analysis to Feature Construction in the Gene Ontology. Elma Akand, Michael Bain, Mark Temple, Proceedings of the Third Australasian Workshop on Advances. the Third Australasian Workshop on AdvancesAustralian Computer Society200785AOW '07</p>
<p>Learning to Predict from Textual Data. Kira Radinsky, Sagie Davidovich, Shaul Markovitch, 10.1613/jair.3865Place: USC INFORMATION SCIENCES INST, 4676 ADMIRALITY WAY. MARINA DEL REY, CAArticle20124590292-6695 USA Publisher: AI ACCESS FOUNDATION Type</p>
<p>A framework to extract biomedical knowledge from gluten-related tweets: The case of dietary concerns in digital era. Martín Pérez-Pérez, Gilberto Igrejas, Florentino Fdez-Riverola, Anália Lourenço, 10.1016/j.artmed.2021.102131Artificial Intelligence in Medicine. 0933-36571181021312021</p>
<p>Transportation sentiment analysis using word embedding and ontology-based topic modeling. Farman Ali, Daehan Kwak, Pervez Khan, Shaker El-Sappagh, Amjad Ali, Sana Ullah, Kye , Hyun Kim, Kyung-Sup Kwak, 10.1016/j.knosys.2019.02.033KNOWLEDGE-BASED SYSTEMS. NX AMSTERDAM, NETHERLANDS Publisher; TypeArticleJune 2019. 1043174</p>
<p>Knowledge-Aware Assessment of Severity of Suicide Risk for Early Intervention. Manas Gaur, Amanuel Alambo, Joy Prakash Sain, Ugur Kursuncu, Krishnaprasad Thirunarayan, Ramakanth Kavuluru, Amit Sheth, Randy Welton, Jyotishman Pathak, 10.1145/3308558.3313698The World Wide Web Conference, WWW '19. New York, NY, USAAssociation for Computing Machinery2019</p>
<p>Utilizing Knowledge Graphs for Neural Machine Translation Augmentation. Diego Moussallem, Axel-Cyrille Ngonga Ngomo, Paul Buitelaar, Mihael Arcan, 10.1145/3360901.3364423Proceedings of the 10th International Conference on Knowledge Capture, K-CAP '19. the 10th International Conference on Knowledge Capture, K-CAP '19New York, NY, USAAssociation for Computing Machinery2019</p>
<p>Matching patients to clinical trials using semantically enriched document representation. Hamed Hassanzadeh, Sarvnaz Karimi, Anthony Nguyen, 10.1016/j.jbi.2020.103406Journal of Biomedical Informatics. 1532-04641051034062020</p>
<p>Information Retrieval Based on Knowledge-Enhanced Word Embedding Through Dialog: A Case Study. Jin Ren, Hengsheng Wang, Tong Liu, 10.2991/ijcis.d.200310.002INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS. 1875-68911312020ArticlePARIS</p>
<p>A Knowledge-Based Deep Learning Architecture for Aspect-Based Sentiment Analysis. Georgios Alexandridis, John Aliprantis, Konstantinos Michalakis, Konstantinos Korovesis, Panagiotis Tsantilas, George Caridakis, 10.1142/S0129065721500465INTERNATIONAL JOURNAL OF NEURAL SYSTEMS. 0129-06573110October 2021</p>
<p>Fusion of sequential visits and medical ontology for mortality prediction. Ke Niu, You Lu, Xueping Peng, Jingni Zeng, 10.1016/j.jbi.2022.104012Journal of Biomedical Informatics. 1532-04641271040122022</p>
<p>Geoscience keyphrase extraction algorithm using enhanced word embedding. Qinjun Qiu, Zhong Xie, Liang Wu, Wenjia Li, 10.1016/j.eswa.2019.02.001Place: THE BOULEVARD. LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND PublisherArticleJuly 2019125</p>
<p>A smart healthcare monitoring system for heart disease prediction based on ensemble deep learning and feature fusion. Farman Ali, Shaker El-Sappagh, S M Islam, Daehan Kwak, Amjad Ali, Muhammad Imran, Kyung-Sup Kwak, 10.1016/j.inffus.2020.06.008INFORMATION FUSION. 1566-253563November 2020. 1043Article</p>
<p>The Handbook of Applied Expert Systems. Jay Liebowitz, 1997CRC Press</p>
<p>Validation of an Ontological Medical Decision Support System for Patient Treatment Using a Repository of Patient Data: Insights into the Value of Machine Learning. Atif Khan, John A Doucette, Robin Cohen, 10.1145/2508037.250804910121-0701 USA Publisher: ASSOC COMPUTING MACHINERY Type: ArticleACM TRANSACTIONS ON INTELLIGENT SYSTEMS AND TECHNOLOGY. 2157-690444September 2013</p>
<p>Enriching integrated statistical open city data by combining equational knowledge and missing value imputation. Stefan Bischof, Andreas Harth, Benedikt Kaempgen, Axel Polleres, Patrik Schneider, 10.1016/j.websem.2017.09.003JOURNAL OF WEB SEMANTICS. 1570-826848January 2018. 1043Article</p>
<p>A semantic model for general purpose contentbased image retrieval systems. Mohsen Sardari Zarchi, Amirhasan Monadjemi, Kamal Jamshidi, 10.1016/j.compeleceng.2014.07.008Computers &amp; Electrical Engineering. 0045-79064072014</p>
<p>EventNet: A Large Scale Structured Concept Library for Complex Event Detection in Video. Guangnan Ye, Yitong Li, Hongliang Xu, Dong Liu, Shih-Fu Chang, 10.1145/2733373.2806221Proceedings of the 23rd ACM International Conference on Multimedia, MM '15. the 23rd ACM International Conference on Multimedia, MM '15New York, NY, USAAssociation for Computing Machinery2015b</p>
<p>Integration of numeric and symbolic information for semantic image interpretation. Ivan Donadello, Luciano Serafini, 10.3233/IA-160093INTELLIGENZA ARTIFICIALE. 1724-80351012016. 1013Article</p>
<p>Exploiting structured high-level knowledge for domain-specific visual classification. S Palazzo, F Murabito, C Pino, F Rundo, D Giordano, M Shah, C Spampinato, 10.1016/j.patcog.2020.107806Place: THE BOULEVARD. LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND PublisherArticleApril 2021112</p>
<p>Knowledge acquisition method from domain text based on theme logic model and artificial neural network. Jun Wang, Yunpeng Wu, Xuening Liu, Xiaoying Gao, 10.1016/j.eswa.2009.05.009Expert Systems with Applications. 0957-41743712010</p>
<p>An ATC instruction processing-based trajectory prediction algorithm designing. Xuan Wang, Yi Mao, Xiaoyong Wu, Qucheng Xu, Weiyu Jiang, Suwan Yin, 10.1007/s00521-021-05713-4Place: 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND Publisher: SPRINGER LONDON LTD Type: Article; Early Access. January 2021b</p>
<p>Designing an intelligent ontological system for traffic light control in isolated intersections. Maryam Keyarsalan, Gholam Ali Montazer, 10.1016/j.engappai.2011.03.005Engineering Applications of Artificial Intelligence. 0952-19762482011</p>
<p>Video representation and suspicious event detection using semantic technologies. Ashish Singh, Patel , Giovanni Merlino, Dario Bruneo, Antonio Puliafito, O P Vyas, Muneendra Ojha, 10.3233/SW-200393Place: NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS Publisher: IOS PRESS Type. Article202112</p>
<p>CILIOS: Connectionist inductive learning and inter-ontology similarities for recommending information agents. D Rosaci, 10.1016/j.is.2006.06.003Information Systems. 0306-43793262007</p>
<p>Common-sense reasoning for human action recognition. Jesus Martinez Del Rincon, Maria J Santofimia, Jean-Christophe Nebel, 10.1016/j.patrec.2012.10.020PATTERN RECOGNITION LETTERS. 0167-865534November 2013. 1043Article</p>
<p>Sensors to Events: Semantic Modeling and Recognition of Events from Data Streams. Prasad Om, Anand V Patri, Panangadan, S Vikrambhai, Viktor K Sorathia, Prasanna, 10.1142/S1793351X16400171Place: 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE Publisher: WORLD SCIENTIFIC PUBL CO PTE LTD Type. ArticleDecember 201610</p>
<p>Never-Ending Learning. T Mitchell, W Cohen, E Hruschka, P Talukdar, B Yang, J Betteridge, A Carlson, B Dalvi, M Gardner, B Kisiel, J Krishnamurthy, N Lao, K Mazaitis, T Mohamed, N Nakashole, E Platanios, A Ritter, M Samadi, B Settles, R Wang, D Wijaya, A Gupta, X Chen, A Saparov, M Greaves, J Welling, 10.1145/3191513Commun. ACM. 0001-0782615April 2018Association for Computing Machinery</p>
<p>Context-Aware Recommendation for Industrial Alarm System. J Márcio, Carlos E Da Silva, Marcelo Pereira, Götz, 10.1016/j.ifacol.2018.08.266IFAC-PapersOnLine. 2405-896351112018</p>
<p>Ontology-based code snippets management in a cloud environment. Jianjun Shi, Weixing Ji, Zhiwei Gao, Yujin Gao, Yizhuo Wang, Xinyi Liao, Feng Shi, 10.1007/s12652-018-0701-yJOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING. 1868-5137August 2019Article</p>
<p>A hybrid neural network approach for fine-grained emotion classification and computing. Wei Zhang, Meng Wang, Yanchun Zhu, Jian Wang, Nasor Ghei, 10.3233/JIFS-179111Place: NIEUWE HEMWEG 6B. BG AMSTERDAM, NETHERLANDS PublisherArticle2019. 101337</p>
<p>A hybrid fault diagnosis method for mechanical components based on ontology and signal analysis. Qiang Zhou, Ping Yan, Huayi Liu, Yang Xin, ; Gz Dordrecht, Publisher, 10.1007/s10845-017-1351-1JOURNAL OF INTELLIGENT MANUFACTURING. 0956-5515304April 2019Article</p>
<p>Indoor location identification of patients for directing virtual care: An AI approach using machine learning and knowledge-based methods. William Van Woensel, Patrice C Roy, Syed Sibte Raza, Samina Abidi, Abidi Raza, 10.1016/j.artmed.2020.101931Artificial Intelligence in Medicine. 0933-36571081019312020</p>
<p>A location conversion method for roads through deep learning-based semantic matching and simplified qualitative direction knowledge representation. Ruozhen Cheng, Jing Chen, 10.1016/j.engappai.2021.104400Engineering Applications of Artificial Intelligence. 0952-19761041044002021</p>
<p>Screw detection for disassembly of electronic waste using reasoning and re-training of a deep learning model. Gwendolyn Foo, Sami Kara, Maurice Pagnucco, 10.1016/j.procir.2021.01.172Procedia CIRP. 2212-8271982021</p>
<p>Ambient context-based modeling for health risk assessment using deep neural network. Kyungyong Chung, Hyun Yoo, Do-Eun Choe, 10.1007/s12652-018-1033-7JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING. 1868-513711April 2020Article</p>
<p>An Unsupervised Approach for Knowledge Construction Applied to Personal Robots. Cristiano Russo, Kurosh Madani, Antonio Maria Rinaldi, 10.1109/TCDS.2020.2983406Place: 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA Publisher: IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC Type. ArticleMarch 202113</p>
<p>DARPA's Explainable Artificial Intelligence (XAI) Program. AI Magazine. David Gunning, David Aha, 10.1609/aimag.v40i2.2850201940</p>            </div>
        </div>

    </div>
</body>
</html>