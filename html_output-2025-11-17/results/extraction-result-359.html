<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-359 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-359</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-359</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-16.html">extraction-schema-16</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <p><strong>Paper ID:</strong> paper-263860008</p>
                <p><strong>Paper Title:</strong> The International Journal of Digital Curation</p>
                <p><strong>Paper Abstract:</strong> There is almost universal agreement that scientific data should be shared for use beyond the purposes for which they were initially collected. Access to data enables system-level science, expands the instruments and products of research to new communities, and advances solutions to complex human problems. While demands for data are not new, the vision of open access to data is increasingly ambitious. The aim is to make data accessible and usable to anyone, anytime, anywhere, and for any purpose. Until recently, scholarly investigations related to data sharing and reuse were sparse. They have become more common as technology and instrumentation have advanced, policies that mandate sharing have been implemented, and research has become more interdisciplinary. Each of these factors has contributed to what is commonly referred to as the “data deluge”. Most discussions about increases in the scale of sharing and reuse have focused on growing amounts of data. There are other issues related to open access to data that also concern scale which have not been as widely discussed: broader participation in data sharing and reuse, increases in the number and types of intermediaries, and more digital data products. The purpose of this paper is to develop a research agenda for scientific data sharing and reuse that considers these three areas. 1</p>
                <p><strong>Cost:</strong> 0.011</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e359.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e359.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Mammogram DB → Epidemiology</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Use of a national database of mammogram images by epidemiologists</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Transfer of a medical imaging data resource (national mammogram image database) from clinical/radiological contexts to epidemiological research to investigate population-level factors in breast cancer.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>Use of medical imaging databases for epidemiological analysis</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>Collecting large-scale mammogram image datasets (a national database) originally gathered for clinical/radiological purposes, and reusing those image collections as input data for epidemiological analyses (e.g., to study risk factors, incidence, and population patterns). This involves discovering relevant image records, linking images to associated metadata (patient demographics, clinical annotations), and applying population-level statistical and image-analysis methods to derive epidemiological inferences.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>data reuse / analytical application of existing data resources</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>medical imaging / radiology / clinical medicine</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>epidemiology / public health research</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>direct application of existing data resource to a different analytic domain (data repurposing)</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>Not detailed in the paper; implied needs include mapping clinical metadata to epidemiologic variables and possibly reformatting or annotating images for large-scale analysis and de-identification to meet privacy requirements.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>Described as potentially useful (paper gives the example that a national mammogram database may be useful to epidemiologists) but no empirical outcome data are provided in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>Differences in required metadata and contextual information, privacy/confidentiality concerns, and lack of documentation or metadata formatted for epidemiologic reuse; the paper notes general difficulties in reusing data collected in another community because of embedded local context.</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>Availability of large, centralized databases; existence of metadata linking images to relevant clinical/demographic information; interdisciplinary demand for such data.</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>Need for appropriate metadata, de-identification/privacy safeguards, domain expertise in both radiology and epidemiology, and tools to map clinical terminologies to epidemiologic variables.</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>Potentially generalizable to other cases where clinical/diagnostic image collections are repurposed for population-level study, but success depends on metadata quality and privacy handling.</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>explicit procedural steps (data reuse workflows) and instrumental/technical skills (data linkage and statistical/image-analysis techniques)</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e359.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e359.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Citizen science → Ecology (phenology)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Use of volunteer-collected phenology and migration observations by ecologists to study climate change</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Application of observational data collected by amateur naturalists (flowering time, bird migration) to professional ecological research on climate change impacts.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>Incorporation of volunteer observational datasets into ecological research (phenology studies)</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>Amateur/volunteer observers collect field observations (dates of flowering, bird migration timings, etc.) which are aggregated into datasets and then analyzed by ecologists to identify large-scale temporal patterns and shifts (e.g., phenological changes attributable to climate change). The procedure includes data collection protocols for volunteers, aggregation and standardization of observations, quality control/validation, and statistical time-series analyses.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>data collection protocol (citizen science) and data reuse/analysis</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>amateur/naturalist observational practice (citizen science / informal natural history)</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>professional ecology / climate science</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>adapted/modified for new context (scientists reuse volunteer data with validation and aggregation)</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>Scientists applied validation/quality-control procedures and statistical analyses to adapt informal observations for scientific use; specific modifications not exhaustively detailed in the paper but include aggregation, cross-checking, and possibly calibration against instrumented records.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>Presented as a successful example: the paper cites ecologists using amateur-collected flowering and bird migration data to study climate change (Whitfield, 2001). Quantitative metrics are not provided in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>Trust in data quality, variable observer expertise, lack of standardized protocols, missing contextual metadata (how/where observations were made).</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>Sufficiently large number of observations over long time periods; some reporting of observer expertise or confidence; domain scientists' ability to statistically accommodate noisy observations; relevance of the phenomena (large-scale, robust signals such as phenology shifts).</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>Mechanisms for recording observer metadata (skill, confidence), aggregation platforms, validation procedures, and domain expertise to interpret volunteer data.</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>Potentially generalizable to other ecological and environmental monitoring contexts where broad spatial/temporal coverage from volunteers can complement professional data, but generalizability depends on the phenomenon's signal-to-noise ratio and data validation procedures.</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>tacit/practical know-how (how to collect observations) combined with explicit procedural steps for aggregation and validation</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e359.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e359.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CDL contributor workflow</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>California Digital Library contributor self-assessment and third-party expert review workflow for citizen-submitted observations</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Adapted submission procedures instituted by the California Digital Library requiring contributors to report expertise/experience/confidence and subjecting volunteer observations to third-party expert review to support scientist reuse.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>Contributor self-assessment plus third-party expert review workflow for curating volunteer-submitted observations</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>When non-scientists submit observational data, contributors are asked to provide metadata about their expertise, experience, and confidence; submitted observations are then routed to third-party experts for review/validation before incorporation into research-accessible resources. This adds provenance and quality indicators to otherwise informal data.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>curation workflow / quality-control protocol</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>citizen-submitted observational data repositories / informal data collection</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>scientific data archives and reuse by professional scientists</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>adaptation of repository submission processes to accommodate volunteer-contributed data (procedural modification)</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>Introduction of mandatory contributor self-assessment fields and a formal third-party expert review step; these were added to standard repository ingestion workflows to provide assessable metadata and vetting for non-expert contributions.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>Partially successful: the paper reports these processes were implemented but 'did not resolve all the concerns of scientist users' (Van House, 2003) — i.e., they helped but trust issues remained.</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>Persisting scientist concerns about trust and quality despite added metadata and reviews, difficulty scaling expert review, variable reliability of self-assessment, and residual lack of context/standardization.</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>Provision of explicit contributor metadata, involvement of domain experts in review, repository infrastructure to collect and store metadata.</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>Access to domain experts for review, submission interfaces that capture contributor metadata, and policies clarifying accepted levels of evidence/validation.</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>Partially generalizable to other repositories accepting volunteer data, but scalability and residual trust issues limit straightforward transfer without additional mechanisms (automated QC, community curation).</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>explicit procedural steps (workflow design) and interpretive frameworks (trust and validation criteria)</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e359.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e359.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Scientific workflows / myExperiment</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Scientific workflow systems and social virtual research environments (e.g., myExperiment) applied to documentation and community curation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Applying computational workflow management systems and social virtual research environments, originally designed for reproducible computational experiments, to capture documentation and support community curation of research data.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>Use of scientific workflow systems and social virtual research environments for data documentation and community curation</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>Scientific workflow systems formalize sequences of computational steps (data ingestion, transformation, analysis) and can record provenance; social virtual research environments (e.g., myExperiment) enable sharing and ‘social’ re-use of these workflows. The idea is to reuse these systems to capture the procedural context around data (how data were processed), enable community annotation, and support reuse by others.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>computational provenance capture / collaboration platform</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>computational e-science / bioinformatics / computer science (workflow management)</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>data curation / documentation practices across scientific domains</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>analogical/adaptive transfer combining existing workflow tech with data curation needs (adapted/modified for documentation and community curation)</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>Not extensively detailed in the paper; suggestions include repurposing provenance-capture features to document experimental context and using social features for community curation — modifications likely include UI/metadata tailoring and integration with data repositories.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>Unproven/uncertain in this paper: authors note 'anecdotal evidence suggests scientific workflows and social media might be useful' but 'very little research has been done to measure their effectiveness.'</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>Lack of empirical assessment of effectiveness, potential mismatch between workflow metadata and domain-specific documentation needs, sociotechnical barriers to adoption by data producers.</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>Existing provenance capture capabilities, community-sharing affordances of social virtual research environments, and increasing computationalization of analysis pipelines.</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>Integration with domain repositories, incentives for researchers to publish workflows and provenance, and tools to reduce burden of generating useful documentation.</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>Potentially generalizable across computationally intensive domains; effectiveness for laboratory or observational domains with less formalized computational steps is less clear without adaptation.</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>instrumental/technical skills (workflow use), explicit procedural steps (captured provenance), and tacit/practical know-how (community curation practices)</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e359.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e359.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Virtual Organizations (VOs)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Virtual organizations applying cyberinfrastructure for distributed resource access and domain-specific data analysis</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Application of VO models and grid/cyberinfrastructure technologies to provide access to distributed instruments, tools and data and to support domain-specific analysis and visualization.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>Deployment of virtual-organization cyberinfrastructure for data sharing and integrated analysis</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>VOs create coordinated, distributed infrastructures (middleware, data services, analytic/visualization tools) that allow scientists to put data into shared spaces and perform analysis across distributed resources. They often include domain-specific tools and interfaces to work with data as well as mechanisms for collaboration.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>infrastructure deployment / computational collaboration platform</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>computer science / grid computing / cyberinfrastructure</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>domain sciences requiring distributed data/instrument access (e.g., astronomy, earth sciences, biomedical informatics)</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>direct application/adaptation of cyberinfrastructure concepts and tools to domain science needs (hybrid approach combining tech with domain expertise)</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>VOs develop specialized domain tools and tailor middleware/services to domain instruments and data formats; paper notes they may lack large-scale archive management expertise, implying hybridization with archives is needed.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>Mixed: VOs have succeeded in providing collaborative access and specialized analysis tools (examples cited), but may have limitations in long-term data archiving and staffing; the paper suggests partnerships among intermediaries are advisable.</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>Mismatch between VO strengths (analysis/visualization) and long-term archiving needs; differing organizational capacities; technical heterogeneity across domains; coordination across intermediaries.</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>Domain alignment (VOs built by/for communities), specialized tools that meet community work practices, and cyberinfrastructure funding/support.</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>Technical middleware and tool development, domain expertise to design interfaces, and partnerships with archives/repositories for preservation.</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>Generally applicable to many data-intensive sciences, but requires adaptation to domain-specific instruments, data formats, and organizational arrangements.</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>instrumental/technical skills (cyberinfrastructure deployment), explicit procedural steps (service configurations), and organizational knowledge (roles of intermediaries)</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>myExperiment: Defining the social virtual research environment <em>(Rating: 2)</em></li>
                <li>Pathfinder: An online collaboration environment for citizen scientists <em>(Rating: 2)</em></li>
                <li>Digital libraries and collaborative knowledge construction <em>(Rating: 2)</em></li>
                <li>Collaboration and trust in healthcare innovation: The eDiaMoND case study <em>(Rating: 2)</em></li>
                <li>The budding amateurs <em>(Rating: 1)</em></li>
                <li>The data deluge: An e-science perspective <em>(Rating: 1)</em></li>
                <li>Beyond being there: A blueprint for advancing the design, development, and evaluation of virtual organizations <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-359",
    "paper_id": "paper-263860008",
    "extraction_schema_id": "extraction-schema-16",
    "extracted_data": [
        {
            "name_short": "Mammogram DB → Epidemiology",
            "name_full": "Use of a national database of mammogram images by epidemiologists",
            "brief_description": "Transfer of a medical imaging data resource (national mammogram image database) from clinical/radiological contexts to epidemiological research to investigate population-level factors in breast cancer.",
            "citation_title": "",
            "mention_or_use": "mention",
            "procedure_name": "Use of medical imaging databases for epidemiological analysis",
            "procedure_description": "Collecting large-scale mammogram image datasets (a national database) originally gathered for clinical/radiological purposes, and reusing those image collections as input data for epidemiological analyses (e.g., to study risk factors, incidence, and population patterns). This involves discovering relevant image records, linking images to associated metadata (patient demographics, clinical annotations), and applying population-level statistical and image-analysis methods to derive epidemiological inferences.",
            "procedure_type": "data reuse / analytical application of existing data resources",
            "source_domain": "medical imaging / radiology / clinical medicine",
            "target_domain": "epidemiology / public health research",
            "transfer_type": "direct application of existing data resource to a different analytic domain (data repurposing)",
            "modifications_made": "Not detailed in the paper; implied needs include mapping clinical metadata to epidemiologic variables and possibly reformatting or annotating images for large-scale analysis and de-identification to meet privacy requirements.",
            "transfer_success": "Described as potentially useful (paper gives the example that a national mammogram database may be useful to epidemiologists) but no empirical outcome data are provided in this paper.",
            "barriers_encountered": "Differences in required metadata and contextual information, privacy/confidentiality concerns, and lack of documentation or metadata formatted for epidemiologic reuse; the paper notes general difficulties in reusing data collected in another community because of embedded local context.",
            "facilitating_factors": "Availability of large, centralized databases; existence of metadata linking images to relevant clinical/demographic information; interdisciplinary demand for such data.",
            "contextual_requirements": "Need for appropriate metadata, de-identification/privacy safeguards, domain expertise in both radiology and epidemiology, and tools to map clinical terminologies to epidemiologic variables.",
            "generalizability": "Potentially generalizable to other cases where clinical/diagnostic image collections are repurposed for population-level study, but success depends on metadata quality and privacy handling.",
            "knowledge_type": "explicit procedural steps (data reuse workflows) and instrumental/technical skills (data linkage and statistical/image-analysis techniques)",
            "uuid": "e359.0"
        },
        {
            "name_short": "Citizen science → Ecology (phenology)",
            "name_full": "Use of volunteer-collected phenology and migration observations by ecologists to study climate change",
            "brief_description": "Application of observational data collected by amateur naturalists (flowering time, bird migration) to professional ecological research on climate change impacts.",
            "citation_title": "",
            "mention_or_use": "mention",
            "procedure_name": "Incorporation of volunteer observational datasets into ecological research (phenology studies)",
            "procedure_description": "Amateur/volunteer observers collect field observations (dates of flowering, bird migration timings, etc.) which are aggregated into datasets and then analyzed by ecologists to identify large-scale temporal patterns and shifts (e.g., phenological changes attributable to climate change). The procedure includes data collection protocols for volunteers, aggregation and standardization of observations, quality control/validation, and statistical time-series analyses.",
            "procedure_type": "data collection protocol (citizen science) and data reuse/analysis",
            "source_domain": "amateur/naturalist observational practice (citizen science / informal natural history)",
            "target_domain": "professional ecology / climate science",
            "transfer_type": "adapted/modified for new context (scientists reuse volunteer data with validation and aggregation)",
            "modifications_made": "Scientists applied validation/quality-control procedures and statistical analyses to adapt informal observations for scientific use; specific modifications not exhaustively detailed in the paper but include aggregation, cross-checking, and possibly calibration against instrumented records.",
            "transfer_success": "Presented as a successful example: the paper cites ecologists using amateur-collected flowering and bird migration data to study climate change (Whitfield, 2001). Quantitative metrics are not provided in this paper.",
            "barriers_encountered": "Trust in data quality, variable observer expertise, lack of standardized protocols, missing contextual metadata (how/where observations were made).",
            "facilitating_factors": "Sufficiently large number of observations over long time periods; some reporting of observer expertise or confidence; domain scientists' ability to statistically accommodate noisy observations; relevance of the phenomena (large-scale, robust signals such as phenology shifts).",
            "contextual_requirements": "Mechanisms for recording observer metadata (skill, confidence), aggregation platforms, validation procedures, and domain expertise to interpret volunteer data.",
            "generalizability": "Potentially generalizable to other ecological and environmental monitoring contexts where broad spatial/temporal coverage from volunteers can complement professional data, but generalizability depends on the phenomenon's signal-to-noise ratio and data validation procedures.",
            "knowledge_type": "tacit/practical know-how (how to collect observations) combined with explicit procedural steps for aggregation and validation",
            "uuid": "e359.1"
        },
        {
            "name_short": "CDL contributor workflow",
            "name_full": "California Digital Library contributor self-assessment and third-party expert review workflow for citizen-submitted observations",
            "brief_description": "Adapted submission procedures instituted by the California Digital Library requiring contributors to report expertise/experience/confidence and subjecting volunteer observations to third-party expert review to support scientist reuse.",
            "citation_title": "",
            "mention_or_use": "mention",
            "procedure_name": "Contributor self-assessment plus third-party expert review workflow for curating volunteer-submitted observations",
            "procedure_description": "When non-scientists submit observational data, contributors are asked to provide metadata about their expertise, experience, and confidence; submitted observations are then routed to third-party experts for review/validation before incorporation into research-accessible resources. This adds provenance and quality indicators to otherwise informal data.",
            "procedure_type": "curation workflow / quality-control protocol",
            "source_domain": "citizen-submitted observational data repositories / informal data collection",
            "target_domain": "scientific data archives and reuse by professional scientists",
            "transfer_type": "adaptation of repository submission processes to accommodate volunteer-contributed data (procedural modification)",
            "modifications_made": "Introduction of mandatory contributor self-assessment fields and a formal third-party expert review step; these were added to standard repository ingestion workflows to provide assessable metadata and vetting for non-expert contributions.",
            "transfer_success": "Partially successful: the paper reports these processes were implemented but 'did not resolve all the concerns of scientist users' (Van House, 2003) — i.e., they helped but trust issues remained.",
            "barriers_encountered": "Persisting scientist concerns about trust and quality despite added metadata and reviews, difficulty scaling expert review, variable reliability of self-assessment, and residual lack of context/standardization.",
            "facilitating_factors": "Provision of explicit contributor metadata, involvement of domain experts in review, repository infrastructure to collect and store metadata.",
            "contextual_requirements": "Access to domain experts for review, submission interfaces that capture contributor metadata, and policies clarifying accepted levels of evidence/validation.",
            "generalizability": "Partially generalizable to other repositories accepting volunteer data, but scalability and residual trust issues limit straightforward transfer without additional mechanisms (automated QC, community curation).",
            "knowledge_type": "explicit procedural steps (workflow design) and interpretive frameworks (trust and validation criteria)",
            "uuid": "e359.2"
        },
        {
            "name_short": "Scientific workflows / myExperiment",
            "name_full": "Scientific workflow systems and social virtual research environments (e.g., myExperiment) applied to documentation and community curation",
            "brief_description": "Applying computational workflow management systems and social virtual research environments, originally designed for reproducible computational experiments, to capture documentation and support community curation of research data.",
            "citation_title": "",
            "mention_or_use": "mention",
            "procedure_name": "Use of scientific workflow systems and social virtual research environments for data documentation and community curation",
            "procedure_description": "Scientific workflow systems formalize sequences of computational steps (data ingestion, transformation, analysis) and can record provenance; social virtual research environments (e.g., myExperiment) enable sharing and ‘social’ re-use of these workflows. The idea is to reuse these systems to capture the procedural context around data (how data were processed), enable community annotation, and support reuse by others.",
            "procedure_type": "computational provenance capture / collaboration platform",
            "source_domain": "computational e-science / bioinformatics / computer science (workflow management)",
            "target_domain": "data curation / documentation practices across scientific domains",
            "transfer_type": "analogical/adaptive transfer combining existing workflow tech with data curation needs (adapted/modified for documentation and community curation)",
            "modifications_made": "Not extensively detailed in the paper; suggestions include repurposing provenance-capture features to document experimental context and using social features for community curation — modifications likely include UI/metadata tailoring and integration with data repositories.",
            "transfer_success": "Unproven/uncertain in this paper: authors note 'anecdotal evidence suggests scientific workflows and social media might be useful' but 'very little research has been done to measure their effectiveness.'",
            "barriers_encountered": "Lack of empirical assessment of effectiveness, potential mismatch between workflow metadata and domain-specific documentation needs, sociotechnical barriers to adoption by data producers.",
            "facilitating_factors": "Existing provenance capture capabilities, community-sharing affordances of social virtual research environments, and increasing computationalization of analysis pipelines.",
            "contextual_requirements": "Integration with domain repositories, incentives for researchers to publish workflows and provenance, and tools to reduce burden of generating useful documentation.",
            "generalizability": "Potentially generalizable across computationally intensive domains; effectiveness for laboratory or observational domains with less formalized computational steps is less clear without adaptation.",
            "knowledge_type": "instrumental/technical skills (workflow use), explicit procedural steps (captured provenance), and tacit/practical know-how (community curation practices)",
            "uuid": "e359.3"
        },
        {
            "name_short": "Virtual Organizations (VOs)",
            "name_full": "Virtual organizations applying cyberinfrastructure for distributed resource access and domain-specific data analysis",
            "brief_description": "Application of VO models and grid/cyberinfrastructure technologies to provide access to distributed instruments, tools and data and to support domain-specific analysis and visualization.",
            "citation_title": "",
            "mention_or_use": "mention",
            "procedure_name": "Deployment of virtual-organization cyberinfrastructure for data sharing and integrated analysis",
            "procedure_description": "VOs create coordinated, distributed infrastructures (middleware, data services, analytic/visualization tools) that allow scientists to put data into shared spaces and perform analysis across distributed resources. They often include domain-specific tools and interfaces to work with data as well as mechanisms for collaboration.",
            "procedure_type": "infrastructure deployment / computational collaboration platform",
            "source_domain": "computer science / grid computing / cyberinfrastructure",
            "target_domain": "domain sciences requiring distributed data/instrument access (e.g., astronomy, earth sciences, biomedical informatics)",
            "transfer_type": "direct application/adaptation of cyberinfrastructure concepts and tools to domain science needs (hybrid approach combining tech with domain expertise)",
            "modifications_made": "VOs develop specialized domain tools and tailor middleware/services to domain instruments and data formats; paper notes they may lack large-scale archive management expertise, implying hybridization with archives is needed.",
            "transfer_success": "Mixed: VOs have succeeded in providing collaborative access and specialized analysis tools (examples cited), but may have limitations in long-term data archiving and staffing; the paper suggests partnerships among intermediaries are advisable.",
            "barriers_encountered": "Mismatch between VO strengths (analysis/visualization) and long-term archiving needs; differing organizational capacities; technical heterogeneity across domains; coordination across intermediaries.",
            "facilitating_factors": "Domain alignment (VOs built by/for communities), specialized tools that meet community work practices, and cyberinfrastructure funding/support.",
            "contextual_requirements": "Technical middleware and tool development, domain expertise to design interfaces, and partnerships with archives/repositories for preservation.",
            "generalizability": "Generally applicable to many data-intensive sciences, but requires adaptation to domain-specific instruments, data formats, and organizational arrangements.",
            "knowledge_type": "instrumental/technical skills (cyberinfrastructure deployment), explicit procedural steps (service configurations), and organizational knowledge (roles of intermediaries)",
            "uuid": "e359.4"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "myExperiment: Defining the social virtual research environment",
            "rating": 2,
            "sanitized_title": "myexperiment_defining_the_social_virtual_research_environment"
        },
        {
            "paper_title": "Pathfinder: An online collaboration environment for citizen scientists",
            "rating": 2,
            "sanitized_title": "pathfinder_an_online_collaboration_environment_for_citizen_scientists"
        },
        {
            "paper_title": "Digital libraries and collaborative knowledge construction",
            "rating": 2,
            "sanitized_title": "digital_libraries_and_collaborative_knowledge_construction"
        },
        {
            "paper_title": "Collaboration and trust in healthcare innovation: The eDiaMoND case study",
            "rating": 2,
            "sanitized_title": "collaboration_and_trust_in_healthcare_innovation_the_ediamond_case_study"
        },
        {
            "paper_title": "The budding amateurs",
            "rating": 1,
            "sanitized_title": "the_budding_amateurs"
        },
        {
            "paper_title": "The data deluge: An e-science perspective",
            "rating": 1,
            "sanitized_title": "the_data_deluge_an_escience_perspective"
        },
        {
            "paper_title": "Beyond being there: A blueprint for advancing the design, development, and evaluation of virtual organizations",
            "rating": 2,
            "sanitized_title": "beyond_being_there_a_blueprint_for_advancing_the_design_development_and_evaluation_of_virtual_organizations"
        }
    ],
    "cost": 0.011013499999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>The International Journal of Digital Curation</p>
<p>Ixchel M Faniel 
School of Information
University of Michigan</p>
<p>Ann Zimmerman 
School of Information
University of Michigan</p>
<p>The International Journal of Digital Curation
1746-8256E32DC591DFFEB2BB490A3A6B315BAB73
There is almost universal agreement that scientific data should be shared for use beyond the purposes for which they were initially collected.Access to data enables system-level science, expands the instruments and products of research to new communities, and advances solutions to complex human problems.While demands for data are not new, the vision of open access to data is increasingly ambitious.The aim is to make data accessible and usable to anyone, anytime, anywhere, and for any purpose.Until recently, scholarly investigations related to data sharing and reuse were sparse.They have become more common as technology and instrumentation have advanced, policies that mandate sharing have been implemented, and research has become more interdisciplinary.Each of these factors has contributed to what is commonly referred to as the "data deluge".Most discussions about increases in the scale of sharing and reuse have focused on growing amounts of data.There are other issues related to open access to data that also concern scale which have not been as widely discussed: broader participation in data sharing and reuse, increases in the number and types of intermediaries, and more digital data products.The purpose of this paper is to develop a research agenda for scientific data sharing and reuse that considers these three areas. 1</p>
<p>Introduction</p>
<p>There is almost universal agreement that scientific data should be shared for use beyond the purposes for which they were initially collected.Access to data enables system-level science, expands the instruments and products of research to new communities, and advances solutions to complex human problems (e.g., Hey &amp; Trefethen, 2003;Hey, Tansley, &amp; Tolle, 2009).While demands for data are not entirely new, the vision of open access to data is increasingly ambitious.The aim is to make data accessible and usable to anyone, anytime, anywhere, and for any purpose.</p>
<p>Until recently, scholarly investigations related to data sharing and reuse were sparse.They have become more common as technology and instrumentation have advanced, policies that mandate sharing have been implemented, and research has become more interdisciplinary.Each of these factors has contributed to what is commonly referred to as the "data deluge" (Hey &amp; Trefethen, 2003).Most discussions about increases in the scale of sharing and reuse have focused on growing amounts of data.We identified three other issues related to open access to data that also concern scale that have not been widely discussed:</p>
<p>• broader participation in data sharing and reuse; • increases in the number and types of intermediaries; • more digital data products.</p>
<p>These three areas form the basis of a research agenda we developed for scientific data sharing and reuse.In this paper, we describe each issue in more detail, discuss findings from prior research and identify research questions that need to be addressed.The aim of the agenda is provide a roadmap to help build a cumulative body of knowledge that furthers basic understanding and informs practice.We do not prescribe specific conceptual frameworks or approaches because we believe multiple perspectives and methods are needed to address the questions we pose.</p>
<p>Broader Participation in Data Sharing and Reuse</p>
<p>Broader participation in data sharing and reuse is an important issue in considerations of scale and can be viewed from three perspectives.First, data sharing and reuse are becoming important in domains in which they were previously uncommon.This situation provides opportunities to understand the factors that drive sharing and reuse among members of the same science community, and the influence these activities exert on culture, practice and communication in fields where they are new.Second, the focus on interdisciplinary research, along with non-scientist participation and interest in the research process, means that data are being used by individuals who are outside of the community in which they were generated.These new contexts of reuse raise questions about how individuals from different cultures and with varied knowledge and expertise find, understand, and reuse data.Finally, in addition to their role as data reusers, non-scientists are increasingly collecting, sharing, and analyzing data that may be used to study scientific questions.This situation has implications for broader participation in science and for understanding how scientists trust and reuse data collected by non-scientists.In the sections that follow we discuss prior work in these areas as well as open questions driven by broader participation in sharing and reuse.</p>
<p>The International Journal of Digital Curation</p>
<p>Data Sharing and Reuse within Science Communities</p>
<p>Much of the prior research has focused on scientists' motivations to share data with others in their own community.These studies show that fields in which data sharing is common are characterized by a mixture of technical capabilities, such as free and easy software for data transfer, management and analysis; socially influenced demands and incentives; and scientifically motivated needs, especially the questions that scientists want to answer (e.g., Birnholtz &amp; Bietz, 2003;Griffiths, 2008).The latter factor is particularly important.For example, research in physical oceanography is conducted using large research vessels carrying expensive data collection equipment.Data are gathered from remote locations, which requires coordination across long distances.Data sharing and reuse are necessary to conduct physical oceanographic research since no individual and few institutions can afford to carry it out on their own (Hesse, Sproull, Kiesler, &amp; Walsh, 1993).For other disciplines, it is only recently that the science being conducted requires data from others within their disciplines.In ecology, for instance, changes to sharing and reuse patterns are being driven by the collection of new types of data, by the online availability of large volumes of data of interest to ecologists, by technologies that make it easier to manage and integrate disparate data, and by slowly changing views about the value of secondary analysis to address important ecological questions (Borgman, Wallis, &amp; Enyedy, 2007;Zimmerman, 2008).Further studies, exemplified by the questions below, are needed to understand the degree to which prior findings are applicable to various disciplines and to make comparisons across disciplines.</p>
<p>How do the factors that motivate data sharing and reuse differ across science communities, and what contributes to the differences? 2. What precipitates the cultural changes necessary for science communities</p>
<p>to engage in large scale data sharing and reuse?</p>
<p>The implicit assumption in much of the literature is that making data more widely available will ensure reuse.However, the few studies that have been conducted show that data reuse is difficult even among scientists from the same community.The major challenge to reuse is that data are embedded in a local context, which makes it difficult for reusers to understand and trust the data (e.g., Berg &amp; Goorman, 1999;Cragin &amp; Shankar, 2006;Jirotka et al., 2005;Zimmerman, 2008).There has been some research into how the local context is communicated to reusers, but no definitive conclusions have been drawn.Some studies have found that the documentation scientists produce for themselves can be of limited use to others (Birnholtz &amp; Bietz, 2003;Shankar, 2007;Zimmerman, 2008).Other investigations have shown scientists' documentation to be quite useful to reusers (Carlson &amp; Anderson, 2007;Faniel &amp; Jacobsen, 2010).Still other research has found that social exchange with the data producer is an important part of data reuse (Collins, 1992).However, social exchange is difficult to accomplish on a large scale, in part because it not always possible or desirable for data producers to communicate with data reusers.Furthermore, technology has not yet been successful in bridging this gap.Anecdotal evidence suggests scientific workflows and social media might be useful for documentation and community curation (e.g., De Roure, Goble, &amp; Bhagat, 2008), but very little research has been done to measure their effectiveness for the data producer or reuser.These challenges suggest the following research questions:</p>
<p>The International Journal of Digital Curation Issue 1, Volume 6 | 2011 • What other types of social interaction beyond that with the data producer can facilitate data reuse (e.g., colleagues, third party experts)?• How might technology be employed to capture and communicate the local context for reusers, while reducing the burden for data producers?• How can social exchange and documentation be combined to support data sharing and reuse on a large scale?</p>
<p>Data Sharing and Reuse across Different Communities</p>
<p>The challenges related to data sharing and reuse within a science community become more daunting as these activities open to scientists and non-scientists outside of the community in which the data were generated.Each type of reuser has particular knowledge, skills and practices, as well as different purposes for reusing data, not all of which are research oriented.For instance, educators, practitioners, policymakers and the general public may want to use scientific research for pedagogy, product and service innovations, policy formulation, or hobbies.Below, we discuss issues related to sharing and reuse by scientists who are outside the domain in which the data were produced and by non-scientists.</p>
<p>Scientists are being encouraged to reuse data from multiple domains because interdisciplinary research is believed to be an important part of addressing many of today's complex problems.Interdisciplinary research occurs when knowledge, experience, technology or expertise is transferred via borrowing, collaboration or boundary crossing (Pierce, 1999).The need for interdisciplinary studies is often raised in the context of grand challenge research which seeks to answer pressing questions that impact society, and have the potential to yield major results and practical benefit if addressed (National Research Council, 2010).For example, a national database of mammogram images may be useful to epidemiologists investigating factors that contribute to breast cancer (Jirotka et al., 2005).In addition to the challenges discussed in the previous section, there is little understanding about what needs to be done to facilitate data reuse in such new contexts.Based on what is known about interdisciplinary research, we expect that it will be difficult for reusers to acquire the technical, tacit and theoretical knowledge required to understand and reuse data collected from other fields.</p>
<p>The same factors that make it hard for scientists to reuse data collected by those from a different community also make it difficult for data producers to share data.Even when they are motivated to share, it is difficult for data producers to provide documentation or otherwise communicate with others outside of their community.Members of a discipline share common terminology and methods as well as their own publication channels for disseminating research (Klein, 1996).Scientists who conduct interdisciplinary research face a number of challenges because the disparities between disciplines make it difficult to communicate information across them (Palmer, 1996;Pierce, 1999).These differences include the expectations of those involved in the peer review process, the models or paradigms on which research is based, and the distinct stylistic and presentational features that exist in each field (Pierce, 1999).These disparities also lead to concerns by data producers that their data will be misused (Van House, 2002;Van House, Butler, &amp; Schiff, 1998).</p>
<p>The International Journal of Digital Curation</p>
<p>All of the issues scientists face when reusing data for interdisciplinary research are magnified when non-scientists attempt to reuse science data.Non-scientists have different needs, goals, skills and knowledge.For example, scientists may rely on factors internal to the scientific enterprise (e.g., methodological rigor) when working with data, whereas non-scientists may depend on ones external to the scientific process, such as the extent to which scientific explanations match their experience (Weeks &amp; Packard, 1997).Moreover, it is not clear that non-scientists are interested in reusing the data per se.Instead, they may be interested in reusing the various products of scientific research (e.g., interpretations, discussion of practical implications), or they may benefit from new products that are developed to match their needs (e.g., synthesis documents, guidelines for application).</p>
<p>The last issue we take up in regard to broader participation in sharing and reuse is the production of data by non-scientists.For example, data collected by lay people in astronomy, entomology, botany, cancer research or other fields are potentially valuable to scientists and are sometimes used by them (e.g., Luther, et al., 2009).Questions remain, though, about how scientists come to trust data gathered by non-scientists, even when processes are in place to support sharing across different communities.For instance, when non-scientists began contributing observational data to the California Digital Library, changes were made to procedures for sharing data.Specifically, data producers were asked to report their level of expertise, experience and confidence in making observations, and to submit their observations to third party expert review.However, these processes did not resolve all the concerns of scientist users (Van House, 2003).In other cases, scientists have found ways to confidently reuse nonscientists' data.Some ecologists, for example, have used data on the flowering time of plants and bird migration collected by amateur naturalists to study climate change (Whitfield, 2001).</p>
<p>The sharing and reuse of data across different communities raises a number of questions for future research, including:</p>
<p>How do data sharing practices within a science community change as nonmembers participate as data producers? How do non-members become viewed as legitimate participants in data sharing activities? 2. When are non-scientists in need of scientific research, what are they interested in reusing, and how do their reuse practices differ from members of the science community? 3. How do the reuse practices of people who are not members of a science community vary across user type and reuse purpose? 4. What factors influence the degree to which an integrated function for data sharing and reuse among members and non-members of a science community can be offered?</p>
<p>The International Journal of Digital Curation</p>
<p>Issue 1, Volume 6 | 2011</p>
<p>Increases in the Number and Types of Intermediaries</p>
<p>As we move from small to large scale data sharing, where data are managed and maintained for broad access, we also are seeing an increase in the number and type of intermediaries.Intermediaries, in the form of organizations and the people who work for them, prepare data for reuse by eliciting, organizing, storing, packaging and/or preserving data, and by performing various roles in dissemination and facilitation (Markus, 2001).Three intermediaries that currently exist are data archives, institutional repositories (IRs) and virtual organizations (VOs).Below we discuss the strengths and capabilities of each with regard to data sharing and reuse.</p>
<p>Until recently, data archives that acquire, manage and preserve data intended for use by a specific domain or by the general science and education community were the primary infrastructure for data sharing (Green &amp; Gutmann, 2007;National Science Board, 2005).Data archives have staff and expertise that allow them to offer support throughout the data lifecycle, including the capture, management and preservation of data (Borgman, 2007;Green &amp; Gutmann, 2007).They also provide infrastructure for data sharing and reuse that includes documentation, statistical services and standardization.Furthermore, data archives that serve specific science domains have close connections to those communities.The Inter-University Consortium for Political and Social Research and the Arabidopsis Information Resource in the biological sciences are two examples of domain specific archives.For disciplines that lack data archives, IRs and VOs offer two different alternatives.</p>
<p>Libraries are building IRs to house many types of digital intellectual products (e.g., publications, presentations) created by the faculty, research staff and students of their institutions (Crow, 2002).Although librarians have become increasingly interested in working with all kinds of scholarly output, IRs are currently best suited to collect, organize and preserve materials near the end of the research life cycle.Examples of IRs include DeepBlue at the University of Michigan and e-Scholar at Purdue University.The advantages of IRs are that the process to contribute to them is simple and they can serve disciplines without other options for data sharing (Green &amp; Gutmann, 2007).In addition, the scholarly publications and other end products of research that libraries collect are often a starting point for data reusers, which make IRs important intermediaries for data (Zimmerman, 2007).</p>
<p>VOs are different still from IRs and data archives.They have been established by science and engineering communities to take advantage of new technologies to support collaboration and provide access to distributed resources such as instruments, tools and data (Cummings et al., 2008).Examples of VOs include the George E. Brown, Jr. Network for Earthquake Engineering Simulation, the Cancer Biomedical Informatics Grid and the Sloan Digital Sky Survey (Cummings et al., 2008).A major objective of a VO is to develop specialized tools and technologies to not only put in and take out data but also work with the data (e.g., analyze, visualize).Although VOs have expertise in the instruments and methods to produce the data, they may have fewer staff and less expertise managing large-scale data archives.Some people have suggested that the various intermediaries should consider building partnerships and clarifying roles and responsibilities, given differences in their strengths and the ways they facilitate data sharing and reuse (e.g., Association of</p>
<p>The International Journal of Digital Curation</p>
<p>Issue 1, Volume 6 | 2011 Research Libraries, 2006;Green &amp; Gutmann, 2007).With this in mind, the overarching research questions we pose focus on the choices among intermediaries from the perspective of those who contribute and reuse data.In addition, we call for more research that examines factors related to the growth and effectiveness of these intermediaries or new ones that might emerge.</p>
<p>What factors influence data producers' decisions about where to deposit data?</p>
<p>• What factors influence data reusers' seeking behavior and experiences in data reuse?• What contributes to the success of large scale data management, sharing and reuse?How do these factors differ across intermediaries?• What are the affordances of each intermediary from the perspective of data contributors and reusers?• What organizational, social and technical arrangements are needed to manage dependencies and coordinate offerings across intermediaries?</p>
<p>Along with the expansion of intermediaries in the sense of institutions and organizations, there are more individuals who have a part to play in the data universe.Large-scale data sharing and reuse requires skills and expertise that span the entire lifecycle of data.In addition, some people are stepping into newly created roles and others are finding they need to redefine existing ones.For example, graduate schools in information and library science are increasingly offering students the option to specialize in data curation.At the same time, domain scientists are struggling to find the right balance between data management and the research skills and disciplinary knowledge the next generation of researchers need to advance their respective fields.These issues raise the following questions:</p>
<p>• How does the evolving nature of the data professions change education in the domain sciences and in information science, computer science and archives?• What are the roles and responsibilities of the various professionals involved in data management?</p>
<p>More Digital Data Products</p>
<p>The third way in which open access to data affects scale is through the potential to create new types of digital products that include data.These products might take a seemingly endless array of forms (e.g., artistic creations, educational learning modules, integrated data sets, end-to-end connections between laboratory results and published findings) that result from linking, integrating or weaving together data with publications, other data or other digital resources.The possibilities for these new products, as well as the challenges they present in terms of intellectual property, standardization and preservation, have been discussed by other authors (e.g., Borgman, 2007;Hey &amp; Trefethen, 2008;NRC, 2010).While creating new digital products that include data are not yet common, we expect this to change as technologies and policies evolve to support it; this will lead to new questions for researchers.Clearly, this is a wide-ranging and complex area, and the questions below only begin to outline the potential issues.</p>
<p>The International Journal of Digital Curation</p>
<p>Issue 1, Volume 6 | 2011 • What obstacles (e.g., legal, technical, social)</p>
<p>Conclusions</p>
<p>The need to share and reuse data is an important topic in almost every high-level report or discussion concerning contemporary science.There are two overarching reasons for this emphasis.First, there is a belief that these activities are necessary to advance scientific research and solve important global problems.Second, there is a move to make the products of research available to a broad audience to support transparency, participation in the scientific process, and decision-making.Sharing and reuse at a large scale and over the long term imply that data can be accessed by anyone, anytime, from anywhere and used for any purpose, and that they can exist beyond the lives of the technology and the people who produced them.</p>
<p>In this paper, we argued that a dramatic increase in the amount of data, while important, is only one factor prompting the need for new research on data sharing and reuse.In order to achieve the vision of open access to data, we proposed a research agenda that addresses questions related to three other issues of scale: broader participation in data sharing and reuse, increases in the number and types of intermediaries, and more digital data products.Research in these areas should not only draw from and produce theory, but must also attempt to answer practical questions of curation for open access.Below we discuss three of the potentially many ways in which studies designed to address the research questions posed in this paper could inform data curation and the lifecycle model (Higgins, 2008).</p>
<p>First, the challenges related to sharing data at a large scale and over the long term are new to many fields of science.Scientists in these areas are struggling with issues such as how to determine what data to save and for how long, how to ensure the accuracy and integrity of their own data as well as data they might reuse, how to document data for their own and others' use, and where to store data so they are broadly accessible.We believe an important first step toward supporting sharing and reuse can be gained through research that takes an in-depth look at how scientists manage data for their own use.This, coupled with more research on how people reuse data, would give data curators insight into how they might capitalize on scientists' personal documentation practices when creating documentation for others.</p>
<p>Second, it is often difficult to know in advance which data are valuable to curate and preserve.These decisions would become easier if we knew more about potential reusers of data: Who are they?What data skills do they possess?How do they find data and what do they need to know to reuse them?What are they interested in reusing (e.g., raw data, interpreted results, techniques)?Answers to these questions may help data curators better align their practices, policies and expertise in developing metadata standards, data file formats for preservation, and software, services and tools with the The International Journal of Digital Curation Issue 1, Volume 6 | 2011 needs of potential reusers.The answers may also inform the description and representation of information associated with data, and the capture, storage and dissemination of data.</p>
<p>Third, there are a growing number of choices available to people who want to deposit data.Yet, more options do not make it easier for people to select the best venue for sharing.Research that examines what influences how people make their data available may give data curators a better sense for what data are being placed where and the rationale behind these decisions.For instance, knowing the degree to which factors such as mandates from funding agencies, the existence of trusted repositories and supportive tools, and data producers' confidence in their data management skills may help data curators shape and advertise their capabilities, collections and services.</p>
<p>To conclude, our examples above illustrate how researchers can inform practice, but we also believe practitioners can and should inform the research.More active collaborations between the two are needed, such as joint formulation of research questions and proposals.Similarly, the research agenda we propose would benefit from collaborations among researchers from multiple disciplines, such as archives and computer, social, library and information, and domain sciences.</p>
<p>exist to the creation of new digital objects and services that include data?• How do people create, share and reuse these new objects?• Who will be responsible for creating digital data objects that meet the needs of different types of reusers?
• To what extent should these digital data products be captured andpreserved?• What value do new products have beyond the components that were usedto create them?
AcknowledgementsWe appreciate comments from Nancy McGovern and three anonymous reviewers.The IJDC is published by UKOLN at the University of Bath and is a publication of the Digital Curation Centre.
To stand the test of time: Long-term stewardship of digital data in science and engineering. 2006Association of Research LibrariesWashington, DC</p>
<p>The contextual nature of medical information. M Berg, E Goorman, International Journal of Medical Informatics. 561999Elsevier Science</p>
<p>Data at work: Supporting sharing in science and engineering. J P Birnholtz, M J Bietz, Proceedings of the International ACM SIGGROUP Conference on Supporting Group Work. the International ACM SIGGROUP Conference on Supporting Group WorkSanibel Island, FL. New YorkACM Press2003</p>
<p>C L Borgman, Scholarship in the digital age: Information, infrastructure, and the Internet. Cambridge, MAMIT Press2007</p>
<p>Little science confronts the data deluge: Habitat ecology, embedded sensor networks, and digital libraries. C L Borgman, J C Wallis, N Enyedy, International Journal on Digital Libraries. 71-22007Springer</p>
<p>What are data? The many kinds of data and their implications for reuse. S Carlson, B Anderson, The International Journal of Digital Curation Issue. 1222007. July 31, 2010. 2011Journal of Computer-Mediated Communication</p>
<p>. M Ixchel, Ann Faniel, Zimmerman, 67</p>
<p>Changing order: Replication and induction in scientific practice. H M Collins, 1992University of Chicago PressChicago, IL</p>
<p>Scientific data collections and distributed collective practice. M H Cragin, K Shankar, Computer Supported Cooperative Work. 152-32006</p>
<p>. Dordrecht, KluwerThe Netherlands</p>
<p>The case for institutional repositories: A SPARC position paper. R Crow, 2002. August 2, 2010The Scholarly Publishing &amp; Academic Resources CoalitionWashington, DC</p>
<p>Beyond being there: A blueprint for advancing the design, development, and evaluation of virtual organizations. J Cummings, T Finholt, I Foster, C Kesselman, K A Lawrence, 2008National Science FoundationArlington, VA</p>
<p>myExperiment: Defining the social virtual research environment. D De Roure, C Goble, J Bhagat, Proceedings of the 4 th IEEE International Conference on e-Science. the 4 th IEEE International Conference on e-ScienceIndianapolis, Indiana2008</p>
<p>Reusing scientific data: How earthquake engineering researchers assess the reusability of colleagues' data. I M Faniel, T E Jacobsen, Computer Supported Cooperative Work. 192010Kluwer</p>
<p>Building partnerships among social science researchers, institution-based repositories and domain specific data archives. A G Green, M P Gutmann, OCLC Systems &amp; Services. 2012007Meckler</p>
<p>The publication of research data: Researcher attitudes and behaviour. A Griffiths, International Journal of Digital Curation. 412008</p>
<p>Returns to science: Computer networks in oceanography. B W Hesse, L S Sproull, S B Kiesler, J P Walsh, Communications of the ACM. 3681993ACM Press</p>
<p>The fourth paradigm: Data-intensive scientific discovery. T Hey, S Tansley, K Tolle, 2009. August 2, 2010Microsoft Research</p>
<p>The data deluge: An e-science perspective. T Hey, A Trefethen, Grid computing: Making the global infrastructure a reality. F Berman, G C Fox, T Hey, New YorkWiley2003. 20111</p>
<p>E-science, cyberinfrastructure, and scholarly communication. T Hey, A Trefethen, Scientific collaboration on the Internet. G M Olson, A Zimmerman, &amp; N Bos, Cambridge, MAMIT Press2008</p>
<p>The DCC Curation Lifecycle Model. S Higgins, International Journal of Digital Curation. 312008</p>
<p>Collaboration and trust in healthcare innovation: The eDiaMoND case study. M Jirotka, R Procter, M Hartswood, R Slack, A Simpson, C Coopmans, C Hinds, A Voss, Computer Supported Cooperative Work. 142005Kluwer</p>
<p>Interdisciplinary needs: The current context. J T Klein, Library Trends. 4521996The Johns Hopkins University Press</p>
<p>Pathfinder: An online collaboration environment for citizen scientists. K Luther, S Counts, K B Stecher, A Hoff, P Johns, Proceedings of the 27th International Conference on Human Factors in Computing Systems. the 27th International Conference on Human Factors in Computing SystemsNew YorkACM Press2009</p>
<p>Toward a theory of knowledge reuse: Types of knowledge reuse situations and factors in reuse success. M L Markus, Journal of Management Information Systems. 1812001M. E. Sharpe</p>
<p>Steps toward large-scale data integration in the sciences: Summary of a workshop. 2010. August 2, 2010National Academies PressWashington, DC</p>
<p>Long-lived data collections: Enabling research and education in the 21st Century. National Science Foundation. 2005National Science Board.</p>
<p>Information work at the boundaries of science: Linking library services to research practices. C L Palmer, Library Trends. 4521996The Johns Hopkins University Press</p>
<p>Boundary crossing in research literatures as a means of interdisciplinary information transfer. S J Pierce, Journal of the American Society for Information Science. 5031999John Wiley &amp; Sons</p>
<p>Order from chaos: The poetics and pragmatics of scientific record keeping. K Shankar, Journal of the American Society for Information Science and Technology. 58102007. 2011John Wiley &amp; SonsThe International Journal of Digital Curation Issue</p>
<p>. M Ixchel, Ann Faniel, Zimmerman, 69</p>
<p>Digital libraries and practices of trust: Networked biodiversity information. N A Van House, Social Epistemology. 1612002Taylor &amp; Francis</p>
<p>Digital libraries and collaborative knowledge construction. N A Van House, Digital library use: Social practice in design and evaluation. A P Bishop, B Buttenfield, N A Van House, Cambridge, MAMIT Press2003</p>
<p>Cooperative knowledge work and practices of trust: Sharing environmental planning data sets. N A Van House, M H Butler, L R Schiff, ACM Conference on Computer Supported Cooperative Work. New YorkACM Press1998</p>
<p>Acceptance of scientific management by natural resource dependent communities. P Weeks, J M Packard, Conservation Biology. 1111997Wiley-Blackwell</p>
<p>The budding amateurs. J Whitfield, Nature. 4142001Macmillan</p>
<p>Not by metadata alone: The use of diverse forms of knowledge to locate data for reuse. A Zimmerman, International Journal on Digital Libraries. 71-22007Springer</p>
<p>New knowledge from old data: The role of standards in the sharing and reuse of ecological data. A Zimmerman, Sage. The International Journal of Digital Curation Issue. 3352008. 2011Technology, &amp; Human Values</p>            </div>
        </div>

    </div>
</body>
</html>