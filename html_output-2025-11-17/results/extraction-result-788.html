<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-788 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-788</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-788</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-21.html">extraction-schema-21</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of agents that use external tools for planning in partially observable text environments, including how they maintain belief states, incorporate tool outputs, and perform navigation or path-finding tasks.</div>
                <p><strong>Paper ID:</strong> paper-259795831</p>
                <p><strong>Paper Title:</strong> <a href="https://agile-giss.copernicus.org/articles/4/2/2023/agile-giss-4-2-2023.pdf" target="_blank">From Floorplan to Navigation Concepts: Automatic Generation of Text-based Games</a></p>
                <p><strong>Paper Abstract:</strong> . Text-based games are environments in which defining the world, the representation of the world to the player (hereafter, agent) and agent interactions with the environment are all through text. Text-based games expose abstract, executable representations of indoor spaces through verbally referenced concepts. Yet, the ability of text-based games to represent indoor environments of real-world complexity is currently limited due to insufficient support for complex space decomposition and space interaction concepts. This paper suggests a procedure to automate the mapping of real-world geometric floorplan information into text-based game environment concepts, us-ing the Microsoft TextWorld game platform as a case. To capture the complexities of indoor spaces, we enrich existing TextWorld concepts supported by theoretical navigation concepts.We first decompose indoor spaces using skeletonization, and then identify formal space concepts and their relationships. We further enhance the spectrum of supported agent interactions with an extended grammar, including egocentric navigation instructions. We demonstrate and discuss these new capabilities in an evacuation scenario. Our implementation extends the capabilities of TextWorld to provide a research testbed for spatial research, including symbolic spatial modelling, interaction with indoor spaces, and agent-based machine learning and language processing tasks.</p>
                <p><strong>Cost:</strong> 0.015</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e788.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e788.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of agents that use external tools for planning in partially observable text environments, including how they maintain belief states, incorporate tool outputs, and perform navigation or path-finding tasks.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>TextWorld</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>TextWorld (Microsoft TextWorld)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A sandbox environment for creating and running text-based games that compile to Inform7; used to train and evaluate agents (rule-based, supervised, or reinforcement learners) interacting via text in symbolic, often partially-observable worlds.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>unspecified agent (generic TextWorld agent)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>The paper does not introduce a new agent architecture; TextWorld is presented as the environment in which agents (rule-based, supervised, or reinforcement-learning agents cited from prior work) can operate. TextWorld provides the game state, compiles logical rules (Ceptre/Inform7) and descriptions, and (as extended by the authors) tracks agent orientation and position history externally to enable egocentric commands.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>TextWorld</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>A text-only game environment where world state, observations and actions are symbolic descriptions (rooms, doors, objects). Observations are local descriptions returned by the engine in response to agent commands; the paper notes TextWorld is suitable for partially-observable tasks (agents do not get the full global state unless described). Challenges include partial observability, abstracted low-level motion (movement is discretized between text-defined areas), and limited default spatial concepts (rooms, 8 directions) which the paper extends.</td>
                        </tr>
                        <tr>
                            <td><strong>is_partially_observable</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>external_tools_used</strong></td>
                            <td>For environment generation (not by the agent): skeletonization tools and geometry libraries — scikit-geometry (SMAT/MAT), scipy.spatial, shapely, geojson — to produce skeleton graphs/navigation graphs from floorplans; Inform7/Ceptre are used as the logical/compilation toolchain to produce the playable game.</td>
                        </tr>
                        <tr>
                            <td><strong>tool_output_types</strong></td>
                            <td>Structured navigation graphs (skeleton graph nodes/edges), generated Inform7/TextWorld game descriptions (templated textual descriptions), GeoJSON geometries.</td>
                        </tr>
                        <tr>
                            <td><strong>belief_state_mechanism</strong></td>
                            <td>The paper describes extending the TextWorld engine to track the agent's history of positions and an explicit agent orientation value (AO) externally to the agent; orientation and relative direction (RD) are computed by the engine. No internal agent belief architecture (memory network, graph belief, etc.) is specified for agents in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>incorporates_tool_outputs_in_belief</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>belief_update_description</strong></td>
                            <td>Orientation AO and position history are updated by the TextWorld engine as the agent executes actions; relative direction RD is computed as RD = (AO − DN) mod 8, where DN is the integer-coded direction to the next room. The paper does not describe agents explicitly ingesting or updating richer maps or tool outputs into their own belief states.</td>
                        </tr>
                        <tr>
                            <td><strong>planning_approach</strong></td>
                            <td>Not specified for a concrete agent in this paper; the authors note that agents in TextWorld can follow route instructions using rule-based methods, supervised learning, or reinforcement learning (citing prior work). The paper itself focuses on environment generation and engine-level orientation tracking rather than a planning algorithm.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_shortest_path_planning</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>navigation_method</strong></td>
                            <td>Environment provides a graph-like structure (skeleton/navigation graph mapped to TextWorld rooms and doors); agent movement is via allocentric or egocentric text commands. The paper does not describe a particular agent-side pathfinding algorithm (A*, etc.).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_tools</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_tools</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_tool_ablation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>This paper does not present an agent that uses external tools for planning; instead it extends TextWorld to (1) automatically generate text-game worlds from floorplan-derived skeleton/navigation graphs (using external geometry toolchain) and (2) add egocentric navigation grammar by having the engine track agent orientation and compute relative directions. The engine-level orientation tracking enables egocentric commands without requiring agents to maintain full trajectory beliefs themselves.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'From Floorplan to Navigation Concepts: Automatic Generation of Text-based Games', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e788.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e788.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of agents that use external tools for planning in partially observable text environments, including how they maintain belief states, incorporate tool outputs, and perform navigation or path-finding tasks.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Skeleton-based navigation graph</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Skeleton graph (SMAT/MAT-derived navigation graph from floorplans)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A graph derived from medial-axis/skeletonization (MAT/SMAT) of floorplan polygons where nodes represent atomic IndoorAreas and edges represent adjacency; used here to automate generation of TextWorld navigation structure.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>not applicable (graph used to generate environment)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Not an agent — a representation used by the environment generator to instantiate rooms/areas/links (IndoorArea, IndoorRoom, Door, ULink) in TextWorld; agents interact with the instantiated textual environment rather than the raw graph.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>TextWorld (generated worlds)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>TextWorld games generated from geometric floorplans via skeleton graphs; partial observability arises from agents receiving localized textual descriptions mapped from the skeleton-derived partitioning.</td>
                        </tr>
                        <tr>
                            <td><strong>is_partially_observable</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>external_tools_used</strong></td>
                            <td>SMAT/MAT skeletonization algorithms (implemented via scikit-geometry), Voronoi-related computations (scipy.spatial), shapely and geojson for geometry handling.</td>
                        </tr>
                        <tr>
                            <td><strong>tool_output_types</strong></td>
                            <td>Graph structures (nodes/edges representing IndoorAreas and connections), mapping metadata (parent relationships, door/landmark associations), templated Inform7/TextWorld descriptions.</td>
                        </tr>
                        <tr>
                            <td><strong>belief_state_mechanism</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>incorporates_tool_outputs_in_belief</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>belief_update_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>planning_approach</strong></td>
                            <td>Not applicable to an agent in this paper; the skeleton graph is a generation-time artifact that becomes the game's topology.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_shortest_path_planning</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>navigation_method</strong></td>
                            <td>Graph-structured topology is compiled into TextWorld rooms and explicit connections; agents navigate via textual go/egocentric commands reflecting that topology.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_tools</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_tools</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_tool_ablation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Skeletonization (MAT/SMAT) can be used to derive atomic IndoorAreas and adjacency suitable for mapping into TextWorld concepts, enabling richer, more realistic navigation topologies for text-based agents without embedding explicit geometric details in the textual environment.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'From Floorplan to Navigation Concepts: Automatic Generation of Text-based Games', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e788.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e788.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of agents that use external tools for planning in partially observable text environments, including how they maintain belief states, incorporate tool outputs, and perform navigation or path-finding tasks.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Ceptre</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Ceptre (functional language for game logic / linear logic reasoning)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A functional language using linear logic formulas to express game rules and state transitions; used by TextWorld to encode predicates and state-change rules that the Inform7 compiler can translate into executable worlds.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Not an agent; Ceptre provides the formal operational logic (characters, locations, predicates, actions) underlying TextWorld state transitions (e.g., go north rule expressed as logical implication).</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>TextWorld (internal logical layer)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Ceptre encodes state and transition rules for text-based game environments; it is part of the toolchain that produces the game's behavior and descriptions; partial observability depends on what the game rules expose in descriptions.</td>
                        </tr>
                        <tr>
                            <td><strong>is_partially_observable</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>external_tools_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tool_output_types</strong></td>
                            <td>Logical predicates / rule encodings; compiled Inform7 code and resulting textual descriptions at runtime.</td>
                        </tr>
                        <tr>
                            <td><strong>belief_state_mechanism</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>incorporates_tool_outputs_in_belief</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>belief_update_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>planning_approach</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_shortest_path_planning</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>navigation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_tools</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_tools</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_tool_ablation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Ceptre is the logical formalism that enables TextWorld to predict next states from actions; the paper uses this as part of the TextWorld toolchain but does not alter Ceptre itself.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'From Floorplan to Navigation Concepts: Automatic Generation of Text-based Games', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e788.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e788.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of agents that use external tools for planning in partially observable text environments, including how they maintain belief states, incorporate tool outputs, and perform navigation or path-finding tasks.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Dynamic Belief Graphs (Adhikari et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Learning dynamic belief graphs to generalize on text-based games</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A cited prior work that proposes learning dynamic belief graphs as a way to represent and update agent beliefs in text-based games to aid generalization; referenced here as related work on belief maintenance in text environments.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Learning dynamic belief graphs to generalize on text-based games</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Dynamic Belief Graph agent (as referenced)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Not described in detail in this paper; referenced as prior work that constructs and updates graph-structured belief representations for agents operating in text-based games to enable generalization across games.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>text-based game benchmarks (referenced generally)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Partially-observable text-game environments where agents must infer unseen state; this referenced work addresses belief representation to cope with partial observability.</td>
                        </tr>
                        <tr>
                            <td><strong>is_partially_observable</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>external_tools_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tool_output_types</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>belief_state_mechanism</strong></td>
                            <td>graph-structured dynamic belief (as per paper title); the current paper references this mechanism but does not detail it.</td>
                        </tr>
                        <tr>
                            <td><strong>incorporates_tool_outputs_in_belief</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>belief_update_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>planning_approach</strong></td>
                            <td>learning-based (paper title implies learning dynamic belief graphs to generalize — i.e., learned policies conditioned on belief graphs).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_shortest_path_planning</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>navigation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_tools</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_tools</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_tool_ablation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>This paper cites Adhikari et al. (2020) as related work on belief-state representations in text games; the present work does not reimplement or evaluate that approach but positions TextWorld extensions as a testbed where such belief-graph agents could be evaluated in floorplan-derived navigation tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'From Floorplan to Navigation Concepts: Automatic Generation of Text-based Games', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e788.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e788.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of agents that use external tools for planning in partially observable text environments, including how they maintain belief states, incorporate tool outputs, and perform navigation or path-finding tasks.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Graph-Constrained RL</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Graph Constrained Reinforcement Learning for Natural Language Action Spaces (Ammanabrolu & Hausknecht)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Cited prior work on constraining RL action spaces using graph structure for text environments; referenced here as an example of rule-/graph-based approaches for instruction following in text games.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Graph Constrained Reinforcement Learning for Natural Language Action Spaces</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>graph-constrained RL agents (referenced)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Not detailed in this paper; referenced as an approach that uses graph constraints to reduce action space for RL agents in text games, enabling instruction following and navigation.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>text-based games (referenced)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Partially-observable text-game environments where action-space constraints via graphs can aid learning and planning.</td>
                        </tr>
                        <tr>
                            <td><strong>is_partially_observable</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>external_tools_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tool_output_types</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>belief_state_mechanism</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>incorporates_tool_outputs_in_belief</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>belief_update_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>planning_approach</strong></td>
                            <td>reinforcement learning with graph constraints (as cited)</td>
                        </tr>
                        <tr>
                            <td><strong>uses_shortest_path_planning</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>navigation_method</strong></td>
                            <td>graph-constrained action selection (cited), but not detailed in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_tools</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_tools</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_tool_ablation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Mentioned as prior art showing how graph structure can be used to constrain agent action spaces and support instruction following; the current paper provides environment tooling (floorplan→TextWorld) that could enable evaluation of such agents on realistic indoor navigation tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'From Floorplan to Navigation Concepts: Automatic Generation of Text-based Games', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e788.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e788.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of agents that use external tools for planning in partially observable text environments, including how they maintain belief states, incorporate tool outputs, and perform navigation or path-finding tasks.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Egocentric orientation tracking (engine-level)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Engine-level agent orientation tracking and egocentric navigation grammar</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An extension implemented in this paper: the TextWorld engine keeps an explicit orientation (AO) and position history for the agent to enable egocentric commands (e.g., go slight left), mapping them to allocentric directions via RD = (AO − DN) mod 8.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>not an agent (engine feature supporting agents)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>A runtime mechanism external to agents: the engine maintains AO (agent orientation) and computes Relative Direction (RD) between current facing and desired movement, enabling egocentric navigation commands without requiring agents to store trajectory themselves.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>TextWorld (extended)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>TextWorld extended to present egocentric navigation affordances; partial observability remains because observations are localized text descriptions.</td>
                        </tr>
                        <tr>
                            <td><strong>is_partially_observable</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>external_tools_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tool_output_types</strong></td>
                            <td>computed orientation integer (0-7), computed RD integer (0-7), natural-language mapping of egocentric instructions to allocentric moves</td>
                        </tr>
                        <tr>
                            <td><strong>belief_state_mechanism</strong></td>
                            <td>simple engine-side state variables: AO (orientation index) and position history; not a learned memory or belief graph.</td>
                        </tr>
                        <tr>
                            <td><strong>incorporates_tool_outputs_in_belief</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>belief_update_description</strong></td>
                            <td>AO is updated on agent actions and tracked by the engine; RD computed per Equation RD = (AO − DN) mod 8; aliases and egocentric command mappings are handled by the engine's grammar/templates.</td>
                        </tr>
                        <tr>
                            <td><strong>planning_approach</strong></td>
                            <td>Not an agent planning method — a runtime translation mechanism to enable egocentric commands for agents and human players.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_shortest_path_planning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>navigation_method</strong></td>
                            <td>Translates egocentric natural-language navigation commands into allocentric (cardinal/ordinal) moves based on tracked AO and the environment's topology.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_tools</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_tools</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_tool_ablation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Providing engine-level orientation tracking allows egocentric navigation commands in TextWorld without requiring agents to maintain their own trajectory memory; this supports more natural navigation instructions and could facilitate experiments on instruction following in partially-observable text environments.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'From Floorplan to Navigation Concepts: Automatic Generation of Text-based Games', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Learning dynamic belief graphs to generalize on text-based games <em>(Rating: 2)</em></li>
                <li>Graph Constrained Reinforcement Learning for Natural Language Action Spaces <em>(Rating: 2)</em></li>
                <li>Instruction Following in Text-Based Games <em>(Rating: 1)</em></li>
                <li>Textworld: A learning environment for text-based games <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-788",
    "paper_id": "paper-259795831",
    "extraction_schema_id": "extraction-schema-21",
    "extracted_data": [
        {
            "name_short": "TextWorld",
            "name_full": "TextWorld (Microsoft TextWorld)",
            "brief_description": "A sandbox environment for creating and running text-based games that compile to Inform7; used to train and evaluate agents (rule-based, supervised, or reinforcement learners) interacting via text in symbolic, often partially-observable worlds.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "unspecified agent (generic TextWorld agent)",
            "agent_description": "The paper does not introduce a new agent architecture; TextWorld is presented as the environment in which agents (rule-based, supervised, or reinforcement-learning agents cited from prior work) can operate. TextWorld provides the game state, compiles logical rules (Ceptre/Inform7) and descriptions, and (as extended by the authors) tracks agent orientation and position history externally to enable egocentric commands.",
            "environment_name": "TextWorld",
            "environment_description": "A text-only game environment where world state, observations and actions are symbolic descriptions (rooms, doors, objects). Observations are local descriptions returned by the engine in response to agent commands; the paper notes TextWorld is suitable for partially-observable tasks (agents do not get the full global state unless described). Challenges include partial observability, abstracted low-level motion (movement is discretized between text-defined areas), and limited default spatial concepts (rooms, 8 directions) which the paper extends.",
            "is_partially_observable": true,
            "external_tools_used": "For environment generation (not by the agent): skeletonization tools and geometry libraries — scikit-geometry (SMAT/MAT), scipy.spatial, shapely, geojson — to produce skeleton graphs/navigation graphs from floorplans; Inform7/Ceptre are used as the logical/compilation toolchain to produce the playable game.",
            "tool_output_types": "Structured navigation graphs (skeleton graph nodes/edges), generated Inform7/TextWorld game descriptions (templated textual descriptions), GeoJSON geometries.",
            "belief_state_mechanism": "The paper describes extending the TextWorld engine to track the agent's history of positions and an explicit agent orientation value (AO) externally to the agent; orientation and relative direction (RD) are computed by the engine. No internal agent belief architecture (memory network, graph belief, etc.) is specified for agents in this paper.",
            "incorporates_tool_outputs_in_belief": false,
            "belief_update_description": "Orientation AO and position history are updated by the TextWorld engine as the agent executes actions; relative direction RD is computed as RD = (AO − DN) mod 8, where DN is the integer-coded direction to the next room. The paper does not describe agents explicitly ingesting or updating richer maps or tool outputs into their own belief states.",
            "planning_approach": "Not specified for a concrete agent in this paper; the authors note that agents in TextWorld can follow route instructions using rule-based methods, supervised learning, or reinforcement learning (citing prior work). The paper itself focuses on environment generation and engine-level orientation tracking rather than a planning algorithm.",
            "uses_shortest_path_planning": null,
            "navigation_method": "Environment provides a graph-like structure (skeleton/navigation graph mapped to TextWorld rooms and doors); agent movement is via allocentric or egocentric text commands. The paper does not describe a particular agent-side pathfinding algorithm (A*, etc.).",
            "performance_with_tools": null,
            "performance_without_tools": null,
            "has_tool_ablation": null,
            "key_findings": "This paper does not present an agent that uses external tools for planning; instead it extends TextWorld to (1) automatically generate text-game worlds from floorplan-derived skeleton/navigation graphs (using external geometry toolchain) and (2) add egocentric navigation grammar by having the engine track agent orientation and compute relative directions. The engine-level orientation tracking enables egocentric commands without requiring agents to maintain full trajectory beliefs themselves.",
            "uuid": "e788.0",
            "source_info": {
                "paper_title": "From Floorplan to Navigation Concepts: Automatic Generation of Text-based Games",
                "publication_date_yy_mm": "2023-06"
            }
        },
        {
            "name_short": "Skeleton-based navigation graph",
            "name_full": "Skeleton graph (SMAT/MAT-derived navigation graph from floorplans)",
            "brief_description": "A graph derived from medial-axis/skeletonization (MAT/SMAT) of floorplan polygons where nodes represent atomic IndoorAreas and edges represent adjacency; used here to automate generation of TextWorld navigation structure.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "not applicable (graph used to generate environment)",
            "agent_description": "Not an agent — a representation used by the environment generator to instantiate rooms/areas/links (IndoorArea, IndoorRoom, Door, ULink) in TextWorld; agents interact with the instantiated textual environment rather than the raw graph.",
            "environment_name": "TextWorld (generated worlds)",
            "environment_description": "TextWorld games generated from geometric floorplans via skeleton graphs; partial observability arises from agents receiving localized textual descriptions mapped from the skeleton-derived partitioning.",
            "is_partially_observable": true,
            "external_tools_used": "SMAT/MAT skeletonization algorithms (implemented via scikit-geometry), Voronoi-related computations (scipy.spatial), shapely and geojson for geometry handling.",
            "tool_output_types": "Graph structures (nodes/edges representing IndoorAreas and connections), mapping metadata (parent relationships, door/landmark associations), templated Inform7/TextWorld descriptions.",
            "belief_state_mechanism": null,
            "incorporates_tool_outputs_in_belief": false,
            "belief_update_description": null,
            "planning_approach": "Not applicable to an agent in this paper; the skeleton graph is a generation-time artifact that becomes the game's topology.",
            "uses_shortest_path_planning": null,
            "navigation_method": "Graph-structured topology is compiled into TextWorld rooms and explicit connections; agents navigate via textual go/egocentric commands reflecting that topology.",
            "performance_with_tools": null,
            "performance_without_tools": null,
            "has_tool_ablation": null,
            "key_findings": "Skeletonization (MAT/SMAT) can be used to derive atomic IndoorAreas and adjacency suitable for mapping into TextWorld concepts, enabling richer, more realistic navigation topologies for text-based agents without embedding explicit geometric details in the textual environment.",
            "uuid": "e788.1",
            "source_info": {
                "paper_title": "From Floorplan to Navigation Concepts: Automatic Generation of Text-based Games",
                "publication_date_yy_mm": "2023-06"
            }
        },
        {
            "name_short": "Ceptre",
            "name_full": "Ceptre (functional language for game logic / linear logic reasoning)",
            "brief_description": "A functional language using linear logic formulas to express game rules and state transitions; used by TextWorld to encode predicates and state-change rules that the Inform7 compiler can translate into executable worlds.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": null,
            "agent_description": "Not an agent; Ceptre provides the formal operational logic (characters, locations, predicates, actions) underlying TextWorld state transitions (e.g., go north rule expressed as logical implication).",
            "environment_name": "TextWorld (internal logical layer)",
            "environment_description": "Ceptre encodes state and transition rules for text-based game environments; it is part of the toolchain that produces the game's behavior and descriptions; partial observability depends on what the game rules expose in descriptions.",
            "is_partially_observable": null,
            "external_tools_used": null,
            "tool_output_types": "Logical predicates / rule encodings; compiled Inform7 code and resulting textual descriptions at runtime.",
            "belief_state_mechanism": null,
            "incorporates_tool_outputs_in_belief": null,
            "belief_update_description": null,
            "planning_approach": null,
            "uses_shortest_path_planning": null,
            "navigation_method": null,
            "performance_with_tools": null,
            "performance_without_tools": null,
            "has_tool_ablation": null,
            "key_findings": "Ceptre is the logical formalism that enables TextWorld to predict next states from actions; the paper uses this as part of the TextWorld toolchain but does not alter Ceptre itself.",
            "uuid": "e788.2",
            "source_info": {
                "paper_title": "From Floorplan to Navigation Concepts: Automatic Generation of Text-based Games",
                "publication_date_yy_mm": "2023-06"
            }
        },
        {
            "name_short": "Dynamic Belief Graphs (Adhikari et al.)",
            "name_full": "Learning dynamic belief graphs to generalize on text-based games",
            "brief_description": "A cited prior work that proposes learning dynamic belief graphs as a way to represent and update agent beliefs in text-based games to aid generalization; referenced here as related work on belief maintenance in text environments.",
            "citation_title": "Learning dynamic belief graphs to generalize on text-based games",
            "mention_or_use": "mention",
            "agent_name": "Dynamic Belief Graph agent (as referenced)",
            "agent_description": "Not described in detail in this paper; referenced as prior work that constructs and updates graph-structured belief representations for agents operating in text-based games to enable generalization across games.",
            "environment_name": "text-based game benchmarks (referenced generally)",
            "environment_description": "Partially-observable text-game environments where agents must infer unseen state; this referenced work addresses belief representation to cope with partial observability.",
            "is_partially_observable": true,
            "external_tools_used": null,
            "tool_output_types": null,
            "belief_state_mechanism": "graph-structured dynamic belief (as per paper title); the current paper references this mechanism but does not detail it.",
            "incorporates_tool_outputs_in_belief": null,
            "belief_update_description": null,
            "planning_approach": "learning-based (paper title implies learning dynamic belief graphs to generalize — i.e., learned policies conditioned on belief graphs).",
            "uses_shortest_path_planning": null,
            "navigation_method": null,
            "performance_with_tools": null,
            "performance_without_tools": null,
            "has_tool_ablation": null,
            "key_findings": "This paper cites Adhikari et al. (2020) as related work on belief-state representations in text games; the present work does not reimplement or evaluate that approach but positions TextWorld extensions as a testbed where such belief-graph agents could be evaluated in floorplan-derived navigation tasks.",
            "uuid": "e788.3",
            "source_info": {
                "paper_title": "From Floorplan to Navigation Concepts: Automatic Generation of Text-based Games",
                "publication_date_yy_mm": "2023-06"
            }
        },
        {
            "name_short": "Graph-Constrained RL",
            "name_full": "Graph Constrained Reinforcement Learning for Natural Language Action Spaces (Ammanabrolu & Hausknecht)",
            "brief_description": "Cited prior work on constraining RL action spaces using graph structure for text environments; referenced here as an example of rule-/graph-based approaches for instruction following in text games.",
            "citation_title": "Graph Constrained Reinforcement Learning for Natural Language Action Spaces",
            "mention_or_use": "mention",
            "agent_name": "graph-constrained RL agents (referenced)",
            "agent_description": "Not detailed in this paper; referenced as an approach that uses graph constraints to reduce action space for RL agents in text games, enabling instruction following and navigation.",
            "environment_name": "text-based games (referenced)",
            "environment_description": "Partially-observable text-game environments where action-space constraints via graphs can aid learning and planning.",
            "is_partially_observable": true,
            "external_tools_used": null,
            "tool_output_types": null,
            "belief_state_mechanism": null,
            "incorporates_tool_outputs_in_belief": null,
            "belief_update_description": null,
            "planning_approach": "reinforcement learning with graph constraints (as cited)",
            "uses_shortest_path_planning": null,
            "navigation_method": "graph-constrained action selection (cited), but not detailed in this paper.",
            "performance_with_tools": null,
            "performance_without_tools": null,
            "has_tool_ablation": null,
            "key_findings": "Mentioned as prior art showing how graph structure can be used to constrain agent action spaces and support instruction following; the current paper provides environment tooling (floorplan→TextWorld) that could enable evaluation of such agents on realistic indoor navigation tasks.",
            "uuid": "e788.4",
            "source_info": {
                "paper_title": "From Floorplan to Navigation Concepts: Automatic Generation of Text-based Games",
                "publication_date_yy_mm": "2023-06"
            }
        },
        {
            "name_short": "Egocentric orientation tracking (engine-level)",
            "name_full": "Engine-level agent orientation tracking and egocentric navigation grammar",
            "brief_description": "An extension implemented in this paper: the TextWorld engine keeps an explicit orientation (AO) and position history for the agent to enable egocentric commands (e.g., go slight left), mapping them to allocentric directions via RD = (AO − DN) mod 8.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "not an agent (engine feature supporting agents)",
            "agent_description": "A runtime mechanism external to agents: the engine maintains AO (agent orientation) and computes Relative Direction (RD) between current facing and desired movement, enabling egocentric navigation commands without requiring agents to store trajectory themselves.",
            "environment_name": "TextWorld (extended)",
            "environment_description": "TextWorld extended to present egocentric navigation affordances; partial observability remains because observations are localized text descriptions.",
            "is_partially_observable": true,
            "external_tools_used": null,
            "tool_output_types": "computed orientation integer (0-7), computed RD integer (0-7), natural-language mapping of egocentric instructions to allocentric moves",
            "belief_state_mechanism": "simple engine-side state variables: AO (orientation index) and position history; not a learned memory or belief graph.",
            "incorporates_tool_outputs_in_belief": false,
            "belief_update_description": "AO is updated on agent actions and tracked by the engine; RD computed per Equation RD = (AO − DN) mod 8; aliases and egocentric command mappings are handled by the engine's grammar/templates.",
            "planning_approach": "Not an agent planning method — a runtime translation mechanism to enable egocentric commands for agents and human players.",
            "uses_shortest_path_planning": false,
            "navigation_method": "Translates egocentric natural-language navigation commands into allocentric (cardinal/ordinal) moves based on tracked AO and the environment's topology.",
            "performance_with_tools": null,
            "performance_without_tools": null,
            "has_tool_ablation": null,
            "key_findings": "Providing engine-level orientation tracking allows egocentric navigation commands in TextWorld without requiring agents to maintain their own trajectory memory; this supports more natural navigation instructions and could facilitate experiments on instruction following in partially-observable text environments.",
            "uuid": "e788.5",
            "source_info": {
                "paper_title": "From Floorplan to Navigation Concepts: Automatic Generation of Text-based Games",
                "publication_date_yy_mm": "2023-06"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Learning dynamic belief graphs to generalize on text-based games",
            "rating": 2,
            "sanitized_title": "learning_dynamic_belief_graphs_to_generalize_on_textbased_games"
        },
        {
            "paper_title": "Graph Constrained Reinforcement Learning for Natural Language Action Spaces",
            "rating": 2,
            "sanitized_title": "graph_constrained_reinforcement_learning_for_natural_language_action_spaces"
        },
        {
            "paper_title": "Instruction Following in Text-Based Games",
            "rating": 1,
            "sanitized_title": "instruction_following_in_textbased_games"
        },
        {
            "paper_title": "Textworld: A learning environment for text-based games",
            "rating": 2,
            "sanitized_title": "textworld_a_learning_environment_for_textbased_games"
        }
    ],
    "cost": 0.0148455,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>From Floorplan to Navigation Concepts: Automatic Generation of Text-based Games</p>
<p>Reza Arabsheibani reza.arabsheibani@student.unimelb.edu.au 
Department of Infrastructure Engineering
The University of Melbourne
3010ParkvilleVICAustralia</p>
<p>Ehsan Hamzei 
Department of Infrastructure Engineering
The University of Melbourne
3010ParkvilleVICAustralia</p>
<p>Kimia Amoozandeh 
Department of Infrastructure Engineering
The University of Melbourne
3010ParkvilleVICAustralia</p>
<p>Stephan Winter 
Department of Infrastructure Engineering
The University of Melbourne
3010ParkvilleVICAustralia</p>
<p>Martin Tomko 
Department of Infrastructure Engineering
The University of Melbourne
3010ParkvilleVICAustralia</p>
<p>From Floorplan to Navigation Concepts: Automatic Generation of Text-based Games
10.5194/agile-giss-4-2-2023Correspondence: Reza Arabsheibanisymbolic modellingindoor spacetext-based gamesspace concepts
Text-based games are environments in which defining the world, the representation of the world to the player (hereafter, agent) and agent interactions with the environment are all through text. Text-based games expose abstract, executable representations of indoor spaces through verbally referenced concepts. Yet, the ability of text-based games to represent indoor environments of realworld complexity is currently limited due to insufficient support for complex space decomposition and space interaction concepts. This paper suggests a procedure to automate the mapping of real-world geometric floorplan information into text-based game environment concepts, using the Microsoft TextWorld game platform as a case. To capture the complexities of indoor spaces, we enrich existing TextWorld concepts supported by theoretical navigation concepts.We first decompose indoor spaces using skeletonization, and then identify formal space concepts and their relationships. We further enhance the spectrum of supported agent interactions with an extended grammar, including egocentric navigation instructions. We demonstrate and discuss these new capabilities in an evacuation scenario. Our implementation extends the capabilities of TextWorld to provide a research testbed for spatial research, including symbolic spatial modelling, interaction with indoor spaces, and agent-based machine learning and language processing tasks.</p>
<p>Introduction</p>
<p>Modeling indoor space is necessary for indoor locationbased services, including navigation assistance (Karimi, 2015). Indoor space models can be classified as geometric and symbolic models (Afyouni et al., 2012). While the geometric models use coordinate-based geometric representations of space, the symbolic models define the environment using abstract concepts and their relationships (incl. connectivity and containment) (Karas et al., 2006). While current geometric models are widely used in simulation, symbolic representation can only be used if the simulation environment is capable of handling abstract concepts and performing qualitative spatial reasoning.</p>
<p>Text-based games are simulation environments in which the definition of the world, representation of the world to the agent (i.e., human or software agent), and the agent's interaction with the environment are all through text. Textbased games simulate the environment using linguistic concepts with well-defined semantics, such as rooms and doors rather than through interaction with graphic or geometric information. When agents require information about these concepts (rooms and objects in rooms) and their affordances, they interact via text by issuing an action command, such as look. In response, the simulation environment provides natural language descriptions (typically template-based) containing information about visible objects in the room (Figure 1). The capability of text-based games to expose the environment to agents using concepts instead of graphical scenes is appealing for research in indoor space interaction, including navigation. The expressive properties of current text-based games are, however, limited, and their suitability for experimenting with realworld navigation instructions needs to be assessed.</p>
<p>There are limitations to authoring a complex world in current text-based games since they have been developed for fiction games with simple, schematic environments. This is suitable for automatically created game environments or hand-crafted game environments. The repetitive interaction of agents with large amounts of automatically generated worlds enables agents to learn complex skills (Jansen, 2021) and solve complex tasks. However, the concepts available in text-based game models lack the expressive power needed for modeling real-world indoor spaces. Moreover, there is no automatic procedure for mapping generic geometry floorplan data formats into descriptions that are interpretable by text-based games and game agents. The main research question addressed here is "How can we computationally model indoor environments that enable textual interaction to support agent navigation?" Therefore, our modeling focuses on (1) using descriptive, conceptual text definitions of indoor spaces; (2) the ability to represent concepts of the environment that are relevant to navigation; and (3) supporting the interaction of agents with the modelled environment. This paper addresses the hypothesis that a symbolic representation of an indoor space supporting navigation applications can be computed from the spatial information contained in floorplans in a way that schematic geometry (Rüetschi and Timpf, 2004) enables mapping between real-world geometric information and text-based game concepts. We use symbolic models to represent the environment (e.g., locations, objects, and possible actions) through textual descriptions.</p>
<p>The main contributions of this paper are:</p>
<p>• The definition of new indoor space concepts that mediate automatic mapping of geometric information into text-based games descriptions;</p>
<p>• The assessment of space decomposition approaches based on their applicability to the text-based games;</p>
<p>• The enriched user interaction, scenario creation, and definition of new navigation grammars (incl. the introduction of an egocentric reference frame) in a textbased game environment, using TextWorld as a case.</p>
<p>The organization of this paper is as follows: Section 2 elaborates on the history and general specifications of textbased games. We discuss gaps in current implementations of text-based games, their navigation applications, and the potential use of text-based games in the spatial community. Moreover, we elaborate on the indoor space decomposition methods and geometry-to-graph conversion approaches. Section 3 summarizes abstract concepts of the environment. In Section 4, we will propose an approach for automatically converting geometric information of the floorplan into a navigation graph, generating a simulated environment from the navigation graph, and improving TextWorld's user interaction grammar. Proposed concepts implemented in TextWorld are demonstrated in Section 5. Section 6 explains the data, software and libraries, and codes repository. Finally, Section 7 discusses findings and future works.</p>
<p>Background</p>
<p>Text-based Games</p>
<p>Text-based computer games trace back to the 1960s when the only communication form with mainframes was terminals (Nelson et al., 1997). Z-machine is perhaps the oldest low-level interpreter able to parse texts and create interactive fictional text-based games (Koirikivi, 2015). Inform, introduced by Nelson (2006), is a natural-language-based programming language for creating interactive games. In-form7 is the last generation of the Inform family of text environments (Nelson, 2011). Although there are other text-based games authoring systems such as TADS 1 and Twine 2 , they are not as generally adopted as Inform7 by research communities (Jansen, 2021).</p>
<p>In Inform7, all objects are concepts definable by descriptions, and grammar is the set of actions related to the properties of the defined objects. Inform7 models the environment based on an object tree (Figure 2), a simplified hierarchy of objects with their properties and relevant grammar. The relation between Inform7 objects and actions is framed by rules. The atomic unit of text-based games is a room, and the connectivity of rooms is then encoded in directions (typically only supporting cardinal directions). A third basic concept of text environments is that of region.</p>
<p>The adjacent rooms with shared properties can be aggregated into a region. Inform7 also defines a small number of spatial rules and rudimentary reasoning capabilities at its core, e.g. the reverse direction (for example, since north and south are reverse directions, if room A is at the north of room B, then room B is at the south of room A) and containment relationships (for example, when room A is inside room B, if the agent exits room A, then the agent is in room B).</p>
<p>In text-based games, the agent's movement inside a room is considered trivial. This major conceptual gap limits the applicability of text environments for modeling interaction in real-world settings. Consider a real-world example: a customer cannot see every object inside a supermarket if they remain stationary. In contrast, the representation of a supermarket as a room in a text-based game generally means that an agent can see and interact without locomotion with all objects within the supermarket.</p>
<p>TextWorld is an environment the Microsoft Research team introduced as a sandbox for training reinforcement learning agents (Côté et al., 2018). TextWorld provides an operational and logical framework for creating In-form7 worlds. To generalize an operational logic for the interaction between the agent and TextWorld, Ceptre, a functional language that uses linear logic formulas to reason about games, has been introduced (Martens, 2015). For example, if P is the player (or agent), r and r' are rooms, at(P,r) means player P is inside room r, and north_of(r', r) means r is located to the north of room r', then using defined datatypes and predicates it is possible to define the go north rule as: go/north::at(P, r) &amp; north_of(r', r)-&gt; at(P, r'). Ceptre introduces characters, locations, and objects as substantial types and defines predicates (such as character locations, sentiments, and actions) that enable state transitions in TextWorld. At its lowest level, TextWorld translates this logical framework to Inform7 code for compiling. The TextWorld structure can predict the next state when the agent chooses a possible action.</p>
<p>Text-based Games for Spatial Research</p>
<p>Text-based games and interacting agents may support a range of spatial research through their appealing properties:</p>
<p>• Symbolic Modeling: Text-based games rely on symbolic modeling of the environment, capturing the interrelationship of space subdivisions or hierarchies of spatial entities. In the case of indoor navigation, geometric models of indoor spaces work only for agents who are aware of (or able to determine) their current position in the environment, e.g. a robot with multi-radar sensory information of distances to immediate barriers (Zhou et al., 2022). TextWorld overcomes this by providing programmatic means to interact with an environment defined symbolically and to develop agents with capabilities to interact with the symbolic environment.</p>
<p>• Abstraction: Text-based games expose an environment with fully deterministic, abstracted responses to agent actions or state transitions at a given level of detail. For example, if a door connects the current room to a room in the north, and the agent interacts (e.g., by issuing the open the door and go north command), the agent's location will deterministically change to the northern room. This process excludes lower-level reasoning about required motions such as walking toward the door, turning the key, and pulling the door. The abstraction capability of textbased games allows reasoning about the concepts and actions at a higher conceptual level of environmental interaction, liberating from lower-level physical interaction details. This level of abstraction allows focusing on hierarchical spatial reasoning, spatial learning, and problems related to navigation.</p>
<p>• Extensibility: In contrast to 3D virtual environments and simulators, agents in text-based games interact with objects using textual commands, without the need for grounding agent-object interaction. 3D virtual environments, e.g., AI2-Thor (Kolve et al., 2017), use photos to create scenes and include physic laws for the interaction of agents and objects. Action space is limited in 3D modeling, and extending agentobject or object-object interactions is expensive and complex (Jansen, 2021). The definition of new actions for available concepts in text-based games follows the same logic and templates of already defined actions. For example, opening a container in 3D environments requires a new agent-object interaction definition. At the same time, it is a straightforward extension to define a rich collection of action phrases in TextWorld .</p>
<p>• Quest Definition: Text-based games expose the ability to simulate scenarios (quests) for the interacting agents. The scenarios can be constrained by time or the number of interactions. The agent can receive rewards when completing the quest or be otherwise penalized. Text-based games can support environments that change dynamically over time (e.g., as fire can extend in a building), and also, success states for the agent can vary, as a pedestrian may need to change the planned path.</p>
<p>• Route Instruction Following: Text-based game agents can be used for exploring the interpretability of route instructions. Route instructions are verbal descriptions for guiding a wayfinder that capture a sequence of states and actions (Frank, 2003). Similarly, text-based game quests are also sequential decisionmaking engines that consist of states and actions . A similar semantic structure of route instructions and quests in TextWorld  (Aikin, 2009). room: atomic spatial partition, region: aggregation of rooms, direction: cardinal and/or ordinal directions, door: connecting rooms, backdrop: scenery that may extend across rooms, e.g. sky, person: man, women, and pet, container: objects can be put inside containers, and supporter: a horizontal surface on which things can be put, e.g. table. Note: this is an abridged concept tree (e.g., the concept Person holds additional attributes not shown here for legibility.</p>
<p>can be used for assessing route instructions in guiding wayfinders in partially-observable environments. TextWorld offers agent interaction capabilities based on natural language commands from agents and descriptions of the environment back to the agents. The agents' navigation in the simulated world proceeds through this command-based interaction. Agents can follow provided route instruction based on rules (Ammanabrolu and Hausknecht, 2020), supervised learning (Adhikari et al., 2020), or reinforcement learning (Tuli et al., 2022). All agent navigation in TextWorld is allocentric and supports eight cardinal and ordinal directions ( Figure 7) (Paillard, 1991). So the agent must be aware of the relative direction of the next room while navigating. For example, when the agent issues a command go north, if there is a room north of the current room, the agent's location will change accordingly but fail if such a room does not exist. People more commonly navigate using an egocentric reference frame, especially in indoor spaces where recognizing cardinal directions may not be a straightforward task.</p>
<p>Currently, text-based games support only concepts of rooms, regions, and eight directions. Therefore, to use the abstract capabilities of text-based games in spatial domains, their concepts must be extended to capture the complexity of real-world indoor spaces and richer interactions. A model that can capture complex environments' spatial details enables the definition of more complex quests, reasoning, and instruction generation and following. Here we suggest an automatic procedure to generate text-based game descriptions directly from geometric information.</p>
<p>Geometry to Graph</p>
<p>Floorplans are often represented using simple 2D geometries representing the outlines of indoor spaces. Thus, rooms may be represented as polygons or polylines, doors or stairs as lines, and landmarks as points. These polygons and points may be annotated with additional information about the spaces, doors, or landmarks. However, such a geometric representation does not capture connectivity between room walls and is thus inadequate for routing and navigation.</p>
<p>Graph representations of spatial environments are expressive structures enabling the modeling of objects and their relationships, such as topological relationships (Marshall et al., 2018). Graph models of indoor environments are highly varied. In the structure graph introduced by Roth et al. (1982), nodes represent doors or corners, and edges represent walls of an indoor space ( Figure 3b). Deriving the graph representation for navigation purposes from the structure graph is challenging due to the lack of explicit definitions of indoor concepts such as containers (rooms). Hence, Lee and Kwan (2005) defined the primal space and dual graph (Figure 3c). Primal space in 2D divides one universal polygon into a partition of pairwise disjoint polygons (Ledoux and Gold, 2007, p. 3). Dual space assigns a dual vertex to each polygon in the primal space, and if the polygons share an edge, the corresponding dual vertices will be connected by a dual edge. However, if two rooms share their boundary without direct accessibility in the dual graph of an indoor environment, the dual graph still connects them via an edge.</p>
<p>To overcome the accessibility problem in the dual graph, accessibility graph and navigation graph have been suggested (Yang and Worboys, 2015) (Figures 3d and 3e). Navigation graph supports room, door, vertical connectiv-ity, intersection, and landmark. The level of detail of elements modelled in the navigation graph can be used for instruction follower agents. One possible shortcoming is that the navigation graph has no orientation information, while a navigation agent requires orientation guidance.</p>
<p>From a computational perspective, various standard data formats have been provided for indoor space modeling. CityGML 3 is a standardization that addresses elements for both outdoor and indoor spaces using 3D coordinates. In-doorGML 4 is another open data model designed by OGC to represent indoor spaces. IndoorGML supports the definition of indoor space based on geometric information of structure graphs and dual graphs. Industry Foundation Classes (IFC) is an ISO-accepted open standard that can support structure graphs. Geometric and semantic information of the indoor features is defined in the IFC, while the containment relationships of spatial objects can be modelled using the predefined hierarchy, the connectivity of features is not directly defined. Moreover, Indoor Mapping Data Format (IMDF) is a standard that defines indoor spaces based on a hierarchical model that contains venues, buildings, floors, rooms, and objects. The geometric information of features is defined using GeoJSON polygon types in IMDF model 5 . IMDF can support accessibility and navigation graphs.</p>
<p>Abstract Concepts of Environment</p>
<p>To model indoor spaces symbolically, e.g. in a text-based game, a schema of indoor entities is required. Elements of the schema must be abstract enough to link the computational modeling of the space in a text-based game and real-world indoor space. Elements can be distinguished based on visual and/or functional aspects. Lynch (1964) argues that the operation of an individual in different environments relies on a conceptual image of the agent about the environments. An object's imageability is defined as "the quality in a physical object which gives it a high probability of evoking a strong image in any given observer" (Lynch, 1964, p. 9). Imageability is thus reduced to the perceptible visual aspect of physical objects. The socially shared image of an environment then approximates a collection of individuals' images that thus lead to a shared pattern of the environment (Lynch, 1964, p. 40). From the spatial functional perspective, Tomko and Winter (2013) have introduced a formally grounded extension to Lynchean elements that links the dimensionality of city elements and their accessibility, i.e., the affordance of spatial objects that specifies if an agent can enter the inside of the object.</p>
<p>In a complementary manner, Image schemata are a cognitive model that maps observed visual sensory data to a recurring abstract form of knowledge about the world, i.e. patterns (Johnson, 2013). The conceptualization of indoor spaces based on image schemata in geographic information systems was introduced by Raubal et al. (1997) and Frank and Raubal (1999), and applied broadly in spatial cognition research (Kuhn, 2007;Rüetschi, 2007;Hedblom et al., 2019). Rüetschi and Timpf (2004) sketched a formal model of spatial concepts in human wayfinding focusing on qualitative spatial configurations rather than on metric information (the notion of topology defines, metrics refines), which was helpful to avoid issues with the limited device positioning accuracy (if available at all). They extended Johnson's image schemata and defined six concepts based on spatial and functional properties (Table 1).</p>
<p>This study adopts schematic geometry to ground a floorplan in Inform7 concepts. Because schematic geometry is designed for navigation purposes, it is a generic design that enables the implementation of the complexities of indoor spaces. We apply the skeleton graph as the primary space decomposition approach. Skeletonization of the space creates a graph that supports navigation and is flexible in terms of spatial cognition and abstract reasoning (Afyouni et al., 2012) (see Figure 3f). A skeleton graph can model the adjacency and connectivity of nodes (i.e., rooms) connected via edges (i.e., doors), thus fitting with the capabilities of TextWorld. Such skeleton-based approaches fit the case of navigation in narrow corridors (Russo et al., 2014) and support the representation of natural movement within indoor environments (Mortari et al., 2019).</p>
<p>Conceptual Framework of Indoor Space Concepts</p>
<p>A challenge of text-based games for the simulation of real-world indoor spaces is the constrained domain of concepts and related actions, as well as the lack of support for the agent's movement inside a room (or parts of the room, possibly differentiated by intervisibility), as the concept of more atomic partitions is not defined. We extend TextWorld's knowledge base to cover these shortcomings. The newly defined concepts and their specification are summarized as follows (Table 2 illustrates the defined concepts in an example.):</p>
<p>• IndoorArea: The basic new concept for the definition of an atomic indoor space is IndoorArea. An IndoorArea is enterable and affords object containment. An IndoorArea is part of a IndoorRoom. The agent can interact with the objects inside it if the agent is located in the same IndoorArea. An IndoorArea can be adjacent with other neighbouring IndoorAreas, but the movement between adjacent IndoorAreas that belong to the different IndoorRoom require explicit actions.</p>
<p>• IndoorRoom:</p>
<p>The aggregation of IndoorAreas form IndoorRoom, a container of   which boundaries correspond to real-world boundaries such as walls. Every IndoorRoom has at least one IndoorArea, and every IndoorArea relates to only one parent IndoorRoom. The IndoorRoom is partitioned by IndoorAreas. The movement inside IndoorRoom does also not require explicit actions, but movement between IndoorRooms requires interactions with actions and objects, e.g., a door.</p>
<p>• IndoorFloor: The collection of horizontally colocated IndoorRooms form IndoorFloor. Object containment is not the direct affordance of IndoorFloors.</p>
<p>• Door: The link that connect two adjacent IndoorAreas in two different IndoorRoom par-ents is a Door. By definition, doors are located at the boundaries of two IndoorAreas and therefore two parent IndoorRooms. Doors are walkthrough-able. Agent must interact explicitly with Doors and when they do so, both IndoorArea and IndoorRoom related to the agent's location will be changed.</p>
<p>• ULink: The link that connects two adjacent IndoorAreas within the same IndoorRoom is a ULink. They are walk-through-able and the agent experience ULinks implicitly. When an agent uses a ULink, the IndoorArea of the agent changes while the IndoorRoom remains the same.</p>
<p>• Landmark: All objects located inside an IndoorArea are Landmarks. They are not enterable or walk-through-able. Landmarks can be visible or invisible, intractable or non-intractable, and movable or fixed. Signage and fixtures are examples of Landmarks. Signage are landmarks fixed in a location that shows an informative text to assist agents' navigation, and agents can only see them without any other further interaction. Fixtures are landmarks fixed in a location that agents can interact with them but cannot move (such as an ATM). A Landmarks can be visible, intractable, and movable, e.g., an apple on a table. Each Landmark belongs to one and only one parent IndoorArea.</p>
<p>All defined concepts must have defined basic properties, including name and description and can have optional properties such as printed name (an alternative, human-consumable label). The extended concept definitions above enable a conceptual model of indoor spaces. Elements of indoor environments with their properties and affordances can be represented through instances of these concepts.</p>
<p>The mapping of abstract concepts of navigation spaces to the extended concepts introduced earlier, and finally to the core text-based game concepts, is shown in Figure 4. Later, we show how a template-based mapping is applied to instantiate these concepts based on floorplan data.</p>
<p>The concept of Room is the basic spatial partition in TextWorld, so we map IndoorArea extracted from skeleton graph into TextWorl's Room. IndoorArea is the basic partition of our defined concepts, so they cannot contain any other concept while they must be contained in at least one IndoorRoom. IndoorRoom maps a realworld room surrounded by physical walls into TextWorl's Rooms that support containment of other Rooms (mapped from IndoorAreas). IndoorFloor maps between horizontally colocated rooms with shared properties using TextWorld Region concept.</p>
<p>Navigating between IndoorAreas might need interaction (e.g., opening a closed door) or be an implicit experience, such as walking through an open gate. Doors map explicit connections and Ulinks map implicit connections. Ulink use the Door of TextWorld concepts which is always open while Door use those openable and closable Textworld Doors.</p>
<p>Landmark map all objects inside IndoorAreas into TextWorld concept of Thing. Things can have different properties, such as portable or fixed, described or undescribed, and intractable or not-interactable.</p>
<p>To automatically map the information derived from the floorplan into TextWorld understandable format, we use templates shown in Table 3. IndoorArea and IndoorRooms use the template of general concepts, as those are new concepts introduced to TextWorld.</p>
<p>Properties schema of new concepts can be defined using the template of the property of concepts, for example, the parent attribute of theIndoorArea, which is an IndoorRoom. Moreover, the affordances of new concepts must follow the specified template. Visibility, openablity, and enterablity are examples of concepts' affordances. Concepts can be instantiated by passing a name and a human-consumable description to the template. The properties of instances can also be specified by passing the initialization value.</p>
<p>Computational Implementation</p>
<p>The TextWorld engine uses a knowledge base and themes as inputs for a generator that translates the world specifications into Inform7 descriptions. Then, the engine interactively presents the world to the user. This study extends TextWorld's structure ( Figure 5) in three domains:</p>
<p>• Defining new concepts (IndoorArea, IndoorRoom, Ulink) based on schematic geometry to ensure the availability of generic concepts allow for capturing the complexities of indoor spaces;</p>
<p>• Extracting abstract objects, instances, properties, and their corresponding descriptions from a geometric floorplan, thus providing a third modality for world creation to the two available currently in TextWorld (random world creation and handcrafted worlds);</p>
<p>• Extending the expressivity of the TextWorld engine by extending direction instructions with egocentric agent navigation concepts, extending the set of available actions and predicates for new concepts, and introducing action aliases. Figure 6 shows the general workflow of the proposed implementation to automatically generate text-based game descriptions from the geometric information of an architectural floorplan. The workflow starts with the geometries of floorplan elements, including rooms, doors, and landmarks, as well as initial information about the Quest, such as the origin and destination location of the agent, the agent's initial orientation, and the maximum number of interactions in a quest (stopping condition).</p>
<p>Next, a geo-processing step recognizes areas and assigns them to corresponding doors and landmarks based on applying the templated instantiations of geometries to textbased game concepts. Finally, descriptions that are understandable for TextWorld is generated and demonstrated.</p>
<p>Generating Skeleton Graph from Floorplan</p>
<p>The skeleton graph extraction from floorplans relies on medial axis transformation (MAT) (Lee, 1982). The MAT of a polygon is the set of loci from which at least two points on the polygon's boundary are equidistant (Lee, 1982). In other words, skeleton points are an aggregation of circles' centroids inscribed inside a polygon that IndoorRooms IndoorRoom1 is an indoor_room. IndoorRoom2 is an indoor_room.</p>
<p>IndoorAreas</p>
<p>IndoorArea1 is an area. the parent of the IndoorArea1 is IndoorRoom2. IndoorArea2 is an area. the parent of the IndoorArea2 is IndoorRoom2.</p>
<p>IndoorArea0 is an area. the parent of the IndoorArea0 is IndoorRoom1. Ulinks north of IndoorArea2 is south of IndoorArea1.</p>
<p>Doors</p>
<p>Door1 is a door. "Door Room 1 to Room 2". Door1 is north of IndoorArea3. Door1 is south of IndoorArea2.</p>
<p>Landmarks</p>
<p>Landmark1 is a landmark. printed name of the Landmark1 is "Landmark 1". the Landmark1 is in IndoorRoom1.</p>
<p>IndoorFloors</p>
<p>IndoorFloor1 is a region. IndoorRoom1 is in IndoorFloor1. IndoorRoom2 is in IndoorFloor1. touches the boundary in at least two points. Therefore the circle fitting method is used to compute MAT, and is one of the steps in the computation of the Voronoi diagram. Lee (2004) proposed a complementary algorithm called Straight MAT or SMAT. SMAT solves distortion problems in MAT, including T-shape, L-shape, and X-shape displacements, by simplifying Voronoi diagrams of planar straight-line graphs.</p>
<p>The space decomposition used in this study relies on Lee's algorithm for SMAT calculation implemented in the scikitgeometry Python library 6 . A skeleton graph derived using the SMAT algorithm is shown in Figure 3f for an example floorplan. According to the conceptual design introduced in Section 3, the skeleton nodes represent the IndoorAreas. TextWorld environments are symbolic representations and do not include geometric information. Hence, instead of calculating the boundaries of the IndoorAreas, only their connections and adjacency are captured here.</p>
<p>Generating Text-based Games' Environments from Skeleton Graphs</p>
<p>We define dynamic and static templates to frame the automatic generation of text-based games. These templates use the skeleton graph generated based on the floorplan as input and create concepts, instances, relationships, and actions. The outputs are descriptions understandable to In-form7 and TextWorld compilers. Concepts defined in 3, concept properties, affordances, and their default values have been set using a predefined set of templates (Table  3).</p>
<p>The text generation process must enable automatic definition and identification of Ulink connections between the atomic IndoorAreas, so that the agent can continue exploring in the same room without opening a door. Door is the connection between two neighboring IndoorAreas located in different rooms. Algorithm 1 summarizes the process of establishing valid connections between neighbouring IndoorAreas.</p>
<p>Landmarks are added to the TextWorld descriptions using predefined templates and located at the nearest skeleton node. If the agent's corresponding IndoorAreea is the same as that of a Landmark, the agent can interact with the Landmark. However, there can be Landmarks that do not afford interaction while they afford visibility to an agent located in a distant IndoorArea (i.e., IndoorArea that is not the parent of the Landmark). </p>
<p>Extending Agent Interactions</p>
<p>Interactions in TextWorld are supported by grammar relating to new concepts, properties, and actions. Only instructions with known mapping to actions, including operands, are supported. Thus, for direction concepts, it is necessary to identify the actions, i.e., the impact on the agent's state the action will have (e.g., turning), as well as the terms used for issuing these commands (the grammar).</p>
<p>For calculating the agent's orientation, We extended TextWorld to keep track of the history of the agent's positions. Tracking the agent's orientation enables to use of relative movement actions and translates them to cardinal or even the more nuanced eight inter-cardinal (aka ordinal) directions. We define relative direction RD as the deviation between the direction in which the agent is currently oriented (looking) and the desired movement direction. Specifically, RD is calculated based on the agent's orientation AO and the direction of the next room D N (Equation 1). Thus, a direction is expressed internally in TextWorld as an integer number 0-7, starting from North, counterclockwise (Figure 7).
RD = (AO − D N ) mod 8(1)
Constant tracking of AO is handled by the TextWorld engine (that, as shown in Figure 5, by obtaining information from both the agent and the designed game, generates a description for possible actions in each state for the agent) externally from the agent and enables interactions through egocentric navigation commands included in the grammar of actions. The implementation of egocentric navigation commands using the TextWorld engine corresponds to the TextWorld design since, currently, the agents cannot track their trajectories. For example, if the agent is currently looking North (N, AO = 0) and communicates with the environment by the go sharp left command, the agent will enter the room Southwest (SW) of the current Understand "Area 0 in Room 0" as a0r0.</p>
<p>room. Details for all possible agent orientations and egocentric navigation commands are illustrated in Figure 8, including the two turn qualifiers, slight and sharp.  Table 3. The interaction for the example above would be Understand "veer right" as going slight right.</p>
<p>Demonstration</p>
<p>We have implemented the proposed workflow to a simple grid floorplan as well as a real-world indoor floor plan (Figure 9). The floorplan, templates, and concepts are integrated in a TextWorld generator program using a Python conversion tool, importing GeoJSON geometries. This GeoJSON represents the floorplan through three separate files, containing simple 2D geometries that capture rooms as closed polygons, doors as points along the edge where two polygons touch, and landmarks as points within these polygons. This is a structure equivalent to the IMDF format (which can capture further, more complex information). The conversion from IMDF or IFC to our model is not covered in this paper.</p>
<p>In this demonstration, the floorplan data of a real-world indoor environment are represented through 10 polygon geometries representing rooms of the environment, 13 point geometries of doors, and 6 point geometries of landmarks.</p>
<p>The ID of features are assigned randomly while the features' description attributes are assigned based on their corresponding role in the environment. Landmarks include ordinary objects and signs showing the agent guiding text. For example, a sign in Room 8 in Figure 9 guides the agent with a Exit is in this room! description. Then, the quest is defined with parameters incl. starting location, destination (winning location), and the maximum number of allowed interactions.</p>
<p>Users can navigate the rooms and areas using the extended TextWorld commands, including egocentric agent orientation. As shown in Table 4, the descriptions of the current state of the agent and the movement options to the immediate next states are provided to the player and agent. Descriptions may contain quest instructions that suggest the agent choose particular actions. For example, when the agent visits Room 3 in Table 4, TextWorld will guide the agent by a Move toward the east! description that is derived from a sign landmark.</p>
<p>Instruction may be about the immediate action or final goal. For example, in In the implemented experiment, the agent starts in Room 1, IndoorArea1, which is shown by the point close to Pear landmark in Figure 9. The desired destination for the agent is Room 8. The agent can explore and receive information about the consequences of immediate actions (e.g., enter the r9 by going south) or the desired destination (e.g., Exit is in this room!). Agents can choose navigation actions based on the understanding capabilities of the text-based game environment. The examples shown in Table 4 contain allocentric and egocentric navigation instructions. This provides more options for the agent to choose actions in each state (IndoorArea).</p>
<p>Agents can interact with landmarks in several ways, such as by opening a box with a open the wooden box command, adding a keychain to the inventory with a take the red key command, and wearing cloth by wear the jacket on the table command. As shown in Table 4, some landmarks can be visible but are too distant to be manipulated by the agent at some IndoorAreas -these are so-called intractable landmarks. To interact with them, agents must navigate to the same IndoorArea of distant landmarks.</p>
<p>It is possible to extend the aliases of the actions in TextWorld so that the agent can communicate with TextWorld by using different commands, i.e., different commands will apply to the same actions. We can use alias understanding templates introduced in Table 3 to extend concept aliases (such as understand "Area 1 in Room 2" as a1r2) that is applicable for translating human-understandable descriptions to TextWorld variables. Moreover, alias understanding templates can also be applied to actions (such as Understand the command "access" as "open"). The TextWorld aliasing feature helps to introduce synonyms, map commands entered by the agent to actions, or recognize landmarks by their properties (such as</p>
<p>Understand the yellow landmark as bannana).</p>
<p>The presented work is a novel approach for generating text-based games from real-world indoor environments. By leveraging GeoJSON geometries and extending the TextWorld platform, the proposed workflow enables the generation of games with multiple rooms, doors, and landmarks. The demonstration of the proposed approach on real-world indoor floorplans highlights the potential for its application in domains such as route instruction following. The use of aliases to extend the understanding of concepts and actions further enhances the adaptability of the generated games, allowing for more natural and intuitive interactions. To wrap it up, the proposed workflow and its implementation hold promise for the development of interactive text-based games from real-world environments, opening up new possibilities for text-based agent navigation applications.</p>
<p>Data and Software Availability</p>
<p>The Geojson data of indoor environments and codes used in this paper are available from the URL: https://github. com/tomko-lab/Geometry_to_TextWorld. We have used scikit-geometry, scipy.spatial, shapely, and geojson Pyhton libraries for geometric calculations and the TextWorld library for description generation.</p>
<p>Conclusions and Future Work</p>
<p>In this paper, we have introduced the capabilities of textbased game environments for spatial research, particularly for simulating real-world indoor spaces and interactions in these spaces. After reviewing the challenges of capturing spatial complexities in text-based games, we defined a small set of new abstract concepts based on wayfinding image schemata. We then describe how spatial data from geometric floorplans can be mapped into abstract concepts in text-based games.</p>
<p>We further introduce egocentric agent navigation in TextWorld using relative direction commands. A new grammar is added to the TextWorld engine based on extended navigation concepts to enrich agent interaction modalities.</p>
<p>We demonstrate how this approach enables to import and navigate an indoor space floorplan in TextWorld based on an automatic import procedure. We demonstrate this capability on both real-world and made-up floorplans.</p>
<p>In this paper we did not address the impact of different skeletonization methods like MAT and SMAT on floorplan modeling. Additionally, to make the process fully automated, the input must be in a well-known format, reminiscent of IMDF. In future work, we will address the ability to fully automatically import valid IMDF environments.</p>
<p>In future work, we will focus on the agent-environment interaction aspect of text-based games, as a target environ- Table 4. Sample agent navigation in TextWorld using the extended egocentric grammar.</p>
<blockquote>
<p>go forward</p>
</blockquote>
<p>Room 3 An area (2) in r3</p>
<p>Move toward the East! You can continue in Room 3 by going north (on the left) You can continue in Room 3 by going south (on the right) You can continue in Room 3 by going east (at the front) You can continue in Room 3 by going west (at the back) Landmark 5 is visible from here, but too far! You can move in this room to examine or access it 5 minutes have passed, decide well in your future actions, you have limited time (10 minutes)</p>
<p>ment for assessing route instruction following capabilities based on deterministic (rule-based) and learning agents navigating in both simulated and real-world environments.</p>
<p>There, we will also explore the Inform7 concept of Person to model agent affordances. Text-based games provide a flexible and extensible base for novel approaches to spatial language understanding, instruction generation, instruction following, and complex space simulation (e.g., integration of indoor and outdoor spaces).</p>
<p>Figure 1 .
1Examples of user interaction with a text-based game: (a) Opening scene of Zork, a classic text adventure game. (b) illustration of how players can observe the environment and navigate among rooms using only text-based commands, as the game provides no graphical interface.</p>
<p>Figure 2 .
2Inform7 object tree</p>
<p>Figure 3 .
3Graphs for modeling indoor spaces. (a) Floorplan containing geometric information of rooms and doors, (b) Structure graph containing coordinates of points of doors and polygons of rooms, (c) Dual graph in which nodes correspond to rooms and edges signify rooms adjacency, (d) Accessibility graph in which nodes correspond to rooms and edges signify doors or gates between adjacent rooms, (e) Navigation graph in which nodes correspond to both rooms and doors and edges represent connectivity relationship, (f) Skeleton graph in which nodes represent intersections and edges correspond to locus equidistant to two points in the boundary.</p>
<p>Figure 4 .- 2023 Figure 5 .Figure 6 .
4202356UML of defined concepts and their relation with schematic geometry and text-based games concepts.AGILE: GIScience Series, 4, 2, 2023 | https://doi.org/10.5194/agile-giss-4-2Extended structure of TextWorld, adopted from(Côté et al., 2018) Proposed workflow for automatic text-based games description generation from floorplan AGILE: GIScience Series, 4, 2, 2023 | https://doi.org/10.5194/agile-giss-4-2-2023</p>
<p>Figure 7 .
7Assigned numbers to cardinal and ordinal directions: N=North, W=West, E=East, S=South, SE=Southeast, SW=Southwest, NE=Northeast, NW=NorthwestThe complementary interaction enhancement of the actions proposed here is the definition of extensions to the grammar supporting the actions related to directions. For example, when new actions such as go slight right are defined for navigation, the environment must include the corresponding instructions, such as veer right or turn slight right. To introduce a new grammar component to the TextWorld knowledge base, we use the template alias understanding from</p>
<p>Figure 8 .Figure 9 .
89Conversion of allocentric reference frame into egocentric using agent orientation AO and next room direction, AO -Agent Orientation, F -Front, B -Back, R -Right, L -Left, Sh -Sharp, S -Slight Sample floorplan of the indoor space implemented in TextWorld based on extended concepts and templates. The numbers are the labels of the rooms. Derived from MAT skeleton, nodes are IndoorAreas. Green landmarks are navigational signage that guides the agent to find the destination. The agent cannot interact with signage landmarks but can pick up other landmarks, such as Apple.</p>
<p>Table 1 .
1concept of space based on wayfinding (Rüetschi and Timpf, 2004) </p>
<p>element 
definition 
example 
room 
enterable and bounded container 
kitchen, hallway 
region 
bounded area or surface affording support 
3rd floor, shopping area 
collection spatially or functionally similar things 
train station 
gateway 
a walk-able link that is consciously experienced door 
ulink 
unconscious link 
open kitchen 
item 
objects that does not fit to other concepts 
landmarks </p>
<p>Table 2 .
2An example of newly defined concepts in actionFloorplan and Decomposed Floorplan 
Concepts 
World definition </p>
<p>Table 3 .
3Templates and examples for the automatic generation of concepts, instances, relationships, and actions in text-based gamesDefinition 
Template 
Example 
general concept 
{concept} is a kind of {type}. 
area is a kind of room. 
properties of con-
cepts </p>
<p>{concept} has a {type} called { 
variable}. </p>
<p>area has a text called 
description. 
area has a indoor_room called 
parent. 
affordances of con-
cepts </p>
<p>{concept} can be {ability}. 
area can be enterable. </p>
<p>instances of con-
cepts </p>
<p>{instance} is a {concept}. "{ 
description}". </p>
<p>a0r0 is a area."An area (0) in 
[parent]". 
properties of in-
stances </p>
<p>the {property} of {instance} is 
{value}. 
the parent of the a0r0 is r0. </p>
<p>connectivity rela-
tionship between 
instances </p>
<p>{relation} of {area1} is { 
reverse_relation} of {area2 
}. </p>
<p>north of a0r1 is south of a1r1. </p>
<p>alias understanding 
Understand "{reference}" as { 
variable}. </p>
<p>Table 4 ,
4lines that explain possible actions and their immediate results, such as You can continue in However, Move toward the east! or Exit is in this room! are about the final goal of the designed quest.the Room 3 by going north 
(on the left) 
for 
moving 
within 
a 
room 
or 
(first opening Door 12) 
You can enter the Room 9 by going south 
(on the right) 
for 
moving 
between 
the 
rooms. 
www.twinery.org 2 www.tads.org
AGILE: GIScience Series, 4, 2, 2023 | https://doi.org/10.5194/agile-giss-4-2-2023
www.opengis.net/doc/IS/CityGML-1/3.0 4 www.indoorgml.net 5 https://apple.com/indoor</p>
<p>Learning dynamic belief graphs to generalize on text-based games. A Adhikari, X Yuan, M.-A Côté, M Zelinka, M.-A Rondeau, R Laroche, P Poupart, J Tang, A Trischler, Hamilton , W , Advances in Neural Information Processing Systems. 33Adhikari, A., Yuan, X., Côté, M.-A., Zelinka, M., Rondeau, M.- A., Laroche, R., Poupart, P., Tang, J., Trischler, A., and Hamil- ton, W.: Learning dynamic belief graphs to generalize on text-based games, Advances in Neural Information Process- ing Systems, 33, 3045-3057, 2020.</p>
<p>Spatial models for context-aware indoor navigation systems: A survey. I Afyouni, C Ray, C Claramunt, Journal of Spatial Information Science. 1Afyouni, I., Ray, C., and Claramunt, C.: Spatial models for context-aware indoor navigation systems: A survey, Journal of Spatial Information Science, 1, 85-123, 2012.</p>
<p>The inform 7 handbook, www.musicwords.net/if. J Aikin, Aikin, J.: The inform 7 handbook, www.musicwords.net/if, 2009.</p>
<p>Graph Constrained Reinforcement Learning for Natural Language Action Spaces. P Ammanabrolu, M Hausknecht, International Conference on Learning Representations. Ammanabrolu, P. and Hausknecht, M.: Graph Constrained Rein- forcement Learning for Natural Language Action Spaces, in: International Conference on Learning Representations, 2020.</p>
<p>Textworld: A learning environment for text-based games. M.-A Côté, A Kádár, X Yuan, B Kybartas, T Barnes, E Fine, J Moore, M Hausknecht, L E Asri, M Adada, Workshop on Computer Games. SpringerCôté, M.-A., Kádár, A., Yuan, X., Kybartas, B., Barnes, T., Fine, E., Moore, J., Hausknecht, M., Asri, L. E., Adada, M., et al.: Textworld: A learning environment for text-based games, in: Workshop on Computer Games, pp. 41-75, Springer, 2018.</p>
<p>Pragmatic information content-how to measure the information in a route, Foundations of Geographic Information Science. A U Frank, 47Frank, A. U.: Pragmatic information content-how to measure the information in a route, Foundations of Geographic Infor- mation Science, p. 47, 2003.</p>
<p>Formal specification of image schemata-a step towards interoperability in geographic information systems. A U Frank, M Raubal, Spatial Cognition and Computation. 1Frank, A. U. and Raubal, M.: Formal specification of image schemata-a step towards interoperability in geographic infor- mation systems, Spatial Cognition and Computation, 1, 67- 101, 1999.</p>
<p>Interactive fiction games: A colossal adventure. M Hausknecht, P Ammanabrolu, M.-A Côté, X Yuan, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence34Hausknecht, M., Ammanabrolu, P., Côté, M.-A., and Yuan, X.: Interactive fiction games: A colossal adventure, in: Pro- ceedings of the AAAI Conference on Artificial Intelligence, vol. 34, pp. 7903-7910, 2020.</p>
<p>Image schema combinations and complex events. M M Hedblom, O Kutz, R Peñaloza, G Guizzardi, KI-Künstliche Intelligenz33Hedblom, M. M., Kutz, O., Peñaloza, R., and Guizzardi, G.: Im- age schema combinations and complex events, KI-Künstliche Intelligenz, 33, 279-291, 2019.</p>
<p>P A Jansen, arXiv:2107.04132A Systematic Survey of Text Worlds as Embodied Natural Language Environments. arXiv preprintJansen, P. A.: A Systematic Survey of Text Worlds as Embodied Natural Language Environments, arXiv preprint arXiv:2107.04132, 2021.</p>
<p>The body in the mind: The bodily basis of meaning, imagination, and reason. M Johnson, University of Chicago pressJohnson, M.: The body in the mind: The bodily basis of meaning, imagination, and reason, University of Chicago press, 2013.</p>
<p>Automatically extracting 3D models and network analysis for indoors. I R Karas, F Batuk, A E Akay, I Baz, Innovations in 3D Geo Information Systems. SpringerKaras, I. R., Batuk, F., Akay, A. E., and Baz, I.: Automatically extracting 3D models and network analysis for indoors, in: Innovations in 3D Geo Information Systems, pp. 395-404, Springer, 2006.</p>
<p>H A Karimi, Indoor wayfinding and navigation. CRC PressKarimi, H. A.: Indoor wayfinding and navigation, CRC Press, 2015.</p>
<p>The architecture and evolution of computer game engines. R Koirikivi, Pelimoottorit. jultika. oulu. fiKoirikivi, R.: The architecture and evolution of computer game engines, Pelimoottorit. jultika. oulu. fi, 2015.</p>
<p>E Kolve, R Mottaghi, W Han, E Vanderbilt, L Weihs, A Herrasti, D Gordon, Y Zhu, A Gupta, A Farhadi, arXiv:1712.05474AI2-THOR: An Interactive 3D Environment for Visual AI. arXiv preprintKolve, E., Mottaghi, R., Han, W., VanderBilt, E., Weihs, L., Her- rasti, A., Gordon, D., Zhu, Y., Gupta, A., and Farhadi, A.: AI2- THOR: An Interactive 3D Environment for Visual AI, arXiv preprint arXiv:1712.05474, 2017.</p>
<p>An image-schematic account of spatial categories. W Kuhn, International Conference on Spatial Information Theory. SpringerKuhn, W.: An image-schematic account of spatial categories, in: International Conference on Spatial Information Theory, pp. 152-168, Springer, 2007.</p>
<p>Simultaneous storage of primal and dual three-dimensional subdivisions, Computers, Environment and Urban Systems. H Ledoux, C M Gold, 31Ledoux, H. and Gold, C. M.: Simultaneous storage of primal and dual three-dimensional subdivisions, Computers, Envi- ronment and Urban Systems, 31, 393-408, 2007.</p>
<p>Medial axis transformation of a planar shape. D.-T Lee, IEEE Transactions on Pattern Analysis and Machine Intelligence. 4Lee, D.-T.: Medial axis transformation of a planar shape, IEEE Transactions on Pattern Analysis and Machine Intelligence, 4, 363-369, 1982.</p>
<p>A spatial access-oriented implementation of a 3-D GIS topological data model for urban entities. J Lee, GeoInformatica. 8Lee, J.: A spatial access-oriented implementation of a 3-D GIS topological data model for urban entities, GeoInformatica, 8, 237-264, 2004.</p>
<p>A combinatorial data model for representing topological relations among 3D geographical features in micro-spatial environments. J Lee, M.-P Kwan, K Lynch, International Journal of Geographical Information Science. 19MIT pressThe image of the cityLee, J. and Kwan, M.-P.: A combinatorial data model for repre- senting topological relations among 3D geographical features in micro-spatial environments, International Journal of Geo- graphical Information Science, 19, 1039-1056, 2005. Lynch, K.: The image of the city, MIT press, 1964.</p>
<p>Street network studies: from networks to models and their representations, Networks and Spatial Economics. S Marshall, J Gil, K Kropf, M Tomko, L Figueiredo, 10.1007/s11067-018-9427-9Marshall, S., Gil, J., Kropf, K., Tomko, M., and Figueiredo, L.: Street network studies: from networks to models and their rep- resentations, Networks and Spatial Economics, pp. 735-749, https://doi.org/10.1007/s11067-018-9427-9, 2018.</p>
<p>Ceptre: A language for modeling generative interactive systems. C Martens, 10.1007/s11067-018-9427-9Eleventh Artificial Intelligence and Interactive Digital Entertainment Conference. Martens, C.: Ceptre: A language for modeling generative inter- active systems, in: Eleventh Artificial Intelligence and Inter- active Digital Entertainment Conference, 2015.</p>
<p>An indoor navigation model and its network extraction. F Mortari, E Clementini, S Zlatanova, L Liu, Applied Geomatics. 11Mortari, F., Clementini, E., Zlatanova, S., and Liu, L.: An indoor navigation model and its network extraction, Applied Geomat- ics, 11, 413-427, 2019.</p>
<p>Natural language, semantic analysis, and interactive fiction. G Nelson, IF Theory Reader. 141Nelson, G.: Natural language, semantic analysis, and interactive fiction, IF Theory Reader, 141, 99-104, 2006.</p>
<p>Afterword: Five years later, IF Theory Reader. G Nelson, 189Nelson, G.: Afterword: Five years later, IF Theory Reader, p. 189, 2011.</p>
<p>The z-machine standards document. G Nelson, Nelson, G. et al.: The z-machine standards document, Version, 1, 22, 1997.</p>
<p>Motor and representational framing of space, Brain and Space. J Paillard, Paillard, J.: Motor and representational framing of space, Brain and Space, pp. 163-182, 1991.</p>
<p>Structuring space with image schemata: Wayfinding in airports as a case study. M Raubal, M J Egenhofer, D Pfoser, N Tryfona, International Conference on Spatial Information Theory. SpringerRaubal, M., Egenhofer, M. J., Pfoser, D., and Tryfona, N.: Struc- turing space with image schemata: Wayfinding in airports as a case study, in: International Conference on Spatial Informa- tion Theory, pp. 85-102, Springer, 1997.</p>
<p>Turning a graph into a rectangular floor plan. J Roth, R Hashimshony, A Wachman, Building and Environment. 17Roth, J., Hashimshony, R., and Wachman, A.: Turning a graph into a rectangular floor plan, Building and Environment, 17, 163-173, 1982.</p>
<p>Wayfinding in scene space: Modelling transfers in public transport. U.-J Rüetschi, University of ZurichPh.D. thesisRüetschi, U.-J.: Wayfinding in scene space: Modelling transfers in public transport, Ph.D. thesis, University of Zurich, 2007.</p>
<p>Schematic geometry of public transport spaces for wayfinding, Geoinformation und Mobilität. U.-J Rüetschi, S Timpf, 40Rüetschi, U.-J. and Timpf, S.: Schematic geometry of public transport spaces for wayfinding, Geoinformation und Mobil- ität, 40, 191-203, 2004.</p>
<p>Route directions generation using visible landmarks. D Russo, S Zlatanova, E Clementini, Proceedings of the sixth ACM SIGSPATIAL international workshop on indoor spatial awareness. the sixth ACM SIGSPATIAL international workshop on indoor spatial awarenessRusso, D., Zlatanova, S., and Clementini, E.: Route directions generation using visible landmarks, in: Proceedings of the sixth ACM SIGSPATIAL international workshop on indoor spatial awareness, pp. 1-8, 2014.</p>
<p>Describing the functional spatial structure of urban environments, Computers, Environment and Urban Systems. M Tomko, S Winter, 41Tomko, M. and Winter, S.: Describing the functional spatial structure of urban environments, Computers, Environment and Urban Systems, 41, 177-187, 2013.</p>
<p>M Tuli, A C Li, P Vaezipoor, T Q Klassen, S Sanner, S A Mcilraith, The Third Wordplay: When Language Meets Games Workshop. Instruction Following in Text-Based GamesTuli, M., Li, A. C., Vaezipoor, P., Klassen, T. Q., Sanner, S., and McIlraith, S. A.: Instruction Following in Text-Based Games, in: The Third Wordplay: When Language Meets Games Work- shop, 2022.</p>
<p>Generation of navigation graphs for indoor space. L Yang, M Worboys, International Journal of Geographical Information Science. 29Yang, L. and Worboys, M.: Generation of navigation graphs for indoor space, International Journal of Geographical Informa- tion Science, 29, 1737-1756, 2015.</p>
<p>HiVG: A hierarchical indoor visibility-based graph for navigation guidance in multi-storey buildings. Z Zhou, R Weibel, K.-F Richter, H Huang, Computers, Environment and Urban Systems. 93Zhou, Z., Weibel, R., Richter, K.-F., and Huang, H.: HiVG: A hierarchical indoor visibility-based graph for navigation guid- ance in multi-storey buildings, Computers, Environment and Urban Systems, 93, 101 751, 2022.</p>            </div>
        </div>

    </div>
</body>
</html>