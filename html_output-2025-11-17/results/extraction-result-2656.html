<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2656 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2656</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2656</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-68.html">extraction-schema-68</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <p><strong>Paper ID:</strong> paper-6c5c6f883604a3abaa829b83d2958de8c343beeb</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/6c5c6f883604a3abaa829b83d2958de8c343beeb" target="_blank">A Computational Inflection for Scientific Discovery</a></p>
                <p><strong>Paper Venue:</strong> Communications of the ACM</p>
                <p><strong>Paper TL;DR:</strong> Enabling researchers to leverage systems to overcome the limits of human cognitive capacity is a central challenge in the next generation of artificial intelligence.</p>
                <p><strong>Paper Abstract:</strong> Enabling researchers to leverage systems to overcome the limits of human cognitive capacity.</p>
                <p><strong>Cost:</strong> 0.02</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2656.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2656.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Bridger</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Bridger: Novel Author Discovery System</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An author-matching retrieval system that recommends unfamiliar but relevant researchers to stimulate new research directions by extracting problems and methods from a user's papers and matching to authors with contrasting methods.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Bridger: Toward bursting scientific filter bubbles and boosting innovation via novel author discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Bridger</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Bridger represents a user's inner knowledge by extracting mentions of problems and methods from the user's papers and weighting them by term frequency. It represents outer knowledge as other authors' extracted problems/methods. It matches authors by measuring relevance combined with novelty (contrast in methods) and presents ranked author 'cards' showing salient problems, methods and papers to inspire directions. Key components: NLP extraction of problems/methods, term-frequency weighting for user profile, author similarity/contrast matching, faceted presentation UI.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>retrieval-augmented / author-recommendation (analogy-inspired retrieval)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>general/computer science (human-centered AI use cases reported)</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Generates research directions by surfacing authors who are relevant to the user's problems but employ different methods â€” analogical/contrastive retrieval driven by NLP-extracted problem and method facets.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td>Implicit novelty via contrast in extracted methods and presentation of unfamiliar authors; evaluated in user studies by human judgments of novelty (no formal novelty metric reported).</td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td>Balances relevance to user's extracted problem profile with novelty by explicitly scoring matches that are relevant yet methodologically different; details of scoring formula not provided.</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Human-subject studies with computer science researchers measuring creative search and usefulness compared to baseline neural search; qualitative examples of useful cross-domain inspirations.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>User studies reported 'dramatically boosted creative search and inspiration' relative to state-of-the-art neural models used by Semantic Scholar; no numeric accuracy/precision metrics provided in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>Outperformed state-of-the-art neural models (Semantic Scholar) in user studies for creative inspiration; specific quantitative comparisons not detailed here.</td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Relies on rough proxies of inner knowledge (papers/term frequencies); challenges in representation, controlling for user preferences, and generalization across domains were noted.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Computational Inflection for Scientific Discovery', 'publication_date_yy_mm': '2022-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2656.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2656.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Solvent</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Solvent: Mixed-Initiative Analogy-Finding System</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A mixed-initiative system that finds analogies by retrieving inventions/papers with partially similar mechanistic structure to a user-provided description, aimed at stimulating creative solution generation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Solvent: A mixed initiative system for finding analogies between research papers.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Solvent</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Solvent allows a user to provide a textual description of an invention/problem and retrieves candidate inspirations from a database of technological inventions by computing partial structural similarity (mechanism-level matching). Components include mechanism extraction from texts, structural similarity retrieval, and a mixed-initiative UI where users inspect and adapt retrieved analogies.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>analogy-mining / retrieval-augmented</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>engineering / technological invention domains (biomechanical engineering example reported)</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Generates candidate solution ideas by retrieving structurally analogous inventions/papers (mechanism-level analogical matches) that users can adapt into hypotheses/solutions.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Human ideation experiments: participants produced more creative ideas after viewing Solvent-retrieved inspirations vs. baseline retrieval methods; examples of practitioners finding useful analogies reported.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Significant boosts in human creativity measures in ideation experiments compared to baseline retrieval; no specific numeric metrics provided in this paper excerpt.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>Outperformed baseline information retrieval methods in human creativity/ideation studies.</td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Extraction accuracy and generalization of mechanistic representations are challenges; system depends on quality of mechanism extraction and structural matching.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Computational Inflection for Scientific Discovery', 'publication_date_yy_mm': '2022-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2656.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2656.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SearchEngine-Challenges</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Search engine for discovery of scientific challenges and directions</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A retrieval system designed to find statements of uncertainty, open questions and hypotheses in the literature to guide researchers' attention to under-explored or uncertain areas.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>A search engine for discovery of scientific challenges and directions.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Search engine for discovery of scientific challenges and directions</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>This prototype search engine indexes literature to retrieve expressions of difficulties, uncertainties and hypotheses (statements of open questions) rather than typical relevance-focused results. It uses NLP to identify sentences/contexts that express uncertainty or open problems and ranks them for the user's query topic.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>uncertainty-focused retrieval / NLP-based search</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>biomedical (example: ACE2 and COVID-19) and general scientific literature</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Surfaces existing hypotheses and open questions from literature as seeds for new hypothesis formation.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>User studies with diverse researchers (including medical doctors) comparing discovery of challenges/directions against PubMed; qualitative examples given (e.g., ACE2-liver damage hypothesis surfaced).</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td>Explicit retrieval of textual statements that express uncertainty/open questions (textual signaling used as proxy for uncertainty); no probabilistic UQ reported.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Reported to 'dramatically outperform PubMed search' at discovering important/interesting areas of challenges and directions for given query topics; no numeric metrics provided in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>Compared against PubMed; prototype surfaced more uncertainties/open questions relevant to queries.</td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Relies on accurate detection of linguistic markers of uncertainty; scope limited by access to literature and extraction accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Computational Inflection for Scientific Discovery', 'publication_date_yy_mm': '2022-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2656.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2656.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BEEP</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Biomedical Evidence Enhanced Prediction (BEEP)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A retrieval-augmented predictive system that improves clinical outcome prediction for ICU patients by retrieving and synthesizing relevant medical papers together with EMR data.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Literature-augmented clinical outcome prediction.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>BEEP</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>BEEP retrieves medical papers relevant to each ICU patient using queries extracted from internal clinical notes, then synthesizes retrieved literature with EMR features to produce predictions (e.g., in-hospital mortality, prolonged length of stay). Components: patient-specific retrieval module, synthesis module combining literature-derived signals with EMR-based predictive model.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>retrieval-augmented predictive model</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>medicine / clinical outcomes (ICU prediction)</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Not primarily a hypothesis-generator; uses literature retrieval to augment predictions and to align model outputs with clinical evidence (can surface evidence supporting predictions).</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Aligns outputs with evidence by matching patient aspects to related cohorts in papers to increase interpretability/plausibility; detailed scoring not provided.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Empirical evaluation on clinical prediction tasks showing substantial improvements over state-of-the-art models that omit literature retrieval; evaluation used held-out clinical data (exact numeric results not included in this paper excerpt).</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Reported 'large improvements' over state-of-the-art models without retrieval on ICU outcome prediction tasks; no specific metrics (e.g., AUC) provided in this summary.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>Improved over state-of-the-art non-retrieval models in empirical evaluations (specific numbers not provided in this paper).</td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Dependency on retrieval quality and alignment between EMR queries and literature; details of extraction and synthesis quality affect performance.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Computational Inflection for Scientific Discovery', 'publication_date_yy_mm': '2022-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2656.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2656.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Generative Pre-trained Transformer 4</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A large multimodal transformer-based language model (OpenAI GPT-4) reported to demonstrate advanced capabilities in reasoning, coding, and domain tasks, and that can assist with hypothesis formulation and critique.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Sparks of artificial general intelligence: Early experiments with GPT-4.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>GPT-4 (LLM)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>GPT-4 is a large pre-trained transformer language model capable of interpreting and generating complex texts and code; the paper reports early experiments showing GPT-4's abilities to formulate hypotheses, recommend research directions, and critique studies when combined with training and retrieval over scientific corpora.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>LLM-based</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>general / cross-domain (medical examples reported)</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Generative natural-language hypothesis formulation using model compositionality and relational reasoning; can be augmented with retrieval (retrieval-augmented LLM workflow) to ground outputs in literature.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Early experiments (informal) reported for tasks like formulating hypotheses and critiquing studies; no systematic experimental validation or metrics provided in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Described qualitatively as exhibiting 'promising abilities' in formulating hypotheses, recommending directions and critiquing studies; no numeric performance values provided in this paper excerpt.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Representations learned by LLMs lack interpretability and control hooks; extraction/grounding errors and hallucinations remain concerns; grounding with retrieval and structured representations needed.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Computational Inflection for Scientific Discovery', 'publication_date_yy_mm': '2022-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2656.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e2656.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Robot Scientist</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Robot Scientist (King et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An automated laboratory system that formulates empirical hypotheses from data and closes the loop by executing experiments in the lab to test them (functional genomic hypothesis generation and experimentation).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Functional genomic hypothesis generation and experimentation by a robot scientist.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Robot Scientist (robotic automation for scientific discovery)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Robot Scientist systems combine curated background knowledge (e.g., gene regulatory networks), automated hypothesis-generation algorithms inspired by cognitive models, and robotic lab automation to select, run and analyze experiments; the loop includes hypothesis formation, experiment execution, and updating knowledge bases.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>robotic-automation + ML (closed-loop experimental automation)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>biology / functional genomics</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Algorithmic hypothesis generation from data and structured background knowledge (computational discovery techniques inspired by symbolic/inductive methods), followed by automated experiment scheduling.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Experimental validation in wet lab: the system runs experiments to test generated hypotheses and updates models accordingly (as described in referenced work).</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td>Referenced work reports automated generation and experimental testing of functional genomic hypotheses; specifics are in the cited paper.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Typically limited to narrow curated domains where background knowledge and robotic protocols are available; scaling to broader open scientific domains is challenging.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Computational Inflection for Scientific Discovery', 'publication_date_yy_mm': '2022-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2656.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e2656.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PPI Debiasing / Prioritization</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Methods for debiasing attention and reprioritizing protein-protein interaction (PPI) discovery</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Analytical methods that detect a 'bias of locality' in historical PPI discovery and propose reprioritization mechanisms to surface understudied candidate PPIs that could have been discovered earlier.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>On biases of attention in scientific discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>PPI attention-bias analysis and reprioritization methods</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>This line of work constructs a temporal graph of confirmed PPIs and analyzes growth patterns to identify locality-driven attention bias; it then uses protein properties and graph-based reprioritization heuristics to rank candidate PPIs that are under-explored, demonstrating retrospective cases where earlier discovery would have been possible.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>graph-analysis / prioritization (data-driven prioritization)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>biology / protein-protein interactions</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Generates hypotheses by reprioritizing candidate PPIs (edges) that are under-attended given protein properties and graph locality features; these ranked candidates serve as testable hypotheses.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td>Novelty inferred via lower historical attention/locality; no formal novelty metric reported beyond analyses of historical discovery timing.</td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Plausibility assessed via features of proteins and retrospective analysis showing that higher-ranked candidates correspond to eventual confirmations under different prioritization.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Temporal retrospective analysis showing that reprioritization could have led to earlier discoveries; demonstration of improved candidate rankings using protein properties.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td>Historical PPI databases (growing graph of confirmed PPIs over decades) as used in the study</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Temporal analyses revealed a measurable 'bias of locality' and demonstrated mechanisms for reprioritizing candidate PPIs that could have enabled earlier discoveries; no single numeric accuracy metric provided in this summary.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>Shown to change prioritization relative to historical discovery order; retrospective evidence suggests earlier discovery under new prioritization.</td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Locality bias reflects understandable scientific focus; translating reprioritizations into practice requires incentives and experimental follow-up; dependency on available PPI data and feature engineering.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Computational Inflection for Scientific Discovery', 'publication_date_yy_mm': '2022-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2656.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e2656.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Accord</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Accord: Multi-document Concept Description Generator</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A multi-document system that generates diverse, grounded descriptions of scientific concepts by retrieving explanations that relate target concepts to source concepts familiar to the user and rewriting them in a structured template.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Accord: A multi-document approach to generating diverse descriptions of scientific concepts.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Accord</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Accord takes as input a list of source concepts representing a user's known concepts (from papers they wrote or read), retrieves definitions of a target concept from multiple scientific papers where the target is explained in terms of the source concepts, and uses a neural text-generation model to rewrite and structure the explanations tailored to the user's knowledge.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>multi-document retrieval + neural text generation</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>general scientific literature / concept explanation</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Not designed to generate hypotheses; supports learning and understanding by grounding new concepts in user's known concepts which can indirectly aid hypothesis formation.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Grounding in retrieved literature aims to increase plausibility of generated explanations; explicit plausibility scoring not reported.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Evaluations reported in EMNLP paper (reference) for quality and diversity of generated descriptions; user-aligned grounding tested.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td>Grounding generated descriptions in retrieved multi-document evidence to reduce free-form hallucination; specifics not detailed here.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Reported generation of diverse, user-grounded definitions in EMNLP evaluation; no numeric rates provided in this summary.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Quality depends on retrieval accuracy and generation model; grounding reduces but does not eliminate risk of unsupported wording.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Computational Inflection for Scientific Discovery', 'publication_date_yy_mm': '2022-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2656.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e2656.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Scisight</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Scisight: Exploratory Scientific Search</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An exploratory scientific search system combining faceted navigation and research group detection to support exploration of COVID-19 literature and discovery of perspectives and groups.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Scisight: Combining faceted navigation and research group detection for covid-19 exploratory scientific search.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Scisight</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Scisight provides faceted navigation and research group detection over COVID-19 literature to aid exploratory search and surface cross-cutting perspectives and research communities; it is a prototype for augmenting attention and literature review.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>exploratory search / faceted retrieval</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>biomedical / COVID-19 literature</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Supports ideation by surfacing diverse papers, facets and groups rather than directly generating hypotheses.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Described as a prototype for exploratory search; evaluation details are in cited EMNLP work.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Focused on exploratory navigation; not a hypothesis-generation/validation engine per se.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Computational Inflection for Scientific Discovery', 'publication_date_yy_mm': '2022-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2656.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e2656.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AlphaFold</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>AlphaFold (DeepMind)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A deep learning system that predicts protein 3D structures from amino-acid sequences with high accuracy, revolutionizing structural biology and serving as an example of AI-driven scientific prediction.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Highly accurate protein structure prediction with alphafold.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>AlphaFold</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>AlphaFold is a deep neural network architecture trained to predict atomic-level protein structures from sequence inputs, combining attention-based architectures, evolutionary information and structural priors to achieve high-accuracy predictions.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>deep learning / structure prediction</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>biology / structural biology</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Produces structural predictions (testable scientific predictions) from sequence data; not framed as hypothesis generator for experimental design in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Validated extensively against known structures and community benchmarks (CASP); described here as an example of ML enabling scientific discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Validated against experimentally determined protein structures (e.g., CASP benchmarks in the cited Nature paper).</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Reported highly accurate structure predictions in Nature paper (see citation) â€” specifics are in the AlphaFold publication.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Domain-specific success; not a general hypothesis-generation system for arbitrary scientific claims.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Computational Inflection for Scientific Discovery', 'publication_date_yy_mm': '2022-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Bridger: Toward bursting scientific filter bubbles and boosting innovation via novel author discovery. <em>(Rating: 2)</em></li>
                <li>Solvent: A mixed initiative system for finding analogies between research papers. <em>(Rating: 2)</em></li>
                <li>Functional genomic hypothesis generation and experimentation by a robot scientist. <em>(Rating: 2)</em></li>
                <li>Literature-augmented clinical outcome prediction. <em>(Rating: 2)</em></li>
                <li>A search engine for discovery of scientific challenges and directions. <em>(Rating: 2)</em></li>
                <li>On biases of attention in scientific discovery. <em>(Rating: 2)</em></li>
                <li>Accord: A multi-document approach to generating diverse descriptions of scientific concepts. <em>(Rating: 2)</em></li>
                <li>Sparks of artificial general intelligence: Early experiments with GPT-4. <em>(Rating: 2)</em></li>
                <li>Highly accurate protein structure prediction with alphafold. <em>(Rating: 1)</em></li>
                <li>Scisight: Combining faceted navigation and research group detection for covid-19 exploratory scientific search. <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2656",
    "paper_id": "paper-6c5c6f883604a3abaa829b83d2958de8c343beeb",
    "extraction_schema_id": "extraction-schema-68",
    "extracted_data": [
        {
            "name_short": "Bridger",
            "name_full": "Bridger: Novel Author Discovery System",
            "brief_description": "An author-matching retrieval system that recommends unfamiliar but relevant researchers to stimulate new research directions by extracting problems and methods from a user's papers and matching to authors with contrasting methods.",
            "citation_title": "Bridger: Toward bursting scientific filter bubbles and boosting innovation via novel author discovery.",
            "mention_or_use": "use",
            "system_name": "Bridger",
            "system_description": "Bridger represents a user's inner knowledge by extracting mentions of problems and methods from the user's papers and weighting them by term frequency. It represents outer knowledge as other authors' extracted problems/methods. It matches authors by measuring relevance combined with novelty (contrast in methods) and presents ranked author 'cards' showing salient problems, methods and papers to inspire directions. Key components: NLP extraction of problems/methods, term-frequency weighting for user profile, author similarity/contrast matching, faceted presentation UI.",
            "system_type": "retrieval-augmented / author-recommendation (analogy-inspired retrieval)",
            "scientific_domain": "general/computer science (human-centered AI use cases reported)",
            "hypothesis_generation_method": "Generates research directions by surfacing authors who are relevant to the user's problems but employ different methods â€” analogical/contrastive retrieval driven by NLP-extracted problem and method facets.",
            "novelty_assessment_method": "Implicit novelty via contrast in extracted methods and presentation of unfamiliar authors; evaluated in user studies by human judgments of novelty (no formal novelty metric reported).",
            "plausibility_assessment_method": null,
            "novelty_plausibility_balance": "Balances relevance to user's extracted problem profile with novelty by explicitly scoring matches that are relevant yet methodologically different; details of scoring formula not provided.",
            "hypothesis_quality_metrics": null,
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Human-subject studies with computer science researchers measuring creative search and usefulness compared to baseline neural search; qualitative examples of useful cross-domain inspirations.",
            "reproducibility_measures": null,
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": null,
            "benchmark_dataset": null,
            "performance_metrics": "User studies reported 'dramatically boosted creative search and inspiration' relative to state-of-the-art neural models used by Semantic Scholar; no numeric accuracy/precision metrics provided in this paper.",
            "comparison_with_baseline": "Outperformed state-of-the-art neural models (Semantic Scholar) in user studies for creative inspiration; specific quantitative comparisons not detailed here.",
            "validated_on_real_science": true,
            "novel_discoveries": null,
            "limitations": "Relies on rough proxies of inner knowledge (papers/term frequencies); challenges in representation, controlling for user preferences, and generalization across domains were noted.",
            "uuid": "e2656.0",
            "source_info": {
                "paper_title": "A Computational Inflection for Scientific Discovery",
                "publication_date_yy_mm": "2022-05"
            }
        },
        {
            "name_short": "Solvent",
            "name_full": "Solvent: Mixed-Initiative Analogy-Finding System",
            "brief_description": "A mixed-initiative system that finds analogies by retrieving inventions/papers with partially similar mechanistic structure to a user-provided description, aimed at stimulating creative solution generation.",
            "citation_title": "Solvent: A mixed initiative system for finding analogies between research papers.",
            "mention_or_use": "use",
            "system_name": "Solvent",
            "system_description": "Solvent allows a user to provide a textual description of an invention/problem and retrieves candidate inspirations from a database of technological inventions by computing partial structural similarity (mechanism-level matching). Components include mechanism extraction from texts, structural similarity retrieval, and a mixed-initiative UI where users inspect and adapt retrieved analogies.",
            "system_type": "analogy-mining / retrieval-augmented",
            "scientific_domain": "engineering / technological invention domains (biomechanical engineering example reported)",
            "hypothesis_generation_method": "Generates candidate solution ideas by retrieving structurally analogous inventions/papers (mechanism-level analogical matches) that users can adapt into hypotheses/solutions.",
            "novelty_assessment_method": null,
            "plausibility_assessment_method": null,
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": null,
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Human ideation experiments: participants produced more creative ideas after viewing Solvent-retrieved inspirations vs. baseline retrieval methods; examples of practitioners finding useful analogies reported.",
            "reproducibility_measures": null,
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": null,
            "benchmark_dataset": null,
            "performance_metrics": "Significant boosts in human creativity measures in ideation experiments compared to baseline retrieval; no specific numeric metrics provided in this paper excerpt.",
            "comparison_with_baseline": "Outperformed baseline information retrieval methods in human creativity/ideation studies.",
            "validated_on_real_science": true,
            "novel_discoveries": null,
            "limitations": "Extraction accuracy and generalization of mechanistic representations are challenges; system depends on quality of mechanism extraction and structural matching.",
            "uuid": "e2656.1",
            "source_info": {
                "paper_title": "A Computational Inflection for Scientific Discovery",
                "publication_date_yy_mm": "2022-05"
            }
        },
        {
            "name_short": "SearchEngine-Challenges",
            "name_full": "Search engine for discovery of scientific challenges and directions",
            "brief_description": "A retrieval system designed to find statements of uncertainty, open questions and hypotheses in the literature to guide researchers' attention to under-explored or uncertain areas.",
            "citation_title": "A search engine for discovery of scientific challenges and directions.",
            "mention_or_use": "use",
            "system_name": "Search engine for discovery of scientific challenges and directions",
            "system_description": "This prototype search engine indexes literature to retrieve expressions of difficulties, uncertainties and hypotheses (statements of open questions) rather than typical relevance-focused results. It uses NLP to identify sentences/contexts that express uncertainty or open problems and ranks them for the user's query topic.",
            "system_type": "uncertainty-focused retrieval / NLP-based search",
            "scientific_domain": "biomedical (example: ACE2 and COVID-19) and general scientific literature",
            "hypothesis_generation_method": "Surfaces existing hypotheses and open questions from literature as seeds for new hypothesis formation.",
            "novelty_assessment_method": null,
            "plausibility_assessment_method": null,
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": null,
            "pre_experiment_evaluation": true,
            "validation_mechanism": "User studies with diverse researchers (including medical doctors) comparing discovery of challenges/directions against PubMed; qualitative examples given (e.g., ACE2-liver damage hypothesis surfaced).",
            "reproducibility_measures": null,
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": "Explicit retrieval of textual statements that express uncertainty/open questions (textual signaling used as proxy for uncertainty); no probabilistic UQ reported.",
            "benchmark_dataset": null,
            "performance_metrics": "Reported to 'dramatically outperform PubMed search' at discovering important/interesting areas of challenges and directions for given query topics; no numeric metrics provided in this paper.",
            "comparison_with_baseline": "Compared against PubMed; prototype surfaced more uncertainties/open questions relevant to queries.",
            "validated_on_real_science": true,
            "novel_discoveries": null,
            "limitations": "Relies on accurate detection of linguistic markers of uncertainty; scope limited by access to literature and extraction accuracy.",
            "uuid": "e2656.2",
            "source_info": {
                "paper_title": "A Computational Inflection for Scientific Discovery",
                "publication_date_yy_mm": "2022-05"
            }
        },
        {
            "name_short": "BEEP",
            "name_full": "Biomedical Evidence Enhanced Prediction (BEEP)",
            "brief_description": "A retrieval-augmented predictive system that improves clinical outcome prediction for ICU patients by retrieving and synthesizing relevant medical papers together with EMR data.",
            "citation_title": "Literature-augmented clinical outcome prediction.",
            "mention_or_use": "use",
            "system_name": "BEEP",
            "system_description": "BEEP retrieves medical papers relevant to each ICU patient using queries extracted from internal clinical notes, then synthesizes retrieved literature with EMR features to produce predictions (e.g., in-hospital mortality, prolonged length of stay). Components: patient-specific retrieval module, synthesis module combining literature-derived signals with EMR-based predictive model.",
            "system_type": "retrieval-augmented predictive model",
            "scientific_domain": "medicine / clinical outcomes (ICU prediction)",
            "hypothesis_generation_method": "Not primarily a hypothesis-generator; uses literature retrieval to augment predictions and to align model outputs with clinical evidence (can surface evidence supporting predictions).",
            "novelty_assessment_method": null,
            "plausibility_assessment_method": "Aligns outputs with evidence by matching patient aspects to related cohorts in papers to increase interpretability/plausibility; detailed scoring not provided.",
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": null,
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Empirical evaluation on clinical prediction tasks showing substantial improvements over state-of-the-art models that omit literature retrieval; evaluation used held-out clinical data (exact numeric results not included in this paper excerpt).",
            "reproducibility_measures": null,
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": null,
            "benchmark_dataset": null,
            "performance_metrics": "Reported 'large improvements' over state-of-the-art models without retrieval on ICU outcome prediction tasks; no specific metrics (e.g., AUC) provided in this summary.",
            "comparison_with_baseline": "Improved over state-of-the-art non-retrieval models in empirical evaluations (specific numbers not provided in this paper).",
            "validated_on_real_science": true,
            "novel_discoveries": null,
            "limitations": "Dependency on retrieval quality and alignment between EMR queries and literature; details of extraction and synthesis quality affect performance.",
            "uuid": "e2656.3",
            "source_info": {
                "paper_title": "A Computational Inflection for Scientific Discovery",
                "publication_date_yy_mm": "2022-05"
            }
        },
        {
            "name_short": "GPT-4",
            "name_full": "Generative Pre-trained Transformer 4",
            "brief_description": "A large multimodal transformer-based language model (OpenAI GPT-4) reported to demonstrate advanced capabilities in reasoning, coding, and domain tasks, and that can assist with hypothesis formulation and critique.",
            "citation_title": "Sparks of artificial general intelligence: Early experiments with GPT-4.",
            "mention_or_use": "use",
            "system_name": "GPT-4 (LLM)",
            "system_description": "GPT-4 is a large pre-trained transformer language model capable of interpreting and generating complex texts and code; the paper reports early experiments showing GPT-4's abilities to formulate hypotheses, recommend research directions, and critique studies when combined with training and retrieval over scientific corpora.",
            "system_type": "LLM-based",
            "scientific_domain": "general / cross-domain (medical examples reported)",
            "hypothesis_generation_method": "Generative natural-language hypothesis formulation using model compositionality and relational reasoning; can be augmented with retrieval (retrieval-augmented LLM workflow) to ground outputs in literature.",
            "novelty_assessment_method": null,
            "plausibility_assessment_method": null,
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": null,
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Early experiments (informal) reported for tasks like formulating hypotheses and critiquing studies; no systematic experimental validation or metrics provided in this paper.",
            "reproducibility_measures": null,
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": null,
            "benchmark_dataset": null,
            "performance_metrics": "Described qualitatively as exhibiting 'promising abilities' in formulating hypotheses, recommending directions and critiquing studies; no numeric performance values provided in this paper excerpt.",
            "comparison_with_baseline": null,
            "validated_on_real_science": null,
            "novel_discoveries": null,
            "limitations": "Representations learned by LLMs lack interpretability and control hooks; extraction/grounding errors and hallucinations remain concerns; grounding with retrieval and structured representations needed.",
            "uuid": "e2656.4",
            "source_info": {
                "paper_title": "A Computational Inflection for Scientific Discovery",
                "publication_date_yy_mm": "2022-05"
            }
        },
        {
            "name_short": "Robot Scientist",
            "name_full": "Robot Scientist (King et al.)",
            "brief_description": "An automated laboratory system that formulates empirical hypotheses from data and closes the loop by executing experiments in the lab to test them (functional genomic hypothesis generation and experimentation).",
            "citation_title": "Functional genomic hypothesis generation and experimentation by a robot scientist.",
            "mention_or_use": "mention",
            "system_name": "Robot Scientist (robotic automation for scientific discovery)",
            "system_description": "Robot Scientist systems combine curated background knowledge (e.g., gene regulatory networks), automated hypothesis-generation algorithms inspired by cognitive models, and robotic lab automation to select, run and analyze experiments; the loop includes hypothesis formation, experiment execution, and updating knowledge bases.",
            "system_type": "robotic-automation + ML (closed-loop experimental automation)",
            "scientific_domain": "biology / functional genomics",
            "hypothesis_generation_method": "Algorithmic hypothesis generation from data and structured background knowledge (computational discovery techniques inspired by symbolic/inductive methods), followed by automated experiment scheduling.",
            "novelty_assessment_method": null,
            "plausibility_assessment_method": null,
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": null,
            "pre_experiment_evaluation": null,
            "validation_mechanism": "Experimental validation in wet lab: the system runs experiments to test generated hypotheses and updates models accordingly (as described in referenced work).",
            "reproducibility_measures": null,
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": null,
            "benchmark_dataset": null,
            "performance_metrics": null,
            "comparison_with_baseline": null,
            "validated_on_real_science": true,
            "novel_discoveries": "Referenced work reports automated generation and experimental testing of functional genomic hypotheses; specifics are in the cited paper.",
            "limitations": "Typically limited to narrow curated domains where background knowledge and robotic protocols are available; scaling to broader open scientific domains is challenging.",
            "uuid": "e2656.5",
            "source_info": {
                "paper_title": "A Computational Inflection for Scientific Discovery",
                "publication_date_yy_mm": "2022-05"
            }
        },
        {
            "name_short": "PPI Debiasing / Prioritization",
            "name_full": "Methods for debiasing attention and reprioritizing protein-protein interaction (PPI) discovery",
            "brief_description": "Analytical methods that detect a 'bias of locality' in historical PPI discovery and propose reprioritization mechanisms to surface understudied candidate PPIs that could have been discovered earlier.",
            "citation_title": "On biases of attention in scientific discovery.",
            "mention_or_use": "use",
            "system_name": "PPI attention-bias analysis and reprioritization methods",
            "system_description": "This line of work constructs a temporal graph of confirmed PPIs and analyzes growth patterns to identify locality-driven attention bias; it then uses protein properties and graph-based reprioritization heuristics to rank candidate PPIs that are under-explored, demonstrating retrospective cases where earlier discovery would have been possible.",
            "system_type": "graph-analysis / prioritization (data-driven prioritization)",
            "scientific_domain": "biology / protein-protein interactions",
            "hypothesis_generation_method": "Generates hypotheses by reprioritizing candidate PPIs (edges) that are under-attended given protein properties and graph locality features; these ranked candidates serve as testable hypotheses.",
            "novelty_assessment_method": "Novelty inferred via lower historical attention/locality; no formal novelty metric reported beyond analyses of historical discovery timing.",
            "plausibility_assessment_method": "Plausibility assessed via features of proteins and retrospective analysis showing that higher-ranked candidates correspond to eventual confirmations under different prioritization.",
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": null,
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Temporal retrospective analysis showing that reprioritization could have led to earlier discoveries; demonstration of improved candidate rankings using protein properties.",
            "reproducibility_measures": null,
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": null,
            "benchmark_dataset": "Historical PPI databases (growing graph of confirmed PPIs over decades) as used in the study",
            "performance_metrics": "Temporal analyses revealed a measurable 'bias of locality' and demonstrated mechanisms for reprioritizing candidate PPIs that could have enabled earlier discoveries; no single numeric accuracy metric provided in this summary.",
            "comparison_with_baseline": "Shown to change prioritization relative to historical discovery order; retrospective evidence suggests earlier discovery under new prioritization.",
            "validated_on_real_science": true,
            "novel_discoveries": null,
            "limitations": "Locality bias reflects understandable scientific focus; translating reprioritizations into practice requires incentives and experimental follow-up; dependency on available PPI data and feature engineering.",
            "uuid": "e2656.6",
            "source_info": {
                "paper_title": "A Computational Inflection for Scientific Discovery",
                "publication_date_yy_mm": "2022-05"
            }
        },
        {
            "name_short": "Accord",
            "name_full": "Accord: Multi-document Concept Description Generator",
            "brief_description": "A multi-document system that generates diverse, grounded descriptions of scientific concepts by retrieving explanations that relate target concepts to source concepts familiar to the user and rewriting them in a structured template.",
            "citation_title": "Accord: A multi-document approach to generating diverse descriptions of scientific concepts.",
            "mention_or_use": "use",
            "system_name": "Accord",
            "system_description": "Accord takes as input a list of source concepts representing a user's known concepts (from papers they wrote or read), retrieves definitions of a target concept from multiple scientific papers where the target is explained in terms of the source concepts, and uses a neural text-generation model to rewrite and structure the explanations tailored to the user's knowledge.",
            "system_type": "multi-document retrieval + neural text generation",
            "scientific_domain": "general scientific literature / concept explanation",
            "hypothesis_generation_method": "Not designed to generate hypotheses; supports learning and understanding by grounding new concepts in user's known concepts which can indirectly aid hypothesis formation.",
            "novelty_assessment_method": null,
            "plausibility_assessment_method": "Grounding in retrieved literature aims to increase plausibility of generated explanations; explicit plausibility scoring not reported.",
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": null,
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Evaluations reported in EMNLP paper (reference) for quality and diversity of generated descriptions; user-aligned grounding tested.",
            "reproducibility_measures": null,
            "hallucination_prevention_method": "Grounding generated descriptions in retrieved multi-document evidence to reduce free-form hallucination; specifics not detailed here.",
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": null,
            "benchmark_dataset": null,
            "performance_metrics": "Reported generation of diverse, user-grounded definitions in EMNLP evaluation; no numeric rates provided in this summary.",
            "comparison_with_baseline": null,
            "validated_on_real_science": true,
            "novel_discoveries": null,
            "limitations": "Quality depends on retrieval accuracy and generation model; grounding reduces but does not eliminate risk of unsupported wording.",
            "uuid": "e2656.7",
            "source_info": {
                "paper_title": "A Computational Inflection for Scientific Discovery",
                "publication_date_yy_mm": "2022-05"
            }
        },
        {
            "name_short": "Scisight",
            "name_full": "Scisight: Exploratory Scientific Search",
            "brief_description": "An exploratory scientific search system combining faceted navigation and research group detection to support exploration of COVID-19 literature and discovery of perspectives and groups.",
            "citation_title": "Scisight: Combining faceted navigation and research group detection for covid-19 exploratory scientific search.",
            "mention_or_use": "mention",
            "system_name": "Scisight",
            "system_description": "Scisight provides faceted navigation and research group detection over COVID-19 literature to aid exploratory search and surface cross-cutting perspectives and research communities; it is a prototype for augmenting attention and literature review.",
            "system_type": "exploratory search / faceted retrieval",
            "scientific_domain": "biomedical / COVID-19 literature",
            "hypothesis_generation_method": "Supports ideation by surfacing diverse papers, facets and groups rather than directly generating hypotheses.",
            "novelty_assessment_method": null,
            "plausibility_assessment_method": null,
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": null,
            "pre_experiment_evaluation": null,
            "validation_mechanism": "Described as a prototype for exploratory search; evaluation details are in cited EMNLP work.",
            "reproducibility_measures": null,
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": null,
            "benchmark_dataset": null,
            "performance_metrics": null,
            "comparison_with_baseline": null,
            "validated_on_real_science": null,
            "novel_discoveries": null,
            "limitations": "Focused on exploratory navigation; not a hypothesis-generation/validation engine per se.",
            "uuid": "e2656.8",
            "source_info": {
                "paper_title": "A Computational Inflection for Scientific Discovery",
                "publication_date_yy_mm": "2022-05"
            }
        },
        {
            "name_short": "AlphaFold",
            "name_full": "AlphaFold (DeepMind)",
            "brief_description": "A deep learning system that predicts protein 3D structures from amino-acid sequences with high accuracy, revolutionizing structural biology and serving as an example of AI-driven scientific prediction.",
            "citation_title": "Highly accurate protein structure prediction with alphafold.",
            "mention_or_use": "mention",
            "system_name": "AlphaFold",
            "system_description": "AlphaFold is a deep neural network architecture trained to predict atomic-level protein structures from sequence inputs, combining attention-based architectures, evolutionary information and structural priors to achieve high-accuracy predictions.",
            "system_type": "deep learning / structure prediction",
            "scientific_domain": "biology / structural biology",
            "hypothesis_generation_method": "Produces structural predictions (testable scientific predictions) from sequence data; not framed as hypothesis generator for experimental design in this paper.",
            "novelty_assessment_method": null,
            "plausibility_assessment_method": "Validated extensively against known structures and community benchmarks (CASP); described here as an example of ML enabling scientific discovery.",
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": null,
            "pre_experiment_evaluation": null,
            "validation_mechanism": "Validated against experimentally determined protein structures (e.g., CASP benchmarks in the cited Nature paper).",
            "reproducibility_measures": null,
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": null,
            "benchmark_dataset": null,
            "performance_metrics": "Reported highly accurate structure predictions in Nature paper (see citation) â€” specifics are in the AlphaFold publication.",
            "comparison_with_baseline": null,
            "validated_on_real_science": true,
            "novel_discoveries": null,
            "limitations": "Domain-specific success; not a general hypothesis-generation system for arbitrary scientific claims.",
            "uuid": "e2656.9",
            "source_info": {
                "paper_title": "A Computational Inflection for Scientific Discovery",
                "publication_date_yy_mm": "2022-05"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Bridger: Toward bursting scientific filter bubbles and boosting innovation via novel author discovery.",
            "rating": 2
        },
        {
            "paper_title": "Solvent: A mixed initiative system for finding analogies between research papers.",
            "rating": 2
        },
        {
            "paper_title": "Functional genomic hypothesis generation and experimentation by a robot scientist.",
            "rating": 2
        },
        {
            "paper_title": "Literature-augmented clinical outcome prediction.",
            "rating": 2
        },
        {
            "paper_title": "A search engine for discovery of scientific challenges and directions.",
            "rating": 2
        },
        {
            "paper_title": "On biases of attention in scientific discovery.",
            "rating": 2
        },
        {
            "paper_title": "Accord: A multi-document approach to generating diverse descriptions of scientific concepts.",
            "rating": 2
        },
        {
            "paper_title": "Sparks of artificial general intelligence: Early experiments with GPT-4.",
            "rating": 2
        },
        {
            "paper_title": "Highly accurate protein structure prediction with alphafold.",
            "rating": 1
        },
        {
            "paper_title": "Scisight: Combining faceted navigation and research group detection for covid-19 exploratory scientific search.",
            "rating": 1
        }
    ],
    "cost": 0.020136750000000002,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>A Computational Inflection for Scientific Discovery</h1>
<p>Tom Hope<br>tomh@allenai.org<br>The Allen Institute for AI<br>The Hebrew University of Jerusalem</p>
<p>Doug Downey<br>dougd@allenai.org<br>The Allen Institute for AI<br>Northwestern University</p>
<h2>Oren Etzioni</h2>
<p>oren@allenai.org
The Allen Institute for AI</p>
<h2>Daniel S. Weld</h2>
<p>danw@allenai.org
The Allen Institute for AI
The University of Washington</p>
<h2>Eric Horvitz</h2>
<p>horvitz@microsoft.com
Office of the Chief Scientific Officer
Microsoft
of possibility. The way we search through and reflect about information across the vast space-the areas we select to explore, and how we explore them-is hindered by cognitive biases [26] and lacks principled and scalable tools for guiding our attention [32]. "Unknowns" are not just holes in science, but important gaps in personal knowledge about the broader knowns across the sciences.</p>
<p>We thus face an imbalance between the treasure trove of scholarly information and our limited ability to reach into it. Despite technological advances, we require new paradigms and capabilities to address this widening gap. We see promise in developing new foundational capabilities that address the cognitive bottleneck, aimed at extending human performance on core tasks of researche.g., keeping abreast with developments, forming and prioritizing ideas, conducting experiments, reading and understanding papers (see Table 1). We focus on a research agenda we call task-guided scientific knowledge retrieval, in which systems counter humans' bounded capacity by ingesting corpora of scientific knowledge and retrieving inspirations, explanations, solutions and evidence synthesized to directly serve task-specific utility. We present key concepts of task-guided scientific knowledge retrieval, including work on prototypes that highlight the promise of the direction and bring into focus concrete steps forward for novel representations, tools, and services. In Section 4 we review systems that help researchers discover novel perspectives and inspirations [8, 9, 11, 29], help guide the attention of researchers toward opportunity areas rife with uncertainties and unknowns [18, 32], and models that leverage retrieval and synthesis of scientific knowledge as part of machine learning and prediction [6, 24]. We conclude in Section 5 with a discussion of opportunities ahead with computational approaches that have the potential to revolutionize science.</p>
<p>To set the stage, in the following section we begin by discussing some fundamental concepts and background for our research agenda.</p>
<h2>3 HUMAN-CENTRIC PERSPECTIVE</h2>
<p>Extraordinary developments at the convergence of AI and scientific discovery have emerged in specific areas, including new kinds of analytical tools, with the prominent example of AlphaFold, which harnesses deep neural models to dramatically improve the prediction of protein structure from amino acid sequence information [15]. Large language models (LLMs) have very recently made stellar progress in the ability to reason about complex tasks, including in the medical domain [25]. The most advanced LLM at presentemerging before the ink has dried on this paper-is GPT-4, which</p>
<table>
<thead>
<tr>
<th>Task/Activity</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>Attention to areas of interest</td>
<td>A background process of keeping track of latest developments in relevant scientific communities.</td>
</tr>
<tr>
<td></td>
<td>Involves applying selective attention, perceiving relevance and utility.</td>
</tr>
<tr>
<td>Problem identification &amp; prioritization</td>
<td>Identifying new research questions and deciding on which ones to work. Involves factors such as</td>
</tr>
<tr>
<td></td>
<td>subjective preferences and assessment of feasibility.</td>
</tr>
<tr>
<td>Forming directions</td>
<td>Given a problem/question, forming ideas to address it. Involves cognitive processes such as</td>
</tr>
<tr>
<td></td>
<td>constructing mental models of a problem, problem reformulation, abstraction and decomposition,</td>
</tr>
<tr>
<td></td>
<td>adaptation of relevant knowledge to new scenarios, and assessing likelihood of success.</td>
</tr>
<tr>
<td>Literature search &amp; review</td>
<td>Accessing and ingesting knowledge in the literature. Involves many processes such as query</td>
</tr>
<tr>
<td></td>
<td>formulation, skimming and assessing relevance, positioning ideas with relations and contrasts to</td>
</tr>
<tr>
<td></td>
<td>existing work, and reading and summarization strategies.</td>
</tr>
<tr>
<td>Learning, understanding, sense-making</td>
<td>The cognitive processes and activities involved in assimilating new knowledge and concepts, and</td>
</tr>
<tr>
<td></td>
<td>making sense of complex scientific information spaces.</td>
</tr>
<tr>
<td>Experimentation, analysis, action</td>
<td>A broad category referring to the many processes and activities involved in formulating and</td>
</tr>
<tr>
<td></td>
<td>conducting experiments (e.g., planning data collection and measurements), performing analyses</td>
</tr>
<tr>
<td></td>
<td>(e.g., understanding a set of data points, modeling and extrapolation, prediction, evaluation), and</td>
</tr>
<tr>
<td></td>
<td>producing artifacts, techniques, theories, decisions, policies, actions.</td>
</tr>
<tr>
<td>Research communication</td>
<td>Writing research documents (papers, proposals, analyses), communicating with peers (feedback</td>
</tr>
<tr>
<td></td>
<td>and review, collaboration, presentation).</td>
</tr>
</tbody>
</table>
<p>Table 1: Research may be decomposed into salient tasks that are prime targets for computational augmentation (Â§ 4).</p>
<p>has exhibited jaw-dropping skill at handling clinical questions, mathematical problems and computer coding tasks [1].</p>
<p>We view these developments as tremendous research opportunities for building computational approaches that accelerate scientific discovery. We take a human-centered, cognitive perspective: augmenting researchers by taking into account the diversity of tasks, contexts, and cognitive processes involved in consuming and producing scientific knowledge. Collectively, we refer to these as the inner cognitive world of a researcher (see Figure 1). The researcher interacts with the scientific ecosystemâ€”literature, resources, discussionsâ€”in order to inform decisions and actions. Researchers have different uses for scholarly information, depending on the task at hand and the stage of exploration (see Table 1 and discussion in Section 4). We pursue a research agenda around assisting researchers in their tasks, guided by two main desiderata:</p>
<p>(1) Systems for augmenting human capabilities in the sciences need to enhance the effective flow of knowledge from the outer world of scientific information and discourse to the researcherâ€™s inner cognitive worldâ€”countering humansâ€™ bounded capacity by retrieving and synthesizing information targeted to enhance performance on tasks. Achieving this goal requires methods that build and leverage rich representations of scientific content and that can align computational representations with human representations, in the context of specific tasks and backgrounds of researchers.</p>
<p>(2) Research on such systems should be rooted in conceptual models of the inner cognitive world of a researcher. Shining a spotlight on this inner world brings numerous factors and questions to the fore. How do researchers form ideas? How do they decide which problems to look into? How do they find and assimilate new information in the process of making decisions? What cognitive representations and bottlenecks are involved? What computing services would best augment these processes?</p>
<p>Figure 1: Information flows from the outer world into the inner cognitive world of researchers, constrained by cognitive capacity and biases. We see opportunities to support researchers by retrieving knowledge that helps with tasks across multiple phases of the scientific process (Table 1).</p>
<p>Background and Related Themes. We leverage research in natural language processing, information retrieval, data mining and human-computer interaction and draw concepts from multiple disciplines. For example, efforts in metascience focus on sociological factors that influence the evolution of science [17], e.g., analyses of information silos that impede mutual understanding and interaction [38], analyses of macro-scale ramifications of the rapid growth in scholarly publications [4], and of current metrics for measuring impact [5] â€” work enabled by digitization of scholarly corpora (see Section 3.1). Metascience research makes important observations about human biases (desideratum 2) but generally does not engage in building computational interventions to augment researchers (desideratum 1). Conversely, work in literature-based discovery [33] mines information from literature to generate new predictions (e.g., functions of materials or drug targets) but is typically done in isolation from cognitive considerations; however, these techniques have great promise in being used as part of human-augmentation</p>
<p>(2) Research on such systems should be rooted in conceptual models of the inner cognitive world of a researcher. Shining a spotlight on this inner world brings numerous factors and questions to the fore. How do researchers form ideas? How do they decide which problems to look into? How do they find and assimilate new information in the process of making decisions? What cognitive representations and bottlenecks are involved? What computing services would best augment these processes?</p>
<p>systems (see Sections 4-5). Other work uses machines to automate aspects of science. Pioneering work from Herbert Simon and Pat Langley automated discovery of empirical laws from data, with models inspired by cognitive mechanisms of discovery (see Section 3.2). More recent work has focused on developing robot scientists [16, 30] that run certain experiments in biology or chemistry-not only formulating hypotheses but "closing the loop" by automated tests in a physical laboratory-where robots may use narrow curated background knowledge (e.g., of a specific gene regulatory network) and machine learning to guide new experiments. Related work explores automating scientific data analysis [6], which we discuss in Section 4 as a case of retrieval from scientific repositories to augment aspects of experimentation and analysis (see Table 1).</p>
<p>We now turn to a discussion of central concepts: the ecosystem of science, and the cognitive world. This presentation lays the foundations for our exposition of task-guided retrieval in Section 4 and the research opportunities in Section 5.</p>
<h3>3.1 Outer World: Scientific Ecosystem</h3>
<p>We collectively name the scientific ecosystem and the digital representations of scientific knowledge as the outer world (see Figure 1). The outer world is comprised of scientific communities, a complex and shifting web of peers, concepts, methodologies, problems and directions revolving around shared interests, understandings and paradigms. This ecosystem generates digital information-digital "traces" of scientific thought and behavior-lying at the center of our attention as computer scientists interested in boosting human capacity to "reach into" the pool of scientific knowledge. This knowledge includes scholarly publications that appear in journals, conference proceedings, and online preprint repositories. Online publications are a main case of digital research artifacts; other examples of products of research include software, datasets, knowledge bases. Research artifacts are also associated typically with signals of quality and interest, such as citations to a specific paper or downloads of a dataset. The specific context of why a paper or resource was cited or used is often reflected in natural language descriptions. Different types of signals include peer review prior to publication (mostly not shared publicly), and social media discussions such as on Twitter, which has become a major virtual platform for academic dissemination and conversation. Along with the trend in society, private communication channels among researchers are also digital-mails, online calls and messages. Similarly, note taking and writing-important activities across the scientific workflow-are done in digital form. This information is siloed in different platforms under privacy restrictions, yet represents a treasure trove for tools for the augmentation of scientific reasoning and exploration.</p>
<h3>3.2 Inner World: Human Cognition in Science</h3>
<p>The way researchers decide to interact with information in the outer world and the way they process and use this information is governed by a complex array of cognitive processes, personal knowledge and preferences, biases and limitations, which are only partially understood. We collectively name these the inner world, and briefly discuss several salient aspects.</p>
<p>Early work in AI by Herbert Simon and Alan Newell and later efforts by Pat Langley and Paul Thagard focused on cognitive and
computational aspects of problem solving, creativity, decision making and scientific reasoning and discovery, seeking algorithmic representations to help understand and mimic human intelligence [19, 36]. Cognitive mechanisms that play important roles in scientific discovery include inductive and abductive reasoning, mental modeling of problems and situations, abstraction, decomposition, reformulation, analogical transfer and recombination; for example, in analogical transfer, given a situation or problem being considered in our working memory, we retrieve from our long-term memory prior analogous problems or situations.</p>
<p>This cognitive machinery powers humans' ingenuity. However, the human mind also has severe limitations-bounded rationality in the words of Simon-that impede these powerful mechanisms. Our limitations and capabilities have been studied for over a hundred years with cognitive psychology. Our limitations manifest in bounded cognitive capacity and knowledge, and biases that govern our behaviors and preferences. These limitations are all tightly interrelated. The ability to generate ideas, for instance, directly relies on prior knowledge; but, when a large volume of information from the outer world of science is met by insufficient cognitive capacity for processing and assimilating it, the result is information overload-a ubiquitous hindrance for researchers [29]. Information overload in science strains the attentional resources of researchers, and forces researchers to allocate attention to increasingly narrow areas. This effect, in turn, amplifies a host of biases which researchers, just like all humans, suffer from [26, 32]. For example, scientists can be limited by confirmation bias, aversion to information from novel domains, homophily, and fixation on specific directions and perspectives without consideration of alternative views [11, 26]. More broadly, selection of directions and areas to work on is a case of decision-making, and as such personal preference and subjective utility play fundamental roles. Our research decisions rely on subjective assessment of feasibility, long-term or short-term goals and interests, and even psychological factors (e.g., tendencies for risk aversion). These factors are of course also impacted by biases [26].</p>
<p>Clearly, the inner world of researchers is dauntingly complex. However, in the next section, we present encouraging results of applying computational methods to augment cognition in the sciences, helping to mitigate biases and limitations and enabling researchers to make better use of their powerful creative mechanisms.</p>
<h2>4 TASK-GUIDED RETRIEVAL</h2>
<p>How might we widen and deepen the connection between the outer world of science and researchers' limited cognitive worlds? We see a key bridge and research opportunity with developing tools for scientific task-guided knowledge retrieval. In this section, we discuss our vision and present initial work toward achieving it.</p>
<p>Drawing from discussions in literature on the process of scientific discovery, we enumerate in Table 1 salient scientific tasks and activities, such as problem identification, forming directions, learning, literature search and review, experimentation. These tasks could benefit from augmentation of human capabilities but remain underexplored in computer science. Existing computational technologies for assisting humans in discovering scientific knowledge are underinvested in important aspects of the intricate cognitive processes and goal-oriented contexts involved in scholarly endeavors.</p>
<p>The dominant approach to information retrieval research and systems can be summarized as "relevance first"-focusing on results that answer user queries as accurately as possible. Academic search engines assume users know what queries to explore and how to formulate them. For pinpointed literature search in familiar areas, this assumption may often suffice; but a broad array of other scholarly tasks, such as ideation or learning about a new topic, are very much underserved [9-11, 18, 29]. At the same time, many voices in the information retrieval community have discussed a different, broader view of utility-driven search situated in a wider context of information seeking by users with specific intents and tasks [31]. Here, we adapt ideas and principles from this general paradigm.</p>
<p>We envision methods for task-guided scientific knowledge retrieval: systems that retrieve and synthesize outer knowledge in a manner that directly serves a task-guided utility of a researcher, while taking into consideration the researcher's goals, state of inner knowledge, and preferences.</p>
<p>Consider the tasks in Table 1. For researchers engaged in experimentation or analysis, we envision systems that help users identify experiments and analyses in the literature to guide design choices and decisions. For researchers in early stages of selecting problems to work on, we picture systems that support this decision with information from literature and online discussions, synthesized to obtain estimated impact and feasibility. As part of forming directions to address a problem, systems will help users find inspirations for solutions. Researchers who are learning about a new topic will be provided with retrieved texts and discussions that explain the topic in a manner personally tailored to personal knowledge. Importantly, task-guided knowledge retrieval follows the two desiderata introduced in Section 3; namely, systems should enable users to find knowledge that directly assists them in core research tasks by augmenting their cognitive capacity and mitigating their biases, and computational representations and services should align with salient cognitive aspects of the inner world of researchers.</p>
<h3>4.1 Prototypes of Task-Guided Retrieval</h3>
<p>We present work on initial steps and prototypes, including representative work that we have done and the work of others, framed in alignment with task-guided knowledge retrieval and tasks enumerated in Table 1. The main aim of this brief review is to stimulate discussion in the computer science community on tools for extending human capabilities in the sciences. Existing methods are far from able to realize our vision. For example, we see major challenges in representation and inferences about the inner world of knowledge and preferences, and aligning these with representations and inferences drawn from the outer world knowledge. Today's prototypes are limited examples of our vision, using very rough proxies of inner knowledge and interest based on papers and documents written or read by the user, or in some cases only a set of keywords. We discuss these research challenges and others in Section 5.</p>
<p>Forming Directions. We have developed methods for helping researchers generate new directions. A fundamental pattern in the cognitive process of creativity involves detecting abstract connections across ideas and transferring ideas from one problem to another [36]. Grounded in this cognitive understanding, we have pursued several approaches for stimulating creativity powered by
retrieving outer knowledge. We developed and studied a system named Bridger that connects researchers to peers who inspire novel directions for research [29]. Bridger identifies matches among authors based on commonalities and contrasts, identifying peers who are both relevant and novel-working on similar problems but using very different methods, potentially inspiring new solutions. By doing so, Bridger helps mitigate the cognitive bias of fixation [11].</p>
<p>In this setting, inner knowledge is represented as mentions of problems and methods extracted automatically from a researcher's papers and weighted by term frequency. The outer knowledge being retrieved takes the form of other authors in computer science, following the same representation. For each retrieved author, the system displays salient problems, methods and papers, ranked by measures of relevance to the user. In studies with CS researchers, we found that Bridger dramatically boosted creative search and inspiration over state-of-art neural models employed by the Semantic Scholar search engine, surfacing useful connections across diverse areas; for example, one researcher drew novel connections between the mathematical area of graph theory and their own area of human-centered AI, by exploring a recommended author who applies graph theory to decision making. The studies also surfaced important challenges, discussed in Section 5.
<img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 2: Matching researchers to authors with whom they are unfamiliar, to help in generating directions. Author cards show key problems and methods extracted from their papers.</p>
<p>We have also explored retrieving outer knowledge to enhance the human ability to find opportunities for analogical transfer [3, 8]. Extensive work in cognitive studies has highlighted the human knack for "analogical retrieval" as a central function in creativitybringing together structurally related ideas and adapting them to a task at hand [36]. We developed a search method that enables researchers to search through a database of technological inventions and find mechanisms that can be transferred from distant domains to solve a given problem. Given as input from the user a textual description of an invention, we retrieve ideas (inventions, papers) that have partial structural similarity to the input (e.g., inventions with similar mechanisms), to facilitate discovery of analogical transfer opportunities. We found that the method could significantly boost measures of human creativity in ideation experiments, in which users were asked to formulate new ideas after viewing inspirations retrieved with our approach versus baseline information retrieval methods. For example, a biomechanical engineering lab working on polymer stretching/folding for creating novel structures found useful inspiration in a civil engineering paper on web crippling in steel beams-abstractly related to stretching and folding.</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 3: Using an extracted hierarchy of problems to retrieve new perspectives on a focal problem of interest.</p>
<p>Innovation may also involve traversing multiple levels of abstraction around a problem to "break out" of fixation on the details of a specific problem by exploring novel perspectives. Given as input a problem description written by the user (as a proxy summary of the user's inner world of knowledge and purpose), we have pursued mechanisms that can retrieve diverse problem perspectives that are related to the focal problem, with the goal of inspiring new ideas for problem abstraction and reformulation [11] (see Figure 3). Using NLP models to extract mentions of problems, we mine a corpus of technological invention texts to discover problems that often appear together, and use this information to form a hierarchical problem graph that supports automatic traversal of neighboring problems around a focal problem, surfacing novel inspirations to users. In a study of the efficacy of the methods, over $60 \%$ of "inspirations" retrieved this way were found to be useful and novel-a relative boost of $50-60 \%$ over the best-performing baselines. For example, given an input problem of reminding patients to take medication, our system retrieves related problems such as in patient health tracking and alerting devices.</p>
<p>Guiding attention and problem identification. We see great opportunity in developing methods for guiding the attention of researchers to important areas in the space of ideas where there exists less knowledge or certainty [18, 32] (Figure 4). In one direction, we built a search engine that allows users to retrieve outer knowledge in the form of difficulties, uncertainties and hypotheses in the literature. The key goals of this mode of search are to bolster attention to rising and standing challenges of relevance to the user so as to help overall with identification and selection of problems. We performed experiments with participants with diverse research backgrounds, including medical doctors working in a large hospital. Using query topics as a proxy for the inner world of participants' interests, we found the system could dramatically outperform PubMed search, the go-to biomedical search engine, at discovering important and interesting areas of challenges and directions. For example, while searching PubMed for the ACE2 receptor in the context of COVID19 returns well-studied results, the prototype system by contrast focuses on finding statements of uncertainty, open questions and initial hypotheses, like a paper noting the possibility that ACE2 plays a role in liver damage in COVID-19 patients.</p>
<p>Another direction on biases and blindspots considers the longterm effort to identify protein-protein interactions (PPIs). A dataset of the growing graph of confirmed PPIs over decades was constructed and leveraged to identify patterns of scientific attention [32]. A temporal analysis revealed a significant "bias of locality," where explorations of PPIs are launched more frequently from those that were most recently studied, rather than following more general prioritization of exploration. While locality reflects an understandable focus on adjacent and connected problems in the biosciences, the pattern of attention leads to systematic blindspots in large,</p>
<p>Input:
Items of interest (concepts, entities, topics...)
<img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 4: Suggesting research opportunities for query concepts (e.g., medical topics) by identifying blindspots, gaps in collective knowledge and promising areas for exploration.
widely used PPI databases that are likely unappreciated-further exacerbating attentional biases. The study further demonstrated mechanisms for reprioritizing candidate PPIs based on properties of proteins, and showed how earlier discoveries could be made with use of the debiasing methods. The findings underscore the promise of tools that retrieve existing outer world knowledge to guide attention to worthwhile directions. In this case, the outer knowledge source is a PPI database, and a user-selected sub-graph provides a proxy for inner world knowledge and interests.</p>
<p>Literature search and review. A great body of work on literature search and review has deep relevance to task-guided retrieval in the sciences. In particular, we see great opportunity with building on recent advances in information retrieval to (1) help biomedical researchers with domain-specific representations and (2) enhance scientific search by building new neural models.</p>
<p>Specialized search systems have been developed for the biomedical domain, with the overall vision of harnessing natural language understanding technologies to help researchers discover relevant evidence and expedite the costly process of systematic literature review [27]. For example, Nye et al. [27] build a search and synthesis system based on automated extraction of biomedical treatmentoutcome relations from clinical trial reports. The system is found to assist in identification of drug repurposing opportunities. As another recent example, the SPIKE system enables researchers to extract and retrieve facts from a corpus using an expressive query language with biomedical entity types and new term classes that the user can define interactively [34]. Together, this work underscores the importance of extracting a semantically meaningful representation of outer world knowledge that aligns with core aspects of inner world reasoning by researchers (see Section 5).</p>
<p>In separate work, neural language models built via self-supervision on large corpora of biomedical publications have recently led to performance boosts and new features in literature search systems [39], such as support for natural language queries that provide users with a more natural way to formulate their informational goals. Neural models have also been trained to match abstract discourse aspects of pairs of papers (e.g., sentences referring to methodologies) and</p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 5: Leveraging medical corpora to enhance the precision of AI models for inference about patient outcomes.
automatically retrieve documents that are aspectually similar [23]. By employing a representation that aligns with scientific reasoning across areas, this method achieves state-of-art results across biomedical and computer science literature.</p>
<p>Experimentation, analysis, and action. Beyond helping researchers via awareness and knowledge, we see great opportunities to use scientific corpora to construct task-centric inferential systems with automated models and tools for assisting with analysis, prediction and decisions. We demonstrate these ideas by casting two different lines of work as cases of task-guided retrieval.
(1) Workflows are multi-step computational pipelines used as part of scientific experimentation for data preparation, analysis and simulation [6]. Technically this includes execution of code scripts, services and tools, querying databases and submitting jobs to the cloud. In the life sciences, in areas such as genomics, there are specialized workflow management systems to help researchers find and use workflows, enabled by a community that creates and publicly shares repositories of workflows with standardised interfaces, metadata and functional annotations of tools and data. As discussed in Gil [6], machine learning algorithms can potentially use these resources to automate workflow construction, learning to retrieve and synthesize data analysis pipelines. In this setting, outer world knowledge takes the form of workflow repositories, from which systems retrieve and synthesize modular building blocks; users' inner world is reflected via analysis objectives and constraints.
(2) In our work on clinical predictions [24], the goal is to enhance prediction of medical outcomes of patients hospitalized in the intensive care unit (ICU), such as in-hospital mortality or prolonged length of stay. Our system, named BEEP (biomedical evidence enhanced prediction), learns to perform predictions by retrieving medical papers that are relevant to each specific ICU patient, and to synthesize this outer knowledge in combination with internal EMR knowledge to form a final prediction. The primary envisaged user is a practice-oriented researcher-a medical doctor, whose inner knowledge is given by a rough proxy in the form of internal clinical notes from which we extract "queries" issued over medical papers. We find BEEP to provide large improvements over state-of-art models that do not use retrieval from the literature. BEEP's output can
be aligned with inner world representations, e.g., matches between patient aspects and related cohorts in papers (see Figure 5).</p>
<p>Learning and understanding. We introduced a system [22] for helping users learn about new concepts by showing definitions grounded in familiar concepts; e.g., a new algorithm is explained as a variant of an algorithm familiar to the user. Cognitive studies have asserted that effective descriptions of a new concept ground it within the network of known concepts. Our system takes as input a list of source concepts reflecting the user's inner knowledge as obtained from papers that they have written or read. When the user seeks a definition of a new target concept, we retrieve outer knowledge in the form of definitions appearing in scientific papers in which the target concept is explained in terms of the source concepts; a neural text generation model then re-writes the text in a structured, template form that relates the target to the source.</p>
<h2>5. OPPORTUNITIES AHEAD</h2>
<p>The challenges of task-guided retrieval in support of researchers frame a host of problems and opportunities. We discuss select challenges and directions (see also Table 2). We begin with an illustrative example, imagining a futuristic system to motivate the discussion.</p>
<h3>5.1. Aspirations</h3>
<p>We envision tools that flow outer world knowledge to researchers based on inferences about their inner world-users' knowledge, past and present goals and difficulties, and the tasks from Table 1 they are engaged in. The systems would use multiple signals for making inferences, including users' papers, data, experiments and communication channels, and also converse with the user to understand needs and suggest solutions, hypotheses and experiments.</p>
<p>We foresee systems powered by rich representations of both inner and outer scientific knowledge. For a given concept, e.g., a certain algorithm or organism, an aspirational system would ingest all papers on the subject to form a multi-faceted representation of concepts as objects with associated properties and functions. Using this representation, the system could assist in literature search and review, enabling expressive queries to outer world information that target abstract aspects like functionalities, mechanisms, behaviors and designs in a manner that transcends field-specific jargon, abstracting away lexical differences that hindered historical search engines (e.g., Google Scholar). To help users learn and understand new concepts they encounter, the system would explain them in relation to other concepts the user already knows. A future system might also assist in automating experimentation, analysis and action and in forming directions, by forming compositions of concepts and predicting the resultant affordances; for example, matching a certain algorithm with a suitable problem based on the algorithm's properties and the problem's requirements, matching an organism with a specific method of measurement or modification, or recombining parts of two devices to form a new device. The system could help identify related problems in the literature, synthesizing from them useful suggestions for problem reformulations. Considering the huge combinatorial space of potential suggestions, a system could assist in prioritization using estimated measures of interestingness, feasibility and value by synthesizing historical and current signals in literature, online discussions and knowledge bases.</p>
<p>Envisioned systems would be designed as human-centric, focusing on the individual researcher. The systems would enable users to convey preferences, goals and interests, and mediate the presentation of suggested directions and problem solutions based on personal prior knowledge, proposing concrete new directions grounded in representations that researchers can follow, and assisting users in reading complex retrieved texts by editing their language to conform with concepts that users are familiar with.</p>
<h3>5.2 Research Directions</h3>
<p>While we have witnessed remarkable strides in AI, the journey towards actualizing our vision requires further advancement. Envisioning such capabilities, however, can serve as a compass for directing research endeavors. An encouraging development can be seen in the recent developments with large language models, which have demonstrated surprising capabilities with interpreting and generating complex texts and tackling technical tasks. The proficiencies demonstrated by these models instills confidence that many of the possibilities that we discussed are attainable. We now elaborate on challenges and directions ahead, including limitations in representing scientific knowledge and making inferences about the inner worlds of researchers (see Table 2).</p>
<p>Task-aligned representations and scientific NLP. Paul Thagard writes: "thinking can best be understood in terms of representational structures in the mind and computational procedures that operate on those structures". We seek representations that can be aligned with human thinking-for insight-building, decision making and communication. Can we go beyond textual representation toward representations that support such cognitive processes?</p>
<p>The quest for a universal schema representing scientific ideas goes back hundreds of years. Gottfried Leibniz and RenÃ© Descartes were intrigued by the prospects of a universal codification of knowledge. Leibniz proposed the characteristica universalis, a hypothesized formal language of ideas enabling inferences with algebraic operators. While such a representation is not within reach, envisioning its existence-and how to even roughly approximate it-points to important research directions. One exciting direction is obtaining representations that support a "computational algebra of ideas"e.g., modeling compositions of concepts and the affordances that would be formed as a result. Early work on learning vector representations of natural language concepts supported rudimentary forms of addition, subtraction, and analogy (e.g., the Word2vec model).</p>
<p>Recently, large language models (LLM) [28] have made striking progress in generating new content and coherently combining concepts. Emerging evidence on GPT-4's ability to reason not only in unstructured language but also with logical structures grounded in code, suggests strong potential for generating novel ideas via compositionality and relational reasoning [1]. Our early experiments with GPT-4 have revealed a constellation of promising abilities to assist with the scientific process, such as formulating hypotheses, recommending future research directions, and critiquing studies. Equipped with training and retrieval with access to millions of scientific papers, descendants of today's models may have an ability to synthesize original scientific concepts with the in-depth technical detail at a level reported in high-quality scientific papers. We see great opportunity ahead to leverage LLMs to augment human scientific reasoning along the lines described in this paper.</p>
<p>One limitation with LLMs is that representations learned by these models are currently far from understood and lack "hooks" for control and interpretability, which are important in human-AI collaboration. In line with our focus on grounding representations of outer world knowledge with inner world cognitive aspects, we have pursued methods that "reverse engineer" scientific papers to automatically extract, using NLP, structured representations that balance three desiderata:
(1) Semantically meaningful representations, aligned with a salient task from the tasks in Table 1, grounded in cognitive research to guide us toward useful structures.
(2) Representations with sufficient level of abstraction to generalize across areas and topics.
(3) Representations expressive enough for direct utility in helping researchers as measured in human studies.</p>
<p>For example, we have extracted representations of causal mechanisms and hierarchical graphs of functional relationships. This kind of decomposition of ideas has enabled us to perform basic analogical inference in the space of technological and scientific ideas, helping researchers discover inspirations (see Section 4). However, many richer structures should be explored (e.g., of experimentation processes and methodologies, to enable tasks in Table 1).</p>
<p>A central challenge is that current models' extraction accuracy is limited, and the diversity of scientific language leads to problems in generalization and normalization of terms and concepts. We have pursued construction of new datasets, models and evaluations for identifying similarity between concepts and aspects across papers [2, 23], with fundamental problems in resolving diversity, ambiguity and hierarchy of language. As our results have highlighted, models tend to focus on surface-level lexical patterns, rather than deeper semantic relationships. Generally, substantial advances are needed to handle challenges posed by scientific documents. We require NLP models with full-document understanding, not only of text but of tables, equations, figures, and reference links. Open access corpora (e.g., S2ORC [20]) provide a foundation to address this challenge.</p>
<p>New modes of writing and reading. Perhaps the way we write can be dramatically different, using machine-actionable representations? Beyond reporting and documentation, writing represents a channel between the inner and outer worlds, forcing us to communicate ideas in concrete language; this process often begets new questions and perspectives. Can systems accompany different phases of writing, suggesting new ideas? In parallel, there is the task of reading what others have written; a recent interactive PDF reader offers, for example, customized concept definitions [7]. We imagine a future where every reader will see a different form of the same paper, re-written to align with readers' knowledge; e.g., our personalized concept definitions system [22] (Â§4) will insert new wording and explanations grounded in readers' knowledge.</p>
<p>Internal world of researchers. Grounding new concepts in readers' knowledge, suggests a wider and highly challenging problem. How can we enable researchers to specify their knowledge and preferences to direct systems to carry out tasks? Directly querying for these aspects burdens the researcher and may be prone to reporting biases. Digital traces present an opportunity for automatically estimating a researcher's knowledge, objectives, needs and interests-based on data. We are interested in using researchers'</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Challenge</th>
<th style="text-align: left;">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Task-aligned representations, scientific NLP</td>
<td style="text-align: left;">How can we automatically and accurately extract conceptual representations of scientific <br> knowledge, that are aligned with tasks that comprise the endeavor of science (Table 1)? How <br> can we build NLP models that understand full scientific papers?</td>
</tr>
<tr>
<td style="text-align: left;">Computational algebra of ideas</td>
<td style="text-align: left;">Can we build representations of scientific knowledge that support composition of ideas? e.g., <br> inferring the result of recombining two concepts.</td>
</tr>
<tr>
<td style="text-align: left;">Identifying conceptual relationships across <br> literature</td>
<td style="text-align: left;">How do we detect important relationships across scientific ideas, across related discussions <br> in different communities and areas? How can we resolve challenges of diversity, ambiguity, <br> and multiple levels of detail in scientific language?</td>
</tr>
<tr>
<td style="text-align: left;">Estimation of personal knowledge</td>
<td style="text-align: left;">How can we estimate the knowledge of a given researcher? What are useful, practical models <br> of this knowledge? What concepts does a researcher know, which of their aspects, and to <br> what technical extent? How do we account for latent knowledge?</td>
</tr>
<tr>
<td style="text-align: left;">Addressing gaps in knowledge</td>
<td style="text-align: left;">Given an estimated model of a researcher's knowledge, and given a specific task in Table 1, <br> what new knowledge would be useful for the task at hand?</td>
</tr>
<tr>
<td style="text-align: left;">Estimation of preferences, goals, interests</td>
<td style="text-align: left;">How can we estimate key latent preferences, interests and subjective utilities of researchers? <br> Using information in papers and discussions to infer factors behind researchers' choices.</td>
</tr>
<tr>
<td style="text-align: left;">Prediction and prioritization</td>
<td style="text-align: left;">How might we identify promising sparse/unexplored areas in large "spaces of ideas" and <br> prioritize directions that are novel, plausible and valuable?</td>
</tr>
<tr>
<td style="text-align: left;">Developing new representations for learning <br> and communicating</td>
<td style="text-align: left;">Might the way we read and write papers change to be more effective? Might we communicate <br> with machine-actionable, interlinked representations of scholarly knowledge. Might we <br> create personalized "living" documents that tailor their content to readers' backgrounds.</td>
</tr>
</tbody>
</table>
<p>Table 2: Directions with formulating and leveraging computational representations of scientific knowledge.
papers to estimate what concepts users know and to what extent. We envision mixed-initiative interfaces [12] in which approximations of the inner world are presented to researchers and refined in human-machine collaboration, to identify and fill personal gaps in knowledge for a specific task. Representations of interest and preference are central in web commerce based on user activity histories. We are encouraged by results highlighting the feasibility of rich user models, e.g., in search personalization [31, 35] and dynamic inferences [14]. Paul Samuelson wrote of "revealed preferences"preferences revealed indirectly by the economic price people are willing to pay; while not equivalent, researchers' digital traces may reveal preferences, e.g., by working on one problem and not another.</p>
<p>Prediction and prioritization of directions. Whenever we decide to work on a research direction, we are implicitly making a prediction about an area in "idea space". Can automated systems help make these predictions? This involves identifying promising areas and generating directions-hypotheses, ideas-in either natural or structured language, under constraints on users' background knowledge; directions should be ranked by estimated likelihood (feasibility, plausibility), utility and novelty. Despite the great challenges involved, we are encouraged by advances in models trained for predicting specific targets (e.g., protein structures [15]); we see potential in building on these advances as part of our wider agenda that considers the inner world of cognitive aspects and tasks, and the outer world outside the context of a narrow dataset.</p>
<p>Pursuing challenges of translation. Finally, we note challenges for introducing new technologies into scientific workflows. In the context of systems for discovery, researchers interviewed in our studies [29] reported being limited in time and resources, making them less likely to enter new areas and learn unfamiliar concepts, preventing them discovering potentially promising ideas. More broadly, the sociotechnical environment in which AI models
are deployed has critical impact on their success [13, 21]. A pertinent example comes via reports on difficulties with translating IBM's Watson Health systems into practice. The vision of the effort included systems providing insights about patients by mining research papers to suggest, e.g., therapies or diagnostics [21]. A prototype system faced difficulties ranging from data processing and availability problems to deeper perceived gaps between the system's understanding of literature and that of physicians [37]. Challenges such as these are fundamental to the fielding of new applications not only in healthcare but in any setting where humans are required to interact with AI systems [40]. While issues such as data quality and privacy are orthogonal to our agenda, we see directions in modeling of human needs and limitations to inform the design of human-AI experiences within scientific workflows.</p>
<h2>6 SUMMARY</h2>
<p>As the terrain of science widens at a fast pace, researchers are constrained by the limits of human cognition, and lack principled methods to follow developments, guide attention, and formulate and prioritize directions. For the first time in history, essentially all of scientific knowledge and discourse has moved into the digital space. At the time of this writing, dramatic advances in AI with large language models are taking place at breathtaking speed. These shifts present tremendous opportunities for leveraging scientific corpora as databases from which solutions, insights, and inspirations can be gleaned. We see opportunity ahead for systems that can address the imbalance between the treasure trove of scholarly information and researchers' limited ability to reach into it, harnessing humankind's collective knowledge to revolutionize the scientific process. Numerous challenges stand in the way of the vision we have laid out. However, even small steps forward will unlock vast opportunities for making advances at the frontiers of science.</p>
<h2>ACKNOWLEDGMENTS</h2>
<p>We thank the members of the Semantic Scholar team for stimulating discussions. Projects were supported by NSF Convergence Accelerator Grant 2132318, NSF RAPID grant 2040196, and ONR grant N00014-18-1-2193.</p>
<h2>REFERENCES</h2>
<p>[1] SÃ©bastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg, et al. Sparks of artificial general intelligence: Early experiments with GPT-4. arXiv preprint arXiv:2303.12712, 2023.
[2] Arie Cattan, Sophie Johnson, Daniel Weld, Ido Dagan, Iz Beltagy, Doug Downey, and Tom Hope. Scico: Hierarchical cross-document coreference for scientific concepts. Automated Knowledge Base Construction (AKBC) 2021, 2021.
[3] Joel Chan, Joseph Chee Chang, Tom Hope, Dafna Shahaf, and Aniket Kittur. Solvent: A mixed initiative system for finding analogies between research papers. Proceedings of the ACM on Human-Computer Interaction, 2(CSCW):1-21, 2018.
[4] Johan SG Chu and James A Evans. Slowed canonical progress in large fields of science. Proceedings of the National Academy of Sciences, 118(41), 2021.
[5] Cristina GarcÃ­a-Villar. A critical review on altmetrics: can we measure the social impact factor? Insights into Imaging, 12(1):1-10, 2021.
[6] Yolanda Gil. Will AI write scientific papers in the future? AI Magazine, 2022.
[7] Andrew Head, Kyle Lo, Dongyeop Kang, Raymond Fok, Sam Skjonsberg, Daniel S. Weld, and Marti A. Hearst. Augmenting scientific papers with just-in-time, position-sensitive definitions of terms and symbols. In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, 2021.
[8] Tom Hope, Joel Chan, Aniket Kittur, and Dafna Shahaf. Accelerating innovation through analogy mining. In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, 2017.
[9] Tom Hope, Jason Portenoy, Kishore Vasan, Jonathan Borchardt, Eric Horvitz, Daniel S Weld, Marti A Hearst, and Jevin West. Scisight: Combining faceted navigation and research group detection for covid-19 exploratory scientific search. In EMNLP, 2020.
[10] Tom Hope, Asla Amini, David Wadden, Madeleine van Zuylen, Sravanthi Parasa, Eric Horvitz, Daniel S Weld, Roy Schwartz, and Hannaneh Hajishirzi. Extracting a knowledge base of mechanisms from covid-19 papers. In NAACL, 2021.
[11] Tom Hope, Ronen Tamari, Hyeomu Kang, Daniel Hershcovich, Joel Chan, Aniket Kittur, and Dafna Shahaf. Scaling creative inspiration with fine-grained functional facets of product ideas. In CHI, 2022.
[12] Eric Horvitz. Principles of mixed-initiative user interfaces. In Proceedings of the SIGCHI conference on Human Factors in Computing Systems, pages 159-166, 1999.
[13] Eric Horvitz. The future of biomedical informatics: Bottlenecks and opportunities. In Biomedical Informatics: Computer Applications in Health Care and Biomedicine, E.H. Shortliffe, J.J. Cimino, et. al. Springer, 2021.
[14] Eric J Horvitz, John S Breese, David Heckerman, David Hovel, and Koos Rommelse. The Lumiere project: Bayesian user modeling for inferring the goals and needs of software users. In Proceedings of the Conference on Uncertainty in AI, pages 256-263, 1998.
[15] John Jumper, Richard Evans, Alexander Pritzel, Tim Green, Michael Figurnov, Olaf Ronneberger, Kathryn Tunyasuvunakool, Russ Bates, Augustin Å½idek, Anna Potapenko, et al. Highly accurate protein structure prediction with alphafold. Nature, 596(7873):583-589, 2021.
[16] Ross D King, Kenneth E Whelan, Ffion M Jones, Philip GK Reiser, Christopher H Bryant, Stephen H Muggleton, Douglas B Kell, and Stephen G Oliver. Functional genomic hypothesis generation and experimentation by a robot scientist. Nature, 427(6971):247-252, 2004.
[17] Thomas S Kuhn. The structure of scientific revolutions, volume 111. Chicago University of Chicago Press, 1970.
[18] D Lahav, JS Falcon, B Kuehl, S Johnson, S Parasa, N Shomron, DH Chau, D Yang, E Horvitz, DS Weld, and T Hope. A search engine for discovery of scientific challenges and directions. In AAAL 2022.
[19] Pat Langley, Herbert A Simon, Gary L Bradshaw, and Jan M Zytkow. Scientific discovery: Computational explorations of the creative processes. MIT press, 1987.
[20] Kyle Lo, Lucy Lu Wang, Mark Neumann, Rodney Kinney, and Daniel S. Weld. S2ORC: The Semantic Scholar Open Research Corpus. In Proceedings of ACL, 2020.
[21] Steve Lohr. What ever happened to ibm's watson. The New York Times, 16(7):21, 2021.
[22] Sonia Murthy, Kyle Lo, Chandra Bhagavatula, Daniel King, Bailey Kuehl, Sophie Johnson, Jonathan Borchardt, Daniel S. Weld, Tom Hope, and Doug Downey. Accord: A multi-document approach to generating diverse descriptions of scientific concepts. In EMNLP, 2022.
[23] Sheshera Mysore, Arman Cohan, and Tom Hope. Multi-vector models with textual guidance for fine-grained scientific document similarity. NAACL, 2022.
[24] Aakanksha Naik, Sravanthi Parasa, Sergey Feldman, Lucy Lu Wang, and Tom Hope. Literature-augmented clinical outcome prediction. NAACL, 2022.
[25] Harsha Nori, Nicholas King, Scott Mayer McKinney, Dean Carignan, and Eric Horvitz. Capabilities of GPT-4 on medical challenge problems. arXiv preprint arXiv:2303.13375, 2023.
[26] Regina Nuzzo et al. How scientists fool themselves-and how they can stop. Nature, 526(7572):182-185, 2015.
[27] Benjamin Nye, Jay DeYoung, Eric Lehman, Ani Nenkova, Iain J Marshall, and Byron C Wallace. Understanding clinical trial reports: Extracting medical entities and their relations. In AMIA Annual Symposium Proceedings, volume 2021, page 485. American Medical Informatics Association, 2021.
[28] OpenAI. Gpt-4 technical report, 2023.
[29] Jason Portenoy, Marissa Radensky, Jevin West, Eric Horvitz, Daniel Weld, and Tom Hope. Bridger: Toward bursting scientific filter bubbles and boosting innovation via novel author discovery. CHI, 2022.
[30] Edward O Pyser-Knapp, Jed W Pitera, Peter WJ Staar, Seiji Takeda, Teodoro Laino, Daniel P Sanders, James Sexton, John R Smith, and Alessandro Curioni. Accelerating materials discovery using artificial intelligence, high performance computing and robotics. npj Computational Materials, 8(1):1-9, 2022.
[31] Chirag Shah and Emily M Bender. Situating search. In ACM SIGIR Conference on Human Information Interaction and Retrieval, pages 221-232, 2022.
[32] Uriel Singer, Kira Radinsky, and Eric Horvitz. On biases of attention in scientific discovery. Bioinformatics, 12 2020. URL https://doi.org/10.1093/bioinformatics/ btaa1036.
[33] D. R. Swanson. Fish oil, raynaud's syndrome, and undiscovered public knowledge. Perspectives in Biology and Medicine, 30(1):7-18, 1986.
[34] Hillel Taub Tabib, Micali Shl aim, Shoval Sadde, Dan Lahav, Matan Eyal, Yaara Cohen, and Yoav Goldberg. Interactive extractive search over biomedical corpora. In Proceedings of the 19th SIGBioMed Workshop on Biomedical Language Processing, pages 28-37, Online, July 2020. Association for Computational Linguistics. doi: 10.18653/v1:2020.biomlp-1.3. URL https://aclanthology.org/2020.biomlp-1.3.
[35] Jaime Teevan, Susan T Dumais, and Eric Horvitz. Personalizing search via automated analysis of interests and activities. In Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrieval, pages 449-456, 2005.
[36] Paul Thagard. The cognitive science of science: Explanation, discovery, and conceptual change. Mit Press, 2012.
[37] Aish Thamba and Richard B Gunderman. For watson, solving cancer wasn't so elementary: Prospects for artificial intelligence in radiology. Academic Radiology, 29(2):312-314, 2022.
[38] Daril A Vilhena, Jacob G Foster, Martin Rosvall, Jevin D West, James Evans, and Carl T Bergstrom. Finding cultural holes: How structure and culture diverge in networks of scholarly communication. Sociological Science, 1:221, 2014.
[39] Yu Wang, Jinchao Li, Tristan Naumann, Chenyan Xiong, Hao Cheng, Robert Tinn, Cliff Wong, Naoto Usuyama, Richard Rogahn, Zhihong Shen, et al. Domainspecific pretraining for vertical search: Case study on biomedical literature. In Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery \&amp; Data Mining, pages 3717-3725, 2021.
[40] Daniel S Weld and Gagan Bansal. The challenge of crafting intelligible intelligence. Communications of the ACM, 62(6):70-79, 2019.</p>            </div>
        </div>

    </div>
</body>
</html>