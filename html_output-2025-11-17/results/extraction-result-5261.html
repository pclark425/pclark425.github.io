<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-5261 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-5261</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-5261</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-109.html">extraction-schema-109</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <p><strong>Paper ID:</strong> paper-3485829</p>
                <p><strong>Paper Title:</strong> Linking Neural and Symbolic Representation and Processing of Conceptual Structures</p>
                <p><strong>Paper Abstract:</strong> We compare and discuss representations in two cognitive architectures aimed at representing and processing complex conceptual (sentence-like) structures. First is the Neural Blackboard Architecture (NBA), which aims to account for representation and processing of complex and combinatorial conceptual structures in the brain. Second is IDyOT (Information Dynamics of Thinking), which derives sentence-like structures by learning statistical sequential regularities over a suitable corpus. Although IDyOT is designed at a level more abstract than the neural, so it is a model of cognitive function, rather than neural processing, there are strong similarities between the composite structures developed in IDyOT and the NBA. We hypothesize that these similarities form the basis of a combined architecture in which the individual strengths of each architecture are integrated. We outline and discuss the characteristics of this combined architecture, emphasizing the representation and processing of conceptual structures.</p>
                <p><strong>Cost:</strong> 0.019</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e5261.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e5261.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>NBA</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Neural Blackboard Architecture</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A neural-level cognitive architecture that represents concepts as distributed in-situ assemblies and composes them by building temporary connection paths (neural blackboards) via gated binding circuits and working-memory populations to form combinatorial structures such as sentences and relations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Linking Neural and Symbolic Representation and Processing of Conceptual Structures</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Neural Blackboard Architecture (NBA)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Conceptual knowledge is stored in content-addressable, distributed 'in situ' neural assemblies that cannot be copied; compositional structures (e.g., sentences) are represented functionally as temporally-constructed connection paths in dedicated neural blackboards, implemented by structure assemblies, sub-assemblies, gated conditional connections, and working-memory binding populations.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>distributed in-situ assemblies with explicit workspace/blackboard bindings (hybrid: distributed + symbolic structural elements)</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>content-addressability; in-situ distribution across cortical areas; compositionality achieved via temporary connection paths; use of gated conditional connections; binding via sustained WM activity; specialized domain blackboards (sentence, phonological, relations); small-world hub/sub-hub topology to enable flexible interconnectivity.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Matches several empirical observations cited: Huth et al. (2016) semantic maps consistent with distributed assemblies; intracranial binding dynamics (Nelson et al., 2014) mirrored by NBA simulated activation increases then decreases during binding; fMRI evidence of agent/theme specialization (Frankland & Greene, 2015) consistent with specialised connection fields.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>The NBA is a mechanistic proposal whose detailed neural instantiation and direct mapping to all neurophysiological data remain to be fully validated; because representations are 'in situ' the mechanism for simultaneously representing repeated tokens (the 'problem of two') is resolved functionally but requires empirical tests of concurrent multi-role activation of the same neural assembly.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Sentence comprehension and production, phonological composition, reasoning with relations, ambiguity resolution, question answering (e.g., retrieval of sentence constituents), and proposals for hardware-parallel implementations.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Contrasted with purely symbolic architectures and with connectionist distributed representations: unlike symbol copying/variable-token models (e.g., classic symbolic variable binding), NBA preserves in-situ representations and achieves compositionality via blackboard bindings; compared to deep nets, NBA emphasizes explicit combinatorial binding and structured workspace dynamics rather than end-to-end learned distributed encodings.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Formation of compositional structure by (1) activating in-situ concept assemblies; (2) opening gated conditional connections via control circuits or WM populations (disinhibition) to create temporary connection paths; (3) sustaining bindings with reverberatory WM populations; (4) control reservoirs/sequences steer construction and parsing of structures; connection matrices provide dedicated connection nodes for specific role bindings (e.g., agent/theme).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>How exactly structure assemblies develop from experience (paper proposes learning via IDyOT integration); precise neural correlates of every NBA element need empirical localization and validation; scalability and learning of blackboard structure for diverse languages/domains; biophysical plausibility of gating/disinhibition dynamics at required scale remains to be fully demonstrated.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Linking Neural and Symbolic Representation and Processing of Conceptual Structures', 'publication_date_yy_mm': '2017-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5261.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e5261.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>IDyOT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Information Dynamics of Thinking</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A functional, symbolic cognitive architecture that incrementally learns hierarchical, chunked, symbolic representations from sequential data via prediction-driven chunking and that grounds symbols in continuous conceptual spaces to provide semantics.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Linking Neural and Symbolic Representation and Processing of Conceptual Structures</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Information Dynamics of Thinking (IDyOT)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Conceptual knowledge is represented as a hierarchy of learned symbols where each higher-level symbol subtends a sequence (chunk) of lower-level symbols; symbols acquire semantics by being associated with points/regions in low-dimensional conceptual spaces derived from perceptual input, and the system optimizes representations for information-efficiency (predictive accuracy).</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>symbolic hierarchical chunking grounded in continuous conceptual spaces (hybrid: symbolic + geometric continuous semantics)</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>incremental learning and chunking; prediction-driven boundary detection via changes in entropy; multi-layered Markovian transition models at each abstraction level; symbols correspond to regions/points in conceptual spaces; grounding/tethering to sensory modalities; simultaneous optimization of representation and sequential models for predictive efficiency.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Built on computational and empirical principles from statistical learning (citations: Pearce/IDyOM work), evidence for perceptual chunking and boundary detection in music and language (Brent, Pearce et al.) motivate mechanisms; the architecture produces structural representations comparable to sentence structure and can generate predictions that align with human incremental processing phenomena.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>As a high-level cognitive model, direct neurophysiological validation is limited; dependency of learned symbol meanings on input order (history dependence) implies retrospective re-optimization (consolidation) that needs empirical study; computational scaling of viewpoint combinatorics and linking across multiple modalities remains challenging.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Sequence prediction and chunking in language and music, incremental parsing, concept creation from corpora, modeling of timing and expectancy in perception, and as a proposed mechanism for learning structural elements for neural blackboards.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Implements Baars' Global Workspace at a functional level and contrasts with opaque deep learning by providing explicable symbols grounded in perception; compared to purely statistical sequence models (n-gram/ deep nets) it enforces explicit symbol generation and hierarchical abstraction with geometric semantics.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Multiple generators sample from first-order (and layered) Markov models to predict next symbols; when a generator's match produces a maximal increase in uncertainty (entropy), its current chunk gets flushed into the global workspace and stored as a higher-level symbol; conceptual spaces are partitioned (Voronoi) and regions modulated by expectation to tether perception to symbols; consolidation periodically re-optimizes categorizations.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>How to efficiently manage viewpoint combinatorial explosion; how conceptual space geometries are reliably learned from multimodal data; how consolidation schedules and parameters (e.g., gap size, entropy thresholds) map to biological processes; empirical tests relating IDyOT's symbols and dynamics to brain activity are still to be completed (motivates integration with NBA).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Linking Neural and Symbolic Representation and Processing of Conceptual Structures', 'publication_date_yy_mm': '2017-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5261.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e5261.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ConceptualSpaces</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Conceptual Spaces (Gärdenfors)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A geometric framework where concepts are points or regions in low-dimensional spaces with interpretable dimensions, enabling similarity, betweenness, and compositional structure to be expressed geometrically.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Conceptual Spaces: The Geometry of Thought</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Conceptual Spaces</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Concepts are represented as regions/points in structured geometric spaces (conceptual spaces) whose dimensions correspond to interpretable quality dimensions drawn from perception; similarity and category structure are modeled via geometric relations (e.g., distance, convex regions).</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>geometric/continuous prototype-like representation (regions/points in metric spaces)</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>interpretable dimensions; low-dimensional geometric structure; similarity as distance; capacity to represent prototypes, category regions, and mappings between trajectories (sequences) and higher-level points via spectral or other transformations.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Used broadly as a semantics for grounded symbol systems; cited in the paper as providing semantics for IDyOT symbols and as consistent with distributional-to-conceptual-space methods (McGregor et al., 2015); provides an account for multi-modal grounding and similarity judgments observed behaviorally.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Requires identification of appropriate dimensions and metrics for different modalities; empirical derivation of spaces from data is non-trivial and domain-dependent; mapping between temporal trajectories and single points (for higher-level symbols) is a methodological challenge.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Semantic representation, categorization, concept creation, grounding of symbols in perception, and as semantic substrate for hierarchical chunking models like IDyOT.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Offers an interpretable alternative to high-dimensional distributional embeddings and to purely symbolic semantics by providing continuous geometric structure; can be combined with symbolic architectures to yield hybrid representational systems.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Similarity and category membership determined by geometric relations; mapping of lower-level temporal trajectories to higher-level points via spectral transforms or summarization; regions modulated by expectations for perceptual disambiguation (as used in IDyOT).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>How to derive canonical dimensions automatically from large-scale multimodal data; how to represent complex relational or combinatorial structure purely geometrically; operationalization of conceptual spaces for real-time incremental learning.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Linking Neural and Symbolic Representation and Processing of Conceptual Structures', 'publication_date_yy_mm': '2017-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5261.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e5261.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GWT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Global Workspace Theory (Baars)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A cognitive-level theory proposing a central workspace that broadcasts information to multiple specialized processors, enabling conscious access and flexible integration of diverse cognitive contents.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>A Cognitive Theory of Consciousness</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Global Workspace Theory (GWT)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>At the functional level, cognitive processing involves many specialized generators/processors whose outputs compete for access to a global workspace; contents that gain access are broadcast and become available for coordinated processing, enabling integration, serial report, and flexible behavior.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>workspace-mediated symbolic/representational broadcasting (functional workspace model)</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>competition among specialized processors; episodic/global broadcasting of winning representations; serial bottleneck for conscious access; integration of multimodal information via workspace.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>GWT has been used as a high-level functional basis for IDyOT implementation; phenomena of broadcast-like activation and competition in neural data are often interpreted in GWT terms, and the workspace metaphor guides the chunk-flushing mechanism of IDyOT.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Operationalizing the workspace in neural terms is contentious; multiple neural instantiations and alternative theories of consciousness exist; direct tests differentiating GWT from other models can be difficult.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Conscious report, attention, integration across modalities, architecture-level models of cognition (e.g., IDyOT implementing GWT), and models of creativity and spontaneous generation.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Contrasts with strictly parallel distributed processing views by emphasizing a central access/broadcast mechanism; compatible functionally with architectures that implement a mediating workspace (e.g., blackboards) but differs from models lacking explicit broadcast/competition dynamics.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Competition among generators based on information metrics; activation of a winning chunk into the workspace where it is available to other processes; replay/storage in memory and update of predictive models.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>How the workspace is implemented neurally (which regions and dynamics) and how exactly broadcasting occurs in distributed systems; granularity of what constitutes a workspace token across domains.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Linking Neural and Symbolic Representation and Processing of Conceptual Structures', 'publication_date_yy_mm': '2017-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5261.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e5261.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>In-situAssemblies</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>In-situ Neural Assemblies (Hebbian-derived concept assemblies)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A functional description that concepts are encoded by distributed assemblies of neurons across sensory, motor, and associative areas that are content-addressable and cannot be freely copied; meaning arises from both incoming and outgoing connectivity patterns.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>The Organisation of Behaviour</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>In-situ Neural Assembly (Hebbian assembly)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Concepts are represented by distributed networks of neurons (assemblies) formed through learning; these assemblies are activated in their entirety (or parts) when the concept is tokened and are content-addressable by sensory cues, with meaning determined by patterns of both afferent and efferent connections.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>distributed assembly representation (connection-based, non-copyable tokens)</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>distributed over multiple cortical areas; content-addressable activation; integration of perception, action, affect; assemblies grow and refine with experience; not fungible tokens that can be copied arbitrarily.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Consistent with single-unit findings (e.g., Quian Quiroga concept cells), large-scale semantic maps (Huth et al., 2016) showing distributed semantic regions, and behavioral grounding of concepts in perception and action.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>How assemblies support simultaneous multi-role instantiation without explicit token copies (NBA proposes binding mechanisms); need to link assembly-level descriptions to precise temporal dynamics observed in electrophysiology and fMRI.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Semantic memory, object and word recognition, grounding of language in sensorimotor systems, and as a basis for architectures like NBA that require in-situ representations.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Differs from token-copy symbolic accounts (which assume discrete, movable symbols) and from purely connectionist dense vector representations; emphasizes explicit role of connectivity and action-perception links.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Meaning arises from activation patterns across sensory and motor networks and from how assemblies influence downstream processing; assemblies are activated by partial cues (content-addressability) and participate in behavior by activating action networks.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>Precise mechanisms for combinatorial composition with in-situ assemblies; scalability of forming distinct assemblies for large vocabularies; how assemblies map onto observed fMRI/timeseries data at multiple timescales.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Linking Neural and Symbolic Representation and Processing of Conceptual Structures', 'publication_date_yy_mm': '2017-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5261.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e5261.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Huth2016</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Natural speech reveals the semantic maps that tile human cerebral cortex</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>fMRI evidence showing distributed semantic tuning across many cortical areas during natural speech comprehension, organized into semantic domains that tile cortex consistently across subjects.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Natural speech reveals the semantic maps that tile human cerebral cortex</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Cortical semantic maps (Huth et al., 2016)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Semantic content of words evokes activation in a tiled mosaic of cortical regions, each selective for semantic domains; these distributed representations support the idea of concept representations being spread across cortex in content-addressable assemblies.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>distributed semantic maps (topographic domain tiling)</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>large-scale distributed semantic selectivity; multiple cortical tiles each corresponding to semantic domains; consistency across subjects; involvement of both hemispheres.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Analysis of fMRI responses to natural speech across subjects, clustering words into semantic domains and mapping responsiveness across cortical areas; shows distributed and domain-structured semantic representation.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>fMRI spatial resolution and hemodynamic sluggishness limit temporal claims; mapping semantics to tiles does not specify microcircuit-level mechanisms; semantics may interact with tasks/context in ways not captured by passive listening.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Semantic mapping, language comprehension, informing architectures that posit distributed concept assemblies (e.g., NBA), and studies relating distributed cortical patterns to meaning.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Supports distributed/in-situ assembly views over strictly localized modular accounts; complements conceptual spaces approaches by providing cortical localization of semantic domains.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Shows where in cortex different semantic domains are represented; implies that activation of a concept invokes a pattern across multiple tiles depending on context.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>How these mapped regions correspond to dynamically formed assemblies and to temporal binding during compositional processing; how individual variability and task demands modify the maps.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Linking Neural and Symbolic Representation and Processing of Conceptual Structures', 'publication_date_yy_mm': '2017-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5261.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e5261.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Nelson2014</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Constituent structure representations revealed with intracranial data</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Intracranial recordings indicating that binding of words and phrases produces temporally-localized increases and then decreases in neural activity during sentence processing.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Constituent structure representations revealed with intracranial data</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Intracranial evidence for binding dynamics (Nelson et al., 2014)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Electrophysiological recordings from intracranial electrodes reveal transient activity increases during the binding of words/phrases followed by decreases, reflecting the temporal dynamics of constructing constituent structure.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>temporal dynamic markers of composition (event-related electrophysiology)</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>binding-related transient activation peaks; activity reduction after binding; constituent-sensitive temporal profiles.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Intracranial data showing peaks of activity aligned with word presentation and subsequent drops associated with binding events during sentence comprehension (poster presentation cited in paper).</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Poster-level evidence referenced; generalization across tasks/subjects requires more data; linking these dynamics to specific representational mechanisms (e.g., NBA structure assemblies) needs targeted experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Temporal dynamics of sentence parsing, constituent formation, and validation of models predicting binding-related neural signatures.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Provides time-resolved signatures that NBA simulations reproduce (authors claim), supporting architectures that posit discrete binding events over continuous distributed accumulation-only models.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Binding events temporally modulate neural activity—initial activation by input followed by reduced activity when binding stabilizes—consistent with WM-mediated binding and disinhibition mechanisms in NBA.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>Extent to which these signatures are universal across languages, sentence structures, and tasks; mapping of particular intracranial sites to specific role-binding operations.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Linking Neural and Symbolic Representation and Processing of Conceptual Structures', 'publication_date_yy_mm': '2017-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5261.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e5261.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Frankland2015</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>An architecture for encoding sentence meaning in left mid-superior temporal cortex</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>fMRI evidence pointing to cortical regions encoding sentence-level meaning and showing differential activation patterns when nouns serve as agents versus themes, suggesting role-specific representations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>An architecture for encoding sentence meaning in left mid-superior temporal cortex</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Agent/theme specialization in cortex (Frankland & Greene, 2015)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Specific cortical subregions exhibit selective activation patterns depending on the thematic role (e.g., agent vs. theme) nouns play within sentence meaning representations, implying specialized fields for relational roles.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>role-sensitive regional activations (functional localization of role representations)</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>role-selective cortical activations; sentence-meaning encoding at the phrase/clause level; representational differentiation by thematic role.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>fMRI decoding analyses showing separable patterns in left mid-superior temporal cortex for agent vs theme roles during sentence processing.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>fMRI limitations again restrict micro-mechanistic claims; how role-selective regions interact with distributed assemblies or blackboards needs elaboration.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Sentence comprehension, semantic-role representation, informing models that posit specialized connection fields (e.g., NBA connection matrices for agent/theme binding).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Supports NBA prediction of connection fields specialized for roles (agent/theme); complements distributed assembly accounts by indicating role-sensitive cortical substrates.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Indicates that thematic role information is encoded in localized patterns which could serve as hubs/fields for binding operations in architectures that implement role-mediated composition.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>Causal role of these regions in role assignment and binding; temporal dynamics of role encoding and how role representations interact with memory/binding mechanisms.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Linking Neural and Symbolic Representation and Processing of Conceptual Structures', 'publication_date_yy_mm': '2017-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5261.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e5261.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>QuianQuiroga2012</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Concept cells: the building blocks of declarative memory functions</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Single-unit recordings demonstrating sparse, invariant neurons that respond selectively to high-level concepts (e.g., a person's face or name), supporting a content-addressable, concept-linked neuronal representation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Concept cells: the building blocks of declarative memory functions</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Concept cells / sparse invariant neurons</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Certain neurons exhibit highly selective and invariant responses to abstracted concepts (e.g., specific people, landmarks), suggesting neuron-level elements that participate in distributed but content-addressable conceptual representations.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>sparse, invariant unit-level representation embedded in distributed networks</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>selectivity and invariance across modalities (e.g., face and name); suggests a sparse code embedded in broader assemblies; supports content-addressability.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Intracranial single-unit recordings in human medial temporal cortex showing neurons selective for specific persons/objects across stimuli variations.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Interpretation of 'concept cell' as sole representational unit is debated; doesn't preclude distributed assemblies spanning many neurons/areas; how concept cells integrate into compositional structures is not directly shown.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Models of declarative memory, indexing of concepts across modalities, evidence base for content-addressable representations used by NBA and IDyOT grounding claims.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Provides micro-level evidence compatible with in-situ assembly accounts and constrains purely distributed dense-vector-only models by showing sparsity/invariance elements.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Concept activation can be triggered by partial cues and binds to downstream processing, contributing to retrieval and recognition.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>Generality across cortical areas and concepts; role in combinatorial composition and sentence-level processing; how these sparse units relate to conceptual spaces.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Linking Neural and Symbolic Representation and Processing of Conceptual Structures', 'publication_date_yy_mm': '2017-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5261.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e5261.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Chunking</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Perceptual Chunking / Information-driven boundary detection</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A functional principle where sequences are segmented into chunks based on prediction and information-theoretic criteria (entropy changes), forming the basis of hierarchical symbolic representations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Linking Neural and Symbolic Representation and Processing of Conceptual Structures</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Perceptual Chunking driven by predictive entropy (IDyOT principle)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Sequential input is parsed into chunks when predictions and their entropy-change profiles indicate a boundary (agents compete and the largest positive entropy change determines chunking), producing higher-level symbols that subtend sequences and form hierarchical memory.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>hierarchical symbolic chunks grounded in continuous input (symbolic + probabilistic)</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>entropy-based boundary detection; competition of predictors (generators); hierarchical abstraction by recursively chunking sequences; chunk labels linked to conceptual-space regions.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Inspired by computational linguistics and music perception studies showing boundary detection sensitivity to statistical regularities (cited: Brent, Pearce, Sproat, Rohrmeier); matches observed perceptual segmentation phenomena.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Parameter choices (entropy thresholds, gap sizes) and generator designs influence segmentation; human chunking is influenced by semantics, attention and task which need to be integrated explicitly.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Word segmentation, phrase boundary detection in language, musical phrase segmentation, incremental parsing and memory formation in cognitive models.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other models</strong></td>
                            <td>Differs from fixed-grammar parsing and from purely supervised segmentation by using unsupervised, prediction-driven, information-theoretic criteria; complementary to statistical sequence models but produces explicit chunk symbols with geometric grounding.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Generators predict next symbols from Markov models; when a prediction match causes the largest increase in entropy, that generator's chunk is committed to workspace and becomes a higher-level symbol; repeated application creates hierarchical abstraction.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>Mapping of chunking dynamics to neural mechanisms; robustness across noisy and multimodal inputs; how chunking interfaces with top-down semantics and task demands.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Linking Neural and Symbolic Representation and Processing of Conceptual Structures', 'publication_date_yy_mm': '2017-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Neural blackboard architectures of combinatorial structures in cognition <em>(Rating: 2)</em></li>
                <li>Learning of control in a neural architecture of grounded language processing <em>(Rating: 2)</em></li>
                <li>IDyOT: a computational theory of creativity as everyday reasoning from learned information <em>(Rating: 2)</em></li>
                <li>Natural speech reveals the semantic maps that tile human cerebral cortex <em>(Rating: 2)</em></li>
                <li>Concept cells: the building blocks of declarative memory functions <em>(Rating: 2)</em></li>
                <li>An architecture for encoding sentence meaning in left mid-superior temporal cortex <em>(Rating: 2)</em></li>
                <li>From distributional semantics to conceptual spaces: a novel computational method for concept creation <em>(Rating: 1)</em></li>
                <li>The Organisation of Behaviour <em>(Rating: 1)</em></li>
                <li>A Cognitive Theory of Consciousness <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-5261",
    "paper_id": "paper-3485829",
    "extraction_schema_id": "extraction-schema-109",
    "extracted_data": [
        {
            "name_short": "NBA",
            "name_full": "Neural Blackboard Architecture",
            "brief_description": "A neural-level cognitive architecture that represents concepts as distributed in-situ assemblies and composes them by building temporary connection paths (neural blackboards) via gated binding circuits and working-memory populations to form combinatorial structures such as sentences and relations.",
            "citation_title": "Linking Neural and Symbolic Representation and Processing of Conceptual Structures",
            "mention_or_use": "use",
            "theory_or_model_name": "Neural Blackboard Architecture (NBA)",
            "theory_or_model_description": "Conceptual knowledge is stored in content-addressable, distributed 'in situ' neural assemblies that cannot be copied; compositional structures (e.g., sentences) are represented functionally as temporally-constructed connection paths in dedicated neural blackboards, implemented by structure assemblies, sub-assemblies, gated conditional connections, and working-memory binding populations.",
            "representation_format_type": "distributed in-situ assemblies with explicit workspace/blackboard bindings (hybrid: distributed + symbolic structural elements)",
            "key_properties": "content-addressability; in-situ distribution across cortical areas; compositionality achieved via temporary connection paths; use of gated conditional connections; binding via sustained WM activity; specialized domain blackboards (sentence, phonological, relations); small-world hub/sub-hub topology to enable flexible interconnectivity.",
            "empirical_support": "Matches several empirical observations cited: Huth et al. (2016) semantic maps consistent with distributed assemblies; intracranial binding dynamics (Nelson et al., 2014) mirrored by NBA simulated activation increases then decreases during binding; fMRI evidence of agent/theme specialization (Frankland & Greene, 2015) consistent with specialised connection fields.",
            "empirical_challenges": "The NBA is a mechanistic proposal whose detailed neural instantiation and direct mapping to all neurophysiological data remain to be fully validated; because representations are 'in situ' the mechanism for simultaneously representing repeated tokens (the 'problem of two') is resolved functionally but requires empirical tests of concurrent multi-role activation of the same neural assembly.",
            "applied_domains_or_tasks": "Sentence comprehension and production, phonological composition, reasoning with relations, ambiguity resolution, question answering (e.g., retrieval of sentence constituents), and proposals for hardware-parallel implementations.",
            "comparison_to_other_models": "Contrasted with purely symbolic architectures and with connectionist distributed representations: unlike symbol copying/variable-token models (e.g., classic symbolic variable binding), NBA preserves in-situ representations and achieves compositionality via blackboard bindings; compared to deep nets, NBA emphasizes explicit combinatorial binding and structured workspace dynamics rather than end-to-end learned distributed encodings.",
            "functional_mechanisms": "Formation of compositional structure by (1) activating in-situ concept assemblies; (2) opening gated conditional connections via control circuits or WM populations (disinhibition) to create temporary connection paths; (3) sustaining bindings with reverberatory WM populations; (4) control reservoirs/sequences steer construction and parsing of structures; connection matrices provide dedicated connection nodes for specific role bindings (e.g., agent/theme).",
            "limitations_or_open_questions": "How exactly structure assemblies develop from experience (paper proposes learning via IDyOT integration); precise neural correlates of every NBA element need empirical localization and validation; scalability and learning of blackboard structure for diverse languages/domains; biophysical plausibility of gating/disinhibition dynamics at required scale remains to be fully demonstrated.",
            "uuid": "e5261.0",
            "source_info": {
                "paper_title": "Linking Neural and Symbolic Representation and Processing of Conceptual Structures",
                "publication_date_yy_mm": "2017-08"
            }
        },
        {
            "name_short": "IDyOT",
            "name_full": "Information Dynamics of Thinking",
            "brief_description": "A functional, symbolic cognitive architecture that incrementally learns hierarchical, chunked, symbolic representations from sequential data via prediction-driven chunking and that grounds symbols in continuous conceptual spaces to provide semantics.",
            "citation_title": "Linking Neural and Symbolic Representation and Processing of Conceptual Structures",
            "mention_or_use": "use",
            "theory_or_model_name": "Information Dynamics of Thinking (IDyOT)",
            "theory_or_model_description": "Conceptual knowledge is represented as a hierarchy of learned symbols where each higher-level symbol subtends a sequence (chunk) of lower-level symbols; symbols acquire semantics by being associated with points/regions in low-dimensional conceptual spaces derived from perceptual input, and the system optimizes representations for information-efficiency (predictive accuracy).",
            "representation_format_type": "symbolic hierarchical chunking grounded in continuous conceptual spaces (hybrid: symbolic + geometric continuous semantics)",
            "key_properties": "incremental learning and chunking; prediction-driven boundary detection via changes in entropy; multi-layered Markovian transition models at each abstraction level; symbols correspond to regions/points in conceptual spaces; grounding/tethering to sensory modalities; simultaneous optimization of representation and sequential models for predictive efficiency.",
            "empirical_support": "Built on computational and empirical principles from statistical learning (citations: Pearce/IDyOM work), evidence for perceptual chunking and boundary detection in music and language (Brent, Pearce et al.) motivate mechanisms; the architecture produces structural representations comparable to sentence structure and can generate predictions that align with human incremental processing phenomena.",
            "empirical_challenges": "As a high-level cognitive model, direct neurophysiological validation is limited; dependency of learned symbol meanings on input order (history dependence) implies retrospective re-optimization (consolidation) that needs empirical study; computational scaling of viewpoint combinatorics and linking across multiple modalities remains challenging.",
            "applied_domains_or_tasks": "Sequence prediction and chunking in language and music, incremental parsing, concept creation from corpora, modeling of timing and expectancy in perception, and as a proposed mechanism for learning structural elements for neural blackboards.",
            "comparison_to_other_models": "Implements Baars' Global Workspace at a functional level and contrasts with opaque deep learning by providing explicable symbols grounded in perception; compared to purely statistical sequence models (n-gram/ deep nets) it enforces explicit symbol generation and hierarchical abstraction with geometric semantics.",
            "functional_mechanisms": "Multiple generators sample from first-order (and layered) Markov models to predict next symbols; when a generator's match produces a maximal increase in uncertainty (entropy), its current chunk gets flushed into the global workspace and stored as a higher-level symbol; conceptual spaces are partitioned (Voronoi) and regions modulated by expectation to tether perception to symbols; consolidation periodically re-optimizes categorizations.",
            "limitations_or_open_questions": "How to efficiently manage viewpoint combinatorial explosion; how conceptual space geometries are reliably learned from multimodal data; how consolidation schedules and parameters (e.g., gap size, entropy thresholds) map to biological processes; empirical tests relating IDyOT's symbols and dynamics to brain activity are still to be completed (motivates integration with NBA).",
            "uuid": "e5261.1",
            "source_info": {
                "paper_title": "Linking Neural and Symbolic Representation and Processing of Conceptual Structures",
                "publication_date_yy_mm": "2017-08"
            }
        },
        {
            "name_short": "ConceptualSpaces",
            "name_full": "Conceptual Spaces (Gärdenfors)",
            "brief_description": "A geometric framework where concepts are points or regions in low-dimensional spaces with interpretable dimensions, enabling similarity, betweenness, and compositional structure to be expressed geometrically.",
            "citation_title": "Conceptual Spaces: The Geometry of Thought",
            "mention_or_use": "mention",
            "theory_or_model_name": "Conceptual Spaces",
            "theory_or_model_description": "Concepts are represented as regions/points in structured geometric spaces (conceptual spaces) whose dimensions correspond to interpretable quality dimensions drawn from perception; similarity and category structure are modeled via geometric relations (e.g., distance, convex regions).",
            "representation_format_type": "geometric/continuous prototype-like representation (regions/points in metric spaces)",
            "key_properties": "interpretable dimensions; low-dimensional geometric structure; similarity as distance; capacity to represent prototypes, category regions, and mappings between trajectories (sequences) and higher-level points via spectral or other transformations.",
            "empirical_support": "Used broadly as a semantics for grounded symbol systems; cited in the paper as providing semantics for IDyOT symbols and as consistent with distributional-to-conceptual-space methods (McGregor et al., 2015); provides an account for multi-modal grounding and similarity judgments observed behaviorally.",
            "empirical_challenges": "Requires identification of appropriate dimensions and metrics for different modalities; empirical derivation of spaces from data is non-trivial and domain-dependent; mapping between temporal trajectories and single points (for higher-level symbols) is a methodological challenge.",
            "applied_domains_or_tasks": "Semantic representation, categorization, concept creation, grounding of symbols in perception, and as semantic substrate for hierarchical chunking models like IDyOT.",
            "comparison_to_other_models": "Offers an interpretable alternative to high-dimensional distributional embeddings and to purely symbolic semantics by providing continuous geometric structure; can be combined with symbolic architectures to yield hybrid representational systems.",
            "functional_mechanisms": "Similarity and category membership determined by geometric relations; mapping of lower-level temporal trajectories to higher-level points via spectral transforms or summarization; regions modulated by expectations for perceptual disambiguation (as used in IDyOT).",
            "limitations_or_open_questions": "How to derive canonical dimensions automatically from large-scale multimodal data; how to represent complex relational or combinatorial structure purely geometrically; operationalization of conceptual spaces for real-time incremental learning.",
            "uuid": "e5261.2",
            "source_info": {
                "paper_title": "Linking Neural and Symbolic Representation and Processing of Conceptual Structures",
                "publication_date_yy_mm": "2017-08"
            }
        },
        {
            "name_short": "GWT",
            "name_full": "Global Workspace Theory (Baars)",
            "brief_description": "A cognitive-level theory proposing a central workspace that broadcasts information to multiple specialized processors, enabling conscious access and flexible integration of diverse cognitive contents.",
            "citation_title": "A Cognitive Theory of Consciousness",
            "mention_or_use": "use",
            "theory_or_model_name": "Global Workspace Theory (GWT)",
            "theory_or_model_description": "At the functional level, cognitive processing involves many specialized generators/processors whose outputs compete for access to a global workspace; contents that gain access are broadcast and become available for coordinated processing, enabling integration, serial report, and flexible behavior.",
            "representation_format_type": "workspace-mediated symbolic/representational broadcasting (functional workspace model)",
            "key_properties": "competition among specialized processors; episodic/global broadcasting of winning representations; serial bottleneck for conscious access; integration of multimodal information via workspace.",
            "empirical_support": "GWT has been used as a high-level functional basis for IDyOT implementation; phenomena of broadcast-like activation and competition in neural data are often interpreted in GWT terms, and the workspace metaphor guides the chunk-flushing mechanism of IDyOT.",
            "empirical_challenges": "Operationalizing the workspace in neural terms is contentious; multiple neural instantiations and alternative theories of consciousness exist; direct tests differentiating GWT from other models can be difficult.",
            "applied_domains_or_tasks": "Conscious report, attention, integration across modalities, architecture-level models of cognition (e.g., IDyOT implementing GWT), and models of creativity and spontaneous generation.",
            "comparison_to_other_models": "Contrasts with strictly parallel distributed processing views by emphasizing a central access/broadcast mechanism; compatible functionally with architectures that implement a mediating workspace (e.g., blackboards) but differs from models lacking explicit broadcast/competition dynamics.",
            "functional_mechanisms": "Competition among generators based on information metrics; activation of a winning chunk into the workspace where it is available to other processes; replay/storage in memory and update of predictive models.",
            "limitations_or_open_questions": "How the workspace is implemented neurally (which regions and dynamics) and how exactly broadcasting occurs in distributed systems; granularity of what constitutes a workspace token across domains.",
            "uuid": "e5261.3",
            "source_info": {
                "paper_title": "Linking Neural and Symbolic Representation and Processing of Conceptual Structures",
                "publication_date_yy_mm": "2017-08"
            }
        },
        {
            "name_short": "In-situAssemblies",
            "name_full": "In-situ Neural Assemblies (Hebbian-derived concept assemblies)",
            "brief_description": "A functional description that concepts are encoded by distributed assemblies of neurons across sensory, motor, and associative areas that are content-addressable and cannot be freely copied; meaning arises from both incoming and outgoing connectivity patterns.",
            "citation_title": "The Organisation of Behaviour",
            "mention_or_use": "mention",
            "theory_or_model_name": "In-situ Neural Assembly (Hebbian assembly)",
            "theory_or_model_description": "Concepts are represented by distributed networks of neurons (assemblies) formed through learning; these assemblies are activated in their entirety (or parts) when the concept is tokened and are content-addressable by sensory cues, with meaning determined by patterns of both afferent and efferent connections.",
            "representation_format_type": "distributed assembly representation (connection-based, non-copyable tokens)",
            "key_properties": "distributed over multiple cortical areas; content-addressable activation; integration of perception, action, affect; assemblies grow and refine with experience; not fungible tokens that can be copied arbitrarily.",
            "empirical_support": "Consistent with single-unit findings (e.g., Quian Quiroga concept cells), large-scale semantic maps (Huth et al., 2016) showing distributed semantic regions, and behavioral grounding of concepts in perception and action.",
            "empirical_challenges": "How assemblies support simultaneous multi-role instantiation without explicit token copies (NBA proposes binding mechanisms); need to link assembly-level descriptions to precise temporal dynamics observed in electrophysiology and fMRI.",
            "applied_domains_or_tasks": "Semantic memory, object and word recognition, grounding of language in sensorimotor systems, and as a basis for architectures like NBA that require in-situ representations.",
            "comparison_to_other_models": "Differs from token-copy symbolic accounts (which assume discrete, movable symbols) and from purely connectionist dense vector representations; emphasizes explicit role of connectivity and action-perception links.",
            "functional_mechanisms": "Meaning arises from activation patterns across sensory and motor networks and from how assemblies influence downstream processing; assemblies are activated by partial cues (content-addressability) and participate in behavior by activating action networks.",
            "limitations_or_open_questions": "Precise mechanisms for combinatorial composition with in-situ assemblies; scalability of forming distinct assemblies for large vocabularies; how assemblies map onto observed fMRI/timeseries data at multiple timescales.",
            "uuid": "e5261.4",
            "source_info": {
                "paper_title": "Linking Neural and Symbolic Representation and Processing of Conceptual Structures",
                "publication_date_yy_mm": "2017-08"
            }
        },
        {
            "name_short": "Huth2016",
            "name_full": "Natural speech reveals the semantic maps that tile human cerebral cortex",
            "brief_description": "fMRI evidence showing distributed semantic tuning across many cortical areas during natural speech comprehension, organized into semantic domains that tile cortex consistently across subjects.",
            "citation_title": "Natural speech reveals the semantic maps that tile human cerebral cortex",
            "mention_or_use": "mention",
            "theory_or_model_name": "Cortical semantic maps (Huth et al., 2016)",
            "theory_or_model_description": "Semantic content of words evokes activation in a tiled mosaic of cortical regions, each selective for semantic domains; these distributed representations support the idea of concept representations being spread across cortex in content-addressable assemblies.",
            "representation_format_type": "distributed semantic maps (topographic domain tiling)",
            "key_properties": "large-scale distributed semantic selectivity; multiple cortical tiles each corresponding to semantic domains; consistency across subjects; involvement of both hemispheres.",
            "empirical_support": "Analysis of fMRI responses to natural speech across subjects, clustering words into semantic domains and mapping responsiveness across cortical areas; shows distributed and domain-structured semantic representation.",
            "empirical_challenges": "fMRI spatial resolution and hemodynamic sluggishness limit temporal claims; mapping semantics to tiles does not specify microcircuit-level mechanisms; semantics may interact with tasks/context in ways not captured by passive listening.",
            "applied_domains_or_tasks": "Semantic mapping, language comprehension, informing architectures that posit distributed concept assemblies (e.g., NBA), and studies relating distributed cortical patterns to meaning.",
            "comparison_to_other_models": "Supports distributed/in-situ assembly views over strictly localized modular accounts; complements conceptual spaces approaches by providing cortical localization of semantic domains.",
            "functional_mechanisms": "Shows where in cortex different semantic domains are represented; implies that activation of a concept invokes a pattern across multiple tiles depending on context.",
            "limitations_or_open_questions": "How these mapped regions correspond to dynamically formed assemblies and to temporal binding during compositional processing; how individual variability and task demands modify the maps.",
            "uuid": "e5261.5",
            "source_info": {
                "paper_title": "Linking Neural and Symbolic Representation and Processing of Conceptual Structures",
                "publication_date_yy_mm": "2017-08"
            }
        },
        {
            "name_short": "Nelson2014",
            "name_full": "Constituent structure representations revealed with intracranial data",
            "brief_description": "Intracranial recordings indicating that binding of words and phrases produces temporally-localized increases and then decreases in neural activity during sentence processing.",
            "citation_title": "Constituent structure representations revealed with intracranial data",
            "mention_or_use": "mention",
            "theory_or_model_name": "Intracranial evidence for binding dynamics (Nelson et al., 2014)",
            "theory_or_model_description": "Electrophysiological recordings from intracranial electrodes reveal transient activity increases during the binding of words/phrases followed by decreases, reflecting the temporal dynamics of constructing constituent structure.",
            "representation_format_type": "temporal dynamic markers of composition (event-related electrophysiology)",
            "key_properties": "binding-related transient activation peaks; activity reduction after binding; constituent-sensitive temporal profiles.",
            "empirical_support": "Intracranial data showing peaks of activity aligned with word presentation and subsequent drops associated with binding events during sentence comprehension (poster presentation cited in paper).",
            "empirical_challenges": "Poster-level evidence referenced; generalization across tasks/subjects requires more data; linking these dynamics to specific representational mechanisms (e.g., NBA structure assemblies) needs targeted experiments.",
            "applied_domains_or_tasks": "Temporal dynamics of sentence parsing, constituent formation, and validation of models predicting binding-related neural signatures.",
            "comparison_to_other_models": "Provides time-resolved signatures that NBA simulations reproduce (authors claim), supporting architectures that posit discrete binding events over continuous distributed accumulation-only models.",
            "functional_mechanisms": "Binding events temporally modulate neural activity—initial activation by input followed by reduced activity when binding stabilizes—consistent with WM-mediated binding and disinhibition mechanisms in NBA.",
            "limitations_or_open_questions": "Extent to which these signatures are universal across languages, sentence structures, and tasks; mapping of particular intracranial sites to specific role-binding operations.",
            "uuid": "e5261.6",
            "source_info": {
                "paper_title": "Linking Neural and Symbolic Representation and Processing of Conceptual Structures",
                "publication_date_yy_mm": "2017-08"
            }
        },
        {
            "name_short": "Frankland2015",
            "name_full": "An architecture for encoding sentence meaning in left mid-superior temporal cortex",
            "brief_description": "fMRI evidence pointing to cortical regions encoding sentence-level meaning and showing differential activation patterns when nouns serve as agents versus themes, suggesting role-specific representations.",
            "citation_title": "An architecture for encoding sentence meaning in left mid-superior temporal cortex",
            "mention_or_use": "mention",
            "theory_or_model_name": "Agent/theme specialization in cortex (Frankland & Greene, 2015)",
            "theory_or_model_description": "Specific cortical subregions exhibit selective activation patterns depending on the thematic role (e.g., agent vs. theme) nouns play within sentence meaning representations, implying specialized fields for relational roles.",
            "representation_format_type": "role-sensitive regional activations (functional localization of role representations)",
            "key_properties": "role-selective cortical activations; sentence-meaning encoding at the phrase/clause level; representational differentiation by thematic role.",
            "empirical_support": "fMRI decoding analyses showing separable patterns in left mid-superior temporal cortex for agent vs theme roles during sentence processing.",
            "empirical_challenges": "fMRI limitations again restrict micro-mechanistic claims; how role-selective regions interact with distributed assemblies or blackboards needs elaboration.",
            "applied_domains_or_tasks": "Sentence comprehension, semantic-role representation, informing models that posit specialized connection fields (e.g., NBA connection matrices for agent/theme binding).",
            "comparison_to_other_models": "Supports NBA prediction of connection fields specialized for roles (agent/theme); complements distributed assembly accounts by indicating role-sensitive cortical substrates.",
            "functional_mechanisms": "Indicates that thematic role information is encoded in localized patterns which could serve as hubs/fields for binding operations in architectures that implement role-mediated composition.",
            "limitations_or_open_questions": "Causal role of these regions in role assignment and binding; temporal dynamics of role encoding and how role representations interact with memory/binding mechanisms.",
            "uuid": "e5261.7",
            "source_info": {
                "paper_title": "Linking Neural and Symbolic Representation and Processing of Conceptual Structures",
                "publication_date_yy_mm": "2017-08"
            }
        },
        {
            "name_short": "QuianQuiroga2012",
            "name_full": "Concept cells: the building blocks of declarative memory functions",
            "brief_description": "Single-unit recordings demonstrating sparse, invariant neurons that respond selectively to high-level concepts (e.g., a person's face or name), supporting a content-addressable, concept-linked neuronal representation.",
            "citation_title": "Concept cells: the building blocks of declarative memory functions",
            "mention_or_use": "mention",
            "theory_or_model_name": "Concept cells / sparse invariant neurons",
            "theory_or_model_description": "Certain neurons exhibit highly selective and invariant responses to abstracted concepts (e.g., specific people, landmarks), suggesting neuron-level elements that participate in distributed but content-addressable conceptual representations.",
            "representation_format_type": "sparse, invariant unit-level representation embedded in distributed networks",
            "key_properties": "selectivity and invariance across modalities (e.g., face and name); suggests a sparse code embedded in broader assemblies; supports content-addressability.",
            "empirical_support": "Intracranial single-unit recordings in human medial temporal cortex showing neurons selective for specific persons/objects across stimuli variations.",
            "empirical_challenges": "Interpretation of 'concept cell' as sole representational unit is debated; doesn't preclude distributed assemblies spanning many neurons/areas; how concept cells integrate into compositional structures is not directly shown.",
            "applied_domains_or_tasks": "Models of declarative memory, indexing of concepts across modalities, evidence base for content-addressable representations used by NBA and IDyOT grounding claims.",
            "comparison_to_other_models": "Provides micro-level evidence compatible with in-situ assembly accounts and constrains purely distributed dense-vector-only models by showing sparsity/invariance elements.",
            "functional_mechanisms": "Concept activation can be triggered by partial cues and binds to downstream processing, contributing to retrieval and recognition.",
            "limitations_or_open_questions": "Generality across cortical areas and concepts; role in combinatorial composition and sentence-level processing; how these sparse units relate to conceptual spaces.",
            "uuid": "e5261.8",
            "source_info": {
                "paper_title": "Linking Neural and Symbolic Representation and Processing of Conceptual Structures",
                "publication_date_yy_mm": "2017-08"
            }
        },
        {
            "name_short": "Chunking",
            "name_full": "Perceptual Chunking / Information-driven boundary detection",
            "brief_description": "A functional principle where sequences are segmented into chunks based on prediction and information-theoretic criteria (entropy changes), forming the basis of hierarchical symbolic representations.",
            "citation_title": "Linking Neural and Symbolic Representation and Processing of Conceptual Structures",
            "mention_or_use": "use",
            "theory_or_model_name": "Perceptual Chunking driven by predictive entropy (IDyOT principle)",
            "theory_or_model_description": "Sequential input is parsed into chunks when predictions and their entropy-change profiles indicate a boundary (agents compete and the largest positive entropy change determines chunking), producing higher-level symbols that subtend sequences and form hierarchical memory.",
            "representation_format_type": "hierarchical symbolic chunks grounded in continuous input (symbolic + probabilistic)",
            "key_properties": "entropy-based boundary detection; competition of predictors (generators); hierarchical abstraction by recursively chunking sequences; chunk labels linked to conceptual-space regions.",
            "empirical_support": "Inspired by computational linguistics and music perception studies showing boundary detection sensitivity to statistical regularities (cited: Brent, Pearce, Sproat, Rohrmeier); matches observed perceptual segmentation phenomena.",
            "empirical_challenges": "Parameter choices (entropy thresholds, gap sizes) and generator designs influence segmentation; human chunking is influenced by semantics, attention and task which need to be integrated explicitly.",
            "applied_domains_or_tasks": "Word segmentation, phrase boundary detection in language, musical phrase segmentation, incremental parsing and memory formation in cognitive models.",
            "comparison_to_other models": "Differs from fixed-grammar parsing and from purely supervised segmentation by using unsupervised, prediction-driven, information-theoretic criteria; complementary to statistical sequence models but produces explicit chunk symbols with geometric grounding.",
            "functional_mechanisms": "Generators predict next symbols from Markov models; when a prediction match causes the largest increase in entropy, that generator's chunk is committed to workspace and becomes a higher-level symbol; repeated application creates hierarchical abstraction.",
            "limitations_or_open_questions": "Mapping of chunking dynamics to neural mechanisms; robustness across noisy and multimodal inputs; how chunking interfaces with top-down semantics and task demands.",
            "uuid": "e5261.9",
            "source_info": {
                "paper_title": "Linking Neural and Symbolic Representation and Processing of Conceptual Structures",
                "publication_date_yy_mm": "2017-08"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Neural blackboard architectures of combinatorial structures in cognition",
            "rating": 2,
            "sanitized_title": "neural_blackboard_architectures_of_combinatorial_structures_in_cognition"
        },
        {
            "paper_title": "Learning of control in a neural architecture of grounded language processing",
            "rating": 2,
            "sanitized_title": "learning_of_control_in_a_neural_architecture_of_grounded_language_processing"
        },
        {
            "paper_title": "IDyOT: a computational theory of creativity as everyday reasoning from learned information",
            "rating": 2,
            "sanitized_title": "idyot_a_computational_theory_of_creativity_as_everyday_reasoning_from_learned_information"
        },
        {
            "paper_title": "Natural speech reveals the semantic maps that tile human cerebral cortex",
            "rating": 2,
            "sanitized_title": "natural_speech_reveals_the_semantic_maps_that_tile_human_cerebral_cortex"
        },
        {
            "paper_title": "Concept cells: the building blocks of declarative memory functions",
            "rating": 2,
            "sanitized_title": "concept_cells_the_building_blocks_of_declarative_memory_functions"
        },
        {
            "paper_title": "An architecture for encoding sentence meaning in left mid-superior temporal cortex",
            "rating": 2,
            "sanitized_title": "an_architecture_for_encoding_sentence_meaning_in_left_midsuperior_temporal_cortex"
        },
        {
            "paper_title": "From distributional semantics to conceptual spaces: a novel computational method for concept creation",
            "rating": 1,
            "sanitized_title": "from_distributional_semantics_to_conceptual_spaces_a_novel_computational_method_for_concept_creation"
        },
        {
            "paper_title": "The Organisation of Behaviour",
            "rating": 1,
            "sanitized_title": "the_organisation_of_behaviour"
        },
        {
            "paper_title": "A Cognitive Theory of Consciousness",
            "rating": 1,
            "sanitized_title": "a_cognitive_theory_of_consciousness"
        }
    ],
    "cost": 0.01947425,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Linking Neural and Symbolic Representation and Processing of Conceptual Structures
August 2017. 2017</p>
<p>Leonid Perlovsky 
Antonio Chella 
Frank Van Der Velde 
Department of Cognitive Psychology and Ergonomics
Faculty of Behavioural, Management and Social sciences
University of Twente
EnschedeNetherlands</p>
<p>Institute of Psychology (IOP)
LeidenNetherlands</p>
<p>Jamie Forth 
Department of Computing
Goldsmiths University of London
LondonUnited Kingdom</p>
<p>Deniece S Nazareth 
Department of Cognitive Psychology and Ergonomics
Faculty of Behavioural, Management and Social sciences
University of Twente
EnschedeNetherlands</p>
<p>Geraint A Wiggins 
School of Electronic Engineering and Computer Science
Computational Creativity Lab, Cognitive Science Group
Mary University of London
LondonQueenUnited Kingdom</p>
<p>Air Force Research Laboratory
Harvard University
United States</p>
<p>Dorina Rajanen
University of Palermo
Italy</p>
<p>University of Oulu
Finland</p>
<p>Linking Neural and Symbolic Representation and Processing of Conceptual Structures</p>
<p>Front. Psychol
Forth J, Nazareth DS and Wiggins GA81297August 2017. 201710.3389/fpsyg.2017.01297Received: 31 July 2016 Accepted: 17 July 2017HYPOTHESIS AND THEORY Edited by: Reviewed by: *Correspondence: Frank van der Velde f.vandervelde@utwente.nl Specialty section: This article was submitted to Cognition, a section of the journal Frontiers in Psychologycognitive architecturememory representationhebbian learningcompositional learningincremental learningIn situ representations
We compare and discuss representations in two cognitive architectures aimed at representing and processing complex conceptual (sentence-like) structures. First is the Neural Blackboard Architecture (NBA), which aims to account for representation and processing of complex and combinatorial conceptual structures in the brain. Second is IDyOT (Information Dynamics of Thinking), which derives sentence-like structures by learning statistical sequential regularities over a suitable corpus. Although IDyOT is designed at a level more abstract than the neural, so it is a model of cognitive function, rather than neural processing, there are strong similarities between the composite structures developed in IDyOT and the NBA. We hypothesize that these similarities form the basis of a combined architecture in which the individual strengths of each architecture are integrated. We outline and discuss the characteristics of this combined architecture, emphasizing the representation and processing of conceptual structures.</p>
<p>INTRODUCTION</p>
<p>The ability to represent and process conceptual structures, as found in language processing, reasoning, and in generating conceptual representations from visual and auditory perception, are key elements of human cognition. They can be studied with the aim to understand human cognition and its relation to the brain. But they can also be targets for the development of artificial cognitive systems. These aims can be combined to various degrees, because a cognitive architecture that provides an understanding of a (neural) cognitive process can also be used in artificial systems, and, conversely, the way in which an artificial system processes complex information can reveal aspects of human processing as well.</p>
<p>Here, we discuss and relate the different representations used in two cognitive architectures, one neural and one symbolic, in which complex conceptual structures can be represented and processed. That is, we discuss and illustrate the different ways in which complex conceptual structures are represented or learned in the two architectures and how these representations could be related.</p>
<p>In particular, we aim to outline how combined representations could be developed, for use in a combined architecture in which aspects of our neural and symbolic architectures are integrated. We hypothesize that such a combined architecture could serve as a model of human conceptual processing and its relation to the brain. When implemented, it could also serve as a new artificial architecture in which forms of neural (parallel) hardware and neural and symbolic forms of learning and processing could be integrated. We are as yet at the beginning of the integration of our architectures, which is also a reason why we focus on issues of representation here.</p>
<p>The neural representation in our integration is that used in the Neural Blackboard Architecture (NBA), which is aimed to represent and process conceptual structures in language (e.g., van der Velde and de Kamps, 2006Kamps, , 2010, reasoning and other cognitive domains (van der Velde, 2016a). The NBA assumes that conceptual representations in the brain consist of dedicated network structures, or neural assemblies, that develop over time and that can be distributed over wide areas in the brain and cortex. A fundamental characteristic of these network-like conceptual representations is that they are always content addressable, whether they are activated in isolation or whether they are parts of more complex (and even hierarchical) conceptual structures, such as sentences in language.</p>
<p>The NBA provides "neural blackboards" that afford the representation and processing of complex conceptual structures based on neural assembly conceptual representations in specific cognitive domains. Examples are neural blackboards for sentence structures, phonological structures, sequences, and relations as used in reasoning. In each domain, a dedicated neural blackboard will provide a range of specialized structural elements that can bind in a neural manner to the neural assemblies (e.g., representing "words" in language). The neural bindings, implemented with neural circuits, allow the creation and processing of more complex cognitive structures (e.g., "sentences") in a combinatorial manner.</p>
<p>The symbolic representation in our integration is that used in Information Dynamics of Thinking (IDyOT). IDyOT derives (e.g., sentence-like) structures by learning statistical sequential regularities over a linguistic corpus (Wiggins, 2012b;Wiggins and Forth, 2015;Forth et al., 2016). IDyOT is unusual as a machine learning formalism in that it is symbolic in nature, but it generates and gives explicit semantics to its own symbols, in a bottom-up learning process, which is optimized by a general, data-independent principle of information efficiency, conceptualized as predictive accuracy. These symbols correspond with concepts in the semantics of the system. Another unusual aspect of IDyOT's operation is that both representations and sequential models are optimized simultaneously with respect to the prediction accuracy of the models, causing a trade-off between overfitting and accuracy that we propose as a model of the corresponding trade-off in human cognition. The explanation of this process is a novel contribution of the current paper.</p>
<p>The representational links between IDyOT and NBA concern the nature of the dedicated structural elements that allow processing and representation of complex conceptual structures, the way these elements could be activated during processing, and the underlying semantics of the architectures in the form of conceptual spaces that possess a geometrical structure (Gärdenfors, 2000(Gärdenfors, , 2014.</p>
<p>In the NBA, the dedicated structural elements form the neural blackboards. The kinds of elements used and the way they are activated derive from analyses of the cognitive domains at hand, as in the sentence NBA (e.g., de Kamps, 2006, 2010). However, the combination of NBA with IDyOT provides the possibility to derive these structural elements by learning from real corpora. Conversely, the NBA could provide a neural implementation of the more higher-level formal account as provided by IDyOT. Thus, IDyOT potentially supplies a higherlevel formal account and learning abilities to the operations of the NBA. Conversely, the NBA provides a route toward a neural implementation of IDyOT, which could also form the basis of in parallel operating hardware.</p>
<p>THEORETICAL POSITION AND NOVELTY</p>
<p>Our theoretical position here is that the representations used in NBA and IDyOT are in fact two different representations of the same thing, at different levels of abstraction, but with focus on similar representational affordances. In the following sections, we describe the representations, and the relations between thembut, as always, to understand the representations it is necessary also to understand the processes that work over them.</p>
<p>The novelty in the current paper lies in several places, primarily in the thorough-going comparison between the representations and corresponding processes in the two architectures. The entire description of IDyOT memory construction is also novel, and we present a novel simulation of neural activity based on the NBA, which allows for a detailed comparison with brain activity observed in human (sentence) processing. To the best of our knowledge, such a detailed potential comparison between human brain activity and simulated model activity is not available in the case of high-level cognitive processing, such as sentence comprehension. This also strongly motivates the integration of our architectures, because that would endow the NBA with the learning capabilities of IDyOT, based on real corpora (as outlined below). In turn, the dynamics and structure of the NBA would then allow a comparison between the representations and underlying processing as learned by IDyOT and human brain activity.</p>
<p>The structure of the paper is as follows. In the next two sections we briefly describe the representations used in NBA and IDyOT in turn, also giving detail of processing where appropriate. In the sections that follow, we discuss a number of specific links between NBA and IDyOT and the potential benefits of their integration.</p>
<p>NEURAL BLACKBOARD ARCHITECTURE</p>
<p>In our outline of Neural Blackboard Architecture, or NBA for short, we focus on the representation of concepts (e.g., underlying words) in the architecture and the representational structures that are used to integrate concepts in more complex cognitive structures, such as relations and sentences.</p>
<p>The basis of concept representation in the NBA are "neural assemblies, " as proposed by Donald Hebb (1949). In the view of Hebb, these neural assemblies develop over time by interconnecting the neurons in the brain that are involved in processing (sensory) information and generating actions related to the concept they represent. However, unlike Hebbian assemblies, conceptual representations in the NBA are not only associative. Instead, they can (and mostly will) contain relational structures as well. Figure 1 illustrates a neural assembly representation of cat. It would be distributed over different areas in the cortex and brain, depending on the kind of information involved, including networks processing perceptual information about cats and networks that can produce specific actions (e.g., pronouncing the word "cat"). But also networks representing emotional content or associations related to cats belong to the assembly, and networks that instantiate relations, such as cat is pet.</p>
<p>The combination of perception and action in the assembly structure of a concept entails that both the patterns (and activation) of "incoming" and "outgoing" connections determine the meaning of a concept. For example, neurons observed in the medial temporal cortex responded to a person whether the person or his or her name was presented (Quian Quiroga, 2012). These "perception" networks do in fact belong to the assembly structure of a concept, because without them the concept could not be activated (or was not learned). But this would capture only part of the role and (hence) meaning of the conceptual representation involved. Equally important would be the effect of these neurons on downstream processing (van der Velde, 2015).</p>
<p>The notion that conceptual representations interconnect sensory information processing and action generation underscores their role in producing behavior. The ability to produce behavior is a crucial aspect of cognition (and hence of every neuro-cognitive model) because the evolution of cognition depended on the ability to produce behavior. Without advocating a behavioristic view of cognition (e.g., as the basis of modeling cognition) we do argue that the prime role of cognition is to intervene in the reflex (cf. Shanahan, 2010). In this view, the need for a connection structure that transfers sensory activity to motor activity should always be at the background of a neural-cognitive model.</p>
<p>So, in Figure 1, it is not just the gray oval that represents the concept cat, but instead the entire network structure to which it is connected. The gray oval could play the role of a higher-level representation of the concept in the sense that it interconnects the concept to other networks. But it would be wrong to see this as the "genuine" encoding of the concept. Without the networks to which it is connected, the gray oval does not encode anything.</p>
<p>An important feature of conceptual representations given by neural assemblies is that they are "in situ." This entails that they cannot be copied and transported to create more complex structural representations with them (e.g., as found in language or reasoning). Instead, the same assembly (or a part thereof) is always activated when the concept it represents is tokened. One consequence of this kind of representation is that an assembly can develop and grow over time, as originally discussed by Hebb. Another direct consequence of the in situ nature of a neural assembly is that the concept it represents is content addressable. This entails that the same assembly (or part thereof) will be activated when sufficient information about the concept it FIGURE 1 | Left: Neural assembly representation of cat. Right: Sentence structure in the Neural Blackboard Architecture: a sentence neural blackboard (temporarily) interconnects the "in situ" concept representations (given by neural assemblies) of cat, is, on, and mat to form the sentence structure cat is on mat. The thick line connections represent "conditional connections." They can be opened by gating circuits that are either activated by sustained activity in working memory neural populations (representing binding) or by neural control circuits (e.g., performing parsing operations). N, noun; P, preposition; S, sentence; V, verb.</p>
<p>represents is available (e.g., perceived), even when the concept is part of a (complex) sentence structure. Huth et al. (2016) give an indication of the in situ nature of conceptual representation in the brain. They measured brain activity related to words when people were listening to stories (in an fMRI scanner). The parts of the cortex that responded to the words (after statistical analysis) were much larger compared to previous studies in which only individual words were presented. The analysis divided the left hemisphere (LH) into 192 distinct functional areas, 77 of which were semantically selective. The right hemisphere was divided into 128 functional areas, 63 of which were semantically selective (even though the RH is usually regarded as not being involved in language). Remarkably, the organization of these areas was quite similar over the different (7) subjects involved in the study. Furthermore, next to these semantic areas, other areas also responded to other aspects of words (e.g., Broca's area).</p>
<p>Because the study was focused on semantic representation, the words observed in the study were categorized into 12 semantic domains. These domains tiled the cortex in terms of the 77 areas in the LH and the 63 areas in the RH referred to above. Inspection of the data reveals that semantic domains are generally represented in different tiles, distributed over the LH and/or RH cortex.</p>
<p>The semantic representation as observed by Huth et al. (2016) seems to be in line with the Hebbian assembly hypothesis, in that these representations would have arisen over time, and would (partly) be determined by the context in which the concepts were processed. This could explain why, e.g., the same visual concept (e.g., colored) activates areas near the visual cortex but also in the prefrontal cortex. This pattern of activation could reflect different parts of the assembly of the concept, and their selective activation would then be determined by the context (visual processing vs. motor behavior) in which the concept is used and learned. The fact that a concept generates activation in different cortical areas is in line with the assembly representation as illustrated in Figure 1.</p>
<p>Neural Blackboards as Connection Paths</p>
<p>If concepts are represented and distributed as in situ assemblies, the question arises of how they could be combined to represent more complex cognitive structures, such as relations or sentences.</p>
<p>The key notion of the NBA is that more complex cognitive structures are formed by providing (temporal) connection paths between the assemblies (concepts) they contain, in relation with the structure they express. These (temporal) connection paths are formed and controlled in "neural blackboards."</p>
<p>For example, in the case of language, the NBA provides a connection structure (or connection path) that allows arbitrary words in a given language to be (temporarily) interconnected in accordance with the structure of the sentence. The words in this case are the network structures (neural assemblies) as described by Huth et al. (2016). The neural blackboards in the NBA provide a "small world" network structure that would allow the in situ and distributed concept assemblies ("words") to be interconnected using a limited set of intermediary "hubs and sub-hubs, " given by the structure assemblies and their potential bindings in the blackboards. Small world networks are found in a wide variety of natural and man-made structures because they allow arbitrary interconnectivity with minimal means. They also play an important role in the brain (Shanahan, 2010). Figure 1 illustrates how in the NBA a sentence can be formed with in situ concepts encoded by neural assemblies. The in situ assemblies for cat, is, on, and mat are bound to a "neural blackboard" to form the sentence cat is on mat. Figure 1 illustrates the very basic aspects of the neural blackboards that the NBA uses to encode relations between in situ concept assemblies. In the case of language there are (at least) two neural blackboards involved. One is a phonological blackboard, which is not illustrated here. The other is the sentence blackboard which encodes sentence structures, as illustrated here with the sentence cat is on mat.</p>
<p>The need for both a phonological and a sentence blackboard derives from the productivity of natural language. Language has (at least) a two tier productive structure (Jackendoff, 2002) in which first phonemes form words and then words (or word-phoneme combinations) form sentences. The combination of (familiar) phonemes allows the generation of a very large set of words, which can grow continuously in life. These words (including novel but phonetically regular words) can then be combined to give a practically unlimited set of sentences. Yet, it is important to realize that this two tier productivity is restricted to the languages we are familiar with. In the NBA, that means languages for which we have developed neural blackboards (van der Velde and de Kamps, 2015a).</p>
<p>van der Velde and de Kamps (2006Kamps ( , 2010 explain the structure and operations of the neural blackboards in detail. Here, we address a number of main issues, focusing on representational structures in the sentence blackboard. The composite structural elements of the sentence blackboard are "structure assemblies, " as illustrated in Figure 1. They can bind to concept assemblies (or to "word assemblies" in the phonological blackboard) and they can bind to each other to generate the structure of the sentence (e.g., cat is on mat).</p>
<p>The thick-line connections in the blackboards play a crucial role in the process of generating and representing a sentence structure. These connections are "conditional connections, " consisting of gating circuits. To operate as a connection, the gates in the connections have to be opened or activated. This ensures that activation does not flow without control in the neural blackboards, that is, the connections in the blackboards are not associative. The gates can be activated by working memory (WM) activation, representing a binding, and by control circuits, which represent (e.g., syntactic) operations in the architecture. We will discuss these operations in more detail later on.</p>
<p>So, the in situ assembly cat is bound (via the phonological blackboard) to a "Noun" structure assembly Nx in the sentence blackboard. Binding is achieved by working memory activation that opens the gates between the assemblies involved. To this end, the sentence blackboard has a number of Noun assembles which can all potentially bind to each of the Word assemblies in the phonological blackboard (via a matrix or tensor-like connection structure, see below). All bindings in all neural blackboards are of this kind. A specific binding in the "connection matrix" between assemblies is achieved by activating a specific working memory, which consists of sustained activation in a population of neurons. Once activated (by the mutual activation of the assemblies it binds), the population remains active on its own for a while due to "reverberating" activity (e.g., Amit, 1989). So, in this way, cat will bind to Nx. Similarly, is will bind to the Verb structure assembly Vz, on to the Preposition structure assembly Pu and mat to Nw (again, via the phonological blackboard).</p>
<p>Thus, to represent sentences based on in situ words (concepts), the NBA builds a connection path (structure) in the sentence (and phonological) blackboard, in accordance with the syntactic structure of the sentence. These sentences can be novel sentences based on familiar words (or even novel words based on familiar phonemes), and they can include hierarchical structures like (e.g., center) embedding (van der Velde and de Kamps, 2006Kamps, , 2010. Once a connection structure is built it can be used to produce behavior, because it constitutes a connection path between the in situ concept assemblies it interconnects. In turn, this entails that it forms a (temporal) connection path between all perception and action structures embedded in these concept assemblies, thus forming a path between perception and action as the basis for behavior.</p>
<p>IDYOT: THE INFORMATION DYNAMICS OF THINKING</p>
<p>Overview</p>
<p>IDyOT (Information Dynamics of Thinking: Wiggins, 2012b;Wiggins and Forth, 2015;Forth et al., 2016) implements Baars' Global Workspace Theory (GWT; Baars, 1988), affording a computational model of a hypothetical cognitive architecture. At the functional level 1 , a number of generators sample from a complex statistical model of sequences (explained below), performing Markovian prediction from context (Wiggins and Forth, 2015;Forth et al., 2016). Each generator indexes a string of symbols, forming a chunk, a final substring of the overall memory model, expressed as symbols, whose origin is explained below. Each indexed string serves as a context for prediction of the next (as yet unsensed) symbol; predictions are expressed as distributions over the alphabet used to express the input. A chunk is integrated into the memory and Global Workspace (which may be thought of as an AI blackboard: Corkill, 1991) when it meets a criterion based on information content. The upshot of this design is that IDyOT's primary cognitive operation is perceptual chunking. Figure 2 gives a functional overview.</p>
<p>IDyOT maintains a cognitive cycle that continually predicts what is expected next, from a statistical model, expressed in terms of self-generated symbols that are given semantics by perceptual experience; it is thus focused on sequence. Perceptual input is matched against generators' predictions, and where a match leads to a larger increase in uncertainty than other current matches, the corresponding generator's chunk is flushed into the Global Workspace, and stored in memory, linked in sequence with the previous chunk. Chunks that fail to win are forgotten after a fixed period, the duration of which is question of the research. The model entails that, for perception to work, at least some generators must be working in all perceptual modalities at all times; otherwise no generator would be predicting for input in a newly active modality to match against. This activity may account for otherwise unexplained electrical brain activity that is not directly concomitant with perceived events, and it may be responsible for spontaneous creativity (Wiggins and Bhattacharya, 2014).</p>
<p>Representation, Memory, and Prediction in IDyOT</p>
<p>Each chunk, having been recorded, is associated with a symbol in a higher-level model, which adds to the overall predictive model. Each symbol corresponds with a point in a conceptual space (Gärdenfors, 2000(Gärdenfors, , 2014 associated with its own layer, and each such point corresponds with a region or subspace of the conceptual space of the layer below, defined by the lower-level symbols in the chunk. Thus, there are two parallel representations: one symbolic and explicitly sequential; and one continuous and non-sequential, but encoding sequential information. The former provides evidence from which the latter is derived, while the latter provides semantics for the former. 1 The formal implementation of this functional behavior is somewhat different in actuality. However, the description given here is easier to understand in isolation.</p>
<p>FIGURE 2 | Overview of the IDyOT (Information Dynamics of Thinking) architecture. Generators synchronized to perceptual input sample, given previous perceptual input (if any), from a first-order, multidimensional Markov model to predict the next symbol in sequence, which is matched with the input. Predicted symbols that match are grouped in sequence until a chunk is detected on grounds of its information profile. The generator then stores the chunk, as described in §7.1.3 and resets its chunk, which is the sum of the structured hierarchical memory and a detector that searches for salient information, shown as "conscious awareness" here. This allows the resulting chunk of sequence to be stored in the memory, to become part of the statistical model and thence to be used subsequently.</p>
<p>For grounding (or, more precisely, tethering: Sloman and Chappell, 2005), the lowest-level conceptual spaces are a priori defined by the nature of their sensory input (inspired by human biology: for example, auditory input models the output of the Organ of Corti); higher-level ones are inferred from the lower levels using the information in the sequential model. Structures may be grouped together in categories, according to similarity in their conceptual space, giving them semantics in terms of mutual interrelation. Using this, a consolidation phase allows membership of categories to be optimized, by local adjustment, in terms of the predictive accuracy of the overall model. Theoretically, the layering of models and its associated abstraction into categories can proceed arbitrary far up the constructed hierarchy (Wiggins, 2012b;Wiggins and Forth, 2015). Forth et al. (2016) provide an account of the representation of timing in IDyOT; these aspects, however, are beyond the scope of the current paper.</p>
<p>In general, the stimuli to which IDyOT will respond are sequences of atomic percepts. All the dimensions of music, pitch, timbre, amplitude and time, which also feature in speech, are used for prediction, as has been demonstrated in IDyOM (Pearce, 2005;Pearce et al., 2012), as can any other transduced signal. This demands a more powerful Markov model than is common in cognitive science language modeling. Conklin and Witten (1995) proposed a viewpoint-based approach that allows a set of interacting features, associated by means of sequences of multi-dimensional symbols, to perform multi-dimensional prediction. This is the system used in IDyOM and adapted for multidimensional language models by Wiggins (2012a). A key contribution of the viewpoint idea is the ability to superpose distributions from different features with weights determined by their entropy . Given Conklin's notion of viewpoint (Conklin and Witten, 1995) and the associated mathematics, it becomes possible also to represent propositional meaning within the statistical framework: to do this, one incorporates representations of the meaning (perhaps drawn from another sensory modality, e.g., describing in language a scene representation derived from visual input) in the statistical model (Eshghi et al., 2013). Here, we presuppose a rich, multisensory input which allows associations to be constructed between different sensory modalities, on the basis of co-occurrence.</p>
<p>A key scientific advantage of this representations is that its symbols are (directly or indirectly) explicable in terms of IDyOT's perceptual input, and a record of that perception is maintained. Thus, its status as a cognitive model is more easily tested than in equally powerful, but less semantically transparent, learning systems, such as deep neural networks.</p>
<p>Summary: the Principles of IDyOT</p>
<p>In summary, the IDyOT model is based on 6 principles. Notations used in the current description of IDyOT are presented in the 4. The cognitive system always strives to maintain the optimal representation of its memory. Optimality is expressed in terms of the mean number of bits required to represent each symbol in the memory: smaller is better. 5. Meaning is constructed internally to the cognitive system, and incrementally, and consists in associations between symbols in the IDyOT memory ( § §6.1.3,7.1.4). 6. Because the model maps directly to experience, it is learned incrementally ( §7.1). This has the following consequences:</p>
<p>a. Meanings attributed to symbols depend on the order of events that the model learns ( §7.1). b. It is necessary from time to time to re-optimize the model, after an extended phase of incremental learning. This is termed memory consolidation. One consequence is that meanings can change retrospectively as the system learns.</p>
<p>NBA AND IDYOT AS COMPLEMENTARY APPROACHES TO REPRESENTATION</p>
<p>Although the NBA is a neural architecture whereas IDyOT is primarily a symbolic one, they are functionally and structurally related. </p>
<p>ℵ(v)</p>
<p>The alphabet associated with viewpoint v.</p>
<p>D t,A</p>
<p>The distribution that constitutes IDyOT's prediction at time point t over alphabet A.</p>
<p>H(D)</p>
<p>The estimated entropy of distribution D, over alphabet A:
H(D) = − s∈A p(s) log 2 p(s). h(D, s)
The estimated information content of symbol s drawn from distribution D over alphabet A: h(D,s) = −log 2 p(s).</p>
<p>S A</p>
<p>The conceptual space (Gärdenfors, 2000) associated with alphabet A.
R A,s
The region of S A that corresponds with the symbol s ∈ A.</p>
<p>In particular, chunking plays a key role in this relation between the two architectures. Perceptual chunking is the key operation of IDyOT, but it is also the underlying principle of structure formation in the NBA. The neural blackboards in the NBA not only interconnect information or provide a workspace in which information can interact and compete, they also form larger chunks of the information presented to them. These chunks arise during information processing and competition and are represented with the structure assemblies that characterize a given blackboard.</p>
<p>In this way, the two approaches are strongly mutually complementary: IDyOT can provide the structural elements that would be needed in a neural blackboard representation, instead of deriving them from a laborious and perhaps faulty analyses. The way in which IDyOT derives these structural elements is much more direct and secure than the engineering approach in NBA, because the elements derived by IDyOT are based on learning mechanisms using real corpora. These learning methods could also be used to develop the structural elements of a phonological neural blackboard and for neural blackboards of other languages than English.</p>
<p>In turn, the NBA provides a direct neural implementation of the structures as learned by IDyOT. This offers the possibilities for fast hardware implementations combined with processing abilities based on dynamic competitions in the neural blackboards. The dynamics in neural blackboards also strengthen functional processing in the architecture. For example, they can play a role in sentence processing, in the generation of behavior (e.g., answering questions) or in ambiguity resolution. They also reduce the constraints that need to be learned to perform these tasks.</p>
<p>In the next sections we address a number of relations between the representations used in the NBA and IDyOT in more detail.</p>
<p>STRUCTURAL ELEMENTS IN NEURAL BLACKBOARDS OR WORKSPACES</p>
<p>The first relation between NBA and IDyOT concerns the role of neural blackboards or a workspace. In both architectures, special operators (or neural circuits) process and generate special forms of information. But to account for the productivity of human cognition there has to be a way in which the information processed or generated by special processors is interrelated and combined. A neural blackboard or workspace allows these interactions to occur, with the special processors feeding into and competing within them. The role of neural blackboards or workspace in both architectures is also related to the small-world network structures that would allow different brain processors (areas) to interconnect with each other in a flexible way.</p>
<p>Blackboards play a role in classical computation (Corkill, 1991), in which they allow the representation of generic forms of information that can be stored and retrieved at will (in line with the characteristics of symbolic information processing). In contrast, the neural blackboards in the NBA are not generic in this sense. They do not represent arbitrary information which can be stored and retrieved at will. Instead, the information that can be stored in a given neural blackboard is determined by the nature of its composite structural elements, which depends on the kind of process the neural blackboard is involved in. For example, the structural elements of the neural sentence blackboard are different from those in the phonological neural blackboard: the sentence neural blackboard has main assemblies and sub assemblies for specific syntactic structural elements (e,g., "clause" or "preposition"), which are not found in the phonological neural blackboard. As a consequence, the neural sentence blackboard cannot (by itself) represent phonological structures. This is why the blackboards in the NBA are referred to as neural blackboards, to emphasize their internal and selective neural structure.</p>
<p>The workspace in IDyOT is symbolic. But the composite structural elements in the workspace, learned by IDyOT, are related to the composite structural elements in the neural blackboards of the NBA.</p>
<p>In the NBA, however, the composite structural elements (or 'structure assemblies') are engineered, derived from an analysis of the domain (e.g., language) for which the neural blackboards are used. In contrast, the structural elements in IDyOT that provide a representation of phonological and sentential structures are learned from a real corpus.</p>
<p>It would be a huge advantage for an architecture as the NBA if the structures in neural blackboards could be learned from real corpora instead of being designed. In return, the NBA could then offer a neural (parallel and dynamic) implementation of the structures as learned by IDyOT. The following subsections illustrate, for the first time, how learning proceeds in IDyOT and how structural elements as learned in IDyOT can be implemented in a neural and dynamic manner. Because IDyOT's learning process is incremental, as opposed to the one-shot learning of most statistical learning systems, there is diachronic development of meaning in its memory. As a result, it is difficult to see how the system works from a static, descriptive perspective. Therefore, we begin with a static description of the representation and how it is used, so that the reader has a clear idea of where the incremental process is heading. Related, but different descriptions are given by Wiggins and Forth (2015), with respect to the dynamics of lexical disambiguation, and by Forth et al. (2016) with respect to timing in music and language. First, then, the reader is asked to focus on the data structure presented, and to postpone the question of how it is constructed to §7.1. The "viewpoint" terminology used in the following description was originated by Conklin (1990) and Conklin and Witten (1995).</p>
<p>IDyOT's conceptual representation consists of two components, both of which are learned. The primary component is a sequence of events with separable features (viewpoints), annotated with chunk extents, which themselves form a sequence, and to which chunking is then applied recursively, up to a limit which is a parameter of the system (see §7.1.3); we say that a symbol at level i subtends a sequence at level i − 1; Figure 3 illustrates this. The shortest possible event is a multidimensional object that describes a simultaneous moment as sensed by IDyOT, at a sampling rate which is a parameter of the system, but of which 40 Hz is a preferred value, in terms of all the sensory modalities available to it. The examples given here are taken from auditory processing; however, there is no implication that this should be the only modality available.</p>
<p>Sequence</p>
<p>The sequence memory consists of symbols, beginning at the lowest representational level, and recorded sequentially in perceived time, as abstractly illustrated in Figure 3. Higher layers in the hierarchy constitute abstractions of the sequences that their symbols subtend, in lower layers. Thus, once the memory is constructed, there are in general three directions of possible prediction from any given context: up, with increased abstraction, down, with decreased abstraction, and forwards in perceived sequence. The theory does not currently consider the complicating possibility of reasoning backwards, nor of subsequent conscious reinterpretation; reinterpretation should be layered on top of this. The structure so produced, combined with the contextualized distributions afforded by the transition matrices, is similar in nature to a Dynamic Bayesian Network (Pearl, 1999).</p>
<p>For a concrete example, consider speech input. The lowestlevel representation of this would be spectral and highly granular, and therefore prohibitively expensive in memory. Since the basic symbols would, in a full example, be sensory inputs, for a humanlike IDyOT, retention of the very lowest levels of memory should be fleeting, modeling echoic memory, and therefore our example is more realistic, beginning, like Wiggins and Forth (2015), at the somewhat artificial level of phonemes, pitch and amplitude: these constitute our basic viewpoints. Consider the extremely simple example sentence, "John loves Mary" in Figure 4, which illustrates the idea in multiple dimensions. For example only, we use emoji to denote the semantics of the sentence: these are presented at the same time as the example sentence is being spoken. This could be represented by viewpoint "emoji" in Figure 4A, which should be thought of as alongside the other viewpoints, together constituting level 0 in Figure 4B, simulating more complex world experience. We can consider not just single viewpoints, but also their cross products (known in Conklin's system as a linked viewpoint), whose alphabet consists of pairs constructed from the two source FIGURE 3 | Simplified illustration of the abstract structure of IDyOT memory. The three generators are working at the level denoted by labels with upper case L; these have been derived from the lower case l labels, below, and the generators are engaged in working on the next level up, denoted by labels with upper case italic L. Arrows with empty heads denote abstraction; arrows with solid heads denote concretisation; and arrows with open heads denote temporal sequence, though note that the diagram shows only sequence, and does not represent time. Recall that each generator's chunk subtends the sequence from its pointer to the end of the memory. Finally, note that each arrow denotes a range of possible next labels, with an associated distribution, and that generators can work at any and all of these levels. The diagram is simplified by showing only one of the alternative labels that exist at each level; thus, each of the abstraction and concretisation arrows should be thought of as a range of choices, governed by a distribution derived from observed likelihood.</p>
<p>FIGURE 4 | Two perspectives on IDyOT memory. (A)</p>
<p>An illustration of the parallel basic viewpoints for the sentence "John loves Mary," expressed in phonemes with associated voice pitch and amplitude signals, and semantics represented (for the purposes of example only) by emoji sequences. The top group are the basic viewpoints, as directly transduced (again, for the purposes of example); the middle example shows a linked viewpoint at the basic level; and the bottom example shows a linked viewpoint that encodes the discovered association between the semantic representations and the spoken words; such links can only take be generated when the two source viewpoints are aligned in time. (B) The hiearchical memory structures resulting from sensing of the sentence, "John loves Mary," in terms of the individual phoneme and emoji viewpoints by a fully trained IDyOT. Note that this does not correspond with the standard syntactic parse, and nor is it the same as a MERGE style parse of the words. Associated with each layer of the tree, L, is a continuous, time-variant conceptual space, S L , (Gärdenfors, 2000) of timbre; this is a complex Hilbert space, whose points are time-slices in a spectral representation, such as a Fourier transform. Each stimulus at level 0 corresponds with a temporal trajectory (of variable length) in that space, while the corresponding structures at level 1 are points in a different, abstract space. S i+1 is related to S i by spectral (e.g., Fourier) transformation, following Chella et al. (2007). Then, the sound /dZ/ is represented in full spectral detail at level 0, but in summary form, as a point, at level 1, as are /o/ and /n/. At level 1, further trajectories connect the more abstract representations, and thus the temporal detail of the individual sounds is abstracted, allowing (for example) the same word to be recognized regardless of how long the vowel takes. Expectations as to timing are generated from the various examples of each sound in each context in the memory (Forth et al., 2016). alphabets. This, of course, generates a combinatorial explosion of viewpoints.</p>
<p>At each layer, there is a first-order Markov model, which allows prediction of the next item in sequence; Wiggins (2012b) explains the importance of this prediction with respect to creativity. Predictions, expressed as distributions over the alphabet of the relevant layer, may be generated for any point at the leading edge of the hierarchical memory structure as it is generated: thus, higher-level, abstract predictions are current at the same time as surface-level ones, and this is how long-term dependency in language, music, and narrative is managed.</p>
<p>Meaning</p>
<p>IDyOT is unusual as a symbolic learning system because it does not use symbols with predefined meanings. Rather, symbols are grounded in perception, and their meaning is determined either in terms of synchronic relations between sensory modalities, or in terms of the diachronic sequence chunks that they subtend. In either case, meaning is placed in context of the conceptual spaces (Gärdenfors, 2000(Gärdenfors, , 2014 associated with the viewpoints and the alphabets built above them. To summarize very briefly, conceptual spaces are low-dimensional geometrical spaces that afford judgments of similarity or betweenness. An example is the familiar color spindle, which has regions corresponding with colors of the spectrum, in which Euclidean distance models similarity (Gärdenfors, 2000(Gärdenfors, , 2014. Different perceptual phenomena exhibit different geometries (for example, musical pitch is a spiral, Shepard, 1964), and methods for deriving these properties are a rich area of future research; Tenenbaum et al. (2011) propose various candidate statistical structures. In the higher layers of IDyOT memory, because a symbol subtends a sequence of symbols below it, it must be possible to map a trajectory of points or regions in a lower space to a single point in a higher one; this suggests that spectral representations are a promising route; Chella et al. (2008) and Chella (2015) suggest methods.</p>
<p>The conceptual spaces in IDyOT are important, because they afford the similarity measures that categorize chunks together in the incremental chunking and representation process, which we describe in §7.1.</p>
<p>NBA: binding sequential structures and concepts</p>
<p>The abstract structure of IDyOT memory, as illustrated in Figure 3, consist of learned components, organized in hierarchical layers. They form the link between the learning mechanisms of IDyOT and the neural blackboard structures of the NBA. Figure 5 illustrates these neural blackboard structures in more detail, with the structure the sentence cat sees cat, to compare the encoding of sequential structures in IDyOT and the NBA.</p>
<p>The red and black thick lines in the figure illustrate the (crucial) conditional connections in the NBA, which consist of gating circuits. In the NBA, each concept assembly (e.g., of a noun) is connected to a set of structure assemblies of the same kind (all Ni assemblies in the case of a noun) with gating circuits. (In fact, the words need to be represented in a phonological blackboard first, to enhance the productivity of the architecture, being able to represent novel but phonologically regular words, and to reduce the number of conditional connections in the architecture.) In turn, each structure assembly consists of a "main assembly, " such as N1, and (a set of) sub assemblies, such as n or t. The connection between a main assembly and a sub assembly consists of a gating circuit as well.</p>
<p>Structure assemblies of different kinds, such as V1 and N2, are connected by their sub assemblies of the same kind. Here, by their t (theme) sub assemblies, which represents the fact that a verb can have a theme (object). This connection (red line) also consists of a gating circuit, which can be activated by a WM neural population. This results in the binding of the two connected sub assemblies and hence their main assemblies, which last as long as this WM population is active. When two sub assemblies are bound in this way, activation can flow from one of the main assemblies to the other, by opening the gates between these main assemblies and their sub assemblies.</p>
<p>The gating circuits operate by disinhibition (di), as illustrated in Figure 5. When N1 is active, it activates a neuron (or neuron population) X and an inhibitory neuron (or population) i. The latter inhibits X, which blocks the flow of activation. But when i itself is inhibited (by neuron or population di), activation can flow from N1 (via X) to n.</p>
<p>Gating circuits can be disinhibited (or "activated") in one of two different ways. In the case of gating circuits between main assemblies and sub assemblies (the black connections in Figure 5), the activation results from an external control circuit that activates the di population. This is how syntactical operations affect binding in the blackboard. A control circuit could have recognized that sees cat represent a verb and a theme. It then activates all di populations in the gating circuits between all Vi and Nj assemblies and their t assemblies. As a result, the active Vi and Nj will activate their t sub assembly.</p>
<p>Gating circuits between sub assemblies and between word and main assemblies (the red connections in Figure 5) are activated by (specific) "working memory" (WM) populations. A WM population remains active for a while, after initial activation, by reverberating activation in the population (e.g., Amit, 1989). An active WM population binds the assemblies to which it is connected. Figure 6 illustrates how this is achieved in the NBA. Figures 6A-C illustrate the same binding process with increasing detail. In Figure 6A, the binding between the t sub assemblies of V1 (or V1−t) and N2 (N2−t) in Figure 5 is repeated. Figure 6B illustrates that this binding is based on a "connection matrix, " which consists of columns and rows of "connection nodes, " which are illustrated in Figure 6C.</p>
<p>Each specific Vi − t and Nj − t pair of sub assemblies is interconnected in a specific connection node, located in a connection matrix dedicated to binding Vi − t and Nj − t sub assemblies. In general, when two assemblies Xi and Yj (e.g., Vi − t and Nj−t) are concurrently active in the processing of a sentence, they activate a WM population in their connection node by means of a gating circuit, as illustrated in Figure 6C. In turn, the active WM population disinhibits a gating circuit by which activation can flow from Xi to Yj, and another such circuit, not show in (c), by which activation can flow from Yj to Xi. As long as their WM population is active, Xi and Yj are "bound" because activation will flow from one to the other whenever one of them is (initially) activated.</p>
<p>The NBA allows any noun to bind to any verb in any thematic role using dedicated connection matrices. Also, the NBA has structure assemblies that can bind to other structure assemblies, such as S1 in Figure 5 or clause structure assemblies. In this way, hierarchical sentence structures can be represented, such as relative or complement clauses.</p>
<p>Sentence Structure as Connection Path</p>
<p>To form a sentence structure, the structure assemblies have to bind to each other. This process is regulated by control circuits that build a sentence structure in line with the (syntactical) relations in the sentence (van der Velde and de Kamps, 2010).  So, with cat sees cat in Figure 5, the control circuits will recognize cat as the subject of the sentence, expressed by the binding of N1 to the 'Sentence' structure assembly S1, and sees as the verb of the main clause, expressed by binding V1 with S1.</p>
<p>But then, the control circuits will recognize the second occurrence of cat as the object of the sentence. This seems to pose a problem, because that would seem to require a copy (different token) of cat to bind as the object to the verb. Indeed, symbol manipulation represents the sentence cat sees cat with two tokens of cat. But in the NBA, a given concept assembly can bind to different structure assemblies at the same time, allowing the creation of sentence structures in which words are repeated, as illustrated in Figure 5. However, the concept assemblies remain in situ in this way, so words in sentence structures are always content addressable and grounded. This example illustrates how the NBA solves the "problem of two" posed by Jackendoff (2002).</p>
<p>The sentence structures in the NBA (as illustrated in Figures 1, 5) and IDyOT (e.g., John loves Mary in Figure 4) are structurally similar. The sentence in IDyOT is derived from its learning principles, as outlined above, and it can be represented in the NBA in the manner illustrated in Figure 5.</p>
<p>As we argued, the representational similarities between IDyOT and NBA would offer a basis for combining the learning mechanisms of IDyOT, based on real corpora, with the parallel and dynamic implementation of the NBA. The dynamics in the neural blackboard can in fact be used to solve forms of (e.g., sentence) ambiguity (van der Velde and de Kamps, 2015b), which in turn offers the possibility of further reduction of the constraints that would have to be learned to represent and process complex cognitive structures.</p>
<p>PROCESSING OF SEQUENTIAL STRUCTURES</p>
<p>A second link between the NBA and IDyOT concerns the processing of sequential information. Based on its learning mechanism, IDyOT derives probabilistic choices between structural interpretations of the processed information, in the form of transition matrices. Based on learning, predictions can be made that influence further processing of the input sequence.</p>
<p>The NBA uses similar kinds of information to train control circuits that selectively activate the neural blackboards, as illustrated in Figure 5. Control circuits have been implemented with feedforward networks (van der Velde and de Kamps, 2010) and, more recently, with reservoirs (Jaeger and Haas, 2004) consisting of "sequence nodes" (van der Velde, 2016a).</p>
<p>Similar to the connection nodes in Figure 6, each sequence node has a column structure with gating circuits that control the activation of the node. This activation depends on three sources: previously activated sequence nodes (hence forming a chain of nodes in the reservoir, representing sequential order), external activation generated by the (ongoing) input sequence, and activation already generated in the neural blackboard. The latter includes the predictions generated in the neural blackboard in the course of processing an input sequence, as in the resolution of ambiguity (van der Velde and de Kamps, 2015b).</p>
<p>The reservoir can, for example, learn to answer the question Where is cat? with the sentence Cat is on mat in Figure 1. The reservoir can learn to do this by recognizing the sequence Where -localizer -noun -Agent. Here, the sequence Wherelocalizer -noun is based on transforming the question Where is cat? in a more general form (with is = localizer and cat = noun). The Agent in the sequence is derived from the activation of the neural blackboard representation of cat is on mat, because cat in the question Where is cat? activates its in situ neural assembly (Figure 1) and thus the part of the neural blackboard representation of cat is on mat to which the assembly cat is bound. In this way, the reservoir can learn to reactivate the sentence representation of cat is on mat in the neural blackboard, to generate the answer mat (van der Velde, 2016b).</p>
<p>But, for example, the transformation of the question Where is cat? into the more general form Where -localizer -noun?, learned by the reservoir in the NBA, is based on an analysis. In contrast, the learning mechanism of IDyOT can provide the information to train the reservoir in the NBA, based on real corpora. Conversely, the distinction between structured neural blackboards and the control reservoirs in the NBA can strongly reduce the number of contingencies that have to be learned over time, as illustrated with the ease with which the reservoir can learn to recognize Where -localizer -noun -Agent (van der Velde, 2016b).</p>
<p>The more elaborate learning mechanism of IDyOT would thus have to be integrated with the NBA, and eventually be implemented with neural reservoirs that interact with the neural blackboard in the NBA. The learning process in IDyOT is outlined in more detail below, again for the first time.</p>
<p>7.1. The IDyOT Incremental Learning Process 7.1.1. Initial State</p>
<p>Initially, IDyOT has no memory, no symbols, and only inputs. Input is in terms of percepts conceptualized as symbols representing continuous real-world phenomena at whatever level of abstract is chosen: here, phonemes, pitch, amplitude, and observed meaning (emoji).</p>
<p>Chunks and Labels</p>
<p>Given a low-level, predefined conceptual space, S v (which initially has no geometry, but learns it as more data is received), for each low-level viewpoint, v, IDyOT labels the mutually discriminable points in S v with symbols, building an alphabet, ℵ(v), and, separately, builds a chain of these symbols as the input sequence proceeds; this may be thought of as the chain l i in Figure 3. Simultaneously, IDyOT builds a first order transition matrix of the chain; this will allow the construction of successive distributions over ℵ(v), D t,ℵ(v) , as time, t, proceeds. Each symbol is considered in relation to the symbols already created, in terms of their corresponding points: a quasi-Euclidean distance (norm), in S v , may be computed between them. At the same time, the space is progressively partitioned into regions whose points are nearest to each point in the sequence, as in a Voronoi Tessellation (Aurenhammer, 1991). This tessellation, possibly modified by a parameter which creates a gap between the regions (Figure 7), forms the basis of similarity comparison. Points in (non-zero) gap regions form new seeds. This process will, of course, produce initially inaccurate predictions and labelings, but as sufficient data is processed, these early errors fade into statistical obscurity, propelled by the memory consolidation process described below.</p>
<p>However, this simple mechanism would not account for the human propensity to perceive what is expected, because S v , the conceptual space associated with v, is static. The distribution, D 0,ℵ(v) , describes IDyOT's expectation at this point; it is derived from the transition matrix for v. Each region, R v,s , where s ∈ ℵ(v) in the Voronoi tessellation of S v is now expanded or contracted, by changing the position of each plane dividing the space, in proportion to the relative likelihood of the symbols corresponding with the points to whose connecting line the plane is perpendicular. A parameter, whose value is the subject of study, determines the degree of variation; an interesting possibility is that this value is related to entropy of the distribution, as was found empirically to be case in a related application of distributions in IDyOM , where distributions containing more information influence the outcome more. Thus, the less expected a phoneme, s, is, the smaller its R v,s temporarily becomes, and so a phoneme that is both imprecisely articulated and unexpected may be misidentified as one near it, which is more likely in the distribution (Figure 7). IDyOT behaves like a human in this context: it commits to memory incorrect perceptions, as if they were correct.</p>
<p>Chunking: Competition and Boundary Entropy</p>
<p>Each new symbol, indexing a point in S v , is available to all generators associated with this viewpoint (see Figure 3). As the transition matrix is populated, predictions can be made of likelihood, and as IDyOT's memory develops, progressively more informed predictions may be made using the probabilistic network afforded by the layered memory. Thus, the entire context will influence D t,ℵ(v) it any time point t. Again, initially, these predictions will not be particularly accurate; as more data is received they will improve. As each new label appears, therefore, a new distribution is generated, and its entropy, H(D t+1,ℵ(v) ) can be calculated and compared with H (D t,ℵ(v) ). On the basis of empirical evidence from computational linguistics and music cognition (e.g., Sproat et al., 1994;Brent, 1999;Pearce et al., 2010;Rohrmeier et al., 2015), at each time step, IDyOT's agents compete for global workspace access, the largest positive change being the winner. If no agent registers an increase in entropy, there is no winner, and no change in the memory; IDyOT proceeds to the next input stimulus.</p>
<p>Thus, IDyOT achieves hierarchical perceptual chunking.</p>
<p>Layer Formation and Abstraction</p>
<p>Following the identification of a chunk in memory, IDyOT must decide whether to generate a new label or to label this chunk with an existing symbol, on grounds of similarity. In the former case, a new label is generated, at level L i in Figure 3, and it is added to memory, along with pointers to the lower level chunk that it subtends; also, the transition matrix for the upper layer is updated. A further transition matrix, of which one exists for each pair of contiguous levels, is also updated with the new symbol and transition. In this connection, a higher-level symbol is deemed to connect down to any symbol in its chunk, while any lower level symbol is deemed to connect to any symbol in whose chunk it appears. It is implicit in this process that each symbol in an IDyOT memory chain may be subtended by more than one symbol at the immediately higher level, and it may subtend more than one symbol below. Transition matrices for these upward connections, too, must be maintained.</p>
<p>Returning to the example: the higher level sequence has a transition matrix, and so its entropy can be determined, symbolwise, as above, and therefore the same boundary test as above can be applied. If a new chunk at this level is detected, then the same process applies, and so on up the layers of the network, using the same principle of similarity measurement as above. This first generates level L i in Figure 3, and then on beyond the scope of that simple example.</p>
<p>This recursive process constructs a tree from the very lowest level of representation up to the highest possible abstraction, as shown for our concrete example, in Figure 4. Although this simple example has focused on only one aspect of the stimulus, it is important to recall that, in a fully implemented IDyOT, all modalities of perception would be active simultaneously, and synchronized (Forth et al., 2016) in such a way as to interrelate simultaneous stimuli. Thus, the association between, for example, the word "orange", the sound [6rInZ], and appropriate representations of the corresponding color, fruit, pop star and politics, could be learned, as illustrated in Figure 4.</p>
<p>FURTHER RELATIONS BETWEEN NBA AND IDYOT</p>
<p>Conceptual spaces</p>
<p>The semantics underlying the IDyOT and NBA representations are derived from the conceptual spaces with which they interact. In turn, the conceptual spaces play a role in processing in both architectures. For IDyOT, the role of conceptual spaces is illustrated in Figure 4. In the NBA, representations of conceptual structures (relations, propositions, sentences) are based on content addressable concept representations, which directly and selectively activate conceptual structures in neural blackboards. Also, conceptual domains and relations are needed to influence sequential processing in the control reservoirs of the NBA (van der Velde, 2016a).</p>
<p>McGregor et al. (2015) outline a basis for a geometrical conceptual space, with interpretable spaces and dimensions derived from observed co-occurrence statistics in a large corpus. Conceptual relations and domains can be obtained by the techniques described by McGregor et al. (2015) and by the metric based on a semantic map as derived by van der Velde et al. (2015). This semantic map also consists of a co-occurrence matrix, derived from human categorizations. The metric provided a similar concept-cluster structure as derived from reduction techniques. But it also revealed the possibility of deriving bridges between conceptual domains based on metric violations.</p>
<p>The geometrical nature of such a conceptual space provides a natural representation for the content addressable concept representations underling the combined IDyOT-NBA architecture. Furthermore, the geometrical nature of this conceptual space and the neural blackboard mechanisms of the IDyOT-NBA architecture provide the possibilities of new forms of hardware implementations that can circumvent the limitations of the Von Neumann Architecture, on which symbolic computation is standardly based.</p>
<p>Brain and Computation</p>
<p>As referred to in our introduction, the processing of conceptual structures can be studied with the aim to understand human cognition and its relation to the brain. Or they can be targets for the development of artificial cognitive systems. We argue that a combined IDyOT-NBA architecture can address both aims.</p>
<p>Because learning in IDyOT is based on information found in real corpora, it derives structures and processes based on human information processing and generation. In this way, the NBA structures and processes derived from IDyOT will be based on human information processing as well. The neural implementation of the NBA then allows a comparison between the structures and processes of the combined architecture with those observed in brain research.</p>
<p>An example of how the combined architecture can be related to neuro-cognitive processing is presented in Figure 8. The figure illustrates a novel simulation of NBA activity, with the processing of the sentence Bill-Gates has met two very tired dancers in Dallas, with Bill-Gates as one noun (BG). Activation of "main assemblies" (MA), "sub assemblies" (SA) and binding in working memory (WM) are shown, because they determine the representation structure of the sentence in the sentence neural blackboard of the NBA (van der Velde and de Kamps, 2006). Also shown is the overall activation of all assemblies and circuits, consisting of more than 300 neural populations in all (marked "Total"; red line). The neural populations are simulated with Wilson and Cowan population dynamics (Wilson and Cowan, 1972).</p>
<p>Using intracranial measurements, Nelson et al. (2014) observed that binding of words and phrases produces an increase and then decrease of activity (e.g., because binding related activation will reduce after binding). The NBA activation simulates this effect, and also indicates why it occurs, i.e., which structures and processes are related to this effect. In particular, total neural activity first increases when a new word is presented (as illustrated by the increase of total activity at the location of the black vertical bars, that indicate the presentation times of the words). But then, total activity drops, due to the binding of the presented word to previously presented words and phrases in the developing sentence structure in the sentence neural blackboard of the NBA. Occasionally, activity does not decline, as with Bill has or very tired, which results from the fact that Bill is the first word, which cannot bind to other words yet, and very does not bind to the previous word two.</p>
<p>Hence, the simulation illustrates the close relation between neural dynamics and the representation structures underlying processed sentences in the NBA. The aim of the integration of NBA with IDyOT is to develop these representation structures by learning from real corpora. In this way, machine learning FIGURE 8 | (A): NBA structure of Bill-Gates has met two very tired dancers in Dallas, with B(ill)-Gates as one noun. Aux, va, auxiliary verb; Adj, na, adjective; Adv, ad, adverb; N, n, noun; Num, nm, numerator; PP, pv, pn, preposition; S, sentence; V, v, verb. (B): Neural activity in the NBA when Bill-Gates has met two very tired dancers in Dallas is processed. BG, Bill Gates; d'ers, dancers; MA, main assemblies; SA, sub assemblies; WM, working memory. 'Total' (red activity ) is the sum of the activation of all neural populations in the NBA structure of this sentence (over 300 populations), simulated with Wilson-Cowan population dynamics. The words of the sentence are presented at the times indicated with the vertical bars. The last bar signals the end of input activation.</p>
<p>could be related to brain activity observed in human cognitive processing.</p>
<p>Furthermore, the NBA predicts the existence of "connection" fields (or matrices) with special roles, such as "agent" and "theme" (object) in which bindings between (e.g.,) arbitrary verbs and nouns as (agent or theme) arguments can occur. Recent fMRI observations indicated the existence of (agent and theme) areas in the cortex that are selectively activated when nouns function, respectively, as agents or themes of verbs (Frankland and Greene, 2015). The activation patterns in these areas also concur with the activation patterns produced in the NBA. These areas could form a neural substrate for (parts of) a Global Workspace, in which competitions between neural structural representations could occur.</p>
<p>The combined IDyOT-NBA architecture also targets the development of artificial cognitive systems. Recently, Lake et al. (2016) argued that, despite recent successes, Deep Learning does not capture essential characteristics of human learning and processing. One of the difficulties for Deep Learning concerns compositional (combinatorial) processing, in which structured information is processed in terms of already familiar constituents and partial structures.</p>
<p>A crucial feature of compositional processing is the interaction between specialized processors and domains in which these processors, and the information they process, can interact, compete, and be combined. This is what the neural blackboards and the workspace in NBA and IDyOT are about. Because the combined architecture can develop and activate these structures based on learning from real corpora, it can address key features of human cognitive processing.</p>
<p>The combined architecture can also address new demands on computing power because the NBA can be implemented fully as a system operating in parallel, based on dynamic interactions. Of course, processing will be sequential when input is presented in a sequential manner. Also, the dynamic interactions will proceed in time as well. But each of the components (e.g., connection nodes in the connection matrices) will operate in parallel with all other components, and their interactions are based on direct dynamical activation and competition. When implemented in hardware, this allows the system to operate at minimal levels of power, with fast processing speeds.</p>
<p>CONCLUSION</p>
<p>We have presented two knowledge representations, used in two cognitive architectures, the NBA and IDyOT, that both aim to account for conceptual representation and processing in productive forms of cognition. Although the architectures differ in that the NBA is neural and IDyOT is symbolic, they are also similar in many ways. Both assume that conceptual representations consist of structures in which all aspects related to a concept are interconnected. Both assume that processing with representations occur in blackboards or a workspace, in which these representations can interact and can be (re)combined. And both rely on the principles of chunking to generate higher-level structural representations based on the more elementary ones.</p>
<p>Finally, the relations between both architectures combined with their different bases provide unique opportunities for a complementary integration. The NBA could provide a neural implementation of the processing and representation of higher level conceptual representations and IDyOT could provide the learning mechanisms by which the more elementary representations needed for this implementation could be derived from human cognitive (corpus) material.</p>
<p>AUTHOR CONTRIBUTIONS</p>
<p>FvV and DN wrote the sections on NBA. GW wrote the sections on IDyOT, based on discussions with JF. The rest was a joint effort.</p>
<p>FIGURE 5 |
5Left: conditional connections. N, n, noun; i, inhibition; di, dis-inhibition; WM, working memory. Right: Representation of cat sees cat in the sentence neural blackboard. S, sentence; V, v, verb; t, theme (object).</p>
<p>FIGURE 6 |
6(A) Conditional connections. N, noun; V, verb, t, theme (object) . (B) Connection matrix. (C) Connection node. i, inhibition; di, dis-inhibition; WM, working memory.</p>
<p>FIGURE 7 |
7Modulating conceptual regions according to expectedness. (A) The unmodified Voronoi tessellation of the conceptual space of phonemes, S , showing the boundary between R S ,@ and R S ,D . (B) The modified tessellation; note that the distances from the labeled points to the boundary have changed in proportion to the relative likelihoods in D 0, . (C) The tessellation with a non-zero gap. (D) Schematic partial representation of the distribution, D 0, showing (imaginary) proportions for /@/ and /D/.</p>
<p>Table 1 .
11. The fundamental function of cognition is to efficiently process sensory information so as to predict what is to happen next in the world.2. Predictions are made by classifying events ( § §6.1.3,7.1.3), counting likelihoods of short sequences, and building a literal model of the experience of the organism in these terms ( §6.1.1). Predictions are expressed as distributions over alphabets of events. 3. Events are identified by chunking sensory input ( §7.1.3).</p>
<p>TABLE 1 |
1Notation used in the current description of IDyOT.
August 2017 | Volume 8 | Article 1297
Frontiers in Psychology | www.frontiersin.org
ACKNOWLEDGMENTSConflict of Interest Statement:The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.Copyright © 2017 van der Velde, Forth, Nazareth and Wiggins. This is an openaccess article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) or licensor are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.
Modeling Brain Function. D Amit, Cambridge University PressCambridge, MAAmit, D. (1989). Modeling Brain Function. Cambridge, MA: Cambridge University Press.</p>
<p>Voronoi diagrams -a survey of a fundamental geometric data structure. F Aurenhammer, 10.1145/116873.116880ACM Comput. Surv. 23Aurenhammer, F. (1991). Voronoi diagrams -a survey of a fundamental geometric data structure. ACM Comput. Surv. 23, 345-405. doi: 10.1145/116873.116880</p>
<p>A Cognitive Theory of Consciousness. B J Baars, Cambridge University PressNew York, NYBaars, B. J. (1988). A Cognitive Theory of Consciousness. New York, NY: Cambridge University Press.</p>
<p>An efficient, probabilistically sound algorithm for segmentation and word discovery. M R Brent, 10.1023/A:1007541817488Mach. Learn. 34Brent, M. R. (1999). An efficient, probabilistically sound algorithm for segmentation and word discovery. Mach. Learn. 34, 71-105. doi: 10.1023/A:1007541817488</p>
<p>Applications of Conceptual Spaces: The Case for Geometric Knowledge Representation, number 359 in Synthese Library. A Chella, Cham HeidelbergA cognitive architecture for music perception exploiting conceptual spacesChella, A. (2015). "A cognitive architecture for music perception exploiting conceptual spaces, " in Applications of Conceptual Spaces: The Case for Geometric Knowledge Representation, number 359 in Synthese Library. Cham Heidelberg;</p>
<p>Imitation learning and anchoring through conceptual spaces. A Chella, H Dindo, I Infantino, 10.1080/08839510701252619Appl. Artif. Intell. 21Chella, A., Dindo, H., and Infantino, I. (2007). Imitation learning and anchoring through conceptual spaces. Appl. Artif. Intell. 21, 343-359. doi: 10.1080/08839510701252619</p>
<p>A cognitive architecture for robot self-consciousness. A Chella, M Frixione, S Gaglio, 10.1016/j.artmed.2008.07.003Artif. Intell. Med. 44Chella, A., Frixione, M., and Gaglio, S. (2008). A cognitive architecture for robot self-consciousness. Artif. Intell. Med. 44, 147-154. doi: 10.1016/j.artmed.2008.07.003</p>
<p>Prediction and Entropy of Music. D Conklin, Department of Computer Science, University of CalgaryMaster's ThesisConklin, D. (1990). Prediction and Entropy of Music. Master's Thesis, Department of Computer Science, University of Calgary.</p>
<p>Multiple viewpoint systems for music prediction. D Conklin, I Witten, 10.1080/09298219508570672J. New Music Res. 24Conklin, D., and Witten, I. (1995). Multiple viewpoint systems for music prediction. J. New Music Res. 24, 51-73. doi: 10.1080/09298219508</p>
<p>Blackboard systems. D D Corkill, AI Expert. 6Corkill, D. D. (1991). Blackboard systems. AI Expert 6, 40-47.</p>
<p>Probabilistic induction for an incremental semantic grammar. A Eshghi, M Purver, J Hough, Proceedings of the 10th International Conference on Computational Semantics (IWCS 2013) -Long Papers. the 10th International Conference on Computational Semantics (IWCS 2013) -Long PapersPotsdamAssociation for Computational LinguisticsEshghi, A., Purver, M., and Hough, J. (2013). "Probabilistic induction for an incremental semantic grammar, " in Proceedings of the 10th International Conference on Computational Semantics (IWCS 2013) -Long Papers, (Potsdam: Association for Computational Linguistics), 107-118.</p>
<p>Entraining IDyOT: time in the information dynamics of thinking. J Forth, K Agres, M Purver, G A Wiggins, 10.3389/fpsyg.2016.01575Front. Psychol. 71575Forth, J., Agres, K., Purver, M., and Wiggins, G. A. (2016). Entraining IDyOT: time in the information dynamics of thinking. Front. Psychol. 7:1575. doi: 10.3389/fpsyg.2016.01575</p>
<p>An architecture for encoding sentence meaning in left mid-superior temporal cortex. S M Frankland, J D Greene, 10.1073/pnas.1421236112Proc. Natl. Acad. Sci. U.S.A. 112Frankland, S. M., and Greene, J. D. (2015). An architecture for encoding sentence meaning in left mid-superior temporal cortex. Proc. Natl. Acad. Sci. U.S.A. 112, 11732-11737. doi: 10.1073/pnas.1421236112</p>
<p>Conceptual Spaces: The Geometry of Thought. P Gärdenfors, MIT PressCambridge, MAGärdenfors, P. (2000). Conceptual Spaces: The Geometry of Thought. Cambridge, MA: MIT Press.</p>
<p>Geometry of Meaning. P Gärdenfors, MIT PressCambridge, MAGärdenfors, P. (2014). Geometry of Meaning. Cambridge, MA: MIT Press.</p>
<p>The Organisation of Behaviour. D O Hebb, WileyNew York, NYHebb, D. O. (1949). The Organisation of Behaviour. New York, NY: Wiley.</p>
<p>Natural speech reveals the semantic maps that tile human cerebral cortex. A G Huth, W A De Heer, T L Griffiths, F E Theunissen, J L Gallant, 10.1038/nature17637Nature. 532Huth, A. G., de Heer, W. A., Griffiths, T. L., Theunissen, F. E., and Gallant, J. L. (2016). Natural speech reveals the semantic maps that tile human cerebral cortex. Nature 532, 453-458. doi: 10.1038/nature17637</p>
<p>Foundations of Language. R Jackendoff, Oxford University PressOxfordJackendoff, R. (2002). Foundations of Language. Oxford: Oxford University Press.</p>
<p>Harnessing nonlinearity: predicting chaotic systems and saving energy in wireless communication. H Jaeger, H Haas, 10.1126/science.1091277Science. 304Jaeger, H., and Haas, H. (2004). Harnessing nonlinearity: predicting chaotic systems and saving energy in wireless communication. Science 304, 78-80. doi: 10.1126/science.1091277</p>
<p>Building machines that learn and think like people. B M Lake, T D Ullman, J B Tenenbaum, S J Gershman, 10.1017/S0140525X16001837Behav. Brain Sci. Epub ahead of printLake, B. M., Ullman, T. D., Tenenbaum, J. B., and Gershman, S. J. (2016). Building machines that learn and think like people. Behav. Brain Sci. doi: 10.1017/S0140525X16001837. [Epub ahead of print].</p>
<p>From distributional semantics to conceptual spaces: a novel computational method for concept creation. S Mcgregor, K Agres, M Purver, G A Wiggins, 10.1515/jagi-2015-0004J. Artif. Gen. Intell. 6McGregor, S., Agres, K., Purver, M., and Wiggins, G. A. (2015). From distributional semantics to conceptual spaces: a novel computational method for concept creation. J. Artif. Gen. Intell. 6, 55-86. doi: 10.1515/jagi- 2015-0004</p>
<p>M J Nelson, I El Karoui, V Rangarajan, C Pallier, J Parvizi, L Cohen, Constituent structure representations revealed with intracranial data. Washington, DCPosterSociety for Neuroscience Annual MeetingNelson, M. J., El Karoui, I., Rangarajan, V., Pallier, C., Parvizi, J., Cohen, L., et al. (2014). "Constituent structure representations revealed with intracranial data, " in Society for Neuroscience Annual Meeting (Washington, DC: Poster).</p>
<p>The Construction and Evaluation of Statistical Models of Melodic Structure in Music Perception and Composition. M T Pearce, LondonDepartment of Computing, City UniversityPh.D. ThesisPearce, M. T. (2005). The Construction and Evaluation of Statistical Models of Melodic Structure in Music Perception and Composition. Ph.D. Thesis, Department of Computing, City University, (London).</p>
<p>Methods for combining statistical models of music. M T Pearce, D Conklin, G A Wiggins, Computer Music Modelling and Retrieval. U. K. WiilHeidelbergSpringer VerlagPearce, M. T., Conklin, D., and Wiggins, G. A. (2005). "Methods for combining statistical models of music, " in Computer Music Modelling and Retrieval, ed U. K. Wiil (Heidelberg: Springer Verlag), 295-312.</p>
<p>The role of expectation and probabilistic learning in auditory boundary perception: a model comparison. M T Pearce, D Müllensiefen, G A Wiggins, 10.1068/p6507Perception. 39Pearce, M. T., Müllensiefen, D., and Wiggins, G. A. (2010). The role of expectation and probabilistic learning in auditory boundary perception: a model comparison. Perception 39, 1367-1391. doi: 10.1068/p6507</p>
<p>Auditory expectation: the information dynamics of music perception and cognition. M T Pearce, G A Wiggins, 10.1111/j.1756-8765.2012.01214.xTop. Cogn. Sci. 4Pearce, M. T., and Wiggins, G. A. (2012). Auditory expectation: the information dynamics of music perception and cognition. Top. Cogn. Sci. 4, 625-652. doi: 10.1111/j.1756-8765.2012.01214.x</p>
<p>Bayesian networks. J Pearl, The MIT Encyclopedia of the Cognitive Sciences. R. A. Wilson and F. C. KeilCambridge, MAMIT PressPearl, J. (1999). "Bayesian networks, " in The MIT Encyclopedia of the Cognitive Sciences, eds R. A. Wilson and F. C. Keil (Cambridge, MA: MIT Press), 72-74.</p>
<p>Concept cells: the building blocks of declarative memory functions. R Quian Quiroga, 10.1038/nrn3251Nat. Rev. Neurosci. 13Quian Quiroga, R. (2012). Concept cells: the building blocks of declarative memory functions. Nat. Rev. Neurosci. 13, 587-597. doi: 10.1038/nrn3251</p>
<p>Principles of structure building in music, language and animal song. M Rohrmeier, W Zuidema, G A Wiggins, C Scharff, 10.1098/rstb.2014.0097Philos. Trans. R. Soc. Lond. B Biol. Sci. 370Rohrmeier, M., Zuidema, W., Wiggins, G. A., and Scharff, C. (2015). Principles of structure building in music, language and animal song. Philos. Trans. R. Soc. Lond. B Biol. Sci. 370:20140097. doi: 10.1098/rstb.2014.0097</p>
<p>Embodiment and the Inner Life. M Shanahan, Oxford University PressOxfordShanahan, M. (2010). Embodiment and the Inner Life. Oxford: Oxford University Press.</p>
<p>Circulatory in judgments of relative pitch. R N Shepard, 10.1121/1.1919362J. Acoust. Soc. Am. 36Shepard, R. N. (1964). Circulatory in judgments of relative pitch. J. Acoust. Soc. Am. 36, 2346-2353. doi: 10.1121/1.1919362</p>
<p>The altricial-precocial spectrum for robots. A Sloman, J Chappell, Proceedings of the 19th International Joint Conference on Artificial Intelligence. the 19th International Joint Conference on Artificial IntelligenceEdinburghSloman, A., and Chappell, J. (2005). "The altricial-precocial spectrum for robots, " in Proceedings of the 19th International Joint Conference on Artificial Intelligence, Edinburgh.</p>
<p>A stochastic finite-state wordsegmentation algorithm for chinese. R Sproat, C Shih, W Gale, Chang , N , Proceedings of the 32nd Annual Meeting of the Association for Computational Linguistics. the 32nd Annual Meeting of the Association for Computational LinguisticsLas Cruces, NMSproat, R., Shih, C., Gale, W., and Chang, N. (1994). "A stochastic finite-state word- segmentation algorithm for chinese, " in Proceedings of the 32nd Annual Meeting of the Association for Computational Linguistics, Las Cruces, NM. 66-73.</p>
<p>How to grow a mind: statistics, structure, and abstraction. J B Tenenbaum, C Kemp, T L Griffiths, N D Goodman, 10.1126/science.1192788Science. 331Tenenbaum, J. B., Kemp, C., Griffiths, T. L., and Goodman, N. D. (2011). How to grow a mind: statistics, structure, and abstraction. Science 331, 1279-1285. doi: 10.1126/science.1192788</p>
<p>Concepts and relations in neurally inspired in situ concept-based computing. F ; F Van Der Velde, 10.3389/fnbot.2016.00004doi: 10.3389/fnbot.2016.00004Front. Neurorobot. 624Neural Netw.van der Velde, F. (2015). Communication, concepts and grounding. Neural Netw. 62, 112-117. doi: 10.1016/j.neunet.2014.07.003 van der Velde, F. (2016a). Concepts and relations in neurally inspired in situ concept-based computing. Front. Neurorobot. 10:4. doi: 10.3389/fnbot.2016.00004</p>
<p>Learning sequential control in a neural blackboard architecture for in situ concept reasoning. F Van Der Velde, Proceedings of NeSy 2016: Neural-Symbolic Learning and Reasoning. T. R. Besold, W. Tabor, L. Serafini and L. LambNeSy 2016: Neural-Symbolic Learning and ReasoningNew York, NYvan der Velde, F. (2016b). "Learning sequential control in a neural blackboard architecture for in situ concept reasoning, " in Proceedings of NeSy 2016: Neural- Symbolic Learning and Reasoning, eds T. R. Besold, W. Tabor, L. Serafini and L. Lamb (New York, NY), 1-11.</p>
<p>Neural blackboard architectures of combinatorial structures in cognition. F Van Der Velde, M De Kamps, 10.1017/S0140525X06009022Behav. Brain Sci. 29van der Velde, F., and de Kamps, M. (2006). Neural blackboard architectures of combinatorial structures in cognition. Behav. Brain Sci. 29, 37-70. doi: 10.1017/S0140525X06009022</p>
<p>Learning of control in a neural architecture of grounded language processing. F Van Der Velde, M De Kamps, 10.1016/j.cogsys.2008.08.007Cogn. Syst. Res. 11van der Velde, F., and de Kamps, M. (2010). Learning of control in a neural architecture of grounded language processing. Cogn. Syst. Res. 11, 93-107. doi: 10.1016/j.cogsys.2008.08.007</p>
<p>The necessity of connection structures in neural models of variable binding. F Van Der Velde, M De Kamps, 10.1007/s11571-015-9331-7Cogn. Neurodyn. 9van der Velde, F., and de Kamps, M. (2015a). The necessity of connection structures in neural models of variable binding. Cogn. Neurodyn. 9, 359-370. doi: 10.1007/s11571-015-9331-7</p>
<p>Combinatorial structures and processing in neural blackboard architectures. F Van Der Velde, M De Kamps, Cognitive Computation. van der Velde, F., and de Kamps, M. (2015b). "Combinatorial structures and processing in neural blackboard architectures, " in Cognitive Computation:</p>
<p>A semantic map for evaluating creativity. F Van Der Velde, R A Wolf, M Schmettow, D S Nazareth, inProceedings of the Sixth International Conference on Computational Creativity. H. Toivonen, S. Colton, M. Cook, and D. VenturaPark CityUT: Brigham Young UniversityICCC 2015van der Velde, F., Wolf, R. A., Schmettow, M., and Nazareth, D. S. (2015). "A semantic map for evaluating creativity, " inProceedings of the Sixth International Conference on Computational Creativity (ICCC 2015), eds H. Toivonen, S. Colton, M. Cook, and D. Ventura (Park City, UT: Brigham Young University), 94-101.</p>
<p>Mind the gap: an attempt to bridge computational and neuroscientific approaches to study creativity. G Wiggins, J Bhattacharya, 10.3389/fnhum.2014.00540Front. Hum. Neurosci. 8540Wiggins, G., and Bhattacharya, J. (2014). Mind the gap: an attempt to bridge computational and neuroscientific approaches to study creativity. Front. Hum. Neurosci. 8:540. doi: 10.3389/fnhum.2014.00540</p>
<p>I let the music speak: cross-domain application of a cognitive model of musical learning. G A Wiggins, Statistical Learning and Language Acquisition. P. Rebuschat and J. WilliamsAmsterdam, NLMouton De GruyterWiggins, G. A. (2012a). "I let the music speak: cross-domain application of a cognitive model of musical learning, " in Statistical Learning and Language Acquisition, eds P. Rebuschat and J. Williams (Amsterdam, NL: Mouton De Gruyter). 463-495.</p>
<p>The mind's chorus: creativity before consciousness. G A Wiggins, 10.1007/s12559-012-9151-6Cogn. Comput. 4Wiggins, G. A. (2012b). The mind's chorus: creativity before consciousness. Cogn. Comput. 4, 306-319. doi: 10.1007/s12559-012-9151-6</p>
<p>IDyOT: a computational theory of creativity as everyday reasoning from learned information. G A Wiggins, J C Forth, Computational Creativity Research: Towards Creative Machines. T. R. Besold, M. Schorlemmer, and A. SmaillAtlantis/SpringerWiggins, G. A., and Forth, J. C. (2015). "IDyOT: a computational theory of creativity as everyday reasoning from learned information, " in Computational Creativity Research: Towards Creative Machines, eds T. R. Besold, M. Schorlemmer, and A. Smaill (Atlantis/Springer: Atlantis Thinking Machines). 127-150.</p>
<p>Excitatory and inhibitory interactions in localized populations of model neurons. H R Wilson, J D Cowan, 10.1016/S0006-3495(72)86068-5Biophys. J. 12Wilson, H. R., and Cowan, J. D. (1972). Excitatory and inhibitory interactions in localized populations of model neurons. Biophys. J. 12, 1-24. doi: 10.1016/S0006-3495(72)86068-5</p>            </div>
        </div>

    </div>
</body>
</html>