<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-247 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-247</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-247</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-14.html">extraction-schema-14</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic operations, including the types of arithmetic tasks, model properties, performance results, methods used, and any mechanistic insights about how the models solve arithmetic problems.</div>
                <p><strong>Paper ID:</strong> paper-267027689</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2401.08664v3.pdf" target="_blank">Adapting Large Language Models for Education: Foundational Capabilities, Potentials, and Challenges</a></p>
                <p><strong>Paper Abstract:</strong> Online education platforms, leveraging the internet to distribute education resources, seek to provide convenient education but often fall short in real-time communication with students. They often struggle to address the diverse obstacles students encounter throughout their learning journey. Solving the problems encountered by students poses a significant challenge for traditional deep learning models, as it requires not only a broad spectrum of subject knowledge but also the ability to understand what constitutes a student's individual difficulties. It's challenging for traditional machine learning models, as they lack the capacity to comprehend students' personalized needs. Recently, the emergence of large language models (LLMs) offers the possibility for resolving this issue by comprehending individual requests. Although LLMs have been successful in various fields, creating an LLM-based education system is still challenging for the wide range of educational skills required. This paper reviews the recently emerged LLM research related to educational capabilities, including mathematics, writing, programming, reasoning, and knowledge-based question answering, with the aim to explore their potential in constructing the next-generation intelligent education system. Specifically, for each capability, we focus on investigating two aspects. Firstly, we examine the current state of LLMs regarding this capability: how advanced they have become, whether they surpass human abilities, and what deficiencies might exist. Secondly, we evaluate whether the development methods for LLMs in this area are generalizable, that is, whether these methods can be applied to construct a comprehensive educational supermodel with strengths across various capabilities, rather than being effective in only a singular aspect.</p>
                <p><strong>Cost:</strong> 0.016</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e247.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e247.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic operations, including the types of arithmetic tasks, model properties, performance results, methods used, and any mechanistic insights about how the models solve arithmetic problems.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-4 / ChatGPT (arithmetic observations)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-4 and ChatGPT (observations reported in survey)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Surveyed observations that GPT-4 and ChatGPT handle addition and subtraction relatively well but show degraded accuracy on multiplication with large numbers; suggested remedies include fine-tuning or outsourcing computation to tools.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>How well do Large Language Models perform in Arithmetic tasks?</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4 / ChatGPT</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_architecture</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>arithmetic_operation_type</strong></td>
                            <td>addition, subtraction, multiplication (noted degradation on larger multiplication)</td>
                        </tr>
                        <tr>
                            <td><strong>number_range_or_complexity</strong></td>
                            <td>large-number multiplication (unspecified number of digits); general multi-digit cases referenced</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_intervention</strong></td>
                            <td>standard prompting / zero-shot usage as evaluated in referenced analyses (no calculator by default)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_result</strong></td>
                            <td>Reported as 'good' on addition and subtraction but accuracy decreases for multiplication with larger numerical values (no precise percentages provided in survey text).</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_insight</strong></td>
                            <td>Survey cites that LLMs do not perform deterministic arithmetic internally but generate text (digits) token-by-token, so errors compound as answer length grows.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_scaling</strong></td>
                            <td>Performance degrades as number of digits increases; even large-capacity models like GPT-4 can struggle on large multiplications compared to their performance on other benchmarks.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>Cumulative digit-wise errors for multi-digit results; particularly poor on large-number multiplication.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared implicitly to fine-tuned specialized models and to approaches that use external calculators or tool-augmented methods.</td>
                        </tr>
                        <tr>
                            <td><strong>key_finding</strong></td>
                            <td>High-capacity conversational LLMs (e.g., GPT-4/ChatGPT) often handle simple addition/subtraction but fail on large multi-digit multiplication because they generate answers token-by-token rather than performing exact arithmetic; tool use or fine-tuning is needed for reliable results.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Adapting Large Language Models for Education: Foundational Capabilities, Potentials, and Challenges', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e247.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e247.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic operations, including the types of arithmetic tasks, model properties, performance results, methods used, and any mechanistic insights about how the models solve arithmetic problems.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Small transformers (fine-tuned on stepwise arithmetic)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Small transformer models trained/fine-tuned on high-quality, stepwise arithmetic data</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Multiple works report that relatively small transformer models can achieve high accuracy on multi-digit arithmetic when fine-tuned on datasets that include detailed calculation steps or procedural traces.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Teaching arithmetic to small transformers</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Small transformer models (unspecified architectures in survey)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_architecture</strong></td>
                            <td>transformer (small)</td>
                        </tr>
                        <tr>
                            <td><strong>arithmetic_operation_type</strong></td>
                            <td>multi-step arithmetic, multi-digit addition/multiplication (general)</td>
                        </tr>
                        <tr>
                            <td><strong>number_range_or_complexity</strong></td>
                            <td>multi-digit problems (exact ranges not specified in survey); emphasis on multi-digit multiplication/addition</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_intervention</strong></td>
                            <td>fine-tuning on high-quality datasets containing detailed calculation processes / procedural traces (supervised fine-tuning)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_result</strong></td>
                            <td>Survey reports that small transformers trained in this manner can 'solve arithmetic problems with high accuracy' and 'avoid mistakes on multi-digit problems' (no numeric accuracies reported in the survey itself).</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_insight</strong></td>
                            <td>When trained on step-by-step calculation traces, small models appear to learn algorithmic/procedural strategies rather than only memorizing outputs, enabling correct multi-digit computation.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_scaling</strong></td>
                            <td>Fine-tuning on targeted, high-quality arithmetic data can enable small models to match or surpass larger models on arithmetic tasks; performance depends more on task-specific training data quality than raw parameter count.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>Without task-specific fine-tuning or stepwise training data, small transformers would revert to token-generation failure modes similar to larger LLMs.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Before vs after fine-tuning on stepwise arithmetic traces; small fine-tuned models compared favorably to larger unfine-tuned LLMs on arithmetic tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>key_finding</strong></td>
                            <td>Carefully curated, stepwise training data can teach small transformers to implement reliable arithmetic procedures, demonstrating that data quality (detailed procedural supervision) can outweigh sheer model size for arithmetic competence.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Adapting Large Language Models for Education: Foundational Capabilities, Potentials, and Challenges', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e247.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e247.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic operations, including the types of arithmetic tasks, model properties, performance results, methods used, and any mechanistic insights about how the models solve arithmetic problems.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Goat (fine-tuned LLaMA)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Goat: Fine-tuned LLaMA Outperforms GPT-4 on Arithmetic Tasks</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A referenced work that fine-tunes a LLaMA-based model on arithmetic tasks and reports superior arithmetic performance compared to GPT-4 on those tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Goat: Fine-tuned LLaMA Outperforms GPT-4 on Arithmetic Tasks</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Goat (fine-tuned LLaMA variant)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_architecture</strong></td>
                            <td>LLaMA-based transformer (fine-tuned)</td>
                        </tr>
                        <tr>
                            <td><strong>arithmetic_operation_type</strong></td>
                            <td>arithmetic tasks (paper title implies a focus on arithmetic benchmarks including multi-digit tasks)</td>
                        </tr>
                        <tr>
                            <td><strong>number_range_or_complexity</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>method_or_intervention</strong></td>
                            <td>fine-tuning of a base LLaMA model on arithmetic-specific datasets</td>
                        </tr>
                        <tr>
                            <td><strong>performance_result</strong></td>
                            <td>Survey cites the external paper's claim that Goat (fine-tuned LLaMA) outperforms GPT-4 on arithmetic tasks; survey provides no numerical breakdown itself.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_insight</strong></td>
                            <td>Implied insight: targeted fine-tuning on arithmetic datasets enables language models to internalize reliable arithmetic behavior that may not emerge from general pretraining alone.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_scaling</strong></td>
                            <td>Indicates that fine-tuning can allow a smaller/fine-tuned model to outperform a larger general-purpose model on narrow arithmetic benchmarks.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared (in the referenced work) against GPT-4; in-survey mention is as a cited result without further internal evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>key_finding</strong></td>
                            <td>Specialized fine-tuning (as in Goat) can yield arithmetic performance exceeding that of larger general-purpose LLMs, reinforcing the value of task-focused data for arithmetic competence.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Adapting Large Language Models for Education: Foundational Capabilities, Potentials, and Challenges', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e247.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e247.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic operations, including the types of arithmetic tasks, model properties, performance results, methods used, and any mechanistic insights about how the models solve arithmetic problems.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Tool-augmented arithmetic (calculator/code interpreter)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLMs augmented with external calculators or code-execution (tool integration)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Surveyed strategy where LLMs delegate deterministic computation to external tools (calculators, code execution environments) or call code to self-verify; this reliably fixes numeric inaccuracies from token-generation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLM + external tool (calculator / code interpreter)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_architecture</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>arithmetic_operation_type</strong></td>
                            <td>large-number arithmetic, multi-step arithmetic, computational verification via code</td>
                        </tr>
                        <tr>
                            <td><strong>number_range_or_complexity</strong></td>
                            <td>arbitrary (tool can handle large numbers beyond model token-generation limits)</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_intervention</strong></td>
                            <td>tool integration (invoke calculator or execute code), code-based self-verification, tool-augmented prompting</td>
                        </tr>
                        <tr>
                            <td><strong>performance_result</strong></td>
                            <td>Survey reports that outsourcing arithmetic to a calculator ensures accuracy and that encouraging code use/self-verification significantly improves zero-shot accuracy (no numeric accuracies provided in survey).</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_insight</strong></td>
                            <td>Delegation transfers deterministic numeric calculation to a precise external process rather than relying on probabilistic token prediction; models act as orchestrators deciding when to call tools.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_scaling</strong></td>
                            <td>Tool use bypasses the model-size limitations on arithmetic correctness; accuracy becomes dependent on tool correctness and the model's ability to format/interpret tool I/O.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>Requires reliable tool integration and correct prompt-to-tool formatting; introduces latency and engineering complexity; model may fail to call tool when needed.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared qualitatively against models performing arithmetic internally (no-tool) and against fine-tuned arithmetic models.</td>
                        </tr>
                        <tr>
                            <td><strong>key_finding</strong></td>
                            <td>Invoking external calculators or running code is an effective and practical way to obtain exact arithmetic results from LLM-based systems, sidestepping token-generation errors inherent to pure-language computation.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Adapting Large Language Models for Education: Foundational Capabilities, Potentials, and Challenges', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e247.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e247.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic operations, including the types of arithmetic tasks, model properties, performance results, methods used, and any mechanistic insights about how the models solve arithmetic problems.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Mechanistic insight: token-by-token digit prediction</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Token-by-token digit prediction as the internal arithmetic mechanism of LLMs</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Survey highlights a mechanistic explanation: LLMs typically produce arithmetic answers by sequential token prediction (including digits), not by executing numeric algorithms, causing error accumulation for long answers.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>How well do Large Language Models perform in Arithmetic tasks?</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>General pretrained LLMs</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_architecture</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>arithmetic_operation_type</strong></td>
                            <td>digit-wise generation of arithmetic outputs (applies across addition/multiplication etc.)</td>
                        </tr>
                        <tr>
                            <td><strong>number_range_or_complexity</strong></td>
                            <td>multi-digit outputs suffer most due to sequence length and compounding probability of token errors</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_intervention</strong></td>
                            <td>observational description of default LLM behavior without arithmetic-specific interventions</td>
                        </tr>
                        <tr>
                            <td><strong>performance_result</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_insight</strong></td>
                            <td>LLMs produce numeric answers as sequences of tokens; each token decision is probabilistic so the probability of producing the entire correct multi-digit answer decreases multiplicatively with length — explaining why larger-digit arithmetic is error-prone.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_scaling</strong></td>
                            <td>Error probability increases with number of output tokens (digits); this effect can be mitigated by stepwise reasoning supervision, fine-tuning, or tool delegation.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>Compounding token-wise errors leading to incorrect digits or truncated/garbled numeric outputs; inability to enforce exact arithmetic constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_finding</strong></td>
                            <td>The probabilistic token-generation paradigm of LLMs explains systematic failure on multi-digit arithmetic: they are not executing exact arithmetic algorithms internally but approximating answers token-by-token.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Adapting Large Language Models for Education: Foundational Capabilities, Potentials, and Challenges', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>How well do Large Language Models perform in Arithmetic tasks? <em>(Rating: 2)</em></li>
                <li>Goat: Fine-tuned LLaMA Outperforms GPT-4 on Arithmetic Tasks <em>(Rating: 2)</em></li>
                <li>Teaching arithmetic to small transformers <em>(Rating: 2)</em></li>
                <li>Show your work: Scratchpads for intermediate computation with language models <em>(Rating: 2)</em></li>
                <li>GPT Can Solve Mathematical Problems Without a Calculator <em>(Rating: 2)</em></li>
                <li>Solving quantitative reasoning problems with language models <em>(Rating: 1)</em></li>
                <li>Tora: A tool-integrated reasoning agent for mathematical problem solving <em>(Rating: 1)</em></li>
                <li>Evaluating and Improving Tool-Augmented Computation-Intensive Math Reasoning <em>(Rating: 2)</em></li>
                <li>Injecting numerical reasoning skills into language models <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-247",
    "paper_id": "paper-267027689",
    "extraction_schema_id": "extraction-schema-14",
    "extracted_data": [
        {
            "name_short": "GPT-4 / ChatGPT (arithmetic observations)",
            "name_full": "GPT-4 and ChatGPT (observations reported in survey)",
            "brief_description": "Surveyed observations that GPT-4 and ChatGPT handle addition and subtraction relatively well but show degraded accuracy on multiplication with large numbers; suggested remedies include fine-tuning or outsourcing computation to tools.",
            "citation_title": "How well do Large Language Models perform in Arithmetic tasks?",
            "mention_or_use": "mention",
            "model_name": "GPT-4 / ChatGPT",
            "model_size": null,
            "model_architecture": null,
            "arithmetic_operation_type": "addition, subtraction, multiplication (noted degradation on larger multiplication)",
            "number_range_or_complexity": "large-number multiplication (unspecified number of digits); general multi-digit cases referenced",
            "method_or_intervention": "standard prompting / zero-shot usage as evaluated in referenced analyses (no calculator by default)",
            "performance_result": "Reported as 'good' on addition and subtraction but accuracy decreases for multiplication with larger numerical values (no precise percentages provided in survey text).",
            "mechanistic_insight": "Survey cites that LLMs do not perform deterministic arithmetic internally but generate text (digits) token-by-token, so errors compound as answer length grows.",
            "performance_scaling": "Performance degrades as number of digits increases; even large-capacity models like GPT-4 can struggle on large multiplications compared to their performance on other benchmarks.",
            "failure_modes": "Cumulative digit-wise errors for multi-digit results; particularly poor on large-number multiplication.",
            "comparison_baseline": "Compared implicitly to fine-tuned specialized models and to approaches that use external calculators or tool-augmented methods.",
            "key_finding": "High-capacity conversational LLMs (e.g., GPT-4/ChatGPT) often handle simple addition/subtraction but fail on large multi-digit multiplication because they generate answers token-by-token rather than performing exact arithmetic; tool use or fine-tuning is needed for reliable results.",
            "uuid": "e247.0",
            "source_info": {
                "paper_title": "Adapting Large Language Models for Education: Foundational Capabilities, Potentials, and Challenges",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "Small transformers (fine-tuned on stepwise arithmetic)",
            "name_full": "Small transformer models trained/fine-tuned on high-quality, stepwise arithmetic data",
            "brief_description": "Multiple works report that relatively small transformer models can achieve high accuracy on multi-digit arithmetic when fine-tuned on datasets that include detailed calculation steps or procedural traces.",
            "citation_title": "Teaching arithmetic to small transformers",
            "mention_or_use": "mention",
            "model_name": "Small transformer models (unspecified architectures in survey)",
            "model_size": null,
            "model_architecture": "transformer (small)",
            "arithmetic_operation_type": "multi-step arithmetic, multi-digit addition/multiplication (general)",
            "number_range_or_complexity": "multi-digit problems (exact ranges not specified in survey); emphasis on multi-digit multiplication/addition",
            "method_or_intervention": "fine-tuning on high-quality datasets containing detailed calculation processes / procedural traces (supervised fine-tuning)",
            "performance_result": "Survey reports that small transformers trained in this manner can 'solve arithmetic problems with high accuracy' and 'avoid mistakes on multi-digit problems' (no numeric accuracies reported in the survey itself).",
            "mechanistic_insight": "When trained on step-by-step calculation traces, small models appear to learn algorithmic/procedural strategies rather than only memorizing outputs, enabling correct multi-digit computation.",
            "performance_scaling": "Fine-tuning on targeted, high-quality arithmetic data can enable small models to match or surpass larger models on arithmetic tasks; performance depends more on task-specific training data quality than raw parameter count.",
            "failure_modes": "Without task-specific fine-tuning or stepwise training data, small transformers would revert to token-generation failure modes similar to larger LLMs.",
            "comparison_baseline": "Before vs after fine-tuning on stepwise arithmetic traces; small fine-tuned models compared favorably to larger unfine-tuned LLMs on arithmetic tasks.",
            "key_finding": "Carefully curated, stepwise training data can teach small transformers to implement reliable arithmetic procedures, demonstrating that data quality (detailed procedural supervision) can outweigh sheer model size for arithmetic competence.",
            "uuid": "e247.1",
            "source_info": {
                "paper_title": "Adapting Large Language Models for Education: Foundational Capabilities, Potentials, and Challenges",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "Goat (fine-tuned LLaMA)",
            "name_full": "Goat: Fine-tuned LLaMA Outperforms GPT-4 on Arithmetic Tasks",
            "brief_description": "A referenced work that fine-tunes a LLaMA-based model on arithmetic tasks and reports superior arithmetic performance compared to GPT-4 on those tasks.",
            "citation_title": "Goat: Fine-tuned LLaMA Outperforms GPT-4 on Arithmetic Tasks",
            "mention_or_use": "mention",
            "model_name": "Goat (fine-tuned LLaMA variant)",
            "model_size": null,
            "model_architecture": "LLaMA-based transformer (fine-tuned)",
            "arithmetic_operation_type": "arithmetic tasks (paper title implies a focus on arithmetic benchmarks including multi-digit tasks)",
            "number_range_or_complexity": null,
            "method_or_intervention": "fine-tuning of a base LLaMA model on arithmetic-specific datasets",
            "performance_result": "Survey cites the external paper's claim that Goat (fine-tuned LLaMA) outperforms GPT-4 on arithmetic tasks; survey provides no numerical breakdown itself.",
            "mechanistic_insight": "Implied insight: targeted fine-tuning on arithmetic datasets enables language models to internalize reliable arithmetic behavior that may not emerge from general pretraining alone.",
            "performance_scaling": "Indicates that fine-tuning can allow a smaller/fine-tuned model to outperform a larger general-purpose model on narrow arithmetic benchmarks.",
            "failure_modes": null,
            "comparison_baseline": "Compared (in the referenced work) against GPT-4; in-survey mention is as a cited result without further internal evaluation.",
            "key_finding": "Specialized fine-tuning (as in Goat) can yield arithmetic performance exceeding that of larger general-purpose LLMs, reinforcing the value of task-focused data for arithmetic competence.",
            "uuid": "e247.2",
            "source_info": {
                "paper_title": "Adapting Large Language Models for Education: Foundational Capabilities, Potentials, and Challenges",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "Tool-augmented arithmetic (calculator/code interpreter)",
            "name_full": "LLMs augmented with external calculators or code-execution (tool integration)",
            "brief_description": "Surveyed strategy where LLMs delegate deterministic computation to external tools (calculators, code execution environments) or call code to self-verify; this reliably fixes numeric inaccuracies from token-generation.",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": "LLM + external tool (calculator / code interpreter)",
            "model_size": null,
            "model_architecture": null,
            "arithmetic_operation_type": "large-number arithmetic, multi-step arithmetic, computational verification via code",
            "number_range_or_complexity": "arbitrary (tool can handle large numbers beyond model token-generation limits)",
            "method_or_intervention": "tool integration (invoke calculator or execute code), code-based self-verification, tool-augmented prompting",
            "performance_result": "Survey reports that outsourcing arithmetic to a calculator ensures accuracy and that encouraging code use/self-verification significantly improves zero-shot accuracy (no numeric accuracies provided in survey).",
            "mechanistic_insight": "Delegation transfers deterministic numeric calculation to a precise external process rather than relying on probabilistic token prediction; models act as orchestrators deciding when to call tools.",
            "performance_scaling": "Tool use bypasses the model-size limitations on arithmetic correctness; accuracy becomes dependent on tool correctness and the model's ability to format/interpret tool I/O.",
            "failure_modes": "Requires reliable tool integration and correct prompt-to-tool formatting; introduces latency and engineering complexity; model may fail to call tool when needed.",
            "comparison_baseline": "Compared qualitatively against models performing arithmetic internally (no-tool) and against fine-tuned arithmetic models.",
            "key_finding": "Invoking external calculators or running code is an effective and practical way to obtain exact arithmetic results from LLM-based systems, sidestepping token-generation errors inherent to pure-language computation.",
            "uuid": "e247.3",
            "source_info": {
                "paper_title": "Adapting Large Language Models for Education: Foundational Capabilities, Potentials, and Challenges",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "Mechanistic insight: token-by-token digit prediction",
            "name_full": "Token-by-token digit prediction as the internal arithmetic mechanism of LLMs",
            "brief_description": "Survey highlights a mechanistic explanation: LLMs typically produce arithmetic answers by sequential token prediction (including digits), not by executing numeric algorithms, causing error accumulation for long answers.",
            "citation_title": "How well do Large Language Models perform in Arithmetic tasks?",
            "mention_or_use": "mention",
            "model_name": "General pretrained LLMs",
            "model_size": null,
            "model_architecture": null,
            "arithmetic_operation_type": "digit-wise generation of arithmetic outputs (applies across addition/multiplication etc.)",
            "number_range_or_complexity": "multi-digit outputs suffer most due to sequence length and compounding probability of token errors",
            "method_or_intervention": "observational description of default LLM behavior without arithmetic-specific interventions",
            "performance_result": null,
            "mechanistic_insight": "LLMs produce numeric answers as sequences of tokens; each token decision is probabilistic so the probability of producing the entire correct multi-digit answer decreases multiplicatively with length — explaining why larger-digit arithmetic is error-prone.",
            "performance_scaling": "Error probability increases with number of output tokens (digits); this effect can be mitigated by stepwise reasoning supervision, fine-tuning, or tool delegation.",
            "failure_modes": "Compounding token-wise errors leading to incorrect digits or truncated/garbled numeric outputs; inability to enforce exact arithmetic constraints.",
            "comparison_baseline": null,
            "key_finding": "The probabilistic token-generation paradigm of LLMs explains systematic failure on multi-digit arithmetic: they are not executing exact arithmetic algorithms internally but approximating answers token-by-token.",
            "uuid": "e247.4",
            "source_info": {
                "paper_title": "Adapting Large Language Models for Education: Foundational Capabilities, Potentials, and Challenges",
                "publication_date_yy_mm": "2023-12"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "How well do Large Language Models perform in Arithmetic tasks?",
            "rating": 2,
            "sanitized_title": "how_well_do_large_language_models_perform_in_arithmetic_tasks"
        },
        {
            "paper_title": "Goat: Fine-tuned LLaMA Outperforms GPT-4 on Arithmetic Tasks",
            "rating": 2,
            "sanitized_title": "goat_finetuned_llama_outperforms_gpt4_on_arithmetic_tasks"
        },
        {
            "paper_title": "Teaching arithmetic to small transformers",
            "rating": 2,
            "sanitized_title": "teaching_arithmetic_to_small_transformers"
        },
        {
            "paper_title": "Show your work: Scratchpads for intermediate computation with language models",
            "rating": 2,
            "sanitized_title": "show_your_work_scratchpads_for_intermediate_computation_with_language_models"
        },
        {
            "paper_title": "GPT Can Solve Mathematical Problems Without a Calculator",
            "rating": 2,
            "sanitized_title": "gpt_can_solve_mathematical_problems_without_a_calculator"
        },
        {
            "paper_title": "Solving quantitative reasoning problems with language models",
            "rating": 1,
            "sanitized_title": "solving_quantitative_reasoning_problems_with_language_models"
        },
        {
            "paper_title": "Tora: A tool-integrated reasoning agent for mathematical problem solving",
            "rating": 1,
            "sanitized_title": "tora_a_toolintegrated_reasoning_agent_for_mathematical_problem_solving"
        },
        {
            "paper_title": "Evaluating and Improving Tool-Augmented Computation-Intensive Math Reasoning",
            "rating": 2,
            "sanitized_title": "evaluating_and_improving_toolaugmented_computationintensive_math_reasoning"
        },
        {
            "paper_title": "Injecting numerical reasoning skills into language models",
            "rating": 2,
            "sanitized_title": "injecting_numerical_reasoning_skills_into_language_models"
        }
    ],
    "cost": 0.01636575,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Adapting Large Language Models for Education: Foundational Capabilities, Potentials, and Challenges
26 Apr 2024</p>
<p>Qingyao Li 
Lingyue Fu 
Weiming Zhang 
Xianyu Chen 
Yong Yu 
Weiming Zhang 
Jingwei Yu 
Wei Xia 
Weinan Zhang 
Ruiming Tang 
Weinan Zhang </p>
<p>Shanghai Jiao Tong University
China</p>
<p>Shanghai Jiao Tong University
China</p>
<p>Shanghai Jiao Tong University
China</p>
<p>Adapting Large Language Models for Education: Foundational Capabilities, Potentials, and Challenges
26 Apr 2024851B80A9A5F4CA44B7D074EEE0154DEAarXiv:2401.08664v3[cs.AI]CCS Concepts:Information systems• Applied computing → EducationLarge Language Models, Educational Data Mining Foundational Capabilities Mathematics Basic Arithmetic Problems Goat [74], GENBERT [36] Challenging Mathematics Problems WizardMath [83], MeatMath [150] Multimodal Problems Mathvista [80], Unigeo [14] Mathematical Proof LeanDojo [145], LEGO-Prover [140] Writing Text Summarization BRIO [78], PROM [86] Grammatical Error Correction CoEdit [78], GrammarGPT [27] Programming Code Writing CodeLlama [112], WizardCoder [84] Code Refinement Codet [13], SEIDR [79] Reasoning Supervised Fine-tuning CAGE [109], Scratchpad [94] Prompt Engineering CoT [136], SelfConsistency [133] Hybrid Methodologies FineTuneCoT [44], STaR [152] Knowledge-based QA Open-domain QA Retro [10], FRESHPROMPT [129] Domain-specific QA Reta-llm [72], LeanContext [5]
Online education platforms, leveraging the internet to distribute education resources, seek to provide convenient education but often fall short in real-time communication with students.They often struggle to address the diverse obstacles students encounter throughout their learning journey.Solving the problems encountered by students poses a significant challenge for traditional deep learning models, as it requires not only a broad spectrum of subject knowledge but also the ability to understand what constitutes a student's individual difficulties.It's challenging for traditional machine learning models, as they lack the capacity to comprehend students' personalized needs.Recently, the emergence of large language models (LLMs) offers the possibility for resolving this issue by comprehending individual requests.Although LLMs have been successful in various fields, creating an LLM-based education system is still challenging for the wide range of educational skills required.This paper reviews the recently emerged LLM researches related to educational capabilities, including mathematics, writing, programming, reasoning, and knowledge-based question answering, with the aim to explore their potential in constructing the next-generation intelligent education system.Specifically, for each capability, we focus on investigating two aspects.Firstly, we examine the current state of LLMs regarding this capability: how advanced they have become, whether they surpass human abilities, and what deficiencies might exist.Secondly, we evaluate whether the development methods for LLMs in this area are generalizable-that is, whether these methods can be applied to construct a comprehensive educational supermodel with strengths across various capabilities, rather than being effective in only a singular aspect.Based on the current development status, we further outline two approaches for an LLM-based education system: a unified approach and a mixture-of-expert (MoE) approach.Finally, we explore the challenges and future directions, providing new research opportunities and perspectives on adapting LLMs for education.</p>
<p>INTRODUCTION</p>
<p>Education plays a vital role in shaping individuals' futures as it forms the foundation for providing people with knowledge, skills, and critical thinking abilities.Conventional education systems heavily rely on teachers for imparting knowledge to students, which place a significant demand on educational resources.However, the advent of online education has substantially lowered the cost of accessing these educational materials.Many people are conveniently acquiring knowledge through online courses and exercises.</p>
<p>Much effort has been made to achieve personalized learning in online-education [1,38,64].Most of these methods are based on predicting students' knowledge states or recommending personalized learning resources using neural networks, based on sequences of student behaviors.However, this approach achieves only a coarse level of personalization.Even when students receive recommended resources, the specific difficulties they encounter in their learning process can remain unresolved.These difficulties may vary from student to student; for example, different students might struggle with different aspects of the same problem, such as misconceptions in understanding key concepts or difficulties in the reasoning process.These issues require detailed descriptions from each student for educators to understand.However, current online education systems face the issue of not being able to interact with students in real-time like a teacher.</p>
<p>Presently, online education platforms typically offer static course videos and exercises, leaving students unable to ask questions or seek dynamic solutions to their specific issues.Therefore, developing a teaching assistant model capable of addressing students' individual concerns represents a crucial step forward in advancing online education.</p>
<p>The emergence of large language models (LLMs) instills optimism in creating an intelligent education system.Since the launch of ChatGPT, LLMs have shown exceptional ability in understanding human knowledge and have been widely applied in various professional fields, including recommendation systems [67], healthcare [73], economics [63], and others.By introducing expansive world knowledge, considerable reasoning capabilities, and the ability to understand human language, LLMs have the potential to introduce new forms of interactions and methodologies across these fields.</p>
<p>However, the challenge intensifies when constructing an LLM-based education system.To solve the specific problems encountered by students, it's not only necessary for LLMs to understand the precise issues faced by the students but also essential for them to possess specialized educational-related knowledge and skills.Only then they would be able to address problems that the students themselves might not be able to resolve.</p>
<p>The act of LLMs answering students' questions can be considered as a process that involves using multiple educational capabilities.For instance, as depicted in Figure 1, the question posed by the student requires the education assistant to possess both mathematics and programming skills simultaneously.Therefore, summarizing the methods of developing LLMs' education-related capabilities is meaningful for building the next-generation intelligent education system.In this paper, we study LLMs from the perspective of these education-related capabilities and explore the potential of an LLM-based education system, aiming to provide valuable insights into the areas that need further improvement.We present our primary investigation in Figure 2. Our specific focus centers on five distinct capabilities of LLMs:</p>
<p>• Mathematics: We primarily summarize the current development of LLMs in solving mathematical problems of varying difficulties and types, encompassing basic arithmetic operations, challenging problems, multi-modal problems, and math proof.Sure!You can use a mathematical formula to calculate the sum of numbers from 1 to 100.The formula for the sum of an arithmetic series is ( + 1)/2, where  is the last number in the series.In this case,  = 100.</p>
<p>Here is a simple Python program using this formula :</p>
<p>def calculate_sum(): n = 100 total_sum = n * (n+1) // 2 return total_sum result = calculate_sum() print(f"The sum of numbers from 1 to 100 is: {result}") Fig. 1.An example of LLM-based education systems integrating multiple abilities to solve student problems.</p>
<p>• Writing: We investigate the performance of LLMs on a number of representative writing tasks to outline the problems LLMs face and potential future directions.</p>
<p>• Programming: In accordance with human programming conventions, we divide LLMs' programming process into two stages: code writing and code refinement.We review the researches in this area and summarize the remaining problems for LLMs in coding.</p>
<p>• Reasoning: We explore the capability of LLMs to perform reasoning in various ways, including supervised fine-tuning, prompt engineering, and hybrid methods, and explore their potential applications in the field of education.</p>
<p>• Knowledge-based Question Answering: We investigate the development of LLMs in open-domain and domain-specific knowledge-based question answering.We hope to offer a comprehensive view of incorporating such capabilities into the education system.These five capabilities form the foundation of an LLM-based education system.Building upon this foundation, we propose two potential approaches for forming an LLM-based education system.One approach involves training a comprehensive language model with multiple capabilities, while the other is based on an LLM controller in a mixture-of-experts framework.</p>
<p>The rest of this paper is organized as follows.In section 2, we briefly introduce the education tasks and educational LLMs.In section 3, we summarize the current development status of five foundational abilities related to education, followed by discussion of the development trend of education-related LLM capabilities.In section 4, we investigate the performance of well-known LLMs in education-related capabilities.In section 5, we introduce the potential approaches for organizing an LLM-based education system.Finally, in section 6 and section 7, we highlight the challenges and future directions for designing an LLM-based education system and concludes this survey.</p>
<p>BACKGROUND</p>
<p>In this section, we first discuss the educational tasks and introduce of LLMs' roles in smart education.Then, we introduce the current development of educational large language models and compare our survey with previous works.</p>
<p>Educational Tasks</p>
<p>Artificial Intelligence can significantly boost the development of online education.Developing an intelligent education system involves tackling a wide array of tasks, which can be broadly categorized into two types.The first type centers around solving personalized, knowledge-based questions from students [148,150,160].This category aims to assist students in resolving their queries during the learning process, such as clarifying misunderstandings about a particular concept [59], solving a math problem [39,135,141], or writing a piece of code to address a specific issue [13,111,158].</p>
<p>The second type focuses on aiding students with their learning planning, such as mapping out learning paths [18,64],</p>
<p>knowledge tracing [1,20,103], and computerized adaptive testing [37,89,124].These tasks are designed to support the learning process from a broader perspective, instead of addressing specific learning challenges students face.</p>
<p>In this paper, we mainly survey the former category which mainly develops the abilities of LLMs answering students' specific questions requiring specific skills, due to that it's the main scenario that LLMs could contribute more.The former scenario is where LLMs currently play a significant role, for two main reasons: 1) From the perspective of task characteristics, tasks like designing learning paths and tracking knowledge, though also guiding student learning, are mainly based on students' learning sequences.The reasoning process mostly happens in the background, with relatively less need for dialogue.2) From the viewpoint of the characteristics of LLMs, the advantage of language models over traditional recommendation models lies in their extensive world knowledge, conversational abilities, and logical reasoning capacities.These capabilities are crucial for addressing the personalized and subject-specific questions that students encounter.These questions are often complex and personalized, requiring dialogue for effective understanding-a feature not possessed by previous deep learning models.However, for issues like learning path planning and knowledge tracking, deep learning models, through training, can handle them well [37,64,103].</p>
<p>Educational Large Language Models</p>
<p>Currently, many online education companies have launched their own large educational models [41,48].The iFLYTEK Spark[48], introduced by iFLYTEK Company, boasts capabilities in multimodal interaction, coding, text generation, solving math problems, and knowledge Q&amp;A.The introduction of LLMs could evidently enhance the efficiency of learners [57].MathGPT[41], developed by TAL Education Group, is an LLM specializing in math problem-solving and lecturing.From the development patterns of these companies, it is evident that the primary application scenario for these large models is to address specific knowledge-based questions from students.This approach benefits the industry in two main ways: 1) It allows for more interaction with students.Answering specific questions about subjects or knowledge points involves more detailed participation in the students' learning process compared to learning path planning and knowledge tracking, thereby increasing the time students spend on the platform.2) Solving student questions makes the model appear more intelligent.Planning learning paths and assessing students can be achieved with traditional models, but understanding and solving students' problems through dialogue is only possible with large models, making the platform's products more intelligent.In summary, because they better retain student users and make their products more intelligent, the main trend for platforms developing educational large models is to enable them to solve specific student questions.Of course, issues like learning path planning and knowledge tracking are also very important, but the transformation in the era of large models requires further exploration.</p>
<p>Related Surveys</p>
<p>LLMs hold vast potential in the field of education.There are already several surveys about LLMs in education, while our work is different from them.Gan et al. [34] explored various roles LLMs can play in the education process.It focuses on analyzing the roles undertaken by LLMs from the perspective of different application scenarios, such as learning support tools, personalized learning experiences, content creation and generation, language learning and teaching, cross-lingual communication, and translation.The basic capabilities of LLMs are not discussed in it.Kasneci et al. [56] explores the benefits and challenges of LLMs in education from both students' and teachers' perspectives, highlighting the potential of LLMs in research, writing, and problem-solving tasks, as well as their ability to provide domain-specific language skills for specialized learning.</p>
<p>Other than that, AL-Smadi [4] primarily explored the use of generative AI models in education, focusing on their application as teaching aids, the generation of personalized learning materials, and the assessment of student learning outcomes.It primarily assesses ChatGPT's performance on tasks such as instructional design from an educational perspective, in a qualitative rather than quantitative manner.Meyer et al. [90] is an editorial on the opportunities and challenges of LLMs in academia, analyzing the potential impacts and risks of LLMs from the perspectives of academic writing, education, and programming education.They primarily discussed the role of LLMs in education from a pedagogical perspective, whereas our work leans towards analyzing the current capabilities of LLMs in solving subject-specific questions in the educational process from a technological standpoint, offering ideas and insights for creating an LLM capable of addressing problems across various subjects.Wang et al. [131] summarized the development of LLMs in education from the perspective of data and technology, discussing the current applications of LLMs in tasks such as study assisting, teach assisting, and adaptive learning.It is important to note that while the article mentions some technical methods for developing LLMs' problem-solving abilities in study assisting, the content covered is not systematic.The technical development for solving problems for students didn't take up much space of this article.</p>
<p>Moreover, the disciplines explored in the article are not foundational but include advanced subjects such as Medicine and Finance.In contrast, our work primarily focuses on discussing the development of LLMs' fundamental capabilities in assisting students with solving various problems.</p>
<p>While previous surveys have provided ample discussion on the potential applications of LLMs in education, they exhibit two main shortcomings: 1) Their exploration of LLMs' applications in education often spans a wide range of topics, including designing learning paths, assisting teachers, and planning curricula.As discussed in Section 2.1, although these capabilities are important, they do not represent the primary direction of current practical applications of educational LLMs.Our work, in contrast, primarily focuses on the ability of LLMs to answer subject-specific questions.2) They have not analyzed the development of LLMs' educational capabilities from a technological perspective.Discussing the evolution of LLMs' educational abilities from a technical standpoint is crucial for building a general LLM-based intelligent education system.Different from them, we review the evolution of LLMs from the perspective of education-related capabilities.We summarize the techniques to promote LLMs in these capabilities.Additionally, we provide foresight into constructing feasible frameworks for LLM-based education systems.Our work emphasizes a comprehensive understanding of LLMs' educational competencies and explores frameworks that can effectively integrate these abilities into the educational landscape.</p>
<p>FOUNDATIONAL CAPABILITIES</p>
<p>Mathematics</p>
<p>Mathematics demands reasoning of complex information, making it one of the disciplines that place the highest premium on the cognitive abilities.There is significant academic interest in enhancing the mathematical capabilities of LLMs [82].In the pursuit of creating an education system based on LLMs, the goal is to equip it with the capability to tackle a wide range of mathematical problems.These problems may encompass basic numerical calculations, complex logical reasoning, or challenges that require the integration of information from multiple modalities.In this section, we summarize the developments of the mathematical capabilities of LLMs, focusing on four aspects: fundamental numerical computations, complex reasoning, the handling of multi-modal problem-solving, and mathematical proof.</p>
<p>3.1.1Basic Arithmetic Problems.Recently, significant scholarly attention has focused on augmenting LLMs' proficiency in this domain [36,99,135,154].In human learning mathematics, foundational mathematical operations serve as the basis for addressing more advanced problems.Given the robust comprehension of human language and notable textual reasoning abilities exhibited by LLMs, it is natural for many to assume that LLMs should effortlessly handle fundamental mathematical problems.However, the reality proves otherwise.Yuan et al. [151] pointed out that ChatGPT and GPT-4 [2] perform well in addition and subtraction operations, but their accuracy decreases when dealing with multiplication involving larger numerical values.This limitation arises because the LLMs do not access a calculator during the computations.More importantly, when LLMs solve computational problems, their internal logic does not perform actual calculations.Instead, they generate text to predict each digit of the answer step by step.This approach means that as the number of digits in the answer increases, the probability of making an error grows cumulatively.This problem is not unsolvable.Yang et al. [146] and Liu and Low [74] proposed to fine-tune LLMs on high-quality datasets and found that even small language models could avoid making mistakes on multi-digit problems.Lee et al. [60] found that even small transformers could solve arithmetic problems with high accuracy as long as trained on data with detailed calculation process.All in all, fine-tuning on high quality data is one workable solution.However, this approach may only work when a specialized arithmetic model need to be build while not applicable for building general LLMs since it is not feasible to fine-tune each LLM individually.How to prevent such issues during the pre-training phase of LLMs remains an open question.At the current stage, a simple and feasible solution is to have the LLMs outsource arithmetic problems to a calculator, which can ensure the accuracy of the calculations [115].</p>
<p>3.1.2Challenging Mathematics Problems.Despite occasional errors in basic mathematical operations, the expectation for LLMs to solve more complex problems remains high, and the LLMs' capabilities in this area continue to develop.</p>
<p>For education, the ability to handle college-level mathematics is particularly beneficial for senior students' learning, offering significant assistance in understanding challenging concepts.For simple arithmetic problems, LLMs make mistakes mainly due to the gap between text generation and digit calculation.For complex mathematical problems, the challenge arises for requiring LLMs' advanced symbolic reasoning abilities and domain knowledge.In this regard, LLMs still need further development.Wang et al. [132] introduced a benchmark SCIBENCH, which contains collegiate-level scientific problems from mathematics, chemistry, and physics textbooks, while GPT-4 could only get averagely 53.24% on the math part.Furthermore, Sawada et al. [114] collected a harder dataset ARB that contains math problems from Harvard PhD comprehensive exams in mathematics, where GPT-4 could only get less than 10% right.All these results demonstrate that LLMs have a lot of room for improvement.</p>
<p>In recent years, more and more work has been proposed to enhance this ability [62,83,132,150].Luo et al. [83] tried to increase the mathematical reasoning abilities of Llama-2 by applying Reinforcement Learning from Evol-Instruct Feedback (RLEIF) on complex mathematics datasets.The Evol-Instruct method made LLMs to generate easier and harder questions from the original questions to make the LLMs think deeper.In addition to training on high-quality datasets, there are also many efforts that attempt to leverage programming as an external tool to assist in solving mathematical problems.Zhou et al. [160] tried to enhance GPT-4's mathematical ability by encouraging it to use code to self-verify its answers.This approach leads to a significant improvement in the zero-shot accuracy of mathematical problem-solving.ToRA [39] divided the process of LLMs solving math problems into a cyclical rationale-action process, where the action involves invoking external tools, including computation libraries and symbolic solvers, thereby amalgamating the analytical prowess of language with the computational efficiency of tools.Overall, solving complex mathematical problems requires reasoning abilities, computational power, and knowledge in the mathematical domain.</p>
<p>Fine-tuning on relevant datasets primarily aims to enhance its reasoning capabilities and knowledge on related issues, while computational abilities can be supplemented by invoking external tools, such as calculators or code compilers.</p>
<p>Problems Involving</p>
<p>Multi-Modal Information.Multi-modal inputs are common in mathematics problems like geometric questions.They require LLMs to understand text and image information for solutions.Research in multi-modal LLMs for mathematical reasoning is emerging [14,80,101].This type of task poses a high requirement for the formation and quality of the training data.Chen et al. [14] introduced a Unified Geometry problem benchmark combining calculation and proving tasks.Based on this dataset, the study presented a framework capable of simultaneously solving calculations and proving tasks through a sequence generation approach.Furthermore, Lu et al. [80] proposed MATHVISTA, a benchmark for diverse mathematical and visual challenges.Zhang et al. [155] developed a benchmark GeoEval for testing geometry problem-solving ability of LLMs.Their results showed that WizardMath and GPT-4V excels in handling multi-modal mathematics problems.</p>
<p>Various methods have been proposed for this task.For geometric problems, Zhang et al. [156] converted diagrams into text clauses, using a convolutional neural network and a language model for encoding and a GRU-based framework for answer generation.Gao et al. [35] argued that the reason current models fail on solving geometry problems is that they struggle to accurately comprehending basic geometric elements and their relationships.So they built a augmented dataset Geo170K containing high-quality descriptions of geometric information and developed a model G-LLaVA on it, which demonstrated exceptional performance in solving geometric problems, significantly outperforming GPT-4-V on the MathVista benchmark with only 7B parameters.Besides geometry problems that involves processing images and text, Lu et al. [81] presented the Tabular Math Word Problems (TABWP) dataset, requiring textual and tabular data reasoning, and introduced PROMPTPG, a policy gradient-based selector for training and prompt construction for test samples.</p>
<p>3.1.4Mathematical Proof.Unlike other types of mathematical problems where LLMs primarily focus on providing answers, LLMs' role in mathematical proofs emphasizes the integration with proof assistants such as Coq [8], Isabelle [93],</p>
<p>and Lean [22].These proof assistants correspond to specific programming languages, requiring users to formulate proofs in the required languages, after which the assistant can verify the proof's correctness.Many LLM-based methods are proposed to help theorem proving [50,71,141].Based on these proof assistants, there are two main approaches to utilizing LLMs for mathematical proofs.</p>
<p>The first approach is formal proof search, exemplified by models like GPT-f [104], which involves prompting LLMs to produce the next proof step (also called 'tactic' in proof assistants) based on the current proof state and some optional context.In conjunction with proof assistants, it transforms the proof of mathematical propositions into a process of executing actions.Here, an action can be the application of a mathematical theorem or a method of variable substitution, which can transform and decompose the original proposition.The LLM is responsible for generating actions, sampling multiple actions in each round and iterating over multiple rounds to produce a tree structure.It utilizes the proof assistant's functionality to verify the validity of proofs to evaluate branches, thereby employing tree search methods to find proof strategies.Following GPT-f, Thor [51] was further proposed to help select the premise for theorem proving.Yang et al. [145] introduced an open-source framework named LeanDojo based on the Lean proof assistant.This framework comprises data, toolkits, models, and benchmarks, and it has led to the development of ReProver (Retrieval-Augmented Prover), which enhanced proof accuracy by using retrieval methods to extract premises for LLMs to base their mathematical proofs.</p>
<p>The second is natural proof translation, also known as autoformalization, which is to convert math proofs written in natural language into formalized versions.In such schemes, the responsibility of LLMs is not to generate proof steps.Due to the extremely low prevalence of these proof assistants in the human corpus, LLMs struggle to directly undertake the task of generating proof steps.This approach primarily tackles the challenge of insufficient data for formal mathematical proofs.By leveraging autoformalization, a significant increase in this type of data can be achieved, consequently enhancing the proof-generating capabilities of neural provers that have been fine-tuned on this expanded dataset.Initially, Wu et al. [138] demonstrated that LLMs perform well in autoformalization.They employed LLMs for autoformalization, transforming mathematical proofs and problems expressed in natural language into formal specifications and proofs in Isabelle language.The generated data was used to train a neural theorem prover, enhancing the effectiveness of the original prover.Following it, Cunningham et al. [21] utilized an encoder-decoder framework based on the universal transformer architecture, converting both problem statements and mathematical proofs written in LaTeX into the language of the Coq interactive prover.Jiang et al. [52] built a pipeline of Draft, Sketch, Prove (DSP), where the informal and incomplete proof is first generated (Draft) and given to LLMs for autoformalization (Sketch), and finally passed to off-the-shelf prover to be completed (Prove).</p>
<p>In mathematical education, proof problems are indispensable.Currently, LLMs for math proof primarily operate in the form of interactive theorem proving.In this approach, LLMs complete proofs by interacting with software proof assistants.To realize completely automated theorem proving with LLMs, it is essential that these models possess not only strong reasoning skills but also the capability to formalize concepts effectively.There is no room for hallucination in mathematical proofs, which poses a formidable challenge for LLMs.</p>
<p>3.1.5Summary.When examining the progress of large language models (LLMs) in terms of their mathematical abilities, it becomes evident that the primary obstacle lies in the inherent conflict between the principles of mathematical logic and those of text generation.This discrepancy manifests itself not only in the outcomes (e.g., LLMs encountering difficulties with multiplication involving large numbers and struggling with complex mathematical problems) but also in the training data itself.Mathematical problems, in their symbolic form, represent only a minor fraction of the training corpora used for these expansive models.Consequently, the current approaches to bolstering the mathematical capabilities of LLMs can be broadly categorized into two main strategies: 1) Data enhancement: The most straightforward method to improve LLMs' performance on mathematical tasks is to provide them with high-quality, relevant data during the fine-tuning phase of their training.By exposing the models to a more comprehensive and representative set of mathematical problems, their ability to handle such challenges can be significantly enhanced.2) Tool integration: Another effective approach is to leverage external tools, such as calculators and code compilers, to compensate for the inherent limitations of LLMs.By strategically invoking these tools at the points where the models struggle, their functional shortcomings can be effectively mitigated, allowing for a more comprehensive and accurate handling of mathematical problems.</p>
<p>Writing</p>
<p>Writing proficiency is crucial for LLMs, underpinning their ability to comprehend inputs deeply and produce semantically and syntactically accurate outputs [12,25].In education, the writing capability of LLMs holds the potential to transform how writing is taught.They can assist in content creation, simplify complex topics for students, and offer personalized educational materials.In this part, we dive into LLM's writing capability on two education-related tasks: text summarization and grammatical error correction.</p>
<p>Text Summarization. Text summarization is a task that requires LLMs to compress lengthy texts into concise</p>
<p>summaries while maintaining the essential information.This process presents a significant challenge for LLMs, as they must effectively comprehend and distill the key points from a wide range of diverse content, such as news articles and texts written in multiple languages.In the context of education, students are often confronted with an overwhelming volume of intricate learning materials.A well-crafted summary can prove invaluable in helping them grasp the core concepts quickly and efficiently, saving them considerable time and effort.For instance, a summary can break down a complex piece of code into its fundamental components, making it easier for students to understand its structure and functionality.Similarly, a summary can highlight the main ideas and key takeaways from a lengthy chapter, allowing students to focus on the most critical information without getting lost in the details.It is evident that traditional fine-tuning methods are less effective with the advent of advanced LLMs [78,105].Pu et al. [105] and Liang et al. [65] showed LLMs like ChatGPT initially lag behind fine-tuned models like T5 [107] and BART [61] in ROUGE scores [66] for text summarization.However, when human judges evaluate overall quality, LLMs outperform fine-tuned models and even standard human summaries, superior in aspects like factual consistency, fluency, and diversity.This discovery underscored the limitations of traditional evaluation methods and suggested a need for new paradigms to guide summarization tasks in the LLM era.For example, BRIO [78] implemented a ranking task to foster more diverse summarizations.Furthermore, Liu et al. [77] utilized a GPT model based on BRIO to directly generate training data to guide the learning process of other models, which is similar to the process of RLHF [120].</p>
<p>Given the outstanding performance of LLMs in the domain of text summarization, researchers have already begun to tackle more challenging tasks.Liu et al. [76] benchmarked LLMs on instruction controllable text summarization.In this task, the input provided to the model consists of two components: the source article that needs to be summarized and a set of instructions in natural language that specify the desired characteristics of the summary output.The goal is to evaluate how well LLMs can generate summaries that adhere to these specific requirements.In a related study, Shen et al. [116] investigated whether LLMs could potentially replace human evaluators in assessing the quality of abstractive summarization.Abstractive summarization involves generating a summary that captures the main ideas of the source text while potentially using different words and phrases.The researchers found that, at present, LLMs are not capable of serving as reliable substitutes for human evaluators in this task.LLM evaluators rate each candidate system inconsistently and are dimension-dependent.Moreover, LLMs face challenges when comparing candidate summaries that have similar levels of performance.They find it difficult to make fine-grained distinctions between summaries of comparable quality, which limits their ability to provide accurate comparative assessments.The correlation between the ratings provided by LLMs and those given by human evaluators becomes lower when dealing with higher-quality summaries.Although LLMs can surpass humans in text summarization tasks, they are not without flaws.Current LLMs make fewer silly mistakes (e.g., entity confusion, irrelevant information generation) but more sophisticated ones [105].For example, they fill in the details related to but not directly supported by the source text, which is a kind of "hallucination".Liu et al. [75] tried to employ human feedback to enhance the summarization factual consistency.The dataset DeFacto they built contained human demonstrations and informational natural language feedback consisting of corrective instructions, edited summaries, and explanations with respect to the factual consistency of the summary.Feng et al. [29] tried to resolve this hallucination problem by disentangling the comprehension and embellishment abilities of LLMs.It trained the embellishment to be consistent with the facts presented in the original text.</p>
<p>Overall, LLMs perform well in text summarization tasks, even surpassing humans in simple summaries, but this does not mean they are flawless.In the educational domain, helping students summarize learning materials should ensure there is no conflict between the summary and the original content.LLMs still face issues with hallucinations in this aspect.While these hallucination issues can be mitigated through post-processing techniques, hallucinations remain a fundamental problem with LLMs that extends beyond the task of text summarization.Addressing the issue of hallucinations in LLMs is an ongoing research challenge that requires further investigation and development of novel approaches.Until a satisfactory solution is found, it is important to exercise caution when using LLM-generated summaries in educational contexts and to have mechanisms in place to verify the accuracy and consistency of the summaries with the original learning materials.</p>
<p>Grammatical Error Correction.</p>
<p>We are well aware of the remarkable capability of LLMs to generate fluent and coherent conversations.However, from an educational perspective, the importance of producing grammatically correct dialogues cannot be overstated, especially for students learning a new language.The correctness of grammar in conversations plays a vital role in language acquisition, providing students with reliable examples to emulate and learn from.Numerous studies have evaluated the effectiveness of LLMs in grammatical error correction (GEC).Several works [28,91,137] first evaluated the error correction performance of closed-source LLMs such as ChatGPT.Although there exists a pronounced gap between ChatGPT and the previous state-of-the-art [40,95] models on the overall F0.5 metric, closer analysis shows that ChatGPT underperforms other models in terms of precision but far exceeds other models in terms of recall.That said, LLMs like ChatGPT are good at error detection.A detailed manual analysis of ChatGPT's outputs revealed that, in most cases, it maintained grammar accuracy better than the previous methods.However, it often overcorrects sentences to increase diversity and fluency, resulting in a decrease in the recall score.As a result of this characteristic, LLMs perform better when evaluated on higher-order metrics such as fluency, which assess modifications to text.However, for issues requiring minimal edit corrections, they may not necessarily outperform traditional models.Some efforts have attempted to mitigate the problem of over-correction in large models by employing instruction-tuning techniques, encouraging them to make only the necessary, such as CoEdit [108], which covered multiple text editing tasks (including GEC) by fine-tuning LLMs to integrate the capabilities brought by these tasks.</p>
<p>GrammarGPT [27] collected grammatically incorrect sentences and performed instruction tuning on LLMs to improve the ability of positioning grammar errors.</p>
<p>Overall, LLMs perform well in the area of GEC, with their main issue being over-correction.In scenarios such as copywriting or article writing, this problem is not critical, as LLMs can assist individuals in correcting grammatical errors while crafting more fluent sentences.However, in educational settings, LLMs' GEC capabilities are more often utilized to aid students in learning grammar.This requires LLMs to accurately identify grammatical errors in sentences.</p>
<p>The issue of over-correction could potentially mislead students, making further adjustments necessary.</p>
<p>Summary.</p>
<p>Leveraging LLMs' proficiency in text summarization and grammatical error correction can significantly benefit education.Their capability to condense complex material into concise summaries facilitates efficient learning, while error correction tools help improve students' writing and language skills.However, critical challenges need to be resolved to integrate these writing-related capabilities to help education.It becomes evident that more refined evaluation metrics and task-specific optimizations are essential for LLMs.</p>
<p>Programming</p>
<p>Programming is a process of writing code and correcting code if unexpected results are obtained.Incorporating LLMs in programming education is reshaping the future of AI-assisted programming learning.LLMs could play multiple roles: as instructors providing guidance, as teaching assistants offering personalized tutorials, and as collaborative coding partners.Studies like [85] demonstrated improved performance (17%) and efficiency (13%) among programming novices using LLM-based assistants.Research from [102] focused on programming education tasks and benchmarks like [32] and [24], which were used to evaluate the effectiveness of LLMs.This section mainly discusses the LLMs' coding capability development from two perspectives: code writing and code refinement, corresponding to the two stages in programming.</p>
<p>Code</p>
<p>Writing.Unlike natural language tasks, generating code requires a more rigorous token syntax and places higher demands on the training stage.A common method to improve LLMs' performance in generating code is to train or fine-tune them on extensive code datasets [15,92].WizardCoder [84] introduced the Evol-Instruct [142] method to generate complex and diverse instruction datasets of code-related tasks.To emulate the iterative process of humans repeatedly modifying and reviewing code, InCoder [31] utilized bidirectional encoding instead of left-to-right encoding.</p>
<p>In addition to next-token prediction, training or fine-tuning code-aimed LLMs on additional code-related tasks could enhance their programming capabilities.LLMs first learn language patterns and representations from a large amount of text data through unsupervised learning.Then, they could be fine-tuned on labeled code tasks, allowing them to learn targeted code representations and gain a deep understanding of code structure and semantics based on the provided labels.CodeT5+ [134] introduced the concepts of unimodal and bimodal alignment, increasing the model's adaptability to function in different modes for various downstream tasks.During the bimodal alignment phase, the model synchronizes the representations of text-code pairs using multiple tasks, which improves its ability to understand and generate content across different modalities.CodeLlama [112] also applied the multi-task objectives, including autoregression and causal infilling prediction, which achieves better performance among open models.MFTCoder Conference acronym 'XX, June 03-05, 2018, Woodstock, NY Q.Li, et al. [70] utilized the Multi-Task Learning (MTL) technique and incorporated a training loss computation algorithm to alleviate the instability and imbalance of multi-task training.Given that code text has its unique syntax and structure compared to natural language text, the methods mentioned above all attempt to construct datasets of code and perform fine-tuning.This is the most direct and effective approach to enhancing the code capabilities of LLMs.</p>
<p>By fine-tuning on code datasets, LLMs can enhance the probability of generating a correct piece of code.Considering the human programming process, besides relying on the programmer's coding skills, it also involves various stages such as consulting documentation, designing code frameworks, implementing and testing submodules, which entail numerous decision-making processes.Therefore, many works perceive LLMs as agents, viewing the coding process as a continuous series of decisions and external tool invocations.Zhang et al. [158] attempts to enhance the effectiveness of model code generation by employing a tree search approach, without altering the parameters of LLM itself.Specifically, each token in the code is regarded as an action, with the generated code serving as the state.The LLM makes decisions step by step, while utilizing Monte Carlo Tree Search (MCTS) to calculate the value of each action (token) in the current state, thereby selecting the optimal action and significantly improving its pass rate in code generation.Similarly, Zhou et al. [161] also treats LLM as an agent, where each action involves generating a complete piece of code.It employs MCTS to estimate the value of each action as well.Shinn et al. [118] introduced Reflexion framework, which enhances LLM agents through linguistic feedback.The method assigned LLMs the roles of both generating code as actors and evaluating it the code as evaluators.Additionally, it utilizes self-reflection to generate verbal reinforcement cues aimed at assisting the actor in self-improvement.[163] introduces a document retriever as a precursor to the code generator, extracting relevant function descriptions from documents to provide external information to the LLM.This enables the generated code to utilize the latest library functions.By considering the LLM as an agent and utilizing external documents or tree search algorithms, the accuracy of the agent's decisions can be improved without the need to update the model's parameters, which reduces training costs.However, this approach also has a downside: it increases the time required for decision-making during the code generation process, resulting in lower inference efficiency compared to using the LLM alone.</p>
<p>In addition to single-agent approaches, multi-agent systems have also made significant progress in code generation tasks.Qian et al. [106] developed ChatDev that divided the process of writing code into four stages: designing, coding, testing, and documenting.Each stage is managed by a group of "software agents", with the entire chat chain acting as a facilitator, assigning specific sub-tasks to each stage.The system achieved efficient code writing.Furthermore, Hong et al. [45] proposed MetaGPT, a Multi-agent system for coding, which assigns diverse roles to different agents, such as Product Managers, Architects, Engineers, etc.They introduce Standardized Operating Procedures (SOPs) into prompt sequences, effectively enhancing the effectiveness of code generation.Although chat-based multi-agent systems have shown significant effectiveness in code generation tasks, they impose high demands on the fundamental capabilities of LLMs due to the need for dialogue-based coordination between agents.The effectiveness of these systems generally increases with the rise in the parameter size and capability of LLMs.</p>
<p>Code</p>
<p>Refinement.In most cases, LLMs could not generate the correct code at once.We could enable LLMs to generate a code sketch (either actual code or pseudocode) and utilize various methods to guide the model to modify and refine the code.By leveraging the inherent code correction ability of LLMs, the overall precision and quality of the code could be significantly enhanced.</p>
<p>We investigate the development of LLMs in code refinement from two perspectives.One aspect is the advancement of LLMs in the task of fixing code bugs, known as Automated Program Repair (APR).Sobania et al. [119] conducted experiments analyzing the performance of ChatGPT on the APR task.They found that it can achieve competitive results compared to previous deep learning-based methods, and incorporating additional information through dialogue can surpass previous approaches.Xia and Zhang [139] introduced conversational APR, enabling LLMs to obtain bug feedback through dialogue, effectively enhancing the performance of various LLMs in APR.In addition to the APR task itself, the second aspect involves integrating code refinement into the process of code generation, leveraging bug feedback to enhance the effectiveness of code generation.Liventsev et al. [79] constructed a pipeline: Synthesize, Execute, Instruct, Debug, and Rank (SEIDR).It first generates multiple different codes and undergoes the process of code filtering and debugging, ultimately selecting the best code among them.According to Magister et al. [87], teaching an LLM to debug its program draft via few-shot demonstrations could improve the performance on code generation tasks.</p>
<p>Another method for LLM debug is generating unit tests by LLM itself and checking its code [13].By mimicking the human coding process, LLM's programming ability is greatly enhanced.However, these methods lead to an increased number of calls to LLMs, resulting in a significant increase in inference time.</p>
<p>In the context of coding education, the support and guidance provided by LLMs do not yet match the level of assistance offered by human instructors.One major reason for this gap is that LLMs still have substantial room for improvement in their coding capabilities.While LLMs can generate functional code for relatively simple tasks, when it comes to generating complex algorithms, LLMs' performance rapidly declines compared to the functionality achieved by humans [16].Additionally, due to the lack of real-world data, LLMs struggle to learn the intermediate thinking process of code writing, making it difficult for them to provide relevant explanations and instructions to beginners.As a result, the use of LLMs in programming education still needs to be improved, especially in terms of interpretability.</p>
<p>Summary.</p>
<p>Code data is more abundant in the training corpora of LLMs compared to mathematical data.This is primarily due to the inherent nature of coding, which heavily relies on computers and the internet.As LLMs are trained using data scraped from the web, they are exposed to a significant amount of code-related information during the training process.Many improvements to LLMs' code generation abilities are inspired by the human programming process.For instance, programmers often refer to documentation and resources to gain a better understanding of the problem and potential solutions.For complex coding tasks, the solving process typically involves a cycle of design, writing, and debugging.These thought processes can be utilized to enhance the programming effectiveness of LLMs.</p>
<p>From an educational perspective, it is crucial for LLMs to not only generate correct code but also possess the ability to analyze and provide feedback on code written by students.This involves identifying issues, suggesting improvements, and offering explanations to help students learn and grow as programmers.</p>
<p>Reasoning</p>
<p>The reasoning capability of LLMs offers significant potential for educational use, serving as advanced tools that enhance students' cognitive processes, provide personalized mentorship, and offer tailored learning support.This section reviews LLMs' general reasoning ability development strategies.</p>
<p>Supervised Fine-tuning for Reasoning. Previous studies have primarily focused on fully supervised fine-tuning</p>
<p>LLMs to enhance their reasoning capabilities.This approach aligns model outputs closely with labeled datasets, allowing the models to produce highly accurate predictions within specific domains.One such study by [109] demonstrated the efficacy of fine-tuning a pre-trained GPT model, which generated rationales for predictions on the CoS-E dataset [121].The results revealed that models trained with explanations exhibited improved performance in commonsense question-answering tasks.However, the effectiveness of fine-tuning methods heavily relies on the availability of a specific dataset that includes explicit reasoning steps.Acquiring such a dataset can prove to be challenging.Moreover, the scope of inference from fine-tuned models is restricted to the dataset's domain, hinging largely on the data's inferential quality.This constraint highlights the benefits and limitations of fully supervised fine-tuning, as it narrows the model's reasoning abilities to the dataset's specific domain.Consequently, it underscores the need to explore methods that harness LLMs' intrinsic reasoning capabilities, potentially providing broader relevance and deeper insights beyond the limitations of domain-specific datasets.</p>
<p>3.4.2Prompt Engineering for Reasoning.Efforts have been made in recent research to tackle the constraints inherent in the fine-tuning process of LLMs.These fine-tuning methods tend to overfit specific dataset distributions, reducing their effectiveness on more diverse datasets.In response to this issue, a variety of strategies have been proposed.These strategies are designed to draw upon the robust reasoning abilities inherent in LLMs by leveraging their extensively pretrained parameters.One approach involves guiding LLMs to generate inference and reasoning through demonstrations or prompts.For example, Wei et al. [136] introduced the "Chain of Thought" (CoT) method, which utilized natural language reasoning steps as prompts for the model.By integrating CoT within a few-shot prompting framework, the model leveraged its extensive parameters to produce analogous chains of reasoning.Consequently, this approach empowered the model to adeptly navigate complex reasoning tasks across diverse domains, obviating additional training or fine-tuning.This innovation underscored the model's inherent capability to generate deductive pathways, significantly enhancing its applicability and versatility in problem-solving scenarios without extensive domain-specific adaptations.Similarly, Wang et al. [133] introduced a self-consistency strategy that enhances model performance by sampling various reasoning paths and selecting the most consistent answer.This approach diversified the exploration of reasoning strategies.It ensured the conclusions' reliability, showcasing an innovative way to leverage the model's capabilities for improved decision-making and problem-solving across different contexts.Confronting the limitations of relying on static, manually annotated demonstrations, which can restrict the adaptability of LLMs to the varying complexities of real-world tasks, Diao et al. [23] introduced an active selection approach.This technique dynamically pinpointed the most pertinent demonstrations aligned with the specific demands of a task from a broad set of queries.In this way, the approach enhanced the flexibility and effectiveness of LLMs in adapting to diverse and evolving problem contexts.Concurrently, Zhou et al. [162] devised a prompting methodology that broke down intricate problems into their simpler constituent sub-problems.This tactic not only promoted a step-by-step problem-solving process but also hold promise for augmenting the efficacy of LLMs in handling complex tasks.</p>
<p>Building upon the CoT methodology, subsequent developments have introduced more sophisticated frameworks for enhancing the reasoning capabilities of LLMs.The Tree of Thoughts (ToT) [147] framework extended CoT by enabling LLMs to explore multiple reasoning paths through a hierarchical structure, thereby improving decision-making for tasks requiring strategic planning.Following the ToT, the Boosting of Thoughts (BoT) [17] framework introduced a novel approach by iteratively exploring and self-evaluating multiple trees of thoughts.This process accumulated an ensemble of trial-and-error reasoning experiences, offering a new form of prompting designed to tackle complex problems.Starting with simple prompts, BOT iteratively refined reasoning steps through error analysis, significantly improving the generation of reasoning paths and achieving higher problem-solving rates on complex tasks than existing advanced prompting strategies.To structure thoughts through prompts without depending on fine-tuning, the Graph of Thoughts (GoT) framework [9] introduced a new angle by arranging thoughts generated by LLMs into a graph structure.This setup fostered a dynamic interaction among different thought units, facilitating synthesizing synergistic results, simplifying intricate thought networks, and refining ideas via feedback mechanisms.GoT's graph-based approach presented a versatile tool for problem-solving, allowing for a more nuanced and interconnected reasoning process that mirrors the complexity of human thought.</p>
<p>The emergence of CoT and related prompting strategies marked a significant evolution in utilizing LLMs for advanced reasoning, transitioning away from dependence on fine-tuning.These methods exploited the LLMs' inherent capabilities to enhance their flexibility and effectiveness across various tasks without reliance on domain-specific tuning.</p>
<p>Hybrid Methodologies for</p>
<p>Reasoning.Despite the success of prompt engineering in leveraging the intrinsic characteristics and capabilities of LLMs to enhance their performance, this approach falls short of fundamentally augmenting the model's core reasoning abilities, as it does not alter the model's underlying parameters.This inherent limitation points to a need for strategies that not only exploit the pre-existing strengths of LLMs but also seek to expand their innate capabilities.Innovative approaches that integrate the specificity of fine-tuning with the flexibility of prompt engineering have been developed to bridge this gap.These hybrid methodologies aim to bolster the LLMs' responsiveness to complex prompts and substantially improve their intrinsic reasoning capacities, offering a more comprehensive enhancement of their problem-solving prowess.One practical approach is to utilize LLMs to "teach" language models with smaller model sizes.Ho et al. [44], Magister et al. [87] explored to fine-tune a student model on the chain of thought outputs generated by a larger teacher model and proved that enriching the fine-tuning data with such diverse reasoning results in a substantial performance boost across datasets even for very small models.Moreover, Zelikman et al. [152] reported significant performance improvements across multiple datasets by generating step-bystep rationales and fine-tuning models based on correct answers, thus facilitating model learning from its reasoning.</p>
<p>Similarly, Huang et al. [47] proposed that by employing chain-of-thought prompting [136] and self-consistency [133] to generate rationale-augmented answers, and then used these answers for fine-tuning, LLMs autonomously refined their reasoning capabilities.This approach highlighted the significant ability of LLMs to advance their knowledge and problem-solving skills independently.</p>
<p>Summary.</p>
<p>In the educational domain, reasoning tasks possess unique characteristics that necessitate not only the accurate processing of information but also the capability to navigate and elucidate complex concepts in a manner that is accessible and educational for learners.As mentioned above, the discussed methods have significantly advanced the reasoning capability of LLMs, optimally utilizing their unique features for diverse reasoning tasks.This enhancement can greatly benefit educational applications.However, it's crucial to recognize the limitations.As underscored by Valmeekam et al. [128] and Ruis et al. [113], LLMs struggle with complex reasoning tasks and those requiring implicit expressions.</p>
<p>For example, LLMs can struggle with complex reasoning scenarios, leading to a notable decrease in performance.This is particularly relevant in educational contexts, where incorrect problem-solving modeled by LLMs could misguide students and lead to misunderstandings or flawed comprehension.Thus, despite LLMs' immense educational potential, their limitations must be carefully considered to ensure they facilitate rather than obstruct learning.</p>
<p>Knowledge-based Question Answering</p>
<p>In the context of Knowledge-based Question Answering using LLM, the user presents a question to LLM, and LLM leverages knowledge-based methods and responds with the corresponding answer.Previous work by [110] showed that LLMs have an inaccurate perception of factual boundaries and often exhibit overconfidence.Many studies have explored and utilized external knowledge from open-world and domain-specific databases to enhance the knowledge base of these LLMs.Due to the fixed parameters of the model, ensuring real-time information solely through the LLM itself is challenging, and LLMs commonly suffer from severe hallucination issues [143], posing a challenge to their authenticity as well.</p>
<p>Jiang et al. [54] evaluated the accuracy of LLM responses to a particular question from the perspective of calibration.</p>
<p>Through experiments, the researchers discovered that models such as T5, BERT, and GPT-2 are not well-calibrated in QA tasks.While suggesting that incorporating calibration-related methods into the fine-tuning process can effectively enhance performance in QA tasks, it is evident that solely pre-trained language models still face significant challenges in open-domain tasks.To overcome this challenge, many works tried to add additional information to help the LLMs answer correctly [10,43,58].A common information source used is from the web.Lazaridou et al. [59] employed information gathered from web searches as prompt input for LLMs, conditioning it to generate answers to questions.</p>
<p>This approach effectively enables LLMs to use open-world information to answer questions.Vu et al. [129] introduced FreshPrompt, which incorporated web pages collected from the internet into prompts given to large-scale models.This allowed them to leverage the latest information when answering questions.Kasai et al. [55] developed a QA platform REALTIME QA that updated itself weekly.Through evaluation on this platform, they found that GPT-3 could update its generation results based on newly retrieved documents.However, when retrieved documents fail to provide sufficient information to find the answer, GPT-3 may provide outdated answers.</p>
<p>The development of LLM-based open-domain question answering highlights significant challenges, particularly in</p>
<p>dealing with hallucinations.In the context of establishing an LLM-based education system, this issue becomes more critical for providing seemingly correct yet incorrect answers, leading to misleading students.Drawing insights from approaches that introduce additional information from sources such as the web or textbooks can offer valuable lessons for the development of an LLM-based education system.</p>
<p>3.5.2Domain-specific QA.Although LLMs are trained on vast corpora, they may still exhibit gaps in understanding specific domains.The primary challenge faced by LLMs in this task is the lack of domain knowledge.For specific domain questions, providing good answers often requires a considerable amount of expertise or skills in that field, while professional data is relatively scarce in the corpus of large-scale models.One straightforward approach is to fine-tune LLMs on specialized datasets.Typically, there are dedicated knowledge repositories for professional content that consolidate domain-specific knowledge, such as MedlinePlus1 , GeeksforGeeks2 , etc. Choi et al. [19] utilized an external knowledge base to generate a set of question-answer pairs and then employed fine-tuning to transfer financial knowledge to LLMs, significantly improving financial question-answering tasks.Another common approach is to leverage the in-context learning capability of LLMs by incorporating retrieved knowledge from the knowledge base into prompts.Peng et al. [100] demonstrate this approach in their work on pest identification.They first use text embeddings, which are dense vector representations of text, to retrieve relevant information from a knowledge base.Text embeddings allow for efficient and accurate retrieval of similar or related content based on the semantic similarity between the query and the stored information.Once the relevant knowledge is retrieved, it is incorporated into the prompts provided to the LLMs.The LLMs then utilize their automatic feature extraction capabilities to process and understand the retrieved information in the context of the pest identification task.zhang et al. [159] utilized K-nearest neighbors (KNN) [42] to search for the most similar K records from an accounting database, serving as k-shot examples, and greatly improved accounting efficiency.There are also works that train and improve the retriever encoder [157], as well as distill and refine the data in the database [49].Such retrieval frameworks have lower costs and can be more flexible in applications across different domains.Liu et al. [72] proposed the RETA-LLM, a system that leveraged an information retrieval system based on Google Search to initially retrieve the top-k documents relevant to a user's query, allowing LLMs to generate answers based on these retrieved documents.Furthermore, the system included plug-and-play modules that enable users to construct their own domain-specific LLMs.These modules covered various functionalities, including request rewriting, document retrieval, passage extraction, answer generation, and fact-checking.</p>
<p>By integrating Information Retrieval (IR) systems, LLMs can enhance their capabilities with professional knowledge, gaining valuable and precise supplemental information.Furthermore, according to Ren et al. [110], retrieval augmentation can also be employed to improve LLMs' ability to perceive facts within the boundaries of their legal knowledge, mitigating the issue of hallucinations.During the education process, different majors or courses involve different professional content.Applying external knowledge repositories as an enhancement mechanism can provide more accurate guidance in domain-specific contexts and mitigate the issues caused by misleading information.Therefore, domain-specific question-answering ability is crucial for developing an LLM-based education system.</p>
<p>Discussion</p>
<p>Despite the varied and specific challenges associated with each capability, certain strategies and insights resonate universally among researchers working to harness the capabilities of LLMs for educational purposes.Here we discuss the trends or commonalities we discovered across the development of capabilities.approach extends beyond mere training.Through in-context learning, where desired inputs and outputs are formed into demonstrations and provided as prompts to LLMs, if the demonstrations are well-chosen, they can also greatly enhance the model's capabilities.</p>
<p>There is a notable trend towards leveraging smaller models fine-tuned on high-quality data to surpass the performance of larger language models.This approach emphasizes the importance of focused, domain-specific training rather than simply relying on the vast number of parameters in large-scale models.The term "high-quality data" here refers to data that provides detailed supervisory signals for specific domain problems.For instance, even powerful LLMs like GPT-4 encounter high error rates with large multiplication in basic arithmetic problems.However, with a dataset that includes detailed steps for multiplication and addition, even a small transformer model can effectively solve these problems.Similarly, for reasoning tasks, it's possible to improve LLMs' performance on these issues without altering model parameters, simply by incorporating specific reasoning steps into the demonstrations in the prompt.This highlights that the application of "high-quality data" in LLMs extends beyond just fine-tuning.</p>
<p>There is a concerted effort among researchers to explore how smaller models can achieve equivalent or superior outcomes in certain scenarios where LLMs have already exceeded human benchmarks.This pursuit reflects a broader shift towards optimizing computational efficiency and model scalability, ensuring that the advancements in LLM technology remain accessible and sustainable.The primary scenarios and objectives for training small models can be divided into two categories:</p>
<p>• Training specialized models with high-quality data.For applications within specific, narrow fields, such as programming, developing a small, specialized model through data collection can facilitate deployment and reduce the computational resources needed for inference, among other benefits.</p>
<p>• Training small models through knowledge distillation.In cases where the required knowledge and skills for an application are more general, it may be challenging to construct a specific dataset for training a small model.By learning to match the outputs of the teacher model, the student model can effectively absorb the knowledge and skills of the larger model, without the need for a curated dataset.This allows the smaller model to inherit the generalization capabilities of the large teacher model, while being more computationally efficient and easier to deploy in resource-constrained environments.</p>
<p>Efficiency is an unavoidable issue for LLMs during training and real-world deployment.Training-wise, low-loss, high-efficiency training schemes like LoRA (Low-Rank Adaptation) [46] are continually being introduced.These can significantly reduce the number of trainable parameters required during fine-tuning.However, small models are still needed.In practical applications, where the trained models need to be deployed and used for generating predictions or outputs, the size of the model still plays a critical role.</p>
<p>3.6.2LLMs could achieve self-improvement.The inference abilities and text comprehension skills of LLMs enable them to conveniently obtain feedback, which allows them to refine their outputs.This process is known as the self-improvement, which is a general approach in improving LLMs' answers to all the capabilities.LLMs can achieve self-improvement through a methodical approach that involves iterative refinement and multiple sampling.For instance, to provide better responses to queries, an LLM may first generate an initial output.Then, it evaluates the output's effectiveness or accuracy.</p>
<p>Leveraging multiple sampling, the LLM explores different solution pathways or creative responses, which expands its potential answers pool.Through iterative refinement, it compares, contrasts, and consolidates these possibilities, learning which strategies yield the best results.This could involve internal processes such as adjusting parameters based on feedback loops, where it might integrate data from new examples or corrections provided by human users.</p>
<p>Over time, this enhances the LLM's ability to provide more precise, informative, and contextually relevant answers, thus gradually improving its problem-solving and content creation skills.In addition to individual LLMs enhancing their capabilities through feedback, the method of coordinating multiple LLMs to improve overall output is also being explored across various fields.For example, in solving programming problems, the process can be segmented into different stages, with each stage managed by a distinct LLM.These LLMs communicate and collaborate to complete the task collectively.Alternatively, one LLM may act as a generator to produce answers, while another serves as an evaluator to provide feedback.Through continuous dialogue between the two, the response can be consistently assessed and refined, thereby improving the quality of the answer.This cooperative approach leverages the strengths of different models to achieve a more effective and sophisticated problem-solving mechanism.Although the method of self-improvement is effective, it often results in a longer time to produce responses.For an LLM-based education system, the importance of providing accurate answers to students' questions (to avoid misleading them) outweighs the need for speed.Therefore, employing a multi-agent approach to enhance answer quality through LLMs' collaboration, or using sampling and iterative optimization for self-improvement, is an appropriate strategy for developing an education system.This ensures that the system prioritizes the correctness and reliability of information, which is crucial in educational settings where students' learning effect is depend on the accuracy of the content provided.</p>
<p>3.6.3Calling external tools is an universal method.The integration of external tools into the LLM framework is a widely adopted method.This strategy not only enhances the models' ability to access and incorporate real-time information and authoritative sources but also mitigates some of the inherent limitations of LLMs, such as their tendency towards factual inaccuracies or hallucinations.We can divide the use of external tools by LLMs into two perspectives:</p>
<p>• LLMs inherently have certain limitations that cannot be resolved through training alone, and external tools can be used to address these deficiencies.In this scenario, tools serve the LLMs.For example, LLMs' high error rates in large number multiplication can easily be mitigated by employing an external calculator.Similarly, LLMs' inability to access real-time information can be compensated for by retrieving the latest web pages via web API calls.</p>
<p>• Utilizing the reasoning and decision-making capabilities of LLMs, the invocation of external tools can influence the real world.In this approach, the primary task of LLMs is to make informed decisions about when and which tools to utilize in order to accomplish specific tasks.The key responsibility of LLMs in this approach is to act as intelligent agents that can analyze a given situation, understand the requirements and constraints, and determine the most appropriate course of action.</p>
<p>The LLM that solves problems by invoking external tools is a type of LLM agent, where the external tool is not necessarily an API but can also be an expert model.Fine-tuning LLMs on specific datasets can yield excellent results on the corresponding task, but it's impractical to fine-tune LLMs across datasets for all capabilities.A viable solution is to use fine-tuned small language models as expert models, which serve as external tools for the central LLM.Compared to APIs, the advantage of trained expert language models is their ability to understand more granular and flexible demands from the LLM, providing targeted feedback.</p>
<p>OVERALL DEVELOPMENT STATUS</p>
<p>Before exploring the possibilities of building an education system based on LLMs, we first need to investigate the performance of LLMs in capabilities related to education.We select representative benchmarks to assess the current development of LLMs across education-related capabilities.Specifically, we mainly collect the results from three sources:  1, where one can observe that:</p>
<p>• It is hard for a single LLM to be superior across all capabilities.Among the current LLMs, GPT-4 has shown the most impressive overall performance.However, utilizing GPT-4 comes with higher associated costs compared to other LLMs, which can be a significant consideration for users and organizations with limited budgets, and it has been surpassed by TigerBot in knowledge-based QA tasks.For mathematics, GPT-4 achieves optimal performance on the representative dataset GSM8K, but it exhibits a higher error rate in basic arithmetic tasks, such as large number multiplication.• LLMs still lag significantly behind humans in some crucial abilities.One notable example of this gap is illustrated by their performance on TruthfulQA [68], a benchmark designed to evaluate the ability of models to provide truthful and accurate answers, where human achieves achieving 94% accuracy while GPT-4 only got 59% correct.</p>
<p>• Most LLMs display considerable variation in developing these skills.While certain models (such as Alpaca and Yi) might excel in text comprehension tasks, their effectiveness often diminishes in areas requiring deep understanding and reasoning, like Mathematics and Programming.This reveals the substantial challenges in building a unified education-focused LLM since it may fail in certain areas.</p>
<p>POTENTIAL OF LLM-BASED EDUCATION SYSTEM</p>
<p>LLMs can potentially transform online education by understanding a wide range of student questions, similar to human teachers.They aim to provide support across different subjects and skill levels.With the latest developments in LLMs, we suggest two approaches for creating LLM-based education systems.The first involves training a comprehensive and unified LLM that can handle questions from various subjects.The second approach uses a mixture-of-experts (MoE) framework, integrating specialized models to support the system with an LLM controller to manage interactive dialogues with students.An education framework implemented with a mixture-of-experts (MoE) approach is illustrated in Figure 4(b), consisting of multiple models that excel in individual capabilities (not necessarily LLMs) and an LLM controller.The controller is mainly responsible for three tasks:</p>
<p>• Understand the student's request and decide which specific area or areas the request is about.</p>
<p>• Re-form the request to fit the input of the specific areas' expert models.</p>
<p>• Aggregate the output of the related experts and generate the final response to the student.</p>
<p>The advantage of the MoE approach is that training is less challenging.The result is a suite of models, each excelling in its specific domain or capability, which, when combined, offer a comprehensive educational tool.This specialization means training can be more focused and less onerous, optimizing resources towards developing excellence in distinct areas of knowledge and skills.However, one significant drawback is the increased potential for misunderstandings or errors during the system's inference phase, primarily due to the complexity of interactions between the different specialized models and the LLM controller.Errors can arise from the LLM controller misinterpreting student inputs or incorrectly assigning tasks to the specialized models.Moreover, integrating outputs from various experts into a coherent response can also introduce discrepancies, as differences in context or terminology used by each model can lead to inconsistencies in the overall communication with students.Despite these challenges, the approach represents a practical pathway toward realizing an LLM-based educational assistant system.By leveraging specialized models for different capabilities, it's possible to create a more flexible and efficient system that can adapt to a wide range of educational needs and learning styles.The key to success lies in improving the integration and communication between the specialized models and the overarching LLM controller, ensuring that the system can handle complex inquiries and deliver accurate, useful responses to students.Currently, this approach appears to be a viable strategy for achieving the ambitious goal of an effective LLM-based educational assistant, promising a future where personalized education is accessible and adaptable to every learner's need.</p>
<p>CHALLENGES AND FUTURE DIRECTIONS</p>
<p>Recently, more and more researchers have been trying to apply LLMs to handle education tasks, such as course design, student evaluation, lesson plan design, and others.Nevertheless, there are still numerous challenges and opportunities that need to be addressed.</p>
<p>• Planning for Students.Solving subject-related questions for students can significantly address the issue of students not receiving targeted guidance from teachers.Furthermore, a higher-level task involves assessing students' knowledge status and planning their learning paths.These tasks are continuously evolving in the era of deep learning, with the adaptation and application of LLMs in these areas requiring further exploration.</p>
<p>The primary challenge in planning learning paths for students lies in integrating knowledge from two aspects: first, the human knowledge system, which involves the structural relationships between knowledge points, requiring LLMs to understand the meaning of these knowledge points.Second, the personalized information of students, including their knowledge state, learning interests, and habits.Previous deep learning models for this task have been trained on sequences of student behaviors, which are often constructed as IDs rather than text.</p>
<p>Since the foundation of LLMs is their ability to process text, the gap in data form presents a significant challenge in applying LLMs to this task.• Interdisciplinary Reasoning Ability.Students may encounter interdisciplinary reasoning problems during real-world learning, requiring the education system to integrate multiple capabilities to formulate responses.</p>
<p>As illustrated in Figure 1, student intends to write a program to solve a mathematical problem, and the model needs first to comprehend the mathematical problem, devise a solution, and then generate the code.</p>
<p>This process necessitates the model to synthesize both mathematical and programming capabilities.However, there is currently limited research in the integration of multiple interdisciplinary capabilities for LLMs at this stage, including both datasets and algorithms.Boyko et al. [11] examined how LLMs augment scientific inquiry, code development, scientific writing process, etc., and they propose that LLMs can foster interdisciplinary work by bridging knowledge gaps across scientific fields.However, they mainly discuss the LLMs' ability to help researchers' interdisciplinary collaboration instead of their ability to answer interdisciplinary questions.</p>
<p>Cultivating an LLM to obtain this ability would help to develop a unified education system, which is an essential research direction.</p>
<p>• Student Modeling.Before the era of LLMs, in the age of deep learning, modeling student behavior was primarily achieved through sequential models, such as RNNs [117] and Transformers.A drawback of this approach was the inability to obtain student feedback, and the results lacked interpretability.Establishing an LLM-based education system allows students to articulate their personalized needs through dialog.Through such conversations, we can extract or infer personalized features about students, such as their current mastery of topics and preferences in learning styles.Besides modeling students from conversations, some researches [3,6] have shown that LLMs have certain abilities in simulating humans and generating human samples.Applying to education, this ability indicates a potential for LLM-based student simulation.In this way, for the students with few interaction records, the LLM-based simulator could generate more samples and provide data to help the expert model better understand the student.It could help human teachers develop teaching skills better.</p>
<p>• Social Bias of LLMs Even after training through Reinforcement Learning from Human Feedback (RLHF) [98],</p>
<p>LLMs can to some extent avoid answers that do not align with human cultural habits and values [30,53], it has been observed that LLMs still manifest a certain degree of value bias in their responses.Feng et al. [30] pointed out that the training of LLMs can lead to a certain degree of political bias.In the field of education, although most questions posed by students are related to scientific knowledge, issues such as writing and text reasoning should ideally be avoided by researchers developing foundational LLM models.In educational applications, the social biases inherent in LLMs pose a risk of inadvertently impart imparting skewed value systems to students.</p>
<p>To safeguard the educational integrity and ensure the neutral and fair dissemination of knowledge, it is crucial to implement stringent measures.These could include developing advanced content review systems, establishing clear guidelines for the ethical use of LLMs in educational settings, and continuously monitoring the quality and nature of the LLM-generated content.Through these efforts, the educational community can leverage the benefits of LLMs while minimizing the risk of perpetuating biases, thus maintaining a balanced and objective learning environment.</p>
<p>• Preventing Cheating in Education.The texts generated by LLMs are indistinguishable from or even surpass those produced by humans in terms of fluency and usage.Although the primary aim of this article is to survey the development of LLMs in educational capacities, offering insights for the creation of an educational supermodel, it's crucial to recognize that in certain educational contexts, the over-reliance on LLMs is not desirable as it could hinder the natural learning process.For instance, while it's acceptable for students to seek assistance from LLMs to aid understanding during homework tasks, relying on LLMs to complete assignments without thoughtful consideration prevents students from receiving the necessary practice and learning.Therefore, identifying content generated by LLMs holds significant importance in the educational domain to prevent cheating and ensure the integrity of the learning process.By striking a balance between leveraging LLMs for educational enhancement and maintaining rigorous educational standards, educators and technologists can create an environment where students benefit from technology without compromising their learning journey.Recent studies have proposed detectors to identify LLM-generated texts.The foundational ideas could be broadly categorized into two primary strategies: statistical outlier detection methods and supervised classifiers.The former strategy focuses on uncovering statistical differences in linguistic features between texts written by humans and those generated by LLMs.This involves analyzing patterns, such as syntactic structures, vocabulary diversity, and stylistic nuances, that distinguish LLM-generated texts from human-crafted writings.These statistical indicators serve as markers for automated systems to detect content that deviates from human norms, potentially signaling LLM involvement.</p>
<p>On the other hand, supervised classifiers rely on a different mechanism.This approach employs machine learning algorithms that have been trained on a labeled dataset containing examples of both human-written and LLM-generated texts.The battle against detecting LLM-generated texts is dynamic, necessitating ongoing research and adaptation of detection methodologies.As LLMs become increasingly sophisticated, the strategies for distinguishing their outputs from human-created content will need to evolve, embracing a combination of statistical insights, machine learning innovations, and perhaps new, yet-to-be-discovered methods.</p>
<p>• Multi-modal Education.In education, multi-modal information is common, like geometry problems combining text and images or textbook concepts with illustrations.Building a general intelligent education system requires handling such multi-modal data.Notably, the development of multi-modal LLMs is rapidly advancing [26,149].</p>
<p>Different kinds of architectures and pre-train tasks are proposed [26].However, the education domain often exhibits unique distribution characteristics in multi-modal information.Firstly, in education, images and text often have a high level of detail matching; for example, geometry questions often describe the specific parameters of shapes in images in great detail.Therefore, multi-modal large models need to have a high capability of capturing details in image information.Secondly, the multi-modal information in education often requires the model to have a high capacity for cross-modal reasoning, but such data is less common in multi-modal datasets, leading to a potential shortfall in the reasoning capabilities of multi-modal language models across different modalities.Addressing this gap may require targeted datasets, and inspired by Chain of Thought (CoT) and its variants, the data should ideally contain detailed steps of multi-modal reasoning.Efforts are currently being made to address these data deficiencies in the field.Moreover, the characteristics of image and text data in education could limit the choice of structures for multi-modal models.For instance, a popular approach in the field of multi-modal large models involves dividing images into patches to create "image tokens", [88] which are then processed alongside text tokens as input.However, in the educational context, such division might disrupt certain key geometric structures within the images, thereby affecting their interpretation.This drawback could be more pronounced in educational multi-modal scenarios.</p>
<p>CONCLUSION</p>
<p>In this paper, we presented an overview of the development of the LLM-based education system.We first reviewed the important development of LLMs' education-related abilities.Then, we analyzed the potential of it and proposed two different ways of building such a system.We also highlighted the future directions that are worth working on.We hope this survey provides some insight into future research in this direction.</p>
<p>to write a Python program to calculate the sum from 1 to 100 in a simple way.Could you help me to solve this problem?</p>
<p>Fig. 2 .
2
Fig. 2. Summary of LLM's education-related foundational capabilities.</p>
<p>Conference acronym 'XX, June 03-05, 2018, Woodstock, NY Q.Li, et al.</p>
<p>Conference acronym 'XX, June 03-05, 2018, Woodstock, NY Q.Li, et al.</p>
<ol>
<li>
<p>5 . 1
51
Open-domain QA.Open-domain question answering requires LLMs to accurately determine the reliability of information in the open world and craft their responses based on that understanding.The critical requirements for open-domain QA are real-time responsiveness and authenticity.LLMs exhibit disadvantages in both of these aspects.</p>
</li>
<li>
<p>5 . 3
53
Summary.While LLMs have mastered a broad range of open-world knowledge through extensive corpus training, their fixed parameters make it challenging to handle real-time, high-demand open-domain questions.Severe hallucination issues further compromise their accuracy in both open-domain and domain-specific queries.In the field of education, where authenticity is paramount, students may pose questions about textbook knowledge points.If the accuracy of these responses cannot be guaranteed, it could potentially mislead students.Therefore, a feasible solution to the inherent hallucination issues in foundational LLMs is to integrate external information, such as authoritative documents, allowing LLMs to base their responses on such external sources to mitigate hallucination problems.</p>
</li>
</ol>
<p>Fig. A summary framework diagram for the approaches of LLMs in the development of education-related abilities.It categorizes previous enhancement strategies into three parts: Input Data Refinement, Model Self-Improvement, and External Tool Usage.</p>
<ol>
<li>6 . 1
61
High-quality data could help LLMs develop capabilities effectively.Since the advent of the deep learning era, high-quality training data has significantly improved model performance.This is especially true for LLMs, and the Conference acronym 'XX, June 03-05, 2018, Woodstock, NY Q.Li, et al.</li>
</ol>
<p>Conference acronym 'XX, June 03-05, 2018, Woodstock, NY Q.Li, et al.</p>
<p>Fig. 4 .
4
Fig.4.Two frameworks towards LLM-based educational framework.(a) depicts the unified approach, where a single LLM addresses all aspects of educational-related queries, utilizing its internal capabilities such as mathematics, writing, knowledge-based question answering, reasoning, and programming.(b) illustrates the Mixture of Experts (MoE) approach, where an LLM controller is tasked with task distribution, delegating specific questions to specialized expert models that are proficient in individual areas.</p>
<p>Conference acronym 'XX, June 03-05, 2018, Woodstock, NY Q.Li, et al.</p>
<p>OpenCompass 4 and C-Eval5.The formal two are comprehensive leaderboards.C-Eval is a Chinese evaluation suite for foundation models spanning 52 diverse disciplines.We collect performance data from popular general LLMs on these benchmarks, and the compiled results are presented in Table
GPT-4OpenAI [97]92.0062.0067.0091.4059.0068.70ChatGPTOpenAI [96]57.1048.6048.1079.5047.0054.40TigerBot-70B-Chat-V2(70B)TigerResearch [125]54.3661.3030.5082.8375.40-LLaMA2(70B)Touvron et al. [127]60.2751.6029.9082.3056.1855.20LLaMA(65B)Touvron et al. [126]43.3747.1023.7082.3055.0938.80Yi(34B)lingyiwanwu [69]50.6448.9026.2082.0056.2381.40Vicuna(33B)TheVicunaTeam [123]13.7244.9015.2083.0056.1639.80WizardLM(30B)Xu et al. [142]34.42-26.0876.3249.14-Moss(16B)FudanUniversity [33]6.9039.00-55.8049.0033.10Qwen(14B)Bai et al. [7]58.9852.743.9080.2049.4372.10Baichuan2(13B)Yang et al. [144]55.3051.5017.0766.9048.9840.00Alpaca(7B)Taori et al. [122]0.1539.509.1075.7136.2829.90ChatGLM3(6B)Zeng et al. [153]72.3043.1044.5076.50-69.00Huggingface 3 ,
https://medlineplus.gov
https://www.geeksforgeeks.org
https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard
https://opencompass.org.cn/leaderboard-llm
https://cevalbenchmark.com/static/leaderboard.html
ACKNOWLEDGMENTSThe SJTU team is partially supported by National Natural Science Foundation of China (62177033).Unified ApproachThe most straightforward idea for establishing an LLM-based education system is to train a language model capable of answering students' questions across all subjects.As shown in Figure4(a), the foundational capabilities are included in the unified LLM, and the student can directly communicate with it and ask questions.Research on whether general LLMs can handle educational tasks has been underway.Wang and Demszky[130]introduced three teacher coaching tasks for generative AI: (A) scoring transcript segments using classroom observation instruments, (B) identifying highlights and missed opportunities for effective instructional strategies, and (C) offering actionable suggestions to encourage more student reasoning.And evaluated by human teachers, ChatGPT on these tasks for elementary math classroom transcripts generates responses that are relevant to improving instruction, but they are often not novel or insightful.Beyond that, Phung et al.[102]assessed the programming education ability of ChatGPT and GPT-4 by comparing them with human tutors.The result shows that GPT-4 performs way better than ChatGPT, even close to human tutors in some scenarios, while it also highlights some situations in which GPT-4 struggles.In particular, for the grading feedback and task creation scenarios that have a substantial gap in the performance of GPT-4 compared to that of human tutors.From the methods proposed by researchers in developing LLMs for educational capabilities, we can extract some common, scalable approaches to lay the groundwork for developing a unified LLM-based educational system:• High-quality demonstrations.While collecting high-quality data from various fields for fine-tuning LLMs is impractical, achieving better responses through prompt engineering as a form of demonstration is feasible.• API Tool Learning.For inherent challenges within LLMs, such as large number computations and the absence of real-time information, these can be addressed by incorporating external APIs as tools.• Search-based methods.Attempts have been made across various fields to improve the task completion accuracy of LLMs using search-based methods, leveraging the probabilistic nature of LLMs.For challenging questions, LLMs might waver among multiple possible responses.Here, employing search-based methods to evaluate and filter all options can effectively enhance accuracy, offering a generally applicable solution.The benefit of developing a unified LLM-based educational system is that it centers around a general LLM handling the core reasoning tasks.This setup means that all major language-based interactions are directly between the LLM and the students, making the system easier to deploy.The most significant effort and resources are invested during the training phase.This critical period is where the LLM gains expert-level skills in a wide range of subjects, preparing it to effectively support and educate students across various disciplines.MoE ApproachSection 3 reviewed the current development of LLMs across various capabilities.Unfortunately, despite the existence of comprehensive language models, such as GPT-4, these models often exhibit notable deficiencies in certain abilities.This situation poses a challenge, indicating that relying solely on an LLM itself for educational guidance involving all these capabilities is currently a difficult task.Yet, LLMs can achieve excellent results through fine-tuning individual capabilities, and their ability to comprehend human language is exceptionally strong.Therefore, we can aggregate models with distinct capabilities using a mixture-of-experts approach.By establishing an LLM-based controller for language interaction and task assignment with students, a currently feasible education system can be generated.
Knowledge tracing: A survey. Qing Ghodai Abdelrahman, Bernardo Wang, Nunes, Comput. Surveys. 552023. 2023</p>
<p>Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, arXiv:2303.08774Shyamal Anadkat, et al. 2023. Gpt-4 technical report. 2023arXiv preprint</p>
<p>Using large language models to simulate multiple humans and replicate human subject studies. Rosa I Gati V Aher, Adam Arriaga, Kalai Tauman, International Conference on Machine Learning. PMLR2023</p>
<p>Al-Smadi Mohammad, arXiv:2311.15198ChatGPT and Beyond: The Generative AI Revolution in Education. 2023. 2023arXiv preprint</p>
<p>Leancontext: Cost-efficient domain-specific question answering using llms. Biplob Md Adnan Arefeen, Srimat Debnath, Chakradhar, arXiv:2309.008412023. 2023arXiv preprint</p>
<p>Out of one, many: Using language models to simulate human samples. Ethan C Lisa P Argyle, Nancy Busby, Joshua R Fulda, Christopher Gubler, David Rytting, Wingate, Political Analysis. 312023. 2023</p>
<p>Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang, Xiaodong Deng, Yang Fan, Wenbin Ge, Yu Han, Fei Huang, arXiv:2309.16609Qwen technical report. 2023. 2023arXiv preprint</p>
<p>The Coq proof assistant reference manual: Version 6.1. Bruno Barras, Samuel Boutin, Cristina Cornes, Judicaël Courant, Jean-Christophe Filliatre, Eduardo Gimenez, Hugo Herbelin, Gerard Huet, Cesar Munoz, Chetan Murthy, 1997Ph. D. Dissertation. Inria</p>
<p>Graph of thoughts: Solving elaborate problems with large language models. Maciej Besta, Nils Blach, Ales Kubicek, Robert Gerstenberger, Lukas Gianinazzi, Joanna Gajda, Tomasz Lehmann, Michal Podstawski, Hubert Niewiadomski, Piotr Nyczyk, arXiv:2308.096872023. 2023arXiv preprint</p>
<p>Improving language models by retrieving from trillions of tokens. Sebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor Cai, Eliza Rutherford, Katie Millican, George Bm Van Den Driessche, Jean-Baptiste Lespiau, Bogdan Damoc, Aidan Clark, International conference on machine learning. PMLR2022</p>
<p>James Boyko, Joseph Cohen, Nathan Fox, Maria Han Veiga, Jennifer I Li, Jing Liu, Bernardo Modenesi, Andreas H Rauch, Kenneth N Reid, Soumi Tribedi, arXiv:2311.04929An Interdisciplinary Outlook on Large Language Models for Scientific Research. 2023. 2023arXiv preprint</p>
<p>Yupeng Chang, Xu Wang, Jindong Wang, Yuan Wu, Kaijie Zhu, Hao Chen, Linyi Yang, Xiaoyuan Yi, Cunxiang Wang, Yidong Wang, arXiv:2307.03109A survey on evaluation of large language models. 2023. 2023arXiv preprint</p>
<p>Bei Chen, Fengji Zhang, Anh Nguyen, Daoguang Zan, Zeqi Lin, Jian-Guang Lou, Weizhu Chen, arXiv:2207.10397[cs.CL]CodeT: Code Generation with Generated Tests. 2022</p>
<p>Jiaqi Chen, Tong Li, Jinghui Qin, Pan Lu, Liang Lin, Chongyu Chen, Xiaodan Liang, arXiv:2212.02746UniGeo: Unifying Geometry Logical Reasoning via Reformulating Mathematical Expression. 2022. 2022arXiv preprint</p>
<p>. Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde De Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet ; Igor Babuschkin, Suchir Balaji, Shantanu Jain, William Saunders, Christopher Hesse, arXiv:2107.03374[cs.LG]Felipe Petroski Such. Josh Achiam, Vedant Misra, Evan Morikawa, Alec RadfordJan LeikeIlya Sutskever, and Wojciech Zaremba. 2021. Evaluating Large Language Models Trained on Code</p>
<p>. Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde De Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet ; Igor Babuschkin, Suchir Balaji, Shantanu Jain, William Saunders, Christopher Hesse, arXiv:2107.03374[cs.LG]Felipe Petroski Such. Josh Achiam, Vedant Misra, Evan Morikawa, Alec RadfordJan LeikeIlya Sutskever, and Wojciech Zaremba. 2021. Evaluating Large Language Models Trained on Code</p>
<p>Boosting of thoughts: Trial-and-error problem solving with large language models. Sijia Chen, Baochun Li, Di Niu, arXiv:2402.111402024. 2024arXiv preprint</p>
<p>Set-to-sequence ranking-based concept-aware learning path recommendation. Xianyu Chen, Jian Shen, Wei Xia, Jiarui Jin, Yakun Song, Weinan Zhang, Weiwen Liu, Menghui Zhu, Ruiming Tang, Kai Dong, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202337</p>
<p>Stephen Choi, William Gazeley, Siu Ho Wong, Tingting Li, arXiv:2310.13001[cs.IR]Conversational Financial Information Retrieval Model (ConFIRM). 2023</p>
<p>Knowledge tracing: Modeling the acquisition of procedural knowledge. T Albert, John R Corbett, Anderson, User modeling and user-adapted interaction. 41994. 1994</p>
<p>Garett Cunningham, Razvan C Bunescu, David Juedes, arXiv:2301.02195Towards Autoformalization of Mathematics and Code Correctness: Experiments with Elementary Proofs. 2023. 2023arXiv preprint</p>
<p>The Lean theorem prover (system description). Leonardo De Moura, Soonho Kong, Jeremy Avigad, Floris Van Doorn, Jakob Von Raumer, Automated Deduction-CADE-25: 25th International Conference on Automated Deduction. Berlin, GermanySpringer2015. August 1-7, 201525</p>
<p>Active prompting with chain-of-thought for large language models. Shizhe Diao, Pengcheng Wang, Yong Lin, Tong Zhang, arXiv:2302.122462023. 2023arXiv preprint</p>
<p>Yangruibo Ding, Zijian Wang, Uddin Wasi, Hantian Ahmad, Ming Ding, Nihal Tan, Jain, Krishna Murali, Ramesh Ramanathan, Parminder Nallapati, Dan Bhatia, Bing Roth, Xiang, arXiv:2310.11248[cs.LG]CrossCodeEval: A Diverse and Multilingual Benchmark for Cross-File Code Completion. 2023</p>
<p>A Survey of Natural Language Generation. Chenhe Dong, Yinghui Li, Haifan Gong, Miaoxin Chen, Junxin Li, Ying Shen, Min Yang, 10.1145/3554727ACM Comput. Surv. 551732022. dec 2022</p>
<p>A survey of vision-language pre-trained models. Yifan Du, Zikang Liu, Junyi Li, Wayne Xin Zhao, arXiv:2202.109362022. 2022arXiv preprint</p>
<p>GrammarGPT: Exploring Open-Source LLMs for Native Chinese Grammatical Error Correction with Supervised Fine-Tuning. Yaxin Fan, Feng Jiang, Peifeng Li, Haizhou Li, CCF International Conference on Natural Language Processing and Chinese Computing. Springer2023</p>
<p>Is chatgpt a highly fluent grammatical error correction system?. Tao Fang, Shu Yang, Kaixin Lan, Derek F Wong, Jinpeng Hu, Lidia S Chao, Yue Zhang, arXiv:2304.01746a comprehensive evaluation. 2023. 2023arXiv preprint</p>
<p>Improving Factual Consistency of Text Summarization by Adversarially Decoupling Comprehension and Embellishment Abilities of LLMs. Huawen Feng, Yan Fan, Xiong Liu, Ting-En Lin, Zekun Yao, Yuchuan Wu, Fei Huang, Yongbin Li, Qianli Ma, arXiv:2310.193472023. 2023arXiv preprint</p>
<p>From pretraining data to language models to downstream tasks: Tracking the trails of political biases leading to unfair NLP models. Shangbin Feng, Chan Young Park, Yuhan Liu, Yulia Tsvetkov, arXiv:2305.082832023. 2023arXiv preprint</p>
<p>Daniel Fried, Armen Aghajanyan, Jessy Lin, Sida Wang, Eric Wallace, Freda Shi, Ruiqi Zhong, Wen Tau Yih, Luke Zettlemoyer, Mike Lewis, arXiv:2204.05999[cs.SE]InCoder: A Generative Model for Code Infilling and Synthesis. 2023</p>
<p>Lingyue Fu, Huacan Chai, Shuang Luo, Kounianhua Du, Weiming Zhang, Longteng Fan, Jiayi Lei, Renting Rui, Jianghao Lin, Yuchen Fang, Yifan Liu, Jingkuan Wang, Siyuan Qi, Kangning Zhang, Weinan Zhang, Yong Yu, arXiv:2309.01940[cs.CL]CodeApex: A Bilingual Programming Evaluation Benchmark for Large Language Models. 2023</p>
<p>Large language models in education: Vision and opportunities. Wensheng Gan, Zhenlian Qi, Jiayang Wu, Jerry Chun, -Wei Lin, arXiv:2311.131602023. 2023arXiv preprint</p>
<p>G-llava: Solving geometric problem with multi-modal large language model. Jiahui Gao, Renjie Pi, Jipeng Zhang, Jiacheng Ye, Wanjun Zhong, Yufei Wang, Lanqing Hong, Jianhua Han, Hang Xu, Zhenguo Li, arXiv:2312.113702023. 2023arXiv preprint</p>
<p>Injecting numerical reasoning skills into language models. Mor Geva, Ankit Gupta, Jonathan Berant, arXiv:2004.044872020. 2020arXiv preprint</p>
<p>Aritra Ghosh, Andrew Lan, arXiv:2108.07386Bobcat: Bilevel optimization-based computerized adaptive testing. 2021. 2021arXiv preprint</p>
<p>Attentional graph convolutional networks for knowledge concept recommendation in moocs in a heterogeneous view. Jibing Gong, Shen Wang, Jinlong Wang, Wenzheng Feng, Hao Peng, Jie Tang, Philip S Yu, Proceedings of the 43rd international ACM SIGIR conference on research and development in information retrieval. the 43rd international ACM SIGIR conference on research and development in information retrieval2020</p>
<p>Tora: A tool-integrated reasoning agent for mathematical problem solving. Zhibin Gou, Zhihong Shao, Yeyun Gong, Yujiu Yang, Minlie Huang, Nan Duan, Weizhu Chen, arXiv:2309.174522023. 2023arXiv preprint</p>
<p>Grammarly, Grammarly. 2023</p>
<p>KNN model-based approach in classification. Gongde Guo, Hui Wang, David Bell, Yaxin Bi, Kieran Greer, On The Move to Meaningful Internet Systems 2003: CoopIS, DOA, and ODBASE: OTM Confederated International Conferences, CoopIS, DOA, and ODBASE 2003. Catania, Sicily, ItalySpringer2003. November 3-7, 2003</p>
<p>Retrieval augmented language model pre-training. Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, Mingwei Chang, International conference on machine learning. PMLR2020</p>
<p>Namgyu Ho, Laura Schmid, Se-Young Yun, arXiv:2212.10071Large language models are reasoning teachers. 2022. 2022arXiv preprint</p>
<p>Sirui Hong, Xiawu Zheng, Jonathan Chen, Yuheng Cheng, Jinlin Wang, Ceyao Zhang, Zili Wang, Steven Ka, Shing Yau, Zijuan Lin, Liyang Zhou, arXiv:2308.00352Metagpt: Meta programming for multi-agent collaborative framework. 2023. 2023arXiv preprint</p>
<p>J Edward, Yelong Hu, Phillip Shen, Zeyuan Wallis, Yuanzhi Allen-Zhu, Shean Li, Lu Wang, Weizhu Wang, Chen, arXiv:2106.09685Lora: Low-rank adaptation of large language models. 2021. 2021arXiv preprint</p>
<p>Large language models can self-improve. Jiaxin Huang, Shixiang Shane Gu, Le Hou, Yuexin Wu, Xuezhi Wang, Hongkun Yu, Jiawei Han, arXiv:2210.116102022. 2022arXiv preprint</p>
<p>InPars-v2: Large Language Models as Efficient Dataset Generators for Information Retrieval. Vitor Jeronymo, Luiz Bonifacio, Hugo Abonizio, Marzieh Fadaee, Roberto Lotufo, Jakub Zavrel, Rodrigo Nogueira, arXiv:2301.01820[cs.IR]2023</p>
<p>Wenda Albert Q Jiang, Mateja Li, Jamnik, arXiv:2311.03755Multilingual Mathematical Autoformalization. 2023. 2023arXiv preprint</p>
<p>Thor: Wielding hammers to integrate language models and automated theorem provers. Albert Qiaochu Jiang, Wenda Li, Szymon Tworkowski, Konrad Czechowski, Tomasz Odrzygóźdź, Piotr Miłoś, Yuhuai Wu, Mateja Jamnik, Advances in Neural Information Processing Systems. 352022. 2022</p>
<p>Draft, sketch, and prove: Guiding formal theorem provers with informal proofs. Sean Albert Q Jiang, Jin Peng Welleck, Wenda Zhou, Jiacheng Li, Mateja Liu, Timothée Jamnik, Yuhuai Lacroix, Guillaume Wu, Lample, arXiv:2210.122832022. 2022arXiv preprint</p>
<p>Hang Jiang, Doug Beeferman, Brandon Roy, Deb Roy, arXiv:2209.07065CommunityLM: Probing partisan worldviews from language models. 2022. 2022arXiv preprint</p>
<p>How can we know when language models know? on the calibration of language models for question answering. Zhengbao Jiang, Jun Araki, Haibo Ding, Graham Neubig, Transactions of the Association for Computational Linguistics. 92021. 2021</p>
<p>RealTime QA: What's the Answer Right Now?. Jungo Kasai, Keisuke Sakaguchi, Ronan Le Bras, Akari Asai, Xinyan Yu, Dragomir Radev, Noah A Smith, Yejin Choi, Kentaro Inui, Advances in Neural Information Processing Systems. 362024. 2024</p>
<p>ChatGPT for good? On opportunities and challenges of large language models for education. Enkelejda Kasneci, Kathrin Seßler, Stefan Küchemann, Maria Bannert, Daryna Dementieva, Frank Fischer, Urs Gasser, Georg Groh, Stephan Günnemann, Eyke Hüllermeier, Learning and individual differences. 1031022742023. 2023</p>
<p>How Novices Use LLM-based Code Generators to Solve CS1 Coding Tasks in a Self-Paced Learning Environment. Majeed Kazemitabaar, Xinying Hou, Austin Henley, Barbara Jane Ericson, David Weintrop, Tovi Grossman, 10.1145/3631802.3631806Proceedings of the 23rd Koli Calling International Conference on Computing Education Research (<conf-loc>. the 23rd Koli Calling International Conference on Computing Education Research (<conf-loc>New York, NY, USAAssociation for Computing Machinery2024Koli Calling '23). Article 3, 12 pages</p>
<p>Urvashi Khandelwal, Omer Levy, Dan Jurafsky, Luke Zettlemoyer, Mike Lewis, arXiv:1911.00172Generalization through memorization: Nearest neighbor language models. 2019. 2019arXiv preprint</p>
<p>Internet-augmented language models through few-shot prompting for open-domain question answering. Angeliki Lazaridou, Elena Gribovskaya, Wojciech Stokowiec, Nikolai Grigorev, arXiv:2203.051152022. 2022arXiv preprint</p>
<p>Teaching arithmetic to small transformers. Nayoung Lee, Kartik Sreenivasan, Jason D Lee, Kangwook Lee, Dimitris Papailiopoulos, arXiv:2307.033812023. 2023arXiv preprint</p>
<p>Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Ves Stoyanov, Luke Zettlemoyer, arXiv:1910.134612019. 2019BartarXiv preprint</p>
<p>Solving quantitative reasoning problems with language models. Aitor Lewkowycz, Anders Andreassen, David Dohan, Ethan Dyer, Henryk Michalewski, Vinay Ramasesh, Ambrose Slone, Cem Anil, Imanol Schlag, Theo Gutman-Solo, 2022. 2022. 2022</p>
<p>Large language model-empowered agents for simulating macroeconomic activities. Nian Li, Chen Gao, Yong Li, Qingmin Liao, arXiv:2310.104362023. 2023arXiv preprint</p>
<p>Graph Enhanced Hierarchical Reinforcement Learning for Goal-oriented Learning Path Recommendation. Qingyao Li, Wei Xia, Jian Li'ang Yin, Renting Shen, Weinan Rui, Xianyu Zhang, Ruiming Chen, Yong Tang, Yu, Proceedings of the 32nd ACM International Conference on Information and Knowledge Management. the 32nd ACM International Conference on Information and Knowledge Management2023</p>
<p>Percy Liang, Rishi Bommasani, Tony Lee, Dimitris Tsipras, Dilara Soylu, Michihiro Yasunaga, Yian Zhang, Deepak Narayanan, Yuhuai Wu, Ananya Kumar, arXiv:2211.09110Holistic evaluation of language models. 2022. 2022arXiv preprint</p>
<p>Rouge: A package for automatic evaluation of summaries. Chin-Yew Lin, Text summarization branches out. 2004</p>
<p>Jianghao Lin, Xinyi Dai, Yunjia Xi, Weiwen Liu, Bo Chen, Xiangyang Li, Chenxu Zhu, Huifeng Guo, Yong Yu, Ruiming Tang, arXiv:2306.05817How Can Recommender Systems Benefit from Large Language Models: A Survey. 2023. 2023arXiv preprint</p>
<p>Stephanie Lin, Jacob Hilton, Owain Evans, arXiv:2109.07958Truthfulqa: Measuring how models mimic human falsehoods. 2021. 2021arXiv preprint</p>
<p>Bingchang Liu, Chaoyu Chen, Cong Liao, Zi Gong, Huan Wang, Zhichao Lei, Ming Liang, Dajun Chen, Min Shen, Hailian Zhou, Hang Yu, Jianguo Li, arXiv:2311.02303[cs.LG]MFTCoder: Boosting Code LLMs with Multitask Fine-Tuning. 2023</p>
<p>Chengwu Liu, Jianhao Shen, Huajian Xin, Zhengying Liu, Ye Yuan, Haiming Wang, Wei Ju, Chuanyang Zheng, Yichun Yin, Lin Li, arXiv:2309.04295Fimo: A challenge formal dataset for automated theorem proving. 2023. 2023arXiv preprint</p>
<p>Jiongnan Liu, Jiajie Jin, Zihan Wang, Jiehan Cheng, Zhicheng Dou, Ji-Rong Wen, arXiv:2306.05212[cs.IR]RETA-LLM: A Retrieval-Augmented Large Language Model Toolkit. 2023</p>
<p>Qilin-Med-VL: Towards Chinese Large Vision-Language Model for General Healthcare. Junling Liu, Ziming Wang, Qichen Ye, Dading Chong, Peilin Zhou, Yining Hua, arXiv:2310.179562023. 2023arXiv preprint</p>
<p>Goat: Fine-tuned LLaMA Outperforms GPT-4 on Arithmetic Tasks. Tiedong Liu, Bryan Kian, Hsiang Low, arXiv:2305.142012023. 2023arXiv preprint</p>
<p>On improving summarization factual consistency from natural language feedback. Yixin Liu, Budhaditya Deb, Milagro Teruel, Aaron Halfaker, Dragomir Radev, Ahmed H Awadallah, arXiv:2212.099682022. 2022arXiv preprint</p>
<p>Benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization. Yixin Liu, Jiawen Alexander R Fabbri, Yilun Chen, Simeng Zhao, Shafiq Han, Pengfei Joty, Dragomir Liu, Chien-Sheng Radev, Arman Wu, Cohan, arXiv:2311.091842023. 2023arXiv preprint</p>
<p>Yixin Liu, Pengfei Alexander R Fabbri, Dragomir Liu, Arman Radev, Cohan, arXiv:2305.14239On Learning to Summarize with Large Language Models as References. 2023. 2023arXiv preprint</p>
<p>Yixin Liu, Pengfei Liu, Dragomir Radev, Graham Neubig, arXiv:2203.16804BRIO: Bringing order to abstractive summarization. 2022. 2022arXiv preprint</p>
<p>Fully Autonomous Programming with Large Language Models. Vadim Liventsev, Anastasiia Grishina, Aki Härmä, Leon Moonen, 10.1145/3583131.3590481Proceedings of the Genetic and Evolutionary Computation Conference. the Genetic and Evolutionary Computation ConferenceACM2023</p>
<p>Pan Lu, Hritik Bansal, Tony Xia, Jiacheng Liu, Chunyuan Li, Hannaneh Hajishirzi, Hao Cheng, Kai-Wei Chang, Michel Galley, Jianfeng Gao, arXiv:2310.02255MathVista: Evaluating Mathematical Reasoning of Foundation Models in Visual Contexts. 2023. 2023arXiv preprint</p>
<p>Dynamic prompt learning via policy gradient for semi-structured mathematical reasoning. Pan Lu, Liang Qiu, Kai-Wei Chang, Ying Nian Wu, Song-Chun Zhu, Tanmay Rajpurohit, Peter Clark, Ashwin Kalyan, arXiv:2209.146102022. 2022arXiv preprint</p>
<p>A survey of deep learning for mathematical reasoning. Pan Lu, Liang Qiu, Wenhao Yu, Sean Welleck, Kai-Wei Chang, arXiv:2212.105352022. 2022arXiv preprint</p>
<p>Haipeng Luo, Qingfeng Sun, Can Xu, Pu Zhao, Jianguang Lou, Chongyang Tao, Xiubo Geng, Qingwei Lin, Shifeng Chen, Dongmei Zhang, arXiv:2308.09583Wizardmath: Empowering mathematical reasoning for large language models via reinforced evol-instruct. 2023. 2023arXiv preprint</p>
<p>Ziyang Luo, Can Xu, Pu Zhao, Qingfeng Sun, Xiubo Geng, Wenxiang Hu, Chongyang Tao, Jing Ma, Qingwei Lin, Daxin Jiang, arXiv:2306.08568[cs.CL]WizardCoder: Empowering Code Large Language Models with Evol-Instruct. 2023</p>
<p>Qianou Ma, Hua Shen, Kenneth Koedinger, Tongshuang Wu, arXiv:2310.05292[cs.HC]HypoCompass: Large-Language-Model-based Tutor for Hypothesis Construction in Debugging for Novices. 2023</p>
<p>Xinbei Ma, Yeyun Gong, Pengcheng He, Hai Zhao, Nan Duan, arXiv:2305.06647PROM: A Phrase-level Copying Mechanism with Pre-training for Abstractive Summarization. 2023. 2023arXiv preprint</p>
<p>Teaching small language models to reason. Lucie Charlotte Magister, Jonathan Mallinson, Jakub Adamek, Eric Malmi, Aliaksei Severyn, arXiv:2212.084102022. 2022arXiv preprint</p>
<p>Brandon Mckinzie, Zhe Gan, Jean-Philippe Fauconnier, Sam Dodge, Bowen Zhang, Philipp Dufter, Dhruti Shah, Xianzhi Du, Futang Peng, Floris Weers, arXiv:2403.09611MM1: Methods, Analysis &amp; Insights from Multimodal LLM Pre-training. 2024. 2024arXiv preprint</p>
<p>Computerized adaptive testing: Overview and introduction. R Rob, Michael L Meijer, Nering, Applied psychological measurement. 231999. 1999</p>
<p>ChatGPT and large language models in academia: opportunities and challenges. Jesse G Meyer, Ryan J Urbanowicz, Karen O' Patrick Cn Martin, Ruowang Connor, Pei-Chen Li, Tiffani J Peng, Nicholas Bright, Tatonetti, Jae Kyoung, Graciela Won, Gonzalez-Hernandez, BioData Mining. 16202023. 2023</p>
<p>ChatGPT Evaluation: Can It Replace Grammarly and Quillbot Tools?. Osamah Mohammed, Mueen Thaeer, Sahib, M Israa, Sani Hayder, Misbah Salisu, Shahid, British Journal of Applied Linguistics. 32023. 2023</p>
<p>Erik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu, Huan Wang, Yingbo Zhou, Silvio Savarese, Caiming Xiong, arXiv:2203.13474[cs.LG]CodeGen: An Open Large Language Model for Code with Multi-Turn Program Synthesis. 2023</p>
<p>Isabelle/HOL: a proof assistant for higher-order logic. Tobias Nipkow, Markus Wenzel, Lawrence C Paulson, 2002Springer</p>
<p>Maxwell Nye, Anders Johan Andreassen, Guy Gur-Ari, Henryk Michalewski, Jacob Austin, David Bieber, David Dohan, Aitor Lewkowycz, Maarten Bosma, David Luan, arXiv:2112.00114Show your work: Scratchpads for intermediate computation with language models. 2021. 2021arXiv preprint</p>
<p>Kostiantyn Omelianchuk, Vitaliy Atrasevych, Artem Chernodub, Oleksandr Skurzhanskyi, arXiv:2005.12592GECToR-grammatical error correction: tag, not rewrite. 2020. 2020arXiv preprint</p>
<p>Training language models to follow instructions with human feedback. Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, Advances in neural information processing systems. 352022. 2022</p>
<p>Arkil Patel, Satwik Bhattamishra, Navin Goyal, arXiv:2103.07191Are NLP models really able to solve simple math word problems?. 2021. 2021arXiv preprint</p>
<p>Ruoling Peng, Kang Liu, Po Yang, Zhipeng Yuan, Shunbao Li, arXiv:2308.03107[cs.AI]Embedding-based Retrieval with LLM for Effective Agriculture Information Extracting from Unstructured Data. 2023</p>
<p>GeoDRL: A Self-Learning Framework for Geometry Problem Solving using Reinforcement Learning in Deductive Reasoning. Shuai Peng, Di Fu, Yijun Liang, Liangcai Gao, Zhi Tang, Findings of the Association for Computational Linguistics: ACL 2023. 2023</p>
<p>Tung Phung, Victor-Alexandru Pădurean, José Cambronero, Sumit Gulwani, Tobias Kohn, Rupak Majumdar, Adish Singla, Gustavo Soares, arXiv:2306.17156[cs.CY]Generative AI for Programming Education: Benchmarking ChatGPT, GPT-4, and Human Tutors. 2023</p>
<p>Chris Piech, Jonathan Bassen, Jonathan Huang, Surya Ganguli, Mehran Sahami, Leonidas J Guibas, Jascha Sohl-Dickstein, Deep knowledge tracing. 2015. 201528</p>
<p>Generative language modeling for automated theorem proving. Stanislas Polu, Ilya Sutskever, arXiv:2009.033932020. 2020arXiv preprint</p>
<p>Xiao Pu, Mingqi Gao, Xiaojun Wan, arXiv:2309.09558Summarization is (almost) dead. 2023. 2023arXiv preprint</p>
<p>Chen Qian, Xin Cong, Cheng Yang, Weize Chen, Yusheng Su, Juyuan Xu, Zhiyuan Liu, Maosong Sun, arXiv:2307.07924Communicative agents for software development. 2023. 2023arXiv preprint</p>
<p>Exploring the limits of transfer learning with a unified text-to-text transformer. Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, Peter J Liu, The Journal of Machine Learning Research. 2112020. 2020</p>
<p>Dhruv Vipul Raheja, Ryan Kumar, Dongyeop Koo, Kang, arXiv:2305.09857CoEdIT: Text Editing by Task-Specific Instruction Tuning. 2023. 2023arXiv preprint</p>
<p>Explain yourself! leveraging language models for commonsense reasoning. Nazneen Fatema Rajani, Bryan Mccann, Caiming Xiong, Richard Socher, arXiv:1906.023612019. 2019arXiv preprint</p>
<p>Investigating the Factual Knowledge Boundary of Large Language Models with Retrieval Augmentation. Ruiyang Ren, Yuhao Wang, Yingqi Qu, Wayne Xin Zhao, Jing Liu, Hua Hao Tian, Ji-Rong Wu, Haifeng Wen, Wang, arXiv:2307.11019[cs.CL]2023</p>
<p>Jonas Baptiste Roziere, Fabian Gehring, Sten Gloeckle, Itai Sootla, Gat, Ellen Xiaoqing, Yossi Tan, Jingyu Adi, Tal Liu, Jérémy Remez, Rapin, arXiv:2308.12950Code llama: Open foundation models for code. 2023. 2023arXiv preprint</p>
<p>Jonas Baptiste Rozière, Fabian Gehring, Sten Gloeckle, Itai Sootla, Gat, Ellen Xiaoqing, Yossi Tan, Jingyu Adi, Tal Liu, Jérémy Remez, Artyom Rapin, Ivan Kozhevnikov, Joanna Evtimov, Manish Bitton, Cristian Canton Bhatt, Aaron Ferrer, Wenhan Grattafiori, Alexandre Xiong, Jade Défossez, Faisal Copet, Hugo Azhar, Louis Touvron, Martin, arXiv:2308.12950[cs.CL]Nicolas Usunier, Thomas Scialom, and Gabriel Synnaeve. 2023. Code Llama: Open Foundation Models for Code. </p>
<p>Large language models are not zero-shot communicators. Laura Ruis, Akbir Khan, Stella Biderman, Sara Hooker, Tim Rocktäschel, Edward Grefenstette, arXiv:2210.149862022. 2022arXiv preprint</p>
<p>Tomohiro Sawada, Daniel Paleka, Alexander Havrilla, Pranav Tadepalli, Paula Vidas, Alexander Kranias, John J Nay, Kshitij Gupta, Aran Komatsuzaki, arXiv:2307.13692Arb: Advanced reasoning benchmark for large language models. 2023. 2023arXiv preprint</p>
<p>Toolformer: Language models can teach themselves to use tools. Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu, Maria Lomeli, Eric Hambro, Luke Zettlemoyer, Nicola Cancedda, Thomas Scialom, Advances in Neural Information Processing Systems. 362024. 2024</p>
<p>Large language models are not yet human-level evaluators for abstractive summarization. Chenhui Shen, Liying Cheng, Xuan-Phi Nguyen, Yang You, Lidong Bing, Findings of the Association for Computational Linguistics: EMNLP 2023. 2023</p>
<p>Fundamentals of recurrent neural network (RNN) and long short-term memory (LSTM) network. Alex Sherstinsky, Physica D: Nonlinear Phenomena. 4041323062020. 2020</p>
<p>Reflexion: Language agents with verbal reinforcement learning. Noah Shinn, Federico Cassano, Ashwin Gopinath, Karthik Narasimhan, Shunyu Yao, Advances in Neural Information Processing Systems. 362024. 2024</p>
<p>An analysis of the automatic bug fixing performance of chatgpt. Dominik Sobania, Martin Briesch, Carol Hanna, Justyna Petke, IEEE/ACM International Workshop on Automated Program Repair. 2023. 2023. APRIEEE</p>
<p>Learning to summarize with human feedback. Nisan Stiennon, Long Ouyang, Jeffrey Wu, Daniel Ziegler, Ryan Lowe, Chelsea Voss, Alec Radford, Dario Amodei, Paul F Christiano, Advances in Neural Information Processing Systems. 332020. 2020</p>
<p>Commonsenseqa: A question answering challenge targeting commonsense knowledge. Alon Talmor, Jonathan Herzig, Nicholas Lourie, Jonathan Berant, arXiv:1811.009372018. 2018arXiv preprint</p>
<p>. Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, Tatsunori B Hashimoto, 2023</p>
<p>. Thevicunateam, 2023</p>
<p>A framework for the development of computerized adaptive tests. A Nathan, David A Thompson, Weiss, Practical Assessment, Research, and Evaluation. 1612019. 2019</p>
<p>Tigerresearch, Tigerbot. 2023</p>
<p>Thibaut Hugo Touvron, Gautier Lavril, Xavier Izacard, Marie-Anne Martinet, Timothée Lachaux, Baptiste Lacroix, Naman Rozière, Eric Goyal, Faisal Hambro, Azhar, arXiv:2302.13971Llama: Open and efficient foundation language models. 2023. 2023arXiv preprint</p>
<p>Llama 2: Open foundation and fine-tuned chat models. Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, arXiv:2307.092882023. 2023arXiv preprint</p>
<p>Large Language Models Still Can't Plan (A Benchmark for LLMs on Planning and Reasoning about Change). Karthik Valmeekam, Alberto Olmo, Sarath Sreedharan, Subbarao Kambhampati, arXiv:2206.104982022. 2022arXiv preprint</p>
<p>Tu Vu, Mohit Iyyer, Xuezhi Wang, Noah Constant, Jerry Wei, Jason Wei, Chris Tar, Yun-Hsuan Sung, Denny Zhou, Quoc Le, arXiv:2310.03214Freshllms: Refreshing large language models with search engine augmentation. 2023. 2023arXiv preprint</p>
<p>E Rose, Dorottya Wang, Demszky, arXiv:2306.03090Is ChatGPT a Good Teacher Coach? Measuring Zero-Shot Performance For Scoring and Providing Actionable Insights on Classroom Instruction. 2023. 2023arXiv preprint</p>
<p>Shen Wang, Tianlong Xu, Hang Li, Chaoli Zhang, Joleen Liang, Jiliang Tang, Philip S Yu, Qingsong Wen, arXiv:2403.18105Large Language Models for Education: A Survey and Outlook. 2024. 2024arXiv preprint</p>
<p>Scibench: Evaluating college-level scientific problem-solving abilities of large language models. Xiaoxuan Wang, Ziniu Hu, Pan Lu, Yanqiao Zhu, Jieyu Zhang, Satyen Subramaniam, Shichang Arjun R Loomba, Yizhou Zhang, Wei Sun, Wang, arXiv:2307.106352023. 2023arXiv preprint</p>
<p>Self-consistency improves chain of thought reasoning in language models. Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdhery, Denny Zhou, arXiv:2203.111712022. 2022arXiv preprint</p>
<p>Yue Wang, Hung Le, Akhilesh Deepak Gotmare, D Q Nghi, Junnan Bui, Steven C H Li, Hoi, arXiv:2305.07922[cs.CL]CodeT5+: Open Code Large Language Models for Code Understanding and Generation. 2023</p>
<p>Deep neural solver for math word problems. Yan Wang, Xiaojiang Liu, Shuming Shi, Proceedings of the 2017 conference on empirical methods in natural language processing. the 2017 conference on empirical methods in natural language processing2017</p>
<p>Chain-of-thought prompting elicits reasoning in large language models. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Denny Quoc V Le, Zhou, Advances in Neural Information Processing Systems. 352022. 2022</p>
<p>Haoran Wu, Wenxuan Wang, Yuxuan Wan, Wenxiang Jiao, Michael Lyu, arXiv:2303.13648Chatgpt or grammarly? evaluating chatgpt on grammatical error correction benchmark. 2023. 2023arXiv preprint</p>
<p>Autoformalization with large language models. Yuhuai Wu, Albert Qiaochu Jiang, Wenda Li, Markus Rabe, Charles Staats, Mateja Jamnik, Christian Szegedy, Advances in Neural Information Processing Systems. 352022. 2022</p>
<p>Chunqiu Steven, Xia , Lingming Zhang, arXiv:2301.13246Conversational automated program repair. 2023. 2023arXiv preprint</p>
<p>Huajian Xin, Haiming Wang, Chuanyang Zheng, Lin Li, Zhengying Liu, Qingxing Cao, Yinya Huang, Jing Xiong, Han Shi, Enze Xie, arXiv:2310.00656LEGO-Prover: Neural Theorem Proving with Growing Libraries. 2023. 2023arXiv preprint</p>
<p>Jing Xiong, Jianhao Shen, Ye Yuan, Haiming Wang, Yichun Yin, Zhengying Liu, Lin Li, Zhijiang Guo, Qingxing Cao, Yinya Huang, arXiv:2310.10180TRIGO: Benchmarking Formal Mathematical Proof Reduction for Generative Language Models. 2023. 2023arXiv preprint</p>
<p>Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng, Pu Zhao, Jiazhan Feng, Chongyang Tao, Daxin Jiang, arXiv:2304.12244[cs.CL]WizardLM: Empowering Large Language Models to Follow Complex Instructions. 2023</p>
<p>Hallucination is inevitable: An innate limitation of large language models. Ziwei Xu, Sanjay Jain, Mohan Kankanhalli, arXiv:2401.118172024. 2024arXiv preprint</p>
<p>Aiyuan Yang, Bin Xiao, Bingning Wang, Borong Zhang, Chao Yin, Chenxu Lv, Dian Da Pan, Dong Wang, Fan Yan, Yang, arXiv:2309.10305Open large-scale language models. 2023. 20232arXiv preprint</p>
<p>Kaiyu Yang, Aidan M Swope, Alex Gu, Rahul Chalamala, Peiyang Song, Shixing Yu, Saad Godil, Ryan Prenger, Anima Anandkumar, arXiv:2306.15626Leandojo: Theorem proving with retrieval-augmented language models. 2023. 2023arXiv preprint</p>
<p>Zhen Yang, Ming Ding, Qingsong Lv, Zhihuan Jiang, Zehai He, Yuyi Guo, Jinfeng Bai, Jie Tang, arXiv:2309.03241GPT Can Solve Mathematical Problems Without a Calculator. 2023. 2023arXiv preprint</p>
<p>Tree of thoughts: Deliberate problem solving with large language models. Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Tom Griffiths, Yuan Cao, Karthik Narasimhan, Advances in Neural Information Processing Systems. 362024. 2024</p>
<p>QA-GNN: Reasoning with language models and knowledge graphs for question answering. Michihiro Yasunaga, Hongyu Ren, Antoine Bosselut, Percy Liang, Jure Leskovec, arXiv:2104.063782021. 2021arXiv preprint</p>
<p>Qinghao Ye, Haiyang Xu, Jiabo Ye, Ming Yan, Haowei Liu, Qi Qian, Ji Zhang, Fei Huang, Jingren Zhou, arXiv:2311.04257mPLUG-Owl2: Revolutionizing Multi-modal Large Language Model with Modality Collaboration. 2023. 2023arXiv preprint</p>
<p>Longhui Yu, Weisen Jiang, Han Shi, Jincheng Yu, Zhengying Liu, Yu Zhang, James T Kwok, Zhenguo Li, Adrian Weller, Weiyang Liu, arXiv:2309.12284Metamath: Bootstrap your own mathematical questions for large language models. 2023. 2023arXiv preprint</p>
<p>How well do Large Language Models perform in Arithmetic tasks?. Zheng Yuan, Hongyi Yuan, Chuanqi Tan, Wei Wang, Songfang Huang, arXiv:2304.020152023. 2023arXiv preprint</p>
<p>Eric Zelikman, Yuhuai Wu, Jesse Mu, Noah D Goodman, Star: Bootstrapping reasoning with reasoning. 2022. 2022. 2022</p>
<p>Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang, Hanyu Lai, Ming Ding, Zhuoyi Yang, Yifan Xu, Wendi Zheng, Xiao Xia, arXiv:2210.02414Glm-130b: An open bilingual pre-trained model. 2022. 2022arXiv preprint</p>
<p>Beichen Zhang, Kun Zhou, Xilin Wei, Wayne Xin Zhao, Jing Sha, Shijin Wang, Ji-Rong Wen, arXiv:2306.02408Evaluating and Improving Tool-Augmented Computation-Intensive Math Reasoning. 2023. 2023arXiv preprint</p>
<p>Jiaxin Zhang, Zhongzhi Li, Mingliang Zhang, Fei Yin, Chenglin Liu, Yashar Moshfeghi, arXiv:2402.10104GeoEval: Benchmark for Evaluating LLMs and Multi-Modal Models on Geometry Problem-Solving. 2024. 2024arXiv preprint</p>
<p>A Multi-Modal Neural Geometric Solver with Textual Clauses Parsed from Diagram. Ming-Liang Zhang, Fei Yin, Cheng-Lin Liu, arXiv:2302.110972023. 2023arXiv preprint</p>
<p>Peitian Zhang, Shitao Xiao, Zheng Liu, Zhicheng Dou, Jian-Yun Nie, arXiv:2310.07554[cs.IR]Retrieve Anything To Augment Large Language Models. 2023</p>
<p>Planning with large language models for code generation. Shun Zhang, Zhenfang Chen, Yikang Shen, Mingyu Ding, Joshua B Tenenbaum, Chuang Gan, arXiv:2303.055102023. 2023arXiv preprint</p>
<p>Cash transaction booking via retrieval augmented LLM. Sabrina Zhang, Daksha Yadav, Tom Jin, KDD 2023 Workshop on Robust NLP for Finance (RobustFin). 2023</p>
<p>Solving challenging math word problems using gpt-4 code interpreter with code-based self-verification. Aojun Zhou, Ke Wang, Zimu Lu, Weikang Shi, Sichun Luo, Zipeng Qin, Shaoqing Lu, Anya Jia, Linqi Song, Mingjie Zhan, arXiv:2308.079212023. 2023arXiv preprint</p>
<p>Language agent tree search unifies reasoning acting and planning in language models. Andy Zhou, Kai Yan, Michal Shlapentokh-Rothman, Haohan Wang, Yu-Xiong Wang, arXiv:2310.044062023. 2023arXiv preprint</p>
<p>Denny Zhou, Nathanael Schärli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schuurmans, Claire Cui, Olivier Bousquet, Quoc Le, arXiv:2205.10625Least-to-most prompting enables complex reasoning in large language models. 2022. 2022arXiv preprint</p>
<p>Shuyan Zhou, Uri Alon, Frank F Xu, Zhiruo Wang, Zhengbao Jiang, Graham Neubig, arXiv:2207.05987Docprompting: Generating code by retrieving the docs. 2022. 2022arXiv preprint</p>            </div>
        </div>

    </div>
</body>
</html>