<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-4259 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-4259</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-4259</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-98.html">extraction-schema-98</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs being used to process scholarly papers and extract qualitative laws, principles, patterns, or theories from them.</div>
                <p><strong>Paper ID:</strong> paper-263827375</p>
                <p><strong>Paper Title:</strong> The future landscape of large language models in medicine</p>
                <p><strong>Paper Abstract:</strong> Large language models (LLMs) are artificial intelligence (AI) tools specifically trained to process and generate text. LLMs attracted substantial public attention after OpenAI’s ChatGPT was made publicly available in November 2022. LLMs can often answer questions, summarize, paraphrase and translate text on a level that is nearly indistinguishable from human capabilities. The possibility to actively interact with models like ChatGPT makes LLMs attractive tools in various fields, including medicine. While these models have the potential to democratize medical knowledge and facilitate access to healthcare, they could equally distribute misinformation and exacerbate scientific misconduct due to a lack of accountability and transparency. In this article, we provide a systematic and comprehensive overview of the potentials and limitations of LLMs in clinical practice, medical research and medical education.</p>
                <p><strong>Cost:</strong> 0.013</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e4259.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e4259.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs being used to process scholarly papers and extract qualitative laws, principles, patterns, or theories from them.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLMs (general)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Large language models (LLMs)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Unspecified large pretrained transformer-based language models discussed as tools to summarize scientific literature, extract structured data from unstructured text/images, and uncover connections across publications to suggest new research trajectories.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>The future landscape of large language models in medicine</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>unspecified LLMs (general)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>The paper describes, at a conceptual level, that LLMs can be used to (1) summarize scientific concepts and existing evidence, (2) extract data of interest from vast unstructured text files or images, and (3) uncover connections between pieces of literature to help discover new research trajectories. No concrete prompting templates, multi-step pipelines, retrieval-augmented methods, or system architectures for extracting qualitative laws/principles are provided in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_field</strong></td>
                            <td>medicine / medical research</td>
                        </tr>
                        <tr>
                            <td><strong>type_of_laws_extracted</strong></td>
                            <td>Literature-scale patterns and empirical generalizations (e.g., cross-study connections, high-level research hypotheses and trajectories); structured data extraction from text.</td>
                        </tr>
                        <tr>
                            <td><strong>example_laws_extracted</strong></td>
                            <td>The paper does not report concrete extracted laws; it gives conceptual examples such as: (a) extracting data of interest from vast unstructured text, and (b) uncovering possible connections between literature to suggest new research trajectories.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>LLMs could potentially distill and synthesize scientific knowledge, surface cross-paper connections, and accelerate idea generation in research, but these capabilities are described at a conceptual level rather than demonstrated empirically in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>No concrete evaluation reported; limitations noted include static (non–real-time) knowledge, hallucinations, reproduction of biases from training data, lack of transparency about training data and code, potential for misinformation, and reproducibility/versioning issues when models change.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The future landscape of large language models in medicine', 'publication_date_yy_mm': '2023-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4259.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e4259.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs being used to process scholarly papers and extract qualitative laws, principles, patterns, or theories from them.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Generative Pre-trained Transformer 4 (GPT-4)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A state-of-the-art LLM from OpenAI discussed in the paper as having strong medical domain knowledge and improved factuality over predecessors, with example usages for summarization and reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>The future landscape of large language models in medicine</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>The paper reports that GPT-4 demonstrates high medical domain knowledge (e.g., performing well on medical licensing exams) and shows improved content-level corrections versus GPT-3.5 in example prompts, but it does not describe any specific method using GPT-4 to process scholarly papers to extract qualitative laws or a detailed prompting/extraction pipeline.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_field</strong></td>
                            <td>medicine / medical research</td>
                        </tr>
                        <tr>
                            <td><strong>type_of_laws_extracted</strong></td>
                            <td>Not demonstrated; paper speculates that models like GPT-4 could be used for summarization and discovering literature connections (empirical generalizations, research hypotheses), but no concrete laws are extracted in the work.</td>
                        </tr>
                        <tr>
                            <td><strong>example_laws_extracted</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Example-based comparison in Box 2 (GPT-3.5 vs GPT-4) for clinical/scientific text corrections; no evaluation of literature-scale law extraction.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared qualitatively to GPT-3.5 in example prompts (improved factual and grammatical corrections), but no quantitative baseline for law extraction provided.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>GPT-4 shows improved factual correction and medical reasoning compared with GPT-3.5 in illustrative examples; the authors state such advanced models increase the potential to summarize and synthesize medical literature but caution about hallucinations and biases.</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Despite improvements, GPT-4 still faces limitations when used as a primary source for up-to-date peer-reviewed evidence (static knowledge cutoff), may hallucinate, reproduce bias, and lacks transparent training data; the paper does not present GPT-4-based extraction of qualitative laws from scholarly corpora.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The future landscape of large language models in medicine', 'publication_date_yy_mm': '2023-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4259.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e4259.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs being used to process scholarly papers and extract qualitative laws, principles, patterns, or theories from them.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SPIRES</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Structured prompt interrogation and recursive extraction of semantics (SPIRES)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A referenced method (from the bibliography) proposed for populating knowledge bases via structured prompting and recursive semantic extraction (zero-shot), relevant to extracting structured knowledge from texts.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Structured prompt interrogation and recursive extraction of semantics (SPIRES): a method for populating knowledge bases using zeroshot learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>SPIRES</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>The paper only cites SPIRES in the bibliography; no method details are provided in the main text. From the reference title, SPIRES appears to use structured prompt interrogation and recursive extraction (zero-shot) to populate knowledge bases from text — i.e., an approach that iteratively queries text with prompts to extract semantic relations for KB population. The focal paper does not describe the prompting templates, recursive steps, or retrieval augmentation used by SPIRES.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_field</strong></td>
                            <td>general scientific text / knowledge base population (applicable to biomedical literature)</td>
                        </tr>
                        <tr>
                            <td><strong>type_of_laws_extracted</strong></td>
                            <td>Semantic relations and structured knowledge suitable for knowledge bases; potentially patterns/hypotheses derivable from aggregated relations (not explicitly stated in this paper).</td>
                        </tr>
                        <tr>
                            <td><strong>example_laws_extracted</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Included in references as an example of methods for extracting semantics from text; the present paper does not evaluate SPIRES or report results.</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>No specific commentary in the paper about SPIRES beyond citation; general limitations applicable to such methods (from the paper) include hallucination, dependency on input data quality, lack of transparency, and reproducibility concerns.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The future landscape of large language models in medicine', 'publication_date_yy_mm': '2023-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4259.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e4259.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs being used to process scholarly papers and extract qualitative laws, principles, patterns, or theories from them.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BioGPT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>BioGPT: generative pre-trained transformer for biomedical text generation and mining</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A biomedical-specialized generative transformer model referenced as an example of models trained for biomedical text generation and mining, relevant to extracting biomedical knowledge from literature.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>BioGPT: generative pre-trained transformer for biomedical text generation and mining</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>BioGPT</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Referenced in the bibliography; the paper does not describe how BioGPT was applied here. The cited work is a biomedical LLM intended for text generation and mining, which by design could be used to extract structured biomedical knowledge or patterns from scientific texts, but no extraction pipeline or prompting strategy is provided in this perspective.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_field</strong></td>
                            <td>biomedical / medicine</td>
                        </tr>
                        <tr>
                            <td><strong>type_of_laws_extracted</strong></td>
                            <td>Potentially biomedical knowledge statements, relations, and empirical generalizations (not demonstrated in this paper).</td>
                        </tr>
                        <tr>
                            <td><strong>example_laws_extracted</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>BioGPT is listed among domain-specific models that could improve factuality and domain suitability for medical tasks; the paper suggests domain-specialized models may be more appropriate for medical literature processing.</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>The perspective notes general challenges for domain models: dependence on training data quality, potential biases, opacity of training corpora, and lack of dynamic updating; no BioGPT-specific evaluations are provided here.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The future landscape of large language models in medicine', 'publication_date_yy_mm': '2023-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4259.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e4259.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs being used to process scholarly papers and extract qualitative laws, principles, patterns, or theories from them.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SciBERT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>SciBERT: a pretrained language model for scientific text</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A domain-adapted BERT model pre-trained on scientific text, referenced as an example of models tailored for processing scholarly literature.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>SciBERT: a pretrained language model for scientific text</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>SciBERT</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Referenced in the bibliography as a pretrained model for scientific text; the paper does not describe using SciBERT to extract qualitative laws. SciBERT is typically used for scientific NLP tasks (e.g., citation intent, information extraction) but no specific extraction workflow is provided in this article.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_field</strong></td>
                            <td>scientific literature / biomedical science</td>
                        </tr>
                        <tr>
                            <td><strong>type_of_laws_extracted</strong></td>
                            <td>Typically supports extraction of relations, classifications, and structured information from scientific text (no examples provided in this paper).</td>
                        </tr>
                        <tr>
                            <td><strong>example_laws_extracted</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Cited as an example of domain-adapted language models useful for scientific text mining; the authors argue domain-specific models may improve factuality and applicability in medicine.</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>No SciBERT-specific limitations discussed beyond the paper's general cautions about domain bias, data transparency, and hallucination risks for LLM-derived outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The future landscape of large language models in medicine', 'publication_date_yy_mm': '2023-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Structured prompt interrogation and recursive extraction of semantics (SPIRES): a method for populating knowledge bases using zeroshot learning <em>(Rating: 2)</em></li>
                <li>BioGPT: generative pre-trained transformer for biomedical text generation and mining <em>(Rating: 2)</em></li>
                <li>SciBERT: a pretrained language model for scientific text <em>(Rating: 2)</em></li>
                <li>Evaluating large language models on medical evidence summarization <em>(Rating: 2)</em></li>
                <li>Large language models encode clinical knowledge <em>(Rating: 2)</em></li>
                <li>Structured prompt interrogation and recursive extraction of semantics (SPIRES): a method for populating knowledge bases using zeroshot learning <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-4259",
    "paper_id": "paper-263827375",
    "extraction_schema_id": "extraction-schema-98",
    "extracted_data": [
        {
            "name_short": "LLMs (general)",
            "name_full": "Large language models (LLMs)",
            "brief_description": "Unspecified large pretrained transformer-based language models discussed as tools to summarize scientific literature, extract structured data from unstructured text/images, and uncover connections across publications to suggest new research trajectories.",
            "citation_title": "The future landscape of large language models in medicine",
            "mention_or_use": "mention",
            "model_name": "unspecified LLMs (general)",
            "model_size": null,
            "method_name": null,
            "method_description": "The paper describes, at a conceptual level, that LLMs can be used to (1) summarize scientific concepts and existing evidence, (2) extract data of interest from vast unstructured text files or images, and (3) uncover connections between pieces of literature to help discover new research trajectories. No concrete prompting templates, multi-step pipelines, retrieval-augmented methods, or system architectures for extracting qualitative laws/principles are provided in the paper.",
            "number_of_papers": null,
            "domain_or_field": "medicine / medical research",
            "type_of_laws_extracted": "Literature-scale patterns and empirical generalizations (e.g., cross-study connections, high-level research hypotheses and trajectories); structured data extraction from text.",
            "example_laws_extracted": "The paper does not report concrete extracted laws; it gives conceptual examples such as: (a) extracting data of interest from vast unstructured text, and (b) uncovering possible connections between literature to suggest new research trajectories.",
            "evaluation_method": null,
            "performance_metrics": null,
            "comparison_baseline": null,
            "key_findings": "LLMs could potentially distill and synthesize scientific knowledge, surface cross-paper connections, and accelerate idea generation in research, but these capabilities are described at a conceptual level rather than demonstrated empirically in this paper.",
            "challenges_limitations": "No concrete evaluation reported; limitations noted include static (non–real-time) knowledge, hallucinations, reproduction of biases from training data, lack of transparency about training data and code, potential for misinformation, and reproducibility/versioning issues when models change.",
            "uuid": "e4259.0",
            "source_info": {
                "paper_title": "The future landscape of large language models in medicine",
                "publication_date_yy_mm": "2023-10"
            }
        },
        {
            "name_short": "GPT-4",
            "name_full": "Generative Pre-trained Transformer 4 (GPT-4)",
            "brief_description": "A state-of-the-art LLM from OpenAI discussed in the paper as having strong medical domain knowledge and improved factuality over predecessors, with example usages for summarization and reasoning.",
            "citation_title": "The future landscape of large language models in medicine",
            "mention_or_use": "mention",
            "model_name": "GPT-4",
            "model_size": null,
            "method_name": null,
            "method_description": "The paper reports that GPT-4 demonstrates high medical domain knowledge (e.g., performing well on medical licensing exams) and shows improved content-level corrections versus GPT-3.5 in example prompts, but it does not describe any specific method using GPT-4 to process scholarly papers to extract qualitative laws or a detailed prompting/extraction pipeline.",
            "number_of_papers": null,
            "domain_or_field": "medicine / medical research",
            "type_of_laws_extracted": "Not demonstrated; paper speculates that models like GPT-4 could be used for summarization and discovering literature connections (empirical generalizations, research hypotheses), but no concrete laws are extracted in the work.",
            "example_laws_extracted": null,
            "evaluation_method": "Example-based comparison in Box 2 (GPT-3.5 vs GPT-4) for clinical/scientific text corrections; no evaluation of literature-scale law extraction.",
            "performance_metrics": null,
            "comparison_baseline": "Compared qualitatively to GPT-3.5 in example prompts (improved factual and grammatical corrections), but no quantitative baseline for law extraction provided.",
            "key_findings": "GPT-4 shows improved factual correction and medical reasoning compared with GPT-3.5 in illustrative examples; the authors state such advanced models increase the potential to summarize and synthesize medical literature but caution about hallucinations and biases.",
            "challenges_limitations": "Despite improvements, GPT-4 still faces limitations when used as a primary source for up-to-date peer-reviewed evidence (static knowledge cutoff), may hallucinate, reproduce bias, and lacks transparent training data; the paper does not present GPT-4-based extraction of qualitative laws from scholarly corpora.",
            "uuid": "e4259.1",
            "source_info": {
                "paper_title": "The future landscape of large language models in medicine",
                "publication_date_yy_mm": "2023-10"
            }
        },
        {
            "name_short": "SPIRES",
            "name_full": "Structured prompt interrogation and recursive extraction of semantics (SPIRES)",
            "brief_description": "A referenced method (from the bibliography) proposed for populating knowledge bases via structured prompting and recursive semantic extraction (zero-shot), relevant to extracting structured knowledge from texts.",
            "citation_title": "Structured prompt interrogation and recursive extraction of semantics (SPIRES): a method for populating knowledge bases using zeroshot learning",
            "mention_or_use": "mention",
            "model_name": null,
            "model_size": null,
            "method_name": "SPIRES",
            "method_description": "The paper only cites SPIRES in the bibliography; no method details are provided in the main text. From the reference title, SPIRES appears to use structured prompt interrogation and recursive extraction (zero-shot) to populate knowledge bases from text — i.e., an approach that iteratively queries text with prompts to extract semantic relations for KB population. The focal paper does not describe the prompting templates, recursive steps, or retrieval augmentation used by SPIRES.",
            "number_of_papers": null,
            "domain_or_field": "general scientific text / knowledge base population (applicable to biomedical literature)",
            "type_of_laws_extracted": "Semantic relations and structured knowledge suitable for knowledge bases; potentially patterns/hypotheses derivable from aggregated relations (not explicitly stated in this paper).",
            "example_laws_extracted": null,
            "evaluation_method": null,
            "performance_metrics": null,
            "comparison_baseline": null,
            "key_findings": "Included in references as an example of methods for extracting semantics from text; the present paper does not evaluate SPIRES or report results.",
            "challenges_limitations": "No specific commentary in the paper about SPIRES beyond citation; general limitations applicable to such methods (from the paper) include hallucination, dependency on input data quality, lack of transparency, and reproducibility concerns.",
            "uuid": "e4259.2",
            "source_info": {
                "paper_title": "The future landscape of large language models in medicine",
                "publication_date_yy_mm": "2023-10"
            }
        },
        {
            "name_short": "BioGPT",
            "name_full": "BioGPT: generative pre-trained transformer for biomedical text generation and mining",
            "brief_description": "A biomedical-specialized generative transformer model referenced as an example of models trained for biomedical text generation and mining, relevant to extracting biomedical knowledge from literature.",
            "citation_title": "BioGPT: generative pre-trained transformer for biomedical text generation and mining",
            "mention_or_use": "mention",
            "model_name": "BioGPT",
            "model_size": null,
            "method_name": null,
            "method_description": "Referenced in the bibliography; the paper does not describe how BioGPT was applied here. The cited work is a biomedical LLM intended for text generation and mining, which by design could be used to extract structured biomedical knowledge or patterns from scientific texts, but no extraction pipeline or prompting strategy is provided in this perspective.",
            "number_of_papers": null,
            "domain_or_field": "biomedical / medicine",
            "type_of_laws_extracted": "Potentially biomedical knowledge statements, relations, and empirical generalizations (not demonstrated in this paper).",
            "example_laws_extracted": null,
            "evaluation_method": null,
            "performance_metrics": null,
            "comparison_baseline": null,
            "key_findings": "BioGPT is listed among domain-specific models that could improve factuality and domain suitability for medical tasks; the paper suggests domain-specialized models may be more appropriate for medical literature processing.",
            "challenges_limitations": "The perspective notes general challenges for domain models: dependence on training data quality, potential biases, opacity of training corpora, and lack of dynamic updating; no BioGPT-specific evaluations are provided here.",
            "uuid": "e4259.3",
            "source_info": {
                "paper_title": "The future landscape of large language models in medicine",
                "publication_date_yy_mm": "2023-10"
            }
        },
        {
            "name_short": "SciBERT",
            "name_full": "SciBERT: a pretrained language model for scientific text",
            "brief_description": "A domain-adapted BERT model pre-trained on scientific text, referenced as an example of models tailored for processing scholarly literature.",
            "citation_title": "SciBERT: a pretrained language model for scientific text",
            "mention_or_use": "mention",
            "model_name": "SciBERT",
            "model_size": null,
            "method_name": null,
            "method_description": "Referenced in the bibliography as a pretrained model for scientific text; the paper does not describe using SciBERT to extract qualitative laws. SciBERT is typically used for scientific NLP tasks (e.g., citation intent, information extraction) but no specific extraction workflow is provided in this article.",
            "number_of_papers": null,
            "domain_or_field": "scientific literature / biomedical science",
            "type_of_laws_extracted": "Typically supports extraction of relations, classifications, and structured information from scientific text (no examples provided in this paper).",
            "example_laws_extracted": null,
            "evaluation_method": null,
            "performance_metrics": null,
            "comparison_baseline": null,
            "key_findings": "Cited as an example of domain-adapted language models useful for scientific text mining; the authors argue domain-specific models may improve factuality and applicability in medicine.",
            "challenges_limitations": "No SciBERT-specific limitations discussed beyond the paper's general cautions about domain bias, data transparency, and hallucination risks for LLM-derived outputs.",
            "uuid": "e4259.4",
            "source_info": {
                "paper_title": "The future landscape of large language models in medicine",
                "publication_date_yy_mm": "2023-10"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Structured prompt interrogation and recursive extraction of semantics (SPIRES): a method for populating knowledge bases using zeroshot learning",
            "rating": 2,
            "sanitized_title": "structured_prompt_interrogation_and_recursive_extraction_of_semantics_spires_a_method_for_populating_knowledge_bases_using_zeroshot_learning"
        },
        {
            "paper_title": "BioGPT: generative pre-trained transformer for biomedical text generation and mining",
            "rating": 2,
            "sanitized_title": "biogpt_generative_pretrained_transformer_for_biomedical_text_generation_and_mining"
        },
        {
            "paper_title": "SciBERT: a pretrained language model for scientific text",
            "rating": 2,
            "sanitized_title": "scibert_a_pretrained_language_model_for_scientific_text"
        },
        {
            "paper_title": "Evaluating large language models on medical evidence summarization",
            "rating": 2,
            "sanitized_title": "evaluating_large_language_models_on_medical_evidence_summarization"
        },
        {
            "paper_title": "Large language models encode clinical knowledge",
            "rating": 2,
            "sanitized_title": "large_language_models_encode_clinical_knowledge"
        },
        {
            "paper_title": "Structured prompt interrogation and recursive extraction of semantics (SPIRES): a method for populating knowledge bases using zeroshot learning",
            "rating": 1,
            "sanitized_title": "structured_prompt_interrogation_and_recursive_extraction_of_semantics_spires_a_method_for_populating_knowledge_bases_using_zeroshot_learning"
        }
    ],
    "cost": 0.012674749999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>The future landscape of large language models in medicine</p>
<p>Jan Clusmann 0000-0003-2925-8438
Else Kroener Fresenius Center for Digital Health
TUD Dresden University of Technology
DresdenGermany</p>
<p>Department of Medicine III
University Hospital RWTH Aachen
AachenGermany</p>
<p>Fiona R Kolbinger 0000-0003-2265-4809
Else Kroener Fresenius Center for Digital Health
TUD Dresden University of Technology
DresdenGermany</p>
<p>Department of Visceral
Thoracic and Vascular Surgery
Faculty of Medicine Carl Gustav Carus
University Hospital
TUD Dresden University of Technology
DresdenGermany</p>
<p>Hannah Sophie Muti 
Else Kroener Fresenius Center for Digital Health
TUD Dresden University of Technology
DresdenGermany</p>
<p>Department of Visceral
Thoracic and Vascular Surgery
Faculty of Medicine Carl Gustav Carus
University Hospital
TUD Dresden University of Technology
DresdenGermany</p>
<p>Zunamys I Carrero 0000-0001-8501-1566
Else Kroener Fresenius Center for Digital Health
TUD Dresden University of Technology
DresdenGermany</p>
<p>Jan-Niklas Eckardt 
Else Kroener Fresenius Center for Digital Health
TUD Dresden University of Technology
DresdenGermany</p>
<p>Department of Medicine I
University Hospital Dresden
DresdenGermany</p>
<p>Narmin Ghaffari Laleh 
Else Kroener Fresenius Center for Digital Health
TUD Dresden University of Technology
DresdenGermany</p>
<p>Department of Medicine III
University Hospital RWTH Aachen
AachenGermany</p>
<p>Chiara Maria Lavinia Löffler 
Else Kroener Fresenius Center for Digital Health
TUD Dresden University of Technology
DresdenGermany</p>
<p>Department of Medicine I
University Hospital Dresden
DresdenGermany</p>
<p>Sophie-Caroline Schwarzkopf 
Department of Visceral
Thoracic and Vascular Surgery
Faculty of Medicine Carl Gustav Carus
University Hospital
TUD Dresden University of Technology
DresdenGermany</p>
<p>Michaela Unger 0000-0001-5811-0200
Else Kroener Fresenius Center for Digital Health
TUD Dresden University of Technology
DresdenGermany</p>
<p>Gregory P Veldhuizen 
Else Kroener Fresenius Center for Digital Health
TUD Dresden University of Technology
DresdenGermany</p>
<p>Sophia J Wagner 
Helmholtz Munich-German Research Center for Environment and Health
MunichGermany</p>
<p>School of Computation, Information and Technology
Technical University of Munich
MunichGermany</p>
<p>Jakob Nikolas Kather jakob-nikolas.kather@alumni.dkfz.de 
Else Kroener Fresenius Center for Digital Health
TUD Dresden University of Technology
DresdenGermany</p>
<p>Department of Medicine III
University Hospital RWTH Aachen
AachenGermany</p>
<p>Department of Medicine I
University Hospital Dresden
DresdenGermany</p>
<p>Medical Oncology
National Center for Tumor Diseases (NCT)
University Hospital Heidelberg
HeidelbergGermany</p>
<p>Hannah Sophie 
The future landscape of large language models in medicine
B987AC9568092E1A94A41199F7C01A5F10.1038/s43856-023-00370-1Received: 15 February 2023; Accepted: 21 September 2023;
Large language models (LLMs) are artificial intelligence (AI) tools specifically trained to process and generate text.LLMs attracted substantial public attention after OpenAI's ChatGPT was made publicly available in November 2022.LLMs can often answer questions, summarize, paraphrase and translate text on a level that is nearly indistinguishable from human capabilities.The possibility to actively interact with models like ChatGPT makes LLMs attractive tools in various fields, including medicine.While these models have the potential to democratize medical knowledge and facilitate access to healthcare, they could equally distribute misinformation and exacerbate scientific misconduct due to a lack of accountability and transparency.In this article, we provide a systematic and comprehensive overview of the potentials and limitations of LLMs in clinical practice, medical research and medical education.Large language models (LLMs) use computational artificial intelligence (AI) algorithms to generate language that resembles that produced by humans 1,2 .These models are trained on large amounts of text, for example, obtained from the internet, and can answer questions, provide summaries or translations and create stories or poems (Fig.1a)3,4.Users provide a set of keywords or queries, and the LLM generates text on these topics.It is also possible to request a particular style of text, such as simplified language or poetry.LLMs could potentially assist in various areas of medicine, given their capability to process complex concepts, as well as respond to diverse requests and questions (prompts) 2,5,6 .However, these models also raise concerns about misinformation, privacy, biases in the training data, and potential for misuse3,[7][8][9][10].Here, we provide an overview of how LLMs could impact patient care, medical research and medical education.Development of LLMsLLMs use neural networks and were developed following previous work using natural language processing (NLP) models such as the Bidirectional Encoder Representations from Transformers (BERT) and its variations2,5,[11][12]<a href="see Box 1 for a glossary of technical terms used in this article">13</a>.In 2018 OpenAI released their first LLM, Generative Pre-trained Transformer (GPT)-1 14 , and</p>
<p>this was followed by the release of other LLMs from companies such as Google and Meta 2, [15][16][17] .In November 2022, OpenAI released an updated LLM called ChatGPT (https://chat.openai.com), which attracted attention 18 due to its public accessibility, convenient usability, and human-like output.This is achieved through an incorporated reward model based on human feedback, known as reinforcement learning from human feedback (RLHF), resulting in more credible output than previous LLMs (Fig. 1a) [18][19][20] .</p>
<p>Since the release of ChatGPT, several other LLMs and tools have been published at unprecedented speed.GPT-4, developed with further reinforcement learning from ChatGPT by OpenAI 21 , now exceeds the passing score on every step of the US-medical licensing exam (USMLE) 5,22 .Application programming interfaces (APIs) for PaLM and the ChatBot BARD (by Google, https://blog.google/technology/ai/google-palm-2-ai-largelanguage-model) 16,23, Llama and Llama-2 (by Meta, https:// huggingface.co/docs/transformers/main/model_doc/llama) 24, Alpaca 7b 25 and Vicuna 26 (both smaller models, developed based on Llama by Stanford University, UC Berkeley, CMU, and UC San Diego for affordable reproduction) as well as GPT-4 are now publicly provided.This allows users to integrate the models into independent software.Furthermore, new functionalities such as visual input 21 and plugins 27 allow for an exponentially growing body of possible applications.</p>
<p>Patient care</p>
<p>Throughout medical disciplines, human communication is an integral part of patient care.Accurate interpretation of spoken language is one of the most critical factors that influence the success of communication.This is vital for the patient-caregiver rapport, patient satisfaction and to enable optimal clinical outcomes.At the same time, written text is used for a lot of the communication between medical professionals about patients, such as reports on diagnostic and therapeutic procedures, the results and the implications thereof.A lack of clarity in patient reports correlates with inferior quality of patient care 28 .Also, inefficient communication between healthcare providers results in a substantial economic burden for clinical institutions and healthcare systems 29 .Here, we describe three main examples of how LLMs can be used to improve patient care: Conveying medical knowledge, assisting communication with patients Box 1 | Glossary of computational terms Artificial Intelligence (AI) models: Computational systems designed to simulate human intelligence and perform tasks such as problem-solving, decision-making, and language processing.Application Programming Interface (API): Interface that facilitates communication and interaction between different software applications, enabling seamless integration and data exchange.Bidirectional Encoder Representations from Transformers (BERT): A specific natural language processing (NLP) model that utilizes a transformerbased neural network architecture.It focuses on understanding the contextual meaning of words by considering both the preceding and following words in a sentence.Code debugging: Process of identifying and rectifying errors or issues in software code, ensuring that the program functions correctly and produces the intended results.Data leakage: Unintended exposure or disclosure of sensitive or confidential information to unauthorized individuals or entities, potentially leading to privacy breaches or security risks.Domain knowledge: Expertise and understanding in a specific field or subject area.It encompasses the concepts, principles, and practical applications relevant to that particular domain.Externalization: The process of expressing or representing factual knowledge in an external form, such as written documents, diagrams, or databases, to make it more tangible and accessible.Generative Pre-trained Transformer (GPT)-1: Generative Pre-trained Transformer (GPT)-1 is a large language model developed by OpenAI.It utilizes a generative pre-training approach and a transformer architecture to generate text that closely resembles human language.Natural language input: Using human language, whether spoken or written, to interact with computer systems.It allows users to provide instructions or input in a more intuitive and human-like manner.Natural Language Processing (NLP) models: AI models specifically designed to understand and analyze human language.They enable computers to process and interpret text data, extract meaning, and perform language-related tasks.Plugin: Software component or module that adds specific features or functionality to an existing software application, enhancing its capabilities or extending its functionality.Prompt, Re-prompt: A specific stimulus or cue given to initiate a particular action or response.In the context of prompt-triggered chart review or initial prompted queries, it represents a question or instruction provided to facilitate a particular task or inquiry.Re-prompting involves providing additional prompts or cues to elicit further responses or actions from a user or system, often to gather more specific or detailed information.Prompt injection attack: Malicious addition of unauthorized prompts or commands into a system, often with the intention of compromising security, manipulating functionality, or extracting sensitive information.Query: A specific request or question posed to a system or database to obtain relevant information or data.Reinforcement learning: A machine learning method where decisions are made by interacting with an environment.The model receives external (i.e., human) feedback in the form of rewards or punishments, enabling it to improve its performance over time.Reinforcement Learning from Human Feedback (RLHF): A technique that combines reinforcement learning methods with additional guidance or feedback from human experts.This approach enhances the model's performance and aligns it with human preferences.Safety guardrails: Measures or rules implemented to ensure the safe and responsible operation of a system.They serve as safeguards to mitigate risks, prevent harmful outcomes, and maintain the integrity and reliability of the system.Semantic knowledge: Semantic knowledge refers to the understanding of the meaning, relationships, and context of words and sentences.It involves comprehending the deeper nuances and conceptual associations within language.Structured information: Data or information that is organized and formatted in a predefined manner, such as a database or spreadsheet.It follows a consistent structure, allowing for easier storage, retrieval, and analysis.Unstructured information: Data or information that does not adhere to a predefined or organized format.Examples include text, images, audio, or video data, requiring advanced techniques for processing, interpretation, and analysis.Medical knowledge and medical core competencies.LLMs have the potential to improve patient care by augmenting core medical competencies such as factual knowledge or interpersonal communication skills (Fig. 1b).ChatGPT, for example, has substantial semantic medical knowledge and is capable of medical reasoning 2 (Box 2, Supplementary Data, example 1), as demonstrated in its performing well at medical licensing exams 5,6,30 .Fine-tuning LLMs by providing additional training with questions in the style of medical licensing examinations and example answers selected by clinical experts can further enhance medical reasoning and comprehension by the LLM 2 .GPT-4 thus far demonstrates the highest medical domain knowledge of LLMs to date 5 .Still, LLMs have the inherent limitation of reproducing existing medical biases 31 (Supplementary Data, example 2) and perpetuating inequalities related to factors such as race, gender, sexual orientation, and socioeconomic status 30,32 .</p>
<p>Through their text simplification capabilities 33 , LLMs may improve communication between healthcare staff and patients 34 .They can be accessed by patients at any time and do not have the same time constraints as healthcare experts, potentially making contact easier and more comfortable 35 .These benefits are especially pronounced for conditions that carry a social stigma, such as addiction or sexually transmitted diseases.Digital tools addressing this need have been developed since smartphones became broadly available in the late 2000s.Examples of such tools are First Derm 36,37 , a teledermoscopy application for the diagnosis of skin conditions, enabling dermatologists to remotely assess and provide guidance, and Pahola 38 , a digital chatbot to provide guidance on alcohol consumption.Currently, the success of such digital health applications is mostly limited by technical constraints 39 and limited acceptance by healthcare practitioners 40 .The rapid advancement of LLMs and subsequent improvements in functionality and usability could help overcome these limitations.Still, LLMs currently lack the capacity for true empathy, which is a crucial aspect in emotionally challenging situations and is likely to remain a task that must be done by humans.</p>
<p>Box 2 | Example prompts and outputs of GPT-3.5 and GPT-4 in the context of patient care, research, and medical education Model outputs were generated using ChatGPT (model versions: GPT-4-May 3, 2023, GPT-3.5-May 3, 2023).Additional example outputs are listed in the Supplementary Data.</p>
<p>Clinical recommendation</p>
<p>Administration of prokinetic agents can be fatal in patients with (mechanical) ileus.This false recommendation was output by GPT-3.5 but could not be reproduced with GPT-4.Prompt: As a doctor on a surgical ward, a postoperative patient on your ward is presenting with ileus symptoms.What therapeutic measures would you initiate immediately?GPT-3.5:[1.-2.] 3. Administer a prokinetic agent, such as metoclopramide or erythromycin, to stimulate intestinal motility and help move the blockage through the intestine.</p>
<p>Scientific output</p>
<p>While GPT-3.5 corrected grammar errors, it did not correct the intrinsically false statement (MSI is not exclusive for colorectal cancer).GPT-4 corrected errors on both grammar and content level.Prompt: Correct the content of the following paragraph: MSI is a type of mutation that only happens in colorectal cancer.The cancer patients with this mutation show a very good response to the treatments.Their survival time is much longer than other colorectal cancer patients.GPT-3.5:MSI is a type of genetic alteration that occurs exclusively in colorectal cancer patients.Individuals with this mutation tend to exhibit better response to treatments, and their survival rate is significantly higher compared to those without the MSI mutation.GPT-4: Microsatellite instability (MSI) is a type of mutation that occurs not only in colorectal cancer but also in other cancers.Patients with this mutation typically show a very good response to treatments.Their survival time is often longer compared to other colorectal cancer patients.Audience-adapted explanations Both GPT-3.5 and GPT-4 are capable of adapting wording and style to different audiences.Prompt: Explain protein biosynthesis to a five-year-old.GPT-3.5:Proteins are special molecules that are important for our bodies.They help us grow, stay healthy, and do many different things.Just like how different building blocks can be used to build different things, our bodies use small building blocks called amino acids to build proteins.The process of protein biosynthesis is like following a recipe to make something tasty.Our bodies have a special recipe book called DNA that contains instructions for making proteins.DNA is like a special code that tells our bodies how to make different proteins.When it's time to make a protein, our bodies read the recipe from the DNA book.It's like a chef reading a recipe to make a cake.But instead of using flour and sugar, our bodies use amino acids as ingredients.Our bodies have little factories called ribosomes that help put the amino acids together in the right order, just like a chef mixing the ingredients in the right way.The ribosomes read the recipe from the DNA and make sure the amino acids are put together in the correct order to make the protein.Once the protein is made, it can go to different parts of our body to do its job.Some proteins help our muscles move, some help us see, and some help us fight off germs to stay healthy.So, protein biosynthesis is like following a recipe to make special molecules called proteins using amino acids as ingredients.Our bodies have a special code called DNA and little factories called ribosomes that help put the amino acids together in the right way to make the proteins we need.I hope that helps you understand protein biosynthesis, even at a young age!GPT-4: Protein biosynthesis is like building a toy with tiny building blocks called amino acids.Our body has a special set of instructions called DNA that tells it how to put these building blocks together in the right order.Imagine a big factory inside our body where tiny workers called ribosomes read the instructions and put the amino acids together.When the amino acids are connected in the right order, they form proteins.These proteins are important because they help our body grow, repair itself, and do all the things we need to live, like running and playing!Translations and summaries.Language barriers often hinder patient participation in decisions regarding their own wellbeing 41,42 .LLMs can provide fast and accurate translations to many languages, effectively enabling both healthcare providers and patients to participate in clinical decision-making regardless of their native language (Supplementary Data, example 3).LLMs can also act as translators of medical terminology into plain everyday language, which is likely to improve therapy adherence by empowering patients in their health-related decisions.Documentation.Documentation and administrative requirements consume around 25% of clinicians' workdays 35 .LLMs could assist in the generation of more concise and standardized reports and documentation.Crucially, LLMs can convert unstructured notes into a structured format, thereby easing documentation tasks in routine patient care or clinical trials (Supplementary Data, example 4).Combining the potential of LLMs in the processing and production of both written and spoken language 43 could result in automated dictation or prompt-triggered chart review.Such integration could relieve clinicians from the burden of parts of the documentation process, reducing cognitive load and thus increasing their availability to patients.</p>
<p>Medical research</p>
<p>Providing high-quality healthcare requires physicians to integrate the latest medical evidence into their decision-making processes.Also, physicians are often involved in preclinical, translational, and clinical research.Efficient communication of research findings, such as in the form of written publications and oral reports at conferences, enables findings to reach appropriate medical and scientific communities and, ultimately, enables uptake in the clinic.LLMs will likely impact and change medical research soon.However, while they have the potential to democratize access to scientific evidence, they could result in misinformation and facilitate scientific misconduct [44][45][46] .Here, we provide an overview of how LLMs could impact access to scientific knowledge, scientific writing, and programming tasks.</p>
<p>Access to scientific knowledge.Scientific research is fast-paced and continuously evolving, resulting in a growing number of publications of varying quality.Utilizing this knowledge appropriately is a considerable challenge for researchers [47][48][49] .Also, the content of non-open-access publications remains hidden behind paywalls which limits access.LLMs could help summarize scientific concepts and existing evidence, enabling researchers to require access to a smaller number of more easily accessible resources.However, the quality and benefit of these summaries are dependent on the underlying training data.While GPT-4 is more factually accurate than its predecessor, GPT-3.5 (Box 2, Supplementary Data, example 2, 5, 10), LLMs currently do not always provide appropriate detailed summaries or critical appraisals of up-to-date, high-quality, peer-reviewed evidence 50 .As LLMs are currently not dynamically updated, their knowledge is static, which prevents access to the latest scientific progress if used as a primary source of information (Box 2, Supplementary Data, example 5).However, if real-time updates could be implemented and factuality could be improved, the value of LLMs as sources of up-to-date evidence would rise substantially.It is conceivable that such next-generation LLMs could help counteract the trend toward less disruptive research 49 if employed as scientific tools.For example, LLMs can be used to efficiently extract data of interest from vast, unstructured text files or images, which is a tedious task that can lead to errors if it is done manually 51 .LLM-enabled quality summaries could help navigate the challenges of rapidly evolving scientific evidence, and by uncovering possible connections between literature, LLMs could help discover new research trajectories, thereby contributing to shaping a more innovative and dynamic research landscape.Scientific text production.An LLM's potential to produce and adapt the content, language, and style of text can be used to produce scientific content 52,53 .For example, ChatGPT is capable of generating scientific abstracts that humans struggle to differentiate from those written by human researchers 54 .Nonetheless, using LLMs for scientific writing currently requires significant revisions by human authors due to inaccurate, shallow and repetitive outputs (Supplementary Data, example 6).It is anticipated that LLMs will impact the communication of scientific findings 9,55 .However, their use may compromise the quality of scientific publications by complicating the verification of the authenticity of scientific text, as well as underlying facts and references.To make scientific developments as transparent as possible, it will be important to define a framework for the usage of LLMs in the scientific context 9,46,56 .</p>
<p>Computer programming.Besides written language, LLMs can also be trained on code in various programming languages.Popular applications of LLMs in the fields of data science and bioinformatics are code debugging and simplification, translation to different programming languages, and derivation of code from natural language input (Supplementary Data, example 7).While these outputs can sometimes be inaccurate, LLMs are able to provide solutions upon further request and can help researchers with simple and complex coding tasks, e.g., fast visualization of data.This provides scientists with a technical skillset, enabling clinicians and others who lack substantial programming expertise to use code-based tools to test their hypotheses and boost their efficiency.</p>
<p>Reproducibility.Reproducibility is a fundamental prerequisite for maintaining high standards in scientific practice.Although dynamically updating models can lead to improved performance compared to their predecessors 5,21 , such updates, or restrictions to their access, can also compromise reliable and consistent reproduction of research findings.For instance, we observed substantial differences between the initial prompted queries using GPT-3.5 and re-prompting with GPT-4 (Box 2, Supplementary Data).Minor changes were also seen when using different versions of GPT-3.5.This highlights the importance of meticulous documentation of prompts and model versions in scientific publications, as well as the implementation of open-access version control solutions by developers, to enable the future recreation of version-specific content.</p>
<p>Medical education</p>
<p>Education has changed as new technologies have emerged.For example, the availability of calculators enabled mathematics teaching to concentrate on theories and arguments rather than learning how to undertake complex mental calculations.Because a vast amount of knowledge is now readily available via the internet and smart devices, memorization has become less of a requisite in medical education 57,58 .Instead, educators have placed more emphasis on critical thinking, debating and discussing, as these are skills that are still required.LLMs will likely introduce further changes to educational methods, as they can assist with reasoning.In the following section, we will explore the potential of LLMs in medical education, examining their potential impact on the critical thinking abilities of healthcare professionals and identifying important topics that should be addressed in medical education as LLMs become more prevalent.</p>
<p>Beneficial uses of LLMs in education.When used responsibly, LLMs can complement educational strategies in many ways.They can provide convincing summaries, presentations, translations, explanations, step-by-step guides and contextualization on many topics, coupled with customizable depth, tone and style of the output.For example, they can break down complex concepts to an amateur level (Box 2, Supplementary Data, example 8, 9) and provide individualized feedback on academic topics with reasonable explanations (Supplementary Data, example 9) 6 .These properties make LLMs suitable to function as personalized teaching assistants that could, for example, prepare revision aids and examples of tests.LLMs can be used to create interactive and engaging learning simulations.For example, students may use LLMs to simulate conversations with fictitious patients, allowing them to practice taking patient histories or assessing diagnosis and treatment plans (Supplementary Data, example 11).</p>
<p>Impact on critical thinking.The use of LLMs as educational tools raises concerns, as students can use them in inappropriate ways.As for scientific settings, usage of LLMs at educational institutions will need to be transparently regulated, for example, with the help of machine learning algorithms to differentiate between text generated by LLMs and self-written text 59 .Still, it is to be expected that LLMs could negatively impact students' abilities to discriminate valuable information from wrong and irrelevant input.This can only be achieved via critical thinking, which is based on understanding, analytical thinking and critical evaluation 60,61 .Therefore, the use of LLMs as a crutch for assignments could lead to a decrease in the critical thinking and creativity of students.In the context of medical education, in addition to externalizing factual knowledge, readily available LLMs harbor the danger of externalization of medical reasoning.</p>
<p>Education about LLMs.It will be essential to implement responsible interaction guidelines for LLM use to prevent inappropriate use by students, especially in medical education, where misinformation can lead to inaccurate decisions, potentially resulting in patient harm.All students should undergo a basic introduction to LLMs given their wide potential applications.This should include awareness of intrinsic biases and limitations.It is particularly important students learn appropriate prompt engineering, i.e., appropriate and precise phrasing of an appropriate input to achieve the desired output 62 , as misconceived prompts may result in biases or misinformation with potentially serious consequences 4 .</p>
<p>Ethical use and misinformation</p>
<p>LLMs can provide broader access to medical knowledge.However, despite recent improvements in factual accuracy 21 , the recurring issue of misinformation (Box 2, Supplementary Data, example 10 63 ) and potentially harmful consequences for patient care remains.Technical options to overcome limitations in factuality and mitigate (bias-related) harms can generally be implemented throughout the entire development process of LLMs.Input data can be improved through sampling and filtering processes, model architectures can be augmented to incorporate factual information from databases or knowledge graphs, harmful outputs can be detected and rewritten on inference level, and harmful and false model outputs can be flagged and redacted 33,[64][65][66][67][68] .These possibilities have been insufficiently employed to date, and a legal framework to handle potential issues will need to be established before clinical usage of LLMs for decision-making or therapeutic recommendations 69,70 .</p>
<p>We anticipate the following ethical issues presenting significant challenges that must be addressed.First, data privacy is of utmost importance to protect sensitive personal data that is routinely assessed, documented and exchanged in clinical settings.Reports of data leakage 71 or malicious attempts (prompt injection attacks to steal data) 72 are concerning and have to be addressed.Implementing APIs 23,26 into independent, secure applications rather than using interfaces such as ChatGPT could solve this issue.A second challenge arises from the lack of publicly available training datasets and source code 63 .As the output quality of any model is highly dependent on the quality of the input data, it is crucial for the scientific community to gain insights into the underlying data of current LLMs.Lastly, to date, the development of LLMs has been driven primarily by commercial companies such as OpenAI/Microsoft 21 , Meta 24 , and Google 2 .To prevent medical knowledge and healthcare access from being restricted to global monopolies, it is essential to encourage the development of non-commercial open-source LLM projects 9,63 .</p>
<p>Outlook</p>
<p>It is anticipated that LLMs will have a substantial impact on clinical care, research and medical education.However, it is important to be aware of and consider their limitations.LLMs have been shown to reproduce existing biases and are susceptible to hallucinating false information and spreading misinformation 32,73 .In the context of medical and non-medical education, students are vulnerable to misinformation and might fail to develop the required critical thinking capabilities.Currently, there are no mechanisms to ensure that an LLM's output is correct.This substantially limits the applicability of LLMs in clinical settings, as errors and misinformation could have fatal consequences.This is aggravated by the lack of accountability of LLMs.On the other hand, safety guardrails implemented into LLMs could pose a limitation of their own, for example, if bias prevention leads to different symptoms in men and women being overlooked.However, in general, recently updated versions and models designed specifically for medical applications and trained on medical data show promising progress in this domain 2,5,74 .Nevertheless, before LLMs can be applied in the medical domain, central conditions such as safety, validity and ethical concerns must be addressed.</p>
<p>Reporting summary.Further information on research design is available in the Nature Portfolio Reporting Summary linked to this article.</p>
<p>Fig. 1
1
Fig. 1 Large language models (LLMs) in medicine.a Simplified design of the architecture behind ChatGPT, including training, iterations of reinforcement learning by human feedback, choice of available model and implementation of guardrails to improve safety.b Overview of potential applications for LLMs in medicine, including patient care, research, and education.c Limitations of LLMs in their current state.</p>
<p>Visual input: Information received through visual perception, such as images, videos, or graphical representations.AI models can analyze and process visual input for various tasks, such as object recognition or image classification.COMMUNICATIONS MEDICINE | https://doi.org/10.1038/s43856-023-00370-1PERSPECTIVE COMMUNICATIONS MEDICINE | (2023) 3:141 | https://doi.org/10.1038/s43856-023-00370-1| www.nature.com/commsmedthrough translations and summaries, and simplifying documentation tasks by converting between unstructured and structured information.</p>
<p>[4.-8.]GPT-4: Postoperative ileus is a temporary impairment of bowel motility that occurs after surgery, particularly abdominal surgery.If you suspect ileus in a patient, consider taking the following steps: 1. Assess the patient: Obtain a thorough history and […] physical examination, […] monitor vital signs […] 2. Order investigations: Order laboratory tests, […] an abdominal X-ray or CT scan […] 3. NPO (nothing by mouth) […] to […] minimize the risk of aspiration in case of vomiting.4. IV fluids […] to maintain hydration and electrolyte balance. 5. […] Consider placing a nasogastric tube to decompress the stomach and alleviate symptoms […] 6. Pain management [7.-8.]</p>
<p>COMMUNICATIONS MEDICINE | (2023) 3:141 | https://doi.org/10.1038/s43856-023-00370-1 | www.nature.com/commsmed
Acknowledgements F.R.K. and S.J.W. were supported by the Add-on Fellowship of the Joachim Herz Foundation.S.J.W. was supported by the Helmholtz Association under the joint research school "Munich School for Data Science-MUDS".G.P.V. was supported by BMBF (Federal Ministry of Education and Research) in DAAD project 57616814 (SECAI, School of Embedded Composite AI, https://secai.org/) as part of the program Konrad Zuse Schools of Excellence in Artificial Intelligence.J.N.K. is supported by the German Federal Ministry of Health (DEEP LIVER, ZMVI1-2520DAT111) and the Max-Eder-Programme of the German Cancer Aid (grant #70113864), the German Federal Ministry of Education and Research (PEARL, 01KD2104C), and the German Academic Exchange Service (SECAI, 57616814).Data availabilityNo datasets were created in the context of this work.Examples of LLM outputs are provided in the Supplementary Data.FundingOpen Access funding enabled and organized by Projekt DEAL.Author contributionsJ.C., F.R.K., H.S.M., and J.N.K. conceptualized this work.J.C., F.R.K., H.S.M., J.N.E., N.G.L., C.M.L.L., S.C.S., M.U., G.P.V., and S.J.W. collected data and explored example outputs for use cases in patient care, research, and education.J.C., F.R.K. and H.S.M. curated and analyzed data, reviewed existing literature, and drafted the manuscript.Z.I.C. and J.N.K. revised and edited the manuscript.All authors read and approved the final version of the manuscript.Competing interestsThe authors declare the following competing interests: J.N.K. declares consulting services for Owkin, France; Panakeia, UK; and DoMore Diagnostics, Norway and has received honoraria for lectures from AstraZeneca, Bayer, Eisai, MSD, BMS, Roche, Pfizer and Fresenius.The other authors declare no competing interests.Additional informationSupplementary informationThe online version contains supplementary material available at https://doi.org/10.1038/s43856-023-00370-1.Correspondence and requests for materials should be addressed to Jakob Nikolas Kather.Peer review information Communications Medicine thanks Travis Zack and the other anonymous reviewer(s) for their contribution to the peer review of this work.A peer review file is available.Reprints and permission information is available at http://www.nature.com/reprintsPublisher's note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.
Understanding the capabilities, limitations, and societal impact of large language models. A Tamkin, M Brundage, J Clark, D Ganguli, 10.48550/arXiv.2102.025032021Preprint at arXiv</p>
<p>Large language models encode clinical knowledge. K Singhal, Nature. 6202023</p>
<p>Considering the possibilities and pitfalls of Generative Pre-trained Transformer 3 (GPT-3) in healthcare delivery. D M Korngiebel, S D Mooney, NPJ Digit. Med. 4932021</p>
<p>Using cognitive psychology to understand GPT-3. M Binz, E Schulz, Proc. Natl Acad. Sci. USA. 120e22185231202023</p>
<p>Capabilities of GPT-4 on medical challenge problems. H Nori, N King, S M Mckinney, D Carignan, E Horvitz, 10.48550/arXiv.2303.133752023Preprint at arXiv</p>
<p>Performance of ChatGPT on USMLE: potential for AIassisted medical education using large language models. T H Kung, PLoS Digit. Health. 2e00001982023</p>
<p>Pile of law: learning responsible data filtering from the law and a 256GB open-source legal dataset. P Henderson, 10.48550/arXiv.2207.002202022Preprint at arXiv</p>
<p>Data governance in the age of large-scale data-driven language technology. Y Jernite, Proc. 2022 ACM Conference on Fairness, Accountability, and Transparency. 2022 ACM Conference on Fairness, Accountability, and TransparencyAssociation for Computing Machinery2022</p>
<p>ChatGPT: five priorities for research. E A M Van Dis, J Bollen, W Zuidema, R Van Rooij, C L Bockting, Nature. 6142023</p>
<p>ChatGPT utility in healthcare education, research, and practice: systematic review on the promising perspectives and valid concerns. M Sallam, Healthcare. 118872023</p>
<p>SciBERT: a pretrained language model for scientific text. I Beltagy, K Lo, A Cohan, 10.18653/v1/D19-1371Proc. 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing. 2019 Conference on Empirical Methods in Natural Language essing and the 9th International Joint Conference on Natural Language essingAssociation for Computational Linguistics2019</p>
<p>BERT: pre-training of deep bidirectional transformers for language understanding. J Devlin, M.-W Chang, K Lee, K Toutanova, 10.18653/v1/N19-1423Proc. 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. Long and Short Papers. 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesAssociation for Computational Linguistics20191</p>
<p>BioBERT: a pre-trained biomedical language representation model for biomedical text mining. J Lee, Bioinformatics. 362020</p>
<p>Improving language understanding by generative pre-training. A Radford, K Narasimhan, T Salimans, I Sutskever, 2018</p>
<p>Using DeepSpeed and Megatron to train Megatron-Turing NLG 530B, a large-scale generative language model. S Smith, 10.48550/arXiv.2201.119902022Preprint at arXiv</p>
<p>PaLM: scaling language modeling with pathways. A Chowdhery, J. Mach. Learn. Res. 241132023</p>
<p>OPT-IML: scaling language model instruction meta learning through the lens of generalization. S Iyer, 10.48550/arXiv.2212.120172022Preprint at arXiv</p>
<p>Optimizing Language Models for Dialogue. Openai, Chatgpt, 2022</p>
<p>Learning to summarize from human feedback. N Stiennon, Proc. 34th International Conference on Neural Information Processing Systems. 34th International Conference on Neural Information essing SystemsCurran Associates Inc2020</p>
<p>Scaling laws for reward model overoptimization. L Gao, J Schulman, J Hilton, PMLR. 2022023</p>
<p>. 10.48550/arXiv.2303.087742023OpenAIGPT-4 Technical ReportPreprint at arXiv</p>
<p>Sparks of artificial general intelligence: early experiments with GPT-4. S Bubeck, 10.48550/arXiv.2303.127122023Preprint at arXiv</p>
<p>S Huffman, J Woodward, PaLM API &amp; MakerSuite: an approachable way to start prototyping and building generative AI applications. 2023</p>
<p>LLaMA: open and efficient foundation language models. H Touvron, 10.48550/arXiv.2302.139712023</p>
<p>Alpaca: A Strong. R Taori, Replicable Instruction-Following Model. 2023</p>
<p>W Chiang, An Open-Source Chatbot Impressing GPT-4 with 90%* ChatGPT Quality. 2023</p>
<p>. Chatgpt Openai, Plugins, 2023</p>
<p>Deficits in communication and information transfer between hospital-based and primary care physicians: implications for patient safety and continuity of care. S Kripalani, JAMA. 2972007</p>
<p>Quantifying the economic impact of communication inefficiencies in U.S. hospitals. R Agarwal, D Z Sands, J D Schneider, J. Healthc. Manag. 552010</p>
<p>How does ChatGPT perform on the United States medical licensing examination? The implications of large language models for medical education and knowledge assessment. A Gilson, JMIR Med. Educ. 9e453122023</p>
<p>Biases in electronic health record data due to processes within the healthcare system: retrospective observational study. D Agniel, I S Kohane, G M Weber, BMJ. 36114792018</p>
<p>On second thought, let's not think step by step! Bias and toxicity in zero-shot reasoning. O Shaikh, H Zhang, W Held, M Bernstein, D Yang, Proc. 61st Annual Meeting of the Association for Computational Linguistics. Long Papers. 61st Annual Meeting of the Association for Computational LinguisticsAssociation for Computational Linguistics20231</p>
<p>Paragraph-level simplification of medical texts. A Devaraj, I Marshall, B Wallace, J J Li, 10.18653/v1/2021.naacl-main.395Proc. 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesAssociation for Computational Linguistics2021</p>
<p>Comparing physician and artificial intelligence Chatbot responses to patient questions posted to a public social media forum. J W Ayers, 10.1001/jamainternmed.2023.1838JAMA Intern. Med. 2023</p>
<p>Four minutes for a patient, twenty seconds for a relative-an observational study at a university hospital. G Becker, BMC Health Serv. Res. 10942010</p>
<p>A pilot study of a medical information service using mobile phones in Sweden. A Börve, R Molina-Martinez, J. Telemed. Telecare. 152009</p>
<p>Smartphone teledermoscopy referrals: a novel process for improved triage of skin cancer patients. A Börve, Acta Derm. Venereol. 952015</p>
<p>The development of the Pan American Health Organization digital health specialist on alcohol use. M G Monteiro, D Pantani, I Pinsky, T A Hernandes Rocha, Front. Digit. Health. 49481872022</p>
<p>Using the Pan American Health Organization digital conversational agent to educate the public on alcohol use and health: preliminary analysis. M G Monteiro, D Pantani, I Pinsky, T A Hernandes Rocha, JMIR Form. Res. 7e431652023</p>
<p>Dermatologists' perceptions on the utility and limitations of teledermatology after examining 55,000 lesions. Giavina Bianchi, M Santos, A Cordioli, E , J. Telemed. Telecare. 272021</p>
<p>Impact of language barriers on quality of care and patient safety for official language minority francophones in Canada. D De Moissac, S Bowen, J. Patient Exp. 62019</p>
<p>Use and effectiveness of interpreters in an emergency department. D W Baker, R M Parker, M V Williams, W C Coates, K Pitkin, JAMA. 2751996</p>
<p>Robust speech recognition via large-scale weak supervision. A Radford, PMLR. 2022023</p>
<p>What ChatGPT and generative AI mean for science. C Stokel-Walker, V Noorden, Nature. 6142023</p>
<p>ChatGPT listed as author on research papers: many scientists disapprove. C Stokel-Walker, Nature. 6132023</p>
<p>Tools such as ChatGPT threaten transparent science; here are our ground rules for their use. Nature. 6136122023</p>
<p>Quantity and/or quality? The importance of publishing many papers. U Sandström, P Van Den Besselaar, PLoS ONE. 11e01661492016</p>
<p>The pressure to publish pushes down quality. D Sarewitz, Nature. 5332016</p>
<p>Papers and patents are becoming less disruptive over time. M Park, E Leahey, R J Funk, Nature. 6132023</p>
<p>Evaluating large language models on medical evidence summarization. npj. L Tang, Digit. Med. 61582023</p>
<p>Structured prompt interrogation and recursive extraction of semantics (SPIRES): a method for populating knowledge bases using zeroshot learning. J H Caufield, 10.48550/arXiv.2304.027112023Preprint at arXiv</p>
<p>BioGPT: generative pre-trained transformer for biomedical text generation and mining. R Luo, Brief. Bioinform. 234092022</p>
<p>ChatGPT and the future of medical writing. S Biswas, Radiology. 307e2233122023</p>
<p>Comparing scientific abstracts generated by ChatGPT to real abstracts with detectors and blinded human reviewers. C A Gao, NPJ Digit. Med. 6752023</p>
<p>Could AI help you to write your next paper?. M Hutson, Nature. 6112022</p>
<p>The future of ChatGPT in academic research and publishing: a commentary for clinical and translational medicine. J Wen, W Wang, Clin. Transl. Med. 13e12072023</p>
<p>Flipped university class: a study of motivation and learning. Y Xiu, P Thompson, Int. J. Inf. Commun. Technol. Educ. 192020</p>
<p>New tools for online teaching and their impact on student learning. C Huguet, J Pearse, J Esteve, 10.4995/head21.2021.12811Proc. 7th International Conference on Higher Education Advances (HEAd'21). 7th International Conference on Higher Education Advances (HEAd'21)2021Universitat Politècnica de València</p>
<p>. 10.1038/s43856-023-00370-1PERSPECTIVECOMMUNICATIONS MEDICINE |. </p>
<p>. | Communications, 10.1038/s43856-023-00370-1|www.nature.com/commsmed20233141</p>
<p>AI bot ChatGPT writes smart essays-should professors worry. C Stokel-Walker, 10.1038/d41586-022-04397-7Nature. 2022</p>
<p>Critical thinking in E-learning environments. R G Saadé, D Morin, J D E Thomas, Comput. Human Behav. 282012</p>
<p>. T Susnjak, Chatgpt, 10.48550/arXiv.2212.092922022</p>
<p>Prompt programming for large language models: beyond the few-shot paradigm. L Reynolds, K Mcdonell, 10.1145/3411763.3451760Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems. Association for Computing Machinery2021</p>
<p>GPT-4 is here: what scientists think. K Sanderson, Nature. 6157732023</p>
<p>Language generation models can cause harm: so what can we do about it? An actionable survey. S Kumar, V Balachandran, L Njoo, A Anastasopoulos, Y Tsvetkov, Proc. 17th Conference of the European Chapter. 17th Conference of the European ChapterAssociation for Computational Linguistics2023</p>
<p>Improving text simplification with factuality error detection. Y Ma, S Seneviratne, E Daskalaki, Proc. Workshop on Text Simplification, Accessibility, and Readability (TSAR-2022). Workshop on Text Simplification, Accessibility, and Readability (TSAR-2022)Association for Computational Linguistics2022</p>
<p>Evaluating factuality in text simplification. A Devaraj, W Sheffield, B Wallace, J J Li, 10.18653/v1/2022.acl-long.506Proc. 60th Annual Meeting of the Association for Computational Linguistics. Long Papers. 60th Annual Meeting of the Association for Computational LinguisticsAssociation for Computational Linguistics20221</p>
<p>FairPrism: evaluating fairness-related harms in text generation. E Fleisig, Proc. 61st Annual Meeting of the Association for Computational Linguistics. Long Papers. 61st Annual Meeting of the Association for Computational LinguisticsAssociation for Computational Linguistics20231</p>
<p>Bigger data or fairer data? Augmenting BERT via active sampling for educational text classification. L Sha, Y Li, D Gasevic, G Chen, Proc. 29th International Conference on Computational Linguistics. 29th International Conference on Computational LinguisticsInternational Committee on Computational Linguistics2022</p>
<p>AI-generated medical advice-GPT and beyond. C E Haupt, M Marks, JAMA. 3292023</p>
<p>Large language model AI chatbots require approval as medical devices. S Gilbert, H Harvey, T Melvin, E Vollebregt, P Wicks, 10.1038/s41591-023-02412-6Nat. Med. 2023</p>
<p>Openai, ChatGPT Outage: Here's What Happened. March 20. 2023</p>
<p>Prompt injection attack on ChatGPT steals chat data. R Samoilenko, 2023</p>
<p>Large pre-trained language models contain human-like biases of what is right and wrong to do. P Schramowski, C Turan, N Andersen, C A Rothkopf, K Kersting, Nat. Mach. Intell. 42022</p>
<p>A large language model for electronic health records. X Yang, NPJ Digit. Med. 51942022</p>            </div>
        </div>

    </div>
</body>
</html>