<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-3460 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-3460</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-3460</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-80.html">extraction-schema-80</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <p><strong>Paper ID:</strong> paper-15898438</p>
                <p><strong>Paper Title:</strong> A General Knowledge Representation Model of Concepts</p>
                <p><strong>Paper Abstract:</strong> Knowledge is not a simple concept to define, and although many definitions have been given of it, only a few describe the concept with enough detail to grasp it in practical terms; knowledge is sometimes seen as a thing out in the real word waiting to be uncovered and taken in by the receptive mind; however, knowledge is not a thing to be encountered and taken in, no knowledge can be found in any mind without first have been processed by cognition. Knowledge is not something just to be uncovered or transmitted and stored, it has to be constructed. The construction of knowledge involves the use of previous knowledge and different cognitive processes, which play an intertwined function to facilitate the development of association between the new concepts to be acquired and previously acquired concepts. Knowledge is about information that can be used or applied, that is, it is information that has been contextualised in a certain domain, and therefore, any piece of knowledge is related with more knowledge in a particular and different way in each individual.</p>
                <p><strong>Cost:</strong> 0.016</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e3460.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e3460.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RTM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Representational Theory of the Mind</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Functional-level symbolic theory that concepts are mental objects or states (representations) with attributes; cognition manipulates these internal representations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Representational Theory of the Mind (RTM)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Concepts are stored as discrete symbolic representations (mental objects) with attributes; reasoning proceeds by manipulation of these symbols according to syntactic rules.</td>
                        </tr>
                        <tr>
                            <td><strong>level_of_analysis</strong></td>
                            <td>functional</td>
                        </tr>
                        <tr>
                            <td><strong>supporting_evidence</strong></td>
                            <td>Explains capacity for rule-like, compositional symbolic reasoning and underlies early symbolic AI systems; historical/philosophical arguments (Hobbes) and uses in knowledge engineering and semantic networks.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence_or_challenges</strong></td>
                            <td>Does not readily explain graded similarity effects, associative learning, or how symbols are grounded in perception/experience; criticized for neglecting sub-symbolic/connectionist phenomena.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_theories</strong></td>
                            <td>Contrasted with distributed/connectionist accounts (neural networks) which represent concepts as activation patterns; paper frames RTM as the basis for symbolic systems (semantic nets, rule systems, ontologies) and as complementary to other views.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_limitations_or_open_questions</strong></td>
                            <td>How symbolic representations are implemented in neural tissue (grounding), how they emerge from learning, and how to reconcile RTM with empirical findings of graded/associative behavior remain open.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A General Knowledge Representation Model of Concepts', 'publication_date_yy_mm': '2012-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3460.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e3460.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LOTH</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Language of Thought Hypothesis</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Proposal that thought has a combinatorial, language-like medium (a mental 'language') whose symbols and syntax support computation-like reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Language of Thought Hypothesis (LOTH)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Thoughts are encoded in an internal language (a system of symbols with syntax) enabling formal manipulation and computable reasoning; concepts correspond to expressions in this language.</td>
                        </tr>
                        <tr>
                            <td><strong>level_of_analysis</strong></td>
                            <td>functional</td>
                        </tr>
                        <tr>
                            <td><strong>supporting_evidence</strong></td>
                            <td>Explains systematicity and productivity of thought and supports symbolic AI implementations where reasoning is formalised; motivates rule-based systems and formal knowledge bases (e.g., CYC).</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence_or_challenges</strong></td>
                            <td>Empirical grounding is debated; connectionist models challenge the necessity of explicit symbols and syntax; difficulty explaining rapid learning and graded similarity effects.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_theories</strong></td>
                            <td>Presented as a higher-level extension of RTM and contrasted with connectionist/distributed models and constructivist accounts; LOTH motivates symbolic architectures (rules, frames, ontologies).</td>
                        </tr>
                        <tr>
                            <td><strong>notable_limitations_or_open_questions</strong></td>
                            <td>How the language-like representations are learned from sensory experience and how they interface with sub-symbolic neural processes are open questions.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A General Knowledge Representation Model of Concepts', 'publication_date_yy_mm': '2012-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3460.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e3460.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Connectionist</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Connectionist / Distributed Representation (Neural Networks)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Concepts are represented by distributed activation patterns across many simple units (neurons); learning changes connection weights to encode associations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Connectionist / Distributed Representation</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Conceptual knowledge is encoded as patterns of activation across networks of units; associations and similarity arise from weight configurations, and concepts are robust to partial damage.</td>
                        </tr>
                        <tr>
                            <td><strong>level_of_analysis</strong></td>
                            <td>functional</td>
                        </tr>
                        <tr>
                            <td><strong>supporting_evidence</strong></td>
                            <td>Accounts for graded typicality, similarity-based generalization, robustness to partial input, associative learning, and models of perceptual classification; inspires empirically successful neural-network models.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence_or_challenges</strong></td>
                            <td>Paper notes connectionist approaches typically do not capture causality or high-level compositional structure; require extensive training and are often 'black box' making symbolic interpretability and large-scale knowledge integration difficult.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_theories</strong></td>
                            <td>Contrasted with symbolic/semantic-network approaches: distributed models excel at pattern recognition/similarity but struggle with compositional, causal, and rule-governed reasoning that symbolic models capture.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_limitations_or_open_questions</strong></td>
                            <td>Scaling distributed models to represent very large explicit knowledge bases and capturing causal/compositional semantics without explicit symbolic structure remain challenges.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A General Knowledge Representation Model of Concepts', 'publication_date_yy_mm': '2012-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3460.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e3460.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Constructivist</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Constructivist Layered Association Theories (Vygotsky-style)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Functional/developmental account in which concepts emerge via layers of associations, from loosely coupled ideas to stable, high-level concepts through active construction.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Constructivist layered association theory</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Concepts are built through progressive organization of associative material into hierarchical layers; low-level loose associations aggregate into stable, abstract concept structures via active cognitive construction.</td>
                        </tr>
                        <tr>
                            <td><strong>level_of_analysis</strong></td>
                            <td>functional</td>
                        </tr>
                        <tr>
                            <td><strong>supporting_evidence</strong></td>
                            <td>Developmental observations (Vygotsky) and educational taxonomies (Bloom) showing progressive skill/concept formation, and empirical findings that prior knowledge scaffolds new concept acquisition.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence_or_challenges</strong></td>
                            <td>Less formalized mathematically; harder to implement directly in large-scale computational models without additional formal machinery; may not specify mechanistic neural implementation.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_theories</strong></td>
                            <td>Presented as complementary to connectionist theories (adds causality/probability/context) and as providing the developmental and contextual glue absent in pure symbolic or pure connectionist accounts.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_limitations_or_open_questions</strong></td>
                            <td>How to operationalize and computationally model the layered transition from loose associations to abstract concepts, and how such layers map onto brain substrates remains open.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A General Knowledge Representation Model of Concepts', 'publication_date_yy_mm': '2012-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3460.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e3460.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SemanticNet</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Semantic Networks (Symbolic associative networks)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Graph-based symbolic model where concepts are nodes and associations are labeled arcs; knowledge and meaning arise from network structure and link strengths.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Semantic network (symbolic associative graph)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Concepts are represented as nodes in a graph and relations/associations as directed, typed links (arcs); link strengths and types encode semantic relations, facilitating retrieval and similarity-based inference.</td>
                        </tr>
                        <tr>
                            <td><strong>level_of_analysis</strong></td>
                            <td>functional</td>
                        </tr>
                        <tr>
                            <td><strong>supporting_evidence</strong></td>
                            <td>Used successfully to model declarative knowledge, lexical resources (WordNet), and similarity-based reasoning; intuitive mapping to human association data and many NLP systems.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence_or_challenges</strong></td>
                            <td>Traditional semantic nets had limited relation expressivity (presence/absence only); scaling to multiple contexts and encoding causality/higher-order relations requires richer relation types (OAR, MultiNet); can become redundant without good design.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_theories</strong></td>
                            <td>Positioned as the symbolic counterpart to connectionist distributed representations; paper compares semantic networks to MM, MultiNet, OAR and ontology approaches emphasizing differences in context handling.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_limitations_or_open_questions</strong></td>
                            <td>Context sensitivity and representation of procedural/causal relations are challenging; choices about what information an association should hold (type, direction, domain) remain design questions.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A General Knowledge Representation Model of Concepts', 'publication_date_yy_mm': '2012-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3460.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e3460.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Frames/Scripts</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Frame and Script Theories (Minsky/Shank)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Structured symbolic schemas representing stereotyped situations (frames) or sequences/events (scripts) that integrate declarative attributes with procedural fragments for situation-based understanding.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Frame and Script theories</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Conceptual knowledge for stereotyped situations is stored as frames (structured slots plus procedural 'demons') or scripts (sequences for events/plans), enabling rapid inference and procedural guidance in familiar contexts.</td>
                        </tr>
                        <tr>
                            <td><strong>level_of_analysis</strong></td>
                            <td>functional</td>
                        </tr>
                        <tr>
                            <td><strong>supporting_evidence</strong></td>
                            <td>Explains human ability to apply stereotyped knowledge in common situations, supports episodic memory modeling and provides natural integration of procedural and declarative knowledge in AI systems.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence_or_challenges</strong></td>
                            <td>May lack flexibility for novel combinations and require many hand-authored frames/scripts; scaling and coverage issues for broad knowledge domains are problematic.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_theories</strong></td>
                            <td>Presented as a subtype of semantic/symbolic networks that explicitly embed procedures; contrasted with purely declarative semantic nets and with distributed models that lack explicit procedural slots.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_limitations_or_open_questions</strong></td>
                            <td>How frames/scripts are learned rather than hand-specified, and how they interface with sub-symbolic learning systems, are open challenges.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A General Knowledge Representation Model of Concepts', 'publication_date_yy_mm': '2012-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3460.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e3460.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Rule-based</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Rule-based (Production) Systems</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Procedural symbolic model where knowledge is encoded as condition-action rules (productions) that fire to produce behavior; commonly used to model skills and problem solving.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Rule-based (production) systems</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Procedural knowledge is represented as a library of rules of the form IF(condition) THEN(action); cognitive behavior arises from pattern-matching and rule-firing over working memory.</td>
                        </tr>
                        <tr>
                            <td><strong>level_of_analysis</strong></td>
                            <td>functional</td>
                        </tr>
                        <tr>
                            <td><strong>supporting_evidence</strong></td>
                            <td>Explains stepwise problem solving, skill execution, and many aspects of reasoning that are naturally expressed as condition-action mappings; influential in cognitive architectures (Soar, ACT-R).</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence_or_challenges</strong></td>
                            <td>Fragile when faced with noisy or incomplete inputs; difficult to scale hand-authoring of large rule sets; does not naturally capture graded similarity or associative learning.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_theories</strong></td>
                            <td>Complementary to semantic networks for declarative knowledge and to connectionist models for sub-symbolic learning; cognitive architectures integrate rule-based processing with other mechanisms.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_limitations_or_open_questions</strong></td>
                            <td>Learning new rules from experience and integrating probabilistic/graded knowledge into rule systems are ongoing research problems.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A General Knowledge Representation Model of Concepts', 'publication_date_yy_mm': '2012-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3460.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e3460.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Ontologies</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Ontologies (explicit conceptualizations for AI)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Formal, symbolic specifications of conceptualizations (types, relations, constraints) meant to make domain knowledge explicit and machine-interpretable (e.g., OWL-based).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Ontologies (formal conceptualizations)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Knowledge is represented as formally specified concepts, relations, constraints, and instances (often in first-order predicate logic or OWL), enabling shared semantics and automated reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>level_of_analysis</strong></td>
                            <td>functional</td>
                        </tr>
                        <tr>
                            <td><strong>supporting_evidence</strong></td>
                            <td>Enables interoperability in AI systems, facilitates controlled vocabularies, taxonomies and reasoning (used in semantic web, multi-agent protocols, and projects like CYC).</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence_or_challenges</strong></td>
                            <td>Debate over what qualifies as an ontology; scalability and usability problems (CYC complexity); rigid ontologies can fail to capture folk or contextual meanings (folksonomies vs ontologies).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_theories</strong></td>
                            <td>Viewed as a form of symbolic semantic network with formal constraints; compared to folksonomies and lightweight taxonomies in terms of expressivity and social construction.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_limitations_or_open_questions</strong></td>
                            <td>Balancing expressivity vs computability (OWL expressive levels), handling context-dependent meanings, and automated ontology acquisition remain open issues.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A General Knowledge Representation Model of Concepts', 'publication_date_yy_mm': '2012-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3460.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e3460.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CognitiveArch</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Cognitive Architectures (ACT-R, Soar, Unified Theories)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Architectural-level functional models that specify memory systems, representational formats, and production mechanisms to simulate human cognition across tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Cognitive architectures (e.g., ACT-R, Soar, Unified Theories of Cognition)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Integrated frameworks specifying modules (STM/LTM), representational formats (declarative chunks, procedural productions), and control/learning mechanisms to model human cognitive performance.</td>
                        </tr>
                        <tr>
                            <td><strong>level_of_analysis</strong></td>
                            <td>functional</td>
                        </tr>
                        <tr>
                            <td><strong>supporting_evidence</strong></td>
                            <td>Used to simulate large sets of empirical behavioral data across tasks (memory, problem solving, learning) and to operationalize theories for computational experiments; influential in AI and cognitive modeling.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence_or_challenges</strong></td>
                            <td>Complexity and parameter tuning can obscure mechanistic claims; architectures often combine symbolic and sub-symbolic elements and still struggle with open-ended learning and massive knowledge bases.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_theories</strong></td>
                            <td>Positioned as integrative frameworks that can incorporate symbolic (rule/frame) and sub-symbolic (learned weights) mechanisms; paper cites them as influential for knowledge-representation models.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_limitations_or_open_questions</strong></td>
                            <td>How to scale architectures to real-world knowledge sizes, represent context-sensitive conceptual change, and ground symbolic elements neurally are unresolved.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A General Knowledge Representation Model of Concepts', 'publication_date_yy_mm': '2012-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3460.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e3460.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Memory Map (MM) model</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A context-focused directed-graph knowledge representation that models concepts (Concept-RUs) and skills (Skill-RUs) as nodes connected by typed, domain-tagged associations carrying role, directionality and strength.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Memory Map (context-tagged directed semantic graph)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Concepts and skills are represented as Representation Units (Concept-RU, Skill-RU); associations between RUs carry roles, domain tags and quantitative strengths, allowing a single RU to have multiple context-dependent meanings by selecting domain-tagged subsets of associations.</td>
                        </tr>
                        <tr>
                            <td><strong>level_of_analysis</strong></td>
                            <td>functional</td>
                        </tr>
                        <tr>
                            <td><strong>supporting_evidence</strong></td>
                            <td>Paper reports conceptual/engineering support: MM implemented as directed graph, compared to MultiNet and OAR for context flexibility; applied in a prototype Advanced Learning Environment for personalization and affective-adaptive sequencing with preliminary mapping and tests described.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence_or_challenges</strong></td>
                            <td>No neural or large-scale empirical cognitive validation presented; potential for contradictions and cycles when merging domains; computability issues when contexts combine (OWL-like problems); relies on manual authoring/editing and domain tagging.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_theories</strong></td>
                            <td>Compared directly with MultiNet and OAR: MM emphasizes re-use of the same concept nodes across contexts (domain-tagged associations) whereas other models often reinstantiate concept instances per context; MM is positioned as hybrid between symbolic and distributed local representations because attributes are mostly contextual associations.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_limitations_or_open_questions</strong></td>
                            <td>How MM maps to brain mechanisms is unaddressed; scalability and automated acquisition of associations/domains, conflict resolution when combining domains, and empirical validation of cognitive fidelity are open issues.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A General Knowledge Representation Model of Concepts', 'publication_date_yy_mm': '2012-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>The Language of Thought <em>(Rating: 2)</em></li>
                <li>Thought and Language <em>(Rating: 2)</em></li>
                <li>Semantic Information Processing <em>(Rating: 2)</em></li>
                <li>An integrated theory of the mind <em>(Rating: 2)</em></li>
                <li>Unified Theories of Cognition <em>(Rating: 2)</em></li>
                <li>A Framework for Representing Knowledge <em>(Rating: 2)</em></li>
                <li>A connectionist approach to knowledge representation and limited inference <em>(Rating: 2)</em></li>
                <li>The OAR Model of Neural Informatics for Internal knowledge Representation in the Brain <em>(Rating: 2)</em></li>
                <li>Layer Structures and Conceptual Hierarchies in Semantice Representation for NLP <em>(Rating: 1)</em></li>
                <li>Mapping ontologies into Cyc <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-3460",
    "paper_id": "paper-15898438",
    "extraction_schema_id": "extraction-schema-80",
    "extracted_data": [
        {
            "name_short": "RTM",
            "name_full": "Representational Theory of the Mind",
            "brief_description": "Functional-level symbolic theory that concepts are mental objects or states (representations) with attributes; cognition manipulates these internal representations.",
            "citation_title": "",
            "mention_or_use": "mention",
            "theory_name": "Representational Theory of the Mind (RTM)",
            "theory_description": "Concepts are stored as discrete symbolic representations (mental objects) with attributes; reasoning proceeds by manipulation of these symbols according to syntactic rules.",
            "level_of_analysis": "functional",
            "supporting_evidence": "Explains capacity for rule-like, compositional symbolic reasoning and underlies early symbolic AI systems; historical/philosophical arguments (Hobbes) and uses in knowledge engineering and semantic networks.",
            "counter_evidence_or_challenges": "Does not readily explain graded similarity effects, associative learning, or how symbols are grounded in perception/experience; criticized for neglecting sub-symbolic/connectionist phenomena.",
            "comparison_to_other_theories": "Contrasted with distributed/connectionist accounts (neural networks) which represent concepts as activation patterns; paper frames RTM as the basis for symbolic systems (semantic nets, rule systems, ontologies) and as complementary to other views.",
            "notable_limitations_or_open_questions": "How symbolic representations are implemented in neural tissue (grounding), how they emerge from learning, and how to reconcile RTM with empirical findings of graded/associative behavior remain open.",
            "uuid": "e3460.0",
            "source_info": {
                "paper_title": "A General Knowledge Representation Model of Concepts",
                "publication_date_yy_mm": "2012-05"
            }
        },
        {
            "name_short": "LOTH",
            "name_full": "Language of Thought Hypothesis",
            "brief_description": "Proposal that thought has a combinatorial, language-like medium (a mental 'language') whose symbols and syntax support computation-like reasoning.",
            "citation_title": "",
            "mention_or_use": "mention",
            "theory_name": "Language of Thought Hypothesis (LOTH)",
            "theory_description": "Thoughts are encoded in an internal language (a system of symbols with syntax) enabling formal manipulation and computable reasoning; concepts correspond to expressions in this language.",
            "level_of_analysis": "functional",
            "supporting_evidence": "Explains systematicity and productivity of thought and supports symbolic AI implementations where reasoning is formalised; motivates rule-based systems and formal knowledge bases (e.g., CYC).",
            "counter_evidence_or_challenges": "Empirical grounding is debated; connectionist models challenge the necessity of explicit symbols and syntax; difficulty explaining rapid learning and graded similarity effects.",
            "comparison_to_other_theories": "Presented as a higher-level extension of RTM and contrasted with connectionist/distributed models and constructivist accounts; LOTH motivates symbolic architectures (rules, frames, ontologies).",
            "notable_limitations_or_open_questions": "How the language-like representations are learned from sensory experience and how they interface with sub-symbolic neural processes are open questions.",
            "uuid": "e3460.1",
            "source_info": {
                "paper_title": "A General Knowledge Representation Model of Concepts",
                "publication_date_yy_mm": "2012-05"
            }
        },
        {
            "name_short": "Connectionist",
            "name_full": "Connectionist / Distributed Representation (Neural Networks)",
            "brief_description": "Concepts are represented by distributed activation patterns across many simple units (neurons); learning changes connection weights to encode associations.",
            "citation_title": "",
            "mention_or_use": "mention",
            "theory_name": "Connectionist / Distributed Representation",
            "theory_description": "Conceptual knowledge is encoded as patterns of activation across networks of units; associations and similarity arise from weight configurations, and concepts are robust to partial damage.",
            "level_of_analysis": "functional",
            "supporting_evidence": "Accounts for graded typicality, similarity-based generalization, robustness to partial input, associative learning, and models of perceptual classification; inspires empirically successful neural-network models.",
            "counter_evidence_or_challenges": "Paper notes connectionist approaches typically do not capture causality or high-level compositional structure; require extensive training and are often 'black box' making symbolic interpretability and large-scale knowledge integration difficult.",
            "comparison_to_other_theories": "Contrasted with symbolic/semantic-network approaches: distributed models excel at pattern recognition/similarity but struggle with compositional, causal, and rule-governed reasoning that symbolic models capture.",
            "notable_limitations_or_open_questions": "Scaling distributed models to represent very large explicit knowledge bases and capturing causal/compositional semantics without explicit symbolic structure remain challenges.",
            "uuid": "e3460.2",
            "source_info": {
                "paper_title": "A General Knowledge Representation Model of Concepts",
                "publication_date_yy_mm": "2012-05"
            }
        },
        {
            "name_short": "Constructivist",
            "name_full": "Constructivist Layered Association Theories (Vygotsky-style)",
            "brief_description": "Functional/developmental account in which concepts emerge via layers of associations, from loosely coupled ideas to stable, high-level concepts through active construction.",
            "citation_title": "",
            "mention_or_use": "mention",
            "theory_name": "Constructivist layered association theory",
            "theory_description": "Concepts are built through progressive organization of associative material into hierarchical layers; low-level loose associations aggregate into stable, abstract concept structures via active cognitive construction.",
            "level_of_analysis": "functional",
            "supporting_evidence": "Developmental observations (Vygotsky) and educational taxonomies (Bloom) showing progressive skill/concept formation, and empirical findings that prior knowledge scaffolds new concept acquisition.",
            "counter_evidence_or_challenges": "Less formalized mathematically; harder to implement directly in large-scale computational models without additional formal machinery; may not specify mechanistic neural implementation.",
            "comparison_to_other_theories": "Presented as complementary to connectionist theories (adds causality/probability/context) and as providing the developmental and contextual glue absent in pure symbolic or pure connectionist accounts.",
            "notable_limitations_or_open_questions": "How to operationalize and computationally model the layered transition from loose associations to abstract concepts, and how such layers map onto brain substrates remains open.",
            "uuid": "e3460.3",
            "source_info": {
                "paper_title": "A General Knowledge Representation Model of Concepts",
                "publication_date_yy_mm": "2012-05"
            }
        },
        {
            "name_short": "SemanticNet",
            "name_full": "Semantic Networks (Symbolic associative networks)",
            "brief_description": "Graph-based symbolic model where concepts are nodes and associations are labeled arcs; knowledge and meaning arise from network structure and link strengths.",
            "citation_title": "",
            "mention_or_use": "mention",
            "theory_name": "Semantic network (symbolic associative graph)",
            "theory_description": "Concepts are represented as nodes in a graph and relations/associations as directed, typed links (arcs); link strengths and types encode semantic relations, facilitating retrieval and similarity-based inference.",
            "level_of_analysis": "functional",
            "supporting_evidence": "Used successfully to model declarative knowledge, lexical resources (WordNet), and similarity-based reasoning; intuitive mapping to human association data and many NLP systems.",
            "counter_evidence_or_challenges": "Traditional semantic nets had limited relation expressivity (presence/absence only); scaling to multiple contexts and encoding causality/higher-order relations requires richer relation types (OAR, MultiNet); can become redundant without good design.",
            "comparison_to_other_theories": "Positioned as the symbolic counterpart to connectionist distributed representations; paper compares semantic networks to MM, MultiNet, OAR and ontology approaches emphasizing differences in context handling.",
            "notable_limitations_or_open_questions": "Context sensitivity and representation of procedural/causal relations are challenging; choices about what information an association should hold (type, direction, domain) remain design questions.",
            "uuid": "e3460.4",
            "source_info": {
                "paper_title": "A General Knowledge Representation Model of Concepts",
                "publication_date_yy_mm": "2012-05"
            }
        },
        {
            "name_short": "Frames/Scripts",
            "name_full": "Frame and Script Theories (Minsky/Shank)",
            "brief_description": "Structured symbolic schemas representing stereotyped situations (frames) or sequences/events (scripts) that integrate declarative attributes with procedural fragments for situation-based understanding.",
            "citation_title": "",
            "mention_or_use": "mention",
            "theory_name": "Frame and Script theories",
            "theory_description": "Conceptual knowledge for stereotyped situations is stored as frames (structured slots plus procedural 'demons') or scripts (sequences for events/plans), enabling rapid inference and procedural guidance in familiar contexts.",
            "level_of_analysis": "functional",
            "supporting_evidence": "Explains human ability to apply stereotyped knowledge in common situations, supports episodic memory modeling and provides natural integration of procedural and declarative knowledge in AI systems.",
            "counter_evidence_or_challenges": "May lack flexibility for novel combinations and require many hand-authored frames/scripts; scaling and coverage issues for broad knowledge domains are problematic.",
            "comparison_to_other_theories": "Presented as a subtype of semantic/symbolic networks that explicitly embed procedures; contrasted with purely declarative semantic nets and with distributed models that lack explicit procedural slots.",
            "notable_limitations_or_open_questions": "How frames/scripts are learned rather than hand-specified, and how they interface with sub-symbolic learning systems, are open challenges.",
            "uuid": "e3460.5",
            "source_info": {
                "paper_title": "A General Knowledge Representation Model of Concepts",
                "publication_date_yy_mm": "2012-05"
            }
        },
        {
            "name_short": "Rule-based",
            "name_full": "Rule-based (Production) Systems",
            "brief_description": "Procedural symbolic model where knowledge is encoded as condition-action rules (productions) that fire to produce behavior; commonly used to model skills and problem solving.",
            "citation_title": "",
            "mention_or_use": "mention",
            "theory_name": "Rule-based (production) systems",
            "theory_description": "Procedural knowledge is represented as a library of rules of the form IF(condition) THEN(action); cognitive behavior arises from pattern-matching and rule-firing over working memory.",
            "level_of_analysis": "functional",
            "supporting_evidence": "Explains stepwise problem solving, skill execution, and many aspects of reasoning that are naturally expressed as condition-action mappings; influential in cognitive architectures (Soar, ACT-R).",
            "counter_evidence_or_challenges": "Fragile when faced with noisy or incomplete inputs; difficult to scale hand-authoring of large rule sets; does not naturally capture graded similarity or associative learning.",
            "comparison_to_other_theories": "Complementary to semantic networks for declarative knowledge and to connectionist models for sub-symbolic learning; cognitive architectures integrate rule-based processing with other mechanisms.",
            "notable_limitations_or_open_questions": "Learning new rules from experience and integrating probabilistic/graded knowledge into rule systems are ongoing research problems.",
            "uuid": "e3460.6",
            "source_info": {
                "paper_title": "A General Knowledge Representation Model of Concepts",
                "publication_date_yy_mm": "2012-05"
            }
        },
        {
            "name_short": "Ontologies",
            "name_full": "Ontologies (explicit conceptualizations for AI)",
            "brief_description": "Formal, symbolic specifications of conceptualizations (types, relations, constraints) meant to make domain knowledge explicit and machine-interpretable (e.g., OWL-based).",
            "citation_title": "",
            "mention_or_use": "mention",
            "theory_name": "Ontologies (formal conceptualizations)",
            "theory_description": "Knowledge is represented as formally specified concepts, relations, constraints, and instances (often in first-order predicate logic or OWL), enabling shared semantics and automated reasoning.",
            "level_of_analysis": "functional",
            "supporting_evidence": "Enables interoperability in AI systems, facilitates controlled vocabularies, taxonomies and reasoning (used in semantic web, multi-agent protocols, and projects like CYC).",
            "counter_evidence_or_challenges": "Debate over what qualifies as an ontology; scalability and usability problems (CYC complexity); rigid ontologies can fail to capture folk or contextual meanings (folksonomies vs ontologies).",
            "comparison_to_other_theories": "Viewed as a form of symbolic semantic network with formal constraints; compared to folksonomies and lightweight taxonomies in terms of expressivity and social construction.",
            "notable_limitations_or_open_questions": "Balancing expressivity vs computability (OWL expressive levels), handling context-dependent meanings, and automated ontology acquisition remain open issues.",
            "uuid": "e3460.7",
            "source_info": {
                "paper_title": "A General Knowledge Representation Model of Concepts",
                "publication_date_yy_mm": "2012-05"
            }
        },
        {
            "name_short": "CognitiveArch",
            "name_full": "Cognitive Architectures (ACT-R, Soar, Unified Theories)",
            "brief_description": "Architectural-level functional models that specify memory systems, representational formats, and production mechanisms to simulate human cognition across tasks.",
            "citation_title": "",
            "mention_or_use": "mention",
            "theory_name": "Cognitive architectures (e.g., ACT-R, Soar, Unified Theories of Cognition)",
            "theory_description": "Integrated frameworks specifying modules (STM/LTM), representational formats (declarative chunks, procedural productions), and control/learning mechanisms to model human cognitive performance.",
            "level_of_analysis": "functional",
            "supporting_evidence": "Used to simulate large sets of empirical behavioral data across tasks (memory, problem solving, learning) and to operationalize theories for computational experiments; influential in AI and cognitive modeling.",
            "counter_evidence_or_challenges": "Complexity and parameter tuning can obscure mechanistic claims; architectures often combine symbolic and sub-symbolic elements and still struggle with open-ended learning and massive knowledge bases.",
            "comparison_to_other_theories": "Positioned as integrative frameworks that can incorporate symbolic (rule/frame) and sub-symbolic (learned weights) mechanisms; paper cites them as influential for knowledge-representation models.",
            "notable_limitations_or_open_questions": "How to scale architectures to real-world knowledge sizes, represent context-sensitive conceptual change, and ground symbolic elements neurally are unresolved.",
            "uuid": "e3460.8",
            "source_info": {
                "paper_title": "A General Knowledge Representation Model of Concepts",
                "publication_date_yy_mm": "2012-05"
            }
        },
        {
            "name_short": "MM",
            "name_full": "Memory Map (MM) model",
            "brief_description": "A context-focused directed-graph knowledge representation that models concepts (Concept-RUs) and skills (Skill-RUs) as nodes connected by typed, domain-tagged associations carrying role, directionality and strength.",
            "citation_title": "here",
            "mention_or_use": "use",
            "theory_name": "Memory Map (context-tagged directed semantic graph)",
            "theory_description": "Concepts and skills are represented as Representation Units (Concept-RU, Skill-RU); associations between RUs carry roles, domain tags and quantitative strengths, allowing a single RU to have multiple context-dependent meanings by selecting domain-tagged subsets of associations.",
            "level_of_analysis": "functional",
            "supporting_evidence": "Paper reports conceptual/engineering support: MM implemented as directed graph, compared to MultiNet and OAR for context flexibility; applied in a prototype Advanced Learning Environment for personalization and affective-adaptive sequencing with preliminary mapping and tests described.",
            "counter_evidence_or_challenges": "No neural or large-scale empirical cognitive validation presented; potential for contradictions and cycles when merging domains; computability issues when contexts combine (OWL-like problems); relies on manual authoring/editing and domain tagging.",
            "comparison_to_other_theories": "Compared directly with MultiNet and OAR: MM emphasizes re-use of the same concept nodes across contexts (domain-tagged associations) whereas other models often reinstantiate concept instances per context; MM is positioned as hybrid between symbolic and distributed local representations because attributes are mostly contextual associations.",
            "notable_limitations_or_open_questions": "How MM maps to brain mechanisms is unaddressed; scalability and automated acquisition of associations/domains, conflict resolution when combining domains, and empirical validation of cognitive fidelity are open issues.",
            "uuid": "e3460.9",
            "source_info": {
                "paper_title": "A General Knowledge Representation Model of Concepts",
                "publication_date_yy_mm": "2012-05"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "The Language of Thought",
            "rating": 2,
            "sanitized_title": "the_language_of_thought"
        },
        {
            "paper_title": "Thought and Language",
            "rating": 2,
            "sanitized_title": "thought_and_language"
        },
        {
            "paper_title": "Semantic Information Processing",
            "rating": 2,
            "sanitized_title": "semantic_information_processing"
        },
        {
            "paper_title": "An integrated theory of the mind",
            "rating": 2,
            "sanitized_title": "an_integrated_theory_of_the_mind"
        },
        {
            "paper_title": "Unified Theories of Cognition",
            "rating": 2,
            "sanitized_title": "unified_theories_of_cognition"
        },
        {
            "paper_title": "A Framework for Representing Knowledge",
            "rating": 2,
            "sanitized_title": "a_framework_for_representing_knowledge"
        },
        {
            "paper_title": "A connectionist approach to knowledge representation and limited inference",
            "rating": 2,
            "sanitized_title": "a_connectionist_approach_to_knowledge_representation_and_limited_inference"
        },
        {
            "paper_title": "The OAR Model of Neural Informatics for Internal knowledge Representation in the Brain",
            "rating": 2,
            "sanitized_title": "the_oar_model_of_neural_informatics_for_internal_knowledge_representation_in_the_brain"
        },
        {
            "paper_title": "Layer Structures and Conceptual Hierarchies in Semantice Representation for NLP",
            "rating": 1,
            "sanitized_title": "layer_structures_and_conceptual_hierarchies_in_semantice_representation_for_nlp"
        },
        {
            "paper_title": "Mapping ontologies into Cyc",
            "rating": 1,
            "sanitized_title": "mapping_ontologies_into_cyc"
        }
    ],
    "cost": 0.016255,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>A General Knowledge Representation Model of Concepts</p>
<p>Carlos Ramirez 
DASL4LTD Research Group
Tec of Monterrey Campus Queretaro
Mexico</p>
<p>Benjamin Valdes 
DASL4LTD Research Group
Tec of Monterrey Campus Queretaro
Mexico</p>
<p>A General Knowledge Representation Model of Concepts
Selection of our books indexed in the Book Citation Index in Web of Science Core Collection (BKCI) Interested in publishing with us? Contact book.department@intechopen.com Numbers displayed above are based on latest data collected. For more information visit www.intechopen.com Open access books available Countries delivered to Contributors from top 500 universities International authors and editors Our authors are among the most cited scientists Downloads We are IntechOpen, the world's leading publisher of Open Access books Built by scientists, for scientists 12.2% 141,000 180M TOP 1% 154 5,700 3</p>
<p>Introduction</p>
<p>Knowledge is not a simple concept to define, and although many definitions have been given of it, only a few describe the concept with enough detail to grasp it in practical terms; knowledge is sometimes seen as a thing out in the real word waiting to be uncovered and taken in by the receptive mind; however, knowledge is not a thing to be encountered and taken in, no knowledge can be found in any mind without first have been processed by cognition. Knowledge is not something just to be uncovered or transmitted and stored, it has to be constructed. The construction of knowledge involves the use of previous knowledge and different cognitive processes, which play an intertwined function to facilitate the development of association between the new concepts to be acquired and previously acquired concepts. Knowledge is about information that can be used or applied, that is, it is information that has been contextualised in a certain domain, and therefore, any piece of knowledge is related with more knowledge in a particular and different way in each individual.</p>
<p>In this chapter, a model for the representation of conceptual knowledge is presented. Knowledge can have many facets, but it is basically constituted by static components, called concepts or facts, and dynamic components, called skills, abilities, procedures, actions, etc., which together allow general cognition, including all different processes typically associated to it, such as perceiving, distinguishing, abstracting, modelling, storing, recalling, remembering, etc., which are part of three primary cognitive processes: learning, understanding and reasoning (Ramirez and Cooley, 1997). No one of those processes can live isolated or can be carried out alone, actually it can be said that those processes are part of the dynamic knowledge, and dynamic knowledge typically requires of conceptual or factual knowledge to be used.</p>
<p>In the first section of this chapter, a review of the basic concepts behind knowledge representation and the main types of knowledge representation models is presented; in the second section, a deep explanation of the components of knowledge and the way in which they are acquired is provided; in the third section, a computer model for knowledge representation called Memory Map (MM) that integrates concepts and skills is explained, and in section four, a practical application for the MM in a learning environment is presented. </p>
<p>What is knowledge?</p>
<p>There is not a unified definition for the concept of knowledge, diverse definitions from different backgrounds and perspectives have been proposed since the old times; some definitions complement each other and some prove more useful in practical terms. In philosophy we find the very first definitions of knowledge, one of the most accepted ones was provided by Sir Thomas Hobbes in 1651: knowledge is the evidence of truth, which must have four properties: first knowledge must be integrated by concepts; second, each concept can be identified by a name; third, names can be used to create propositions, and fourth, such propositions must be concluding (Hobbes, 1969). Hobbes is also credited with writing the most intuitively and broadly used definition of concept in his book "Leviathan", Hobbes's definition has its origins in the traditional Aristotelian view of ideas; this is known as the Representational Theory of the Mind (RTM), till this day RTM continues to be used by most works in Cognitive Science. It must be taken into account that Hobbes's works were of a political, philosophical and religious nature, for this reason there is not one simple hard interpretation of RTM, in this work we will refer to the most common one which is the following: RTM states that knowledge is defined as the evidence of truth composed by conceptualisations product of the imaginative power of the mind, i.e., cognitive capabilities; ideas here are pictured as objects with mental properties, which is the way most people picture concepts and ideas as abstract objects. RTM is complemented at a higher cognitive level by the Language of Thought Hypothesis (LOTH) from Jerry Fodors proposed in the 70's (Fodors, 1975). LOTH states that thoughts are represented in a language supported by the principles of symbolic logic and computability, this language is different form the one we to use to speak, it is a separate in which we can write our thoughts and we can validate them using symbolic logic. This definition is much more useful for computer science including Artificial Intelligence and Cognitive Informatics, since it implies that reasoning can be formalised into symbols; hence thought can be described and mechanised, and therefore, theoretically a machine should be able to, at least, emulate thought. The idea that thought in itself has a particular language is not unique, in fact there are previous works such as Vygotsky's Language and Thought (1986) that propose a similar approach. The difference between Vygotsky's and Fodor's approach is that LOTH's is based on a logic system and logic systems can, to an extent, be used for computation, whereas Vygotsky's work is based more on his observations of experiments with children and how this affects their learning processes and general development. The first approach can be directly linked to knowledge in the hard branch of A.I., for example project CYC which will be discussed in future sections of this chapter, while the second one can be put to better use in the development of practical tools in soft A.I., such as in Intelligent Tutoring Systems and more application oriented agents.</p>
<p>Not as old as Philosophy but still directly relevant to knowledge is Psychology, particularly the branches of Psychology that study the learning process. In Psychology through more empirical methods, a vast number of theories to understand and interpret human behaviour in relation to knowledge have been developed, among the most relevant theories for knowledge representation systems are associative theories also referred to as connectionist theories, cognitive theories and constructivist theories. There is also a group of theories that study behaviour by itself know as behaviourist theories, these theories did have a strong impact on Psychology in general and how humans were perceived to learn. In their classic posture behaviourists do not contemplate an internal cognitive process, only external behaviour, i.e., www.intechopen.com A General Knowledge Representation Model of Concepts 45 behavioural responses to different stimulus, for this reason behaviourist theories cannot explain thought (Chomsky, 1967) or knowledge in the desired depth, and will not be studied here. Connectionist theories state that knowledge can be described as a number of interconnected concepts, each concept is connected through associations, these are the roots of semantics as means for knowledge representation (Vygotsky, 1986), i.e., what we know today as semantic knowledge representation. Semantic knowledge representation has been proven to be the main driver along with similarity behind reasoning for unstructured knowledge (Crisp-Bright, 2010), traditional connectionist approaches do not account for causality; they just focus on the presence or absence of associations and their quantity. This proves that connectionist theories are not wrong, but they still can't explain higher cognitive processes and therefore higher types of knowledge. Constructivist theories on the other hand do contemplate more complex reasoning drivers such as causality, probability and context. Most constructivist theories therefore complement connectionist approaches by stating that each group of associations integrate different layers of thought where the difference between in each level is the strength of the associations. As a result, the highest layer is the concept, i.e., an organised and stable structure of knowledge and the lowest layer are loosely coupled heaps of ideas (Vygotsky, 1986). This layered structure for knowledge and the way it is built is the reason why constructivism is so relevant to semantic knowledge, because it presents mechanisms complex enough to represent how semantic knowledge is built to our current understanding.</p>
<p>Cognitive Science has focused on modelling and validating previous theories from almost every other science ranging from Biology and Neuroscience to Psychology and Artificial Intelligence (Eysenck, 2010); because of this, Cognitive Science is positioned as the ideal common ground where knowledge definitions from all of the above disciplines can meet computer oriented sciences, this has in fact been argued by Laird in his proposition of mental models (Laird, 1980) though this theory in reasoning rather than in knowledge. Cognitive Science is therefore a fertile field for new theories or for the formalisation of previous ones through computer models (Marr, 1982). It is common for knowledge in this field to be described through equations, mathematical relations and computer models, for this reason approaches like connectionism in Psychology have been retaken through the modelling of neural networks and similar works (Shastri, 1988). In this more oriented computer approach knowledge is treated as the structure in terms of association's strength, we will discuss the approach with more detail in the following section. Other famous approaches in this field include Knowledge Space Theory (Doignon &amp; Falmagne, 1999) which defines knowledge as a group of questions which are combined with possible answers to form knowledge states. The possible permutations of operations through set theory of these states are used to create a congruent framework for knowledge, based on the assumption that knowledge can be described as questions and correct answers in its most basic form. Ackoff's (1989) distinction between data information and knowledge is helpful in providing a practical definition for knowledge in real life. Data are symbols without significance, such as numbers, information is data that also includes basic relations between such symbols in a way that provide meaning, and knowledge is context enriched information that can be used or applied, and serves a purpose or goal. Brown (1989) in her studies of knowledge transfer, states that knowledge in its learning continuum, is composed of theories, causal explanation, meaningful solutions and arbitrary solutions, where theories are networks of concepts, causal explanations are facts, meaningful solutions are isolated pieces of knowledge and arbitrary solutions are random decisions.</p>
<p>Fig. 1. Approaches to Knowledge Representation from different disciplines</p>
<p>As it shown in figure 1 there are several approaches to describe and define knowledge, though most of them come different fields we can compare them through Cognitive Science which has served as a common ground for similar issues in the past. What is of interest here is not to get the most complete specific definition, but a generic definition that can be worked with and used in a computer model. For this reason this work focuses on the common elements in every presented theory, these elements represent a common ground for knowledge representation and any system or model for knowledge representation should consider them:</p>
<p>i. Knowledge is composed of basic units, which we shall refer to as concepts. Some authors use attributes as basic units and others use network structures, however all of them agree on the existence of concepts. The approaches for representing those basic structures will be discussed in section 2.3. ii. Concepts have associations or relations to other concepts. On this point there is general consensus, the debate on associations is about the representational aspects regarding to the following issues: a) What information should an association contain and b) What elements should be used to describe such information i.e., type, directionality, name, intension, extension, among others. These characteristics will be addressed in section 2.3 and 4. iii. Associations and concepts build dynamic structures which tend to become stable through time. These structures are the factual or conceptual knowledge. The representation of such structures of knowledge is what varies most, in section 2.1 we will explore several different approaches used to model these structures.</p>
<p>From the consensus it can be assumed that these three key points are the core components of knowledge, other characteristics can be included to create more complete definitions, but www.intechopen.com A General Knowledge Representation Model of Concepts 47 these will be context dependent. With a basic notion of what knowledge is, more interesting questions can be posed in the following sections.</p>
<p>What types of knowledge do exist?</p>
<p>There are several ways to classify knowledge; the most common distinction is closely related to human memory: the memories related to facts and the memories related to processes, i.e., factual and procedural. Factual or declarative knowledge explains what things are e.g., the dogs eats meat or a dog has a tail. Procedural knowledge explains how things work for example what the dog needs to do in order to eat, e.g. if dog hungry -&gt; find food, then chew food, then swallow, then find more food if still hungry.</p>
<p>We use both types of knowledge in our everyday life; in fact it is hard to completely separate them; however, many computer models can only represent abstract ideal situations with simplified contexts in which each type of knowledge can be clearly identified, but trading off completeness for simplification. The three characteristics of knowledge, discussed in section 2, hold true for both types of knowledge, although they are easier to observe in declarative knowledge because on procedural knowledge concepts are integrated into processes, usually referred to as skills and competences, and the relations between them are imbued in rule sets. An example of declarative knowledge representation and procedural knowledge representation can be seen in figure 2. Another important distinction is between structured and unstructured knowledge, since this has a strong implication on our reasoning processes. Structured knowledge relies strongly on organisation and analysis of information using higher cognitive processes, unstructured knowledge relies in lower cognitive processes such as associative knowledge and similarity (Crisp-Bright, 2010;Redher, 2009;Sloman, 1996). In order for unstructured knowledge to become structured there needs to be a higher cognitive process involved in its acquisition and ordering knowledge such as taxonomy knowledge, domain knowledge, direction of causality, and description of the type of association, among others. Though some computer systems already do this in their knowledge representation such as semantic networks and Bayesian causality networks, they do so mainly on intuitive bases (Crisp-Bright A. K., 2010), where the particular reasoning process used is imbued in the heuristic or algorithm employed for information extraction and processing.</p>
<p>Both of these distinctions are important because they can strongly influence the way in which knowledge is represented, other common types of knowledge include domain specific knowledge which can be regarded as a categorisation of knowledge by subject, such as taxonomic knowledge domain, ecological knowledge domain and causality knowledge domain, among others (Crisp-Bright A.K., 2010).</p>
<p>What are knowledge representation models?</p>
<p>The purpose of understanding what knowledge is, and what types of knowledge exist, is to allow us to use it in artificial systems. This long standing ambition has been fuelled by the desire to develop intelligent technologies that allow computers to perform complex tasks, be it to assist humans or because humans cannot perform them. In this section it will be explained how knowledge can be used in computer systems by representing it through different knowledge representation models.</p>
<p>Knowledge representation is deeply linked to learning and reasoning processes, as Crisp-Bright states when defining knowledge as "the psychological result of perception, learning and reasoning" (2010). In other words, in order to have any higher level cognitive process, knowledge must be generated, represented, and stored. The works of Newell (1972Newell ( , 1982Newell ( , 1986Newell ( , 1994 and Anderson (1990Anderson ( , 2004 provide comprehensive explanations for the relations between these processes, as well as computer frameworks to emulate them. Both Newell's Unified theories of Cognition (1994) and Anderson's Adaptive Character of Thought (1990) theory have strongly influenced today's knowledge representation models in cognitive and computer sciences, examples include the components of the Cognitive Informatics Theoretical Framework (Wang, 2009). Models are representations of theories that allows us to run simulations and carry out tests that would render outputs predicted by the theory, therefore when we speak of knowledge representation models, we are referring to a particular way of representing knowledge that will allow the prediction of what a system knows and what is capable of with knowledge and reasoning mechanisms. Since most knowledge representation models have been designed to emulate the human brain and its cognitive processes, it is common to find knowledge representation models that focus on long term memory (LTM), short term memory (STM) or combine both types of memory (Newell, 1982).</p>
<p>Having computers that can achieve complex tasks such as driving a car require intelligence. Intelligence involves cognitive processes like learning, understanding and reasoning, and as has been said before, all of these processes require knowledge to support or guide them. As Cognitive Informatics states if computers with cognitive capabilities are desired (Wang, 2003), then computerised knowledge representations are required.</p>
<p>To understand how generic knowledge can be represented in abstract systems we must also understand the types of possible representations, it is important to consider that these representations are descriptions of the types of knowledge; therefore they are usually akin www.intechopen.com A General Knowledge Representation Model of Concepts 49 to particular types of knowledge. A helpful metaphor is to picture types of knowledge as ideas and types of representations as languages, not all languages can express the same ideas with the same quality, there are words which can only be roughly translated.</p>
<p>Types of knowledge representation models</p>
<p>A distinction should be made between types of knowledge and types of knowledge representation models. Types of knowledge were described in the section 2.1 as declarative vs. procedural and structured vs. unstructured. Types of models are the different ways each type of knowledge can be represented.</p>
<p>The types of representation models used for knowledge systems include distributed, symbolic, non-symbolic, declarative, probabilistic, ruled based, among others, each of them suited for a particular type of reasoning: inductive, deductive, analogy, abduction, etc (Russell &amp; Norvig, 1995). The basic ideas behind each type of knowledge representation model will be described to better understand the complex approaches in current knowledge representation models. Since this is a vast field of research, the focus will be directed to monotonic non probabilistic knowledge representations models.</p>
<p>Symbolic systems are called that way because they use human understandable representations based on symbols as the basic representation unit, each symbols means something i.e., a word, a concept, a skill, a procedure, an idea. Symbolic systems were in fact the original and predominant approach in AI until the late 80's (Haugeland, 1989). Nonsymbolic systems use machine understandable representations based on the configuration of items, such as numbers, or nodes to represent an idea, a concept, a skill, a word, nonsymbolic systems are also known as distributed system. Symbolic systems include structures such as semantic networks, rule based systems and frames, whereas distributed systems include different types neural or probabilistic networks, for instance. An example of a symbolic system in the way of semantic network and non-symbolic model in the way of a neural network can be seen in Figure 3. As their names states, semantic networks are concept networks where concepts are represented as nodes and associations are represented as arcs (Quillian, 1968), they can be defined as a graphical equivalent for propositional logic (Gentzen, 1935). This type of knowledge representation models rely strongly on similarity, contrast and closeness for conceptual representation or interpretation. In semantic networks, associations have a grade which represents knowledge or strength of the association; learning is represented by increasing the grade of the association or creating new associations between concepts. Semantic networks are commonly used to model declarative knowledge both in structured and an unstructured way, but they are flexi b l e e n o u g h t o b e u s e d w i t h p r o c e d u r a l knowledge. When modelling structured knowledge the associations must be directed and have information of causality or hierarchy. Figure 3 on the left shows an example of a semantic network. Semantic networks are based in traditional RTM and associative theories.</p>
<p>Ruled based systems are symbolic representation models focused in procedural knowledge, they are usually organised as a library of rules in the form of condition -action, e.g., if answer is found then stop else keep looking. Rule systems proved to be a powerful way of representing skills, learning and solving problems (Newell's &amp; Simon's, 1972, Anderson, 1990, rule based systems are frequently used when procedural knowledge is present. Rule systems might also be used for declarative knowledge generally with classification purposes, e.g., if it barks then is dog else not dog. The else component is not actually necessary, when there is no else component systems do nothing or go to the next rule, an example of a rules can be seen on the right side of figure 2.</p>
<p>A frame is a data-structure for representing a stereotyped situation (Minsky, 1975). Frames can be considered as a type of semantic network which mixes declarative knowledge and structured procedural knowledge. Frames are different from other networks because they are capable of including procedures (fragments of code) within each symbol. This means that each symbol in the network is a frame which contains a procedure, which is called a 'demon' (Minsky, 1975), and a group of attributes for the description of the situation. The idea behind the frame is to directly emulate human memory which stores situations that mix procedural and declarative knowledge. When we find ourselves in a situation similar to one we have lived before, we allude to the stereotype stored in our memory so we can know how to react to this new situation. This theory is an attempt at joining unifying several other approaches proposed by psychology, linguistics and Artificial Intelligence.</p>
<p>Very similar and contemporary theory to Minsky's theory of frames is Shank's theory of scripts. Scripts are language oriented as their name suggests they resemble a long sentence that describes an action. Scripts are part of the description of a larger plan or goal, which can also be used to model networks similar to those of semantic networks (Shank, 1975). Script theory was originally oriented toward the understanding of human language and focusing on episodic memory, he later used it in his Dynamic Memory Model (1982) to explain higher aspects of cognition. Since scripts and frames have theories resemble so much they are both treated as part of a same sub-group of semantic networks.</p>
<p>Neural networks are the most popular type of distributed knowledge representation models, instead of using a symbol to represent a concept they use an activation pattern over and entire network. A simple way to understand how neural networks work, is by looking at the place from where the idea came, i.e., the human brain. Humans have a number of www.intechopen.com neurons connected in a highly complex structure, each time a person thinks thousands or millions of neurons in a localised part of the brain activate. This pattern of activation can be used then to identify a concept or an idea; hence if a tiny specific part of the concept is lost, is does not affect the general idea because what matters is the overall pattern. The pattern is strengthened each time we think about it, we refer to this as training of a network. Neural Networks emulate this cognitive process of mental reconstruction.</p>
<p>Fig. 4. Frames as a type of symbolic representation.</p>
<p>As shown in the right side of figure 3, in a Neural Network attributes are used as basic inputs. The combination of these inputs will activate an input layer and will generate a pattern of propagation until it reaches the last layer where it will return the result of a function which could be a concept. Even though neural networks are very flexible and robust for knowledge representation of certain structures, they cannot be used for vast amount of knowledge, since they become too complex for implementation over a small amount of time. The second reason why neural networks are not used as large scale knowledge representation models is that they must be trained so they can learn the patterns which will identify specific concepts; this means that knowledge must be previously modelled as training sets before it can fed unto the net , thus it becomes unpractical for average knowledge retrieval. Also it is worth mentioning that the black box nature of the neural networks does not show to get to the knowledge, it only shows that some inputs will render this and that output ,i.e., its representation is non-symbolic. The real advantage of neural networks are their capacity to emulate any function, this implies that the entire network will specialize in that particular function therefore it cannot specialize on everything. Among the common types of Neural Network the following can be found: perceptrons which don not have hidden layers; Feed forward networks, back propagation and resilient propagation which are networks with the same structure but differ in the approach used to adjust the weights of the networks; Radio based function networks; Hopfield networks, which are bidirectional associative networks; and self-organizing feature maps, which are a kind of network that does not require much training per se; among others (Rojas 1996, Kriesel, 2011. Neural networks indeed are of very different natures but in the end they are all based on connectionist theory and are inspired on biological neural networks, in particular the human, brain science.</p>
<p>Ontologies remain a debate issue in two aspects, first as to what is to be considered an ontology, and second how it should be used in computer science (Weller, 2007). Some authors argue that simple hierarchical relations in a structure is not enough as to call it an ontology (Gauch &amp; et. al 2007), while others use these simple structures and argument they are (Weller, 2007). The most relevant insights in artificial intelligence as to how to define ontologies in computer systems are provided by Grubber: "An ontology is an explicit specification of a conceptualisation  A conceptualisation is an abstract, simplified view of the world that we want to represent For AI systems, what 'exists' is that which can be represented." (Gruber, 1993). Gruber also notes that "Ontologies are not about truth or beauty, they are agreements, made in a social context, to accomplish some objectives, it's important to understand those objectives, and be guided by them." (Gruber, 2003) However this definition has created a new debate since it also applies to folksonomies (Gruber, 2007), especially since ontologies and folksonomies (Medelyan &amp; Legg 2008) became popular in the context of semantic web through RDF and OWL (McGuiness &amp; Harmelen, 2004) specifications. Weller (2007) and Gruber (2007) present a deeper explanation of this debate as well as the differences and advantages of each of both folksonomies and ontologies. In practical sense ontology are flexible hierarchical structures that define in terms that a computer can understand, the relations between its elements, a language often used for this purpose is first order logic. In reality, ontologies have been used mostly as enhanced controlled vocabularies with associated functionalities and categorisation. Computational implementations of ontologies tend to resemble taxonomies or concept networks (Helbig, 2003, Chen 2009), i.e., semantic networks with formal conceptual descriptions for their associations, and therefore can be considered symbolic systems. Some examples of Ontology include those defined as part of an interaction communication protocol in multi agent systems (FIPA, 2000), those built though ontology edition tools for ontology web language (OWL) like protg which are used to build the semantic net, and project CYC which will be addressed in section 4.</p>
<p>All representation models presented satisfy the three basic characteristics placed above. Both symbolic and distributed systems recognise a concept as a unit of knowledge, the main difference between them is that one approach models it as a symbol and the other as a pattern. Both approaches agree on the need for associations between concepts and both recognise that the configuration of the associations also represents knowledge. It should be noted that some symbolic models like ontologies include instances as another layer for representation of the embodiment of a concept, however not every models includes them and therefor even though they will be mentioned in future sections they will not be included within the basic characteristics that all knowledge representation models have in common.</p>
<p>With this we conclude a basic introduction of what knowledge is and how it is represented in computers, now we will analyse each of the basic units that compose knowledge: concepts, skills and associations.</p>
<p>concepts, and procedural knowledge in higher cognitive scale can be used to represent skills. As was mentioned in section 1, this does not mean that any fact can be considered a concept or any procedure a skill, the inter-association between each of these components as well as the structures they build must also be considered. To get a deeper understanding of knowledge we now review each of these components in more depth.</p>
<p>Definition of concept</p>
<p>The definition of a concept is closely related to the discussion of knowledge, in fact most of the theories attempting to explain one also explain the other. The most traditional definitions of concepts are based on Aristotelian philosophy and can be considered as revisions and complements previous works in the same line, Representational Theory of the Mind (Hobbes, 1651) was the first formalisation of this philosophy and Language of Though hypothesis (Fodor, 2004) is the latest extension added to it.</p>
<p>The Representational Theory of the Mind (RTM) states concepts and ideas as mental states with attributes sometimes defined as images, the Language of Thought (LOT) hypothesis states that thoughts are represented in a language which is supported by the principles of symbolic logic and computability. Reasoning can be formalised into symbols and characters; hence it can be described and mechanised. In other words RTM states that concepts exist as mental objects with attributes, while LOT states that concepts are not images but words in a specific language of the mind subject to a unique syntax. A complete and practical definition of concept should be influenced by those two aspects, and therefore be as follows: A concept is considered as the representation of a mental object and a set of attributes, expressed through a specific language of the mind which lets it be represented through symbols or patterns which are computable. Such approach defines concepts as objects formed by a set of attributes, in the same atomic way as the Classic Theory of Concept Representation does (Osherson &amp; Smith, 1981), but also considers descriptive capabilities of the role of a concept in the same as the approach of Concepts as Theory Dependent (Carey, 1985;Murphy and Medin, 1985;Keil,1987). This definition is useful for declarative knowledge since it can be easily included to most existing models and remains specific enough to be computationally implemented as will be shown in section 4.</p>
<p>Definition of skill</p>
<p>Philosophic views such as (Dummet 1993, Kenny 2010 propose that abilities and concepts are the same thing, however, these approaches have not been very popular in computer and cognitive sciences, because of studies made in learning theories from Cognitive Science provide a more practical and empirical approach which instead support the Aristotelian view of concepts. Skills are practical manifestations of procedural knowledge, the most popular definitions of skills used today are based on constructivist theories and variations of Bloom's Taxonomy of Skills, this comes as a historic consequence of research in education, were skills is a core interest in educational psychology. Therefore, it is then not strange that the most referenced theories for skill development are found in this social science. Vygotsky's constructivist theory (Vygotsky, 1986) explains how skills are developed through a complex association process and upon construction of dynamic structures which can be traced through internal language or speech. Bloom's taxonomy for skills provides perhaps the most practical classification and enumeration of cognitive, social and physical www.intechopen.com Advances in Knowledge Representation 54 skills. The combination of those works establishes enough theoretical insight to build more complex models for skill representation, such as those used in Cognitive Informatics for the Real Time Process Algebra (Wang, 2002), Newell's Soar cognitive architecture (Newell, 1990) and Anderson's ACT-R cognitive architecture (Anderson, 1994).</p>
<p>In Thought and Language, Vygostky (1986) explains several processes used to learn and create ideas. Ideas stated as concepts and skills dynamic in nature behave as processes in continual development which go through three evolution stages starting at the basic stage of syncretism heaps, which are loosely coupled ideas through mental images, and concluding in formal abstract stable ideas, which are fully developed concepts and skills that manifest in language.</p>
<p>Benjamin Bloom (1956)  These observations imply that if there is a hierarchy in skills it must be dynamic in nature and this characteristic must be taken into account when defining what a skill is. The idea of flexible structure can also be found in Vygotsky's theories. In the framework for Cognitive Informatics, Wang (2002) proposes an entire system for describing processes, according to what we now know of procedural knowledge we can use such system to define skills in computational terms, thus under this train of thought skills are pieces of computer code located in an action buffer, such processes are composed by sub-processes and are described using Real Time Process Algebra (RTPA). RTPA is oriented to a structured approach where a skill is not as flexible as Kagan's observations suggest, the types of data, processes, metaprocesses and operations between skills, should be included in a comprehensive definition of skills.</p>
<p>Using constructivist theories as a basis, Bloom's taxonomies for organisation and the cognitive architectures for mappings to computational terms, a generic definition for skills in computer systems can be stated as: A cognitive process that interacts with one or more concepts as well as other skills through application and has a specific purpose which produces internal or external results. Skills have different degrees of complexity and may be integrated or composed by other skills. In contrast with concepts which are factual entities by nature, skills are process oriented, they are application/action related by nature and it is common to describe them using verbs.</p>
<p>Associations between concepts and skills</p>
<p>Of the three basic common characteristics of knowledge stated in section 1, perhaps the second characteristic: Concepts have relations or associations to other concepts, is the most agreed upon. Every theory and model reviewed so far agrees that associations are vital to knowledge (Hobbes, 1651, Fodors, 1975, Vygotsky, 1986, Bloom, 1956, Kagan, 2003 www.intechopen.com A General Knowledge Representation Model of Concepts 55 1990, Anderson, 1994, Quillian, 1968, Wang, 2002, Helbig, 2003; the differences appear when defining their properties and implications, these are better observed in cognitive or computer models, since more general theories tend to be vague in this regard and detailed specification is a requirement for computer models (Marr, 1982). Most declarative knowledge representation models rely on propositional logic or its graphical equivalents in network representations e.g., Cyc (Read &amp; Lenat, 2002), WordNet (Miller, 1990) , OAR (Wang, 2006), Multinet (Helbig, 2003) and Telos (Paquette, 1990) among others, the specific type of the network is determined by aspects such as directionality of associations (Helbig, 2003), the type of association (Wang, 2006), if the associations allows cycles, if they are hierarchical in nature (Paquette, 1990) or mixed and if there is a grouping or filtering scheme for them.</p>
<p>Traditional semantic networks only used presence or absence of associations; current semantic networks such as MultiNet or Object Attribute Relation OAR (Wang, 2007) provide deeper types of associations and integrate layers for knowledge composition. Examples of deeper type of association can be seen in MultiNet where associations are defined as a third type of node that contain procedural knowledge similar to Minsky frames, or OAR associations which are described as types of relations which can be grouped into several categories: Inheritances, Extension, Tailoring, Substitute, Composition, Decomposition, Aggregation and Specification. OAR categories are in fact operations for Concept Algebra (Wang, 2006), i.e., a mathematical way to describe how knowledge structures are integrated. Concept algebra does not include procedural k n o w l e d g e , f o r t h i s r e a s o n R T P A h a s a different set of associations which describe a hierarchy for composition of processes; both real time process and concept algebras are integrated in a higher framework called system algebra (Wang, 2009).</p>
<p>Associations are important because they create the context and embody semantic meaning for each context, some authors refer to this as sense (Vygostky, 1986), others discriminate between intrinsic knowledge, i.e., knowledge inherent to that concept, and context knowledge i.e., knowledge inferred from the associations and other concepts surrounding the original concept (Helbig, 2008). Understanding these approaches we can then summarise that an association is a relation between two elements, which can be skills or concepts that contain a particular function and a directionality that explains the nature of the relation. Groups of associations are what create contexts and each of these contexts may provide a uniquely different sense to a concept or skill which should reflect upon interpretation and inference process.</p>
<p>A model for the representation of concepts and skills In different contexts</p>
<p>An important functionality for knowledge representation models is the capacity to represent multiple contexts in a single instantiation, as well as the impact that context changes have on a concept's meaning. Approaches such as micro-theories models used in Cyc contemplate this and have successfully managed to combine multiple facts of a subjective nature into a coherent knowledge base, however, Cyc requires understanding of its own native language which is based on predicate logic semantics for information modelling and for information extraction as well, this has proven a problem for most users (Lenat, 2006). Simpler graphical representations which retain this context flexibility and can be represented in computers present an attractive alternative for average users, www.intechopen.com Advances in Knowledge Representation 56 such as domain experts not versed in CYC language. Graphical oriented models such as Multinet or OAR have been used for natural language processing and for knowledge composition and process specification respectively, but their focus is not to represent several contexts a time.</p>
<p>Multinet for example has specific context differentiation based on grammar attributes such as singular or plural elements, however, it does not have differentiators for the concepts meaning when the context changes. In these models when a new context is to be created only a small fraction of the information of concepts is reused and most of it has to be reinstantiated for each domain, this is a common trait of knowledge representation models that have instances as part of their model. OAR presents a similar situation since the context is defined as the relation between objects and its attributes in a given set (Wang, 2006). OAR is more flexible and does contemplate multiple contexts for the instantiations of the concepts, but not for the concepts themselves, which means that what are dynamic are not the concepts themselves but the objects in regard to the context. The implication for this is that a concept will have several different instantiations depending on the context, however this issue does not represent the impact the context has on the formation of a concept as was described by Vygotsky (1986).</p>
<p>The memory map model</p>
<p>The Memory Map (MM) is a knowledge representation model for concepts and skills, its main goal is to represent the interaction of these elements in different contexts, including the representation of concepts which meaning changes according to the context, i.e., semantic environments. The MM can be visualised as a semantic network which is compliant with the theoretical views presented in section 1 and 2. The main difference between the MM and other models is that the MM strongly focuses in context flexibility, because of this approach, in the MM concepts and skills must have an open granularity subject to the modeller's criteria; an arbitrary level of atomicity which can be specified for each concept, and dynamic hierarchies which can change for different domains of knowledge. The implementation of the MM is a directed graph, very similar to the more flexible types of semantic networks and to ontologies.</p>
<p>Memory map components</p>
<p>There are three main components in the MM which were developed using the theoretical bases for knowledge stated in section 1:</p>
<ol>
<li>Concepts referred to as Concept Representation Units (Concept-RU), they are represented as the round nodes in the network. 2. Skills referred to as Skill Representation Units (Skill-RU), they are represented as the round nodes in the network.</li>
</ol>
<p>Associations between the members of Concept-RUs, between the members of Skill-RUs</p>
<p>and associations among Concept-RUs and Skill-RUs, they are the arcs in the network.</p>
<p>Concept representation units</p>
<p>The basic definition for concept in the MM can be described by the elements of section 2. Syntactically, each concept is enclosed in its particular Concept-RU which has associations www.intechopen.com to other Skill-RUs and Concept-RUs. The attributes of concepts and skills together with their associations define their semantics, therefore any skill or concept is described and defined by the associations it has with other skills and concepts. This means that a Concept-RU has little intrinsic knowledge, and almost all the knowledge is provided from its context through its associations which are also its attributes. A concept's meaning changes depending on the group of attributes that are tagged for each different domain. Using the domain tags for attributes allows a Concept-RU to represent an indeterminate amount of meanings for that concept, since ultimately the concept is in fact a structure; an example of this is presented in figure 5, where the concept cell is represented for 3 different contexts: Biology, Buildings and Communications. A similar approach for attributes can be found in distributed systems with local representation (Eysenck, 2010), which could be closest thing to a hybrid representation model between the symbolic and the distributed systems. </p>
<p>where c is a concept with a name or identifier n, a set of attributes A, and a numerical level of knowledge x, where A is   12 3 n A a , a ,a , . a  (2) each a is an association from the concept to other concepts or skills, and n is the total number associations that the Skill-RU has. Two associated concepts or skills will share an association for each context, so the intersect i o n o f b o t h c o n c e p t s m u s t r e t u r n a l l t h e associations by which they are related. Hence if c a and c b are associated as follows:
        a1 2 3 n b1 2 3 n cn , a , a , aa , x c n, b ,b ,b b ,x 0  (3)
The context representation is handled within each association and will be explained in 4.2.4 and 4.3.</p>
<p>Skill representation units</p>
<p>In accordance to what was established in section 2, a skill in the MM is a cognitive process that interacts with one or more concepts and other skills, usually through application, which www.intechopen.com Advances in Knowledge Representation 58 has a specific purpose and produces a certain result, be it internal or external. Skills have different degrees of complexity and can be integrated with other skills. Skills are process oriented, they are action related by nature, for this reason they are described using verbs. Figure 5 shows the representation for two different versions of Bloom's taxonomy, versions of skills can also be modelled as different contexts, this way combinations of trees and domains of concepts can be used to model knowledge domains in a flexible way re-using most of the information already contained in the model. To represent the dynamicity described by Vygotsky, Skill-RU have knowledge levels which indicate how evolved a Skill-RU or a Concept-RU is, this number can be mapped using thresholds to indicate if a structure is weak, i.e., syncretic or strong and stable, i.e., conceptual. The way in which knowledge is extracted and calculated is explained in 4.2.4. Fig. 6. The structure to the left is a skill representation in the MM of a segment of Bloom's (1956) original taxonomy based on keywords, the structure to the right is a representation of a revision made in 2001 of Bloom's work (L. Anderson et al., 2001).</p>
<p>In a formal definition a Skill-RU is similar to the Concept-RU, the main difference is the type of associations skills have which reflect a more application oriented nature. A skill is defined as follows:
  sn , A , x(4)
Two associated concepts or skills will share an association for each different context, so the intersection of both skills must return all the associations by which they are related. Hence if Sa and Sb are associated:
        a1 2 3 n b1 2 3 n sn , a , a , aa , x s n, b ,b ,b b ,x 0   (5)</p>
<p>Associations</p>
<p>Skill-RUs and Concept-RUs are the constituents in the MM and are glued through associations, there is only one restriction in the associations and that is that only Skill-RUs can have application oriented roles. Skill-RUs and Concept-RUs have independent organisation structures within the MM structure, this is used to represent composition of skill and of concepts as is shown in figure 7. The purpose of the associations is to represent how concepts and skills relate to each other to generate knowledge. Knowledge is not only a group of stored concepts, but the structure of associations itself. An association therefore must:</p>
<p> Provide information of the nature of the relation, knowing that the nature of a relation allows us to understand how the structure is to behave and enables more complex reasoning processes.  Provide information of the directionality of causality, the inheritance of attributes in directly dependent on this factor, when we say inheritance of attributes we also mean inheritance of associations. </p>
<p>Provide information as to the domain where it is valid, so the structure can be context sensitive and discriminate which associations hold true for a domain and which do not.  Provide quantitative information of the strength of the association, knowing the strength of an association will allow probabilistic estimation of how much is known of a concept or skill, this is letting the structure know how much does it know regarding that specific relation.</p>
<p>An association a is defined as a relationship between two representation units which may be either a Concept-RU or a Skill-RU, the first unit is predecessor pre and the second is successor suc. The association role r contains specific information that describes the nature of the relationship and the set of domains D where the association holds true and y indicates the strength of the association.</p>
<p> </p>
<p>pre, suc a u u , r, D, y</p>
<p>where u represents a unit which might either be a concept or a skill, this holds true for groups as well: An example of associations with the information attributes presented above is presented in figure 8. Two representation units can share more than one association as is shown in figure 9, the only restriction is that there can only be one association per domain with the same role and between the same RUs, this avoids two things: the first is direct contradictions within the same domain in case the directionality for that role is inversed, the second is redundancy of information in the case of two associations with the same directionality and the same role which will result in unnecessary repeated information.  can be freely defined and integrated into the model as long as they have a consistent functionality; MultiNet presents a similar approach for its types of relations (Helbig, 2003), the main difference being that MultiNet focuses on natural language and requires more types of relation to describe lexical and grammatical rules. A solid and economic base to describe knowledge composition can be found in OARs types of associations, with only 8 types of associations and an instantiation OAR provides congruent mathematical explanations of concept composition.  A graphical representation of how each association role is presented in figure 10. 
     </p>
<p>Context and inter context associations</p>
<p>Context is the embodiment of semantic knowledge, that is, the way in which groups of ideas are associated. In the MM a context is the body of knowledge composed by one or more domains of knowledge, associations are subject to the domains they belong to, an association between two RUs must belong to at least one domain, using the combination of multiple domains different contexts may be built. A domain cannot present a contradiction within itself, however built contexts can present contradictions since each domain included in a context may have contradictory knowledge in the form of a same rol with inverse directionality, because of this when combining several domains into a mixed context, priority mechanisms for contradictions should be defined as well. Contradictions may generate problems such as creating cyclic structure in MM, this is a common problem for flexible low restriction model like Ontology Web Language OWL (McGuinness &amp; Harmelen, 2004). OWL in its first two levels establishes mainly treelike structures, but at its most expressive and flexible level OWL cannot guaranty computability (McGuinness &amp; Harmelen, 2004), this seems to be a common fault for which workarounds can be made in implementations such as memory stacks or limits in searches, but there seems to be no model solution in sight which does not compromise the models flexibility.</p>
<p>Knowledge extraction</p>
<p>If the model used for knowledge representation is flexible enough then complex information may be extracted using simple functions or algorithms, such is the case of the MM. Queries or knowledge extraction in the model are performed through simple unguided recursive searches that return relevant segments of the MM, it must be stated that the main focus of this knowledge representation model is to be able to easily Where n is the number of existing concepts or skill levels that the search can reach, m is the number of existing roles and l is the number of existing domains. The function in turn will return a group of associations, because the associations themselves represent the structure of knowledge that is sought. We now provide different examples of how the function works for some of the questions presented above:</p>
<p>What does this MM know? If the MM is queried with function setting as parameter n, m, and l, then the function returns the whole MM as is shown in figures 11, 12 and 13.-What is concept www.intechopen.com</p>
<p>A General Knowledge Representation Model of Concepts 63</p>
<p>A composed of or what class does it belong to? If the MM is queried with the function from i to n, the search will return a structure of units for a domain k with the role j, as is shown in figure  10. This represents a hierarchy or a chain of composition, though this will be subject to what role j is. Fig. 11. The search result for an every concept or limitless search with one role and in one domain.</p>
<p>What are the attributes of concept A? If the MM is queried with the function from j to m, the search will return every role associated to the concept i in the domain k, as is shown in figure 12. This represents the direct attributes of the central concept. What attributes does concept A hold for in different domains? If the MM is queried with the function from k to l, the search will return every association with role j associated to the concept i in every domain, as is shown in figure 13. This represents every possible meaning the concept might take in a completely open context. The rest of the questions can be answered with combinations of these criteria.</p>
<p>Knowledge acquisition</p>
<p>New knowledge is acquired by associating it to previous knowledge. Acquisition in the MM also follows this principle, new representation units must be integrated with the main body of representation units that are already known, this follows also the constructivist principle that knowledge is constructed upon more knowledge, hence the more we know the easier it is to learn and retain knowledge in long term memory. This approach establishes then some restrictions:</p>
<p></p>
<p>For a concept or skill to be considered as part of knowledge it must be associated to the structure of knowledge. A domain can appear to have sparsity, i.e., secluded knowledge, however it is because there is an association that link's that concept or skill to the whole structure which cannot be seen because it is part of a different domain. Though the domain seems disconnected, other domains complement it in a natural way and therefore the MM is congruent in general. A real life example of this can be seen in academic courses where requirements come from different fields, e.g., knowledge of programming as well as propositional logic are required for the understanding of artificial intelligence, though they might not be directly related between each other, a novice's MM in the domain of artificial intelligence would appear fragmented since some of the concepts would not be yet related through this domain, however, knowledge of both programming and logic must be associated through other currently www.intechopen.com hidden domains in the novice's MM because they cannot be completely secluded. If knowledge is found to be completely secluded through every context then this represents a memorised fact instead of knowledge.  Associations must always be linked to representation units, an association cannot be linked to an empty unit or remain unlinked.  If a new concept or skill is to be integrated, then the representation units must be created first and the association later. If a structure is to be integrated, then this process is repeated recursively for each unit of the structure.</p>
<p>In general the integration of new knowledge to the structure is described in figure 14. </p>
<p>Knowledge measuring</p>
<p>Knowledge measuring in the MM is subject to context, only in few occasions will it be desired to know all the information from a concept in every domain, most of the time the interest will be in knowing the level of knowledge for a concept in regard to a context. There are two scenarios for knowledge measuring: the first when knowledge is measured in an absolute way, and second when knowledge is measured through a query. The differences between them will now be explained.</p>
<p>To know the general knowledge grade of a concept the average of numeric value v of each association is multiplied by an associative factor determined by:
  Associative Factor 1# @ * 0 . 1  (9)
where #@ is the number of selected associations, the factor represents the increment of impact of a more associated concept, this means that if two concepts have the same average of association strength, the associative factor will give a higher grade to the more associated </p>
<p>where v is the numerical value of a group of associations that were selected.</p>
<p>When measuring knowledge for the general case, 10 will be used for the concept with every existing association, when measuring knowledge for a specific context only those associations included in the domains will be used, therefore a concept will have a different knowledge value for each context. When measuring the knowledge of a group of representation units, a similar approach is used:
      Segment K level Average RUK level * 1 #RU * 0.1   (11)
Where RU level is the representation unit knowledge level, and the average of all the selected concepts are multiplied by a factor determined by representation units, hence if two segments have an equal amount of knowledge level in their representation units, then the segment having more representation units, i.e., concepts and skills is said to have more knowledge.</p>
<p>Properties of the MM</p>
<p>The fact that every attribute is considered as a mixture between a concept and an association in the memory and that depending on the current context, this change generates properties which make the MM flexible and expressive:</p>
<p> Open/Unlimited Granularity. Since the composition of knowledge is a network structure, there can be an indeterminate number of levels to specify composition. A field expert can determine the level of granularity specification for any unit, this means different units within the structure can have different granularities.  Dynamic Hierarchy. Concept and skill representation units can be integrated into proper hierarchies through roles and directionality of associations; a unit can be placed in several taxonomies, i.e., in several hierarchies, where each hierarchy belongs to a different context, the combination of several domains with different hierarchy structures generate in turn new hierarchies, making the hierarchies dynamic and context dependent. This enables the use of semantic information contained in the taxonomy for a context that includes that taxonomy.  Economy of Knowledge. The structure is developed in a way to avoid information redundancy, i.e. the same nodes are used for different knowledge structures, each one of them delimited by a different context.  Informativeness Capability. There is no limit to the amount of Concept-RUs or Skill-RUs in a structure, nor is there a limit to the depth of the knowledge represented, that is, there is no limit for the hierarchy of attributes and associations.  Flexibility. The structure can create associations between any Concept-RU and Skill-RU, and each association can have several roles each offering a unique behaviour. </p>
<p>Application of the MM in an advanced learning environment</p>
<p>The problems and challenges found in the development of smart tools for education remain attractive and closely linked to knowledge representation models in general, for this reason the MM was instrumented as part of an Advance Learning Environment where it is used for the adaptation of learning resources. The adaptation is done through user profiles that contain user knowledge, interest, learning styles and emotional profiles. Similar approaches have been presented in (Carchiolo, Longheu &amp; Malgeri, 2002, Van Marcke, 1998 where integral user profiles are used to model generic personalisation of learning environments. Knowledge Representation models have been used for education successfully in Intelligent Computer Aided Instruction ICAI (Nwanna, 1990), Adaptive Hypermedia (Brusilovsky, 2004) and Intelligent Tutoring System ITS (Nwanna, 1990) fields, the frameworks and architectures established in theese fields can be described as generic adaptation processes, these greatly eases the transition of a purely theoretical models to practical implementations in human learning environments.</p>
<p>Proposed architecture</p>
<p>The architecture for an Advance Learning Environment is meant to provide optimal learning conditions both physical: by adjusting settings such as environment noise, temperature and illumination, as well as cognitive conditions: through the personalisation of learning resources, media, activities, sequencing, evaluation methods and content. To achieve this, the architecture requires physical sensors and algorithms to process the user physical information, such methods are described in , Arroyo &amp; Cooper, 2009) and include body temperature, posture detection, heart rate, facial expression recognition, among others. Each of these methods pass the processed input information to a group of algorithms which will decide what adaptations need to be made to achieve optimal learning conditions.</p>
<p>The complete architecture is presented in figure 15, the cycle that describes the operation of the system is the following:</p>
<ol>
<li>
<p>Starting on the side of the figure we can observe tools for editing the MM, integrating Learning Objects (LO) and Learning Services (LS), modifying student portfolios and creating assessments. The tools are meant to assist teachers in the development of the MMs to be used in their courses, and for students to consult and partially edit their own portfolios. The student portfolios include their cumulative MM from every course they have taken, their emotional-cognitive mappings, their learning profile and their explicit interest and learning goals. Through these editors information is manually captured into the entire system. 2. Once the system has a complete user portfolio, a MM of the course designed by expert and enough LOs and LSs, the system can start the personalisation process. If the student is new to the system and does not have a MM, the process starts with an initial evaluation. The evaluation can be either a regular test, automated observation or through expert direct assessment, with this information the student's MM is created, or updated if a MM already exists. 3. Using heuristics based on the user knowledge level and the course MM, the system determines the next concepts to present. This is done through an overlay approach, i.e., the student knowledge must be a subset of the expert knowledge, (Brusilovsky, 2007).</p>
</li>
<li>
<p>Knowing what the next concept or skill to be taught should be, the system selects from a library of LOs and LSs the most adequate object for the user's profile from a group the group of LSs and LOs that match the selected knowledge. 5. Once the object is selected it passes onto a learning management system (LMS) (Alcorn, &amp; et al. 2000) where the learning object will be integrated into the main sequence of activities to be presented to the student, in this stage smaller modifications regarding the presentation of the object such as colour, font size, layout and duration are also made. 6. Depending on the activity, the student must go through a knowledge evaluation regarding the content just presented either through behaviour observation during activity or through a post-test. 7. With the feedback obtained from this evaluation the student's MM is updated and the cycle begins again until the desired concepts in MM of the course are learnt.</p>
</li>
</ol>
<p>While this is all taking place, physical sensors are continually observing and gathering data to estimate the users emotional condition and with this information the user profile is updated as to determine what factors in the learning process affect the student's emotional state, with enough information on this regard patterns can be established as to predict what will cause undesirable stress in the student. This factor is considered into the algorithms in charge of conceptual selection and those in charge of content personalisation. We will now review each of these applications of the memory map in the advance learning environment with more detail. </p>
<p>Knowledge representation for apprentice/student modelling</p>
<p>If personalisation is desired then a source of information is required, a knowledge representation model is the ideal source of information for advanced adaptations. This is because a knowledge representation model, usually a concept or semantic network, contains key information on how ideas are related and how to present them to a student through a complex negotiation process which can be described through algorithms supported on learning theories, in particular the constructivist theory (Vygotsky, 1986).</p>
<p>In education systems architectures, user modelling is divided into two categories: student model and expert model (Nwanna, 1990, Murray, 1999, whereas their name states the student model contains the information regarding student knowledge and the expert model contains all the information an expert should know for that context. In the advanced learning environment the MM is used to model both the expert model and the student model. The MM is used to model the concepts and associations that a group of students is expected to learn during an academic course or subject to be learnt, this is called the course-MM and would be equivalent to the expert model on cognitive agent architecture; each association and representation unit is taken to be an implicit learning objective which will be mapped to LOs and LSs. For the student a MM is created for her/his particular knowledge, the students MM are built and expanded using academic tests with specifically designed questions to inquire if an association between particular concepts exists, this approach, where a set of specifically designed questions reflect the knowledge of a user on a domain, is used in knowledge spaces theory as well (Doignon &amp; Falmagne 1999).</p>
<p>The fact that both knowledge structures are represented using the same knowledge representation model makes the use of an overlay approach natural for detecting differences between what the student knows and what the courses conceptual contents are, i.e., what the student knows and what he/she must learn in the course. Almost any knowledge representation model can be used to represent both the student model and the expert model, however the context management attributes of the MM allow it to represent several different student domains of the same student for different courses, this is, each context dynamically established in the MM can be treated as a different knowledge domain either for student or for the expert. For example if learner A enrols in course B, only the knowledge in student A's MM that is labelled under the domain (of the course) B or the representation units that are detected to be equivalent to those found in B, will be used for the content selection in the system, as shown in figure 16. The updates to student A's MM will be labelled under the domain B, therefore incrementing A's MM, both in this particular context and in general. A more detail explanation as to the methods used for the personalisation of the learning path can be found in (Ramirez &amp; Valdes 2011).   segments are shown because the real MMs are much bigger, the largest map is of an entire course on Artificial Intelligence, it has over 90 associations just between Concept-RUs and 40 mixed associations between the Concept-RUs and Skill-RUs. In this map there are no associations between Skill-RUs and Skill-RUs. The ABET skill taxonomy was used -although any taxonomy can be used--, ABET taxonomy is based on Bloom's but has no real hierarchy for skill composition.</p>
<p>Knowledge representation working with emotional feedback</p>
<p>In recent years affective learning has becomes one of the main focuses for learning research (Arroyo &amp; Cooper, 2009, Hernndez, Sucar &amp; Conati 2009, Ramirez, Concha &amp; Valdes, 2010a, 2010b, it has been proven that emotional conditions have a strong impact in the learning process of students and furthermore certain combination of emotions have been detected on which optimal learning takes place and reduces learning curve (Csikszentmihalyi, 1991). The advanced learning environment architecture contemplates this factor by using non-invasive sensors matching physical and physiological signals through correlations between temporal emotions and subject's learning processes. Diverse physical and physiological variables can be used to trace the emotional condition of a person, such as cardiac pulse, respiratory rate, posture, facial and voice expressions, etc. The cardiac pulse in particular is a reliable signal that carries useful information about the subject's emotional condition, it is detected using a classroom chair adapted with non-invasive EMFi sensors and an acquisition system that generates ballistocardiogram (BCG) signals, which are analysed to obtain cardiac pulse statistics. If emotions can be successfully monitored then a relation can be established between the emotional state, performance and characteristics of learning activities such as difficulty, time constrains and presentation style among others.</p>
<p>in learning activities to students and their previous experience, i.e., the student's skills and concepts. It is common in current "industrial" education systems to find students that lack previous context specific knowledge to comprehend new ideas, this generates stress and frustration and hinders the learning process. To help the learner get into an adequate emotional state for learning, not only the physical environment should be appropriate; but also the content of the learning subject itself and the order in which it is presented. Altering the order of learning activities might prove to be cheaper and more effective, the problem is to know the most appropriate order for each individual. The main goal is to create a positive emotional impact through personalisation; in order to do this we need to detect and avoid stress barriers due to an excess of difficulty and the lack of proper basis for the learning of complex concepts.</p>
<p>Keeping a record of the emotional feedback and the current LO or LS being presented enables a mapping between the emotions and the content. Negative emotional conditions can be predicted and avoided through pre-emptive adaptations. For example, if a student is presented with very advanced content that she is unable to understand, it is probable that she will experience frustration and anxiety; on the other hand, if she is presented with basic content which she already knows, it is probable the she will experience apathy or boredom (Steels, 2005). On the first case a previous learning activity to develop required skills before entering the scheduled learning activity is introduced in her learning flow; on the second case the learning activity can be skipped or eliminated. A second option in either case would consist of changing the difficulty level of the activity to better suit her. Detection of emotional condition and according reaction in the sequence of learning activities adaptation can be used to check if a previous adaptation is adequate. For example, if frustration is detected in a student while performing an activity, her MM would be checked to verify that she indeed has the required skills for the activity, in case the content is too advanced, assistance would be provided in the way of an AI tutor or an assistance signal could be emitted to the professor if deemed necessary.</p>
<p>Summary</p>
<p>In this chapter it was presented the basic concepts behind Knowledge Representation and types of knowledge going from traditional theories such as RTM to modern ones such as LOTH and showing not only how each discipline or science, including Philosophy, Psychology, Cognitive Science, Brain Science and Computer Science, has its own approach and limitations, but also that most of them complement each other and are situated upon three similar bases. We have also analysed the theoretical foundations for the explanation of the components of knowledge: concepts, skills and associations, including the way in which these are acquired, the way they interact, and their impact in other processes of cognition which in turn allow us to understand the reasons why computer models for knowledge representation are the way they are, and also, how each of these models can and have been used in recent years, in general terms. Additionally, we presented an original computer model for general knowledge representation, called Memory Map (MM). MM integrates both, skills and concepts into dynamic hierarchies defined by domains that reflect knowledge as context dependent. The MM was compared with similar models like MultiNet and OAR, showing similarities and differences, particularly regarding the representation of context. A practical application of the MM model was presented within a learning environment architecture, showing several examples of domains of knowledge modelled with the it. Finally some applications of the MM model for the development of an information system for the personalisation of learning considering affective-cognitive aspects were discussed.</p>
<p>Fig. 2 .
2Example of declarative and procedural knowledge.</p>
<p>Fig. 3 .
3Example of a semantic network for symbolic representation and a neural network for distributed representation. www.intechopen.com Advances in Knowledge Representation 50</p>
<p>Fig. 5 .
5Example of concept representation unit in three different contexts Formally a Concept Representation Unit is defined as:</p>
<p>Fig. 7 .
7Associations between skills and concepts in a Memory Map</p>
<p>Fig. 8 .
8Three types of associations: left Concept-RU-Concept-RU, middle Concept-RU-Skill-RU and right Skill-RU-Skill-RU.</p>
<p>Fig. 9 .
9Two concepts in the same domain share two associations with different roles. Role types: Description inheritance the successor unit inherits all the associations and hence the attributes of the predecessor representation unit. extension the precursor unit integrates single individual attribute tailoring the predecessor unit cannot inherit a specific association to the successor if a group of associations are inherited from it. composition the precursor unit is a component of the successor unit; the successor unit inherits the composition associations of the precursor unit.</p>
<p>Fig. 10 .
10Examples of OAR types of associations Composition, Inheritance, Tailoring and Extension integrated into MM model as roles.</p>
<p>access information for open questions such as: what does this MM know about concept A or skill B? What are the attributes of concept A? How are concepts A and B related under this particular domain of knowledge? What attributes of A hold for every domain? What concepts are related by type of association a?Each of these questions can be answered using the domain or combination of domains, the roles of associations, the depth of knowledge, the directionality knowledge and the combination of all of the above.Basic knowledge extraction in the MM can be described by the recursive function:</p>
<p>Fig. 12 .
12The result for an every role or attributes search for one concept and in one domain. www.intechopen.com Advances in Knowledge Representation 64</p>
<p>Fig. 13 .
13The result for an every domain or open context search for one concept and with one role.</p>
<p>Fig. 14 .
14Integration of new concepts and skills to the structure of knowledge.</p>
<p>Fig. 15 .
15The architecture of the Advanced Learning Environment</p>
<p>Fig. 16 .
16Example of one student memory map. Student A is being used for an overlay approach in two courses: course A and course B.Several courses and topics such as: Artificial Intelligence, Theory of Computation and Search Algorithms have been modelled using the MM and have been used in preliminary tests of the presented architecture, segments of each of the MMs are shown in figures 17, 18 and 19. OnlyFig. 17. Segments of MMs for Theory of Computation.</p>
<p>Fig. 18 .
18Segments of MMs for Artificial Intelligence course. www.intechopen.com</p>
<p>Fig. 19 .
19Segments of MMs for Search Algorithms .</p>
<p>Skill integration in complexity order does not always keep true.developed a taxonomy for skills with a very practical approach, in 
which three domains are specified: cognitive, affective, and psychomotor. Each domain 
contains different layers depending on the complexity of the particular skill. Bloom's 
taxonomy is widely used, however, as with any other taxonomy, criticisms have been 
raised; Spencer Kagan (2008) made the following observations: </p>
<ol>
<li>A given skill can have different degrees of complexity; hence a layer model might not 
provide an adequate representation. </li>
<li></li>
</ol>
<p>Table 1 .
1Examples of association types of OAR used as Roles in the MM. \Since associations contain the information regarding the domain, they change when the 
domain changes, examples are presented in figures 5 and 6. Roles or types of associations </p>
<p>www.intechopen.com </p>
<p>Table 2 .
2Association types of OAR that becomes redundant or Useless in MM.
www.intechopen.comAdvances in Knowledge Representation
. Concepts, skills and their acquisitionWe have already explained that knowledge is divided in two types: factual and procedural; Roughly speaking factual knowledge in a higher cognitive dimension can represent www.intechopen.comA General Knowledge Representation Model of Concepts
On another facet,Steels (2004) demonstrated that the level of difficulty in a task does have an impact in the emotional process. Difficulty can be associated with the contents presented www.intechopen.comAdvances in Knowledge Representation
AcknowledgmentThe authors are members of the DASL4LTD research group would like to thank the Tec of Monterrey Campus Quertaro as well as CONACYT for supporting their financial support.ReferencesAdvances in Knowledge RepresentationAdvances in Knowledge Representation offers a compilation of state of the art research works on topics such as concept theory, positive relational algebra and k-relations, structured, visual and ontological models of knowledge representation, as well as detailed descriptions of applications to various domains, such as semantic representation and extraction, intelligent information retrieval, program proof checking, complex planning, and data preparation for knowledge modelling, and a extensive bibliography. It is a valuable contribution to the advancement of the field. The expected readers are advanced students and researchers on the knowledge representation field and related areas; it may also help to computer oriented practitioners of diverse fields looking for ideas on how to develop a knowledge-based application.How to referenceIn order to correctly reference this scholarly work, feel free to copy and paste the following:CarlosRamirez and Benjamin Valdes (2012). A General Knowledge Representation Model of Concepts, Advances in Knowledge Representation, Dr. Carlos Ramirez (Ed.), ISBN: 978-953-51-0597-8, InTech, Available from: http://www.intechopen.com/books/advances-in-knowledge-representation/a-generalknowledge-representation-model-of-concepts
From Data to Wisdom. R L Ackoff, Journal of Applies Systems Analysis. 16Ackoff, R. L. (1989). "From Data to Wisdom", Journal of Applies Systems Analysis, Volume 16, p 3-9.</p>
<p>Internet-based education support system and methods. R L Alcorn, D E Cane, M L Chasen, T R Chi, S R Gilfus, S Perian, Alcorn, R. L., Cane, D. E., Chasen, M. L., Chi, T. R., Gilfus, S. R., Perian, S., et al. (2000, June). Internet-based education support system and methods.</p>
<p>An integrated theory of the mind. J R Anderson, D Bothell, M D Byrne, S Douglass, C Lebiere, Y Qin, Psychological Review. 1114Anderson, J. R., Bothell, D., Byrne, M. D., Douglass, S., Lebiere, C., &amp; Qin, Y. (2004). An integrated theory of the mind. Psychological Review, 111, (4), 1036-1060</p>
<p>A Taxonomy for Learning, Teaching, and Assessing: A Revision of Bloom's Taxonomy of Educational Objectives. J R. ; L W Anderson, D R Krathwohl, P W Airasian, K A Cruikshank, R E Mayer, P R Pintrich, Studies in Cognition Series. 384The Adaptive Character of Thought. Complete EditionAnderson, J. R. (1990). The Adaptive Character of Thought (Studies in Cognition Series) (p. 304). Psychology Press Anderson, L. W., Krathwohl, D. R., Airasian, P. W., Cruikshank, K. A., Mayer, R. E., Pintrich, P. R., et al. (2000). A Taxonomy for Learning, Teaching, and Assessing: A Revision of Bloom's Taxonomy of Educational Objectives, Complete Edition (p. 384).</p>
<p>. Allyn &amp; Bacon, Allyn &amp; Bacon.</p>
<p>Emotion sensors go to school. I Arroyo, D Cooper, Proceedings of 14th Annual Conference on Artificial Intelligence in Education. Retrieved. 14th Annual Conference on Artificial Intelligence in Education. RetrievedArroyo, I., &amp; Cooper, D. (2009). Emotion sensors go to school. Proceedings of 14th Annual Conference on Artificial Intelligence in Education. Retrieved July 25, 2011, from</p>
<p>Taxonomy of Educational Objectives, Handbook I: The Cognitive Domain. B Bloom, D. McKayDavid McKay Co IncNew YorkBloom, B. (1956). Taxonomy of Educational Objectives, Handbook I: The Cognitive Domain. (D. McKay, Ed.). New York: David McKay Co Inc.</p>
<p>Similarity and Analogical Reasoning. Ann L Brown, 10.1017/CBO9780511529863S. Vosniadou &amp; A. OrtonyCambridge University PressCambridgeBrown, Ann L. (1989). Similarity and Analogical Reasoning. (S. Vosniadou &amp; A. Ortony, Eds.). Cambridge: Cambridge University Press. doi:10.1017/CBO9780511529863</p>
<p>Adaptive Navigation Support : From Adaptive Hypermedia to the Adaptive Web and Beyond. Knowledge Creation Diffusion Utilization. P Brusilovsky, 2Brusilovsky, P. (2004). Adaptive Navigation Support : From Adaptive Hypermedia to the Adaptive Web and Beyond. Knowledge Creation Diffusion Utilization, 2(1), 7 -23.</p>
<p>Adaptive Navigation Support. P Brusilovsky, The adaptive web. P. Brusilovsky, W. Nejdl, &amp; A. KobsaBerlin, HeidelbergSpringer VerlagBrusilovsky, P. (2007). Adaptive Navigation Support. In P. Brusilovsky, W. Nejdl, &amp; A. Kobsa (Eds.), The adaptive web (pp. 263 -290). Berlin, Heidelberg: Springer Verlag.</p>
<p>Adaptive Formative Paths in a Web-based Learning Environment. V Carchiolo, A Longheu, M Malgeri, Educational Technology &amp; Society. 54Carchiolo, V., Longheu, A., &amp; Malgeri, M. (2002). Adaptive Formative Paths in a Web-based Learning Environment. Educational Technology &amp; Society, 5(4), 64-75.</p>
<p>The Psychology of Human-Computer Interaction. S K Card, T P Moran, A Newell, Lawrence Erlbaum AssociatesHillsdale, NJCard, S. K., Moran, T. P., &amp; Newell, A. (1986). The Psychology of Human-Computer Interaction. Hillsdale, NJ: Lawrence Erlbaum Associates. Retrieved from http://www.amazon.com/Psychology-Human-Computer-Interaction-Stuart- Card/dp/0898598591.</p>
<p>Ontology-based concept map for planning a personalised learning path. C M Chen, 10.1109/ICCIS.2008.4670870British Journal of Educational Technology. 406Wiley Online LibraryChen, C. M. (2009). Ontology-based concept map for planning a personalised learning path. British Journal of Educational Technology, 40(6), 1028-1058. Wiley Online Library. doi: 10.1109/ICCIS.2008.4670870.</p>
<p>A Review of B. F. Skinner's Verbal Behavior. N Chomsky, Readings in the psychology of language. L. A. J. A. M. S. Miron.Englewood Cliffs, N.J.Prentice-Hall psychologyChomsky, N. (1967). A Review of B. F. Skinner's Verbal Behavior. In L. A. J. A. M. S. Miron. (Ed.), Readings in the psychology of language (pp. 142 -143). Englewood Cliffs, N.J.: Prentice-Hall psychology.</p>
<p>The Effects of Domain and Type of Knowledge on Category-Based Inductive Reasoning. A K Crisp-Bright, Memory. Crisp-bright, A. K. (2010a). The Effects of Domain and Type of Knowledge on Category- Based Inductive Reasoning. Memory, 67-72.</p>
<p>Knowledge Selection in Category-Based Inductive Reasoning. A K Crisp-Bright, Cognitive Science. Durham UniversityCrisp-bright, A. K. (2010b). Knowledge Selection in Category-Based Inductive Reasoning. Cognitive Science. Durham University.</p>
<p>Knowledge Spaces. Knowledge Spaces. J.-P Doignon, J.-C Falmagne, Springer VerlagNew YorkDoignon, J.-P., &amp; Falmagne, J.-C. (1999). Knowledge Spaces. Knowledge Spaces. New York: Springer Verlag.</p>
<p>Seas of Language. M Dummett, Oxford University PressOxfordDummett, M. (1993). Seas of Language, Oxford: Oxford University Press.</p>
<p>Cognitive Psychology A Student's Handbook. M W Eysenck, M T Keane, East Sussex: Psychology Press. RetrievedEysenck, M. W., &amp; Keane, M. T. (2010). Cognitive Psychology A Student's Handbook, (6th ed.). East Sussex: Psychology Press. Retrieved September 3, 2010.</p>
<p>FIPA Ontology Service Specification. Fipa, Geneva, SwitzerlandFIPA. (2000). FIPA Ontology Service Specification. Geneva, Switzerland. Retrieved from http://www.lsi.upc.edu/~bejar/aia/fipa/FIPA_Ontology_Service_SpecificationX C00086C.pdf</p>
<p>User profiles for personalized information access. J A Fodors, S Gauch, M Speretta, A Chandramouli, A Micarelli, The Adaptive Web. P. Brusilovsky, A. Kobsa, &amp; W. NejdlBerlin, HeidelbergSpringer-VerlagThe Language of ThoughtFodors, J. A. (1975). The Language of Thought (p. 214). Cambridge: Harvard University Press. Gauch, S., Speretta, M., Chandramouli, A., &amp; Micarelli, A. (2007). User profiles for personalized information access. In P. Brusilovsky, A. Kobsa, &amp; W. Nejdl (Eds.), The Adaptive Web (p. 54-89). Berlin, Heidelberg: Springer-Verlag.</p>
<p>Investigations into logical deduction" in The Collected Papers of Gerhard Gentzen. Gerhard Gentzen, M. E. SzaboNorth-Holland Publishing CoAmsterdamUntersuchungen ber das logische SchlieenGentzen, Gerhard (1935) "Untersuchungen ber das logische Schlieen," translated as "Investigations into logical deduction" in The Collected Papers of Gerhard Gentzen, ed. and translated by M. E. Szabo, North-Holland Publishing Co., Amsterdam, 1969, pp. 68-131.</p>
<p>Toward Principles for the Design of Ontologies Used for Knowledge Sharing. T R Gruber, International Journal Human-Computer Studies. 43Gruber, T. R. (1993). Toward Principles for the Design of Ontologies Used for Knowledge Sharing. International Journal Human-Computer Studies, 43, 907-928.</p>
<p>It Is What It Does: The Pragmatics of Ontology. T Gruber, Gruber, T. (2003, March). It Is What It Does: The Pragmatics of Ontology. doi: http://tomgruber.org/writing/cidoc-ontology.htm.</p>
<p>Ontology of Folksonomy: A Mash-up of Apples and Oranges. T Gruber, International Journal on Semantic Web Information Systems. A. Sheth32CILIP.Gruber, T. (2007). Ontology of Folksonomy: A Mash-up of Apples and Oranges. (A. Sheth, Ed.)International Journal on Semantic Web Information Systems, 3(2), 1-11. CILIP. Retrieved from http://tomgruber.org/writing/ontology-of-folksonomy.htm</p>
<p>Layer Structures and Conceptual Hierarchies in Semantice Representation for NLP. Hermann Helbig, 10.1007/978-3-540-78135-6Computational Linguistics and Intelligent Text Processing. A. GelbukhBerlin, Heidelberg; Berlin HeidelbergSpringer4919Helbig, Hermann. (2008). Layer Structures and Conceptual Hierarchies in Semantice Representation for NLP. In A. Gelbukh (Ed.), Computational Linguistics and Intelligent Text Processing (Vol. 4919). Berlin, Heidelberg: Springer Berlin Heidelberg. doi: 10.1007/978-3-540-78135-6.</p>
<p>Incorporating an Affective Behavior Model into an Educational Game. Y Hernndez, L E Sucar, C Conati, FLAIRS. Hernndez, Y., Sucar, L. E., &amp; Conati, C. (2009). Incorporating an Affective Behavior Model into an Educational Game. FLAIRS (p. 448-453).</p>
<p>. T Hobbes, Clarendon PressOxfordleviathanHobbes, T. (1651). leviathan. Oxford: Clarendon Press.</p>
<p>Elements of Law, Natural and Political. T Hobbes, 186RoutledgeHobbes, T. (1969). Elements of Law, Natural and Political (p. 186). Routledge.</p>
<p>Artificial intelligence: the very idea. J Haugeland, MIT Press287Haugeland, J. (1989). Artificial intelligence: the very idea (p. 287). MIT Press. Retrieved from http://books.google.com/books?id=zLFSPdIuqKsC&amp;pgis=1</p>
<p>Mental models in cognitive science. P N Johnson-Laird, 10.1207/s15516709cog0401_4/abstractCognitive science. 41Wiley Online LibraryJohnson-Laird, P. N. (1980). Mental models in cognitive science. Cognitive science, 4(1), 71- 115. Wiley Online Library. Retrieved from http://onlinelibrary.wiley.com/doi/10.1207/s15516709cog0401_4/abstract</p>
<p>Rethinking Thinking Does Bloom's Taxonomy Align with Brain Science? SPENCERS THINKPAD. D S Kagan, Kagan, D. S. (2008). Rethinking Thinking Does Bloom's Taxonomy Align with Brain Science? SPENCERS THINKPAD.</p>
<p>Concepts and Conceptual Development: The ecological and intellectual factors in categorization. F C Keil, U. NeisserCambridge University PressCambridgeConceptual Development and Category StructureKeil, F. C. (1987). Conceptual Development and Category Structure. In U. Neisser (Ed.), Concepts and Conceptual Development: The ecological and intellectual factors in categorization. Cambridge: Cambridge University Press.</p>
<p>Concepts, Brains, and Behaviour, Grazer Philosophische Studien. A Kenny, 81Kenny, A. (2010). Concepts, Brains, and Behaviour, Grazer Philosophische Studien, 81 (1): 105- 113.</p>
<p>A brief introduction to Neural Networks. D Kriesel, Neural Networks. 244Kriesel, D. (2011). A brief introduction to Neural Networks. Neural Networks (p. 244). dkriesel.com. Retrieved from http://www.dkriesel.com/en/science/neural_networks</p>
<p>Computers versus Common Sense. D Lenat, Google Tach Talks. Lenat, D. (2006). Computers versus Common Sense. Google Tach Talks. Retrieved from http://video.google.com/videoplay?docid=-7704388615049492068</p>
<p>D Marr, Vision. CA. San FranciscoW. H. FreemanMarr, D. (1982). Vision. CA San Francisco: W. H. Freeman.</p>
<p>OWL Web Ontology Language Overview. D L Mcguinness, F Van Harmelen, McGuinness, D. L., &amp; Harmelen, F. van. (2004). OWL Web Ontology Language Overview. Retrieved from http://www.w3.org/TR/owl-features/.</p>
<p>Integrating Cyc and Wikipedia: Folksonomy meets rigorously defined common-sense. O Medelyan, C Legg, Proceedings of the WIKI-AI: Wikipedia and AI Workshop at the AAAI. the WIKI-AI: Wikipedia and AI Workshop at the AAAI8Medelyan, O., &amp; Legg, C. (2008). Integrating Cyc and Wikipedia: Folksonomy meets rigorously defined common-sense. Proceedings of the WIKI-AI: Wikipedia and AI Workshop at the AAAI (Vol. 8).</p>
<p>Introduction to WordNet: An On-line Lexical Database. G A Miller, R Beckwith, C Fellbaum, D Gross, K J Miller, International Journal of Lexicography. 3Miller, G. A., Beckwith, R., Fellbaum, C., Gross, D., &amp; Miller, K. J. (1990). Introduction to WordNet: An On-line Lexical Database. International Journal of Lexicography, 3, 235- 244.</p>
<p>A Framework for Representing Knowledge. The Psychology of Computer Vision. M Minsky, Conceptual Change in Childhood. Massachusett: McGrawHill. Carey, S.CambridgeMIT PressMinsky, M. (1975). A Framework for Representing Knowledge. The Psychology of Computer Vision. Massachusett: McGrawHill. Carey, S. (1985). Conceptual Change in Childhood. Cambridge: MIT Press.</p>
<p>The role of theories in conceptual coherence. G L Murphy, D L Medin, Psychological review. 923Murphy, G. L., &amp; Medin, D. L. (1985). The role of theories in conceptual coherence. Psychological review, 92(3), 289-316.</p>
<p>Authoring Intelligent Tutoring Systems : An Analysis of the State of the Art. T Murray, International Journal of Artificial Intelligence in Education. 10Murray, T. (1999). Authoring Intelligent Tutoring Systems : An Analysis of the State of the Art. International Journal of Artificial Intelligence in Education, 10, 98-129.</p>
<p>Human Problem Solving. A Newell, H A Simon, Prentice Hall784RetrievedNewell, A., &amp; Simon, H. A. (1972). Human Problem Solving (p. 784). NJ: Prentice Hall. Retrieved September 3, 2010, from http://www.amazon.com/Human-Problem- Solving-Allen-Newell/dp/0134454030.</p>
<p>The knowledge level. A Newell, Artificial Intelligence. 18Newell, A. (1982). The knowledge level. Artificial Intelligence, 18, 87-127.</p>
<p>Unified Theories of Cognition. A Newell, Harvard University PressMANewell, A. (1994). Unified Theories of Cognition. MA: Harvard University Press.</p>
<p>Intelligent tutoring systems: an overview. H Nwana, 10.1007/BF00168958Artificial Intelligence Review. 44Nwana, H. (1990). Intelligent tutoring systems: an overview. Artificial Intelligence Review, 4(4), 251-277. doi: 10.1007/BF00168958.</p>
<p>Semantic Information Processing. M R Quillian, M. MinskyMIT PressCambridge, MassachusettsQuillian, M. R. (1968). Semantic Information Processing. In M. Minsky (Ed.), (p. 227-270.). Cambridge, Massachusetts: MIT Press.</p>
<p>Cardiac Pulse Detection in BCG Signals Implemented on a Regular Classroom Chair Integrated to an Emotional and Learning Model for Personalization of Learning Resources. C Ramirez, C Concha, B Valdes, The 40th Annual Frontiers in Education (FIE) Conference. L. G. Richards &amp; K. CurryArlington VirginiaIEEERamirez, C., Concha, C., &amp; Valdes, B. (2010). Cardiac Pulse Detection in BCG Signals Implemented on a Regular Classroom Chair Integrated to an Emotional and Learning Model for Personalization of Learning Resources. In L. G. Richards &amp; K. Curry (Eds.), The 40th Annual Frontiers in Education (FIE) Conference. Arlington Virginia: IEEE.</p>
<p>Non-Invasive Technology on a Classroom Chair for Detection of Emotions used for the Personalization of Learning Resources. C Ramirez, C Concha, B Valdes, International Conference on Educational Technology ICET 2010. Paris FranceIEEERamirez, C., Concha, C., &amp; Valdes, B. (2010). Non-Invasive Technology on a Classroom Chair for Detection of Emotions used for the Personalization of Learning Resources. International Conference on Educational Technology ICET 2010. Paris France: IEEE.</p>
<p>Memory Map a Knowledge Representation Model Used for Intelligent Personalization of Learning Activities Sequences. C Ramirez, B Valdes, International Conference on Cognitive Informatics. Ramirez, C., &amp; Valdes, B. (2011). Memory Map a Knowledge Representation Model Used for Intelligent Personalization of Learning Activities Sequences. International Conference on Cognitive Informatics 2011 (pp. 1-9).</p>
<p>Mapping ontologies into Cyc. S L Reed, D B Lenat, AAAI 2002 Conference Workshop on Ontologies For The Semantic Web. Reed, S. L., &amp; Lenat, D. B. (2002). Mapping ontologies into Cyc. AAAI 2002 Conference Workshop on Ontologies For The Semantic Web (p. 1-6).</p>
<p>Causal-based property generalization. B Rehder, 10.1111/j.1551-6709.2009.01015.xCognitive science. 333Rehder, B. (2009). Causal-based property generalization. Cognitive science, 33(3), 301-44. doi: 10.1111/j.1551-6709.2009.01015.x.</p>
<p>Neural networks: a systematic introduction. R Rojas, Neural Networks. 4Springeroi=f nd&amp;pg=PA3&amp;dq=Neural+Networks+A+systematic+Introduction&amp; ots=fl22SGHDAR&amp;sig=yNm2kotq9R9RQvOyOvCtB1X2_-kRojas, R. (1996). Neural networks: a systematic introduction. Neural Networks (p. 509). Springer. Retrieved from http://books.google.com/books?hl=en&amp;lr=&amp;id=txsjjYzFJS4C&amp;oi=f nd&amp;pg=PA3&amp;dq=Neural+Networks+A+systematic+Introduction&amp; ots=fl22SGHDAR&amp;sig=yNm2kotq9R9RQvOyOvCtB1X2_-k</p>
<p>Artificial Intelligence: A Modern Approach. S J Russell, P Norvig, Prentice Hall960Russell, S. J., &amp; Norvig, P. (1995). Artificial Intelligence: A Modern Approach (p. 960). Prentice Hall. Retrieved from http://www.amazon.com/Artificial-Intelligence-Approach- Stuart-Russell/dp/0131038052</p>
<p>R C Schank, Conceptual Information Processing. New York, NY USAElsevier Science IncSchank, R. C. (1975). Conceptual Information Processing. New York, NY USA: Elsevier Science Inc. Retrieved from http://dl.acm.org/citation.cfm?id=540279</p>
<p>Dynamic Memory: A theory of reminding and learning in computers and people. R C Schank, Cambriedge. Cambriedge University PressSchank, R. C. (1982). Dynamic Memory: A theory of reminding and learning in computers and people. Cambriedge: Cambriedge University Press.</p>
<p>A connectionist approach to knowledge representation and limited inference. L Shastri, Cognitive Science. 123ElsevierShastri, L. (1988). A connectionist approach to knowledge representation and limited inference. Cognitive Science, 12(3), 331-392. Elsevier. Retrieved from http://www.sciencedirect.com/science/article/pii/0364021388900274</p>
<p>The empirical case for two systems of reasoning. S A Sloman, Psychological Bulletin. 119Sloman, S. A. (1996). The empirical case for two systems of reasoning. Psychological Bulletin, 119, 3-23</p>
<p>An Architecture of Flow. M. Tokoro and L. Steels. A Learning Zone of One's Own. L Steels, IOS PressAmsterdamSteels, L. (2004) An Architecture of Flow. M. Tokoro and L. Steels. A Learning Zone of One's Own. Amsterdam : IOS Press , pp. 137-150.</p>
<p>GTE: An epistemological approach to instructional modelling. K Van Marcke, Instructional Science. 263SpringerVan Marcke, K. (1998). GTE: An epistemological approach to instructional modelling. Instructional Science, 26(3), 147-191. Springer. Retrieved May 9, 2011, from http://www.springerlink.com/index/k12667t738160225.pdf.</p>
<p>Thought and Language. L Vygotsky, A. KozulinMIT PressNew York, USAVygotsky, L. (1986). Thought and Language. (A. Kozulin, Ed.). New York, USA: MIT Press.</p>
<p>The Real-Time Process Algebra (RTPA). Y Wang, Annals of Software Engineering. 141Wang, Y. (2002). The Real-Time Process Algebra (RTPA). Annals of Software Engineering, 14(1).</p>
<p>On Cognitive Informatics. Y Wang, 10.1002/jbm.a.33145Brain and Mind. 4Wang, Y. (2003). On Cognitive Informatics. Brain and Mind, 4, 151-167. doi: 10.1002/jbm.a.33145.</p>
<p>On Concept Algebra and Knowledge Representation. Y Wang, Y. W. Y.Y. Yao Z.Z. Shi &amp; W. Kinsner5Wang, Y. (2006). On Concept Algebra and Knowledge Representation. In Y. W. Y.Y. Yao Z.Z. Shi &amp; W. Kinsner (Eds.), 5th</p>
<p>The OAR Model of Neural Informatics for Internal knowledge Representation in the Brain. Y Wang, Int'l Journal of Cognitive Informatics and Natural Intelligence. 13Wang, Y. (2007). The OAR Model of Neural Informatics for Internal knowledge Representation in the Brain. Int'l Journal of Cognitive Informatics and Natural Intelligence, 1(3), 66-77.</p>
<p>The theoretical framework of cognitive informatics. Y Wang, A5. IEEE Int. Conf. on Cognitive Informatics. 8Wang, Y. (2009). The theoretical framework of cognitive informatics. Simulation, 8(March), A5. IEEE Int. Conf. on Cognitive Informatics (pp. 320-330).</p>
<p>Folksonomies and ontologies: two new players in indexing and knowledge representation Folksonomies: metadata for. Online Information. K Weller, Weller, K. (2007). Folksonomies and ontologies: two new players in indexing and knowledge representation Folksonomies: metadata for. Online Information (pp. 108-115).</p>            </div>
        </div>

    </div>
</body>
</html>