<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-4399 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-4399</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-4399</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-100.html">extraction-schema-100</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems, methods, or approaches that use large language models (LLMs) to extract information from, synthesize, or generate theories from multiple scientific papers.</div>
                <p><strong>Paper ID:</strong> paper-273963834</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2411.06159v1.pdf" target="_blank">From References to Insights: Collaborative Knowledge Minigraph Agents for Automating Scholarly Literature Review</a></p>
                <p><strong>Paper Abstract:</strong> Literature reviews play a crucial role in scientific research for understanding the current state of research, identifying gaps, and guiding future studies on specific topics. However, the process of conducting a comprehensive literature review is yet time-consuming. This paper proposes a novel framework, collaborative knowledge minigraph agents (CKMAs), to automate scholarly literature reviews. A novel prompt-based algorithm, the knowledge minigraph construction agent (KMCA), is designed to identify relationships between information pieces from academic literature and automatically constructs knowledge minigraphs. By leveraging the capabilities of large language models on constructed knowledge minigraphs, the multiple path summarization agent (MPSA) efficiently organizes information pieces and relationships from different viewpoints to generate literature review paragraphs. We evaluate CKMAs on three benchmark datasets. Experimental results demonstrate that the proposed techniques generate informative, complete, consistent, and insightful summaries for different research problems, promoting the use of LLMs in more professional fields.</p>
                <p><strong>Cost:</strong> 0.019</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e4399.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e4399.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems, methods, or approaches that use large language models (LLMs) to extract information from, synthesize, or generate theories from multiple scientific papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CKMAs</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Collaborative Knowledge Minigraph Agents</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A prompt-based framework that equips LLMs with small, research-oriented semantic graphs ('knowledge minigraphs') to extract, organize, and synthesize information from many scientific-paper abstracts into literature-review paragraphs using iterative graph construction and a mixture-of-experts summarization pipeline.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Collaborative Knowledge Minigraph Agents (CKMAs)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>CKMAs is a two-component system: (1) the Knowledge Minigraph Construction Agent (KMCA) iteratively extracts entities and relations from chunks of reference-paper abstracts via constrained prompt outputs (JSON schema) to build a small semantic 'knowledge minigraph' O; it enforces scientific entity/relation types and a volume constraint and updates O by feeding a text-transformed representation R(O) together with the next chunk. (2) the Multiple Path Summarization Agent (MPSA) performs hierarchical summarization (chunk-level summarization guided by O), samples multiple logical 'paths' by permuting input order (mixture-of-experts), generates multiple candidate summaries, and routes/selects the final summary by computing ROUGE-1 agreement among candidates. The pipeline uses k-sized chunking, iterative minigraph updates, and self-evaluation routing to produce final abstractive related-work paragraphs while also outputting the structured minigraph.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td>GPT-3.5-turbo (used as backbone in experiments; temperature=0.0).</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_technique</strong></td>
                            <td>Prompt-based structured extraction: constrained JSON outputs from LLM prompting, entity & relation schema (Task/Method/Metric/Material/Generic/Other-Scientific-Term) and relation types (Compare, Used-for, Feature-of, Hyponym-of, Evaluate-for, Part-of, Conjunction); iterative chunked extraction and merging into a compact minigraph.</td>
                        </tr>
                        <tr>
                            <td><strong>synthesis_technique</strong></td>
                            <td>Hierarchical summarization guided by the knowledge minigraph: chunk summarization guided by O, path-aware mixture-of-experts by sampling permutations of chunk order, and a ROUGE-1 agreement-based router to select the most-consensus final summary.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td>Designed to process 'numerous' references per instance; uses chunking with k=3 and iteratively merges chunks — evaluated on datasets where each instance contains multiple cited papers (Multi-XScience, TAS2, TAD).</td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_topic</strong></td>
                            <td>Scientific literature multi-document summarization, primarily computer-science papers (evaluated on Multi-Xscience, TAD, TAS2).</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Structured knowledge minigraphs (semantic graph) and abstractive literature-review paragraphs (multi-document summaries).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>ROUGE-1 and ROUGE-2 (automatic n-gram overlap); ablation studies (module removal effects) and case studies (qualitative analyses).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>State-of-the-art on three MSDS datasets reported in the paper: Multi-Xscience ROUGE-1=36.41, ROUGE-2=18.78; TAS2 ROUGE-1=34.16, ROUGE-2=6.22; TAD ROUGE-1=32.31, ROUGE-2=5.36.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared against graph-based methods (LexRank, TextRank, HeterSumGraph, GraphSum, TAG, KGSum), pre-trained PLM summarizers (Pointer-Generator, BertABS, SciBERTABS, HiMAP, BART, MGSum, PRIMERA) and prompt-based LLM baselines (GPT-3.5-turbo, GPT-4, 3A-COT, SumBlogger).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>CKMAs outperforms listed baselines; e.g., on Multi-Xscience CKMAs ROUGE-1 36.41 vs GPT-4 33.21 (≈ +3.20 absolute ROUGE-1), vs GPT-3.5-turbo 31.11 (≈ +5.30 ROUGE-1). The paper reports CKMAs as state-of-the-art on the three evaluation datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Equipping LLMs with an explicit, iterative, compact knowledge structure (minigraph) improves cross-document relational understanding; the mixture-of-experts path-aware summarization (MPSA) yields the largest single-module gain (~+4% relative), KMCA adds further gains (~+2%), and iterative construction is crucial to handle long contexts. Self-evaluation routing (ROUGE-1 agreement) helps pick more consensus/acceptable summaries.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>LLM verbosity and free-form outputs require constrained prompting; long-context limits force chunking and iterative merging (over-length truncation if iterative construction removed); risk of hallucination and incorrect logical linking noted in vanilla LLMs; approach depends on careful prompt design and volume constraints to keep graphs concise.</td>
                        </tr>
                        <tr>
                            <td><strong>scaling_behavior</strong></td>
                            <td>Performance gap vs vanilla LLMs widens as the number of reference papers increases—CKMAs handles more references better due to iterative minigraph construction; chunking (k=3) plus iterative merging permits scaling to many references but increases prompt-LLM call count.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'From References to Insights: Collaborative Knowledge Minigraph Agents for Automating Scholarly Literature Review', 'publication_date_yy_mm': '2024-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4399.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e4399.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems, methods, or approaches that use large language models (LLMs) to extract information from, synthesize, or generate theories from multiple scientific papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>KMCA</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Knowledge Minigraph Construction Agent</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A prompt-based, iterative LLM agent that extracts research-relevant entities and relations from chunks of paper abstracts into a constrained JSON schema and composes/updates a compact 'knowledge minigraph' representation used to guide summarization.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Knowledge Minigraph Construction Agent (KMCA)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>KMCA operates on chunks of k reference abstracts and uses a specially designed prompt G to instruct an LLM to (1) extract entities of predefined scientific types and relations of predefined relation types, (2) output results in a machine-readable JSON format (to control verbosity), (3) apply scientific and volume constraints to focus on top-m significant relations, and (4) allow iterative updates by transforming the current minigraph O into a text form R(O) and feeding it with the next chunk to produce O_i = G(R(O_{i-1}), chunk).</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td>GPT-3.5-turbo (in the paper's experiments).</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_technique</strong></td>
                            <td>Structured prompting for entity and relation extraction into a JSON schema constrained by entity/relation types; iterative chunk merging; transformation R(O) to present existing minigraph to the LLM for updates.</td>
                        </tr>
                        <tr>
                            <td><strong>synthesis_technique</strong></td>
                            <td>Constructs and maintains a compact semantic graph (minigraph) that later serves as structural guidance for downstream summarization (MPSA).</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td>Operates on chunks (k=3 in experiments) and iteratively integrates many chunks; designed for instances with multiple cited references (dozens per instance in some cases).</td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_topic</strong></td>
                            <td>Scientific document understanding and relation extraction for multi-document summarization.</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Structured JSON entity/relation lists and a textualized minigraph representation R(O).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Ablation studies showing impact on ROUGE when KMCA is ablated (reported in paper).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>KMCA reported to bring ~+2% performance gain (ROUGE) compared with ablated variants without minigraph construction (per ablation results).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Ablation baseline: vanilla LLM summarization without KMCA; compared against full CKMAs.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Removing KMCA reduces ROUGE scores (exact ablation numbers in Table 3), indicating KMCA contributes non-trivial gains.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Iterative construction and constrained JSON outputs are effective to produce concise, research-focused knowledge structures; scientific and volume constraints improve relevance and manage length.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>Requires carefully designed prompts and schema; success depends on LLM adhering to constrained output; chunking required due to context length limits; potential omission of relations if volume constraint m is too small.</td>
                        </tr>
                        <tr>
                            <td><strong>scaling_behavior</strong></td>
                            <td>Iterative merging allows scaling to longer reference lists, and iterative construction yields the largest gain among KMCA design choices versus non-iterative input (per ablation).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'From References to Insights: Collaborative Knowledge Minigraph Agents for Automating Scholarly Literature Review', 'publication_date_yy_mm': '2024-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4399.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e4399.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems, methods, or approaches that use large language models (LLMs) to extract information from, synthesize, or generate theories from multiple scientific papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MPSA</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Multiple Path Summarization Agent</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A path-aware summarization agent that uses LLMs as multiple experts by prompting different permutations (hints of logical paths) over chunk summaries and selecting the most consensual output via a ROUGE-1-based router.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Multiple Path Summarization Agent (MPSA)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>MPSA takes chunk summaries (M_i) and the knowledge minigraph O as input, samples E permutations of chunk order to hint different logical paths, prompts an LLM (an 'expert') per permutation to generate candidate summaries Y(e), and then uses a summarization router that computes pairwise ROUGE-1 agreement across experts to select the candidate with highest agreement as final summary. It also uses hierarchical chunk summarization S(A,{C_i},O) as a precursor step.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td>GPT-3.5-turbo (in the paper's experiments); the approach is LLM-agnostic in design.</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_technique</strong></td>
                            <td>Uses chunk-level summarization prompts guided by O (not direct entity extraction); extracts salient chunk-level information into M_i summaries.</td>
                        </tr>
                        <tr>
                            <td><strong>synthesis_technique</strong></td>
                            <td>Mixture-of-experts-style ensemble: generate multiple path-aware abstractive summaries via permutation-based hints, then aggregate/select via a consensus metric (ROUGE-1 agreement).</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td>Operates on chunk summaries aggregated from k-sized chunks (k=3 in experiments) across all referenced papers in an instance; E=3 experts sampled in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_topic</strong></td>
                            <td>Multi-document summarization of scientific papers (related-work generation).</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Abstractive summaries / literature-review paragraphs.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>ROUGE-1 and ROUGE-2; ablation experiments measuring effect of removing MPSA.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>MPSA reported to contribute approximately +4% performance gain to overall CKMAs performance (per ablation studies in the paper).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Ablation: direct single-instruction generation without MPSA; also compared against vanilla LLM outputs (same backbone).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Removing MPSA lowers ROUGE substantially (ablation numbers in Table 3); MPSA yields the largest module-level improvement within CKMAs.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Sampling multiple logical paths (permutations) elicits diverse viewpoints from LLMs; consensus-based routing (ROUGE-1 agreement) effectively selects a more acceptable summary.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>Relies on sensitivity of LLMs to prompt order (permutation hints) which may vary by model; selection via ROUGE-1 agreement favors consensus but may fail when consensus is consistently incorrect; computational cost rises linearly with number of experts E.</td>
                        </tr>
                        <tr>
                            <td><strong>scaling_behavior</strong></td>
                            <td>Using modest E (3) provided gains in experiments; increasing number of experts would increase compute but may improve robustness, while chunking mitigates long-context failure modes.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'From References to Insights: Collaborative Knowledge Minigraph Agents for Automating Scholarly Literature Review', 'publication_date_yy_mm': '2024-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4399.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e4399.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems, methods, or approaches that use large language models (LLMs) to extract information from, synthesize, or generate theories from multiple scientific papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>3A-COT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>3A-COT (Attend-Arrange-Abstract Chain-of-Thought)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A prompt-powered chain-of-thought approach for multi-document summarization that structures reasoning into attend, arrange, and abstract stages to improve multi-document synthesis.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>3A-COT: an attend-arrange-abstract chain-of-thought for multi-document summarization</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>3A-COT (attend-arrange-abstract chain-of-thought)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Described in the cited work as a chain-of-thought prompting pipeline that guides LLMs through attending to evidence, arranging information, and producing an abstracted summary; mentioned in this paper as a recent prompt-powered MSDS baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>extraction_technique</strong></td>
                            <td>Chain-of-thought style prompting to attend to and extract salient content from multiple documents.</td>
                        </tr>
                        <tr>
                            <td><strong>synthesis_technique</strong></td>
                            <td>Stepwise attend-arrange-abstract composition to synthesize multi-document summaries.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td>Multi-document clusters (variable; used for MSDS tasks).</td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_topic</strong></td>
                            <td>Multi-document scientific summarization (MSDS).</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Abstractive multi-document summaries.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Not specified in this paper (referenced work likely reports ROUGE and other summarization metrics).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Mentioned as a recent prompt-powered MSDS approach used for comparison; uses structured chain-of-thought prompts to improve multi-document summary coherence.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>Details not provided in this paper; general chain-of-thought approaches can be sensitive to prompt design and model capabilities.</td>
                        </tr>
                        <tr>
                            <td><strong>scaling_behavior</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'From References to Insights: Collaborative Knowledge Minigraph Agents for Automating Scholarly Literature Review', 'publication_date_yy_mm': '2024-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4399.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e4399.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems, methods, or approaches that use large language models (LLMs) to extract information from, synthesize, or generate theories from multiple scientific papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SumBlogger</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>SumBlogger</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A prompt-powered system for abstractive summarization of large collections of scientific articles, referenced as a recent strong prompt-based MSDS method.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>SumBlogger: Abstractive Summarization of Large Collections of Scientific Articles</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>SumBlogger</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Cited as a prompt-powered abstractive summarizer for large collections; the paper references SumBlogger as a competitive prompt-based MSDS baseline that CKMAs outperforms.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>extraction_technique</strong></td>
                            <td>Prompt-based single-document summarization followed by aggregation (per citation in the paper describing related approaches).</td>
                        </tr>
                        <tr>
                            <td><strong>synthesis_technique</strong></td>
                            <td>Aggregation of per-document or per-chunk summaries into a final multi-document summary.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td>Large collections of scientific articles (exact scale in cited work).</td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_topic</strong></td>
                            <td>Scientific articles (general; evaluated on MSDS datasets).</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Abstractive multi-document summaries.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Not detailed here; likely ROUGE in cited work.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Referenced as a recent prompt-powered baseline; CKMAs outperforms SumBlogger on evaluated datasets per the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>Specific limitations not enumerated in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>scaling_behavior</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'From References to Insights: Collaborative Knowledge Minigraph Agents for Automating Scholarly Literature Review', 'publication_date_yy_mm': '2024-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4399.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e4399.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems, methods, or approaches that use large language models (LLMs) to extract information from, synthesize, or generate theories from multiple scientific papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Zakkas (three-step)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Zakkas et al. three-step prompt pipeline (select → summarize → aggregate)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A referenced three-step approach where papers are selected, single-document summarization is performed, and results are aggregated to produce multi-document summaries.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Zakkas, Verberne, and Zavrel 2024</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Three-step prompt pipeline (Zakkas et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>The cited approach first selects relevant papers, then performs single-document summarization (via prompts or models), and finally aggregates individual summaries into a multi-document summary; mentioned as a prior prompt-based MSDS method.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>extraction_technique</strong></td>
                            <td>Selection (retrieval or filtering) followed by single-document summarization (prompted or model-based).</td>
                        </tr>
                        <tr>
                            <td><strong>synthesis_technique</strong></td>
                            <td>Aggregation of single-document summaries into a final summary (likely via concatenation or further summarization prompts).</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td>Designed for potentially large numbers of papers (exacts in source work).</td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_topic</strong></td>
                            <td>Scientific literature summarization (MSDS).</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Multi-document abstractive summaries.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Not specified in this paper; cited work likely uses ROUGE and other summarization metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Referenced as a modular pipeline approach (select → summarize → aggregate) used for comparison and inspiration in prompt-based MSDS work.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>Chaining single-document summarization can lose cross-document relational structure; aggregation step may not capture inter-paper relations without explicit structure.</td>
                        </tr>
                        <tr>
                            <td><strong>scaling_behavior</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'From References to Insights: Collaborative Knowledge Minigraph Agents for Automating Scholarly Literature Review', 'publication_date_yy_mm': '2024-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4399.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e4399.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems, methods, or approaches that use large language models (LLMs) to extract information from, synthesize, or generate theories from multiple scientific papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>KG-from-LLMs (Trajanoska)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Enhancing Knowledge Graph Construction using Large Language Models</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A referenced approach exploring use of LLMs to assist or improve knowledge-graph construction from raw text, cited as related work showing LLMs can aid structured extraction.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Enhancing knowledge graph construction using large language models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>KG construction via LLMs (Trajanoska et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Cited work investigates LLMs for entity and relation extraction to build or enhance knowledge graphs from textual sources; mentioned as relevant prior work to CKMAs' LLM-assisted minigraph construction.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>extraction_technique</strong></td>
                            <td>LLM-assisted entity and relation extraction for knowledge-graph construction (prompting-based or LLM-facilitated).</td>
                        </tr>
                        <tr>
                            <td><strong>synthesis_technique</strong></td>
                            <td>Structured graph assembly from extracted entities/relations.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_topic</strong></td>
                            <td>Knowledge graph construction from textual corpora; general NLP.</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Knowledge graphs / structured entity-relation outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Indicates that LLMs can be leveraged to enhance KG construction; cited as motivation for LLM-driven minigraph construction in CKMAs.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>Not detailed here; general issues include need for constrained outputs and schema enforcement to prevent free-form hallucinations.</td>
                        </tr>
                        <tr>
                            <td><strong>scaling_behavior</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'From References to Insights: Collaborative Knowledge Minigraph Agents for Automating Scholarly Literature Review', 'publication_date_yy_mm': '2024-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4399.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e4399.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems, methods, or approaches that use large language models (LLMs) to extract information from, synthesize, or generate theories from multiple scientific papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLM-as-experts</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLM as a System of Multiple Expert Agents</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A referenced conceptual approach treating a (large) LLM as multiple expert agents to solve complex tasks by partitioning reasoning or expertise, cited as inspiration for CKMAs' mixture-of-experts path-aware summarization.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Large language model (llm) as a system of multiple expert agents: An approach to solve the abstraction and reasoning corpus (arc) challenge</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>LLM-as-multiple-experts (Tan & Motani)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>The referenced idea frames an LLM as behaving like multiple specialized expert agents—motivating CKMAs' MPSA which samples multiple 'experts' (permutations/prompts) to obtain diverse viewpoints and then aggregates/selects among them.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>extraction_technique</strong></td>
                            <td>Not specified here; conceptual approach can include task partitioning and expert-specific prompts.</td>
                        </tr>
                        <tr>
                            <td><strong>synthesis_technique</strong></td>
                            <td>Mixture-of-experts style aggregation of outputs from multiple prompted 'experts'.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_topic</strong></td>
                            <td>General reasoning/abstraction tasks using LLMs; influence on multi-document summarization methods.</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Aggregated outputs from multiple expert prompts.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Conceptual precedent for using multiple LLM 'experts' or prompt variants to increase diversity and robustness of generated outputs; directly influenced MPSA design.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>Computational cost increases with number of experts; consensus selection requires a reliable comparator metric.</td>
                        </tr>
                        <tr>
                            <td><strong>scaling_behavior</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'From References to Insights: Collaborative Knowledge Minigraph Agents for Automating Scholarly Literature Review', 'publication_date_yy_mm': '2024-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>3A-COT: an attend-arrange-abstract chain-of-thought for multi-document summarization <em>(Rating: 2)</em></li>
                <li>SumBlogger: Abstractive Summarization of Large Collections of Scientific Articles <em>(Rating: 2)</em></li>
                <li>Enhancing knowledge graph construction using large language models <em>(Rating: 2)</em></li>
                <li>Large language model (llm) as a system of multiple expert agents: An approach to solve the abstraction and reasoning corpus (arc) challenge <em>(Rating: 2)</em></li>
                <li>Towards a Unified Framework for Reference Retrieval and Related Work Generation <em>(Rating: 1)</em></li>
                <li>Multi-Document Scientific Summarization from a Knowledge Graph-Centric View <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-4399",
    "paper_id": "paper-273963834",
    "extraction_schema_id": "extraction-schema-100",
    "extracted_data": [
        {
            "name_short": "CKMAs",
            "name_full": "Collaborative Knowledge Minigraph Agents",
            "brief_description": "A prompt-based framework that equips LLMs with small, research-oriented semantic graphs ('knowledge minigraphs') to extract, organize, and synthesize information from many scientific-paper abstracts into literature-review paragraphs using iterative graph construction and a mixture-of-experts summarization pipeline.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Collaborative Knowledge Minigraph Agents (CKMAs)",
            "system_description": "CKMAs is a two-component system: (1) the Knowledge Minigraph Construction Agent (KMCA) iteratively extracts entities and relations from chunks of reference-paper abstracts via constrained prompt outputs (JSON schema) to build a small semantic 'knowledge minigraph' O; it enforces scientific entity/relation types and a volume constraint and updates O by feeding a text-transformed representation R(O) together with the next chunk. (2) the Multiple Path Summarization Agent (MPSA) performs hierarchical summarization (chunk-level summarization guided by O), samples multiple logical 'paths' by permuting input order (mixture-of-experts), generates multiple candidate summaries, and routes/selects the final summary by computing ROUGE-1 agreement among candidates. The pipeline uses k-sized chunking, iterative minigraph updates, and self-evaluation routing to produce final abstractive related-work paragraphs while also outputting the structured minigraph.",
            "llm_model_used": "GPT-3.5-turbo (used as backbone in experiments; temperature=0.0).",
            "extraction_technique": "Prompt-based structured extraction: constrained JSON outputs from LLM prompting, entity & relation schema (Task/Method/Metric/Material/Generic/Other-Scientific-Term) and relation types (Compare, Used-for, Feature-of, Hyponym-of, Evaluate-for, Part-of, Conjunction); iterative chunked extraction and merging into a compact minigraph.",
            "synthesis_technique": "Hierarchical summarization guided by the knowledge minigraph: chunk summarization guided by O, path-aware mixture-of-experts by sampling permutations of chunk order, and a ROUGE-1 agreement-based router to select the most-consensus final summary.",
            "number_of_papers": "Designed to process 'numerous' references per instance; uses chunking with k=3 and iteratively merges chunks — evaluated on datasets where each instance contains multiple cited papers (Multi-XScience, TAS2, TAD).",
            "domain_or_topic": "Scientific literature multi-document summarization, primarily computer-science papers (evaluated on Multi-Xscience, TAD, TAS2).",
            "output_type": "Structured knowledge minigraphs (semantic graph) and abstractive literature-review paragraphs (multi-document summaries).",
            "evaluation_metrics": "ROUGE-1 and ROUGE-2 (automatic n-gram overlap); ablation studies (module removal effects) and case studies (qualitative analyses).",
            "performance_results": "State-of-the-art on three MSDS datasets reported in the paper: Multi-Xscience ROUGE-1=36.41, ROUGE-2=18.78; TAS2 ROUGE-1=34.16, ROUGE-2=6.22; TAD ROUGE-1=32.31, ROUGE-2=5.36.",
            "comparison_baseline": "Compared against graph-based methods (LexRank, TextRank, HeterSumGraph, GraphSum, TAG, KGSum), pre-trained PLM summarizers (Pointer-Generator, BertABS, SciBERTABS, HiMAP, BART, MGSum, PRIMERA) and prompt-based LLM baselines (GPT-3.5-turbo, GPT-4, 3A-COT, SumBlogger).",
            "performance_vs_baseline": "CKMAs outperforms listed baselines; e.g., on Multi-Xscience CKMAs ROUGE-1 36.41 vs GPT-4 33.21 (≈ +3.20 absolute ROUGE-1), vs GPT-3.5-turbo 31.11 (≈ +5.30 ROUGE-1). The paper reports CKMAs as state-of-the-art on the three evaluation datasets.",
            "key_findings": "Equipping LLMs with an explicit, iterative, compact knowledge structure (minigraph) improves cross-document relational understanding; the mixture-of-experts path-aware summarization (MPSA) yields the largest single-module gain (~+4% relative), KMCA adds further gains (~+2%), and iterative construction is crucial to handle long contexts. Self-evaluation routing (ROUGE-1 agreement) helps pick more consensus/acceptable summaries.",
            "limitations_challenges": "LLM verbosity and free-form outputs require constrained prompting; long-context limits force chunking and iterative merging (over-length truncation if iterative construction removed); risk of hallucination and incorrect logical linking noted in vanilla LLMs; approach depends on careful prompt design and volume constraints to keep graphs concise.",
            "scaling_behavior": "Performance gap vs vanilla LLMs widens as the number of reference papers increases—CKMAs handles more references better due to iterative minigraph construction; chunking (k=3) plus iterative merging permits scaling to many references but increases prompt-LLM call count.",
            "uuid": "e4399.0",
            "source_info": {
                "paper_title": "From References to Insights: Collaborative Knowledge Minigraph Agents for Automating Scholarly Literature Review",
                "publication_date_yy_mm": "2024-11"
            }
        },
        {
            "name_short": "KMCA",
            "name_full": "Knowledge Minigraph Construction Agent",
            "brief_description": "A prompt-based, iterative LLM agent that extracts research-relevant entities and relations from chunks of paper abstracts into a constrained JSON schema and composes/updates a compact 'knowledge minigraph' representation used to guide summarization.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Knowledge Minigraph Construction Agent (KMCA)",
            "system_description": "KMCA operates on chunks of k reference abstracts and uses a specially designed prompt G to instruct an LLM to (1) extract entities of predefined scientific types and relations of predefined relation types, (2) output results in a machine-readable JSON format (to control verbosity), (3) apply scientific and volume constraints to focus on top-m significant relations, and (4) allow iterative updates by transforming the current minigraph O into a text form R(O) and feeding it with the next chunk to produce O_i = G(R(O_{i-1}), chunk).",
            "llm_model_used": "GPT-3.5-turbo (in the paper's experiments).",
            "extraction_technique": "Structured prompting for entity and relation extraction into a JSON schema constrained by entity/relation types; iterative chunk merging; transformation R(O) to present existing minigraph to the LLM for updates.",
            "synthesis_technique": "Constructs and maintains a compact semantic graph (minigraph) that later serves as structural guidance for downstream summarization (MPSA).",
            "number_of_papers": "Operates on chunks (k=3 in experiments) and iteratively integrates many chunks; designed for instances with multiple cited references (dozens per instance in some cases).",
            "domain_or_topic": "Scientific document understanding and relation extraction for multi-document summarization.",
            "output_type": "Structured JSON entity/relation lists and a textualized minigraph representation R(O).",
            "evaluation_metrics": "Ablation studies showing impact on ROUGE when KMCA is ablated (reported in paper).",
            "performance_results": "KMCA reported to bring ~+2% performance gain (ROUGE) compared with ablated variants without minigraph construction (per ablation results).",
            "comparison_baseline": "Ablation baseline: vanilla LLM summarization without KMCA; compared against full CKMAs.",
            "performance_vs_baseline": "Removing KMCA reduces ROUGE scores (exact ablation numbers in Table 3), indicating KMCA contributes non-trivial gains.",
            "key_findings": "Iterative construction and constrained JSON outputs are effective to produce concise, research-focused knowledge structures; scientific and volume constraints improve relevance and manage length.",
            "limitations_challenges": "Requires carefully designed prompts and schema; success depends on LLM adhering to constrained output; chunking required due to context length limits; potential omission of relations if volume constraint m is too small.",
            "scaling_behavior": "Iterative merging allows scaling to longer reference lists, and iterative construction yields the largest gain among KMCA design choices versus non-iterative input (per ablation).",
            "uuid": "e4399.1",
            "source_info": {
                "paper_title": "From References to Insights: Collaborative Knowledge Minigraph Agents for Automating Scholarly Literature Review",
                "publication_date_yy_mm": "2024-11"
            }
        },
        {
            "name_short": "MPSA",
            "name_full": "Multiple Path Summarization Agent",
            "brief_description": "A path-aware summarization agent that uses LLMs as multiple experts by prompting different permutations (hints of logical paths) over chunk summaries and selecting the most consensual output via a ROUGE-1-based router.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Multiple Path Summarization Agent (MPSA)",
            "system_description": "MPSA takes chunk summaries (M_i) and the knowledge minigraph O as input, samples E permutations of chunk order to hint different logical paths, prompts an LLM (an 'expert') per permutation to generate candidate summaries Y(e), and then uses a summarization router that computes pairwise ROUGE-1 agreement across experts to select the candidate with highest agreement as final summary. It also uses hierarchical chunk summarization S(A,{C_i},O) as a precursor step.",
            "llm_model_used": "GPT-3.5-turbo (in the paper's experiments); the approach is LLM-agnostic in design.",
            "extraction_technique": "Uses chunk-level summarization prompts guided by O (not direct entity extraction); extracts salient chunk-level information into M_i summaries.",
            "synthesis_technique": "Mixture-of-experts-style ensemble: generate multiple path-aware abstractive summaries via permutation-based hints, then aggregate/select via a consensus metric (ROUGE-1 agreement).",
            "number_of_papers": "Operates on chunk summaries aggregated from k-sized chunks (k=3 in experiments) across all referenced papers in an instance; E=3 experts sampled in experiments.",
            "domain_or_topic": "Multi-document summarization of scientific papers (related-work generation).",
            "output_type": "Abstractive summaries / literature-review paragraphs.",
            "evaluation_metrics": "ROUGE-1 and ROUGE-2; ablation experiments measuring effect of removing MPSA.",
            "performance_results": "MPSA reported to contribute approximately +4% performance gain to overall CKMAs performance (per ablation studies in the paper).",
            "comparison_baseline": "Ablation: direct single-instruction generation without MPSA; also compared against vanilla LLM outputs (same backbone).",
            "performance_vs_baseline": "Removing MPSA lowers ROUGE substantially (ablation numbers in Table 3); MPSA yields the largest module-level improvement within CKMAs.",
            "key_findings": "Sampling multiple logical paths (permutations) elicits diverse viewpoints from LLMs; consensus-based routing (ROUGE-1 agreement) effectively selects a more acceptable summary.",
            "limitations_challenges": "Relies on sensitivity of LLMs to prompt order (permutation hints) which may vary by model; selection via ROUGE-1 agreement favors consensus but may fail when consensus is consistently incorrect; computational cost rises linearly with number of experts E.",
            "scaling_behavior": "Using modest E (3) provided gains in experiments; increasing number of experts would increase compute but may improve robustness, while chunking mitigates long-context failure modes.",
            "uuid": "e4399.2",
            "source_info": {
                "paper_title": "From References to Insights: Collaborative Knowledge Minigraph Agents for Automating Scholarly Literature Review",
                "publication_date_yy_mm": "2024-11"
            }
        },
        {
            "name_short": "3A-COT",
            "name_full": "3A-COT (Attend-Arrange-Abstract Chain-of-Thought)",
            "brief_description": "A prompt-powered chain-of-thought approach for multi-document summarization that structures reasoning into attend, arrange, and abstract stages to improve multi-document synthesis.",
            "citation_title": "3A-COT: an attend-arrange-abstract chain-of-thought for multi-document summarization",
            "mention_or_use": "mention",
            "system_name": "3A-COT (attend-arrange-abstract chain-of-thought)",
            "system_description": "Described in the cited work as a chain-of-thought prompting pipeline that guides LLMs through attending to evidence, arranging information, and producing an abstracted summary; mentioned in this paper as a recent prompt-powered MSDS baseline.",
            "llm_model_used": null,
            "extraction_technique": "Chain-of-thought style prompting to attend to and extract salient content from multiple documents.",
            "synthesis_technique": "Stepwise attend-arrange-abstract composition to synthesize multi-document summaries.",
            "number_of_papers": "Multi-document clusters (variable; used for MSDS tasks).",
            "domain_or_topic": "Multi-document scientific summarization (MSDS).",
            "output_type": "Abstractive multi-document summaries.",
            "evaluation_metrics": "Not specified in this paper (referenced work likely reports ROUGE and other summarization metrics).",
            "performance_results": null,
            "comparison_baseline": null,
            "performance_vs_baseline": null,
            "key_findings": "Mentioned as a recent prompt-powered MSDS approach used for comparison; uses structured chain-of-thought prompts to improve multi-document summary coherence.",
            "limitations_challenges": "Details not provided in this paper; general chain-of-thought approaches can be sensitive to prompt design and model capabilities.",
            "scaling_behavior": null,
            "uuid": "e4399.3",
            "source_info": {
                "paper_title": "From References to Insights: Collaborative Knowledge Minigraph Agents for Automating Scholarly Literature Review",
                "publication_date_yy_mm": "2024-11"
            }
        },
        {
            "name_short": "SumBlogger",
            "name_full": "SumBlogger",
            "brief_description": "A prompt-powered system for abstractive summarization of large collections of scientific articles, referenced as a recent strong prompt-based MSDS method.",
            "citation_title": "SumBlogger: Abstractive Summarization of Large Collections of Scientific Articles",
            "mention_or_use": "mention",
            "system_name": "SumBlogger",
            "system_description": "Cited as a prompt-powered abstractive summarizer for large collections; the paper references SumBlogger as a competitive prompt-based MSDS baseline that CKMAs outperforms.",
            "llm_model_used": null,
            "extraction_technique": "Prompt-based single-document summarization followed by aggregation (per citation in the paper describing related approaches).",
            "synthesis_technique": "Aggregation of per-document or per-chunk summaries into a final multi-document summary.",
            "number_of_papers": "Large collections of scientific articles (exact scale in cited work).",
            "domain_or_topic": "Scientific articles (general; evaluated on MSDS datasets).",
            "output_type": "Abstractive multi-document summaries.",
            "evaluation_metrics": "Not detailed here; likely ROUGE in cited work.",
            "performance_results": null,
            "comparison_baseline": null,
            "performance_vs_baseline": null,
            "key_findings": "Referenced as a recent prompt-powered baseline; CKMAs outperforms SumBlogger on evaluated datasets per the paper.",
            "limitations_challenges": "Specific limitations not enumerated in this paper.",
            "scaling_behavior": null,
            "uuid": "e4399.4",
            "source_info": {
                "paper_title": "From References to Insights: Collaborative Knowledge Minigraph Agents for Automating Scholarly Literature Review",
                "publication_date_yy_mm": "2024-11"
            }
        },
        {
            "name_short": "Zakkas (three-step)",
            "name_full": "Zakkas et al. three-step prompt pipeline (select → summarize → aggregate)",
            "brief_description": "A referenced three-step approach where papers are selected, single-document summarization is performed, and results are aggregated to produce multi-document summaries.",
            "citation_title": "Zakkas, Verberne, and Zavrel 2024",
            "mention_or_use": "mention",
            "system_name": "Three-step prompt pipeline (Zakkas et al.)",
            "system_description": "The cited approach first selects relevant papers, then performs single-document summarization (via prompts or models), and finally aggregates individual summaries into a multi-document summary; mentioned as a prior prompt-based MSDS method.",
            "llm_model_used": null,
            "extraction_technique": "Selection (retrieval or filtering) followed by single-document summarization (prompted or model-based).",
            "synthesis_technique": "Aggregation of single-document summaries into a final summary (likely via concatenation or further summarization prompts).",
            "number_of_papers": "Designed for potentially large numbers of papers (exacts in source work).",
            "domain_or_topic": "Scientific literature summarization (MSDS).",
            "output_type": "Multi-document abstractive summaries.",
            "evaluation_metrics": "Not specified in this paper; cited work likely uses ROUGE and other summarization metrics.",
            "performance_results": null,
            "comparison_baseline": null,
            "performance_vs_baseline": null,
            "key_findings": "Referenced as a modular pipeline approach (select → summarize → aggregate) used for comparison and inspiration in prompt-based MSDS work.",
            "limitations_challenges": "Chaining single-document summarization can lose cross-document relational structure; aggregation step may not capture inter-paper relations without explicit structure.",
            "scaling_behavior": null,
            "uuid": "e4399.5",
            "source_info": {
                "paper_title": "From References to Insights: Collaborative Knowledge Minigraph Agents for Automating Scholarly Literature Review",
                "publication_date_yy_mm": "2024-11"
            }
        },
        {
            "name_short": "KG-from-LLMs (Trajanoska)",
            "name_full": "Enhancing Knowledge Graph Construction using Large Language Models",
            "brief_description": "A referenced approach exploring use of LLMs to assist or improve knowledge-graph construction from raw text, cited as related work showing LLMs can aid structured extraction.",
            "citation_title": "Enhancing knowledge graph construction using large language models",
            "mention_or_use": "mention",
            "system_name": "KG construction via LLMs (Trajanoska et al.)",
            "system_description": "Cited work investigates LLMs for entity and relation extraction to build or enhance knowledge graphs from textual sources; mentioned as relevant prior work to CKMAs' LLM-assisted minigraph construction.",
            "llm_model_used": null,
            "extraction_technique": "LLM-assisted entity and relation extraction for knowledge-graph construction (prompting-based or LLM-facilitated).",
            "synthesis_technique": "Structured graph assembly from extracted entities/relations.",
            "number_of_papers": null,
            "domain_or_topic": "Knowledge graph construction from textual corpora; general NLP.",
            "output_type": "Knowledge graphs / structured entity-relation outputs.",
            "evaluation_metrics": null,
            "performance_results": null,
            "comparison_baseline": null,
            "performance_vs_baseline": null,
            "key_findings": "Indicates that LLMs can be leveraged to enhance KG construction; cited as motivation for LLM-driven minigraph construction in CKMAs.",
            "limitations_challenges": "Not detailed here; general issues include need for constrained outputs and schema enforcement to prevent free-form hallucinations.",
            "scaling_behavior": null,
            "uuid": "e4399.6",
            "source_info": {
                "paper_title": "From References to Insights: Collaborative Knowledge Minigraph Agents for Automating Scholarly Literature Review",
                "publication_date_yy_mm": "2024-11"
            }
        },
        {
            "name_short": "LLM-as-experts",
            "name_full": "LLM as a System of Multiple Expert Agents",
            "brief_description": "A referenced conceptual approach treating a (large) LLM as multiple expert agents to solve complex tasks by partitioning reasoning or expertise, cited as inspiration for CKMAs' mixture-of-experts path-aware summarization.",
            "citation_title": "Large language model (llm) as a system of multiple expert agents: An approach to solve the abstraction and reasoning corpus (arc) challenge",
            "mention_or_use": "mention",
            "system_name": "LLM-as-multiple-experts (Tan & Motani)",
            "system_description": "The referenced idea frames an LLM as behaving like multiple specialized expert agents—motivating CKMAs' MPSA which samples multiple 'experts' (permutations/prompts) to obtain diverse viewpoints and then aggregates/selects among them.",
            "llm_model_used": null,
            "extraction_technique": "Not specified here; conceptual approach can include task partitioning and expert-specific prompts.",
            "synthesis_technique": "Mixture-of-experts style aggregation of outputs from multiple prompted 'experts'.",
            "number_of_papers": null,
            "domain_or_topic": "General reasoning/abstraction tasks using LLMs; influence on multi-document summarization methods.",
            "output_type": "Aggregated outputs from multiple expert prompts.",
            "evaluation_metrics": null,
            "performance_results": null,
            "comparison_baseline": null,
            "performance_vs_baseline": null,
            "key_findings": "Conceptual precedent for using multiple LLM 'experts' or prompt variants to increase diversity and robustness of generated outputs; directly influenced MPSA design.",
            "limitations_challenges": "Computational cost increases with number of experts; consensus selection requires a reliable comparator metric.",
            "scaling_behavior": null,
            "uuid": "e4399.7",
            "source_info": {
                "paper_title": "From References to Insights: Collaborative Knowledge Minigraph Agents for Automating Scholarly Literature Review",
                "publication_date_yy_mm": "2024-11"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "3A-COT: an attend-arrange-abstract chain-of-thought for multi-document summarization",
            "rating": 2,
            "sanitized_title": "3acot_an_attendarrangeabstract_chainofthought_for_multidocument_summarization"
        },
        {
            "paper_title": "SumBlogger: Abstractive Summarization of Large Collections of Scientific Articles",
            "rating": 2,
            "sanitized_title": "sumblogger_abstractive_summarization_of_large_collections_of_scientific_articles"
        },
        {
            "paper_title": "Enhancing knowledge graph construction using large language models",
            "rating": 2,
            "sanitized_title": "enhancing_knowledge_graph_construction_using_large_language_models"
        },
        {
            "paper_title": "Large language model (llm) as a system of multiple expert agents: An approach to solve the abstraction and reasoning corpus (arc) challenge",
            "rating": 2,
            "sanitized_title": "large_language_model_llm_as_a_system_of_multiple_expert_agents_an_approach_to_solve_the_abstraction_and_reasoning_corpus_arc_challenge"
        },
        {
            "paper_title": "Towards a Unified Framework for Reference Retrieval and Related Work Generation",
            "rating": 1,
            "sanitized_title": "towards_a_unified_framework_for_reference_retrieval_and_related_work_generation"
        },
        {
            "paper_title": "Multi-Document Scientific Summarization from a Knowledge Graph-Centric View",
            "rating": 1,
            "sanitized_title": "multidocument_scientific_summarization_from_a_knowledge_graphcentric_view"
        }
    ],
    "cost": 0.019133749999999998,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>From References to Insights: Collaborative Knowledge Minigraph Agents for Automating Scholarly Literature Review
9 Nov 2024</p>
<p>Zhi Zhang zhi271.zhang@connect.polyu.hk 
The Hong Kong Polytechnic University</p>
<p>Yan Liu yan.liu@polyu.edu.hk 
The Hong Kong Polytechnic University</p>
<p>Sheng-Hua Zhong csshzhong@szu.edu.cn 
Shenzhen University</p>
<p>Gong Chen 
The Hong Kong Polytechnic University</p>
<p>Yu Yang cs-yu.yang@polyu.edu.hk 
The Hong Kong Polytechnic University</p>
<p>Jiannong Cao jiannong.cao@polyu.edu.hk 
The Hong Kong Polytechnic University</p>
<p>From References to Insights: Collaborative Knowledge Minigraph Agents for Automating Scholarly Literature Review
9 Nov 202426944FE37325B8BF50704653B4184DAEarXiv:2411.06159v1[cs.CL]
Literature reviews play a crucial role in scientific research for understanding the current state of research, identifying gaps, and guiding future studies on specific topics.However, the process of conducting a comprehensive literature review is yet time-consuming.This paper proposes a novel framework, collaborative knowledge minigraph agents (CKMAs) 1 , to automate scholarly literature reviews.A novel promptbased algorithm, the knowledge minigraph construction agent (KMCA), is designed to identify relationships between information pieces from academic literature and automatically constructs knowledge minigraphs.By leveraging the capabilities of large language models on constructed knowledge minigraphs, the multiple path summarization agent (MPSA) efficiently organizes information pieces and relationships from different viewpoints to generate literature review paragraphs.We evaluate CKMAs on three benchmark datasets.Experimental results demonstrate that the proposed techniques generate informative, complete, consistent, and insightful summaries for different research problems, promoting the use of LLMs in more professional fields.</p>
<p>Introduction</p>
<p>Artificial intelligence (AI) is being increasingly integrated into scientific discovery to augment and accelerate scientific research (Wang et al. 2023).Researchers are developing AI methods to, e.g., literature understanding, experiment development, and manuscript draft writing (Liu et al. 2022;Wang et al. 2024;Martin-Boyle et al. 2024).</p>
<p>Literature reviews play a crucial role in scientific research, assessing and integrating previous research on specific topics (Bolanos et al. 2024).They aim to meticulously identify and appraise all relevant literature related to a specific research question.Recent advancements in AI have shown promising performance in understanding research papers and generating human-like text (Van Dinter, Tekinerdogan, and Catal 2021).By leveraging AI capabilities, automatic literature review models enable researchers to save time and effort in the manual process of conducting literature reviews, rapidly identify key trends and gaps in recent research outputs, and uncover insights that might be overlooked in manual reviews (Wagner, Lukyanenko, and Paré 2022).</p>
<p>(Method) is used for  (Task) …  !(Material) is used for A (Method).</p>
<p>! is used in  and  for .Compared with ,  further involves  "  (Method) is used for  (Task) …  ! and  " (Material) are used for  (Method).</p>
<p>Referencing Paper 1 (understanding)</p>
<p>Referencing Paper 2 (understanding)
Summary (good) Method 𝐵 Method 𝐴 Material Material 𝑀 " Graph (structure) 𝑀 !
 ! is used in  for . ! and  " are used in  for .</p>
<p>Summary (trivial)</p>
<p>Task </p>
<p>Figure 1: Illustration of relationships between information pieces in scientific papers.Capturing these relationships is essential for composing a coherent story in literature reviews.</p>
<p>The automatic literature review models typically involve two stages (Shi et al. 2023): (1) selecting relevant reference papers and (2) determining logical relationships to compose a summary that presents the evolution of a specific field (these stages can be applied iteratively).Multiple scientific document summarization (MSDS), aiming to generate coherent and concise summaries for clusters of topic relevant scientific papers, is the representative work in the second stage.Past decades (Jin, Wang, and Wan 2020) have witnessed the development of summarization methods.Extractive methods directly select important sentences from original papers.Abstractive methods can generate new words and sentences but are technically more challenging than extractive methods.</p>
<p>Recently, large language models (LLMs), pre-trained on extensive text data, have transformed abstractive summarization and show human-like performance in understanding and coherent language synthesis.However, ideas arising in research papers often have complex relationships, e.g., conflicting or duplicate.Without explicit instructions, LLMs fall short in capturing the relations between ideas and composing a story that connects related work reflecting the author's understanding of their field (Li and Ouyang 2024).As shown in Fig 1, effective summarization often involves the ability to understand concepts of materials, methods, and tasks in referencing papers, aggregate complementary ideas (e.g., M 1 is used for T ) while contrasting differences (e.g., M 2 is additionally used for B compared with A).</p>
<p>To tackle this bottleneck, we propose equipping LLMs with structural knowledge.Different from knowledge graphs, which consist of entities as nodes and their relationships as edges, serving as general-purpose knowledge, we introduce knowledge minigraphs.Knowledge minigraphs are small-scale semantic graphs, comprising research-relevant concepts as nodes and their relationships as edges, specially designed to capture the structural information between ideas in references.</p>
<p>To automatically construct knowledge minigraphs, we propose a prompt-based algorithm, the knowledge minigraph construction agent (KMCA) to elicit LLMs to identify research-relevant concepts and relationships based on references.Benefiting from the designed iterative construction strategy, key information and relationships are iteratively extracted and stored from numerous references into minigraphs.</p>
<p>By leveraging the capabilities of LLMs on knowledge minigraphs, the multiple path summarization agent (MPSA) is designed to organize the generated literature review.The MPSA samples multiple summaries from different viewpoints and logical paths in the knowledge minigraph, utilizing the mixture of experts technique.A self-evaluation mechanism is then employed to automatically route to the most desirable summary as the final output.</p>
<p>Related Work</p>
<p>Graphs in MSDS Tasks</p>
<p>To generate a summary that is representative of the overall content, graph-based methods construct external graphs to assist document representation and cross-document relation modeling, achieving promising progress.In this regard, LexRank (Erkan and Radev 2004) and TextRank (Mihalcea and Tarau 2004) first introduced graphs to extractive text summarization in 2004.They compute sentence importance using a graph representation of sentences to extract salient textual units from documents as summarization.In 2020, Wang et al. (Wang et al. 2020) propose to extract salient textual units from documents as summarization using a heterogeneous graph consisting of semantic nodes at several granularity levels of documents.In 2022, Wang et al. (Wang et al. 2022) incorporate knowledge graphs into document encoding and decoding, generating the summary from a knowledge graph template to achieve state-of-the-art performance.</p>
<p>However, to the best of our knowledge, no existing work integrates LLMs into graph-based methods to leverage their natural language understanding capabilities for improved graph construction and summary generation.</p>
<p>Pre-trained Language Models in MSDS Tasks</p>
<p>In recent years, pre-trained language models (PLMs) have demonstrated promising results in multiple document sum-marization.Liu et al. (Liu and Lapata 2019) propose finetuning a pre-trained BERT model as the encoder and a randomly initialized decoder to enhance the quality of generated summaries.Building upon BART (Lewis et al. 2020), Beltagy et al. (Beltagy, Peters, and Cohan 2020) propose LED for lengthy text summarization, which is directly initialized from bart-large but employs global-local attention to better handle long context inputs.Xiao et al. (Xiao et al. 2022) introduce PRIMERA, a pre-trained encoder-decoder multi-document summarization model, by improving aggregating information across documents.More recently, pretrained large language models (LLMs) show promising generation adaptability by training billions of model parameters on massive amounts of text data (Zhao et al. 2023;Minaee et al. 2024).Zhang et al. (Zhang et al. 2024a) utilize welldesigned instructions to extract key elements, arrange key information, and generate summaries.Zakkas et al. (Zakkas, Verberne, and Zavrel 2024) propose a three-step approach to select papers, perform single-document summarization, and aggregate results.</p>
<p>PLMs can provide fluent summary results for referencing papers.However, they fall short in capturing the relations between ideas from multiple related papers.</p>
<p>Method</p>
<p>Fig. 2 illustrates the architecture of the proposed collaborative knowledge minigraph agents (CKMAs).CKMAs consists of two key components: the knowledge minigraph construction agent and the multiple path summarization agent.</p>
<p>Knowledge Minigraph Construction Agent</p>
<p>In this module, we are given T reference documents {C 1 , . . ., C t }'s abstracts.We aim to construct a knowledge structure O that captures the relationships between concepts in the referenced papers.</p>
<p>Past decades have witnessed knowledge graphs become the basis of information systems that require access to structured knowledge (Zou 2020).Knowledge structures are represented as semantic graphs, where nodes denote entities and are connected by relations denoted by edges.However, the general-purpose knowledge graphs are unsuitable for scientific document summarization, as they do not necessarily involve the main ideas of research papers and are not suitable for identifying gaps not addressed by prior work.Thus, in this paper, we propose establishing a knowledge minigraph, defined as as a small set of research-relevant concepts and their relationships.The construction steps of the knowledge minigraph are as follows:</p>
<p>Reference chunking Given a total of T reference documents, we first divide them into I chunks, each containing at most k reference documents.Here, {C i 1 , . . .C i k } represents the k reference papers in the i-th chunk.MSDS usually involves numerous reference papers, forming a long context.LLMs either fail to process the entire context exceeding the acceptable length or suffer from missing crucial information positioned amidst a lengthy context (Zhang et al. 2024b).Thus, we chunk related works and use LLMs to construct the knowledge structure step by step with k reference papers each time.</p>
<p>Concatenate Minigraph with New References
Knowledge Minigraph Chunk 𝑘 References {𝑪 𝟏 𝒊 , … 𝑪 𝒌 𝒊 } @cite_29's abstract -"…" @cite_23's abstract -"…" @cite_19's abstract -"…" @cite_23's abstract -"…" @cite_11's abstract -"…" @cite_15's abstract -"…" (a) Knowledge Minigraph Construction Agent (KMCA) (b) Multiple Path Summarization Agent (MPSA) Minigraph Generation 𝑮(𝑹(𝑶), 𝑪 𝟏 𝒊 , … 𝑪 𝒌 𝒊 ) Scientific Constraint USED- FOR EVALU ATE- FOR USED- FOR USED -FOR USED- FOR Volume Constraint Minigraph transformation 𝑹(𝑶) Minigraph Prompt Chunk Summary 𝑺(𝑶, {𝑪 𝟏 𝒊 , … 𝑪 𝒌 𝒊 }, 𝑨) Path-aware Summary 𝑺 (𝒏) (O,{𝑴 𝒊 }, A)
Route to Final Summary AI: "several approaches have been proposed…" AI: summary of @cite_11 and @cite_15 AI: summary of @cite_29 and @cite_23 AI: summary of chunk 3, chunk 2, and chunk 1 AI: summary of chunk 1, chunk 2, and chunk 3 AI: summary of @cite_19 and @cite_23 AI: summary of chunk 2, chunk 1, and chunk 3 Minigraph generation We employ a knowledge minigraph prompt G({C i 1 , . . .C i k }) to construct the knowledge structure of interest based on the abstracts of referenced papers {C i 1 , . . .C i k }.It is known that constructing knowledge graphs from raw text data requires entity recognition and relation extraction (Trajanoska, Stojanov, and Trajanov 2023).Tailoring recent advancements in prompt techniques, we design instructions for the integration of LLM into these tasks within a single round of dialogue (using the prompt for query and LLMs for response).As shown in Table 1, the prompt involves three special designs:
Different Path Task Material Method Generic Metric … Knowledge Minigraph -" ℎ𝑒𝑎𝑑 ! − 𝑟𝑒𝑙 ! → 𝑡𝑎𝑖𝑙 ! ; ℎ𝑒𝑎𝑑 " − 𝑟𝑒𝑙 " → 𝑡𝑎𝑖𝑙 " ; … ℎ𝑒𝑎𝑑 # − 𝑟𝑒𝑙 # → 𝑡𝑎𝑖𝑙 # " AI: [{ "head": ℎ𝑒𝑎𝑑 ! , "head_type": 𝑡𝑦𝑝𝑒 ! $ , "relation": 𝑟𝑒𝑙 ! , "tail": 𝑡𝑎𝑖𝑙 ! , "tail_type": 𝑡𝑦𝑝𝑒 ! % , }, … ]
(1) Output Constraint: LLMs are well known for being relatively verbose and free-form in their output, making it hard for automated graph construction programs (Tan and Motani 2023).Thus, we prompt LLM to constrain output in a machine-understandable JSON format.(2) Scientific Constraints: To ensure the constructed knowledge structure revolves around the main idea of research topics, we design constraints on entities of interest and relationships of interest.Inspired by DYGIE++ (Wadden et al. 2019), we extract entities classified in six types, Task, Method, Metric, Material, Generic, and OtherScientificTerm, and relations are in seven types, Compare, Used-for, Feature-of, Hyponymof, Evaluate-for, Part-of, and Conjunction.(3) Volume Constraints: Redundant relationships will lead to length issues.To ensure the constructed knowledge structure is concise and informative, we constrain the focus to the top-m significant relationships.</p>
<p>Minigraph transformation To enable LLMs to understand the derived knowledge minigraph, we design a function R(O) to transform the knowledge minigraph O into a text representation for subsequent processing.In detail, available relationships whose type meet the constraints are transformed into a line of text in the format head p − rel p → tail p , where head p and tail p are the head and tail entities, and rel p is the relationship.</p>
<p>Finally, iteratively employing these three steps, the knowledge structure O i is constructed as shown in Eq. 1.
O i = G(R(O i−1 ), C i 1 , . . . C i k ), i ≥ 2 G( C i 1 , . . . C i k ); i = 1 (1)
In the first iteration, we apply the knowledge minigraph prompt G to the first chunk of reference papers to derive the initial knowledge minigraph O 1 .For subsequent iterations, we transform the intermediate knowledge minigraph
O i−1 into a text representation R(O i−1 )
. This text representation is then input along with the i-th chunk of reference papers C i 1 , . . .C i k , allowing for dynamic updates to the knowledge minigraph.</p>
<p>Multiple Path Summarization Agent</p>
<p>In this module, we are given the knowledge structure O, the referencing paper's abstract A, and the chunked referencing papers {C i 1 , . . .C i k }'s abstracts.We aim to generate a summary following the knowledge structure.</p>
<p>Even given O as guidance, generating a summary remains an ill-posed problem, i.e., the solution is not unique and depends on the specific discussion viewpoints.For example, one can highlight different concepts or choose different writing logic for different situations.Can we harness different understandings of the knowledge structure to create a more capable summary?Inspired by the mixture of experts approach (Shazeer et al. 2017), a machine learning technique to leverage diverse model capabilities where multiple expert networks specialize in different skill sets, we propose using LLMs with different hinted paths to understand the knowledge minigraph for generating multiple summaries and selecting the best viewpoint.The steps of the multiple path summarization agent are as follows:</p>
<p>Chunk summarization As mentioned before, MSDS usually involves numerous reference papers, forming a long context problem.We chunk them into I chunks and formulate a hierarchical summarization process, first generating summaries for each chunk of referenced papers.With prompt engineering, we elicit the behavior of LLMs to generate summaries for each chunk under the guidance of de- You are an advanced algorithm designed to extract information in structured formats for building a knowledge graph.Your task is to identify entities and relations from a given text based on the user's prompt.</p>
<p>Default Requirement</p>
<p>You are the most famous researcher in writing the related work section of a given scientific article.Your summaries are concise, informative and of high quality.You are the author of a scientific article.You have already written the abstract of the article, and you are currently writing the related work section of the article.You want to write a paragraph of at most 200 words, which will be used without modification as a paragraph in the related work section that refers to the referenced documents, either to base on their ideas or to challenge them.Be fluent.Avoid repetitive information.Refer to the referenced documents of the list using their $id in this format "@cite_$id".All documents should be cited.You are encouraged to cite more than one document in one place if you are sure that the citation is supported by their summaries.</p>
<p>Output Constraint</p>
<p>Generate the output in JSON format, containing a list of objects with keys: "head", "head_type", "relation", "tail", and "tail_type".</p>
<p>Scientific Constraints</p>
<p>The "head" and "tail" keys should contain the extracted entity text.The "head_type" and "tail_type" keys must be one of the following: "Task", "Method", "Metric", "Material", "Other-Scientific-Term", "Generic".The "relation" key must be one of these types: "Compare", "Conjunction", "Evaluate-For", "Used-For", "FeatureOf", "Part-Of", "Hyponym-Of".</p>
<p>Volume Constraints</p>
<p>Extract up to 32 of the most important relations, prioritizing significant and relevant information.Ensure entity consistency by using the most complete identifier for entities mentioned multiple times in different forms.
M i = S(A, {C i 1 , . . . C i k }, O)(2)
where S is the prompt function for chunk summarization.</p>
<p>Path-aware summarization We employ E experts to merge all chunk summaries {M i } and generate final summaries, with each expert aware of different hinted paths to understand the knowledge minigraph.Given consistent knowledge, different human researchers may have varying understandings, selectively emphasizing concepts in a logical order.To automatically mimic human researchers and generate summaries of different understanding, we leverage the observation that LLMs are sensitive to prompt wording and their order (Pezeshkpour and Hruschka 2023).We find that the order of given referencing papers impacts the generated summary, affecting the order of introducing information from references and the highlighting of concepts.Thus, we propose sampling E permutations from the full permutations of referenced papers to serve as the order of input in the instructions as a hint of the potential logical path in knowledge minigraph, which are then used to prompt the LLM to generate summaries.We use the same prompt as in chunk summarization, except that summaries of referenced papers C i 1 , . . .C i k are replaced by a permutation of chunk summaries M i .Mathematically, the summaries generated by the e-th expert can be denoted as:
Y (e) = S (e) (A, {M i }, O)(3)
where S (e) represents the prompt function for the e-th expert with the sampled e-th permutation of referencing papers.For instance, given chunk summarizations {M 1 , M 2 , M 3 }, where M 1 , M 2 , and M 3 are summaries of the first, second, and third chunks of referencing papers, respectively, three experts can be fed
[M 1 , M 2 , M 3 ], [M 2 , M 1 , M 3 ],
and [M 3 , M 2 , M 1 ] as input.The remaining parts of the instructions remain consistent with S. Summarization router We design a router to evaluate different experts' summaries and automatically select the most desirable summary Y (e) as the final output.Without requiring additional side information, this paper proposes a self-evaluation strategy.In detail, we observe that there are agreements between the experts' viewpoints and their generated summaries.We propose to quantify the degree of agreement for each summary using the ROUGE-1 score (Lin 2004), which measures the overlap between a generated summary and other summaries.We then select the summary with the highest degree of agreement, which indicates that its understanding has the highest likelihood of being supported by other experts, or in other words, is relatively more acceptable.Mathematically, the final summary can be denoted as:
Y = arg max e j̸ =e rouge1(Y (e) , Y (j) )(4)
where rouge1(Y (e) , Y (j) ) is the an 1-gram recall (ROUGE-1 score) between e-expert's generated summary Y (e) and jexpert's generated summary Y (j) .</p>
<p>Experiments</p>
<p>We evaluate our method on three public MSDS datasets: Multi-Xscience (Lu, Dong, and Charlin 2020), TAD (Chen et al. 2022), and TAS2 (Chen et al. 2022).Multi-Xscience is the first large-scale and open MDSS dataset, collected from arXiv and the Microsoft Academic Graph (MAG).It contains 5,093 instances for testing, primarily focusing on the computer science field.TAD and TAS2 are collected from the public scholar corpora S2ORC and Delve, respectively.While TAD contains papers from multiple fields, TAS2 focuses on the computer science field.Both TAD and TAS2 contain 5,000 instances for testing.The input and output format of the three datasets are consistent: each instance contains the abstract of a query paper and the abstracts of reference papers it cites as input, with a paragraph from the related work section of the query paper serving as the gold summary.</p>
<p>For a fair comparison, we follow relevant studies (Zakkas, Verberne, and Zavrel 2024) of prompt-based methods to use the same LLM, gpt-3.5-turbo,as the backbone model.We set the temperature of the sampling to 0.0 for reproducibility.We set the chunk size k to 3 and the number of experts E to 3. We set the volume constraint m to 32.Following previous work, we automatically evaluate the summarization quality using ROUGE scores (Lin 2004).We employ ROUGE-N to calculate the N-grams overlap between the output and gold summary, assessing the summary informativeness:
ROUGE − N = X∈U gram n ∈X C match (gram n ) X ∈ U gram n ∈X C(gram n ) (5)
where X denotes a reference summary sampled from the reference summary collection U , n represents the length of the n-gram, C(.) is the count of the n-gram, and C match (.)</p>
<p>is the maximum number of n-grams co-occurring in a candidate summary and a set of reference summaries.We report unigram and bigram co-occurrence (ROUGE-1 and ROUGE-2).</p>
<p>Comparasion Experiments</p>
<p>Table 2 compares the proposed model with graph-based methods including LexRank (Erkan and Radev 2004), Tex-tRank (Mihalcea and Tarau 2004), HeterSumGraph (Wang et al. 2020), GraphSum (Li et al. 2020), TAG (Chen et al. 2022), and KGSum (Wang et al. 2022) and pre-trained language model-based methods, including Pointer-Generator (See, Liu, and Manning 2017), BertABS (Liu and Lapata 2019), SciBertABS (Beltagy, Lo, and Cohan 2019), HiMAP (Fabbri et al. 2019), BART (Lewis et al. 2020), MGSum (Jin, Wang, and Wan 2020), PRIMERA (Xiao et al. 2022), GPT-3.5-turbo(Ouyang et al. 2022), and GPT-4 (Achiam et al. 2023).The proposed CKMAs achieves state-of-theart performance on all three datasets in terms of ROUGE-1 and ROUGE-2 scores.CKMAs also outperforms the latest prompt-powered MSDS, e.g., 3A-COT (Zhang et al. 2024a) and SumBlogger (Zakkas, Verberne, and Zavrel 2024).</p>
<p>Ablation Studies</p>
<p>This section presents ablation studies to investigate the performance gains brought by the designed modules in CK-MAs.We first ablate the knowledge minigraph construction agent (KMCA) and the multiple path summarization agent (MPSA), respectively.When ablating KMCA, we no longer construct the knowledge minigraph and do not include it as part of the MPSA instruction.When removing MPSA, we use the instruction in Table 1 to directly generate a single summary as the final summary.We report the performance  of the ablated version of the model in the first line of Table 3.Then, we ablate the modules in MPSA and KMCA.For the knowledge minigraph construction agent, when ablating the scientific constraint or volume constraint ablation in minigraph generation, we remove the corresponding instruction in Table 1.To ablate iterative construction, we remove Eq. 1 and directly use all references as input.Due to the length issue, the over-length context is truncated.For the multiple path summarization agent, when ablating chunk summarization, we directly use all references' abstracts as input.To ablate the path-aware summarization strategy, we use the references with original order as input, adjusting temperatures from 0.0 to 0.7.When removing the summarization router, we randomly select a generated summary.</p>
<p>Table 3 shows the results of ablation studies, with the full version of the proposed model reported in the last line.We find that removing any module leads to performance degradation.This indicates that all designs contribute to the final performance.The MPSA brings a 4% performance gain, and KMCA brings a 2% performance gain.For designs in the knowledge minigraph construction agent, the performance gain brought by iterative construction is the largest, indicating its effectiveness in understanding long contexts.For designs in the multiple path summarization agent, the performance gain brought by the summarization router is the largest, indicating the importance of selecting the most desirable summaries from different logical paths.</p>
<p>Case Studies</p>
<p>This section conducts case studies to provide further insights into our model's performance.We first perform statistical analysis to validate in which cases the model succeeds and in which it fails.We group the test samples based on the number of references contained in the gold summary.In every group, we calculate the average ROUGE-L scores for CKMAs and its backbone model (vanilla GPT-3.5-turbo),comparing generated summaries with gold summaries.The results are presented in Fig. 3.We observe that CKMAs consistently outperforms vanilla GPT-3.5-turboregardless of the number of referencing papers.As the number of reference papers increases, the performance gap between CK-MAs and vanilla GPT-3.5-turbowidens.CKMAs demonstrates the capability to model complex relationships within long context, even achieving better results due to more references benefiting the understanding of the research, in contrast to the performance decrease observed in vanilla GPT-3.5-turbo.</p>
<p>For a detailed comparison, we sample an instance from the Multi-Xscience dataset and use well-known LLMs, GPT-3.5-turbo and GPT 4.0, to generate summaries with the default requirements listed in Table 1.The generated results are shown in Table 4.We find that GPT-3.5-turbosuffers from information loss, omitting citation 13.GPT 4.0 shows improvement but lists facts in parallel without logical connections.For example, citations 37 and 14 are listed side by side, but show no parallel logical relationship.It can even lead to hallucination problems, as no evidence shows citation 16 is a statistical method, while citation 16 and citations 3, 6, 5 are all categorized as statistical methods.We then use different versions of the proposed CKMAs to generate a summary.It can be observed that without the knowledge minigraph construction agent (KMCA), the multiple path summarization agent (MPSA) contributes to highlighting different categories of algorithms from the desired viewpoint.Without MPSA, the KMCA contributes to organizing algorithms logically, e.g., from probabilistic to statistical approaches, and then to example-based learning methods.With Information missing: @cite_13 is missing … word sense disambiguation … the naive mix algorithm as introduced by @cite_37 … @cite_14 presents a novel probabilistic modeling technique … the findings of @cite_16 highlight … @cite_5's comparative analysis of learning algorithms underscores … @cite_24 provides empirical support for …</p>
<p>Hallucinated logic: @cite_16's parallel … @cite_24 noted the relationship between sense and collocation while @cite_13 emphasized the value of context … @cite_37 and @cite_14 … the former unveiling the naive mix algorithm ... and the latter … focusing on systematic variable interactions … the exemplar-based learning algorithm … @cite_3 … @cite_6 @cite_5 and @cite_16 further broaden the conversation through the use of statistical methods …</p>
<p>Highlights key information, e.g., models word sense disambiguation … for instance, @cite_13 demonstrated the effectiveness of … while @cite_16 presented a model selection approach … similarly @cite_3 presents an exemplar-based learning algorithm … furthermore @cite_24 shows that a polysemous word … @cite_37… @cite_14 … probabilistic models … statistical methods … @cite_6 … Organized logic, e.g., probabilistic to statistical … word sense disambiguation … for instance @cite_37 and @cite_14 proposed probabilistic models … cite 6 on the … statistical sense resolution methods … furthermore @cite_3 presented exemplar-based learning … @cite_24 showed that a polysemous word … @cite_5 compared seven different learning algorithms … finally @cite_16 expanded existing model selection methodology …</p>
<p>Organized logic, highlight key information … word sense disambiguation including supervised learning algorithms such as … @cite_37 … probabilistic models … @cite_14 and … statistical methods @cite_6 … other approaches include exemplar-based learning … @cite_3 model selection … @cite_16 and … @cite_13 additionally …. @cite_24 and … @cite_5 these approaches … evaluated using various criteria …</p>
<p>Human written summary, special focus word sense disambiguation has more commonly been cast as a problem in supervised learning, e.g., @cite_13 @cite_2 @cite_24 @cite_6 @cite_14 @cite_5 @cite_3 @cite_16 @cite_37 … both modules, CKMAs generates the best summary, categorizing algorithms as supervised learning as in the gold sumand detailing subcategories in a logical order.We then analyze the differences between queried public knowledge graphs and the constructed knowledge minigraphs.We sample an instance from the Multi-Xscience dataset for this comparison.To query the knowledge graph, we use SPARQL to access Wikidata, a collaborative knowledge base.The queried knowledge graph is shown in the upper part of Fig. 4. For the knowledge minigraph, we employ the proposed method with knowledge minigraph construction, with the result displayed in the lower part.We observe that the entities in the queried knowledge graph are generalpurpose and lack specific insights into research problems.The minigraph clearly presents tasks and methods (some including metrics and materials), making it more informative for summarization purposes.</p>
<p>Conclusions and Future Work</p>
<p>This paper aims to provide an intelligent research copilot to assist in writing literature reviews based on given references.While recent LLMs excel at natural language understanding and generation, they struggle to explicitly model complex relationships between ideas from multiple papers.To address this challenge, we propose collaborative knowledge minigraph agents (CKMAs).The contributions of this work are threefold: (1) We propose scientific document-oriented knowledge minigraphs and, for the first time, equip LLMs with knowledge minigraphs for multiple scientific document summarization.(2) We are the first to develop a promptbased iterative algorithm to process a vast amount of literature and automatically construct knowledge minigraphs for multiple scientific document summarization.(3) We firstly introduce a mixture of experts' mechanisms to attempt the organization of literature reviews with different logical paths on minigraphs and derive the best one via self-evaluation.</p>
<p>We conduct comparison experiments, ablation studies,  and case studies.The results show the effectiveness of the proposed method.For future work, we plan to explore finetuning LLMs with the proposed CKMAs to better follow instructions and approximate human-written literature reviews in collected datasets.We also intend to investigate the possibility of generating full survey papers with multiple paragraphs, which involve more scientific documents and more complex relationships and require planning of the survey paper's organization.</p>
<p>Figure 2 :
2
Figure 2: The overall architecture of the proposed collaborative knowledge minigraph agents (CKMAs).</p>
<p>Figure 3 :
3
Figure 3: ROUGE score comparison of the proposed CK-MAs with its backbone models (vanilla GPT-3.5-turbo) group by reference paper number on the Multi-Xscience dataset.</p>
<p>Figure 4 :
4
Figure 4: Case study of knowledge graphs queried from Wikidata (top) and knowledge minigraph constructed by CKMAs (bottom) for the topic "image denoising".</p>
<p>Table 1 :
1
Prompts in the knowledge minigraph construction agent and the multiple path summarization agent.
Knowledge Minigraph Construction Agent (KMCA)Multiple Path Summarization Agent (MPSA)DescriptionPromptDescriptionPromptRole Play</p>
<p>(Zakkas, Verberne, and Zavrel 2024)ustrated in Table1, we instruct LLMs to take into consideration three kinds of information: the scientific article's abstract A, summaries of referenced paper {C i 1 , ...C i k }, and the knowledge minigraphs of referenced paper O.After understanding this information, the LLM is tasked with writing a summary for each chunk, where A and {C i 1 , ...C i k } provide textual details locally and O provide structural knowledge globally.Flexible to customize other instruction details, such as specifying writing style in real-world applications, the default instructions follow the prompts designed by Zakkas et al.(Zakkas, Verberne, and Zavrel 2024)for fair comparison.Mathematically, the chunk summarization can be denoted as:
Scientific article's abstract: {{abstract}}Referenced documents' summaries:InputText: {{knowledge_graph} {{reference_index}}'s abstract -"{{reference_abstract}}" Extracted entities and relations:Input{{reference_index}}'s abstract -"{{reference_abstract}}" Referenced documents' knowledge graphs: {{knowledge_graphs}} Written paragraph:</p>
<p>Table 2 :
2
Comparasion of CKMAs with state-of-the-art methods on Multi-Xscience, TAS2, and TAD datasets.
MethodMulti-Xscience ROUGE-1 ROUGE-2 ROUGE-1 ROUGE-2 ROUGE-1 ROUGE-2 TAD TAS2LexRank (2004)30.195.5327.293.5027.043.18TexRank (2004)31.515.8326.803.6126.193.14GraphsHeterSumGraph (2020) GraphSum (2020)31.36 29.585.82 5.5427.85 26.123.88 4.0327.56 25.013.62 3.23TAG (2022)33.457.0630.486.1628.044.75KGSum (2022)35.777.5132.385.1930.674.76Pointer-Generator (2017)34.116.7631.706.4128.534.96BertABS (2019)31.565.0227.424.8825.453.82SciBertABS (2019)32.125.5927.885.1926.014.13HiMAP (2019)31.665.9130.496.2128.375.07BART (2020)32.836.3625.394.7427.734.80PLMsMGSum (2020)33.116.7527.494.7925.543.75PRIMERA (2022)31.907.4032.045.7829.995.07GPT-3.5-turbo (2023)31.117.3830.774.7826..974.14GPT-4 (2023)33.217.6132.504.9030.714.253A-COT (2024)23.654.8523.023.7322.653.43SumBlogger (2024)35.408.4033.905.5130.693.92Proposed36.418.7834.166.2232.315.36</p>
<p>Table 3 :
3
Ablation study of the proposed collaborative knowledge minigraph agents (CKMAs) on the Multi-Xscience dataset.
Knowledge Minigraph Construction Agent (KMCA)Multiple Path Summarization Agent (MPSA)Scientific Constraint Constraint Construction Volume IterativeROUGE-1 ROUGE-2Chunk Summary Permutation PathSummary ROUGE-1 ROUGE-2 Router×××34.908.56×××32.045.54×✓✓35.698.62×✓✓33.296.47✓×✓35.508.59✓×✓34.007.09✓✓×35.048.57✓✓×32.186.32✓✓✓36.418.78✓✓✓36.418.7835 403336 3738 39 38 39 39 39 39 40 39 40 383640 39 38 3835Average ROUGE score5 10 15 20 25 306 7 7 8 9 8 8 9 8 8 8 9 9 9 7 7 8 9 10 10 10 10 11 11 11 11 11 12 11 11 28 30 32 33 34 32 34 34 33 33 33 32 32 35 3010 13 338 7 7 11 11 12 12 9 30 28 27 2901 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20Reference paper numberCKMAs' ROUGE-1CKMAs' ROUGE-2Vanilla LLM's ROUGE-1Vanilla LLM's ROUGE-2</p>
<p>Table 4 :
4
Case study of the proposed collaborative knowledge minigraph agents (CKMAs) on the Multi-Xscience dataset.
ChatGPT 3.5 (ROUGE-1: 29.50)GPT 4.0 (ROUGE-1: 33.46)Proposed w/o KMC (ROUGE-1: 38.91)</p>
<p>SciBERT: A Pretrained Language Model for Scientific Text. J Achiam, S Adler, S Agarwal, L Ahmad, I Akkaya, F L Aleman, D Almeida, J Altenschmidt, S Altman, S Anadkat, arXiv:2303.08774Conference on Empirical Methods in Natural Language Processing. 2023. 2019arXiv preprintGpt-4 technical report</p>
<p>Longformer: The long-document transformer. I Beltagy, M E Peters, A Cohan, arXiv:2004.051502020arXiv preprint</p>
<p>F Bolanos, A Salatino, F Osborne, E Motta, arXiv:2402.08565Artificial intelligence for literature reviews: Opportunities and challenges. 2024arXiv preprint</p>
<p>Target-aware abstractive related work generation with contrastive learning. X Chen, H Alamro, M Li, S Gao, R Yan, X Gao, X Zhang, International ACM SIGIR Conference on Research and Development in Information Retrieval. 2022</p>
<p>Lexrank: Graph-based lexical centrality as salience in text summarization. G Erkan, D R Radev, Journal of Artificial Intelligence Research. 222004</p>
<p>Multi-News: A Large-Scale Multi-Document Summarization Dataset and Abstractive Hierarchical Model. A R Fabbri, I Li, T She, S Li, D Radev, Annual Meeting of the Association for Computational Linguistics. 2019</p>
<p>Multi-granularity interaction network for extractive and abstractive multidocument summarization. H Jin, T Wang, X Wan, Annual Meeting of the Association for Computational Linguistics. 2020</p>
<p>. M Lewis, Y Liu, N Goyal, M Ghazvininejad, A Mohamed, O Levy, V Stoyanov, L Zettlemoyer, </p>
<p>Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension. Annual Meeting of the Association for Computational Linguistics. BART</p>
<p>Leveraging Graph to Improve Abstractive Multi-Document Summarization. W Li, X Xiao, J Liu, H Wu, H Wang, J Du, Annual Meeting of the Association for Computational Linguistics. 2020</p>
<p>Related Work and Citation Text Generation: A Survey. X Li, J Ouyang, arXiv:2404.115882024arXiv preprint</p>
<p>Rouge: A package for automatic evaluation of summaries. C.-Y Lin, Text summarization branches out. 2004</p>
<p>Generating a structured summary of numerous academic papers: Dataset and method. S Liu, J Cao, R Yang, Z Wen, International Joint Conference on Artificial Intelligence. 2022</p>
<p>Text Summarization with Pretrained Encoders. Y Liu, M Lapata, Conference on Empirical Methods in Natural Language Processing. 2019</p>
<p>Multi-XScience: A Large-scale Dataset for Extreme Multi-document Summarization of Scientific Articles. Y Lu, Y Dong, L Charlin, Conference on Empirical Methods in Natural Language Processing. 2020</p>
<p>Shallow Synthesis of Knowledge in GPT-Generated Texts: A Case Study in Automatic Related Work Composition. A Martin-Boyle, A Tyagi, M A Hearst, D Kang, arXiv:2402.122552024arXiv preprint</p>
<p>Textrank: Bringing order into text. R Mihalcea, P Tarau, Conference on Empirical Methods in Natural Language Processing. 2004</p>
<p>S Minaee, T Mikolov, N Nikzad, M Chenaghlu, R Socher, X Amatriain, J Gao, arXiv:2402.06196Large language models: A survey. 2024arXiv preprint</p>
<p>Training language models to follow instructions with human feedback. L Ouyang, J Wu, X Jiang, D Almeida, C Wainwright, P Mishkin, C Zhang, S Agarwal, K Slama, A Ray, Advances in Neural Information Processing Systems. 202235</p>
<p>Large language models sensitivity to the order of options in multiple-choice questions. P Pezeshkpour, E Hruschka, A See, P J Liu, C D Manning, arXiv:2308.11483Annual Meeting of the Association for Computational Linguistics. 2023. 2017arXiv preprintGet To The Point: Summarization with Pointer-Generator Networks</p>
<p>N Shazeer, A Mirhoseini, K Maziarz, A Davis, Q Le, G Hinton, J Dean, arXiv:1701.06538Outrageously large neural networks: The sparsely-gated mixture-of-experts layer. 2017arXiv preprint</p>
<p>Towards a Unified Framework for Reference Retrieval and Related Work Generation. Z Shi, S Gao, Z Zhang, X Chen, Z Chen, P Ren, Z Ren, 2023Findings of the Association for Computational Linguistics</p>
<p>Large language model (llm) as a system of multiple expert agents: An approach to solve the abstraction and reasoning corpus (arc) challenge. J C M Tan, M Motani, arXiv:2310.051462023arXiv preprint</p>
<p>Enhancing knowledge graph construction using large language models. M Trajanoska, R Stojanov, D Trajanov, arXiv:2305.046762023arXiv preprint</p>
<p>Automation of systematic literature reviews: A systematic literature review. R Van Dinter, B Tekinerdogan, C Catal, Information and Software Technology. 1361065892021</p>
<p>Entity, Relation, and Event Extraction with Contextualized Span Representations. D Wadden, U Wennberg, Y Luan, H Hajishirzi, Conference on Empirical Methods in Natural Language Processing. 2019</p>
<p>Artificial intelligence and the conduct of literature reviews. G Wagner, R Lukyanenko, G Paré, Journal of Information Technology. 3722022</p>
<p>Heterogeneous Graph Neural Networks for Extractive Document Summarization. D Wang, P Liu, Y Zheng, X Qiu, X.-J Huang, Annual Meeting of the Association for Computational Linguistics. 2020</p>
<p>Scientific discovery in the age of artificial intelligence. H Wang, T Fu, Y Du, W Gao, K Huang, Z Liu, P Chandak, S Liu, P Van Katwyk, A Deac, Nature. 62079722023</p>
<p>Multi-Document Scientific Summarization from a Knowledge Graph-Centric View. P Wang, S Li, K Pang, L He, D Li, J Tang, T Wang, International Conference on Computational Linguistics. 2022</p>
<p>Towards a Human-Computer Collaborative Scientific Paper Lifecycle: A Pilot Study and Hands-On Tutorial. Q Wang, C Edwards, H Ji, T Hope, Joint International Conference on Computational Linguistics, Language Resources and EvaluationSummaries. 2024</p>
<p>PRIMERA: Pyramid-based Masked Sentence Pre-training for Multi-document Summarization. W Xiao, I Beltagy, G Carenini, A Cohan, Annual Meeting of the Association for Computational Linguistics. 2022</p>
<p>SumBlogger: Abstractive Summarization of Large Collections of Scientific Articles. P Zakkas, S Verberne, J Zavrel, European Conference on Information Retrieval. 2024</p>
<p>3A-COT: an attend-arrange-abstract chain-of-thought for multi-document summarization. Y Zhang, S Gao, Y Huang, Z Yu, K Tan, International Journal of Machine Learning and Cybernetics. 2024a</p>
<p>Found in the middle: How language models use long contexts better via plug-and-play positional encoding. Z Zhang, R Chen, S Liu, Z Yao, O Ruwase, B Chen, X Wu, Z Wang, W X Zhao, K Zhou, J Li, T Tang, X Wang, Y Hou, Y Min, B Zhang, J Zhang, Z Dong, arXiv:2403.04797arXiv:2303.182232024barXiv preprintet al. 2023. A survey of large language models</p>
<p>A survey on application of knowledge graph. X Zou, Journal of Physics: Conference Series. 2020. 0120161487</p>            </div>
        </div>

    </div>
</body>
</html>