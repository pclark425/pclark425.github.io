<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-3326 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-3326</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-3326</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-76.html">extraction-schema-76</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models using diverse reasoning methods versus similar reasoning styles to solve reasoning problems, including details of the reasoning methods, tasks, model types, and performance comparisons.</div>
                <p><strong>Paper ID:</strong> paper-507acddb0b7f36b83fd7c8bff2f121eb506ac8fb</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/507acddb0b7f36b83fd7c8bff2f121eb506ac8fb" target="_blank">Cumulative Reasoning with Large Language Models</a></p>
                <p><strong>Paper Venue:</strong> Trans. Mach. Learn. Res.</p>
                <p><strong>Paper TL;DR:</strong> C Cumulative Reasoning is introduced, a structured framework that enhances LLM problem-solving by emulating human-like iterative and cumulative thought processes and outperforms existing methods in logical inference tasks with up to a 9.3% improvement.</p>
                <p><strong>Paper Abstract:</strong> Recent advancements in large language models (LLMs) have shown remarkable progress, yet their ability to solve complex problems remains limited. In this work, we introduce Cumulative Reasoning (CR), a structured framework that enhances LLM problem-solving by emulating human-like iterative and cumulative thought processes. CR orchestrates LLMs in three distinct roles--Proposer, Verifier(s), and Reporter--to systematically decompose tasks, generate and validate intermediate reasoning steps, and compose them into a solution by building a dynamic Directed Acyclic Graph (DAG) of verified propositions. This approach substantially enhances problem-solving capabilities. We demonstrate CR's advantage through several complex reasoning tasks: it outperforms existing methods in logical inference tasks with up to a 9.3% improvement, achieving 98.04% accuracy on the curated FOLIO wiki dataset. In the Game of 24, it achieves 98% accuracy, marking a 24% improvement over previous methods. In solving MATH problems, CR achieves a 4.2% increase from previous methods and a 43% relative improvement in the most challenging level 5 problems. When incorporating a code environment with CR, we further harness LLMs'reasoning capabilities and outperform the Program of Thought (PoT) method by 38.8%. The code is available at https://github.com/iiis-ai/cumulative-reasoning.</p>
                <p><strong>Cost:</strong> 0.018</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e3326.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e3326.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models using diverse reasoning methods versus similar reasoning styles to solve reasoning problems, including details of the reasoning methods, tasks, model types, and performance comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A high-capacity chat-format large language model from OpenAI used as the main LLM backbone in multiple experiments; evaluated with different prompting/decoding strategies and with/without a Python code verifier.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Transformer-based large language model accessed via OpenAI chat API; used here as the underlying LLM for Proposer/Verifier/Reporter roles and for baselines (Direct, CoT, CoT-SC, Complex CoT).</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods</strong></td>
                            <td>['Direct', 'Chain-of-Thought (CoT)', 'CoT with Self-Consistency (CoT-SC)', 'Complex CoT', 'Cumulative Reasoning (CR)', 'CR with Python code environment (CR w/ code)', 'Tree-of-Thought (ToT) (baseline comparison)', 'Progressive-Hint Prompting (PHP) (used in comparisons)']</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods_description</strong></td>
                            <td>Direct: single-shot answer generation. CoT: elicit step-by-step natural-language chains. CoT-SC: sample multiple CoT traces and take majority (self-consistency). Complex CoT: hand-crafted richer few-shot CoT prompts. CR: iterative proposer/verifier/reporter roles; proposer proposes candidate steps, verifier(s) validate (natural-language/verifier or symbolic/code), reporter decides termination; CR stores validated propositions in a DAG across iterations. CR w/ code: same CR flow but verifications executed in a Python interpreter (semi-symbolic verification), allowing exact arithmetic/symbolic checks. ToT and PHP used as comparative baselines from prior work.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_of_methods</strong></td>
                            <td>Diverse: paper evaluates and contrasts multiple distinct reasoning styles. CR explicitly implements a multi-role, multi-step, iterative and accumulative reasoning procedure (qualitatively different from single linear CoT and from multiple similar-sampled chains like CoT-SC). CR w/ code further mixes neural reasoning with symbolic/code verification (hybrid).</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_name</strong></td>
                            <td>FOLIO-wiki, FOLIO-wiki-curated, Game of 24, MATH (levels 1-5)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_description</strong></td>
                            <td>FOLIO-wiki: first-order logical inference problems from Wikipedia-derived examples (labels: True/False/Unknown). FOLIO-wiki-curated: cleaned subset. Game of 24: arithmetic puzzle using four integers to reach 24. MATH: benchmark of math problems across topics and difficulty levels (1-5).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_by_method</strong></td>
                            <td>FOLIO-wiki (GPT-4): Direct 80.52% | CoT 84.46% | CoT-SC (k=16) 85.02% | CR (n=2) 87.45%. FOLIO-wiki-curated (GPT-4): Direct 89.57% | CoT 95.00% | CoT-SC 96.09% | CR (n=2) 98.04%. Game of 24 (GPT-4): ToT (b=5) 74% acc (visited states 61.72) | CR (b=5) 98% acc (visited states ~14.86) with intermediate CR breadths: b=1:84% (11.68 states), b=2:94% (13.70), b=3:97% (14.25). MATH (without code, GPT-4): Complex CoT (repro., 8-shot) overall 50.36% (or 53.90% w/ PHP) | CR w/o code (ours, 4-shot) overall 54.20% (58.00% w/ PHP). MATH Level 5 (no code): Complex CoT 22.4% -> CR w/o code 32.1% (9.7 percentage points, 43% relative). MATH (with Python code environment, GPT-4): PAL baseline ~51.8% overall | ToRA ~61.6% | CR w/ code (ours, 2-shot) 72.2% overall; Level 5 CR w/ code 52.2% (compared to PAL* 31.3%, ToRA* 46.3%). The paper also reports CR outperforming Program-of-Thought (PoT) by ≈38.8% (abstract claim) when integrating code environment.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_of_methods</strong></td>
                            <td>Explicit experimental comparisons across Direct, CoT, CoT-SC, ToT, and CR. Key contrasts: CoT produces linear single-chain reasoning; CoT-SC obtains diverse but similar-style chains by sampling and majority voting; ToT explores multiple branches in a tree (breadth/depth fixed) and filters candidates; CR accumulates validated propositions in a DAG and uses dedicated verifier(s) to exclude invalid steps early. Empirically, CR consistently outperforms other methods across logical inference (FOLIO variants), Game of 24, and MATH benchmarks; CR w/ code especially outperforms program-aided baselines (PAL, ToRA) and prior PoT claim in abstract. Ablations show removing the Verifier from CR substantially degrades performance (e.g., GPT-3.5-turbo FOLIO drop from 73.03% to 64.23%).</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Using diverse reasoning machinery (CR's multi-role iterative pipeline and DAG-based accumulation) yields systematically better arrival probability to correct solutions than producing many similar reasoning traces (CoT-SC) or a fixed tree search (ToT). Hybridizing neural proposals with symbolic/code verification (CR w/ code) provides large gains on arithmetic and symbolic math problems (MATH), achieving state-of-the-art reported performance (e.g., 72.2% overall on MATH with GPT-4 + code).</td>
                        </tr>
                        <tr>
                            <td><strong>counter_examples_or_negative_results</strong></td>
                            <td>CoT-SC does not always improve over CoT: e.g., GPT-3.5-turbo CoT-SC (k=16) slightly underperforms CoT on FOLIO-wiki (63.33% vs 64.61%). Some prior methods (Direct, CoT) fail on particular examples (illustrated FOLIO case where CoT answered 'Unknown' but CR produced 'True'). Ablation: CR without verifier or without randomized premise selection loses much of its advantage. The paper notes some tasks where ToT slightly outperforms CR on specific validation sets (e.g., small differences in validation metrics reported in appendix), but overall CR is at least as good or better across main reported benchmarks.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Cumulative Reasoning with Large Language Models', 'publication_date_yy_mm': '2023-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3326.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e3326.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models using diverse reasoning methods versus similar reasoning styles to solve reasoning problems, including details of the reasoning methods, tasks, model types, and performance comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-3.5-turbo</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-3.5-turbo</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A widely-used OpenAI chat-format LLM used here as an experimental backbone for proposer/verifier/reporter roles and baseline comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5-turbo</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Chat-style transformer LLM from OpenAI accessed via chat API; used for role-instantiation in CR experiments and as baseline with Direct/CoT/CoT-SC.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods</strong></td>
                            <td>['Direct', 'Chain-of-Thought (CoT)', 'CoT with Self-Consistency (CoT-SC)', 'Cumulative Reasoning (CR)']</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods_description</strong></td>
                            <td>Same method implementations as described for GPT-4: Direct single-shot answers, CoT linear chains, CoT-SC sampling + majority, CR multi-role iterative proposer/verifier/reporter with DAG accumulation; role-specific few-shot prompts used to instantiate roles on same underlying LLM.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_of_methods</strong></td>
                            <td>Diverse within experiments: authors instantiate multiple distinct prompting/reasoning strategies (Direct, CoT, CoT-SC, CR) on the same model to contrast similar-style sampling vs structured multi-role reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_name</strong></td>
                            <td>FOLIO-wiki, FOLIO-wiki-curated (subset), Ablation studies</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_description</strong></td>
                            <td>Logical inference tasks from natural language premises (True/False/Unknown). Curated subset removes problematic instances for more robust evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_by_method</strong></td>
                            <td>FOLIO-wiki (GPT-3.5): Direct 62.92% | CoT 64.61% | CoT-SC (k=16) 63.33% | CR (n=2) 73.03%. FOLIO-wiki-curated (GPT-3.5): Direct 69.57% | CoT 70.65% | CoT-SC 69.32% | CR (n=2) 78.70%. Ablation (GPT-3.5, FOLIO-wiki): CR w/o Verifier 64.23%; CR w/o premises random choice 68.73%; CR w/o Verifier & w/o premises random choice 67.23% (shows verifier and premise-selection contribute materially to CR gains).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_of_methods</strong></td>
                            <td>Direct and CoT produce lower accuracy than CR on the same model. CoT-SC (self-consistency) sometimes fails to improve or slightly hurts compared to CoT (observed on GPT-3.5 for FOLIO-wiki). Ablations demonstrate the verifier role is crucial: removing verifier reduces CR to near-CoT performance.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>On the same underlying model (GPT-3.5), switching from similar-style methods (CoT/CoT-SC) to a more structured, diverse pipeline (CR) yields double-digit improvements in some settings (e.g., +10.11 percentage points on FOLIO-wiki). Verifier role (semi-symbolic or code) is a primary contributor to gains.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_examples_or_negative_results</strong></td>
                            <td>CoT-SC did not reliably improve over CoT for GPT-3.5 on FOLIO-wiki (CoT 64.61% vs CoT-SC 63.33%). Removing verifier or other CR components reduces benefit, indicating CR's advantage is contingent on its multi-role design and validation step.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Cumulative Reasoning with Large Language Models', 'publication_date_yy_mm': '2023-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3326.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e3326.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models using diverse reasoning methods versus similar reasoning styles to solve reasoning problems, including details of the reasoning methods, tasks, model types, and performance comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLaMA-13B</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLaMA 13B</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A 13-billion-parameter LLaMA-family transformer used as a smaller open-weight baseline to evaluate prompting strategies including CR, CoT, and CoT-SC.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLaMA-13B</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Open-weight transformer model (13B parameters) from the LLaMA family used in experiments as proposer/verifier/reporters via role-specific prompts.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>13B</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods</strong></td>
                            <td>['Direct', 'Chain-of-Thought (CoT)', 'CoT with Self-Consistency (CoT-SC)', 'Cumulative Reasoning (CR)', 'CR (n varied) in AutoTNLI']</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods_description</strong></td>
                            <td>Direct/CoT/CoT-SC baselines implemented with standard few-shot prompts; CR instantiated by applying role-specific few-shot prompts to the same LLaMA-13B model to perform proposer/verifier/reporter cycles; AutoTNLI experiments use n=4 intermediate propositions.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_of_methods</strong></td>
                            <td>Diverse methods evaluated on the same LLaMA model; CR introduces a distinct style (iterative, verified, DAG accumulation) different from the similar-style sampling of CoT-SC.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_name</strong></td>
                            <td>FOLIO-wiki, AutoTNLI</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_description</strong></td>
                            <td>FOLIO-wiki: first-order logic inference task; AutoTNLI: tabular natural language inference adapted from INFOTABS with table→premise encoding.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_by_method</strong></td>
                            <td>FOLIO-wiki (LLaMA-13B): Direct 44.75% | CoT 49.06% | CoT-SC (k=16) 52.43% | CR (n=2) 53.37%. AutoTNLI (LLaMA-13B, top-100 pairs): Direct 52.6% | CoT 54.1% | CoT-SC (k=16) 52.1% | CR (n=4) 57.0%.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_of_methods</strong></td>
                            <td>CR consistently improves over CoT and CoT-SC on both FOLIO-wiki and AutoTNLI for LLaMA-13B, indicating the structured, validated accumulation approach benefits smaller open models as well.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Even with a 13B model, CR provides measurable gains (≈+3-8 percentage points versus CoT/CoT-SC) across logical and tabular inference tasks, supporting that diverse structural reasoning (propose/verify/accumulate) helps beyond simply sampling multiple similar CoT traces.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_examples_or_negative_results</strong></td>
                            <td>None reported for LLaMA-13B where CR underperformed on the main reported tasks; however absolute accuracies remain lower than larger models, showing capacity still limits top performance.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Cumulative Reasoning with Large Language Models', 'publication_date_yy_mm': '2023-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3326.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e3326.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models using diverse reasoning methods versus similar reasoning styles to solve reasoning problems, including details of the reasoning methods, tasks, model types, and performance comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLaMA-65B</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLaMA 65B</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A 65-billion-parameter LLaMA-family transformer used to evaluate the scaling effects of reasoning strategies including CoT, CoT-SC, and CR.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLaMA-65B</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Open-weight transformer model (65B parameters) from the LLaMA family; experiments instantiate proposer/verifier/reporter roles on the same model with role-specific prompts.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>65B</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods</strong></td>
                            <td>['Direct', 'Chain-of-Thought (CoT)', 'CoT with Self-Consistency (CoT-SC)', 'Cumulative Reasoning (CR)']</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods_description</strong></td>
                            <td>Standard Direct/CoT/CoT-SC baselines and CR implemented via role-specific prompting on LLaMA-65B; AutoTNLI evaluated with CR (n=4) and FOLIO-wiki with CR (n=2).</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_of_methods</strong></td>
                            <td>Diverse; similar analysis as other models—CR is a structurally different method compared to traditional/sampling-based CoT approaches and tree-based ToT.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_name</strong></td>
                            <td>FOLIO-wiki, FOLIO-wiki-curated, AutoTNLI</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_description</strong></td>
                            <td>Same logical/tabular inference tasks; FOLIO-wiki-curated is a cleaned subset used to show gains after removing problematic examples.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_by_method</strong></td>
                            <td>FOLIO-wiki (LLaMA-65B): Direct 67.42% | CoT 67.42% | CoT-SC (k=16) 70.79% | CR (n=2) 72.10%. FOLIO-wiki-curated (LLaMA-65B): Direct 74.78% | CoT 74.13% | CoT-SC 79.13% | CR (n=2) 79.57%. AutoTNLI (LLaMA-65B): Direct 59.7% | CoT 63.2% | CoT-SC 61.7% | CR (n=4) 72.5% (notable +12.8 over CoT-SC).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_of_methods</strong></td>
                            <td>CR improves over CoT and CoT-SC notably on AutoTNLI (strong +12.8 percentage points versus CoT-SC for LLaMA-65B) and yields consistent improvements on FOLIO variants; demonstrates that CR's advantage persists at larger open-model scales.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>On a large open-weight model (65B), structured diverse reasoning (CR) leads to substantial improvements on tabular and logical inference tasks versus sampling-based or single-chain approaches; CR's dynamic DAG accumulation and verifier filtering are credited for improvements.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_examples_or_negative_results</strong></td>
                            <td>On FOLIO-wiki the improvement margin is smaller at the larger model scale (e.g., CoT and Direct tie in some cases), indicating model capacity reduces the delta between simple and structured prompting but CR still provides gains.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Cumulative Reasoning with Large Language Models', 'publication_date_yy_mm': '2023-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3326.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e3326.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models using diverse reasoning methods versus similar reasoning styles to solve reasoning problems, including details of the reasoning methods, tasks, model types, and performance comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Cumulative Reasoning (CR)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Cumulative Reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A multi-role, iterative reasoning framework that accumulates validated intermediate propositions in a DAG using proposer, verifier(s), and reporter roles to solve complex problems.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Cumulative Reasoning (applied to GPT-4 / GPT-3.5 / LLaMA variants)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Not a standalone LLM but a procedural framework instantiated by prompting the same underlying LLM into three roles (proposer, verifier(s), reporter); verifier(s) can use symbolic/code environments (e.g., Python) for high-precision checks.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods</strong></td>
                            <td>['Multi-role proposer/verifier/reporter', 'DAG accumulation of validated propositions', 'Iterative generation and verification', 'Hybrid neural + code verification (CR w/ code)']</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods_description</strong></td>
                            <td>Proposer: generates candidate reasoning steps given current accumulated validated propositions; Verifier(s): check candidate steps (in natural language or by executing code/symbolic checks), rejecting invalid steps; Reporter: monitors accumulated validated graph and determines termination and final answer. The system stores verified propositions as nodes in a DAG enabling reuse and conditional probability increases for subsequent steps.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_of_methods</strong></td>
                            <td>Highly diverse: CR synthesizes multiple reasoning styles — generative proposal (neural), symbolic verification (code interpreter), and graph-structured memory — rather than relying on generating many similar linear traces. The paper emphasizes qualitative difference from CoT (single chain) and ToT (fixed tree search).</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_name</strong></td>
                            <td>FOLIO-wiki, FOLIO-wiki-curated, AutoTNLI, Game of 24, MATH (with and without code)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_description</strong></td>
                            <td>A collection of logical inference, tabular inference, arithmetic puzzle solving, and mathematical problem solving that stress multi-step deductive and computational reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_by_method</strong></td>
                            <td>CR across models: FOLIO-wiki (best reported): GPT-4 CR 87.45% vs CoT-SC 85.02%; FOLIO-wiki-curated GPT-4 CR 98.04% vs CoT-SC 96.09%. AutoTNLI LLaMA-65B CR 72.5% vs CoT-SC 61.7%. Game of 24 GPT-4 CR (b=5) 98% acc vs ToT (b=5) 74% (visited states CR ~14.86 vs ToT 61.72). MATH (no code) GPT-4 CR overall 54.20% vs Complex CoT 50.36% (4-shot setting); Level 5 CR 32.1% vs Complex CoT 22.4%. MATH with code GPT-4 CR w/ code 72.2% overall vs PAL 51.8% and ToRA 61.6%; Level 5 CR w/ code 52.2% (large relative gains).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_of_methods</strong></td>
                            <td>Paper provides direct comparisons and theoretical/empirical analyses: CR > ToT > CoT-SC >= CoT in arrival probability under assumptions; empirical tables across datasets reflect this ordering in most cases. Ablation studies demonstrate the importance of the verifier and premise selection. CR is particularly strong when paired with a code environment for exact checking.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>CR's combination of diverse reasoning components (neural proposal + verifier + DAG memory + reporter) yields higher arrival probabilities and substantially better empirical performance across diverse reasoning benchmarks compared to producing many similar CoT traces or fixed-tree exploration. Integrating symbolic/code verification amplifies gains (notably on arithmetic/math tasks).</td>
                        </tr>
                        <tr>
                            <td><strong>counter_examples_or_negative_results</strong></td>
                            <td>Benefits of CR depend on verifier fidelity and premise sampling; CR without verifier shows much smaller gains. In some validation sets and small-scale comparisons, ToT or CoT-SC can be competitive; the authors report small datasets where ToT has comparable performance (appendix) though main benchmarks favor CR.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Cumulative Reasoning with Large Language Models', 'publication_date_yy_mm': '2023-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Chain of Thought Prompting Elicits Reasoning in Large Language Models <em>(Rating: 2)</em></li>
                <li>Tree of Thoughts: Deliberate Problem Solving with Large Language Models <em>(Rating: 2)</em></li>
                <li>Self-Consistency Improves Chain of Thought Reasoning in Language Models <em>(Rating: 2)</em></li>
                <li>Program of Thoughts Prompting: Disentangling Computation from Reasoning for Numerical Reasoning Tasks <em>(Rating: 2)</em></li>
                <li>PAL: Program-aided Language Models <em>(Rating: 2)</em></li>
                <li>ToRA: A Tool-integrated Reasoning Agent for Mathematical Problem Solving <em>(Rating: 2)</em></li>
                <li>DIVERSE: Investigating Various Reasoning Paths and Verifier-weighted Voting <em>(Rating: 1)</em></li>
                <li>Progressive-hint Prompting Improves Reasoning in Large Language Models <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-3326",
    "paper_id": "paper-507acddb0b7f36b83fd7c8bff2f121eb506ac8fb",
    "extraction_schema_id": "extraction-schema-76",
    "extracted_data": [
        {
            "name_short": "GPT-4",
            "name_full": "GPT-4",
            "brief_description": "A high-capacity chat-format large language model from OpenAI used as the main LLM backbone in multiple experiments; evaluated with different prompting/decoding strategies and with/without a Python code verifier.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "GPT-4",
            "model_description": "Transformer-based large language model accessed via OpenAI chat API; used here as the underlying LLM for Proposer/Verifier/Reporter roles and for baselines (Direct, CoT, CoT-SC, Complex CoT).",
            "model_size": null,
            "reasoning_methods": [
                "Direct",
                "Chain-of-Thought (CoT)",
                "CoT with Self-Consistency (CoT-SC)",
                "Complex CoT",
                "Cumulative Reasoning (CR)",
                "CR with Python code environment (CR w/ code)",
                "Tree-of-Thought (ToT) (baseline comparison)",
                "Progressive-Hint Prompting (PHP) (used in comparisons)"
            ],
            "reasoning_methods_description": "Direct: single-shot answer generation. CoT: elicit step-by-step natural-language chains. CoT-SC: sample multiple CoT traces and take majority (self-consistency). Complex CoT: hand-crafted richer few-shot CoT prompts. CR: iterative proposer/verifier/reporter roles; proposer proposes candidate steps, verifier(s) validate (natural-language/verifier or symbolic/code), reporter decides termination; CR stores validated propositions in a DAG across iterations. CR w/ code: same CR flow but verifications executed in a Python interpreter (semi-symbolic verification), allowing exact arithmetic/symbolic checks. ToT and PHP used as comparative baselines from prior work.",
            "diversity_of_methods": "Diverse: paper evaluates and contrasts multiple distinct reasoning styles. CR explicitly implements a multi-role, multi-step, iterative and accumulative reasoning procedure (qualitatively different from single linear CoT and from multiple similar-sampled chains like CoT-SC). CR w/ code further mixes neural reasoning with symbolic/code verification (hybrid).",
            "reasoning_task_name": "FOLIO-wiki, FOLIO-wiki-curated, Game of 24, MATH (levels 1-5)",
            "reasoning_task_description": "FOLIO-wiki: first-order logical inference problems from Wikipedia-derived examples (labels: True/False/Unknown). FOLIO-wiki-curated: cleaned subset. Game of 24: arithmetic puzzle using four integers to reach 24. MATH: benchmark of math problems across topics and difficulty levels (1-5).",
            "performance_by_method": "FOLIO-wiki (GPT-4): Direct 80.52% | CoT 84.46% | CoT-SC (k=16) 85.02% | CR (n=2) 87.45%. FOLIO-wiki-curated (GPT-4): Direct 89.57% | CoT 95.00% | CoT-SC 96.09% | CR (n=2) 98.04%. Game of 24 (GPT-4): ToT (b=5) 74% acc (visited states 61.72) | CR (b=5) 98% acc (visited states ~14.86) with intermediate CR breadths: b=1:84% (11.68 states), b=2:94% (13.70), b=3:97% (14.25). MATH (without code, GPT-4): Complex CoT (repro., 8-shot) overall 50.36% (or 53.90% w/ PHP) | CR w/o code (ours, 4-shot) overall 54.20% (58.00% w/ PHP). MATH Level 5 (no code): Complex CoT 22.4% -&gt; CR w/o code 32.1% (9.7 percentage points, 43% relative). MATH (with Python code environment, GPT-4): PAL baseline ~51.8% overall | ToRA ~61.6% | CR w/ code (ours, 2-shot) 72.2% overall; Level 5 CR w/ code 52.2% (compared to PAL* 31.3%, ToRA* 46.3%). The paper also reports CR outperforming Program-of-Thought (PoT) by ≈38.8% (abstract claim) when integrating code environment.",
            "comparison_of_methods": "Explicit experimental comparisons across Direct, CoT, CoT-SC, ToT, and CR. Key contrasts: CoT produces linear single-chain reasoning; CoT-SC obtains diverse but similar-style chains by sampling and majority voting; ToT explores multiple branches in a tree (breadth/depth fixed) and filters candidates; CR accumulates validated propositions in a DAG and uses dedicated verifier(s) to exclude invalid steps early. Empirically, CR consistently outperforms other methods across logical inference (FOLIO variants), Game of 24, and MATH benchmarks; CR w/ code especially outperforms program-aided baselines (PAL, ToRA) and prior PoT claim in abstract. Ablations show removing the Verifier from CR substantially degrades performance (e.g., GPT-3.5-turbo FOLIO drop from 73.03% to 64.23%).",
            "key_findings": "Using diverse reasoning machinery (CR's multi-role iterative pipeline and DAG-based accumulation) yields systematically better arrival probability to correct solutions than producing many similar reasoning traces (CoT-SC) or a fixed tree search (ToT). Hybridizing neural proposals with symbolic/code verification (CR w/ code) provides large gains on arithmetic and symbolic math problems (MATH), achieving state-of-the-art reported performance (e.g., 72.2% overall on MATH with GPT-4 + code).",
            "counter_examples_or_negative_results": "CoT-SC does not always improve over CoT: e.g., GPT-3.5-turbo CoT-SC (k=16) slightly underperforms CoT on FOLIO-wiki (63.33% vs 64.61%). Some prior methods (Direct, CoT) fail on particular examples (illustrated FOLIO case where CoT answered 'Unknown' but CR produced 'True'). Ablation: CR without verifier or without randomized premise selection loses much of its advantage. The paper notes some tasks where ToT slightly outperforms CR on specific validation sets (e.g., small differences in validation metrics reported in appendix), but overall CR is at least as good or better across main reported benchmarks.",
            "uuid": "e3326.0",
            "source_info": {
                "paper_title": "Cumulative Reasoning with Large Language Models",
                "publication_date_yy_mm": "2023-08"
            }
        },
        {
            "name_short": "GPT-3.5-turbo",
            "name_full": "GPT-3.5-turbo",
            "brief_description": "A widely-used OpenAI chat-format LLM used here as an experimental backbone for proposer/verifier/reporter roles and baseline comparisons.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "GPT-3.5-turbo",
            "model_description": "Chat-style transformer LLM from OpenAI accessed via chat API; used for role-instantiation in CR experiments and as baseline with Direct/CoT/CoT-SC.",
            "model_size": null,
            "reasoning_methods": [
                "Direct",
                "Chain-of-Thought (CoT)",
                "CoT with Self-Consistency (CoT-SC)",
                "Cumulative Reasoning (CR)"
            ],
            "reasoning_methods_description": "Same method implementations as described for GPT-4: Direct single-shot answers, CoT linear chains, CoT-SC sampling + majority, CR multi-role iterative proposer/verifier/reporter with DAG accumulation; role-specific few-shot prompts used to instantiate roles on same underlying LLM.",
            "diversity_of_methods": "Diverse within experiments: authors instantiate multiple distinct prompting/reasoning strategies (Direct, CoT, CoT-SC, CR) on the same model to contrast similar-style sampling vs structured multi-role reasoning.",
            "reasoning_task_name": "FOLIO-wiki, FOLIO-wiki-curated (subset), Ablation studies",
            "reasoning_task_description": "Logical inference tasks from natural language premises (True/False/Unknown). Curated subset removes problematic instances for more robust evaluation.",
            "performance_by_method": "FOLIO-wiki (GPT-3.5): Direct 62.92% | CoT 64.61% | CoT-SC (k=16) 63.33% | CR (n=2) 73.03%. FOLIO-wiki-curated (GPT-3.5): Direct 69.57% | CoT 70.65% | CoT-SC 69.32% | CR (n=2) 78.70%. Ablation (GPT-3.5, FOLIO-wiki): CR w/o Verifier 64.23%; CR w/o premises random choice 68.73%; CR w/o Verifier & w/o premises random choice 67.23% (shows verifier and premise-selection contribute materially to CR gains).",
            "comparison_of_methods": "Direct and CoT produce lower accuracy than CR on the same model. CoT-SC (self-consistency) sometimes fails to improve or slightly hurts compared to CoT (observed on GPT-3.5 for FOLIO-wiki). Ablations demonstrate the verifier role is crucial: removing verifier reduces CR to near-CoT performance.",
            "key_findings": "On the same underlying model (GPT-3.5), switching from similar-style methods (CoT/CoT-SC) to a more structured, diverse pipeline (CR) yields double-digit improvements in some settings (e.g., +10.11 percentage points on FOLIO-wiki). Verifier role (semi-symbolic or code) is a primary contributor to gains.",
            "counter_examples_or_negative_results": "CoT-SC did not reliably improve over CoT for GPT-3.5 on FOLIO-wiki (CoT 64.61% vs CoT-SC 63.33%). Removing verifier or other CR components reduces benefit, indicating CR's advantage is contingent on its multi-role design and validation step.",
            "uuid": "e3326.1",
            "source_info": {
                "paper_title": "Cumulative Reasoning with Large Language Models",
                "publication_date_yy_mm": "2023-08"
            }
        },
        {
            "name_short": "LLaMA-13B",
            "name_full": "LLaMA 13B",
            "brief_description": "A 13-billion-parameter LLaMA-family transformer used as a smaller open-weight baseline to evaluate prompting strategies including CR, CoT, and CoT-SC.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "LLaMA-13B",
            "model_description": "Open-weight transformer model (13B parameters) from the LLaMA family used in experiments as proposer/verifier/reporters via role-specific prompts.",
            "model_size": "13B",
            "reasoning_methods": [
                "Direct",
                "Chain-of-Thought (CoT)",
                "CoT with Self-Consistency (CoT-SC)",
                "Cumulative Reasoning (CR)",
                "CR (n varied) in AutoTNLI"
            ],
            "reasoning_methods_description": "Direct/CoT/CoT-SC baselines implemented with standard few-shot prompts; CR instantiated by applying role-specific few-shot prompts to the same LLaMA-13B model to perform proposer/verifier/reporter cycles; AutoTNLI experiments use n=4 intermediate propositions.",
            "diversity_of_methods": "Diverse methods evaluated on the same LLaMA model; CR introduces a distinct style (iterative, verified, DAG accumulation) different from the similar-style sampling of CoT-SC.",
            "reasoning_task_name": "FOLIO-wiki, AutoTNLI",
            "reasoning_task_description": "FOLIO-wiki: first-order logic inference task; AutoTNLI: tabular natural language inference adapted from INFOTABS with table→premise encoding.",
            "performance_by_method": "FOLIO-wiki (LLaMA-13B): Direct 44.75% | CoT 49.06% | CoT-SC (k=16) 52.43% | CR (n=2) 53.37%. AutoTNLI (LLaMA-13B, top-100 pairs): Direct 52.6% | CoT 54.1% | CoT-SC (k=16) 52.1% | CR (n=4) 57.0%.",
            "comparison_of_methods": "CR consistently improves over CoT and CoT-SC on both FOLIO-wiki and AutoTNLI for LLaMA-13B, indicating the structured, validated accumulation approach benefits smaller open models as well.",
            "key_findings": "Even with a 13B model, CR provides measurable gains (≈+3-8 percentage points versus CoT/CoT-SC) across logical and tabular inference tasks, supporting that diverse structural reasoning (propose/verify/accumulate) helps beyond simply sampling multiple similar CoT traces.",
            "counter_examples_or_negative_results": "None reported for LLaMA-13B where CR underperformed on the main reported tasks; however absolute accuracies remain lower than larger models, showing capacity still limits top performance.",
            "uuid": "e3326.2",
            "source_info": {
                "paper_title": "Cumulative Reasoning with Large Language Models",
                "publication_date_yy_mm": "2023-08"
            }
        },
        {
            "name_short": "LLaMA-65B",
            "name_full": "LLaMA 65B",
            "brief_description": "A 65-billion-parameter LLaMA-family transformer used to evaluate the scaling effects of reasoning strategies including CoT, CoT-SC, and CR.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "LLaMA-65B",
            "model_description": "Open-weight transformer model (65B parameters) from the LLaMA family; experiments instantiate proposer/verifier/reporter roles on the same model with role-specific prompts.",
            "model_size": "65B",
            "reasoning_methods": [
                "Direct",
                "Chain-of-Thought (CoT)",
                "CoT with Self-Consistency (CoT-SC)",
                "Cumulative Reasoning (CR)"
            ],
            "reasoning_methods_description": "Standard Direct/CoT/CoT-SC baselines and CR implemented via role-specific prompting on LLaMA-65B; AutoTNLI evaluated with CR (n=4) and FOLIO-wiki with CR (n=2).",
            "diversity_of_methods": "Diverse; similar analysis as other models—CR is a structurally different method compared to traditional/sampling-based CoT approaches and tree-based ToT.",
            "reasoning_task_name": "FOLIO-wiki, FOLIO-wiki-curated, AutoTNLI",
            "reasoning_task_description": "Same logical/tabular inference tasks; FOLIO-wiki-curated is a cleaned subset used to show gains after removing problematic examples.",
            "performance_by_method": "FOLIO-wiki (LLaMA-65B): Direct 67.42% | CoT 67.42% | CoT-SC (k=16) 70.79% | CR (n=2) 72.10%. FOLIO-wiki-curated (LLaMA-65B): Direct 74.78% | CoT 74.13% | CoT-SC 79.13% | CR (n=2) 79.57%. AutoTNLI (LLaMA-65B): Direct 59.7% | CoT 63.2% | CoT-SC 61.7% | CR (n=4) 72.5% (notable +12.8 over CoT-SC).",
            "comparison_of_methods": "CR improves over CoT and CoT-SC notably on AutoTNLI (strong +12.8 percentage points versus CoT-SC for LLaMA-65B) and yields consistent improvements on FOLIO variants; demonstrates that CR's advantage persists at larger open-model scales.",
            "key_findings": "On a large open-weight model (65B), structured diverse reasoning (CR) leads to substantial improvements on tabular and logical inference tasks versus sampling-based or single-chain approaches; CR's dynamic DAG accumulation and verifier filtering are credited for improvements.",
            "counter_examples_or_negative_results": "On FOLIO-wiki the improvement margin is smaller at the larger model scale (e.g., CoT and Direct tie in some cases), indicating model capacity reduces the delta between simple and structured prompting but CR still provides gains.",
            "uuid": "e3326.3",
            "source_info": {
                "paper_title": "Cumulative Reasoning with Large Language Models",
                "publication_date_yy_mm": "2023-08"
            }
        },
        {
            "name_short": "Cumulative Reasoning (CR)",
            "name_full": "Cumulative Reasoning",
            "brief_description": "A multi-role, iterative reasoning framework that accumulates validated intermediate propositions in a DAG using proposer, verifier(s), and reporter roles to solve complex problems.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Cumulative Reasoning (applied to GPT-4 / GPT-3.5 / LLaMA variants)",
            "model_description": "Not a standalone LLM but a procedural framework instantiated by prompting the same underlying LLM into three roles (proposer, verifier(s), reporter); verifier(s) can use symbolic/code environments (e.g., Python) for high-precision checks.",
            "model_size": null,
            "reasoning_methods": [
                "Multi-role proposer/verifier/reporter",
                "DAG accumulation of validated propositions",
                "Iterative generation and verification",
                "Hybrid neural + code verification (CR w/ code)"
            ],
            "reasoning_methods_description": "Proposer: generates candidate reasoning steps given current accumulated validated propositions; Verifier(s): check candidate steps (in natural language or by executing code/symbolic checks), rejecting invalid steps; Reporter: monitors accumulated validated graph and determines termination and final answer. The system stores verified propositions as nodes in a DAG enabling reuse and conditional probability increases for subsequent steps.",
            "diversity_of_methods": "Highly diverse: CR synthesizes multiple reasoning styles — generative proposal (neural), symbolic verification (code interpreter), and graph-structured memory — rather than relying on generating many similar linear traces. The paper emphasizes qualitative difference from CoT (single chain) and ToT (fixed tree search).",
            "reasoning_task_name": "FOLIO-wiki, FOLIO-wiki-curated, AutoTNLI, Game of 24, MATH (with and without code)",
            "reasoning_task_description": "A collection of logical inference, tabular inference, arithmetic puzzle solving, and mathematical problem solving that stress multi-step deductive and computational reasoning.",
            "performance_by_method": "CR across models: FOLIO-wiki (best reported): GPT-4 CR 87.45% vs CoT-SC 85.02%; FOLIO-wiki-curated GPT-4 CR 98.04% vs CoT-SC 96.09%. AutoTNLI LLaMA-65B CR 72.5% vs CoT-SC 61.7%. Game of 24 GPT-4 CR (b=5) 98% acc vs ToT (b=5) 74% (visited states CR ~14.86 vs ToT 61.72). MATH (no code) GPT-4 CR overall 54.20% vs Complex CoT 50.36% (4-shot setting); Level 5 CR 32.1% vs Complex CoT 22.4%. MATH with code GPT-4 CR w/ code 72.2% overall vs PAL 51.8% and ToRA 61.6%; Level 5 CR w/ code 52.2% (large relative gains).",
            "comparison_of_methods": "Paper provides direct comparisons and theoretical/empirical analyses: CR &gt; ToT &gt; CoT-SC &gt;= CoT in arrival probability under assumptions; empirical tables across datasets reflect this ordering in most cases. Ablation studies demonstrate the importance of the verifier and premise selection. CR is particularly strong when paired with a code environment for exact checking.",
            "key_findings": "CR's combination of diverse reasoning components (neural proposal + verifier + DAG memory + reporter) yields higher arrival probabilities and substantially better empirical performance across diverse reasoning benchmarks compared to producing many similar CoT traces or fixed-tree exploration. Integrating symbolic/code verification amplifies gains (notably on arithmetic/math tasks).",
            "counter_examples_or_negative_results": "Benefits of CR depend on verifier fidelity and premise sampling; CR without verifier shows much smaller gains. In some validation sets and small-scale comparisons, ToT or CoT-SC can be competitive; the authors report small datasets where ToT has comparable performance (appendix) though main benchmarks favor CR.",
            "uuid": "e3326.4",
            "source_info": {
                "paper_title": "Cumulative Reasoning with Large Language Models",
                "publication_date_yy_mm": "2023-08"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Chain of Thought Prompting Elicits Reasoning in Large Language Models",
            "rating": 2
        },
        {
            "paper_title": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models",
            "rating": 2
        },
        {
            "paper_title": "Self-Consistency Improves Chain of Thought Reasoning in Language Models",
            "rating": 2
        },
        {
            "paper_title": "Program of Thoughts Prompting: Disentangling Computation from Reasoning for Numerical Reasoning Tasks",
            "rating": 2
        },
        {
            "paper_title": "PAL: Program-aided Language Models",
            "rating": 2
        },
        {
            "paper_title": "ToRA: A Tool-integrated Reasoning Agent for Mathematical Problem Solving",
            "rating": 2
        },
        {
            "paper_title": "DIVERSE: Investigating Various Reasoning Paths and Verifier-weighted Voting",
            "rating": 1
        },
        {
            "paper_title": "Progressive-hint Prompting Improves Reasoning in Large Language Models",
            "rating": 1
        }
    ],
    "cost": 0.01847275,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Cumulative Reasoning with Large Language Models</h1>
<p>Yifan Zhang ${ }^{1 <em>}$ Jingqin Yang ${ }^{1 </em>}$ Yang Yuan ${ }^{1,2 \dagger}$ Andrew Chi-Chih Yao ${ }^{1,2 \dagger}$<br>${ }^{1}$ IIIS, Tsinghua University<br>${ }^{2}$ Shanghai Qi Zhi Institute<br>{zhangyif21, yangjq21}@mails.tsinghua.edu.cn,<br>{yuanyang, andrewcyao}@tsinghua.edu.cn</p>
<h4>Abstract</h4>
<p>Recent advancements in large language models (LLMs) have shown remarkable progress, yet their ability to solve complex problems remains limited. In this work, we introduce Cumulative Reasoning (CR), an approach that utilizes LLMs cumulatively and iteratively, mirroring human thought processes for problem-solving. CR decomposes tasks into smaller, manageable components and leverages previous propositions for effective composition, significantly enhancing problem-solving capabilities. We demonstrate CR's advantage through several complex reasoning tasks: it outperforms existing methods in logical inference tasks with up to a $9.3 \%$ improvement, achieving $98.04 \%$ accuracy on the curated FOLIO wiki dataset. In the Game of 24 , it achieves $98 \%$ accuracy, marking a $24 \%$ improvement over the prior state-of-the-art. In solving MATH problems, CR achieves a $4.2 \%$ increase from previous methods and a $43 \%$ relative improvement in the most challenging level 5 problems. When incorporating a code environment with CR, we further harness LLMs' reasoning capabilities and outperform the Program of Thought (PoT) method by $38.8 \%$. The code is available at https:// github.com/iiis-ai/cumulative-reasoning.</p>
<h2>1 Introduction</h2>
<p>Large language models (LLMs) have achieved significant advancements across various applications (Devlin et al., 2018; Radford et al., 2018, 2019; Brown et al., 2020; Raffel et al., 2020; OpenAI, 2023). However, they continue to face challenges in delivering stable and accurate answers for highly complex tasks. For example, it has been observed that LLMs struggle to directly generate correct answers for high school math problems (Lightman et al., 2023).</p>
<p>Drawing from Kahneman's dual-process theory (Kahneman, 2011), which distinguishes between fast, intuitive thought (System 1) and slower, more deliberate thought (System 2), current LLMs are predominantly aligned with System 1, which restricts their ability to engage in the systematic and logical reasoning required for complex problem-solving tasks.</p>
<p>Recent efforts to bridge this gap include Chain-of-Thought (CoT) prompting (Wei et al., 2022) and Tree-of-Thought (ToT) methodologies (Yao et al., 2023; Long, 2023), which guide LLMs through</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>a more structured reasoning process. However, these approaches lack mechanisms for dynamically storing and leveraging intermediate results, a crucial aspect of human cognitive processes.</p>
<p>In this work, we introduce Cumulative Reasoning (CR), a reasoning method that characterizes a more holistic representation of the thinking process. CR orchestrates a symphony of three LLM roles-the proposer, verifier(s), and reporter-to iteratively propose, validate, and compile reasoning steps into a comprehensive solution. This decomposition and composition strategy effectively transforms complex, multifaceted problems into a series of manageable tasks, significantly enhancing the problem-solving capabilities of LLMs.</p>
<p>Our empirical evaluation spans three distinct areas:</p>
<ol>
<li>Logical inference tasks: our method demonstrates superior performance on datasets like FOLIO wiki and AutoTNLI, with improvements of up to $9.3 \%$ and an outstanding $98.04 \%$ accuracy on a curated version of the FOLIO dataset.</li>
<li>The Game of 24: we achieved $98 \%$ accuracy, marking a $24 \%$ improvement over the existing state-of-the-art method ToT (Yao et al., 2023) while using only about $25 \%$ visited states.</li>
<li>Solving MATH problems: our method establishes new benchmarks with a margin of $4.2 \%$ over previous methods (Fu et al., 2022; Zheng et al., 2023) without external tools. Noteworthy, our method achieves notable $43 \%$ relative improvements on the hardest level 5 problems ( $22.4 \%$ $\rightarrow 32.1 \%$ ). Moreover, by integrating CR with a Python code environment-absent external aids like retrieval systems, we achieve a $72.2 \%$ accuracy on the MATH dataset, outperforming previous methods such as PoT (Chen et al., 2022) and PAL (Gao et al., 2023) with $38.8 \%$ relative improvement and demonstrating the adaptability and robustness of CR across various complex tasks.</li>
</ol>
<h1>2 Background</h1>
<p>In this section, we review the formal foundations of logic that underpin our approach, and present an illustrative example adapted from the FOLIO dataset (Han et al., 2022).</p>
<h3>2.1 Logic</h3>
<p>Propositional logic is the most basic formal system in logic. It is built from atomic propositions (e.g., $p, q, r$ ) and logical connectives such as conjunction ( $\wedge$ ), disjunction $(\vee)$, implication $(\Rightarrow)$, and negation $(\neg)$. In this setting, the truth values are denoted by the constants 1 (true) and 0 (false). Fundamental laws of propositional logic include:</p>
<p>$$
x \wedge x=x, \quad x \vee x=x, \quad 1 \wedge x=x, \quad 0 \vee x=x
$$</p>
<p>along with the absorption law:</p>
<p>$$
x \wedge(y \vee x)=x=(x \wedge y) \vee x
$$</p>
<p>and the distributive laws:</p>
<p>$$
x \wedge(y \vee z)=(x \wedge y) \vee(x \wedge z), \quad x \vee(y \wedge z)=(x \vee y) \wedge(x \vee z)
$$</p>
<p>In any Boolean algebra, every element $x$ has a complement $\neg x$, which satisfies:</p>
<p>$$
x \wedge \neg x=0, \quad x \vee \neg x=1, \quad \neg \neg x=x
$$</p>
<p>Extending this framework, first-order logic (FOL) introduces quantifiers to reason about collections of objects. Universal quantification $(\forall)$ and existential quantification $(\exists)$ allow statements such as</p>
<p>$$
\forall x(\operatorname{Dog}(x) \Rightarrow \operatorname{Animal}(x))
$$</p>
<p>which reads as "for every $x$, if $x$ is a dog, then $x$ is an animal." In contrast, higher-order logic (HOL) permits quantification over functions and predicates, greatly increasing expressiveness. For a detailed treatment of HOL, please refer to Appendix C.1.</p>
<h1>2.2 Illustrative Example</h1>
<p>To illustrate these concepts, consider an example adapted from the FOLIO dataset, where only natural language statements (without explicit logical formulas) are provided as context. The premises are as follows:</p>
<ol>
<li>All monkeys are mammals: $\forall x(\operatorname{Monkey}(x) \Rightarrow$ $\operatorname{Mammal}(x))$.</li>
<li>Every animal is either a monkey or a bird: $\forall x(\operatorname{Animal}(x) \Rightarrow(\operatorname{Monkey}(x) \vee$ $\operatorname{Bird}(x)))$.
<img alt="img-0.jpeg" src="img-0.jpeg" /></li>
</ol>
<p>Figure 1: An illustration of the logical derivation process.
3. All birds can fly: $\forall x(\operatorname{Bird}(x) \Rightarrow \operatorname{Fly}(x))$.
4. Anything that can fly has wings: $\forall x(\operatorname{Fly}(x) \Rightarrow$ $\operatorname{Wings}(x))$.
5. Rock is not a mammal but is an animal: $\neg \operatorname{Mammal}(\operatorname{Rock}) \wedge \operatorname{Animal}(\operatorname{Rock})$.</p>
<p>The question is: Does Rock have wings?
A rigorous derivation proceeds as follows:
a. The contrapositive of (1) gives:</p>
<p>$$
\forall x(\neg \operatorname{Mammal}(x) \Rightarrow \neg \operatorname{Monkey}(x))
$$</p>
<p>b. Combining (a) with (5) implies that Rock is not a monkey while still being an animal.
c. Premise (2) then entails that Rock must be either a monkey or a bird.
d. Since Rock is not a monkey (by step (b)), it follows that Rock is a bird.
e. From (3) and the conclusion that Rock is a bird, we deduce that Rock can fly.
f. Finally, applying (4) to the fact that Rock can fly, we conclude that Rock has wings.</p>
<p>Although the derivation appears as a linear sequence of steps from (a) to (f), its underlying structure is more naturally modeled as a directed acyclic graph (DAG), where each edge represents an individual inference. This DAG structure better captures the cumulative and interdependent nature of the reasoning process.</p>
<h1>3 Cumulative Reasoning</h1>
<p>In this section, we introduce Cumulative Reasoning (CR), a structured framework that leverages a collaborative process among specialized Large Language Models (LLMs) to tackle complex problems. Rather than relying solely on a single chain of thought, CR decomposes a problem into manageable sub-tasks and incrementally builds a solution by accumulating and validating intermediate reasoning steps. In our framework, three distinct roles are orchestrated:</p>
<ol>
<li>Proposer: Generates candidate reasoning steps based on the current context, thereby initiating each cycle of reasoning.</li>
<li>Verifier(s): Critically assess and validate the proposer's suggestions. These models transform the proposed steps into formal representations-using either symbolic reasoning systems or a code environment-to ensure logical correctness before they are integrated into the overall reasoning context.</li>
<li>Reporter: Monitors the evolving state of the accumulated reasoning and determines the optimal moment to conclude the process once a definitive solution has been reached.
<img alt="img-1.jpeg" src="img-1.jpeg" /></li>
</ol>
<p>Figure 2: Overview of the Cumulative Reasoning (CR) process applied to a problem with three premises.</p>
<p>As illustrated in Figure 2, CR iteratively refines a solution by progressively incorporating validated propositions. In practice, the proposer is best instantiated by a model pre-trained on derivation tasks, while the verifiers ensure that only logically sound steps are accumulated. This division of labor-augmented by role-specific prompting (see Appendix F for details)-allows CR to overcome the inherent self-verification limitations typical of conventional LLM outputs.</p>
<p>The underlying rationale for CR is inspired by intuitionistic logic and the philosophy of mathematical constructivism. By adopting a cumulative and constructive approach, CR dynamically adjusts the reasoning trajectory based on intermediate validations, thereby mirroring the nuanced, iterative nature of human problem-solving. This methodology significantly enhances the problemsolving efficacy and robustness of LLMs in complex reasoning tasks.</p>
<h1>3.1 Comparisons</h1>
<p>While CR seems similar to Chain-of-Thought (CoT) and Tree-of-Thought (ToT), its distinct mechanisms set it apart. In contrast to CoT, which generates a linear sequence of reasoning steps, and ToT, which organizes possibilities in a fixed hierarchical tree, CR dynamically stores and utilizes all historically validated propositions in a Directed Acyclic Graph (DAG). This flexible structure enables CR to effectively leverage a broader context of verified reasoning steps, thereby facilitating the resolution of more intricate problems.</p>
<p>Furthermore, CR's integration of specialized roles (proposer, verifier(s), and reporter) introduces additional layers of error correction and adaptive decision-making. By managing the reasoning context separately for each role, CR incorporates independent perspectives that enhance both the accuracy and robustness of the final solution. For a detailed quantitative comparison of these methods, please refer to Appendix B.</p>
<h2>4 Experiments</h2>
<p>Our experiments are conducted using the Microsoft Guidance library (Lundberg et al., 2023), which seamlessly integrates generation, prompting, and logical control within language model frameworks. We evaluate our method using the following LLMs: GPT-3.5-turbo, GPT-4, LLaMA13B, and LLaMA-65B. In our implementation of Cumulative Reasoning (CR), the roles of Proposer, Verifier(s), and Reporter are instantiated using the same underlying LLM but distinguished by role-specific few-shot prompts. This design both broadens the applicability of our approach and simplifies its deployment. Throughout the experiments, we denote by $n$ the number of intermediate propositions generated and by $k$ the number of majority voting iterations. For decoding, we set the temperature to $t=0.1$ by default and $t=0.7$ for majority voting. Note that GPT-3.5-turbo and GPT-4 are accessed via OpenAI's chat-format APIs.</p>
<h3>4.1 FOLIO Wiki</h3>
<p>The FOLIO dataset (Han et al., 2022) is a collection of first-order logical inference problems expressed in natural language. Each problem is labeled as "True", "False", or "Unknown." Figure 3 presents an example problem along with solutions generated by both a Chain-of-Thought (CoT) approach and our CR method.</p>
<p>We observe that while the CoT reasoning process may generate useful intermediate steps, it often loses trajectory and fails to reach the correct conclusion. By contrast, CR initially produces two valuable propositions and subsequently leverages them to solve the problem accurately.</p>
<p>The FOLIO dataset is a composite of 1435 examples, of which $52.5 \%$ of these instances have been crafted based on knowledge from randomly selected Wikipedia pages. This approach guarantees the infusion of abundant linguistic variations and a rich vocabulary within the corpus. The residual $47.5 \%$ of the examples have been constructed in a hybrid style, based on various complex logical templates. Acknowledging that contemporary LLMs are pre-trained on a considerable volume of human-written corpus, we direct our experiments towards those examples derived from Wikipedia, hereby referred to as FOLIO-wiki. Once a handful of examples are moved aside for few-shot prompts and those examples without source labels for validations are excluded, we are left with a testable collection of 534 examples.</p>
<p>Table 1 reports the performance of different methods evaluated on the FOLIO-wiki dataset. The results demonstrate that CR consistently outperforms Direct prompting, CoT, and CoT with Self-Consistency (CoT-SC), with improvements of up to $8.62 \%$. Notably, when paired with GPT-4, CR achieves an accuracy of $87.45 \%$, compared to $85.02 \%$ for GPT-4 with CoT-SC.</p>
<h1>[Problem Description]</h1>
<h2>Premises:</h2>
<p>(1) It is not true that some giant language models do not have good performance.
(2) All language models with good performance are used by some researchers.
(3) If a language model is used by some researchers, it is popular.
(4) If BERT is a giant language model, then GPT-3 is also a giant language model.
(5) BERT is a giant language model.</p>
<p>Hypothesis: GPT-3 is popular.
Label: [True]</p>
<h2>[Chain-of-Thought Reasoning by GPT-4]</h2>
<p>Reasoning: From the premises, we have:</p>
<ol>
<li>$\neg(\exists x)(\operatorname{Giant}(x) \wedge \neg \operatorname{GoodPerformance}(x))$</li>
<li>$\forall x(\operatorname{GoodPerformance}(x) \rightarrow$ UsedByResearchers $(x))$</li>
<li>$\forall x(\operatorname{UsedByResearchers}(x) \rightarrow \operatorname{Popular}(x))$</li>
<li>BERT $\rightarrow$ GPT-3</li>
<li>BERT</li>
</ol>
<p>Given that BERT is a giant language model, premise (4) implies that GPT-3 is also a giant language model. However, the premises do not explicitly provide information regarding GPT-3's performance or usage by researchers, and hence no definitive conclusion on its popularity can be drawn.
Prediction: [Unknown] (Incorrect)</p>
<h2>[Cumulative Reasoning by GPT-4]</h2>
<h2>Generated Propositions:</h2>
<p>(1) GPT-3 is a giant language model with good performance.
(2) GPT-3 is used by some researchers.</p>
<p>Reasoning: Since GPT-3 is a giant language model with good performance and is used by researchers, and given that any language model used by researchers is considered popular, it follows that GPT-3 is popular.
Prediction: [True] (Correct)
Figure 3: Example from the FOLIO dataset. The left panel shows a problem along with its premises, while the subsequent panels display reasoning by CoT and CR respectively. CR leverages intermediate propositions to yield the correct prediction.</p>
<p>Table 1: Results for various reasoning approaches on FOLIO-wiki.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Model</th>
<th style="text-align: left;">Method</th>
<th style="text-align: left;">Acc. $\uparrow(\%)$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">-</td>
<td style="text-align: left;">[Random]</td>
<td style="text-align: left;">33.33</td>
</tr>
<tr>
<td style="text-align: left;">LLaMA-13B</td>
<td style="text-align: left;">Direct</td>
<td style="text-align: left;">44.75</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">CoT</td>
<td style="text-align: left;">$49.06(+4.31)$</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">CoT-SC $(k=16)$</td>
<td style="text-align: left;">$\underline{52.43}(+7.68)$</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">CR $(n=2)$</td>
<td style="text-align: left;">$\mathbf{5 3 . 3 7}(+8.62)$</td>
</tr>
<tr>
<td style="text-align: left;">LLaMA-65B</td>
<td style="text-align: left;">Direct</td>
<td style="text-align: left;">67.42</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">CoT</td>
<td style="text-align: left;">$67.42(+0.00)$</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">CoT-SC $(k=16)$</td>
<td style="text-align: left;">$\underline{70.79}(+3.37)$</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">CR $(n=2)$</td>
<td style="text-align: left;">$\mathbf{7 2 . 1 0}(+4.68)$</td>
</tr>
<tr>
<td style="text-align: left;">GPT-3.5-turbo</td>
<td style="text-align: left;">Direct</td>
<td style="text-align: left;">62.92</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">CoT</td>
<td style="text-align: left;">$\underline{64.61}(+1.69)$</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">CoT-SC $(k=16)$</td>
<td style="text-align: left;">$63.33(+0.41)$</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">CR $(n=2)$</td>
<td style="text-align: left;">$\mathbf{7 3 . 0 3}(+10.11)$</td>
</tr>
<tr>
<td style="text-align: left;">GPT-4</td>
<td style="text-align: left;">Direct</td>
<td style="text-align: left;">80.52</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">CoT</td>
<td style="text-align: left;">$84.46(+3.94)$</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">CoT-SC $(k=16)$</td>
<td style="text-align: left;">$\underline{85.02}(+4.50)$</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">CR $(n=2)$</td>
<td style="text-align: left;">$\mathbf{8 7 . 4 5}(+6.93)$</td>
</tr>
</tbody>
</table>
<p>Table 2: Results for various reasoning approaches on FOLIO-wiki-curated.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Model</th>
<th style="text-align: left;">Method</th>
<th style="text-align: left;">Acc. $\uparrow(\%)$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">-</td>
<td style="text-align: left;">[Random]</td>
<td style="text-align: left;">33.33</td>
</tr>
<tr>
<td style="text-align: left;">LLaMA-13B</td>
<td style="text-align: left;">Direct</td>
<td style="text-align: left;">49.13</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">CoT</td>
<td style="text-align: left;">$52.17(+3.04)$</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">CoT-SC $(k=16)$</td>
<td style="text-align: left;">$\underline{53.70}(+4.57)$</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">CR $(n=2)$</td>
<td style="text-align: left;">$\mathbf{5 5 . 8 7}(+6.74)$</td>
</tr>
<tr>
<td style="text-align: left;">LLaMA-65B</td>
<td style="text-align: left;">Direct</td>
<td style="text-align: left;">74.78</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">CoT</td>
<td style="text-align: left;">$74.13(-0.65)$</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">CoT-SC $(k=16)$</td>
<td style="text-align: left;">$\mathbf{7 9 . 1 3}(+4.35)$</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">CR $(n=2)$</td>
<td style="text-align: left;">$\mathbf{7 9 . 5 7}(+4.79)$</td>
</tr>
<tr>
<td style="text-align: left;">GPT-3.5-turbo</td>
<td style="text-align: left;">Direct</td>
<td style="text-align: left;">69.57</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">CoT</td>
<td style="text-align: left;">$\underline{70.65}(+1.08)$</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">CoT-SC $(k=16)$</td>
<td style="text-align: left;">$69.32(-0.25)$</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">CR $(n=2)$</td>
<td style="text-align: left;">$\mathbf{7 8 . 7 0}(+9.13)$</td>
</tr>
<tr>
<td style="text-align: left;">GPT-4</td>
<td style="text-align: left;">Direct</td>
<td style="text-align: left;">89.57</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">CoT</td>
<td style="text-align: left;">$95.00(+5.43)$</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">CoT-SC $(k=16)$</td>
<td style="text-align: left;">$\underline{96.09}(+6.52)$</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">CR $(n=2)$</td>
<td style="text-align: left;">$\mathbf{9 8 . 0 4}(+8.47)$</td>
</tr>
</tbody>
</table>
<p>Table 3: Experimental results on the FOLIO-wiki and FOLIO-wiki-curated datasets.</p>
<h1>4.2 FOLIO Wiki Curated</h1>
<p>A detailed review of the FOLIO-wiki dataset revealed several problematic instances, including:</p>
<ol>
<li>Missing or contradictory common knowledge;</li>
<li>Overly ambiguous problems that do not yield unequivocal answers;</li>
<li>Inherent inconsistencies within the premises;</li>
<li>Vague statements or typographical errors; and</li>
<li>Incorrect answer annotations.</li>
</ol>
<p>After removing 74 such problematic instances, the curated set comprises 460 examples (see Appendix E. 2 for detailed examples). As shown in Table 2, when applied to this refined dataset, GPT-4 paired with CR achieves an accuracy of $98.04 \%$ (error rate: $1.96 \%$ ), nearly doubling the effectiveness of GPT-4 with CoT-SC.</p>
<h3>4.3 AutoTNLI</h3>
<p>Experimental Setting. The AutoTNLI dataset (Kumar et al., 2022) extends the INFOTABS dataset (Gupta et al., 2020) to construct a challenging Tabular Natural Language Inference task. This dataset contains 1,478,662 table-hypothesis pairs labeled as either "Entail" or "Neutral." In our adaptation, we treat the tabular data as premises in a manner analogous to the FOLIO dataset. Due to the dataset's large scale, we limit our evaluation to the first 1,000 table-hypothesis pairs</p>
<p>and compare the performance of LLaMA-13B and LLaMA-65B using Direct, CoT, CoT-SC, and our CR method.
Evaluation Results. Table 4 shows that CR significantly outperforms the alternative prompting strategies. In particular, LLaMA-65B with CR achieves a $12.8 \%$ accuracy improvement over CoTSC, demonstrating CR's superior ability to capture structural and linguistic nuances in logical inference.
More Experiments and Ablation Studies. Regarding the computational complexity of different methods, Table 11 and Table 12 show the superiority of CR compared to CoT, CoT-SC, and ToT on several logical inference tasks including LogiQA (Liu et al., 2020) and ProofWriter (Tafjord et al., 2020) datasets. For more experiments on logical reasoning tasks and ablation studies, please refer to Appendix A.</p>
<p>Table 4: Results on the AutoTNLI dataset.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Model</th>
<th style="text-align: left;">Method</th>
<th style="text-align: left;">Acc. $\uparrow(\%)$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">-</td>
<td style="text-align: left;">[Random]</td>
<td style="text-align: left;">50.00</td>
</tr>
<tr>
<td style="text-align: left;">LLaMA-13B</td>
<td style="text-align: left;">Direct</td>
<td style="text-align: left;">52.6</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">CoT</td>
<td style="text-align: left;">$54.1(+1.5)$</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">CoT-SC $(k=16)$</td>
<td style="text-align: left;">$52.1(-0.5)$</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">$\mathbf{C R}(n=4)$</td>
<td style="text-align: left;">$\mathbf{5 7 . 0}(+5.4)$</td>
</tr>
<tr>
<td style="text-align: left;">LLaMA-65B</td>
<td style="text-align: left;">Direct</td>
<td style="text-align: left;">59.7</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">CoT</td>
<td style="text-align: left;">$63.2(+3.5)$</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">CoT-SC $(k=16)$</td>
<td style="text-align: left;">$61.7(+2.0)$</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">$\mathbf{C R}(n=4)$</td>
<td style="text-align: left;">$\mathbf{7 2 . 5}(+12.8)$</td>
</tr>
</tbody>
</table>
<p>Table 5: Results on the Game of 24 using GPT-4.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Method</th>
<th style="text-align: left;">Acc. $\uparrow(\%)$</th>
<th style="text-align: left;"># Visited States $\downarrow$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Direct</td>
<td style="text-align: left;">7.3</td>
<td style="text-align: left;">1</td>
</tr>
<tr>
<td style="text-align: left;">CoT</td>
<td style="text-align: left;">4.0</td>
<td style="text-align: left;">1</td>
</tr>
<tr>
<td style="text-align: left;">CoT-SC $(\mathrm{k}=100)$</td>
<td style="text-align: left;">9.0</td>
<td style="text-align: left;">100</td>
</tr>
<tr>
<td style="text-align: left;">Direct (best of 100)</td>
<td style="text-align: left;">33</td>
<td style="text-align: left;">100</td>
</tr>
<tr>
<td style="text-align: left;">CoT (best of 100)</td>
<td style="text-align: left;">49</td>
<td style="text-align: left;">100</td>
</tr>
<tr>
<td style="text-align: left;">ToT $(\mathrm{b}=5)$</td>
<td style="text-align: left;">74</td>
<td style="text-align: left;">61.72</td>
</tr>
<tr>
<td style="text-align: left;">CR $(\mathrm{b}=1)$</td>
<td style="text-align: left;">$84(+10)$</td>
<td style="text-align: left;">$\mathbf{1 1 . 6 8}(-50.04)$</td>
</tr>
<tr>
<td style="text-align: left;">CR $(\mathrm{b}=2)$</td>
<td style="text-align: left;">$94(+20)$</td>
<td style="text-align: left;">$\underline{13.70}(-48.02)$</td>
</tr>
<tr>
<td style="text-align: left;">CR $(\mathrm{b}=3)$</td>
<td style="text-align: left;">$\underline{97}(+23)$</td>
<td style="text-align: left;">$14.25(-47.47)$</td>
</tr>
<tr>
<td style="text-align: left;">CR $(\mathrm{b}=4)$</td>
<td style="text-align: left;">$\underline{97}(+23)$</td>
<td style="text-align: left;">$14.77(-46.95)$</td>
</tr>
<tr>
<td style="text-align: left;">CR $(\mathrm{b}=5)$</td>
<td style="text-align: left;">$\mathbf{9 8}(+24)$</td>
<td style="text-align: left;">$14.86(-46.86)$</td>
</tr>
</tbody>
</table>
<p>Table 6: Experimental results on the AutoTNLI and Game of 24 datasets.</p>
<h1>4.4 Game of 24</h1>
<p>The Game of 24 is a numerical puzzle in which players must combine four given integers using basic arithmetic operations (addition, subtraction, multiplication, and division) to yield 24. A puzzle is considered successfully solved if the resulting equation is valid and each input number is used exactly once.
Experimental Setup. We evaluate a set of 100 puzzles curated by ToT (Yao et al., 2023). Our primary metrics are accuracy and the average number of visited states during the search. In our CR algorithm, a set of reachable states, $S$, is maintained. The process begins with the initial state $s$ (the four input numbers without operations), and at each iteration a state $u \in S$ is selected. The Proposer chooses two numbers from $u$ and applies a basic operation to generate a new state $v$. After the Verifier confirms the validity of the operation, $v$ is added to $S$. When a state representing a valid solution (i.e., an equation that evaluates to 24) is reached, the Reporter traces back the derivation and outputs the solution. The process terminates either when a solution is reported or when the iteration count exceeds a predefined limit $(L=50)$. We run multiple parallel branches (with breadth $b$ ranging from 1 to 5 ) to account for variability in the search.
Results. As summarized in Table 5, CR substantially outperforms ToT by achieving up to $98 \%$ accuracy (a $24 \%$ improvement over ToT's $74 \%$ ) while exploring significantly fewer states.</p>
<p>Comparison with ToT. In the specific context of the Game of 24, the methodologies of Cumulative Reasoning (CR) and Tree of Thoughts (ToT) share similarities yet diverge significantly in their approach to state generation and exploration. A fundamental difference lies in how each iteration processes: CR is designed to introduce a single new state at each step, focusing on a step-by-step progression towards the solution. Conversely, ToT is characterized by its generation of multiple candidate states during each iteration, employing a filtration mechanism to narrow down the feasible states. This operational distinction suggests that ToT engages in a broader exploration of potential, including invalid, states, compared to the more streamlined approach of CR.</p>
<p>Furthermore, ToT relies on a pre-defined search structure, utilizing a constant width and depth within its search tree. This rigid framework contrasts with CR's more dynamic strategy, where the language model (LLM) itself influences the depth of the search, adapting the exploration breadth as needed across different stages of the problem-solving process. Such flexibility in CR not only optimizes the search path but also tailors the exploration to the complexity and requirements of each specific problem, potentially enhancing efficiency and efficacy in reaching the correct solution.</p>
<p>Table 7: Comparative performance on the MATH dataset using GPT-4 without code environment. We adopted a default temperature setting of $t=0.0$, consistent with prior research settings (greedy decoding). PHP denotes the application of the progressive-hint prompting. "Iters" represents the average number of LLM interactions, and Overall reflects the overall results across MATH subtopics (* denotes using 500 test examples subset following Lightman et al. (2023)).</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;">w/ PHP</th>
<th style="text-align: center;">MATH Dataset</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Precalc</td>
<td style="text-align: center;">Geometry</td>
<td style="text-align: center;">NumT</td>
<td style="text-align: center;">Prob</td>
<td style="text-align: center;">PreAlg</td>
<td style="text-align: center;">Algebra</td>
<td style="text-align: center;">Overall</td>
</tr>
<tr>
<td style="text-align: center;">CoT</td>
<td style="text-align: center;">$\boldsymbol{x}$</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">42.50</td>
</tr>
<tr>
<td style="text-align: center;">Complex CoT <br> 8 shot</td>
<td style="text-align: center;">$\boldsymbol{x}$</td>
<td style="text-align: center;">26.7</td>
<td style="text-align: center;">36.5</td>
<td style="text-align: center;">49.6</td>
<td style="text-align: center;">53.1</td>
<td style="text-align: center;">71.6</td>
<td style="text-align: center;">70.8</td>
<td style="text-align: center;">50.36</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">29.8</td>
<td style="text-align: center;">41.9</td>
<td style="text-align: center;">55.7</td>
<td style="text-align: center;">56.3</td>
<td style="text-align: center;">73.8</td>
<td style="text-align: center;">74.3</td>
<td style="text-align: center;">53.90</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">(Iters)</td>
<td style="text-align: center;">3.2435</td>
<td style="text-align: center;">3.2233</td>
<td style="text-align: center;">3.1740</td>
<td style="text-align: center;">2.8122</td>
<td style="text-align: center;">2.3226</td>
<td style="text-align: center;">2.4726</td>
<td style="text-align: center;">2.8494</td>
</tr>
<tr>
<td style="text-align: center;">Complex CoT* <br> (repro., 8-shot)</td>
<td style="text-align: center;">$\boldsymbol{x}$</td>
<td style="text-align: center;">33.9</td>
<td style="text-align: center;">34.1</td>
<td style="text-align: center;">46.8</td>
<td style="text-align: center;">47.4</td>
<td style="text-align: center;">62.1</td>
<td style="text-align: center;">70.7</td>
<td style="text-align: center;">48.80</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">30.4</td>
<td style="text-align: center;">43.9</td>
<td style="text-align: center;">53.2</td>
<td style="text-align: center;">50.0</td>
<td style="text-align: center;">68.5</td>
<td style="text-align: center;">84.1</td>
<td style="text-align: center;">53.80</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">(Iters)</td>
<td style="text-align: center;">2.4643</td>
<td style="text-align: center;">2.7805</td>
<td style="text-align: center;">2.7581</td>
<td style="text-align: center;">2.4474</td>
<td style="text-align: center;">2.3780</td>
<td style="text-align: center;">2.5484</td>
<td style="text-align: center;">2.59</td>
</tr>
<tr>
<td style="text-align: center;">CR w/o code* <br> (ours, 4-shot)</td>
<td style="text-align: center;">$\boldsymbol{x}$</td>
<td style="text-align: center;">$30.4(-3.5)$</td>
<td style="text-align: center;">$39.0(+4.9)$</td>
<td style="text-align: center;">$54.8(+8.0)$</td>
<td style="text-align: center;">$57.9(+10.5)$</td>
<td style="text-align: center;">$71.8(+9.7)$</td>
<td style="text-align: center;">$79.3(+8.6)$</td>
<td style="text-align: center;">$54.20(+5.40)$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">$35.7(+5.3)$</td>
<td style="text-align: center;">$43.9(+0.0)$</td>
<td style="text-align: center;">$59.7(+6.5)$</td>
<td style="text-align: center;">$63.2(+13.2)$</td>
<td style="text-align: center;">$71.8(+3.3)$</td>
<td style="text-align: center;">$86.6(+2.5)$</td>
<td style="text-align: center;">$58.00(+4.20)$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">(Iters)</td>
<td style="text-align: center;">2.4821</td>
<td style="text-align: center;">2.5122</td>
<td style="text-align: center;">2.2903</td>
<td style="text-align: center;">2.2105</td>
<td style="text-align: center;">2.2195</td>
<td style="text-align: center;">2.3548</td>
<td style="text-align: center;">$2.40(-0.19)$</td>
</tr>
</tbody>
</table>
<h1>4.5 Solving MATH Problems</h1>
<p>The MATH dataset (Hendrycks et al., 2021) provides a comprehensive benchmark for mathematical reasoning across diverse subdomains such as Algebra and Geometry. We compare Complex CoT and our CR method, both with and without Progressive-Hint Prompting (PHP) (Zheng et al., 2023). Our reproduction follows the evaluation protocol of Lightman et al. (2023), using an 8-shot prompting strategy on a 500 -example subset that spans all difficulty levels (Levels 1-5).
Results without Code Environment. Table 7 shows that CR outperforms Complex CoT by 5.4\% in overall accuracy when using a 4 -shot strategy. In particular, CR yields substantial gains in Number Theory, Probability, PreAlgebra, and Algebra. Table 8 further demonstrates that at Level 5-the most challenging subset-CR achieves a $9.7 \%$ improvement, corresponding to a $43 \%$ relative gain over Complex CoT without PHP.</p>
<p>Table 8: Comparative performance on the MATH dataset using GPT-4 without code environment for different difficulty levels. (* denotes evaluation on a 500 -example subset.)</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;">w/ PHP</th>
<th style="text-align: center;">MATH Dataset (* denotes using 500 test examples subset)</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Level 5</td>
<td style="text-align: center;">Level 4</td>
<td style="text-align: center;">Level 3</td>
<td style="text-align: center;">Level 2</td>
<td style="text-align: center;">Level 1</td>
<td style="text-align: center;">Overall</td>
</tr>
<tr>
<td style="text-align: center;">CoT (OpenAI, 2023)</td>
<td style="text-align: center;">$\boldsymbol{x}$</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">42.50</td>
</tr>
<tr>
<td style="text-align: center;">Complex CoT*</td>
<td style="text-align: center;">$\boldsymbol{x}$</td>
<td style="text-align: center;">22.4</td>
<td style="text-align: center;">38.3</td>
<td style="text-align: center;">62.9</td>
<td style="text-align: center;">72.2</td>
<td style="text-align: center;">79.1</td>
<td style="text-align: center;">48.80</td>
</tr>
<tr>
<td style="text-align: center;">(repro., 8-shot)</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">23.9</td>
<td style="text-align: center;">43.8</td>
<td style="text-align: center;">63.8</td>
<td style="text-align: center;">86.7</td>
<td style="text-align: center;">83.7</td>
<td style="text-align: center;">53.80</td>
</tr>
<tr>
<td style="text-align: center;">CR w/o code*</td>
<td style="text-align: center;">$\boldsymbol{x}$</td>
<td style="text-align: center;">$32.1(+9.7)$</td>
<td style="text-align: center;">$43.0(+4.7)$</td>
<td style="text-align: center;">$62.9(+0.0)$</td>
<td style="text-align: center;">$78.9(+6.7)$</td>
<td style="text-align: center;">$83.7(+4.6)$</td>
<td style="text-align: center;">$54.20(+5.40)$</td>
</tr>
<tr>
<td style="text-align: center;">(ours, 4-shot)</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">$27.3(+3.4)$</td>
<td style="text-align: center;">$50.0(+6.2)$</td>
<td style="text-align: center;">$70.9(+7.1)$</td>
<td style="text-align: center;">$86.7(+0.0)$</td>
<td style="text-align: center;">$90.7(+7.0)$</td>
<td style="text-align: center;">$58.00(+4.20)$</td>
</tr>
</tbody>
</table>
<p>With a Code Environment. In addition to the experiments above, we extend CR by incorporating a Python code environment to emulate a semi-symbolic reasoning system. In this configuration, no external aids (such as memory modules, web browsing, or retrieval systems) are employed. Instead, the Python interpreter serves as the verifier, executing and validating arithmetic or symbolic expressions generated by the LLM. This setup allows the proposer to generate hypotheses and mathematical expressions, which are then verified through code execution.</p>
<p>Tables 9 and 10 compare our approach with state-of-the-art methods such as PAL (Gao et al., 2023) and ToRA (Gou et al., 2023). CR with code achieves an overall accuracy of $72.2 \%$ on the MATH dataset, reflecting a $38.9 \%$ relative improvement over PAL and an $18.8 \%$ improvement over ToRA. Furthermore, on the hardest Level 5 problems, CR with code exhibits a $66.8 \%$ relative improvement over PAL and a $12.8 \%$ improvement over ToRA.</p>
<p>Table 9: Comparative performance on the MATH dataset using GPT-4 with a Python code environment. Results are based on greedy decoding $(t=0.0)$. Overall reflects the aggregate accuracy across MATH subtopics.</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;">Precalc</th>
<th style="text-align: center;">Geometry</th>
<th style="text-align: center;">NumT</th>
<th style="text-align: center;">Prob</th>
<th style="text-align: center;">PreAlg</th>
<th style="text-align: center;">Algebra</th>
<th style="text-align: center;">Overall</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">PAL</td>
<td style="text-align: center;">29.3</td>
<td style="text-align: center;">38.0</td>
<td style="text-align: center;">58.7</td>
<td style="text-align: center;">61.0</td>
<td style="text-align: center;">73.9</td>
<td style="text-align: center;">59.1</td>
<td style="text-align: center;">51.8</td>
</tr>
<tr>
<td style="text-align: center;">PAL* (repro., 4-shot)</td>
<td style="text-align: center;">23.2</td>
<td style="text-align: center;">31.7</td>
<td style="text-align: center;">$\underline{66.1}$</td>
<td style="text-align: center;">57.9</td>
<td style="text-align: center;">$\underline{73.2}$</td>
<td style="text-align: center;">65.3</td>
<td style="text-align: center;">52.0</td>
</tr>
<tr>
<td style="text-align: center;">ToRA</td>
<td style="text-align: center;">37.2</td>
<td style="text-align: center;">44.1</td>
<td style="text-align: center;">68.9</td>
<td style="text-align: center;">67.3</td>
<td style="text-align: center;">82.2</td>
<td style="text-align: center;">75.8</td>
<td style="text-align: center;">61.6</td>
</tr>
<tr>
<td style="text-align: center;">ToRA* (repro., 4-shot)</td>
<td style="text-align: center;">$\underline{44.6}$</td>
<td style="text-align: center;">$\underline{48.8}$</td>
<td style="text-align: center;">49.5</td>
<td style="text-align: center;">$\underline{66.1}$</td>
<td style="text-align: center;">67.1</td>
<td style="text-align: center;">$\underline{71.8}$</td>
<td style="text-align: center;">$\underline{60.8}$</td>
</tr>
<tr>
<td style="text-align: center;">CR w/ code* (ours, 2-shot)</td>
<td style="text-align: center;">$\mathbf{5 1 . 8}(+7.2)$</td>
<td style="text-align: center;">$\mathbf{5 3 . 7}(+4.9)$</td>
<td style="text-align: center;">$\mathbf{8 8 . 7}(+22.6)$</td>
<td style="text-align: center;">$\mathbf{7 1 . 1}(+5.0)$</td>
<td style="text-align: center;">$\mathbf{8 6 . 6}(+13.4)$</td>
<td style="text-align: center;">$\mathbf{8 6 . 3}(+14.5)$</td>
<td style="text-align: center;">$\mathbf{7 2 . 2}(+11.4)$</td>
</tr>
</tbody>
</table>
<p>Table 10: Comparative performance on the MATH dataset using GPT-4 with a Python code environment across different difficulty levels.</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;">Difficulty Levels</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Level 5</td>
<td style="text-align: center;">Level 4</td>
<td style="text-align: center;">Level 3</td>
<td style="text-align: center;">Level 2</td>
<td style="text-align: center;">Level 1</td>
<td style="text-align: center;">Overall</td>
</tr>
<tr>
<td style="text-align: center;">PAL</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">51.8</td>
</tr>
<tr>
<td style="text-align: center;">PAL* (repro., 4-shot)</td>
<td style="text-align: center;">31.3</td>
<td style="text-align: center;">45.3</td>
<td style="text-align: center;">60.0</td>
<td style="text-align: center;">65.6</td>
<td style="text-align: center;">$\underline{88.4}$</td>
<td style="text-align: center;">52.0</td>
</tr>
<tr>
<td style="text-align: center;">ToRA</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">61.6</td>
</tr>
<tr>
<td style="text-align: center;">ToRA* (repro., 4-shot)</td>
<td style="text-align: center;">$\underline{46.3}$</td>
<td style="text-align: center;">$\underline{53.9}$</td>
<td style="text-align: center;">$\underline{69.5}$</td>
<td style="text-align: center;">$\underline{75.6}$</td>
<td style="text-align: center;">74.4</td>
<td style="text-align: center;">$\underline{60.8}$</td>
</tr>
<tr>
<td style="text-align: center;">CR w/ code* (ours, 2-shot)</td>
<td style="text-align: center;">$\mathbf{5 2 . 2}(+5.9)$</td>
<td style="text-align: center;">$\mathbf{6 6 . 4}(+12.5)$</td>
<td style="text-align: center;">$\mathbf{8 1 . 9}(+12.4)$</td>
<td style="text-align: center;">$\mathbf{9 0 . 0}(+14.4)$</td>
<td style="text-align: center;">$\mathbf{9 0 . 7}(+2.3)$</td>
<td style="text-align: center;">$\mathbf{7 2 . 2}(+11.4)$</td>
</tr>
</tbody>
</table>
<h1>5 Related Work</h1>
<p>Reasoning with Large Language Models (LLMs). The integration of reasoning capabilities in neural networks, through the generation of intermediate steps, has significantly advanced performance across various domains (Zaidan et al., 2007; Yao et al., 2021; Hase \&amp; Bansal, 2021; Yang et al., 2022; Wu et al., 2022; Zhou et al., 2022). Morishita et al. (2023) enhance language models' reasoning by utilizing a synthetic corpus based on formal logic theory. Uesato et al. (2022); Lightman et al. (2023) compare process-based and outcome-based approaches in solving mathematical reasoning tasks. Further, a considerable breadth of research focuses on augmenting reasoning through symbolic systems, such as code environments, knowledge graphs, and formal theorem provers, showcasing the utility of hybrid approaches in complex reasoning tasks (Mihaylov \&amp; Frank, 2018; Bauer et al., 2018; Kundu et al., 2018; Wang et al., 2019; Lin et al., 2019; Ding et al., 2019; Feng et al., 2020; Nye et al., 2021; Wang et al., 2022a; Chen et al., 2022; Lyu et al., 2023; Chen et al., 2022; Gao et al., 2023; Gou et al., 2023; Li et al., 2023a; Jiang et al., 2022; Yang et al., 2023).</p>
<p>Chain-of-Thought (CoT) Prompting. Initiated by Wei et al. (2022), the CoT reasoning paradigm underscores the value of multi-step logical pathways in deriving conclusive answers. Building on this, Wang et al. (2022b) introduce self-consistency as an advanced decoding strategy, aiming to refine the basic greedy decoding used in CoT. Zhou et al. (2022) and Khot et al. (2022) further dissect complex tasks into manageable sub-tasks, optimizing the reasoning process. Creswell \&amp; Shanahan (2022) explore the enhancement of reasoning quality through a beam search across reasoning traces, while Fu et al. (2022) argue for increasing the complexity within few-shot prompts to improve performance. Recent developments include Li et al. (2023b)'s DIVERSE, which investigates various reasoning paths for the same question and employs a verifier for accuracy through weighted voting. Du et al. (2023) present a multi-agent debate approach with multiple LLMs. Yao et al. (2023)'s Tree-of-Thought (ToT) framework introduces deliberation in decision-making by considering multiple reasoning paths. Zheng et al. (2023) propose an iterative approach, using previous responses as contextual clues in subsequent iterations. Feng et al. (2023) highlight the theoretical and practical implications of CoT for solving complex real-world tasks, including dynamic programming. Recently, there have also been many works on the self-criticizing process (Tyen et al., 2023; Li et al., 2024; Zhang et al., 2024b; Lin et al., 2024; Wang et al., 2024), showing that language models can have self-correction capabilities with theoretical guarantees.</p>
<h2>6 Conclusion</h2>
<p>In this work, we introduce Cumulative Reasoning (CR), an approach leveraging LLMs in a structured, iterative process that mirrors human cognitive strategies. By orchestrating the roles of proposer, verifier(s), and reporter, CR not only decomposes complex problems into manageable tasks but also effectively recomposes the validated steps into comprehensive solutions. This methodology has demonstrated superior performance across various domains, including logical inference, the Game of 24, and MATH problems, showcasing the versatility and potential of CR in advancing the capabilities of LLMs in complex problem-solving scenarios.</p>
<h1>References</h1>
<p>Lisa Bauer, Yicheng Wang, and Mohit Bansal. Commonsense for generative multi-hop question answering tasks. arXiv preprint arXiv:1809.06309, 2018.</p>
<p>Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are few-shot learners. Advances in neural information processing systems, 33:1877-1901, 2020.</p>
<p>Wenhu Chen, Xueguang Ma, Xinyi Wang, and William W Cohen. Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks. arXiv preprint arXiv:2211.12588, 2022.</p>
<p>Jonathan Okeke Chimakonam. Proof in Alonzo Church's and Alan Turing's Mathematical Logic: Undecidability of First Order Logic. Universal-Publishers, 2012.</p>
<p>Robin Cooper, Dick Crouch, Jan Van Eijck, Chris Fox, Johan Van Genabith, Jan Jaspars, Hans Kamp, David Milward, Manfred Pinkal, Massimo Poesio, et al. Using the framework. Technical report, Technical Report LRE 62-051 D-16, The FraCaS Consortium, 1996.</p>
<p>Antonia Creswell and Murray Shanahan. Faithful reasoning using large language models. arXiv preprint arXiv:2208.14271, 2022.</p>
<p>Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805, 2018.</p>
<p>Ming Ding, Chang Zhou, Qibin Chen, Hongxia Yang, and Jie Tang. Cognitive graph for multi-hop reading comprehension at scale. arXiv preprint arXiv:1905.05460, 2019.</p>
<p>Yilun Du, Shuang Li, Antonio Torralba, Joshua B Tenenbaum, and Igor Mordatch. Improving factuality and reasoning in language models through multiagent debate. arXiv preprint arXiv:2305.14325, 2023.</p>
<p>Guhao Feng, Yuntian Gu, Bohang Zhang, Haotian Ye, Di He, and Liwei Wang. Towards revealing the mystery behind chain of thought: a theoretical perspective. arXiv preprint arXiv:2305.15408, 2023.</p>
<p>Yanlin Feng, Xinyue Chen, Bill Yuchen Lin, Peifeng Wang, Jun Yan, and Xiang Ren. Scalable multi-hop relational reasoning for knowledge-aware question answering. arXiv preprint arXiv:2005.00646, 2020.</p>
<p>Yao Fu, Hao Peng, Ashish Sabharwal, Peter Clark, and Tushar Khot. Complexity-based prompting for multi-step reasoning. arXiv preprint arXiv:2210.00720, 2022.</p>
<p>LTF Gamut. Logic, Language, and Meaning, Volume 2: intensional logic and logical grammar. University of Chicago Press, 1990.</p>
<p>Luyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon, Pengfei Liu, Yiming Yang, Jamie Callan, and Graham Neubig. Pal: Program-aided language models. In International Conference on Machine Learning, pp. 10764-10799. PMLR, 2023.</p>
<p>Zhibin Gou, Zhihong Shao, Yeyun Gong, Yujiu Yang, Minlie Huang, Nan Duan, Weizhu Chen, et al. Tora: A tool-integrated reasoning agent for mathematical problem solving. arXiv preprint arXiv:2309.17452, 2023.</p>
<p>Vivek Gupta, Maitrey Mehta, Pegah Nokhiz, and Vivek Srikumar. INFOTABS: inference on tables as semi-structured data. CoRR, abs/2005.06117, 2020.</p>
<p>Simeng Han, Hailey Schoelkopf, Yilun Zhao, Zhenting Qi, Martin Riddell, Luke Benson, Lucy Sun, Ekaterina Zubova, Yujie Qiao, Matthew Burtell, et al. Folio: Natural language reasoning with first-order logic. arXiv preprint arXiv:2209.00840, 2022.</p>
<p>Peter Hase and Mohit Bansal. When can models learn from explanations? a formal framework for understanding the roles of explanation data. arXiv preprint arXiv:2102.02201, 2021.</p>
<p>Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song, and Jacob Steinhardt. Measuring mathematical problem solving with the math dataset. arXiv preprint arXiv:2103.03874, 2021.</p>
<p>Albert Qiaochu Jiang, Sean Welleck, Jin Peng Zhou, Wenda Li, Jiacheng Liu, Mateja Jamnik, Timothée Lacroix, Yuhuai Wu, and Guillaume Lample. Draft, sketch, and prove: Guiding formal theorem provers with informal proofs. ArXiv, abs/2210.12283, 2022.</p>
<p>Daniel Kahneman. Thinking, fast and slow. macmillan, 2011.
Tushar Khot, Harsh Trivedi, Matthew Finlayson, Yao Fu, Kyle Richardson, Peter Clark, and Ashish Sabharwal. Decomposed prompting: A modular approach for solving complex tasks. arXiv preprint arXiv:2210.02406, 2022.</p>
<p>Dibyakanti Kumar, Vivek Gupta, Soumya Sharma, and Shuo Zhang. Realistic data augmentation framework for enhancing tabular reasoning. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, Online and Abu Dhabi, December 2022. Association for Computational Linguistics.</p>
<p>Souvik Kundu, Tushar Khot, Ashish Sabharwal, and Peter Clark. Exploiting explicit paths for multi-hop reading comprehension. arXiv preprint arXiv:1811.01127, 2018.</p>
<p>Chengshu Li, Jacky Liang, Andy Zeng, Xinyun Chen, Karol Hausman, Dorsa Sadigh, Sergey Levine, Li Fei-Fei, Fei Xia, and Brian Ichter. Chain of code: Reasoning with a language modelaugmented code emulator. arXiv preprint arXiv:2312.04474, 2023a.</p>
<p>Loka Li, Guangyi Chen, Yusheng Su, Zhenhao Chen, Yixuan Zhang, Eric Xing, and Kun Zhang. Confidence matters: Revisiting intrinsic self-correction capabilities of large language models. arXiv preprint arXiv:2402.12563, 2024.</p>
<p>Yifei Li, Zeqi Lin, Shizhuo Zhang, Qiang Fu, Bei Chen, Jian-Guang Lou, and Weizhu Chen. Making language models better reasoners with step-aware verifier. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 5315-5333, 2023b.</p>
<p>Hunter Lightman, Vineet Kosaraju, Yura Burda, Harri Edwards, Bowen Baker, Teddy Lee, Jan Leike, John Schulman, Ilya Sutskever, and Karl Cobbe. Let's verify step by step. arXiv preprint arXiv:2305.20050, 2023.</p>
<p>Bill Yuchen Lin, Xinyue Chen, Jamin Chen, and Xiang Ren. Kagnet: Knowledge-aware graph networks for commonsense reasoning. arXiv preprint arXiv:1909.02151, 2019.</p>
<p>Zicheng Lin, Zhibin Gou, Tian Liang, Ruilin Luo, Haowei Liu, and Yujiu Yang. Criticbench: Benchmarking llms for critique-correct reasoning. arXiv preprint arXiv:2402.14809, 2024.</p>
<p>Jian Liu, Leyang Cui, Hanmeng Liu, Dandan Huang, Yile Wang, and Yue Zhang. Logiqa: A challenge dataset for machine reading comprehension with logical reasoning. arXiv preprint arXiv:2007.08124, 2020.</p>
<p>Jieyi Long. Large language model guided tree-of-thought. arXiv preprint arXiv:2305.08291, 2023.
Leopold Löwenheim. On possibilities in the calculus of relatives. Jean van Heijenoort, pp. 18781931, 1967.</p>
<p>Scott Lundberg, Marco Tulio Correia Ribeiro, David Viggiano, Joao Rafael, Riya Amemiya, and et. al. Microsoft guidance library. https://github.com/microsoft/guidance, 2023.</p>
<p>Qing Lyu, Shreya Havaldar, Adam Stein, Li Zhang, Delip Rao, Eric Wong, Marianna Apidianaki, and Chris Callison-Burch. Faithful chain-of-thought reasoning. arXiv preprint arXiv:2301.13379, 2023.</p>
<p>Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, et al. Self-refine: Iterative refinement with self-feedback. arXiv preprint arXiv:2303.17651, 2023.</p>
<p>Todor Mihaylov and Anette Frank. Knowledgeable reader: Enhancing cloze-style reading comprehension with external commonsense knowledge. arXiv preprint arXiv:1805.07858, 2018.</p>
<p>Koji Mineshima, Pascual Martínez-Gómez, Yusuke Miyao, and Daisuke Bekki. Higher-order logical inference with compositional semantics. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pp. 2055-2061, 2015.</p>
<p>Terufumi Morishita, Gaku Morio, Atsuki Yamaguchi, and Yasuhiro Sogawa. Learning deductive reasoning from synthetic corpus based on formal logic. In Andreas Krause, Emma Brunskill, Kyunghyun Cho, Barbara Engelhardt, Sivan Sabato, and Jonathan Scarlett (eds.), Proceedings of the 40th International Conference on Machine Learning, volume 202 of Proceedings of Machine Learning Research, pp. 25254-25274. PMLR, 23-29 Jul 2023.</p>
<p>Maxwell Nye, Anders Johan Andreassen, Guy Gur-Ari, Henryk Michalewski, Jacob Austin, David Bieber, David Dohan, Aitor Lewkowycz, Maarten Bosma, David Luan, et al. Show your work: Scratchpads for intermediate computation with language models. arXiv preprint arXiv:2112.00114, 2021.</p>
<p>OpenAI. Gpt-4 technical report. ArXiv, abs/2303.08774, 2023.</p>
<p>Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever, et al. Improving language understanding by generative pre-training. openai.com, 2018.</p>
<p>Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. Language models are unsupervised multitask learners. OpenAI blog, 1(8):9, 2019.</p>
<p>Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu. Exploring the limits of transfer learning with a unified text-to-text transformer. The Journal of Machine Learning Research, 21(1):5485-5551, 2020.</p>
<p>Laria Reynolds and Kyle McDonell. Prompt programming for large language models: Beyond the few-shot paradigm. In Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems, pp. 1-7, 2021.</p>
<p>Noah Shinn, Federico Cassano, Beck Labash, Ashwin Gopinath, Karthik Narasimhan, and Shunyu Yao. Reflexion: Language agents with verbal reinforcement learning. arXiv preprint arXiv:2303.11366, 2023.</p>
<p>Hongda Sun, Weikai Xu, Wei Liu, Jian Luan, Bin Wang, Shuo Shang, Ji-Rong Wen, and Rui Yan. From indeterminacy to determinacy: Augmenting logical reasoning capabilities with large language models. arXiv preprint arXiv:2310.18659, 2023.</p>
<p>Oyvind Tafjord, Bhavana Dalvi Mishra, and Peter Clark. Proofwriter: Generating implications, proofs, and abductive statements over natural language. arXiv preprint arXiv:2012.13048, 2020.</p>
<p>Alan Mathison Turing et al. On computable numbers, with an application to the entscheidungsproblem. J. of Math, 58(345-363):5, 1936.</p>
<p>Gladys Tyen, Hassan Mansoor, Peter Chen, Tony Mak, and Victor Cărbune. Llms cannot find reasoning errors, but can correct them! arXiv preprint arXiv:2311.08516, 2023.</p>
<p>Jonathan Uesato, Nate Kushman, Ramana Kumar, Francis Song, Noah Siegel, Lisa Wang, Antonia Creswell, Geoffrey Irving, and Irina Higgins. Solving math word problems with process-and outcome-based feedback. arXiv preprint arXiv:2211.14275, 2022.</p>
<p>Xiaoyan Wang, Pavan Kapanipathi, Ryan Musa, Mo Yu, Kartik Talamadupula, Ibrahim Abdelaziz, Maria Chang, Achille Fokoue, Bassem Makni, Nicholas Mattei, et al. Improving natural language inference using external knowledge in the science questions domain. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 33, pp. 7208-7215, 2019.</p>
<p>Xiting Wang, Kunpeng Liu, Dongjie Wang, Le Wu, Yanjie Fu, and Xing Xie. Multi-level recommendation reasoning over knowledge graphs with reinforcement learning. In Proceedings of the ACM Web Conference 2022, pp. 2098-2108, 2022a.</p>
<p>Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdhery, and Denny Zhou. Self-consistency improves chain of thought reasoning in language models. arXiv preprint arXiv:2203.11171, 2022b.</p>
<p>Yifei Wang, Yuyang Wu, Zeming Wei, Stefanie Jegelka, and Yisen Wang. A theoretical understanding of self-correction through in-context alignment. arXiv preprint arXiv:2405.18634, 2024.</p>
<p>Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. Chain-of-thought prompting elicits reasoning in large language models. Advances in Neural Information Processing Systems, 35:24824-24837, 2022.</p>
<p>Tongshuang Wu, Michael Terry, and Carrie Jun Cai. Ai chains: Transparent and controllable human-ai interaction by chaining large language model prompts. In Proceedings of the 2022 CHI conference on human factors in computing systems, pp. 1-22, 2022.</p>
<p>Jingfeng Yang, Haoming Jiang, Qingyu Yin, Danqing Zhang, Bing Yin, and Diyi Yang. Seqzero: Few-shot compositional semantic parsing with sequential prompts and zero-shot models. arXiv preprint arXiv:2205.07381, 2022.</p>
<p>Kaiyu Yang, Aidan M Swope, Alex Gu, Rahul Chalamala, Peiyang Song, Shixing Yu, Saad Godil, Ryan Prenger, and Anima Anandkumar. Leandojo: Theorem proving with retrieval-augmented language models. arXiv preprint arXiv:2306.15626, 2023.</p>
<p>Huihan Yao, Ying Chen, Qinyuan Ye, Xisen Jin, and Xiang Ren. Refining language models with compositional explanations. Advances in Neural Information Processing Systems, 34:8954-8967, 2021.</p>
<p>Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L Griffiths, Yuan Cao, and Karthik Narasimhan. Tree of thoughts: Deliberate problem solving with large language models. arXiv preprint arXiv:2305.10601, 2023.</p>
<p>Omar Zaidan, Jason Eisner, and Christine Piatko. Using "annotator rationales" to improve machine learning for text categorization. In Human language technologies 2007: The conference of the North American chapter of the association for computational linguistics; proceedings of the main conference, pp. 260-267, 2007.</p>
<p>Yifan Zhang, Yang Yuan, and Andrew Chi-Chih Yao. Meta prompting for ai systems. In ICLR 2024 Workshop on Bridging the Gap Between Practice and Theory in Deep Learning, 2024a. URL https://openreview.net/forum?id=vXRKHNYg1F.</p>
<p>Yunxiang Zhang, Muhammad Khalifa, Lajanugen Logeswaran, Jaekyeom Kim, Moontae Lee, Honglak Lee, and Lu Wang. Small language models need strong verifiers to self-correct reasoning. arXiv preprint arXiv:2404.17140, 2024b.</p>
<p>Chuanyang Zheng, Zhengying Liu, Enze Xie, Zhenguo Li, and Yu Li. Progressive-hint prompting improves reasoning in large language models. arXiv preprint arXiv:2304.09797, 2023.</p>
<p>Denny Zhou, Nathanael Schärli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schuurmans, Olivier Bousquet, Quoc Le, and Ed Chi. Least-to-most prompting enables complex reasoning in large language models. arXiv preprint arXiv:2205.10625, 2022.</p>
<p>Pei Zhou, Jay Pujara, Xiang Ren, Xinyun Chen, Heng-Tze Cheng, Quoc V Le, Ed H Chi, Denny Zhou, Swaroop Mishra, and Huaixiu Steven Zheng. Self-discover: Large language models selfcompose reasoning structures. arXiv preprint arXiv:2402.03620, 2024.</p>
<h1>Appendix</h1>
<p>A More on Experiments ..... 18
A. 1 More Experimental Results ..... 18
A. 2 Ablation Studies ..... 18
B Detailed Comparison of CoT, ToT and CR ..... 19
C More on Logic ..... 21
C. 1 Illustrative example on higher-order logic ..... 22
D Appendix for Examples ..... 24
E More on Datasets ..... 27
E. 1 More FOLIO Examples ..... 27
E. 2 Curating FOLIO wiki dataset ..... 30
E. 3 More examples on problems excluded from FOLIO wiki curated ..... 31
F Appendix for Prompts ..... 39</p>
<h1>A More on Experiments</h1>
<h2>A. 1 More Experimental Results</h2>
<p>Table 11: Comparison results on LogiQA</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Method</th>
<th style="text-align: center;">Acc. $\uparrow$</th>
<th style="text-align: center;"># Visited States $\downarrow$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Direct</td>
<td style="text-align: center;">$31.69 \%$</td>
<td style="text-align: center;">1</td>
</tr>
<tr>
<td style="text-align: left;">CoT</td>
<td style="text-align: center;">$38.55 \%$</td>
<td style="text-align: center;">1</td>
</tr>
<tr>
<td style="text-align: left;">CoT-SC</td>
<td style="text-align: center;">$40.43 \%$</td>
<td style="text-align: center;">$\mathbf{1 6}$</td>
</tr>
<tr>
<td style="text-align: left;">ToT</td>
<td style="text-align: center;">$\underline{43.02} \%$</td>
<td style="text-align: center;">19.87</td>
</tr>
<tr>
<td style="text-align: left;">CR</td>
<td style="text-align: center;">$\mathbf{4 5 . 2 5} \%$</td>
<td style="text-align: center;">$\underline{17}$</td>
</tr>
</tbody>
</table>
<p>Table 12: Comparison results on ProofWriter</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Method</th>
<th style="text-align: center;">Acc. $\uparrow$</th>
<th style="text-align: center;"># Visited States $\downarrow$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Standard</td>
<td style="text-align: center;">$46.83 \%$</td>
<td style="text-align: center;">1</td>
</tr>
<tr>
<td style="text-align: left;">CoT</td>
<td style="text-align: center;">$67.41 \%$</td>
<td style="text-align: center;">1</td>
</tr>
<tr>
<td style="text-align: left;">CoT-SC</td>
<td style="text-align: center;">$69.33 \%$</td>
<td style="text-align: center;">$\mathbf{1 6}$</td>
</tr>
<tr>
<td style="text-align: left;">ToT</td>
<td style="text-align: center;">$\underline{70.33} \%$</td>
<td style="text-align: center;">24.57</td>
</tr>
<tr>
<td style="text-align: left;">CR</td>
<td style="text-align: center;">$\mathbf{7 1 . 6 7} \%$</td>
<td style="text-align: center;">$\underline{16.76}$</td>
</tr>
</tbody>
</table>
<p>Table 13: Comparison results on FOLIO-val</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Method</th>
<th style="text-align: center;">Acc. $\uparrow$</th>
<th style="text-align: center;"># Visited States $\downarrow$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Standard</td>
<td style="text-align: center;">$60.29 \%$</td>
<td style="text-align: center;">1</td>
</tr>
<tr>
<td style="text-align: left;">CoT</td>
<td style="text-align: center;">$67.65 \%$</td>
<td style="text-align: center;">1</td>
</tr>
<tr>
<td style="text-align: left;">CoT-SC</td>
<td style="text-align: center;">$68.14 \%$</td>
<td style="text-align: center;">$\underline{16}$</td>
</tr>
<tr>
<td style="text-align: left;">ToT</td>
<td style="text-align: center;">$\mathbf{6 9 . 1 2} \%$</td>
<td style="text-align: center;">19.12</td>
</tr>
<tr>
<td style="text-align: left;">CR</td>
<td style="text-align: center;">$\mathbf{6 9 . 1 1} \%$</td>
<td style="text-align: center;">$\mathbf{1 5 . 8 7}$</td>
</tr>
</tbody>
</table>
<p>Table 14: Comparison results on LD</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Method</th>
<th style="text-align: center;">Acc. $\uparrow$</th>
<th style="text-align: center;"># Visited States $\downarrow$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Standard</td>
<td style="text-align: center;">$71.33 \%$</td>
<td style="text-align: center;">1</td>
</tr>
<tr>
<td style="text-align: left;">CoT</td>
<td style="text-align: center;">$73.33 \%$</td>
<td style="text-align: center;">1</td>
</tr>
<tr>
<td style="text-align: left;">CoT-SC</td>
<td style="text-align: center;">$74.67 \%$</td>
<td style="text-align: center;">$\mathbf{1 6}$</td>
</tr>
<tr>
<td style="text-align: left;">ToT</td>
<td style="text-align: center;">$\underline{76.83} \%$</td>
<td style="text-align: center;">21.83</td>
</tr>
<tr>
<td style="text-align: left;">CR</td>
<td style="text-align: center;">$\mathbf{7 8 . 3 3} \%$</td>
<td style="text-align: center;">$\underline{16.98}$</td>
</tr>
</tbody>
</table>
<p>Table 15: Comparison of results on different datasets.
For a fair comparison of different methods on the LogiQA, ProofWriter, FOLIO (validation set), and LD datasets, we report the third-party reproduced results by Sun et al. (2023). For implementation details on these experiments, please refer to their work.</p>
<h2>A. 2 Ablation Studies</h2>
<p>Table 16: Ablation studies on FOLIO wiki dataset using GPT-3.5-turbo model.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Model</th>
<th style="text-align: left;">Method</th>
<th style="text-align: center;">Acc. $\uparrow(\%)$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">-</td>
<td style="text-align: left;">[Random]</td>
<td style="text-align: center;">33.33</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">Direct</td>
<td style="text-align: center;">62.92</td>
</tr>
<tr>
<td style="text-align: left;">GPT-3.5-turbo</td>
<td style="text-align: left;">CoT</td>
<td style="text-align: center;">$64.61(+1.69)$</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">CoT-SC $(\mathrm{k}=16)$</td>
<td style="text-align: center;">$63.33(+0.41)$</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">CR (ours, $n=2$ )</td>
<td style="text-align: center;">$\mathbf{7 3 . 0 3}(+10.11)$</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">CR (ours, $n=2$, w/o Verifier)</td>
<td style="text-align: center;">$64.23(+1.31)$</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">CR (ours, $n=2$, w/o premises random choice)</td>
<td style="text-align: center;">$\underline{68.73}(+5.81)$</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">CR (ours, $n=2$, w/o Verifier, w/o premises random choice)</td>
<td style="text-align: center;">$67.23(+4.31)$</td>
</tr>
</tbody>
</table>
<h1>B Detailed Comparison of CoT, ToT and CR</h1>
<p>Detailed Comparison of CoT, ToT, and CR. To compare these methods in detail, we consider a simple 2-stage reasoning process, which can be extended to multiple stages as well. For simplicity, whenever the model has a step-verifier, we assume that the verifier has near-perfect accuracy (which can be achieved by using a symbolic verifier environment such as a Python code interpreter or Lean). Moreover, we assume that there exists exactly one correct reasoning path for the problem. We have the following definition:</p>
<p>Definition B. 1 (Arrival Probability). For a given algorithm, we may compute its arrival probability as the probability of reaching the correct conclusion from the initial state. Specifically, denote the arrival probability of CoT as $P_{\mathrm{CoT}}$, the arrival probability of running CoT multiple times as $P_{\mathrm{CoT}-\mathrm{SC}}$, the arrival probability of ToT as $P_{\mathrm{ToT}}=p_{1_{\mathrm{ToT}}} p_{2_{\mathrm{ToT}}}$, the arrival probability of CR as $P_{\mathrm{CR}}=p_{1_{\mathrm{CR}}} p_{2_{\mathrm{CR}}}$. Here, $p_{1_{\mathrm{ToT}}}$ and $p_{1_{\mathrm{CR}}}$ are the probability of getting the first reasoning step correctly, while $p_{2_{\mathrm{ToT}}}$ and $p_{2_{\mathrm{CR}}}$ are for the second step conditioned on the first step is correct.</p>
<p>Since both ToT and CR have verifiers, they can immediately immediately exclude the wrong path; see Figure 4. Therefore, we immediately have $P_{\mathrm{CoT}} \leq p_{1_{\mathrm{ToT}}} p_{2_{\mathrm{ToT}}}$, as CoT explores more useless branches.
<img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 4: Comparison between CoT-SC, ToT, and CR.
Note that using $p_{1_{\mathrm{CR}}}$ or $p_{2_{\mathrm{CR}}}$ to denote the arrival probabilities of CR is not accurate, as CR will maintain a history of visited states. Therefore, we use $p_{1_{\mathrm{CR}}|\langle \cdot\rangle}$ and $p_{2_{\mathrm{CR}}|\langle \cdot\rangle}$ to denote the probability conditioned with additional visited states. We have the following assumption.</p>
<p>Assumption B.2. $p_{1_{\mathrm{ToT}}} \leq p_{1_{\mathrm{CR}}}, p_{2_{\mathrm{ToT}}} \leq p_{2_{\mathrm{CR}}}$. In addition, $p_{1_{\mathrm{CR}}|\langle \cdot\rangle}$ and $p_{2_{\mathrm{CR}}|\langle \cdot\rangle}$ will monotonically increase as more nodes have been entered:</p>
<p>$$
\begin{aligned}
p_{1_{\text {ToT }}} \leq &amp; p_{1_{\mathrm{CR}}|(\text { premises }) \leq p_{2_{\mathrm{CR}}|(\text { premises,stage-1 node }<em 2__mathrm_CR="2_{\mathrm{CR">{1})}} \
&amp; \leq p</em>}}|(\text { premises,stage-1 node <em 2="2">{1}, \text { node }</em>}, \cdots, \text { node <em 2__text="2_{\text" _ToT="{ToT">{n})} \
p</em> \
\leq &amp; p_{2_{\mathrm{CR}}|(\text { premises,stage-1 nodes, stage-2 node }}}} \leq &amp; p_{2_{\mathrm{CR}}|(\text { premises,stage-1 nodes })<em 2__mathrm_CR="2_{\mathrm{CR">{1})} \
\leq &amp; p</em>}}|(\text { premises,stage-1 nodes,stage-2 node <em 2="2">{1}, \text {,node }</em>
\end{aligned}
$$}, \cdots, \text { node }_{n})</p>
<p>This assumption is natural and has been empirically validated in various tasks (Madaan et al., 2023; Shinn et al., 2023) since CR will not enter the failed nodes multiple times, since the verifier has wiped out the possibilities of these nodes and their successors. The following lemma is handy for later comparison.</p>
<p>Lemma B.3. For any positive integer $n$, for any probabilities $p_{1} \in[0,1]$ and $p_{2} \in[0,1]$, the following inequality holds:</p>
<p>$$
1-\left(1-p_{1} \cdot p_{2}\right)^{n} \leq\left(1-\left(1-p_{1}\right)^{n}\right) \cdot\left(1-\left(1-p_{2}\right)^{n}\right)
$$</p>
<p>Proof.</p>
<p>$$
\begin{aligned}
&amp; 1-\left(1-p_{1} \cdot p_{2}\right)^{n} \leq\left(1-\left(1-p_{1}\right)^{n}\right) \cdot\left(1-\left(1-p_{2}\right)^{n}\right) \
\Leftrightarrow &amp; 1-\left(1-p_{1} \cdot p_{2}\right)^{n} \leq 1-\left(1-p_{1}\right)^{n}-\left(1-p_{2}\right)^{n}+\left(1-p_{1}\right)^{n} \cdot\left(1-p_{2}\right)^{n} \
\Leftrightarrow &amp; \left(1-p_{1}\right)^{n}+\left(1-p_{2}\right)^{n} \leq\left(1-p_{1} \cdot p_{2}\right)^{n}+\left(1-p_{1}\right)^{n} \cdot\left(1-p_{2}\right)^{n} \
\Leftrightarrow &amp; \left(1-p_{1}\right)^{n}+\left(1-p_{2}\right)^{n} \leq\left(1-p_{1} \cdot p_{2}\right)^{n}+\left(1-p_{1}-p_{2}+p_{1} \cdot p_{2}\right)^{n}
\end{aligned}
$$</p>
<p>Notice that</p>
<p>$$
\left(1-p_{1} \cdot p_{2}\right)+\left(1-p_{1}-p_{2}+p_{1} \cdot p_{2}\right) \equiv\left(1-p_{2}\right)+\left(1-p_{2}\right) \equiv 2-p_{1}-p_{2}
$$</p>
<p>WLOG, let $p_{1} \geq p_{2}$, then</p>
<p>$$
\left(1-p_{1}-p_{2}+p_{1} \cdot p_{2}\right) \leq\left(1-p_{1}\right) \leq\left(1-p_{2}\right) \leq\left(1-p_{1} \cdot p_{2}\right)
$$</p>
<p>From the monotonicity of function $x^{n}+\left(2-p_{1}-p_{2}-x\right)^{n}$ in the interval $\left(-\infty, \frac{2-p_{1}-p_{2}}{2}\right]$ and the interval $\left[\frac{2-p_{1}-p_{2}}{2},+\infty\right)$ respectively, and the symmetry of $\left{\left(1-p_{1}-p_{2}+p_{1} \cdot p_{2}\right),\left(1-p_{1} \cdot p_{2}\right)\right}$ and the symmetry of $\left{\left(1-p_{1}\right),\left(1-p_{2}\right)\right}$ correspond to $y=\frac{2-p_{1}-p_{2}}{2}$, we conclude the proof.
Theorem B. 4 ( $P_{\mathrm{CoT}-\mathrm{SC}} \leq P_{\mathrm{ToT}} \leq P_{\mathrm{CR}}$ ). Assume CoT-SC has $n$ different trials, while ToT and CR search with breadth at most $n$. Under Assumptions B.2, the following inequality holds:</p>
<p>$$
P_{\mathrm{CoT}-\mathrm{SC}} \leq P_{\mathrm{ToT}} \leq P_{\mathrm{CR}}
$$</p>
<p>Proof.</p>
<p>$$
\begin{gathered}
P_{\mathrm{CoT}-\mathrm{SC}} \leq 1-\left(1-p_{\mathrm{CoT}}\right)^{n} \leq 1-\left(1-p_{1} \cdot p_{2}\right)^{n} \
P_{\mathrm{ToT}}=\left(1-\left(1-p_{1}\right)^{n}\right) \cdot\left(1-\left(1-p_{2}\right)^{n}\right)
\end{gathered}
$$</p>
<p>Combined with Lemma B.3, now we have</p>
<p>$$
P_{\mathrm{CoT}-\mathrm{SC}} \leq P_{\mathrm{ToT}}
$$</p>
<p>From Assumption B.2, we have</p>
<p>$$
\left.P_{\mathrm{ToT}} \leq\left(1-\left(1-p_{1_{\mathrm{CR}} \mid(\text { premises })}\right)^{n}\right) \cdot\left(1-\left(1-p_{2_{\mathrm{CR}} \mid(\text { premises, stage-1 nodes })}\right)^{n}\right) \leq P_{\mathrm{CR}}\right.
$$</p>
<p>Finally, we conclude that</p>
<p>$$
P_{\mathrm{CoT}-\mathrm{SC}} \leq P_{\mathrm{ToT}} \leq P_{\mathrm{CR}}
$$</p>
<p>In order to explore why CR performs better than CoT, we conducted a conceptual experiment on the Game of 24 . Specifically, we divide the solution process of the Game of 24 into two steps. The first step is to randomly select two numbers from the four input numbers to obtain a new number. The second step is to use the remaining three numbers to directly obtain 24 . We refer to the success rate of the first step as $p_{1}$ and the success rate of the second step as $p_{2}$. We also use $p$ to denote the success rate that directly solving Game of 24 with given four numbers. The results are shown in Table 17.</p>
<p>It is evident that completing the problem step by step and verifying the result of each step can effectively improve the accuracy rate.</p>
<p>Table 17: Results for the conceptual experiment. We selected the puzzles with a unique solution path in the test dataset to facilitate evaluation. We repeated the experiment 1000 times for each case.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Puzzle</th>
<th style="text-align: left;">$p(\%)$</th>
<th style="text-align: left;">$p_{1}(\%)$</th>
<th style="text-align: left;">$p_{2}(\%)$</th>
<th style="text-align: left;">$p_{1} p_{2}(\%)$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">$2,7,12,13$</td>
<td style="text-align: left;">3.0</td>
<td style="text-align: left;">62.3</td>
<td style="text-align: left;">8.0</td>
<td style="text-align: left;">$5.0(+2.0)$</td>
</tr>
<tr>
<td style="text-align: left;">$6,11,12,13$</td>
<td style="text-align: left;">0.0</td>
<td style="text-align: left;">64.8</td>
<td style="text-align: left;">8.0</td>
<td style="text-align: left;">$5.2(+5.2)$</td>
</tr>
<tr>
<td style="text-align: left;">$8,8,10,12$</td>
<td style="text-align: left;">1.8</td>
<td style="text-align: left;">6.9</td>
<td style="text-align: left;">63.9</td>
<td style="text-align: left;">$4.4(+2.6)$</td>
</tr>
</tbody>
</table>
<h1>C More on Logic</h1>
<p>Limitations of First-Order Logic Systems. It is not surprising that the labels verified by FOL are still not satisfying. There are several limitations inside the FOL systems:</p>
<ol>
<li>Limitations of Expressiveness (Löwenheim, 1967): FOL even lacks the expressive power to capture some properties of the real numbers. For example, properties involving uncountably many real numbers often cannot be expressed in FOL. In addition, properties requiring quantification over sets of real numbers or functions from real numbers to real numbers cannot be naturally represented in FOL.</li>
</ol>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>*Equal contribution.
${ }^{\dagger}$ Corresponding authors.&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>