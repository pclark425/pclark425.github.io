<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Rediscovery-vs-Discovery Distinction Theory - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-162</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-162</p>
                <p><strong>Name:</strong> Rediscovery-vs-Discovery Distinction Theory</p>
                <p><strong>Type:</strong> specific</p>
                <p><strong>Theory Query:</strong> Build a theory about the evaluation and validation of incremental versus transformational scientific discoveries in automated systems, based on the following results.</p>
                <p><strong>Description:</strong> Automated scientific discovery systems frequently 'rediscover' known scientific results rather than making genuinely novel discoveries. This distinction is critical for evaluating system impact: rediscoveries demonstrate system capability and serve as validation benchmarks (incremental contribution) but do not advance scientific knowledge (transformational contribution). The distinction is often blurred in system evaluations, particularly when systems are tested on historical datasets or known benchmarks. However, the relationship between rediscovery and discovery capability is complex: rediscovery can serve as a necessary validation step, and some systems explicitly track and distinguish between known and novel results. The challenge of novelty assessment—requiring literature comparison, expert evaluation, and often retrospective community validation—makes this distinction operationally difficult but scientifically essential.</p>
                <p><strong>Knowledge Cutoff Year:</strong> 2024</p>
                <p><strong>Knowledge Cutoff Month:</strong> 12</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <ol>
                <li>Rediscovery of known results demonstrates system capability and serves as validation but does not constitute transformational scientific discovery.</li>
                <li>Systems evaluated primarily on rediscovery tasks (historical benchmarks) should be characterized as demonstrating incremental capability, regardless of the novelty of their methods.</li>
                <li>The scientific impact of a system should be measured by the proportion and significance of genuinely novel discoveries, not total discoveries including rediscoveries.</li>
                <li>Rediscovery tasks are valuable and necessary for system validation but insufficient for claiming transformational scientific impact.</li>
                <li>The distinction between rediscovery and discovery requires explicit novelty assessment through literature comparison, expert evaluation, and often retrospective community validation.</li>
                <li>Novelty assessment is operationally challenging due to incomplete literature coverage, knowledge cutoffs, and the time required for community validation.</li>
                <li>Systems that explicitly track and distinguish known vs. novel results (e.g., 'known', 'new and unproven', 'new and proven') provide more transparent evaluation of their contributions.</li>
                <li>Rediscovery capability may be a necessary but not sufficient condition for novel discovery capability.</li>
                <li>The value of a rediscovery depends on context: it may be valuable for validation, for finding simpler methods, or in poorly documented domains, but less valuable when presented as novel discovery.</li>
            </ol>
            <h3>Supporting Evidence</h3>
<ol>
    <li>AI-Descartes explicitly rediscovered known physical laws (Kepler's third law, Einstein's time-dilation law) and is characterized as often confirming known theories rather than producing novel insights <a href="../results/extraction-result-1266.html#e1266.2" class="evidence-link">[e1266.2]</a> </li>
    <li>AI Feynman recovered 100/100 known physics equations from Feynman Lectures and 90% of bonus equations, demonstrating rediscovery capability on known benchmarks <a href="../results/extraction-result-1431.html#e1431.0" class="evidence-link">[e1431.0]</a> <a href="../results/extraction-result-1222.html#e1222.0" class="evidence-link">[e1222.0]</a> </li>
    <li>STAHL/KEKADA rediscovered oxygen theory and Krebs cycle, with success judged by whether outputs corresponded to extant scientific knowledge <a href="../results/extraction-result-1451.html#e1451.2" class="evidence-link">[e1451.2]</a> </li>
    <li>IDS rediscovered Black's heat law and conservation of momentum, demonstrating integration but evaluated by comparison to established domain laws <a href="../results/extraction-result-1206.html#e1206.2" class="evidence-link">[e1206.2]</a> </li>
    <li>Schmidt & Lipson system extracts known conservation laws from experimental data <a href="../results/extraction-result-1192.html#e1192.1" class="evidence-link">[e1192.1]</a> <a href="../results/extraction-result-1452.html#e1452.6" class="evidence-link">[e1452.6]</a> </li>
    <li>Bacon/ABACUS/Fahrenheit/IDS systems rediscover empirical laws from data, with evaluation by ability to rediscover known laws <a href="../results/extraction-result-1452.html#e1452.5" class="evidence-link">[e1452.5]</a> </li>
    <li>DENDRAL rediscovered chemical structure elucidation methods, with novelty limited because outputs corresponded to extant scientific knowledge <a href="../results/extraction-result-1192.html#e1192.0" class="evidence-link">[e1192.0]</a> <a href="../results/extraction-result-1249.html#e1249.0" class="evidence-link">[e1249.0]</a> <a href="../results/extraction-result-1233.html#e1233.3" class="evidence-link">[e1233.3]</a> </li>
    <li>Eureqa searches for mathematical relationships consistent with data, with novelty framed as automating discovery rather than producing new laws <a href="../results/extraction-result-1256.html#e1256.5" class="evidence-link">[e1256.5]</a> <a href="../results/extraction-result-1233.html#e1233.2" class="evidence-link">[e1233.2]</a> </li>
    <li>AI-Hilbert transforms theories and data into consistent mathematical models, but systems often reproduce known laws which limits novelty <a href="../results/extraction-result-1266.html#e1266.1" class="evidence-link">[e1266.1]</a> </li>
    <li>MITM-RF explicitly categorizes outputs as 'known', 'new and proven', or 'new and unproven' based on literature checks <a href="../results/extraction-result-1449.html#e1449.1" class="evidence-link">[e1449.1]</a> <a href="../results/extraction-result-1453.html#e1453.1" class="evidence-link">[e1453.1]</a> </li>
    <li>Ramanujan Machine generates conjectures categorized by whether they are novel relative to published results, with some later proven by community <a href="../results/extraction-result-1243.html#e1243.4" class="evidence-link">[e1243.4]</a> <a href="../results/extraction-result-1453.html#e1453.1" class="evidence-link">[e1453.1]</a> </li>
    <li>Multiple papers note that systems often confirm known theories rather than producing genuinely novel insights without human interpretation <a href="../results/extraction-result-1266.html#e1266.2" class="evidence-link">[e1266.2]</a> <a href="../results/extraction-result-1266.html#e1266.1" class="evidence-link">[e1266.1]</a> <a href="../results/extraction-result-1249.html#e1249.6" class="evidence-link">[e1249.6]</a> </li>
    <li>Novelty assessment requires literature checks, community feedback, and is often retrospective rather than real-time <a href="../results/extraction-result-1449.html#e1449.1" class="evidence-link">[e1449.1]</a> <a href="../results/extraction-result-1178.html#e1178.2" class="evidence-link">[e1178.2]</a> <a href="../results/extraction-result-1209.html#e1209.0" class="evidence-link">[e1209.0]</a> <a href="../results/extraction-result-1202.html#e1202.0" class="evidence-link">[e1202.0]</a> </li>
    <li>Systems evaluated primarily on rediscovery tasks (historical benchmarks) may not generalize to novel discovery <a href="../results/extraction-result-1431.html#e1431.0" class="evidence-link">[e1431.0]</a> <a href="../results/extraction-result-1222.html#e1222.0" class="evidence-link">[e1222.0]</a> <a href="../results/extraction-result-1206.html#e1206.2" class="evidence-link">[e1206.2]</a> </li>
    <li>Rediscovery serves as validation: AI Feynman's ability to recover known equations validates the method before applying to unknown problems <a href="../results/extraction-result-1431.html#e1431.0" class="evidence-link">[e1431.0]</a> </li>
    <li>Some systems produce both rediscoveries and novel discoveries in the same framework, with explicit tracking of which is which <a href="../results/extraction-result-1449.html#e1449.1" class="evidence-link">[e1449.1]</a> <a href="../results/extraction-result-1453.html#e1453.1" class="evidence-link">[e1453.1]</a> <a href="../results/extraction-result-1243.html#e1243.4" class="evidence-link">[e1243.4]</a> </li>
    <li>Novelty assessment is challenging due to offline knowledge cutoffs, incomplete literature coverage, and evolving scientific consensus <a href="../results/extraction-result-1202.html#e1202.0" class="evidence-link">[e1202.0]</a> <a href="../results/extraction-result-1178.html#e1178.2" class="evidence-link">[e1178.2]</a> <a href="../results/extraction-result-1209.html#e1209.0" class="evidence-link">[e1209.0]</a> </li>
    <li>Papers emphasize that high predictive accuracy (e.g., AlphaFold) does not equate to discovering new mechanistic or causal explanatory laws <a href="../results/extraction-result-1233.html#e1233.0" class="evidence-link">[e1233.0]</a> </li>
    <li>Rediscovery with novel methods can itself be scientifically valuable (e.g., finding simpler proofs or more efficient algorithms) <a href="../results/extraction-result-1431.html#e1431.0" class="evidence-link">[e1431.0]</a> </li>
</ol>            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>Systems that excel at rediscovery tasks on historical benchmarks will show degraded performance when applied to genuinely novel discovery tasks where ground truth is unknown.</li>
                <li>The proportion of rediscoveries to novel discoveries will decrease as systems are applied to less well-studied domains or more recent scientific questions.</li>
                <li>Systems with explicit novelty-checking mechanisms (literature search, expert consultation) will have lower overall success rates but higher impact per claimed discovery.</li>
                <li>Systems trained primarily on historical rediscovery tasks will exhibit confirmation bias toward known patterns when applied to novel problems.</li>
                <li>The time lag between a system's output and community validation of novelty will be longer for genuinely novel discoveries than for rediscoveries.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>Whether rediscovery capability is a necessary prerequisite for novel discovery capability, or whether systems could be designed to skip the rediscovery validation phase.</li>
                <li>Whether certain types of rediscoveries (e.g., finding dramatically simpler proofs of known theorems, or more efficient algorithms for known problems) should be considered transformational contributions.</li>
                <li>Whether the rediscovery-discovery distinction will become less meaningful as automated systems become more prevalent and the boundary between 'known' and 'novel' becomes more fluid.</li>
                <li>Whether systems that perform well on rediscovery benchmarks will eventually plateau in their ability to make novel discoveries, or whether rediscovery performance predicts novel discovery performance.</li>
                <li>Whether the scientific community will develop standardized protocols for novelty assessment that can be applied in real-time rather than retrospectively.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>Finding that systems good at rediscovery are equally good at novel discovery (without additional training or modification) would challenge the distinction's practical importance.</li>
                <li>Demonstrating that rediscoveries have equal scientific impact to novel discoveries (in terms of citations, follow-up work, or practical applications) would contradict the theory's impact claims.</li>
                <li>Showing that novelty assessment is so unreliable or subjective that it cannot be consistently applied would undermine the distinction's utility.</li>
                <li>Finding that systems explicitly designed to avoid rediscovery (through novelty checking) perform worse at novel discovery would challenge the theory's recommendations.</li>
                <li>Demonstrating that the community cannot reliably distinguish between rediscoveries and novel discoveries in blind evaluations would question the distinction's validity.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>The value of rediscovery for building confidence in system correctness before applying to novel problems <a href="../results/extraction-result-1431.html#e1431.0" class="evidence-link">[e1431.0]</a> </li>
    <li>How the difficulty of rediscovery tasks correlates with the capability for novel discovery </li>
    <li>The role of rediscovery in pedagogical or educational contexts for training systems </li>
    <li>Whether some domains have higher rediscovery-to-discovery ratios than others and why </li>
    <li>The economic and resource costs of novelty assessment and how they affect system deployment </li>
    <li>How systems should handle cases where 'rediscovery' occurs independently in poorly connected scientific communities </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> closely-related-to-existing</p>
            <p><strong>Explanation:</strong> No explanation provided.</p>
            <p><strong>References:</strong> <ul>
    <li>Kuhn (1962) The Structure of Scientific Revolutions [Discusses normal science vs revolutionary science, relevant to incremental vs transformational distinction]</li>
    <li>Merton (1961) Singletons and Multiples in Scientific Discovery [Discusses independent rediscovery and simultaneous discovery in science]</li>
    <li>Langley et al. (1987) Scientific Discovery: Computational Explorations [Discusses rediscovery in computational systems and its role in validation]</li>
    <li>Simon (1977) Models of Discovery [Discusses the role of rediscovery in understanding discovery processes]</li>
    <li>Kulkarni & Simon (1988) The Processes of Scientific Discovery: The Strategy of Experimentation [Discusses KEKADA's rediscovery of Krebs cycle as validation]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Rediscovery-vs-Discovery Distinction Theory",
    "theory_description": "Automated scientific discovery systems frequently 'rediscover' known scientific results rather than making genuinely novel discoveries. This distinction is critical for evaluating system impact: rediscoveries demonstrate system capability and serve as validation benchmarks (incremental contribution) but do not advance scientific knowledge (transformational contribution). The distinction is often blurred in system evaluations, particularly when systems are tested on historical datasets or known benchmarks. However, the relationship between rediscovery and discovery capability is complex: rediscovery can serve as a necessary validation step, and some systems explicitly track and distinguish between known and novel results. The challenge of novelty assessment—requiring literature comparison, expert evaluation, and often retrospective community validation—makes this distinction operationally difficult but scientifically essential.",
    "supporting_evidence": [
        {
            "text": "AI-Descartes explicitly rediscovered known physical laws (Kepler's third law, Einstein's time-dilation law) and is characterized as often confirming known theories rather than producing novel insights",
            "uuids": [
                "e1266.2"
            ]
        },
        {
            "text": "AI Feynman recovered 100/100 known physics equations from Feynman Lectures and 90% of bonus equations, demonstrating rediscovery capability on known benchmarks",
            "uuids": [
                "e1431.0",
                "e1222.0"
            ]
        },
        {
            "text": "STAHL/KEKADA rediscovered oxygen theory and Krebs cycle, with success judged by whether outputs corresponded to extant scientific knowledge",
            "uuids": [
                "e1451.2"
            ]
        },
        {
            "text": "IDS rediscovered Black's heat law and conservation of momentum, demonstrating integration but evaluated by comparison to established domain laws",
            "uuids": [
                "e1206.2"
            ]
        },
        {
            "text": "Schmidt & Lipson system extracts known conservation laws from experimental data",
            "uuids": [
                "e1192.1",
                "e1452.6"
            ]
        },
        {
            "text": "Bacon/ABACUS/Fahrenheit/IDS systems rediscover empirical laws from data, with evaluation by ability to rediscover known laws",
            "uuids": [
                "e1452.5"
            ]
        },
        {
            "text": "DENDRAL rediscovered chemical structure elucidation methods, with novelty limited because outputs corresponded to extant scientific knowledge",
            "uuids": [
                "e1192.0",
                "e1249.0",
                "e1233.3"
            ]
        },
        {
            "text": "Eureqa searches for mathematical relationships consistent with data, with novelty framed as automating discovery rather than producing new laws",
            "uuids": [
                "e1256.5",
                "e1233.2"
            ]
        },
        {
            "text": "AI-Hilbert transforms theories and data into consistent mathematical models, but systems often reproduce known laws which limits novelty",
            "uuids": [
                "e1266.1"
            ]
        },
        {
            "text": "MITM-RF explicitly categorizes outputs as 'known', 'new and proven', or 'new and unproven' based on literature checks",
            "uuids": [
                "e1449.1",
                "e1453.1"
            ]
        },
        {
            "text": "Ramanujan Machine generates conjectures categorized by whether they are novel relative to published results, with some later proven by community",
            "uuids": [
                "e1243.4",
                "e1453.1"
            ]
        },
        {
            "text": "Multiple papers note that systems often confirm known theories rather than producing genuinely novel insights without human interpretation",
            "uuids": [
                "e1266.2",
                "e1266.1",
                "e1249.6"
            ]
        },
        {
            "text": "Novelty assessment requires literature checks, community feedback, and is often retrospective rather than real-time",
            "uuids": [
                "e1449.1",
                "e1178.2",
                "e1209.0",
                "e1202.0"
            ]
        },
        {
            "text": "Systems evaluated primarily on rediscovery tasks (historical benchmarks) may not generalize to novel discovery",
            "uuids": [
                "e1431.0",
                "e1222.0",
                "e1206.2"
            ]
        },
        {
            "text": "Rediscovery serves as validation: AI Feynman's ability to recover known equations validates the method before applying to unknown problems",
            "uuids": [
                "e1431.0"
            ]
        },
        {
            "text": "Some systems produce both rediscoveries and novel discoveries in the same framework, with explicit tracking of which is which",
            "uuids": [
                "e1449.1",
                "e1453.1",
                "e1243.4"
            ]
        },
        {
            "text": "Novelty assessment is challenging due to offline knowledge cutoffs, incomplete literature coverage, and evolving scientific consensus",
            "uuids": [
                "e1202.0",
                "e1178.2",
                "e1209.0"
            ]
        },
        {
            "text": "Papers emphasize that high predictive accuracy (e.g., AlphaFold) does not equate to discovering new mechanistic or causal explanatory laws",
            "uuids": [
                "e1233.0"
            ]
        },
        {
            "text": "Rediscovery with novel methods can itself be scientifically valuable (e.g., finding simpler proofs or more efficient algorithms)",
            "uuids": [
                "e1431.0"
            ]
        }
    ],
    "theory_statements": [
        "Rediscovery of known results demonstrates system capability and serves as validation but does not constitute transformational scientific discovery.",
        "Systems evaluated primarily on rediscovery tasks (historical benchmarks) should be characterized as demonstrating incremental capability, regardless of the novelty of their methods.",
        "The scientific impact of a system should be measured by the proportion and significance of genuinely novel discoveries, not total discoveries including rediscoveries.",
        "Rediscovery tasks are valuable and necessary for system validation but insufficient for claiming transformational scientific impact.",
        "The distinction between rediscovery and discovery requires explicit novelty assessment through literature comparison, expert evaluation, and often retrospective community validation.",
        "Novelty assessment is operationally challenging due to incomplete literature coverage, knowledge cutoffs, and the time required for community validation.",
        "Systems that explicitly track and distinguish known vs. novel results (e.g., 'known', 'new and unproven', 'new and proven') provide more transparent evaluation of their contributions.",
        "Rediscovery capability may be a necessary but not sufficient condition for novel discovery capability.",
        "The value of a rediscovery depends on context: it may be valuable for validation, for finding simpler methods, or in poorly documented domains, but less valuable when presented as novel discovery."
    ],
    "new_predictions_likely": [
        "Systems that excel at rediscovery tasks on historical benchmarks will show degraded performance when applied to genuinely novel discovery tasks where ground truth is unknown.",
        "The proportion of rediscoveries to novel discoveries will decrease as systems are applied to less well-studied domains or more recent scientific questions.",
        "Systems with explicit novelty-checking mechanisms (literature search, expert consultation) will have lower overall success rates but higher impact per claimed discovery.",
        "Systems trained primarily on historical rediscovery tasks will exhibit confirmation bias toward known patterns when applied to novel problems.",
        "The time lag between a system's output and community validation of novelty will be longer for genuinely novel discoveries than for rediscoveries."
    ],
    "new_predictions_unknown": [
        "Whether rediscovery capability is a necessary prerequisite for novel discovery capability, or whether systems could be designed to skip the rediscovery validation phase.",
        "Whether certain types of rediscoveries (e.g., finding dramatically simpler proofs of known theorems, or more efficient algorithms for known problems) should be considered transformational contributions.",
        "Whether the rediscovery-discovery distinction will become less meaningful as automated systems become more prevalent and the boundary between 'known' and 'novel' becomes more fluid.",
        "Whether systems that perform well on rediscovery benchmarks will eventually plateau in their ability to make novel discoveries, or whether rediscovery performance predicts novel discovery performance.",
        "Whether the scientific community will develop standardized protocols for novelty assessment that can be applied in real-time rather than retrospectively."
    ],
    "negative_experiments": [
        "Finding that systems good at rediscovery are equally good at novel discovery (without additional training or modification) would challenge the distinction's practical importance.",
        "Demonstrating that rediscoveries have equal scientific impact to novel discoveries (in terms of citations, follow-up work, or practical applications) would contradict the theory's impact claims.",
        "Showing that novelty assessment is so unreliable or subjective that it cannot be consistently applied would undermine the distinction's utility.",
        "Finding that systems explicitly designed to avoid rediscovery (through novelty checking) perform worse at novel discovery would challenge the theory's recommendations.",
        "Demonstrating that the community cannot reliably distinguish between rediscoveries and novel discoveries in blind evaluations would question the distinction's validity."
    ],
    "unaccounted_for": [
        {
            "text": "The value of rediscovery for building confidence in system correctness before applying to novel problems",
            "uuids": [
                "e1431.0"
            ]
        },
        {
            "text": "How the difficulty of rediscovery tasks correlates with the capability for novel discovery",
            "uuids": []
        },
        {
            "text": "The role of rediscovery in pedagogical or educational contexts for training systems",
            "uuids": []
        },
        {
            "text": "Whether some domains have higher rediscovery-to-discovery ratios than others and why",
            "uuids": []
        },
        {
            "text": "The economic and resource costs of novelty assessment and how they affect system deployment",
            "uuids": []
        },
        {
            "text": "How systems should handle cases where 'rediscovery' occurs independently in poorly connected scientific communities",
            "uuids": []
        }
    ],
    "conflicting_evidence": [
        {
            "text": "Some systems (MITM-RF, Ramanujan Machine) produce both rediscoveries and novel discoveries in the same framework, suggesting the distinction may be a spectrum rather than a binary",
            "uuids": [
                "e1449.1",
                "e1453.1",
                "e1243.4"
            ]
        },
        {
            "text": "Rediscovery with novel methods (e.g., AI Feynman's physics-inspired symbolic regression) can itself be scientifically valuable and enable new applications",
            "uuids": [
                "e1431.0"
            ]
        },
        {
            "text": "Some papers suggest that rediscovery is a necessary validation step rather than a limitation, complicating the incremental vs. transformational distinction",
            "uuids": [
                "e1431.0",
                "e1206.2"
            ]
        },
        {
            "text": "Adam robot scientist made novel gene-function discoveries (not rediscoveries), showing some systems do achieve genuine discovery",
            "uuids": [
                "e1193.0",
                "e1243.1",
                "e1289.0"
            ]
        },
        {
            "text": "Eve discovered drug repurposing opportunities (TNP-470 for P. vivax) that were novel, not rediscoveries",
            "uuids": [
                "e1193.1"
            ]
        }
    ],
    "special_cases": [
        "In mathematics, finding simpler proofs of known theorems or more efficient algorithms may be considered novel contributions even though the theorem itself is known.",
        "In domains with poor documentation or disconnected research communities, rediscovery may effectively constitute novel discovery for that community.",
        "For system validation and benchmarking purposes, rediscovery tasks are appropriate and valuable, and should not be criticized as limitations.",
        "In rapidly evolving fields, the distinction between known and novel may be temporally dependent on knowledge cutoff dates.",
        "Some rediscoveries may be valuable if they provide new mechanistic understanding or connect previously unrelated areas, even if the result itself was known.",
        "In educational or training contexts, rediscovery may be the explicit goal rather than a limitation."
    ],
    "existing_theory": {
        "likely_classification": "closely-related-to-existing",
        "references": [
            "Kuhn (1962) The Structure of Scientific Revolutions [Discusses normal science vs revolutionary science, relevant to incremental vs transformational distinction]",
            "Merton (1961) Singletons and Multiples in Scientific Discovery [Discusses independent rediscovery and simultaneous discovery in science]",
            "Langley et al. (1987) Scientific Discovery: Computational Explorations [Discusses rediscovery in computational systems and its role in validation]",
            "Simon (1977) Models of Discovery [Discusses the role of rediscovery in understanding discovery processes]",
            "Kulkarni & Simon (1988) The Processes of Scientific Discovery: The Strategy of Experimentation [Discusses KEKADA's rediscovery of Krebs cycle as validation]"
        ]
    },
    "theory_type_general_specific": "specific",
    "reflected_from_theory_index": 6,
    "type": "specific"
}</code></pre>
        </div>
    </div>
</body>
</html>