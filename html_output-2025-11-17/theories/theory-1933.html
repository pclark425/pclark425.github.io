<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Information Structure Mediation Theory - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-1933</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-1933</p>
                <p><strong>Name:</strong> Information Structure Mediation Theory</p>
                <p><strong>Type:</strong> general</p>
                <p><strong>Theory Query:</strong> Build a theory of how problem presentation format affects LLM performance.</p>
                <p><strong>Description:</strong> This theory proposes that the structure and explicitness of information in problem presentation format mediates the LLM's ability to parse, represent, and reason over the problem, thereby affecting performance. Formats that make relevant information salient, reduce irrelevant detail, and provide clear logical or temporal structure enable more effective internal representation and reasoning by the LLM.</p>
                <p><strong>Knowledge Cutoff Year:</strong> -1</p>
                <p><strong>Knowledge Cutoff Month:</strong> -1</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <h3>Statement 0: Salience-Driven Reasoning Law (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; problem_presentation_format &#8594; increases &#8594; salience_of_relevant_information</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; LLM_performance &#8594; is_increased &#8594; on_problem</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Highlighting or reordering key information in prompts improves LLM accuracy. </li>
    <li>Irrelevant or distracting details in prompts reduce LLM performance. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> This law is somewhat related to existing prompt engineering work but formalizes the salience principle.</p>            <p><strong>What Already Exists:</strong> Prompt engineering often involves emphasizing relevant details.</p>            <p><strong>What is Novel:</strong> The law formalizes the effect as a conditional relationship between information salience and LLM performance.</p>
            <p><strong>References:</strong> <ul>
    <li>Liu et al. (2023) Evaluating the Impact of Prompt Engineering on LLM Performance [Salience and relevance in prompts]</li>
</ul>
            <h3>Statement 1: Explicit Structure Facilitation Law (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; problem_presentation_format &#8594; provides &#8594; explicit_logical_or_temporal_structure</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; LLM_internal_representation &#8594; is_more_effective &#8594; for_reasoning<span style="color: #888888;">, and</span></div>
        <div>&#8226; LLM_performance &#8594; is_increased &#8594; on_problem</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Stepwise, tabular, or bullet-point formats improve LLM reasoning and reduce errors. </li>
    <li>Unstructured or narrative formats can obscure logical relationships, reducing performance. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> This law extends existing findings to a broader principle of explicit structure facilitation.</p>            <p><strong>What Already Exists:</strong> Chain-of-thought and structured prompting are known to improve LLM reasoning.</p>            <p><strong>What is Novel:</strong> The law generalizes the effect to all forms of explicit structure, not just stepwise reasoning.</p>
            <p><strong>References:</strong> <ul>
    <li>Wei et al. (2022) Chain-of-Thought Prompting Elicits Reasoning in Large Language Models [Stepwise structure]</li>
    <li>Liu et al. (2023) Evaluating the Impact of Prompt Engineering on LLM Performance [Explicit structure effects]</li>
</ul>
            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>Presenting a problem in a tabular format will improve LLM performance on data extraction tasks.</li>
                <li>Removing irrelevant details from a prompt will increase LLM accuracy on reasoning tasks.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>Will LLMs benefit from novel explicit structures (e.g., flowcharts) not seen during pretraining?</li>
                <li>Can LLMs learn to internally restructure unstructured prompts for better reasoning if given meta-instructions?</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>If LLMs perform equally well on unstructured and explicitly structured formats, the theory is challenged.</li>
                <li>If increasing irrelevant details does not reduce LLM performance, the theory is falsified.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>Cases where LLMs perform well on highly unstructured or narrative prompts due to emergent reasoning abilities. </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> somewhat-related-to-existing</p>
            <p><strong>Explanation:</strong> The theory synthesizes and extends existing findings into general laws about information structure mediation.</p>
            <p><strong>References:</strong> <ul>
    <li>Wei et al. (2022) Chain-of-Thought Prompting Elicits Reasoning in Large Language Models [Stepwise structure]</li>
    <li>Liu et al. (2023) Evaluating the Impact of Prompt Engineering on LLM Performance [Explicit structure effects]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Information Structure Mediation Theory",
    "theory_description": "This theory proposes that the structure and explicitness of information in problem presentation format mediates the LLM's ability to parse, represent, and reason over the problem, thereby affecting performance. Formats that make relevant information salient, reduce irrelevant detail, and provide clear logical or temporal structure enable more effective internal representation and reasoning by the LLM.",
    "theory_statements": [
        {
            "law": {
                "law_name": "Salience-Driven Reasoning Law",
                "if": [
                    {
                        "subject": "problem_presentation_format",
                        "relation": "increases",
                        "object": "salience_of_relevant_information"
                    }
                ],
                "then": [
                    {
                        "subject": "LLM_performance",
                        "relation": "is_increased",
                        "object": "on_problem"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Highlighting or reordering key information in prompts improves LLM accuracy.",
                        "uuids": []
                    },
                    {
                        "text": "Irrelevant or distracting details in prompts reduce LLM performance.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Prompt engineering often involves emphasizing relevant details.",
                    "what_is_novel": "The law formalizes the effect as a conditional relationship between information salience and LLM performance.",
                    "classification_explanation": "This law is somewhat related to existing prompt engineering work but formalizes the salience principle.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Liu et al. (2023) Evaluating the Impact of Prompt Engineering on LLM Performance [Salience and relevance in prompts]"
                    ]
                }
            }
        },
        {
            "law": {
                "law_name": "Explicit Structure Facilitation Law",
                "if": [
                    {
                        "subject": "problem_presentation_format",
                        "relation": "provides",
                        "object": "explicit_logical_or_temporal_structure"
                    }
                ],
                "then": [
                    {
                        "subject": "LLM_internal_representation",
                        "relation": "is_more_effective",
                        "object": "for_reasoning"
                    },
                    {
                        "subject": "LLM_performance",
                        "relation": "is_increased",
                        "object": "on_problem"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Stepwise, tabular, or bullet-point formats improve LLM reasoning and reduce errors.",
                        "uuids": []
                    },
                    {
                        "text": "Unstructured or narrative formats can obscure logical relationships, reducing performance.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Chain-of-thought and structured prompting are known to improve LLM reasoning.",
                    "what_is_novel": "The law generalizes the effect to all forms of explicit structure, not just stepwise reasoning.",
                    "classification_explanation": "This law extends existing findings to a broader principle of explicit structure facilitation.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Wei et al. (2022) Chain-of-Thought Prompting Elicits Reasoning in Large Language Models [Stepwise structure]",
                        "Liu et al. (2023) Evaluating the Impact of Prompt Engineering on LLM Performance [Explicit structure effects]"
                    ]
                }
            }
        }
    ],
    "new_predictions_likely": [
        "Presenting a problem in a tabular format will improve LLM performance on data extraction tasks.",
        "Removing irrelevant details from a prompt will increase LLM accuracy on reasoning tasks."
    ],
    "new_predictions_unknown": [
        "Will LLMs benefit from novel explicit structures (e.g., flowcharts) not seen during pretraining?",
        "Can LLMs learn to internally restructure unstructured prompts for better reasoning if given meta-instructions?"
    ],
    "negative_experiments": [
        "If LLMs perform equally well on unstructured and explicitly structured formats, the theory is challenged.",
        "If increasing irrelevant details does not reduce LLM performance, the theory is falsified."
    ],
    "unaccounted_for": [
        {
            "text": "Cases where LLMs perform well on highly unstructured or narrative prompts due to emergent reasoning abilities.",
            "uuids": []
        }
    ],
    "conflicting_evidence": [
        {
            "text": "Some LLMs show little improvement with explicit structure on certain tasks, suggesting limits to the effect.",
            "uuids": []
        }
    ],
    "special_cases": [
        "Tasks that are inherently simple may not benefit from additional structure.",
        "LLMs with advanced internal representation capabilities may be less dependent on explicit structure."
    ],
    "existing_theory": {
        "what_already_exists": "Prompt engineering and chain-of-thought prompting are established techniques.",
        "what_is_novel": "The explicit generalization to all forms of explicit structure and information salience is new.",
        "classification_explanation": "The theory synthesizes and extends existing findings into general laws about information structure mediation.",
        "likely_classification": "somewhat-related-to-existing",
        "references": [
            "Wei et al. (2022) Chain-of-Thought Prompting Elicits Reasoning in Large Language Models [Stepwise structure]",
            "Liu et al. (2023) Evaluating the Impact of Prompt Engineering on LLM Performance [Explicit structure effects]"
        ]
    },
    "reflected_from_theory_index": 2,
    "type": "general",
    "version": "built-theory-from-results-single-theory-reflection2-nov14-2025-LLM-BASELINE-no-evidence-without-matched-control-theory-name",
    "theory_query": "Build a theory of how problem presentation format affects LLM performance.",
    "original_theory_id": "theory-655",
    "original_theory_name": "Prompt Formatting Induces Degeneration and Output Validity Collapse",
    "provide_matched_control_thery_name": false,
    "matched_control_theory_name": null,
    "model_str": "openai/gpt-4.1-2025-04-14"
}</code></pre>
        </div>
    </div>
</body>
</html>