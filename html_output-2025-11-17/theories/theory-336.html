<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Commonsense Augmentation Necessity Theory - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-336</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-336</p>
                <p><strong>Name:</strong> Commonsense Augmentation Necessity Theory</p>
                <p><strong>Type:</strong> general</p>
                <p><strong>Theory Query:</strong> Build a theory about optimal curricula for compositional acquisition of commonsense and science procedures in interactive text environments.. Please focus on creating new theories that have not been proposed before in the literature.</p>
                <p><strong>Description:</strong> This theory posits that successful acquisition of complex scientific procedures in interactive text environments requires prior or concurrent augmentation with commonsense knowledge. Specifically, agents that learn scientific procedures without adequate commonsense grounding will exhibit systematic failures in: (1) generalizing procedures to novel contexts that differ in surface features but share underlying commonsense structure, (2) handling implicit preconditions and effects that are assumed by human-written instructions, (3) recovering from unexpected states by reasoning about alternative actions, and (4) composing learned procedures into higher-order tasks that require understanding of how procedures interact. The theory proposes that commonsense knowledge serves as a semantic scaffold that enables agents to: interpret ambiguous instructions by filling in unstated assumptions, infer constraints from context, reason about the applicability of procedures across situations, and understand causal relationships between actions and effects. The necessity of commonsense augmentation increases with: (a) the degree of implicit knowledge assumed in task descriptions, (b) the diversity of contexts in which procedures must be applied, (c) the complexity of compositional reasoning required, and (d) the sparsity of domain-specific training examples. Critically, the theory distinguishes between explicit commonsense augmentation (structured training on commonsense reasoning) and implicit acquisition through large-scale pre-training, arguing that both can provide the necessary grounding but through different mechanisms.</p>
                <p><strong>Knowledge Cutoff Year:</strong> -1</p>
                <p><strong>Knowledge Cutoff Month:</strong> -1</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <ol>
                <li>For any scientific procedure P with implicit assumptions I, the probability of successful acquisition and generalization P(success|training) is a function of both domain-specific training D and commonsense knowledge C, where P(success|D,C) > P(success|D,¬C) when |I| > 0.</li>
                <li>There exists a threshold of commonsense knowledge completeness θ_c for each domain, below which scientific procedure learning exhibits non-linear degradation in generalization performance. This threshold is proportional to the number and complexity of implicit assumptions in the domain.</li>
                <li>The transfer efficiency η of learned procedures to novel contexts is proportional to the overlap between the agent's commonsense knowledge base K_c and the implicit assumptions A_t of the target context: η ∝ |K_c ∩ A_t| / |A_t|.</li>
                <li>Commonsense augmentation must precede or co-occur with scientific procedure training for maximal benefit. Post-hoc augmentation shows diminished benefits (by a factor of 0.3-0.7) due to the formation of brittle, context-specific representations during initial learning.</li>
                <li>The necessity of commonsense augmentation N scales with multiple factors: N ∝ α·L + β·I + γ·D + δ·(1/E), where L is linguistic complexity, I is the number of implicit preconditions, D is context diversity, E is the number of training examples, and α, β, γ, δ are domain-specific constants.</li>
                <li>Agents with commonsense grounding above threshold θ_c can perform zero-shot or few-shot adaptation of scientific procedures to novel scenarios, while those below threshold require O(n²) additional training examples where n is the number of novel implicit assumptions.</li>
                <li>Compositional procedure learning (combining k procedures into complex tasks) requires commonsense reasoning to resolve ambiguities. The success rate without commonsense grounding decreases exponentially with k: P(success) ∝ e^(-λk), where λ depends on the degree of ambiguity.</li>
                <li>Commonsense knowledge can be acquired either through explicit structured training or through implicit learning from large-scale diverse pre-training data. Both routes provide similar benefits when the coverage of relevant commonsense concepts exceeds θ_c.</li>
                <li>The benefit of commonsense augmentation is most pronounced in low-data regimes. As domain-specific training data increases beyond a saturation point S_d, the marginal benefit of commonsense augmentation decreases following a power law.</li>
            </ol>
            <h3>Supporting Evidence</h3>
<ol>
    <li>Interactive text environments like ALFWorld and TextWorld require agents to understand everyday object properties, spatial relationships, and physical causality to successfully complete tasks, even when those tasks involve scientific or specialized procedures. </li>
    <li>Agents that incorporate knowledge graphs or commonsense reasoning modules show improved performance on procedural tasks in text-based games compared to agents without such augmentation. </li>
    <li>Pre-training on commonsense knowledge bases like ATOMIC and ConceptNet improves downstream task performance, particularly on tasks requiring inference about implicit preconditions and effects. </li>
    <li>Language models that combine reasoning traces with action generation (requiring commonsense understanding of action effects) outperform pure action-generation models in interactive environments. </li>
    <li>Embodied AI agents in simulated household environments fail on tasks when they lack commonsense understanding of object affordances and typical action sequences, even when they have been trained on similar tasks. </li>
    <li>Curriculum learning approaches that structure training from simple commonsense tasks to complex domain-specific procedures show improved sample efficiency and transfer compared to flat training regimes. </li>
    <li>Large language models demonstrate that extensive pre-training on diverse text (which implicitly includes commonsense knowledge) enables few-shot learning of procedural tasks, supporting the theory that commonsense grounding facilitates procedure acquisition. </li>
</ol>            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>An agent trained first on commonsense reasoning tasks (physical causality, object properties, spatial reasoning, typical action sequences) will learn a novel chemistry procedure in 30-50% fewer episodes than an agent trained only on chemistry-specific tasks, with the benefit most pronounced when training examples are limited (<100 examples).</li>
                <li>When presented with a novel scientific procedure that shares commonsense elements (e.g., heating, mixing, measuring) with previously learned procedures, agents with commonsense augmentation will achieve >60% success rate on first attempt, compared to <25% for agents without such augmentation.</li>
                <li>Agents with commonsense augmentation will correctly infer implicit safety preconditions (e.g., 'wear protective equipment before handling acids', 'ensure adequate ventilation') without explicit instruction in >70% of cases, while non-augmented agents will fail to infer these in >80% of cases.</li>
                <li>In multi-step scientific procedures, when encountering unexpected states (e.g., a container being full, an ingredient being unavailable), agents with commonsense grounding will generate appropriate alternative actions in >65% of cases, while non-augmented agents will either fail or repeat unsuccessful actions in >75% of cases.</li>
                <li>The performance gap between commonsense-augmented and non-augmented agents will increase with the number of procedure composition steps, following approximately a linear relationship: gap ≈ 0.15k where k is the number of composition steps (for k ≤ 5).</li>
                <li>When task instructions contain ambiguous references (e.g., 'the solution' when multiple solutions are present), commonsense-augmented agents will correctly resolve the reference using contextual cues in >70% of cases, compared to <40% for non-augmented agents.</li>
                <li>Agents with commonsense augmentation will show better sample efficiency across multiple scientific domains (chemistry, biology, physics), with the benefit being consistent (20-40% reduction in required training examples) across domains, supporting the domain-general nature of commonsense knowledge.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>If commonsense augmentation is provided through natural language explanations and reasoning traces rather than structured knowledge bases, it may lead to better generalization due to the flexibility and compositionality of linguistic representations, or it may introduce noise and inconsistency that degrades performance - the net effect and optimal format remain unclear.</li>
                <li>There may exist a 'commonsense saturation point' S_c beyond which additional commonsense training provides no further benefit to scientific procedure learning. Whether S_c is universal across domains or varies significantly, and whether it can be predicted from domain characteristics, is unknown but would have major implications for curriculum design efficiency.</li>
                <li>Adversarial or incorrect commonsense knowledge (e.g., 'water boils at 50°C', 'heavier objects fall faster') might either catastrophically degrade scientific procedure learning by creating false expectations, or be overridden by domain-specific training if the scientific evidence is sufficiently strong. The robustness of commonsense-procedure integration and the conditions under which domain knowledge can override commonsense are unclear.</li>
                <li>Whether commonsense augmentation can compensate for severely limited domain-specific training data (e.g., learning from 5-10 examples with commonsense vs. 500-1000 examples without) could reveal fundamental limits on knowledge transfer and the extent to which commonsense provides a 'prior' for procedure learning.</li>
                <li>The theory predicts benefits for human-designed curricula with explicit commonsense-to-procedure progression, but whether meta-learning or automated curriculum learning approaches could discover optimal orderings and combinations of commonsense and procedural tasks that substantially outperform human intuition is unknown and would have significant implications for scalable curriculum design.</li>
                <li>Whether there are critical periods or ordering constraints in commonsense augmentation (e.g., physical causality must precede object affordances, which must precede action sequencing) or whether commonsense knowledge can be acquired in any order without affecting downstream procedure learning is unclear and would inform curriculum structure.</li>
                <li>The interaction between commonsense augmentation and other curriculum learning principles (e.g., task difficulty progression, diversity of examples, spacing effects) may be synergistic or antagonistic in ways that are currently unpredictable but could dramatically affect optimal curriculum design.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>If agents trained exclusively on scientific procedures with complete, explicit specifications (no implicit assumptions) achieve equal or better generalization to novel contexts compared to commonsense-augmented agents, this would suggest commonsense is only necessary for handling ambiguity and implicit knowledge, not for fundamental learning mechanisms.</li>
                <li>If post-hoc commonsense augmentation (after scientific procedure training) produces equivalent performance to prior or concurrent augmentation across multiple domains and task types, this would challenge the theory's claim about the importance of temporal ordering and the formation of brittle representations.</li>
                <li>If the performance gap between augmented and non-augmented agents disappears or reverses when training data exceeds a moderate threshold (e.g., 500-1000 examples per procedure), this would suggest commonsense augmentation is only beneficial in low-data regimes and not a fundamental necessity.</li>
                <li>If agents can learn to compose complex procedures (3+ steps) without commonsense grounding when given sufficient domain-specific compositional examples, achieving >80% success rates, this would challenge the claim about compositional necessity and suggest composition can be learned as a domain-specific skill.</li>
                <li>If the theory's predicted scaling relationships (between commonsense necessity and task complexity, implicit assumptions, context diversity) fail to hold across multiple diverse domains (e.g., chemistry, cooking, mechanical repair, medical procedures), this would undermine the generality of the theory and suggest domain-specific factors dominate.</li>
                <li>If agents with minimal commonsense knowledge but extensive domain-specific training show equal or better error recovery and adaptation to unexpected states compared to commonsense-augmented agents, this would challenge the claim that commonsense is necessary for flexible reasoning.</li>
                <li>If the threshold θ_c varies so dramatically across domains (e.g., by orders of magnitude) that no consistent pattern emerges, this would suggest the theory lacks predictive power and that domain-specific factors are more important than general commonsense grounding.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>The theory does not specify the precise granularity, structure, or specific types of commonsense knowledge (e.g., physical, social, temporal, causal) that are most critical for different scientific domains, making it difficult to operationalize 'adequate commonsense grounding'. </li>
    <li>The cognitive and computational mechanisms by which commonsense knowledge is integrated with procedural knowledge during learning are not fully specified - whether this occurs through attention mechanisms, memory consolidation, analogical reasoning, or other processes remains unclear. </li>
    <li>Individual differences in how agents represent and utilize commonsense knowledge (e.g., symbolic vs. distributed representations, explicit vs. implicit reasoning) may lead to varying degrees of benefit from augmentation, but the theory does not account for these architectural variations. </li>
    <li>The theory does not address how conflicting information between commonsense knowledge and domain-specific scientific knowledge should be resolved (e.g., when quantum mechanics violates commonsense intuitions about causality), or under what conditions domain knowledge should override commonsense. </li>
    <li>The role of metacognitive knowledge (knowing when to apply commonsense reasoning vs. domain-specific rules) is not addressed, though this may be critical for successful procedure learning in domains where commonsense and scientific knowledge diverge. </li>
    <li>The theory does not account for potential negative transfer effects where commonsense knowledge might interfere with learning procedures that violate everyday intuitions, particularly in advanced scientific domains. </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> new</p>
            <p><strong>Explanation:</strong> No explanation provided.</p>
            <p><strong>References:</strong> <ul>
    <li>Bengio et al. (2009) Curriculum Learning [Establishes general curriculum learning principles but does not specifically address commonsense-to-procedure progression or the necessity of commonsense augmentation]</li>
    <li>Elman (1993) Learning and development in neural networks: the importance of starting small [Early work on curriculum learning focusing on starting with simple tasks, no specific focus on commonsense augmentation]</li>
    <li>Talmor et al. (2020) Teaching Pre-Trained Models with Commonsense Reasoning: A Preliminary KB-Based Approach [Addresses commonsense in pre-trained models but does not propose a necessity theory for procedural acquisition in interactive environments]</li>
    <li>Ammanabrolu et al. (2021) Learning Knowledge Graph-based World Models of Textual Environments [Related work on knowledge graphs for text environments but does not propose the necessity theory or curriculum ordering principles]</li>
    <li>Forbes et al. (2019) Do Neural Language Representations Learn Physical Commonsense? [Investigates commonsense in language models but not in the context of curriculum design for procedure learning]</li>
    <li>Narvekar et al. (2020) Curriculum Learning for Reinforcement Learning Domains: A Framework and Survey [Comprehensive survey of curriculum learning in RL but does not specifically address commonsense augmentation as a necessary prerequisite]</li>
    <li>Bosselut et al. (2019) COMET: Commonsense Transformers for Automatic Knowledge Graph Construction [Develops methods for commonsense knowledge generation but does not propose theories about its necessity for procedure learning]</li>
    <li>Ahn et al. (2022) Do As I Can, Not As I Say: Grounding Language in Robotic Affordances [Addresses grounding and affordances but does not propose a general theory about commonsense necessity in curriculum design]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Commonsense Augmentation Necessity Theory",
    "theory_description": "This theory posits that successful acquisition of complex scientific procedures in interactive text environments requires prior or concurrent augmentation with commonsense knowledge. Specifically, agents that learn scientific procedures without adequate commonsense grounding will exhibit systematic failures in: (1) generalizing procedures to novel contexts that differ in surface features but share underlying commonsense structure, (2) handling implicit preconditions and effects that are assumed by human-written instructions, (3) recovering from unexpected states by reasoning about alternative actions, and (4) composing learned procedures into higher-order tasks that require understanding of how procedures interact. The theory proposes that commonsense knowledge serves as a semantic scaffold that enables agents to: interpret ambiguous instructions by filling in unstated assumptions, infer constraints from context, reason about the applicability of procedures across situations, and understand causal relationships between actions and effects. The necessity of commonsense augmentation increases with: (a) the degree of implicit knowledge assumed in task descriptions, (b) the diversity of contexts in which procedures must be applied, (c) the complexity of compositional reasoning required, and (d) the sparsity of domain-specific training examples. Critically, the theory distinguishes between explicit commonsense augmentation (structured training on commonsense reasoning) and implicit acquisition through large-scale pre-training, arguing that both can provide the necessary grounding but through different mechanisms.",
    "supporting_evidence": [
        {
            "text": "Interactive text environments like ALFWorld and TextWorld require agents to understand everyday object properties, spatial relationships, and physical causality to successfully complete tasks, even when those tasks involve scientific or specialized procedures.",
            "citations": [
                "Shridhar et al. (2020) ALFWorld: Aligning Text and Embodied Environments for Interactive Learning",
                "Côté et al. (2018) TextWorld: A Learning Environment for Text-based Games"
            ]
        },
        {
            "text": "Agents that incorporate knowledge graphs or commonsense reasoning modules show improved performance on procedural tasks in text-based games compared to agents without such augmentation.",
            "citations": [
                "Ammanabrolu & Riedl (2019) Playing Text-Adventure Games with Graph-Based Deep Reinforcement Learning",
                "Ammanabrolu et al. (2021) Learning Knowledge Graph-based World Models of Textual Environments"
            ]
        },
        {
            "text": "Pre-training on commonsense knowledge bases like ATOMIC and ConceptNet improves downstream task performance, particularly on tasks requiring inference about implicit preconditions and effects.",
            "citations": [
                "Bosselut et al. (2019) COMET: Commonsense Transformers for Automatic Knowledge Graph Construction",
                "Malaviya et al. (2020) Commonsense Knowledge Base Completion with Structural and Semantic Context"
            ]
        },
        {
            "text": "Language models that combine reasoning traces with action generation (requiring commonsense understanding of action effects) outperform pure action-generation models in interactive environments.",
            "citations": [
                "Yao et al. (2022) ReAct: Synergizing Reasoning and Acting in Language Models",
                "Huang et al. (2022) Language Models as Zero-Shot Planners"
            ]
        },
        {
            "text": "Embodied AI agents in simulated household environments fail on tasks when they lack commonsense understanding of object affordances and typical action sequences, even when they have been trained on similar tasks.",
            "citations": [
                "Puig et al. (2018) VirtualHome: Simulating Household Activities via Programs",
                "Ahn et al. (2022) Do As I Can, Not As I Say: Grounding Language in Robotic Affordances"
            ]
        },
        {
            "text": "Curriculum learning approaches that structure training from simple commonsense tasks to complex domain-specific procedures show improved sample efficiency and transfer compared to flat training regimes.",
            "citations": [
                "Bengio et al. (2009) Curriculum Learning",
                "Narvekar et al. (2020) Curriculum Learning for Reinforcement Learning Domains: A Framework and Survey"
            ]
        },
        {
            "text": "Large language models demonstrate that extensive pre-training on diverse text (which implicitly includes commonsense knowledge) enables few-shot learning of procedural tasks, supporting the theory that commonsense grounding facilitates procedure acquisition.",
            "citations": [
                "Brown et al. (2020) Language Models are Few-Shot Learners",
                "Wei et al. (2022) Chain-of-Thought Prompting Elicits Reasoning in Large Language Models"
            ]
        }
    ],
    "theory_statements": [
        "For any scientific procedure P with implicit assumptions I, the probability of successful acquisition and generalization P(success|training) is a function of both domain-specific training D and commonsense knowledge C, where P(success|D,C) &gt; P(success|D,¬C) when |I| &gt; 0.",
        "There exists a threshold of commonsense knowledge completeness θ_c for each domain, below which scientific procedure learning exhibits non-linear degradation in generalization performance. This threshold is proportional to the number and complexity of implicit assumptions in the domain.",
        "The transfer efficiency η of learned procedures to novel contexts is proportional to the overlap between the agent's commonsense knowledge base K_c and the implicit assumptions A_t of the target context: η ∝ |K_c ∩ A_t| / |A_t|.",
        "Commonsense augmentation must precede or co-occur with scientific procedure training for maximal benefit. Post-hoc augmentation shows diminished benefits (by a factor of 0.3-0.7) due to the formation of brittle, context-specific representations during initial learning.",
        "The necessity of commonsense augmentation N scales with multiple factors: N ∝ α·L + β·I + γ·D + δ·(1/E), where L is linguistic complexity, I is the number of implicit preconditions, D is context diversity, E is the number of training examples, and α, β, γ, δ are domain-specific constants.",
        "Agents with commonsense grounding above threshold θ_c can perform zero-shot or few-shot adaptation of scientific procedures to novel scenarios, while those below threshold require O(n²) additional training examples where n is the number of novel implicit assumptions.",
        "Compositional procedure learning (combining k procedures into complex tasks) requires commonsense reasoning to resolve ambiguities. The success rate without commonsense grounding decreases exponentially with k: P(success) ∝ e^(-λk), where λ depends on the degree of ambiguity.",
        "Commonsense knowledge can be acquired either through explicit structured training or through implicit learning from large-scale diverse pre-training data. Both routes provide similar benefits when the coverage of relevant commonsense concepts exceeds θ_c.",
        "The benefit of commonsense augmentation is most pronounced in low-data regimes. As domain-specific training data increases beyond a saturation point S_d, the marginal benefit of commonsense augmentation decreases following a power law."
    ],
    "new_predictions_likely": [
        "An agent trained first on commonsense reasoning tasks (physical causality, object properties, spatial reasoning, typical action sequences) will learn a novel chemistry procedure in 30-50% fewer episodes than an agent trained only on chemistry-specific tasks, with the benefit most pronounced when training examples are limited (&lt;100 examples).",
        "When presented with a novel scientific procedure that shares commonsense elements (e.g., heating, mixing, measuring) with previously learned procedures, agents with commonsense augmentation will achieve &gt;60% success rate on first attempt, compared to &lt;25% for agents without such augmentation.",
        "Agents with commonsense augmentation will correctly infer implicit safety preconditions (e.g., 'wear protective equipment before handling acids', 'ensure adequate ventilation') without explicit instruction in &gt;70% of cases, while non-augmented agents will fail to infer these in &gt;80% of cases.",
        "In multi-step scientific procedures, when encountering unexpected states (e.g., a container being full, an ingredient being unavailable), agents with commonsense grounding will generate appropriate alternative actions in &gt;65% of cases, while non-augmented agents will either fail or repeat unsuccessful actions in &gt;75% of cases.",
        "The performance gap between commonsense-augmented and non-augmented agents will increase with the number of procedure composition steps, following approximately a linear relationship: gap ≈ 0.15k where k is the number of composition steps (for k ≤ 5).",
        "When task instructions contain ambiguous references (e.g., 'the solution' when multiple solutions are present), commonsense-augmented agents will correctly resolve the reference using contextual cues in &gt;70% of cases, compared to &lt;40% for non-augmented agents.",
        "Agents with commonsense augmentation will show better sample efficiency across multiple scientific domains (chemistry, biology, physics), with the benefit being consistent (20-40% reduction in required training examples) across domains, supporting the domain-general nature of commonsense knowledge."
    ],
    "new_predictions_unknown": [
        "If commonsense augmentation is provided through natural language explanations and reasoning traces rather than structured knowledge bases, it may lead to better generalization due to the flexibility and compositionality of linguistic representations, or it may introduce noise and inconsistency that degrades performance - the net effect and optimal format remain unclear.",
        "There may exist a 'commonsense saturation point' S_c beyond which additional commonsense training provides no further benefit to scientific procedure learning. Whether S_c is universal across domains or varies significantly, and whether it can be predicted from domain characteristics, is unknown but would have major implications for curriculum design efficiency.",
        "Adversarial or incorrect commonsense knowledge (e.g., 'water boils at 50°C', 'heavier objects fall faster') might either catastrophically degrade scientific procedure learning by creating false expectations, or be overridden by domain-specific training if the scientific evidence is sufficiently strong. The robustness of commonsense-procedure integration and the conditions under which domain knowledge can override commonsense are unclear.",
        "Whether commonsense augmentation can compensate for severely limited domain-specific training data (e.g., learning from 5-10 examples with commonsense vs. 500-1000 examples without) could reveal fundamental limits on knowledge transfer and the extent to which commonsense provides a 'prior' for procedure learning.",
        "The theory predicts benefits for human-designed curricula with explicit commonsense-to-procedure progression, but whether meta-learning or automated curriculum learning approaches could discover optimal orderings and combinations of commonsense and procedural tasks that substantially outperform human intuition is unknown and would have significant implications for scalable curriculum design.",
        "Whether there are critical periods or ordering constraints in commonsense augmentation (e.g., physical causality must precede object affordances, which must precede action sequencing) or whether commonsense knowledge can be acquired in any order without affecting downstream procedure learning is unclear and would inform curriculum structure.",
        "The interaction between commonsense augmentation and other curriculum learning principles (e.g., task difficulty progression, diversity of examples, spacing effects) may be synergistic or antagonistic in ways that are currently unpredictable but could dramatically affect optimal curriculum design."
    ],
    "negative_experiments": [
        "If agents trained exclusively on scientific procedures with complete, explicit specifications (no implicit assumptions) achieve equal or better generalization to novel contexts compared to commonsense-augmented agents, this would suggest commonsense is only necessary for handling ambiguity and implicit knowledge, not for fundamental learning mechanisms.",
        "If post-hoc commonsense augmentation (after scientific procedure training) produces equivalent performance to prior or concurrent augmentation across multiple domains and task types, this would challenge the theory's claim about the importance of temporal ordering and the formation of brittle representations.",
        "If the performance gap between augmented and non-augmented agents disappears or reverses when training data exceeds a moderate threshold (e.g., 500-1000 examples per procedure), this would suggest commonsense augmentation is only beneficial in low-data regimes and not a fundamental necessity.",
        "If agents can learn to compose complex procedures (3+ steps) without commonsense grounding when given sufficient domain-specific compositional examples, achieving &gt;80% success rates, this would challenge the claim about compositional necessity and suggest composition can be learned as a domain-specific skill.",
        "If the theory's predicted scaling relationships (between commonsense necessity and task complexity, implicit assumptions, context diversity) fail to hold across multiple diverse domains (e.g., chemistry, cooking, mechanical repair, medical procedures), this would undermine the generality of the theory and suggest domain-specific factors dominate.",
        "If agents with minimal commonsense knowledge but extensive domain-specific training show equal or better error recovery and adaptation to unexpected states compared to commonsense-augmented agents, this would challenge the claim that commonsense is necessary for flexible reasoning.",
        "If the threshold θ_c varies so dramatically across domains (e.g., by orders of magnitude) that no consistent pattern emerges, this would suggest the theory lacks predictive power and that domain-specific factors are more important than general commonsense grounding."
    ],
    "unaccounted_for": [
        {
            "text": "The theory does not specify the precise granularity, structure, or specific types of commonsense knowledge (e.g., physical, social, temporal, causal) that are most critical for different scientific domains, making it difficult to operationalize 'adequate commonsense grounding'.",
            "citations": []
        },
        {
            "text": "The cognitive and computational mechanisms by which commonsense knowledge is integrated with procedural knowledge during learning are not fully specified - whether this occurs through attention mechanisms, memory consolidation, analogical reasoning, or other processes remains unclear.",
            "citations": []
        },
        {
            "text": "Individual differences in how agents represent and utilize commonsense knowledge (e.g., symbolic vs. distributed representations, explicit vs. implicit reasoning) may lead to varying degrees of benefit from augmentation, but the theory does not account for these architectural variations.",
            "citations": []
        },
        {
            "text": "The theory does not address how conflicting information between commonsense knowledge and domain-specific scientific knowledge should be resolved (e.g., when quantum mechanics violates commonsense intuitions about causality), or under what conditions domain knowledge should override commonsense.",
            "citations": []
        },
        {
            "text": "The role of metacognitive knowledge (knowing when to apply commonsense reasoning vs. domain-specific rules) is not addressed, though this may be critical for successful procedure learning in domains where commonsense and scientific knowledge diverge.",
            "citations": []
        },
        {
            "text": "The theory does not account for potential negative transfer effects where commonsense knowledge might interfere with learning procedures that violate everyday intuitions, particularly in advanced scientific domains.",
            "citations": []
        }
    ],
    "conflicting_evidence": [
        {
            "text": "Some large language models demonstrate strong scientific reasoning and procedural capabilities without explicit commonsense curriculum training, suggesting that scale and pre-training data diversity might substitute for structured commonsense augmentation. However, this may actually support the theory if we consider that these models acquire commonsense knowledge implicitly during pre-training.",
            "citations": [
                "Brown et al. (2020) Language Models are Few-Shot Learners",
                "Lewkowycz et al. (2022) Solving Quantitative Reasoning Problems with Language Models",
                "Chowdhery et al. (2022) PaLM: Scaling Language Modeling with Pathways"
            ]
        },
        {
            "text": "End-to-end reinforcement learning agents in some interactive environments learn effective procedures without explicit commonsense knowledge representation, achieving high performance through trial-and-error learning. This suggests that sufficient exploration and training time might substitute for commonsense grounding, though these agents may lack generalization capabilities.",
            "citations": [
                "Mnih et al. (2015) Human-level control through deep reinforcement learning",
                "Vinyals et al. (2019) Grandmaster level in StarCraft II using multi-agent reinforcement learning"
            ]
        },
        {
            "text": "Some domain-specific models trained only on scientific procedures show strong performance on in-domain tasks, suggesting that for narrow, well-defined domains, commonsense augmentation may not be necessary if sufficient domain-specific data is available.",
            "citations": [
                "Jumper et al. (2021) Highly accurate protein structure prediction with AlphaFold",
                "Schwaller et al. (2019) Molecular Transformer: A Model for Uncertainty-Calibrated Chemical Reaction Prediction"
            ]
        }
    ],
    "special_cases": [
        "In highly formalized scientific domains (e.g., pure mathematics, formal logic, theoretical computer science) where procedures are completely specified through formal notation and context-independent, commonsense augmentation may provide minimal benefit (&lt;10% improvement) as the domain explicitly avoids reliance on implicit knowledge.",
        "For agents with very large model capacity (&gt;100B parameters) and extensive pre-training on diverse text corpora, the benefits of explicit commonsense augmentation may be reduced (by 50-70%) as implicit commonsense knowledge is already captured in the model's parameters, though explicit augmentation may still improve sample efficiency.",
        "In safety-critical domains (e.g., medical procedures, chemical handling, nuclear operations), commonsense augmentation may be necessary but not sufficient - additional safety-specific training, verification, and constraint satisfaction mechanisms are required to ensure reliable performance.",
        "When the interactive environment provides complete, explicit feedback and detailed error messages that explain all implicit assumptions, the necessity of commonsense for error recovery and understanding may be reduced by 40-60%, as the environment compensates for missing commonsense knowledge.",
        "For procedures that contradict commonsense intuitions (e.g., quantum mechanics phenomena, relativistic effects, counterintuitive chemical reactions), commonsense augmentation might initially hinder learning (10-30% performance decrease in early training) before benefits emerge as agents learn to recognize when domain knowledge overrides commonsense.",
        "In domains with very high training data availability (&gt;10,000 diverse examples per procedure), the marginal benefit of commonsense augmentation decreases substantially, following a power law decay, as domain-specific patterns can be learned directly from data.",
        "For agents using purely symbolic reasoning systems (e.g., classical AI planners, logic-based systems), commonsense augmentation through knowledge base integration may be more effective than for neural agents, as symbolic systems can more directly leverage structured commonsense knowledge.",
        "In multi-agent or collaborative settings where agents can query each other or access external knowledge sources, the necessity of individual commonsense augmentation may be reduced as agents can compensate for each other's knowledge gaps."
    ],
    "existing_theory": {
        "likely_classification": "new",
        "references": [
            "Bengio et al. (2009) Curriculum Learning [Establishes general curriculum learning principles but does not specifically address commonsense-to-procedure progression or the necessity of commonsense augmentation]",
            "Elman (1993) Learning and development in neural networks: the importance of starting small [Early work on curriculum learning focusing on starting with simple tasks, no specific focus on commonsense augmentation]",
            "Talmor et al. (2020) Teaching Pre-Trained Models with Commonsense Reasoning: A Preliminary KB-Based Approach [Addresses commonsense in pre-trained models but does not propose a necessity theory for procedural acquisition in interactive environments]",
            "Ammanabrolu et al. (2021) Learning Knowledge Graph-based World Models of Textual Environments [Related work on knowledge graphs for text environments but does not propose the necessity theory or curriculum ordering principles]",
            "Forbes et al. (2019) Do Neural Language Representations Learn Physical Commonsense? [Investigates commonsense in language models but not in the context of curriculum design for procedure learning]",
            "Narvekar et al. (2020) Curriculum Learning for Reinforcement Learning Domains: A Framework and Survey [Comprehensive survey of curriculum learning in RL but does not specifically address commonsense augmentation as a necessary prerequisite]",
            "Bosselut et al. (2019) COMET: Commonsense Transformers for Automatic Knowledge Graph Construction [Develops methods for commonsense knowledge generation but does not propose theories about its necessity for procedure learning]",
            "Ahn et al. (2022) Do As I Can, Not As I Say: Grounding Language in Robotic Affordances [Addresses grounding and affordances but does not propose a general theory about commonsense necessity in curriculum design]"
        ]
    },
    "theory_type_general_specific": "general",
    "reflected_from_theory_index": 0,
    "theory_query": "Build a theory about optimal curricula for compositional acquisition of commonsense and science procedures in interactive text environments.. Please focus on creating new theories that have not been proposed before in the literature.",
    "generation_mode": "llm_baseline_no_evidence",
    "original_theory_id": "theory-173",
    "original_theory_name": "Commonsense Augmentation Necessity Theory",
    "model_str": "claude-sonnet-4-5-20250929"
}</code></pre>
        </div>
    </div>
</body>
</html>