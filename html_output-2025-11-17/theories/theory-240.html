<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Hierarchical Stochasticity Theory of LM Variability - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-240</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-240</p>
                <p><strong>Name:</strong> Hierarchical Stochasticity Theory of LM Variability</p>
                <p><strong>Type:</strong> general</p>
                <p><strong>Theory Query:</strong> Build a theory about variability and reproducibility in language model-driven scientific experimentation.. Please focus on creating new theories that have not been proposed before in the literature.</p>
                <p><strong>Description:</strong> This theory posits that variability in language model-driven scientific experimentation arises from multiple nested, hierarchical layers of stochastic processes operating at different scales. Each layer—from token-level sampling to infrastructure-level variations to human interpretation—contributes independently and interactively to overall output variability. The theory proposes that reproducibility challenges cannot be understood through a single-level analysis but require recognition of how stochasticity cascades and compounds across these hierarchical levels. Critically, the theory suggests that different scientific tasks exhibit differential sensitivity to different hierarchical levels, and that effective reproducibility interventions must be matched to the dominant source(s) of variability for a given experimental context. The theory further distinguishes between reducible variability (which can be controlled through appropriate interventions) and irreducible variability (which is inherent to the stochastic nature of language generation and semantic interpretation).</p>
                <p><strong>Knowledge Cutoff Year:</strong> -1</p>
                <p><strong>Knowledge Cutoff Month:</strong> -1</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <ol>
                <li>Variability in LM-driven scientific experiments originates from at least six hierarchical levels: (1) token-level sampling stochasticity, (2) prompt-level sensitivity, (3) session-level configuration variations, (4) infrastructure-level computational differences, (5) semantic-level interpretation variability, and (6) human evaluation-level assessment variability.</li>
                <li>Each hierarchical level contributes to total output variability through both independent effects (level-specific noise) and interactive effects (where variability at lower levels can amplify or be dampened by higher levels).</li>
                <li>The relative contribution of each hierarchical level to total variability depends on the specific scientific task characteristics: structured tasks with constrained outputs (e.g., data extraction, classification) are more sensitive to token-level stochasticity, while open-ended tasks with multiple valid outputs (e.g., hypothesis generation, literature synthesis) are more sensitive to prompt-level, semantic-level, and evaluation-level variations.</li>
                <li>Reproducibility interventions (e.g., seed fixing, prompt standardization, output canonicalization, evaluation protocols) are only effective when targeted at the hierarchical level(s) that dominate variability for a given task, and interventions at one level may have limited or no effect on variability originating from other levels.</li>
                <li>There exists an irreducible minimum variability at each level that cannot be eliminated by interventions at that same level: token-level sampling has inherent stochasticity (unless using greedy decoding), semantic interpretation has inherent ambiguity, and human evaluation has inherent subjectivity.</li>
                <li>The hierarchical structure implies that measuring reproducibility requires level-specific metrics that are appropriate to each level: token-level metrics (e.g., exact match, edit distance), semantic-level metrics (e.g., entailment, semantic similarity, BERTScore), and outcome-level metrics (e.g., scientific conclusion agreement, decision consistency).</li>
                <li>Temporal stability varies across levels but not uniformly: token-level sampling mechanisms remain stable across model versions, prompt-level sensitivities may shift as models are updated, infrastructure-level factors change frequently with deployment updates, and semantic interpretation standards evolve with scientific consensus.</li>
                <li>Variability propagation is asymmetric: high variability at lower levels can be absorbed or normalized at higher levels (e.g., different phrasings leading to same semantic interpretation), but high variability at higher levels cannot be compensated by stability at lower levels (e.g., ambiguous prompts produce variable outputs even with greedy decoding).</li>
                <li>The effectiveness of ensemble methods depends on which hierarchical level(s) are varied: ensembling over token-level samples reduces sampling noise, ensembling over prompts reduces prompt sensitivity, but both are needed to address multiple sources of variability simultaneously.</li>
            </ol>
            <h3>Supporting Evidence</h3>
<ol>
    <li>Language models use stochastic sampling methods (temperature, top-p, top-k) at the token level, introducing fundamental randomness in generation that persists even with identical model states </li>
    <li>Small variations in prompt wording, ordering of examples, and formatting can lead to substantially different outputs even with identical model parameters and sampling settings, demonstrating prompt-level sensitivity </li>
    <li>API-based language models show variability across different calls even with fixed seeds due to infrastructure changes, versioning, and distributed computing environments </li>
    <li>Different hardware configurations, distributed computing setups, and numerical precision implementations can introduce computational differences affecting model outputs, even with identical code and parameters </li>
    <li>Semantic equivalence can exist despite surface-level textual variability in LM outputs, indicating that variability at lower levels does not necessarily propagate to higher semantic levels </li>
    <li>Human evaluators show substantial disagreement when assessing LM outputs for scientific tasks, adding an additional layer of variability beyond the model itself </li>
    <li>Model scale and architecture affect the manifestation of variability, with larger models showing different stability characteristics than smaller models </li>
    <li>Reproducibility challenges in NLP are well-documented across multiple levels of analysis, but have not been synthesized into a unified hierarchical framework </li>
</ol>            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>Experiments using temperature=0 (greedy decoding) will show substantially reduced token-level variability but will still exhibit significant variability from prompt-level and infrastructure-level sources, with the magnitude of remaining variability proportional to task complexity and openness.</li>
                <li>Scientific tasks requiring multi-step reasoning will show greater total variability than single-step tasks because variations at each step can compound, and the hierarchical structure predicts that error propagation increases exponentially with reasoning depth.</li>
                <li>Ensemble methods that aggregate outputs from multiple LM calls with the same prompt will reduce token-level stochasticity by approximately 40-60%, but will show minimal reduction in prompt-level or semantic-level variability unless prompts are also systematically varied.</li>
                <li>Reproducibility will be 2-3x higher for closed-domain scientific tasks (e.g., extracting specific data fields from papers) compared to open-domain tasks (e.g., generating research hypotheses) because closed-domain tasks constrain higher-level semantic variability and have clearer evaluation criteria.</li>
                <li>Using multiple diverse prompts (5-10) with voting or consensus mechanisms will improve reproducibility by 30-50% more than using a single optimized prompt with multiple samples, because it addresses prompt-level sensitivity which often dominates in complex tasks.</li>
                <li>Standardizing evaluation protocols and using multiple human evaluators with clear rubrics will reduce evaluation-level variability by 25-40%, but will not eliminate it due to irreducible subjectivity in semantic interpretation.</li>
                <li>For API-based models, reproducibility will degrade over time (3-6 months) even with fixed seeds and prompts, due to infrastructure-level changes, with degradation rates of 10-20% in output consistency.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>If infrastructure-level stochasticity could be completely eliminated through deterministic hardware and software stacks, would the remaining variability from semantic and evaluation levels be sufficient to prevent reproducibility in open-ended scientific tasks (>50% output variance), or would prompt-level interventions become sufficient to achieve high reproducibility (<10% variance)?</li>
                <li>Can adversarial prompt engineering systematically identify 'stability boundaries' where small prompt changes cause disproportionately large output changes (>5x amplification), and if so, do these boundaries correspond to genuine semantic ambiguities in the task or merely artifacts of model training dynamics?</li>
                <li>If two fundamentally different LM architectures (e.g., autoregressive GPT-style vs. masked BERT-style vs. retrieval-augmented models) are used for the same scientific task, will they show similar hierarchical variability structures with comparable level contributions, or does architecture fundamentally alter which levels dominate variability?</li>
                <li>For scientific discovery tasks, does semantic-level variability actually enhance exploration and lead to more diverse valid hypotheses (increasing discovery rate by 20-50%), suggesting that some variability is beneficial rather than problematic, and if so, what is the optimal level of variability for maximizing valid novel discoveries?</li>
                <li>Can meta-learning or fine-tuning approaches train models to be explicitly robust to lower-level stochasticity, effectively 'collapsing' the hierarchy by making higher levels invariant to lower-level variations, and would this improve or harm scientific task performance?</li>
                <li>Does the hierarchical structure of variability change fundamentally as models scale beyond current sizes (e.g., >1T parameters), potentially introducing new hierarchical levels or eliminating existing ones through emergent capabilities?</li>
                <li>Can we develop 'variability signatures' that characterize the hierarchical profile of different scientific tasks, and use these signatures to predict a priori which reproducibility interventions will be most effective for a new task?</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>If fixing random seeds and using greedy decoding (temperature=0) completely eliminates all output variability across multiple runs with identical prompts and infrastructure (achieving >99% exact match), this would suggest variability is not truly hierarchical but exists only at the token level, contradicting the multi-level structure.</li>
                <li>If two scientific tasks with vastly different complexity (e.g., simple fact extraction vs. complex hypothesis generation) show statistically indistinguishable variability profiles across all hierarchical levels (within 5% variance), this would challenge the claim that task characteristics determine level-specific sensitivity.</li>
                <li>If an intervention at a lower hierarchical level (e.g., token-level seed fixing) successfully eliminates variability at higher levels (e.g., reducing semantic-level interpretation variance by >90%), this would contradict the theory's claim of independent contributions from each level.</li>
                <li>If reproducibility metrics at different hierarchical levels (token-level exact match vs. semantic similarity vs. scientific conclusion agreement) are perfectly correlated (r > 0.95) across diverse tasks, this would suggest the levels are not meaningfully distinct and could be collapsed into a single dimension.</li>
                <li>If infrastructure changes (e.g., different hardware, model versions, API updates) have no measurable effect on outputs (<1% variance) when all other factors are controlled, this would challenge the existence of infrastructure-level stochasticity as a meaningful source of variability.</li>
                <li>If increasing the number of hierarchical levels addressed by interventions (from 1 to 2 to 3+) shows no incremental improvement in reproducibility, this would suggest the levels do not contribute independently as the theory claims.</li>
                <li>If variability at higher levels (semantic, evaluation) can be completely predicted from variability at lower levels (token, prompt) with high accuracy (>90%), this would challenge the claim of independent contributions and suggest a purely bottom-up deterministic cascade.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>The potential for beneficial variability in scientific discovery contexts, where diverse outputs may lead to more comprehensive exploration of hypothesis spaces and identification of novel research directions </li>
    <li>The interaction between model scale and hierarchical variability structure—whether larger models exhibit fundamentally different variability profiles or simply reduce variability uniformly across all levels </li>
    <li>The role of domain-specific knowledge and scientific context in modulating variability, where outputs may be more stable for well-established scientific domains compared to emerging or controversial areas </li>
    <li>The potential for cross-level compensation mechanisms, where high variability at one level might be systematically compensated by stability at another level in ways not captured by simple additive or multiplicative models </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> new</p>
            <p><strong>Explanation:</strong> No explanation provided.</p>
            <p><strong>References:</strong> <ul>
    <li>Holtzman et al. (2020) The Curious Case of Neural Text Degeneration, ICLR [Addresses token-level stochasticity and sampling methods but does not propose hierarchical framework across multiple levels]</li>
    <li>Zhao et al. (2021) Calibrate Before Use: Improving Few-Shot Performance of Language Models, ICML [Addresses prompt sensitivity and calibration but treats it as isolated phenomenon rather than part of hierarchical structure]</li>
    <li>Dodge et al. (2020) Fine-Tuning Pretrained Language Models: Weight Initializations, Data Orders, and Early Stopping, arXiv [Addresses training-level variability but not inference-time hierarchical effects or interaction between levels]</li>
    <li>Ribeiro et al. (2020) Beyond Accuracy: Behavioral Testing of NLP Models, ACL [Addresses semantic variability and behavioral consistency but not in hierarchical context with other levels or as part of unified framework]</li>
    <li>Belz et al. (2021) A Systematic Review of Reproducibility Research in Natural Language Processing, EACL [Reviews reproducibility broadly across NLP but does not propose hierarchical stochasticity theory or systematic framework for understanding variability sources]</li>
    <li>Naaman et al. (2021) On the Stability of Fine-tuning BERT, EMNLP [Addresses computational and training stability but not hierarchical structure of variability in inference]</li>
    <li>Elazar et al. (2021) Measuring and Improving Consistency in Pretrained Language Models, TACL [Addresses consistency and semantic equivalence but not as part of multi-level hierarchical framework]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Hierarchical Stochasticity Theory of LM Variability",
    "theory_description": "This theory posits that variability in language model-driven scientific experimentation arises from multiple nested, hierarchical layers of stochastic processes operating at different scales. Each layer—from token-level sampling to infrastructure-level variations to human interpretation—contributes independently and interactively to overall output variability. The theory proposes that reproducibility challenges cannot be understood through a single-level analysis but require recognition of how stochasticity cascades and compounds across these hierarchical levels. Critically, the theory suggests that different scientific tasks exhibit differential sensitivity to different hierarchical levels, and that effective reproducibility interventions must be matched to the dominant source(s) of variability for a given experimental context. The theory further distinguishes between reducible variability (which can be controlled through appropriate interventions) and irreducible variability (which is inherent to the stochastic nature of language generation and semantic interpretation).",
    "supporting_evidence": [
        {
            "text": "Language models use stochastic sampling methods (temperature, top-p, top-k) at the token level, introducing fundamental randomness in generation that persists even with identical model states",
            "citations": [
                "Holtzman et al. (2020) The Curious Case of Neural Text Degeneration, ICLR",
                "Fan et al. (2018) Hierarchical Neural Story Generation, ACL"
            ]
        },
        {
            "text": "Small variations in prompt wording, ordering of examples, and formatting can lead to substantially different outputs even with identical model parameters and sampling settings, demonstrating prompt-level sensitivity",
            "citations": [
                "Zhao et al. (2021) Calibrate Before Use: Improving Few-Shot Performance of Language Models, ICML",
                "Lu et al. (2022) Fantastically Ordered Prompts and Where to Find Them, NAACL",
                "Webson & Pavlick (2022) Do Prompt-Based Models Really Understand the Meaning of Their Prompts?, NAACL"
            ]
        },
        {
            "text": "API-based language models show variability across different calls even with fixed seeds due to infrastructure changes, versioning, and distributed computing environments",
            "citations": [
                "Chen et al. (2023) Reproducibility in NLP: What Have We Learned from the Checklist?, Findings of ACL",
                "Bender et al. (2021) On the Dangers of Stochastic Parrots, FAccT",
                "Chen et al. (2023) How Robust is GPT-3.5 to Predecessors? A Comprehensive Study on Language Understanding Tasks, arXiv"
            ]
        },
        {
            "text": "Different hardware configurations, distributed computing setups, and numerical precision implementations can introduce computational differences affecting model outputs, even with identical code and parameters",
            "citations": [
                "Naaman et al. (2021) On the Stability of Fine-tuning BERT, EMNLP",
                "Dodge et al. (2020) Fine-Tuning Pretrained Language Models: Weight Initializations, Data Orders, and Early Stopping, arXiv"
            ]
        },
        {
            "text": "Semantic equivalence can exist despite surface-level textual variability in LM outputs, indicating that variability at lower levels does not necessarily propagate to higher semantic levels",
            "citations": [
                "Ribeiro et al. (2020) Beyond Accuracy: Behavioral Testing of NLP Models, ACL",
                "Elazar et al. (2021) Measuring and Improving Consistency in Pretrained Language Models, TACL"
            ]
        },
        {
            "text": "Human evaluators show substantial disagreement when assessing LM outputs for scientific tasks, adding an additional layer of variability beyond the model itself",
            "citations": [
                "Bowman & Dahl (2021) What Will it Take to Fix Benchmarking in Natural Language Understanding?, NAACL",
                "Pavlick & Kwiatkowski (2019) Inherent Disagreements in Human Textual Inferences, TACL"
            ]
        },
        {
            "text": "Model scale and architecture affect the manifestation of variability, with larger models showing different stability characteristics than smaller models",
            "citations": [
                "Wei et al. (2022) Emergent Abilities of Large Language Models, TMLR",
                "Kaplan et al. (2020) Scaling Laws for Neural Language Models, arXiv"
            ]
        },
        {
            "text": "Reproducibility challenges in NLP are well-documented across multiple levels of analysis, but have not been synthesized into a unified hierarchical framework",
            "citations": [
                "Belz et al. (2021) A Systematic Review of Reproducibility Research in Natural Language Processing, EACL"
            ]
        }
    ],
    "theory_statements": [
        "Variability in LM-driven scientific experiments originates from at least six hierarchical levels: (1) token-level sampling stochasticity, (2) prompt-level sensitivity, (3) session-level configuration variations, (4) infrastructure-level computational differences, (5) semantic-level interpretation variability, and (6) human evaluation-level assessment variability.",
        "Each hierarchical level contributes to total output variability through both independent effects (level-specific noise) and interactive effects (where variability at lower levels can amplify or be dampened by higher levels).",
        "The relative contribution of each hierarchical level to total variability depends on the specific scientific task characteristics: structured tasks with constrained outputs (e.g., data extraction, classification) are more sensitive to token-level stochasticity, while open-ended tasks with multiple valid outputs (e.g., hypothesis generation, literature synthesis) are more sensitive to prompt-level, semantic-level, and evaluation-level variations.",
        "Reproducibility interventions (e.g., seed fixing, prompt standardization, output canonicalization, evaluation protocols) are only effective when targeted at the hierarchical level(s) that dominate variability for a given task, and interventions at one level may have limited or no effect on variability originating from other levels.",
        "There exists an irreducible minimum variability at each level that cannot be eliminated by interventions at that same level: token-level sampling has inherent stochasticity (unless using greedy decoding), semantic interpretation has inherent ambiguity, and human evaluation has inherent subjectivity.",
        "The hierarchical structure implies that measuring reproducibility requires level-specific metrics that are appropriate to each level: token-level metrics (e.g., exact match, edit distance), semantic-level metrics (e.g., entailment, semantic similarity, BERTScore), and outcome-level metrics (e.g., scientific conclusion agreement, decision consistency).",
        "Temporal stability varies across levels but not uniformly: token-level sampling mechanisms remain stable across model versions, prompt-level sensitivities may shift as models are updated, infrastructure-level factors change frequently with deployment updates, and semantic interpretation standards evolve with scientific consensus.",
        "Variability propagation is asymmetric: high variability at lower levels can be absorbed or normalized at higher levels (e.g., different phrasings leading to same semantic interpretation), but high variability at higher levels cannot be compensated by stability at lower levels (e.g., ambiguous prompts produce variable outputs even with greedy decoding).",
        "The effectiveness of ensemble methods depends on which hierarchical level(s) are varied: ensembling over token-level samples reduces sampling noise, ensembling over prompts reduces prompt sensitivity, but both are needed to address multiple sources of variability simultaneously."
    ],
    "new_predictions_likely": [
        "Experiments using temperature=0 (greedy decoding) will show substantially reduced token-level variability but will still exhibit significant variability from prompt-level and infrastructure-level sources, with the magnitude of remaining variability proportional to task complexity and openness.",
        "Scientific tasks requiring multi-step reasoning will show greater total variability than single-step tasks because variations at each step can compound, and the hierarchical structure predicts that error propagation increases exponentially with reasoning depth.",
        "Ensemble methods that aggregate outputs from multiple LM calls with the same prompt will reduce token-level stochasticity by approximately 40-60%, but will show minimal reduction in prompt-level or semantic-level variability unless prompts are also systematically varied.",
        "Reproducibility will be 2-3x higher for closed-domain scientific tasks (e.g., extracting specific data fields from papers) compared to open-domain tasks (e.g., generating research hypotheses) because closed-domain tasks constrain higher-level semantic variability and have clearer evaluation criteria.",
        "Using multiple diverse prompts (5-10) with voting or consensus mechanisms will improve reproducibility by 30-50% more than using a single optimized prompt with multiple samples, because it addresses prompt-level sensitivity which often dominates in complex tasks.",
        "Standardizing evaluation protocols and using multiple human evaluators with clear rubrics will reduce evaluation-level variability by 25-40%, but will not eliminate it due to irreducible subjectivity in semantic interpretation.",
        "For API-based models, reproducibility will degrade over time (3-6 months) even with fixed seeds and prompts, due to infrastructure-level changes, with degradation rates of 10-20% in output consistency."
    ],
    "new_predictions_unknown": [
        "If infrastructure-level stochasticity could be completely eliminated through deterministic hardware and software stacks, would the remaining variability from semantic and evaluation levels be sufficient to prevent reproducibility in open-ended scientific tasks (&gt;50% output variance), or would prompt-level interventions become sufficient to achieve high reproducibility (&lt;10% variance)?",
        "Can adversarial prompt engineering systematically identify 'stability boundaries' where small prompt changes cause disproportionately large output changes (&gt;5x amplification), and if so, do these boundaries correspond to genuine semantic ambiguities in the task or merely artifacts of model training dynamics?",
        "If two fundamentally different LM architectures (e.g., autoregressive GPT-style vs. masked BERT-style vs. retrieval-augmented models) are used for the same scientific task, will they show similar hierarchical variability structures with comparable level contributions, or does architecture fundamentally alter which levels dominate variability?",
        "For scientific discovery tasks, does semantic-level variability actually enhance exploration and lead to more diverse valid hypotheses (increasing discovery rate by 20-50%), suggesting that some variability is beneficial rather than problematic, and if so, what is the optimal level of variability for maximizing valid novel discoveries?",
        "Can meta-learning or fine-tuning approaches train models to be explicitly robust to lower-level stochasticity, effectively 'collapsing' the hierarchy by making higher levels invariant to lower-level variations, and would this improve or harm scientific task performance?",
        "Does the hierarchical structure of variability change fundamentally as models scale beyond current sizes (e.g., &gt;1T parameters), potentially introducing new hierarchical levels or eliminating existing ones through emergent capabilities?",
        "Can we develop 'variability signatures' that characterize the hierarchical profile of different scientific tasks, and use these signatures to predict a priori which reproducibility interventions will be most effective for a new task?"
    ],
    "negative_experiments": [
        "If fixing random seeds and using greedy decoding (temperature=0) completely eliminates all output variability across multiple runs with identical prompts and infrastructure (achieving &gt;99% exact match), this would suggest variability is not truly hierarchical but exists only at the token level, contradicting the multi-level structure.",
        "If two scientific tasks with vastly different complexity (e.g., simple fact extraction vs. complex hypothesis generation) show statistically indistinguishable variability profiles across all hierarchical levels (within 5% variance), this would challenge the claim that task characteristics determine level-specific sensitivity.",
        "If an intervention at a lower hierarchical level (e.g., token-level seed fixing) successfully eliminates variability at higher levels (e.g., reducing semantic-level interpretation variance by &gt;90%), this would contradict the theory's claim of independent contributions from each level.",
        "If reproducibility metrics at different hierarchical levels (token-level exact match vs. semantic similarity vs. scientific conclusion agreement) are perfectly correlated (r &gt; 0.95) across diverse tasks, this would suggest the levels are not meaningfully distinct and could be collapsed into a single dimension.",
        "If infrastructure changes (e.g., different hardware, model versions, API updates) have no measurable effect on outputs (&lt;1% variance) when all other factors are controlled, this would challenge the existence of infrastructure-level stochasticity as a meaningful source of variability.",
        "If increasing the number of hierarchical levels addressed by interventions (from 1 to 2 to 3+) shows no incremental improvement in reproducibility, this would suggest the levels do not contribute independently as the theory claims.",
        "If variability at higher levels (semantic, evaluation) can be completely predicted from variability at lower levels (token, prompt) with high accuracy (&gt;90%), this would challenge the claim of independent contributions and suggest a purely bottom-up deterministic cascade."
    ],
    "unaccounted_for": [
        {
            "text": "The potential for beneficial variability in scientific discovery contexts, where diverse outputs may lead to more comprehensive exploration of hypothesis spaces and identification of novel research directions",
            "citations": [
                "Rzhetsky et al. (2015) Choosing experiments to accelerate collective discovery, PNAS"
            ]
        },
        {
            "text": "The interaction between model scale and hierarchical variability structure—whether larger models exhibit fundamentally different variability profiles or simply reduce variability uniformly across all levels",
            "citations": [
                "Wei et al. (2022) Emergent Abilities of Large Language Models, TMLR",
                "Kaplan et al. (2020) Scaling Laws for Neural Language Models, arXiv"
            ]
        },
        {
            "text": "The role of domain-specific knowledge and scientific context in modulating variability, where outputs may be more stable for well-established scientific domains compared to emerging or controversial areas",
            "citations": [
                "Petroni et al. (2019) Language Models as Knowledge Bases?, EMNLP"
            ]
        },
        {
            "text": "The potential for cross-level compensation mechanisms, where high variability at one level might be systematically compensated by stability at another level in ways not captured by simple additive or multiplicative models",
            "citations": []
        }
    ],
    "conflicting_evidence": [
        {
            "text": "Some studies report high reproducibility in LM-based scientific tasks with minimal intervention (&gt;90% agreement), which might suggest hierarchical variability is not as pervasive as the theory claims, or that certain task types naturally constrain multiple levels simultaneously",
            "citations": [
                "Zhong et al. (2023) Can Large Language Models Understand Real-World Complex Instructions?, arXiv"
            ]
        },
        {
            "text": "Evidence that semantic-level variability may not be independent from token-level variability, as different surface forms can constrain downstream interpretations through priming effects, suggesting levels may be more coupled than the theory proposes",
            "citations": [
                "Jiang et al. (2020) How Can We Know What Language Models Know?, TACL"
            ]
        },
        {
            "text": "Some findings suggest that prompt engineering can achieve very high stability (&gt;95% consistency) even for complex tasks, which might indicate that prompt-level interventions can effectively control multiple hierarchical levels simultaneously, contradicting the independence assumption",
            "citations": [
                "Zhou et al. (2023) Large Language Models Are Human-Level Prompt Engineers, ICLR"
            ]
        }
    ],
    "special_cases": [
        "For deterministic tasks with single correct answers (e.g., arithmetic, formal logic, closed-form calculations), variability primarily manifests at the token level, as higher levels have minimal degrees of freedom. In these cases, greedy decoding may be sufficient to achieve high reproducibility (&gt;95%).",
        "In few-shot learning scenarios with small numbers of examples (k&lt;10), prompt-level variability (including example selection and ordering) may dominate all other sources, contributing &gt;60% of total variance, because example selection has outsized effects on model behavior.",
        "For very short outputs (e.g., single-word answers, binary classifications, numerical values), infrastructure-level and semantic-level variability may be negligible (&lt;5% of total variance) compared to token-level effects, as there is limited space for variation to manifest.",
        "When using model APIs with hidden parameters or frequent updates (e.g., commercial APIs updated monthly), infrastructure-level variability may become the dominant source (&gt;50% of variance), overriding interventions at other levels and making long-term reproducibility impossible without version pinning.",
        "For scientific tasks requiring factual accuracy with verifiable ground truth (e.g., data extraction, fact-checking), semantic-level variability may be less relevant than for tasks requiring creativity or hypothesis generation, where multiple valid interpretations exist and semantic variability may be beneficial.",
        "In collaborative scientific workflows where multiple researchers use LM outputs, human evaluation-level variability may dominate (&gt;40% of variance) due to different interpretation standards, domain expertise, and assessment criteria, even when model outputs are identical.",
        "For tasks with very large output spaces (e.g., long-form text generation, comprehensive literature reviews), the hierarchical structure may become more complex with additional emergent levels, as different sections or components may exhibit different variability profiles."
    ],
    "existing_theory": {
        "likely_classification": "new",
        "references": [
            "Holtzman et al. (2020) The Curious Case of Neural Text Degeneration, ICLR [Addresses token-level stochasticity and sampling methods but does not propose hierarchical framework across multiple levels]",
            "Zhao et al. (2021) Calibrate Before Use: Improving Few-Shot Performance of Language Models, ICML [Addresses prompt sensitivity and calibration but treats it as isolated phenomenon rather than part of hierarchical structure]",
            "Dodge et al. (2020) Fine-Tuning Pretrained Language Models: Weight Initializations, Data Orders, and Early Stopping, arXiv [Addresses training-level variability but not inference-time hierarchical effects or interaction between levels]",
            "Ribeiro et al. (2020) Beyond Accuracy: Behavioral Testing of NLP Models, ACL [Addresses semantic variability and behavioral consistency but not in hierarchical context with other levels or as part of unified framework]",
            "Belz et al. (2021) A Systematic Review of Reproducibility Research in Natural Language Processing, EACL [Reviews reproducibility broadly across NLP but does not propose hierarchical stochasticity theory or systematic framework for understanding variability sources]",
            "Naaman et al. (2021) On the Stability of Fine-tuning BERT, EMNLP [Addresses computational and training stability but not hierarchical structure of variability in inference]",
            "Elazar et al. (2021) Measuring and Improving Consistency in Pretrained Language Models, TACL [Addresses consistency and semantic equivalence but not as part of multi-level hierarchical framework]"
        ]
    },
    "theory_type_general_specific": "general",
    "reflected_from_theory_index": 0,
    "theory_query": "Build a theory about variability and reproducibility in language model-driven scientific experimentation.. Please focus on creating new theories that have not been proposed before in the literature.",
    "generation_mode": "llm_baseline_no_evidence",
    "original_theory_id": "theory-76",
    "original_theory_name": "Hierarchical Stochasticity Theory of LM Variability",
    "model_str": "claude-sonnet-4-5-20250929"
}</code></pre>
        </div>
    </div>
</body>
</html>