<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Semantic Translation and Action Space Projection Theory - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-99</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-99</p>
                <p><strong>Name:</strong> Semantic Translation and Action Space Projection Theory</p>
                <p><strong>Type:</strong> general</p>
                <p><strong>Theory Query:</strong> Build a theory of how agents perform planning with external tools in partially observable text environments, including belief-state updates that incorporate tool outputs and guide shortest-path actions, based on the following results.</p>
                <p><strong>Description:</strong> In partially observable text environments with large combinatorial action spaces, agents can achieve high executability by using external tools to project free-form language model outputs onto admissible environment actions. This projection process (semantic translation) acts as a bridge between the agent's internal planning representation and the environment's execution requirements. The effectiveness depends on: (1) the quality of the translation mechanism (embedding similarity, learned mappings, or code generation), (2) the availability of an enumerable or searchable action space, (3) the ability to incorporate execution feedback for iterative refinement, and (4) the trade-off between executability and semantic correctness. Code generation emerges as a particularly powerful translation mechanism because it provides compositionality, precision, and the ability to leverage external interpreters for validation.</p>
                <p><strong>Knowledge Cutoff Year:</strong> 2024</p>
                <p><strong>Knowledge Cutoff Month:</strong> 12</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <ol>
                <li>Semantic translation mechanisms that map between free-form language and structured action spaces enable agents to leverage the reasoning capabilities of large language models while ensuring executability in constrained environments.</li>
                <li>The effectiveness of semantic translation depends on the quality of the embedding space or mapping function: better semantic similarity metrics lead to better action selection, with code generation providing superior precision compared to embedding-based approaches.</li>
                <li>Autoregressive trajectory correction (feeding back translated actions to condition future generation) improves plan coherence and executability compared to one-shot translation by maintaining consistency with environment constraints.</li>
                <li>Code generation as a translation mechanism provides superior compositionality, precision, and debuggability compared to direct natural language action generation, especially for tasks requiring exact specifications or multi-step reasoning.</li>
                <li>The availability of an enumerable or efficiently searchable action space is a prerequisite for effective semantic translation; in unbounded action spaces, translation becomes intractable without additional structure.</li>
                <li>Iterative refinement using execution feedback (error traces, success signals) significantly improves translation quality, with structured error information (e.g., parsed error traces) being more effective than surface-level feedback.</li>
                <li>There exists a trade-off between executability and semantic correctness: aggressive translation to ensure executability may collapse or modify the intended semantics of the original plan.</li>
                <li>Translation confidence scores and out-of-distribution detection enable agents to identify when translation is unreliable and trigger fallback strategies or request clarification.</li>
            </ol>
            <h3>Supporting Evidence</h3>
<ol>
    <li>Translated LM pipeline using Sentence-BERT embeddings to map LM outputs to admissible actions increases executability from 7-18% to 73-79% in VirtualHome <a href="../results/extraction-result-867.html#e867.1" class="evidence-link">[e867.1]</a> <a href="../results/extraction-result-877.html#e877.0" class="evidence-link">[e877.0]</a> </li>
    <li>CALM (GPT-2) generates candidate actions that are scored by DRRN, achieving 9.4% normalized score vs 13.0% for oracle admissible actions in Jericho games <a href="../results/extraction-result-896.html#e896.1" class="evidence-link">[e896.1]</a> </li>
    <li>LLM agent with symbolic modules uses constrained action sets and module outputs to achieve 88.7% average performance across symbolic tasks <a href="../results/extraction-result-770.html#e770.0" class="evidence-link">[e770.0]</a> </li>
    <li>PAL generates Python programs that are executed by interpreter, achieving 72.0% on GSM8K vs lower performance for pure LM reasoning <a href="../results/extraction-result-888.html#e888.0" class="evidence-link">[e888.0]</a> </li>
    <li>ViperGPT generates Python programs composing vision modules, achieving 72.0% IoU on RefCOCO through code execution <a href="../results/extraction-result-866.html#e866.0" class="evidence-link">[e866.0]</a> </li>
    <li>Code as Policies uses LLMs to generate executable code for robot control, bridging high-level language and low-level actions <a href="../results/extraction-result-884.html#e884.0" class="evidence-link">[e884.0]</a> </li>
    <li>EHRAgent uses code generation with iterative debugging and execution feedback, achieving 71.58% success rate on MIMIC-III with rubber duck debugging improving performance by 16.58 percentage points <a href="../results/extraction-result-799.html#e799.0" class="evidence-link">[e799.0]</a> </li>
    <li>ConAgents uses execution agent to translate plans into executable code, with review agent providing corrections, achieving 79.00% success rate on RestBench-TMDB <a href="../results/extraction-result-800.html#e800.0" class="evidence-link">[e800.0]</a> <a href="../results/extraction-result-800.html#e800.2" class="evidence-link">[e800.2]</a> </li>
    <li>ProAgent's DataAgent uses ReAct-based code generation for complex data processing tasks, enabling workflow composability through structured JSON outputs <a href="../results/extraction-result-787.html#e787.1" class="evidence-link">[e787.1]</a> </li>
    <li>SPC uses grounded code generation for dialogue, leveraging executable code to interpret language and call perceptual functions <a href="../results/extraction-result-830.html#e830.2" class="evidence-link">[e830.2]</a> </li>
    <li>TDQN uses template-based action space with vocabulary filling, achieving 6.1% completion with Jericho handicaps <a href="../results/extraction-result-894.html#e894.1" class="evidence-link">[e894.1]</a> </li>
    <li>BYU'16 Agent uses word2vec affordance vectors to propose verb-noun pairs, achieving 0.79% completion <a href="../results/extraction-result-806.html#e806.1" class="evidence-link">[e806.1]</a> <a href="../results/extraction-result-883.html#e883.0" class="evidence-link">[e883.0]</a> </li>
    <li>Golovin uses command-pattern templates and word2vec synonyms to generate actions, achieving 1.45% completion <a href="../results/extraction-result-883.html#e883.1" class="evidence-link">[e883.1]</a> </li>
    <li>NAIL uses modular architecture with LM-based scoring for verb-object interactions and validity detector, achieving 2.56% completion <a href="../results/extraction-result-883.html#e883.3" class="evidence-link">[e883.3]</a> </li>
    <li>Jericho admissible-action handicap provides enumerated valid actions, enabling DRRN to achieve 13.0% vs 9.4% without oracle <a href="../results/extraction-result-896.html#e896.3" class="evidence-link">[e896.3]</a> </li>
    <li>Inner Monologue uses closed-loop feedback from success detectors and scene descriptors to refine LLM plans, improving recovery from failures <a href="../results/extraction-result-875.html#e875.0" class="evidence-link">[e875.0]</a> <a href="../results/extraction-result-875.html#e875.1" class="evidence-link">[e875.1]</a> </li>
    <li>KNOWNO uses LLM with conformal prediction to produce calibrated action sets, achieving 0.76 plan success with average prediction set size 1.72 <a href="../results/extraction-result-876.html#e876.0" class="evidence-link">[e876.0]</a> </li>
    <li>Autoregressive trajectory correction (feeding back translated actions) improves plan coherence in Translated LM pipeline <a href="../results/extraction-result-867.html#e867.1" class="evidence-link">[e867.1]</a> <a href="../results/extraction-result-877.html#e877.0" class="evidence-link">[e877.0]</a> </li>
</ol>            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>An agent using a learned translation model (fine-tuned on environment-specific action mappings) will outperform an agent using generic embedding similarity for semantic translation, especially in domains with specialized action vocabularies.</li>
                <li>Combining multiple translation mechanisms (e.g., embedding similarity + learned classifier + rule-based filters) in an ensemble will be more robust than any single mechanism, particularly when different mechanisms have complementary failure modes.</li>
                <li>Agents that use translation confidence scores to detect out-of-distribution actions and request clarification or fallback strategies will be more reliable than agents that always execute the highest-scoring translation.</li>
                <li>Code generation with access to execution feedback will outperform code generation without feedback on tasks requiring iterative refinement or error correction.</li>
                <li>Translation mechanisms that maintain structured intermediate representations (e.g., abstract syntax trees, typed variables) will be more robust to compositional generalization than those operating purely on text.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>Whether semantic translation can be made sample-efficient enough to work in environments where the action space is not fully enumerable but must be discovered through interaction, potentially requiring online learning of translation mappings.</li>
                <li>Whether end-to-end learned translation (without explicit embedding spaces or code generation) can match the performance of modular translation pipelines while being more adaptable to new environments and requiring less engineering.</li>
                <li>Whether semantic translation mechanisms can handle hierarchical or compositional action spaces as effectively as flat action spaces, particularly when actions have complex preconditions or temporal dependencies.</li>
                <li>Whether multi-modal translation (combining vision, language, and structured representations) can achieve better grounding than language-only translation in embodied environments.</li>
                <li>Whether translation mechanisms can be made robust enough to handle adversarial or out-of-distribution inputs without catastrophic failures.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>Demonstrating that direct action generation (without translation) performs as well as translation-based approaches when both use the same model capacity would challenge the theory's core premise.</li>
                <li>Showing that random action selection from the admissible set performs comparably to semantically-translated actions would question the value of semantic similarity and suggest the action space is too constrained.</li>
                <li>Finding that translation mechanisms fail to improve executability in environments with well-structured action spaces would challenge the theory's scope and suggest the overhead is not justified.</li>
                <li>Demonstrating that translation mechanisms consistently produce semantically incorrect actions despite high executability would challenge the utility of the approach for real-world applications.</li>
                <li>Showing that simple rule-based translation outperforms learned or embedding-based translation across diverse environments would question the need for sophisticated translation mechanisms.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>How to handle action spaces that are partially enumerable or have complex compositional structure where full enumeration is intractable </li>
    <li>The trade-offs between translation accuracy and computational cost for different translation mechanisms, particularly for real-time applications </li>
    <li>How to adapt translation mechanisms online as the agent discovers new actions or action patterns through interaction </li>
    <li>The role of human feedback or demonstrations in improving translation quality and how to incorporate such feedback efficiently </li>
    <li>How translation mechanisms interact with exploration strategies and whether they bias exploration in beneficial or harmful ways </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> closely-related-to-existing</p>
            <p><strong>Explanation:</strong> No explanation provided.</p>
            <p><strong>References:</strong> <ul>
    <li>Huang et al. (2022) Language Models as Zero-Shot Planners: Extracting Actionable Knowledge for Embodied Agents [Semantic translation framework using embedding similarity and autoregressive trajectory correction]</li>
    <li>Yao et al. (2020) Keep CALM and Explore: Language Models for Action Generation in Text-based Games [CALM action generation using LM-generated candidates]</li>
    <li>Liang et al. (2022) Code as Policies: Language Model Programs for Embodied Control [Code generation as action translation mechanism]</li>
    <li>Gao et al. (2022) PAL: Program-aided Language Models [Program generation for reasoning with external execution]</li>
    <li>Surís et al. (2023) ViperGPT: Visual Inference via Python Execution for Reasoning [Code generation composing external modules]</li>
    <li>Liu et al. (2024) EHRAgent: Code Empowers Large Language Models for Few-shot Complex Tabular Reasoning [Code generation with iterative debugging and execution feedback]</li>
    <li>Zeng et al. (2024) Learning to Use Tools via Cooperative and Interactive Agents [Multi-agent code generation and review for tool use]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Semantic Translation and Action Space Projection Theory",
    "theory_description": "In partially observable text environments with large combinatorial action spaces, agents can achieve high executability by using external tools to project free-form language model outputs onto admissible environment actions. This projection process (semantic translation) acts as a bridge between the agent's internal planning representation and the environment's execution requirements. The effectiveness depends on: (1) the quality of the translation mechanism (embedding similarity, learned mappings, or code generation), (2) the availability of an enumerable or searchable action space, (3) the ability to incorporate execution feedback for iterative refinement, and (4) the trade-off between executability and semantic correctness. Code generation emerges as a particularly powerful translation mechanism because it provides compositionality, precision, and the ability to leverage external interpreters for validation.",
    "supporting_evidence": [
        {
            "text": "Translated LM pipeline using Sentence-BERT embeddings to map LM outputs to admissible actions increases executability from 7-18% to 73-79% in VirtualHome",
            "uuids": [
                "e867.1",
                "e877.0"
            ]
        },
        {
            "text": "CALM (GPT-2) generates candidate actions that are scored by DRRN, achieving 9.4% normalized score vs 13.0% for oracle admissible actions in Jericho games",
            "uuids": [
                "e896.1"
            ]
        },
        {
            "text": "LLM agent with symbolic modules uses constrained action sets and module outputs to achieve 88.7% average performance across symbolic tasks",
            "uuids": [
                "e770.0"
            ]
        },
        {
            "text": "PAL generates Python programs that are executed by interpreter, achieving 72.0% on GSM8K vs lower performance for pure LM reasoning",
            "uuids": [
                "e888.0"
            ]
        },
        {
            "text": "ViperGPT generates Python programs composing vision modules, achieving 72.0% IoU on RefCOCO through code execution",
            "uuids": [
                "e866.0"
            ]
        },
        {
            "text": "Code as Policies uses LLMs to generate executable code for robot control, bridging high-level language and low-level actions",
            "uuids": [
                "e884.0"
            ]
        },
        {
            "text": "EHRAgent uses code generation with iterative debugging and execution feedback, achieving 71.58% success rate on MIMIC-III with rubber duck debugging improving performance by 16.58 percentage points",
            "uuids": [
                "e799.0"
            ]
        },
        {
            "text": "ConAgents uses execution agent to translate plans into executable code, with review agent providing corrections, achieving 79.00% success rate on RestBench-TMDB",
            "uuids": [
                "e800.0",
                "e800.2"
            ]
        },
        {
            "text": "ProAgent's DataAgent uses ReAct-based code generation for complex data processing tasks, enabling workflow composability through structured JSON outputs",
            "uuids": [
                "e787.1"
            ]
        },
        {
            "text": "SPC uses grounded code generation for dialogue, leveraging executable code to interpret language and call perceptual functions",
            "uuids": [
                "e830.2"
            ]
        },
        {
            "text": "TDQN uses template-based action space with vocabulary filling, achieving 6.1% completion with Jericho handicaps",
            "uuids": [
                "e894.1"
            ]
        },
        {
            "text": "BYU'16 Agent uses word2vec affordance vectors to propose verb-noun pairs, achieving 0.79% completion",
            "uuids": [
                "e806.1",
                "e883.0"
            ]
        },
        {
            "text": "Golovin uses command-pattern templates and word2vec synonyms to generate actions, achieving 1.45% completion",
            "uuids": [
                "e883.1"
            ]
        },
        {
            "text": "NAIL uses modular architecture with LM-based scoring for verb-object interactions and validity detector, achieving 2.56% completion",
            "uuids": [
                "e883.3"
            ]
        },
        {
            "text": "Jericho admissible-action handicap provides enumerated valid actions, enabling DRRN to achieve 13.0% vs 9.4% without oracle",
            "uuids": [
                "e896.3"
            ]
        },
        {
            "text": "Inner Monologue uses closed-loop feedback from success detectors and scene descriptors to refine LLM plans, improving recovery from failures",
            "uuids": [
                "e875.0",
                "e875.1"
            ]
        },
        {
            "text": "KNOWNO uses LLM with conformal prediction to produce calibrated action sets, achieving 0.76 plan success with average prediction set size 1.72",
            "uuids": [
                "e876.0"
            ]
        },
        {
            "text": "Autoregressive trajectory correction (feeding back translated actions) improves plan coherence in Translated LM pipeline",
            "uuids": [
                "e867.1",
                "e877.0"
            ]
        }
    ],
    "theory_statements": [
        "Semantic translation mechanisms that map between free-form language and structured action spaces enable agents to leverage the reasoning capabilities of large language models while ensuring executability in constrained environments.",
        "The effectiveness of semantic translation depends on the quality of the embedding space or mapping function: better semantic similarity metrics lead to better action selection, with code generation providing superior precision compared to embedding-based approaches.",
        "Autoregressive trajectory correction (feeding back translated actions to condition future generation) improves plan coherence and executability compared to one-shot translation by maintaining consistency with environment constraints.",
        "Code generation as a translation mechanism provides superior compositionality, precision, and debuggability compared to direct natural language action generation, especially for tasks requiring exact specifications or multi-step reasoning.",
        "The availability of an enumerable or efficiently searchable action space is a prerequisite for effective semantic translation; in unbounded action spaces, translation becomes intractable without additional structure.",
        "Iterative refinement using execution feedback (error traces, success signals) significantly improves translation quality, with structured error information (e.g., parsed error traces) being more effective than surface-level feedback.",
        "There exists a trade-off between executability and semantic correctness: aggressive translation to ensure executability may collapse or modify the intended semantics of the original plan.",
        "Translation confidence scores and out-of-distribution detection enable agents to identify when translation is unreliable and trigger fallback strategies or request clarification."
    ],
    "new_predictions_likely": [
        "An agent using a learned translation model (fine-tuned on environment-specific action mappings) will outperform an agent using generic embedding similarity for semantic translation, especially in domains with specialized action vocabularies.",
        "Combining multiple translation mechanisms (e.g., embedding similarity + learned classifier + rule-based filters) in an ensemble will be more robust than any single mechanism, particularly when different mechanisms have complementary failure modes.",
        "Agents that use translation confidence scores to detect out-of-distribution actions and request clarification or fallback strategies will be more reliable than agents that always execute the highest-scoring translation.",
        "Code generation with access to execution feedback will outperform code generation without feedback on tasks requiring iterative refinement or error correction.",
        "Translation mechanisms that maintain structured intermediate representations (e.g., abstract syntax trees, typed variables) will be more robust to compositional generalization than those operating purely on text."
    ],
    "new_predictions_unknown": [
        "Whether semantic translation can be made sample-efficient enough to work in environments where the action space is not fully enumerable but must be discovered through interaction, potentially requiring online learning of translation mappings.",
        "Whether end-to-end learned translation (without explicit embedding spaces or code generation) can match the performance of modular translation pipelines while being more adaptable to new environments and requiring less engineering.",
        "Whether semantic translation mechanisms can handle hierarchical or compositional action spaces as effectively as flat action spaces, particularly when actions have complex preconditions or temporal dependencies.",
        "Whether multi-modal translation (combining vision, language, and structured representations) can achieve better grounding than language-only translation in embodied environments.",
        "Whether translation mechanisms can be made robust enough to handle adversarial or out-of-distribution inputs without catastrophic failures."
    ],
    "negative_experiments": [
        "Demonstrating that direct action generation (without translation) performs as well as translation-based approaches when both use the same model capacity would challenge the theory's core premise.",
        "Showing that random action selection from the admissible set performs comparably to semantically-translated actions would question the value of semantic similarity and suggest the action space is too constrained.",
        "Finding that translation mechanisms fail to improve executability in environments with well-structured action spaces would challenge the theory's scope and suggest the overhead is not justified.",
        "Demonstrating that translation mechanisms consistently produce semantically incorrect actions despite high executability would challenge the utility of the approach for real-world applications.",
        "Showing that simple rule-based translation outperforms learned or embedding-based translation across diverse environments would question the need for sophisticated translation mechanisms."
    ],
    "unaccounted_for": [
        {
            "text": "How to handle action spaces that are partially enumerable or have complex compositional structure where full enumeration is intractable",
            "uuids": []
        },
        {
            "text": "The trade-offs between translation accuracy and computational cost for different translation mechanisms, particularly for real-time applications",
            "uuids": []
        },
        {
            "text": "How to adapt translation mechanisms online as the agent discovers new actions or action patterns through interaction",
            "uuids": []
        },
        {
            "text": "The role of human feedback or demonstrations in improving translation quality and how to incorporate such feedback efficiently",
            "uuids": []
        },
        {
            "text": "How translation mechanisms interact with exploration strategies and whether they bias exploration in beneficial or harmful ways",
            "uuids": []
        }
    ],
    "conflicting_evidence": [
        {
            "text": "Some agents (LSTM-DQN, DRRN) learn to generate actions directly without explicit translation and achieve reasonable performance (e.g., LSTM-DQN achieves ~100% quest completion in Home world)",
            "uuids": [
                "e872.0",
                "e894.0"
            ]
        },
        {
            "text": "End-to-end learned policies in some environments (e.g., MAPPO) achieve optimal performance (90 points, 11.0 rounds) without semantic translation",
            "uuids": [
                "e773.3"
            ]
        },
        {
            "text": "Template-based approaches (TDQN) that don't use semantic similarity can work but achieve lower performance (6.1% vs 13.0% for DRRN with oracle)",
            "uuids": [
                "e894.1"
            ]
        },
        {
            "text": "Vanilla LM planners achieve high human-judged correctness (77.86% for GPT-3 175B) despite low executability (7.79%), suggesting translation may sacrifice semantic quality",
            "uuids": [
                "e867.0"
            ]
        },
        {
            "text": "Some environments (e.g., simple TextWorld tasks) can be solved effectively without translation using learned policies, suggesting translation overhead may not always be justified",
            "uuids": [
                "e761.0",
                "e782.0"
            ]
        }
    ],
    "special_cases": [
        "In environments with very small action spaces (e.g., &lt;10 actions), the benefits of semantic translation may be minimal as exhaustive evaluation is feasible and the overhead of translation may not be justified.",
        "When the action space is continuously changing or context-dependent, pre-computed translation mappings may become stale and require online adaptation or dynamic re-computation.",
        "For environments where action syntax is highly constrained (e.g., formal languages like SQL or PDDL), rule-based or grammar-based translation may outperform learned semantic translation due to the need for exact syntactic correctness.",
        "In multi-step translation pipelines (e.g., LM → code → execution → feedback → refinement), the benefits compound but so do the failure modes, requiring careful error handling at each stage.",
        "When translation confidence is low or actions are out-of-distribution, fallback strategies (e.g., requesting clarification, using conservative defaults) become critical for maintaining reliability.",
        "In environments with hierarchical action spaces, translation may need to operate at multiple levels of abstraction, requiring different mechanisms for high-level goals vs low-level primitives.",
        "For real-time applications, the computational cost of translation (especially for code generation and execution) may be prohibitive, requiring trade-offs between translation quality and latency."
    ],
    "existing_theory": {
        "likely_classification": "closely-related-to-existing",
        "references": [
            "Huang et al. (2022) Language Models as Zero-Shot Planners: Extracting Actionable Knowledge for Embodied Agents [Semantic translation framework using embedding similarity and autoregressive trajectory correction]",
            "Yao et al. (2020) Keep CALM and Explore: Language Models for Action Generation in Text-based Games [CALM action generation using LM-generated candidates]",
            "Liang et al. (2022) Code as Policies: Language Model Programs for Embodied Control [Code generation as action translation mechanism]",
            "Gao et al. (2022) PAL: Program-aided Language Models [Program generation for reasoning with external execution]",
            "Surís et al. (2023) ViperGPT: Visual Inference via Python Execution for Reasoning [Code generation composing external modules]",
            "Liu et al. (2024) EHRAgent: Code Empowers Large Language Models for Few-shot Complex Tabular Reasoning [Code generation with iterative debugging and execution feedback]",
            "Zeng et al. (2024) Learning to Use Tools via Cooperative and Interactive Agents [Multi-agent code generation and review for tool use]"
        ]
    },
    "theory_type_general_specific": "general",
    "reflected_from_theory_index": 2,
    "type": "general"
}</code></pre>
        </div>
    </div>
</body>
</html>