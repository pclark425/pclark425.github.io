<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Hierarchical Episodic-Semantic Memory Theory for LLM Agents in Text Games - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-963</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-963</p>
                <p><strong>Name:</strong> Hierarchical Episodic-Semantic Memory Theory for LLM Agents in Text Games</p>
                <p><strong>Type:</strong> general</p>
                <p><strong>Theory Query:</strong> Build a theory of how LLM agents for text games can best use memory to solve text game tasks.</p>
                <p><strong>Description:</strong> This theory posits that LLM agents can best solve text game tasks by maintaining a hierarchical memory system that separates episodic (event-based, context-specific) and semantic (generalized, abstracted) memories, dynamically integrating both to inform action selection and planning. The agent should use episodic memory to track recent and contextually relevant events, while semantic memory encodes general rules, object properties, and world models, with mechanisms for cross-talk and abstraction between the two.</p>
                <p><strong>Knowledge Cutoff Year:</strong> -1</p>
                <p><strong>Knowledge Cutoff Month:</strong> -1</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <h3>Statement 0: Hierarchical Memory Separation (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; LLM agent &#8594; is_solving &#8594; text game task</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; LLM agent &#8594; maintains &#8594; episodic memory (recent events, context)<span style="color: #888888;">, and</span></div>
        <div>&#8226; LLM agent &#8594; maintains &#8594; semantic memory (generalized knowledge, rules)</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Human cognition separates episodic and semantic memory, supporting flexible reasoning and generalization. </li>
    <li>LLM agents with explicit memory modules outperform those without in multi-step reasoning and recall tasks. </li>
    <li>Memory-augmented neural architectures (e.g., Memory Networks, Differentiable Neural Computers) show improved performance on tasks requiring both recall of specific events and generalization. </li>
    <li>Text games often require both remembering specific past actions (episodic) and applying general world knowledge (semantic). </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> While the episodic/semantic distinction is known, its hierarchical, dynamic application to LLM agents in text games is a new synthesis.</p>            <p><strong>What Already Exists:</strong> The separation of episodic and semantic memory is well-established in cognitive neuroscience and has inspired some AI architectures.</p>            <p><strong>What is Novel:</strong> The explicit hierarchical integration and dynamic cross-talk for LLM agents in text games, with mechanisms for abstraction and context-sensitive retrieval, is novel.</p>
            <p><strong>References:</strong> <ul>
    <li>Tulving (1972) Episodic and semantic memory [establishes the distinction in human memory]</li>
    <li>Khandelwal et al. (2019) Generalization through Memorization: Nearest Neighbor Language Models [nearest neighbor memory in LMs]</li>
    <li>Madotto et al. (2020) Memory Grounded Conversational Reasoning [memory-augmented dialogue agents]</li>
</ul>
            <h3>Statement 1: Dynamic Memory Integration for Planning (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; LLM agent &#8594; faces &#8594; multi-step or partially observable text game task<span style="color: #888888;">, and</span></div>
        <div>&#8226; LLM agent &#8594; has &#8594; hierarchical memory (episodic + semantic)</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; LLM agent &#8594; integrates &#8594; episodic and semantic memory to inform action selection and planning<span style="color: #888888;">, and</span></div>
        <div>&#8226; LLM agent &#8594; updates &#8594; semantic memory with abstractions from episodic memory over time</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Agents that combine short-term and long-term memory outperform those with only one type in complex, multi-step environments. </li>
    <li>Human planning relies on both recent experience and generalized knowledge. </li>
    <li>Text games require both recalling recent events (e.g., which doors have been opened) and applying general rules (e.g., keys open doors). </li>
    <li>Hierarchical memory systems in AI (e.g., hierarchical RL) enable abstraction and transfer across tasks. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> The general idea is related to existing work, but the specific hierarchical, dynamic integration for LLM agents in text games is new.</p>            <p><strong>What Already Exists:</strong> Some RL and cognitive architectures use both short-term and long-term memory for planning.</p>            <p><strong>What is Novel:</strong> The explicit, dynamic integration and abstraction mechanism for LLM agents in text games, including updating semantic memory from episodic traces, is novel.</p>
            <p><strong>References:</strong> <ul>
    <li>Botvinick & Toussaint (2012) Planning as inference [integration of memory in planning]</li>
    <li>Mnih et al. (2016) Asynchronous Methods for Deep Reinforcement Learning [use of memory in RL]</li>
    <li>Urbanek et al. (2019) Learning to Speak and Act in a Fantasy Text Adventure Game [LLM agents in text games]</li>
</ul>
            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>LLM agents with explicit, separated episodic and semantic memory modules will outperform agents with only one type of memory on long-horizon text game tasks.</li>
                <li>Agents that periodically abstract and update semantic memory from episodic traces will show improved generalization to novel game scenarios.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>If semantic memory is updated too frequently from episodic traces, agents may overfit to recent experiences and lose generalization.</li>
                <li>Hierarchical memory agents may develop emergent meta-strategies for memory management, such as selective forgetting or prioritization, which could surpass human-like strategies.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>If agents with only episodic or only semantic memory perform equally well as those with hierarchical memory on complex text games, the theory would be challenged.</li>
                <li>If integrating episodic and semantic memory does not improve planning or action selection in multi-step tasks, the theory would be called into question.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>The impact of memory corruption or adversarial memory manipulation on agent performance is not addressed. </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> somewhat-related-to-existing</p>
            <p><strong>Explanation:</strong> The theory synthesizes known memory distinctions with novel, dynamic integration mechanisms for LLM agents in text games.</p>
            <p><strong>References:</strong> <ul>
    <li>Tulving (1972) Episodic and semantic memory [episodic/semantic distinction]</li>
    <li>Khandelwal et al. (2019) Generalization through Memorization: Nearest Neighbor Language Models [memory in LMs]</li>
    <li>Urbanek et al. (2019) Learning to Speak and Act in a Fantasy Text Adventure Game [LLM agents in text games]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Hierarchical Episodic-Semantic Memory Theory for LLM Agents in Text Games",
    "theory_description": "This theory posits that LLM agents can best solve text game tasks by maintaining a hierarchical memory system that separates episodic (event-based, context-specific) and semantic (generalized, abstracted) memories, dynamically integrating both to inform action selection and planning. The agent should use episodic memory to track recent and contextually relevant events, while semantic memory encodes general rules, object properties, and world models, with mechanisms for cross-talk and abstraction between the two.",
    "theory_statements": [
        {
            "law": {
                "law_name": "Hierarchical Memory Separation",
                "if": [
                    {
                        "subject": "LLM agent",
                        "relation": "is_solving",
                        "object": "text game task"
                    }
                ],
                "then": [
                    {
                        "subject": "LLM agent",
                        "relation": "maintains",
                        "object": "episodic memory (recent events, context)"
                    },
                    {
                        "subject": "LLM agent",
                        "relation": "maintains",
                        "object": "semantic memory (generalized knowledge, rules)"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Human cognition separates episodic and semantic memory, supporting flexible reasoning and generalization.",
                        "uuids": []
                    },
                    {
                        "text": "LLM agents with explicit memory modules outperform those without in multi-step reasoning and recall tasks.",
                        "uuids": []
                    },
                    {
                        "text": "Memory-augmented neural architectures (e.g., Memory Networks, Differentiable Neural Computers) show improved performance on tasks requiring both recall of specific events and generalization.",
                        "uuids": []
                    },
                    {
                        "text": "Text games often require both remembering specific past actions (episodic) and applying general world knowledge (semantic).",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "The separation of episodic and semantic memory is well-established in cognitive neuroscience and has inspired some AI architectures.",
                    "what_is_novel": "The explicit hierarchical integration and dynamic cross-talk for LLM agents in text games, with mechanisms for abstraction and context-sensitive retrieval, is novel.",
                    "classification_explanation": "While the episodic/semantic distinction is known, its hierarchical, dynamic application to LLM agents in text games is a new synthesis.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Tulving (1972) Episodic and semantic memory [establishes the distinction in human memory]",
                        "Khandelwal et al. (2019) Generalization through Memorization: Nearest Neighbor Language Models [nearest neighbor memory in LMs]",
                        "Madotto et al. (2020) Memory Grounded Conversational Reasoning [memory-augmented dialogue agents]"
                    ]
                }
            }
        },
        {
            "law": {
                "law_name": "Dynamic Memory Integration for Planning",
                "if": [
                    {
                        "subject": "LLM agent",
                        "relation": "faces",
                        "object": "multi-step or partially observable text game task"
                    },
                    {
                        "subject": "LLM agent",
                        "relation": "has",
                        "object": "hierarchical memory (episodic + semantic)"
                    }
                ],
                "then": [
                    {
                        "subject": "LLM agent",
                        "relation": "integrates",
                        "object": "episodic and semantic memory to inform action selection and planning"
                    },
                    {
                        "subject": "LLM agent",
                        "relation": "updates",
                        "object": "semantic memory with abstractions from episodic memory over time"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Agents that combine short-term and long-term memory outperform those with only one type in complex, multi-step environments.",
                        "uuids": []
                    },
                    {
                        "text": "Human planning relies on both recent experience and generalized knowledge.",
                        "uuids": []
                    },
                    {
                        "text": "Text games require both recalling recent events (e.g., which doors have been opened) and applying general rules (e.g., keys open doors).",
                        "uuids": []
                    },
                    {
                        "text": "Hierarchical memory systems in AI (e.g., hierarchical RL) enable abstraction and transfer across tasks.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Some RL and cognitive architectures use both short-term and long-term memory for planning.",
                    "what_is_novel": "The explicit, dynamic integration and abstraction mechanism for LLM agents in text games, including updating semantic memory from episodic traces, is novel.",
                    "classification_explanation": "The general idea is related to existing work, but the specific hierarchical, dynamic integration for LLM agents in text games is new.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Botvinick & Toussaint (2012) Planning as inference [integration of memory in planning]",
                        "Mnih et al. (2016) Asynchronous Methods for Deep Reinforcement Learning [use of memory in RL]",
                        "Urbanek et al. (2019) Learning to Speak and Act in a Fantasy Text Adventure Game [LLM agents in text games]"
                    ]
                }
            }
        }
    ],
    "new_predictions_likely": [
        "LLM agents with explicit, separated episodic and semantic memory modules will outperform agents with only one type of memory on long-horizon text game tasks.",
        "Agents that periodically abstract and update semantic memory from episodic traces will show improved generalization to novel game scenarios."
    ],
    "new_predictions_unknown": [
        "If semantic memory is updated too frequently from episodic traces, agents may overfit to recent experiences and lose generalization.",
        "Hierarchical memory agents may develop emergent meta-strategies for memory management, such as selective forgetting or prioritization, which could surpass human-like strategies."
    ],
    "negative_experiments": [
        "If agents with only episodic or only semantic memory perform equally well as those with hierarchical memory on complex text games, the theory would be challenged.",
        "If integrating episodic and semantic memory does not improve planning or action selection in multi-step tasks, the theory would be called into question."
    ],
    "unaccounted_for": [
        {
            "text": "The impact of memory corruption or adversarial memory manipulation on agent performance is not addressed.",
            "uuids": []
        }
    ],
    "conflicting_evidence": [
        {
            "text": "Some transformer-based LLMs can solve short text games without explicit memory modules, suggesting implicit memory may suffice in simple cases.",
            "uuids": []
        }
    ],
    "special_cases": [
        "In extremely simple or deterministic text games, explicit memory separation may not provide a benefit.",
        "If the game world is fully observable and static, episodic memory may be redundant."
    ],
    "existing_theory": {
        "what_already_exists": "Episodic/semantic memory distinction and some memory-augmented neural architectures.",
        "what_is_novel": "Hierarchical, dynamic integration and abstraction for LLM agents in text games.",
        "classification_explanation": "The theory synthesizes known memory distinctions with novel, dynamic integration mechanisms for LLM agents in text games.",
        "likely_classification": "somewhat-related-to-existing",
        "references": [
            "Tulving (1972) Episodic and semantic memory [episodic/semantic distinction]",
            "Khandelwal et al. (2019) Generalization through Memorization: Nearest Neighbor Language Models [memory in LMs]",
            "Urbanek et al. (2019) Learning to Speak and Act in a Fantasy Text Adventure Game [LLM agents in text games]"
        ]
    },
    "reflected_from_theory_index": 0,
    "type": "general",
    "version": "built-theory-from-results-single-theory-reflection2-nov14-2025-LLM-BASELINE-no-evidence-without-matched-control-theory-name",
    "theory_query": "Build a theory of how LLM agents for text games can best use memory to solve text game tasks.",
    "original_theory_id": "theory-593",
    "original_theory_name": "Hybrid Memory Architectures Enable Robust Long-Horizon Reasoning and Generalization in LLM Agents for Text Games",
    "provide_matched_control_thery_name": false,
    "matched_control_theory_name": null,
    "model_str": "openai/gpt-4.1-2025-04-14"
}</code></pre>
        </div>
    </div>
</body>
</html>