<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Commonsense Augmentation Necessity Theory - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-173</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-173</p>
                <p><strong>Name:</strong> Commonsense Augmentation Necessity Theory</p>
                <p><strong>Type:</strong> general</p>
                <p><strong>Theory Query:</strong> Build a theory about optimal curricula for compositional acquisition of commonsense and science procedures in interactive text environments, based on the following results.</p>
                <p><strong>Description:</strong> For text-based interactive environments requiring commonsense reasoning about unobserved or typical properties, agents must be augmented with external commonsense knowledge (from knowledge graphs, language models, or demonstrations) to achieve human-level performance efficiently. Pure reinforcement learning from interaction alone cannot efficiently discover commonsense associations that humans acquire through lifetime experience, particularly when relevant information is sparse or absent from observations. The benefit of commonsense augmentation scales with: (1) the sparsity of relevant observations in the environment, (2) the degree to which task success depends on typical rather than environment-specific properties, and (3) the diversity of objects/scenarios requiring commonsense reasoning. However, the method of knowledge provision matters critically - incremental, curriculum-based exposure outperforms full upfront provision by reducing noise and focusing on relevant knowledge.</p>
                <p><strong>Knowledge Cutoff Year:</strong> 2024</p>
                <p><strong>Knowledge Cutoff Month:</strong> 12</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <ol>
                <li>Commonsense knowledge augmentation provides 20-50% absolute performance gains on tasks requiring reasoning about unobserved but typical properties (e.g., object locations, affordances, typical sequences).</li>
                <li>The benefit of commonsense augmentation is largest (approaching necessity) when relevant information is missing from observations or when observations are sparse - agents without augmentation may fail completely rather than merely perform worse.</li>
                <li>Incremental/curriculum-based exposure to commonsense knowledge (e.g., KG Evolve) outperforms full upfront provision by 10-30% by reducing noise and focusing on currently relevant knowledge.</li>
                <li>Different commonsense sources provide complementary benefits: knowledge graphs for structured relations (e.g., HasA, AtLocation), language models for diverse inferences and natural language understanding, and demonstrations for procedural knowledge and action sequences.</li>
                <li>Without commonsense augmentation, agents require 10-100× more environment interactions to discover the same associations, if they discover them at all - some associations may never be discovered through pure exploration.</li>
                <li>The benefit of commonsense augmentation scales with: (1) observation sparsity (larger benefit when information is missing), (2) task dependence on typical vs. environment-specific properties (larger benefit for typical properties), and (3) diversity of objects/scenarios (larger benefit with more diverse requirements).</li>
                <li>Commonsense augmentation is most critical for zero-shot generalization to novel objects/scenarios not seen during training, where pure RL has no basis for inference.</li>
                <li>The optimal granularity of commonsense knowledge depends on the task: fine-grained triples for structured reasoning, natural language for flexible inference, and embeddings for similarity-based retrieval.</li>
            </ol>
            <h3>Supporting Evidence</h3>
<ol>
    <li>KG-A2C augmented with COMET or Q*BERT commonsense inferences successfully completes bathroom tasks in 9:05 where baseline KG-A2C fails entirely (stuck at reward 2), demonstrating necessity for tasks with missing observations. <a href="../results/extraction-result-1504.html#e1504.0" class="evidence-link">[e1504.0]</a> <a href="../results/extraction-result-1504.html#e1504.1" class="evidence-link">[e1504.1]</a> <a href="../results/extraction-result-1504.html#e1504.2" class="evidence-link">[e1504.2]</a> <a href="../results/extraction-result-1504.html#e1504.3" class="evidence-link">[e1504.3]</a> </li>
    <li>Commonsense-augmented agents (KG Evolve) outperform text-only baselines on TWC tasks, taking fewer steps and achieving higher scores on kitchen cleanup and cooking tasks. <a href="../results/extraction-result-1611.html#e1611.0" class="evidence-link">[e1611.0]</a> <a href="../results/extraction-result-1611.html#e1611.2" class="evidence-link">[e1611.2]</a> <a href="../results/extraction-result-1499.html#e1499.1" class="evidence-link">[e1499.1]</a> <a href="../results/extraction-result-1499.html#e1499.0" class="evidence-link">[e1499.0]</a> </li>
    <li>LLM-guided pretraining (ELLM) unlocks ~6 achievements/episode vs <3 for novelty baselines in Crafter, and improves downstream task performance by biasing toward human-meaningful, context-sensitive goals. <a href="../results/extraction-result-1587.html#e1587.0" class="evidence-link">[e1587.0]</a> <a href="../results/extraction-result-1587.html#e1587.1" class="evidence-link">[e1587.1]</a> </li>
    <li>Knowledge graph seeding from walkthroughs improves initial reward and reduces exploration inefficiency in text adventures, with statistically significant improvements (p < 0.05) over baseline KG-DQN. <a href="../results/extraction-result-1609.html#e1609.0" class="evidence-link">[e1609.0]</a> <a href="../results/extraction-result-1609.html#e1609.1" class="evidence-link">[e1609.1]</a> <a href="../results/extraction-result-1609.html#e1609.2" class="evidence-link">[e1609.2]</a> </li>
    <li>GATA with learned belief graphs improves performance by +24.2% average relative improvement over text-only baselines (Tr-DQN) on cooking tasks across difficulty levels. <a href="../results/extraction-result-1566.html#e1566.0" class="evidence-link">[e1566.0]</a> </li>
    <li>LM-computed object-location priors significantly improve static agent performance on TWC hard games vs uniform priors, with benefits saturating after ~10-15 in-context demonstrations. <a href="../results/extraction-result-1485.html#e1485.0" class="evidence-link">[e1485.0]</a> </li>
    <li>STARLING's LLM-generated auxiliary pretraining yields substantial gains on both commonsense (TWC) and science (ScienceWorld) tasks, with faster initial learning and higher scores than vanilla TBRL, despite using only ~200K parameters vs larger LLM baselines. <a href="../results/extraction-result-1482.html#e1482.0" class="evidence-link">[e1482.0]</a> </li>
    <li>Memory Networks with explicit memory and multi-hop retrieval achieve ~100% accuracy on compositional temporal QA while RNN/LSTM baselines fail on long-range questions, demonstrating necessity of structured knowledge representation. <a href="../results/extraction-result-1568.html#e1568.0" class="evidence-link">[e1568.0]</a> </li>
    <li>COMET generates novel commonsense completions with 56.45% human-judged correctness and high novelty (51.20% novel tuples), providing diverse commonsense inferences beyond static knowledge bases. <a href="../results/extraction-result-1586.html#e1586.0" class="evidence-link">[e1586.0]</a> <a href="../results/extraction-result-1586.html#e1586.1" class="evidence-link">[e1586.1]</a> </li>
    <li>Transfer learning using knowledge graphs between games within the same genre improves learning efficiency compared to training from scratch, as reported in KG-transfer work. <a href="../results/extraction-result-1518.html#e1518.4" class="evidence-link">[e1518.4]</a> <a href="../results/extraction-result-1609.html#e1609.2" class="evidence-link">[e1609.2]</a> </li>
    <li>TextWorld Commonsense benchmark explicitly separates training and evaluation objects to require commonsense knowledge for good performance, with agents falling short of human-level especially on hard multi-room multi-object tasks. <a href="../results/extraction-result-1491.html#e1491.1" class="evidence-link">[e1491.1]</a> <a href="../results/extraction-result-1499.html#e1499.0" class="evidence-link">[e1499.0]</a> </li>
    <li>Incremental commonsense exposure (KG Evolve) outperforms full upfront provision (KG Full) on kitchen cleanup by reducing noisy exploration, with higher average scores and fewer interactions. <a href="../results/extraction-result-1611.html#e1611.0" class="evidence-link">[e1611.0]</a> <a href="../results/extraction-result-1611.html#e1611.3" class="evidence-link">[e1611.3]</a> </li>
</ol>            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>Any new text-based domain requiring commonsense reasoning (e.g., social interaction games, medical diagnosis scenarios, household robotics instructions) will show similar 20-50% gains from commonsense augmentation.</li>
                <li>Combining multiple commonsense sources (e.g., ConceptNet + GPT-4 + demonstrations) will provide additive benefits of 5-15% over single sources, with diminishing returns after 3-4 sources.</li>
                <li>Commonsense augmentation will be most critical for zero-shot generalization to novel objects/scenarios not seen during training, with benefits exceeding 50% in such cases.</li>
                <li>Tasks with higher observation sparsity (e.g., partial observability, missing entity mentions) will show larger benefits from commonsense augmentation, potentially exceeding 100% relative improvement.</li>
                <li>Incremental commonsense exposure curricula will consistently outperform full upfront provision across diverse domains by 10-30%, with larger benefits in domains with more complex knowledge structures.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>Whether there exists a saturation point where additional commonsense knowledge provides diminishing returns, or if benefits scale indefinitely with knowledge coverage - current evidence suggests saturation around 10-15 demonstrations for LM priors but unclear for other sources.</li>
                <li>Whether agents can learn to selectively query commonsense sources only when needed (meta-learning when to use commonsense), reducing computational overhead while maintaining benefits - no current evidence on this capability.</li>
                <li>Whether commonsense augmentation can fully substitute for human demonstrations, or if some procedural knowledge requires interactive learning - current evidence suggests complementary benefits but unclear if one can fully replace the other.</li>
                <li>Whether the benefits of commonsense augmentation persist or diminish with very long training times (millions of episodes) - current evidence shows benefits with typical training budgets but unclear if pure RL could eventually match with unlimited training.</li>
                <li>Whether commonsense augmentation helps or hurts in adversarial or deceptive environments where typical properties are intentionally violated - no current evidence on this boundary condition.</li>
                <li>Whether the optimal method of commonsense integration (graph-based, attention-based, prompt-based) depends on the specific task structure or if one method dominates across all tasks.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>Finding domains where pure RL matches commonsense-augmented performance within reasonable training budgets would challenge the necessity claim and suggest the theory only applies to specific task types.</li>
                <li>Demonstrating that commonsense augmentation hurts performance in some settings (e.g., when commonsense conflicts with environment-specific rules) would reveal important boundary conditions and limitations.</li>
                <li>Showing that the benefits of commonsense augmentation disappear with sufficient training time (e.g., 10-100× longer training) would suggest it only affects sample efficiency, not ultimate capability.</li>
                <li>Finding tasks where incremental commonsense exposure performs worse than full upfront provision would challenge the curriculum-based exposure principle.</li>
                <li>Demonstrating that combining multiple commonsense sources provides no additional benefit over a single source would challenge the complementary benefits claim.</li>
                <li>Finding cases where commonsense augmentation enables learning of incorrect behaviors (negative transfer) would reveal important failure modes.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>The optimal granularity and format for commonsense knowledge representation (triples vs. natural language vs. embeddings) likely depends on task structure, but no systematic comparison exists. <a href="../results/extraction-result-1611.html#e1611.0" class="evidence-link">[e1611.0]</a> <a href="../results/extraction-result-1504.html#e1504.3" class="evidence-link">[e1504.3]</a> <a href="../results/extraction-result-1586.html#e1586.0" class="evidence-link">[e1586.0]</a> </li>
    <li>How to automatically determine which commonsense knowledge is relevant for a given task without manual curation - current approaches use either full graphs or simple heuristics. <a href="../results/extraction-result-1499.html#e1499.1" class="evidence-link">[e1499.1]</a> <a href="../results/extraction-result-1611.html#e1611.0" class="evidence-link">[e1611.0]</a> </li>
    <li>The interaction between commonsense augmentation and other learning enhancements (e.g., curriculum learning, intrinsic motivation, hierarchical RL) - most studies examine commonsense in isolation. <a href="../results/extraction-result-1611.html#e1611.0" class="evidence-link">[e1611.0]</a> <a href="../results/extraction-result-1587.html#e1587.0" class="evidence-link">[e1587.0]</a> </li>
    <li>Whether commonsense augmentation benefits transfer across different modalities (text to vision, vision to text) or if modality-specific commonsense is required. <a href="../results/extraction-result-1530.html#e1530.0" class="evidence-link">[e1530.0]</a> <a href="../results/extraction-result-1530.html#e1530.1" class="evidence-link">[e1530.1]</a> </li>
    <li>The computational cost-benefit tradeoff of different commonsense augmentation methods - some methods (e.g., LLM queries) may be expensive relative to their benefits. <a href="../results/extraction-result-1587.html#e1587.0" class="evidence-link">[e1587.0]</a> <a href="../results/extraction-result-1516.html#e1516.0" class="evidence-link">[e1516.0]</a> </li>
    <li>How commonsense augmentation interacts with different exploration strategies - most studies use standard epsilon-greedy or similar approaches. <a href="../results/extraction-result-1591.html#e1591.0" class="evidence-link">[e1591.0]</a> <a href="../results/extraction-result-1591.html#e1591.2" class="evidence-link">[e1591.2]</a> </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> closely-related-to-existing</p>
            <p><strong>Explanation:</strong> No explanation provided.</p>
            <p><strong>References:</strong> <ul>
    <li>Bosselut et al. (2019) COMET: Commonsense Transformers for Automatic Knowledge Graph Construction [Foundation for commonsense augmentation via LMs, demonstrates feasibility of neural commonsense generation]</li>
    <li>Ammanabrolu & Riedl (2019) Playing Text-Adventure Games with Graph-Based Deep Reinforcement Learning [Early work on KG augmentation for text games, demonstrates benefits of structured knowledge]</li>
    <li>Ammanabrolu & Riedl (2019) Transfer in Deep Reinforcement Learning Using Knowledge Graphs [Demonstrates transfer benefits of KG-based representations across games]</li>
    <li>Murugesan et al. (2020) Text-based RL Agents with Commonsense Knowledge: New Challenges, Environments and Baselines [Directly addresses commonsense augmentation necessity, introduces TWC benchmark]</li>
    <li>Murugesan et al. (2020) Enhancing Text-based Reinforcement Learning Agents with Commonsense Knowledge [Demonstrates incremental vs. full knowledge provision, KG Evolve approach]</li>
    <li>Speer et al. (2017) ConceptNet 5.5: An Open Multilingual Graph of General Knowledge [Foundational commonsense knowledge base used in many augmentation approaches]</li>
    <li>Weston et al. (2014) Memory Networks [Demonstrates necessity of explicit memory structures for compositional reasoning, related to structured knowledge representation]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Commonsense Augmentation Necessity Theory",
    "theory_description": "For text-based interactive environments requiring commonsense reasoning about unobserved or typical properties, agents must be augmented with external commonsense knowledge (from knowledge graphs, language models, or demonstrations) to achieve human-level performance efficiently. Pure reinforcement learning from interaction alone cannot efficiently discover commonsense associations that humans acquire through lifetime experience, particularly when relevant information is sparse or absent from observations. The benefit of commonsense augmentation scales with: (1) the sparsity of relevant observations in the environment, (2) the degree to which task success depends on typical rather than environment-specific properties, and (3) the diversity of objects/scenarios requiring commonsense reasoning. However, the method of knowledge provision matters critically - incremental, curriculum-based exposure outperforms full upfront provision by reducing noise and focusing on relevant knowledge.",
    "supporting_evidence": [
        {
            "text": "KG-A2C augmented with COMET or Q*BERT commonsense inferences successfully completes bathroom tasks in 9:05 where baseline KG-A2C fails entirely (stuck at reward 2), demonstrating necessity for tasks with missing observations.",
            "uuids": [
                "e1504.0",
                "e1504.1",
                "e1504.2",
                "e1504.3"
            ]
        },
        {
            "text": "Commonsense-augmented agents (KG Evolve) outperform text-only baselines on TWC tasks, taking fewer steps and achieving higher scores on kitchen cleanup and cooking tasks.",
            "uuids": [
                "e1611.0",
                "e1611.2",
                "e1499.1",
                "e1499.0"
            ]
        },
        {
            "text": "LLM-guided pretraining (ELLM) unlocks ~6 achievements/episode vs &lt;3 for novelty baselines in Crafter, and improves downstream task performance by biasing toward human-meaningful, context-sensitive goals.",
            "uuids": [
                "e1587.0",
                "e1587.1"
            ]
        },
        {
            "text": "Knowledge graph seeding from walkthroughs improves initial reward and reduces exploration inefficiency in text adventures, with statistically significant improvements (p &lt; 0.05) over baseline KG-DQN.",
            "uuids": [
                "e1609.0",
                "e1609.1",
                "e1609.2"
            ]
        },
        {
            "text": "GATA with learned belief graphs improves performance by +24.2% average relative improvement over text-only baselines (Tr-DQN) on cooking tasks across difficulty levels.",
            "uuids": [
                "e1566.0"
            ]
        },
        {
            "text": "LM-computed object-location priors significantly improve static agent performance on TWC hard games vs uniform priors, with benefits saturating after ~10-15 in-context demonstrations.",
            "uuids": [
                "e1485.0"
            ]
        },
        {
            "text": "STARLING's LLM-generated auxiliary pretraining yields substantial gains on both commonsense (TWC) and science (ScienceWorld) tasks, with faster initial learning and higher scores than vanilla TBRL, despite using only ~200K parameters vs larger LLM baselines.",
            "uuids": [
                "e1482.0"
            ]
        },
        {
            "text": "Memory Networks with explicit memory and multi-hop retrieval achieve ~100% accuracy on compositional temporal QA while RNN/LSTM baselines fail on long-range questions, demonstrating necessity of structured knowledge representation.",
            "uuids": [
                "e1568.0"
            ]
        },
        {
            "text": "COMET generates novel commonsense completions with 56.45% human-judged correctness and high novelty (51.20% novel tuples), providing diverse commonsense inferences beyond static knowledge bases.",
            "uuids": [
                "e1586.0",
                "e1586.1"
            ]
        },
        {
            "text": "Transfer learning using knowledge graphs between games within the same genre improves learning efficiency compared to training from scratch, as reported in KG-transfer work.",
            "uuids": [
                "e1518.4",
                "e1609.2"
            ]
        },
        {
            "text": "TextWorld Commonsense benchmark explicitly separates training and evaluation objects to require commonsense knowledge for good performance, with agents falling short of human-level especially on hard multi-room multi-object tasks.",
            "uuids": [
                "e1491.1",
                "e1499.0"
            ]
        },
        {
            "text": "Incremental commonsense exposure (KG Evolve) outperforms full upfront provision (KG Full) on kitchen cleanup by reducing noisy exploration, with higher average scores and fewer interactions.",
            "uuids": [
                "e1611.0",
                "e1611.3"
            ]
        }
    ],
    "theory_statements": [
        "Commonsense knowledge augmentation provides 20-50% absolute performance gains on tasks requiring reasoning about unobserved but typical properties (e.g., object locations, affordances, typical sequences).",
        "The benefit of commonsense augmentation is largest (approaching necessity) when relevant information is missing from observations or when observations are sparse - agents without augmentation may fail completely rather than merely perform worse.",
        "Incremental/curriculum-based exposure to commonsense knowledge (e.g., KG Evolve) outperforms full upfront provision by 10-30% by reducing noise and focusing on currently relevant knowledge.",
        "Different commonsense sources provide complementary benefits: knowledge graphs for structured relations (e.g., HasA, AtLocation), language models for diverse inferences and natural language understanding, and demonstrations for procedural knowledge and action sequences.",
        "Without commonsense augmentation, agents require 10-100× more environment interactions to discover the same associations, if they discover them at all - some associations may never be discovered through pure exploration.",
        "The benefit of commonsense augmentation scales with: (1) observation sparsity (larger benefit when information is missing), (2) task dependence on typical vs. environment-specific properties (larger benefit for typical properties), and (3) diversity of objects/scenarios (larger benefit with more diverse requirements).",
        "Commonsense augmentation is most critical for zero-shot generalization to novel objects/scenarios not seen during training, where pure RL has no basis for inference.",
        "The optimal granularity of commonsense knowledge depends on the task: fine-grained triples for structured reasoning, natural language for flexible inference, and embeddings for similarity-based retrieval."
    ],
    "new_predictions_likely": [
        "Any new text-based domain requiring commonsense reasoning (e.g., social interaction games, medical diagnosis scenarios, household robotics instructions) will show similar 20-50% gains from commonsense augmentation.",
        "Combining multiple commonsense sources (e.g., ConceptNet + GPT-4 + demonstrations) will provide additive benefits of 5-15% over single sources, with diminishing returns after 3-4 sources.",
        "Commonsense augmentation will be most critical for zero-shot generalization to novel objects/scenarios not seen during training, with benefits exceeding 50% in such cases.",
        "Tasks with higher observation sparsity (e.g., partial observability, missing entity mentions) will show larger benefits from commonsense augmentation, potentially exceeding 100% relative improvement.",
        "Incremental commonsense exposure curricula will consistently outperform full upfront provision across diverse domains by 10-30%, with larger benefits in domains with more complex knowledge structures."
    ],
    "new_predictions_unknown": [
        "Whether there exists a saturation point where additional commonsense knowledge provides diminishing returns, or if benefits scale indefinitely with knowledge coverage - current evidence suggests saturation around 10-15 demonstrations for LM priors but unclear for other sources.",
        "Whether agents can learn to selectively query commonsense sources only when needed (meta-learning when to use commonsense), reducing computational overhead while maintaining benefits - no current evidence on this capability.",
        "Whether commonsense augmentation can fully substitute for human demonstrations, or if some procedural knowledge requires interactive learning - current evidence suggests complementary benefits but unclear if one can fully replace the other.",
        "Whether the benefits of commonsense augmentation persist or diminish with very long training times (millions of episodes) - current evidence shows benefits with typical training budgets but unclear if pure RL could eventually match with unlimited training.",
        "Whether commonsense augmentation helps or hurts in adversarial or deceptive environments where typical properties are intentionally violated - no current evidence on this boundary condition.",
        "Whether the optimal method of commonsense integration (graph-based, attention-based, prompt-based) depends on the specific task structure or if one method dominates across all tasks."
    ],
    "negative_experiments": [
        "Finding domains where pure RL matches commonsense-augmented performance within reasonable training budgets would challenge the necessity claim and suggest the theory only applies to specific task types.",
        "Demonstrating that commonsense augmentation hurts performance in some settings (e.g., when commonsense conflicts with environment-specific rules) would reveal important boundary conditions and limitations.",
        "Showing that the benefits of commonsense augmentation disappear with sufficient training time (e.g., 10-100× longer training) would suggest it only affects sample efficiency, not ultimate capability.",
        "Finding tasks where incremental commonsense exposure performs worse than full upfront provision would challenge the curriculum-based exposure principle.",
        "Demonstrating that combining multiple commonsense sources provides no additional benefit over a single source would challenge the complementary benefits claim.",
        "Finding cases where commonsense augmentation enables learning of incorrect behaviors (negative transfer) would reveal important failure modes."
    ],
    "unaccounted_for": [
        {
            "text": "The optimal granularity and format for commonsense knowledge representation (triples vs. natural language vs. embeddings) likely depends on task structure, but no systematic comparison exists.",
            "uuids": [
                "e1611.0",
                "e1504.3",
                "e1586.0"
            ]
        },
        {
            "text": "How to automatically determine which commonsense knowledge is relevant for a given task without manual curation - current approaches use either full graphs or simple heuristics.",
            "uuids": [
                "e1499.1",
                "e1611.0"
            ]
        },
        {
            "text": "The interaction between commonsense augmentation and other learning enhancements (e.g., curriculum learning, intrinsic motivation, hierarchical RL) - most studies examine commonsense in isolation.",
            "uuids": [
                "e1611.0",
                "e1587.0"
            ]
        },
        {
            "text": "Whether commonsense augmentation benefits transfer across different modalities (text to vision, vision to text) or if modality-specific commonsense is required.",
            "uuids": [
                "e1530.0",
                "e1530.1"
            ]
        },
        {
            "text": "The computational cost-benefit tradeoff of different commonsense augmentation methods - some methods (e.g., LLM queries) may be expensive relative to their benefits.",
            "uuids": [
                "e1587.0",
                "e1516.0"
            ]
        },
        {
            "text": "How commonsense augmentation interacts with different exploration strategies - most studies use standard epsilon-greedy or similar approaches.",
            "uuids": [
                "e1591.0",
                "e1591.2"
            ]
        }
    ],
    "conflicting_evidence": [
        {
            "text": "Full commonsense graphs (KG Full) can sometimes hurt performance vs incremental exposure (KG Evolve) due to noise and overwhelming information, suggesting more is not always better.",
            "uuids": [
                "e1611.0",
                "e1611.3"
            ]
        },
        {
            "text": "In some cooking recipe tasks, ground-truth full belief graphs (GATA Full) outperformed commonsense-based approaches, suggesting task-specific knowledge can be more valuable than general commonsense.",
            "uuids": [
                "e1611.2"
            ]
        },
        {
            "text": "BERT-based policy shaping (KG-A2C-BERT) showed only modest improvements and failed when necessary object mentions were missing, suggesting procedural priors alone cannot substitute for missing entity knowledge.",
            "uuids": [
                "e1504.1"
            ]
        },
        {
            "text": "Reflexion struggled on WebShop despite using self-reflection, showing no improvement after four trials, suggesting commonsense/reflection approaches have limits on tasks requiring broad creative exploration.",
            "uuids": [
                "e1496.3"
            ]
        },
        {
            "text": "COMET with hierarchical meta-tokens showed slightly better automatic metrics but worse human-judged quality compared to regular COMET, suggesting that explicit hierarchical structure doesn't always help.",
            "uuids": [
                "e1586.1"
            ]
        }
    ],
    "special_cases": [
        "For tasks where all relevant information is observable in the environment and task-specific rules dominate over typical properties, commonsense augmentation may provide minimal benefit or even hurt performance.",
        "When commonsense knowledge conflicts with environment-specific rules (e.g., in fantasy or sci-fi settings), agents must learn to override commonsense, which can be difficult and may require explicit mechanisms.",
        "Very large commonsense knowledge bases may require filtering, curriculum-based exposure, or selective retrieval to avoid overwhelming the agent with irrelevant information.",
        "For tasks requiring primarily procedural knowledge (sequences of actions) rather than declarative knowledge (facts about the world), demonstrations may be more effective than commonsense knowledge graphs.",
        "In adversarial or deceptive environments where typical properties are intentionally violated, commonsense augmentation may lead to systematic errors rather than benefits.",
        "The benefit of commonsense augmentation may be smaller for tasks with dense reward signals where pure RL can efficiently discover relevant associations through trial and error.",
        "For very simple tasks or tasks with small state/action spaces, the overhead of commonsense augmentation may outweigh its benefits.",
        "Commonsense augmentation is most beneficial during early training and for zero-shot generalization; with sufficient task-specific training, pure RL may eventually match augmented performance on seen scenarios."
    ],
    "existing_theory": {
        "likely_classification": "closely-related-to-existing",
        "references": [
            "Bosselut et al. (2019) COMET: Commonsense Transformers for Automatic Knowledge Graph Construction [Foundation for commonsense augmentation via LMs, demonstrates feasibility of neural commonsense generation]",
            "Ammanabrolu & Riedl (2019) Playing Text-Adventure Games with Graph-Based Deep Reinforcement Learning [Early work on KG augmentation for text games, demonstrates benefits of structured knowledge]",
            "Ammanabrolu & Riedl (2019) Transfer in Deep Reinforcement Learning Using Knowledge Graphs [Demonstrates transfer benefits of KG-based representations across games]",
            "Murugesan et al. (2020) Text-based RL Agents with Commonsense Knowledge: New Challenges, Environments and Baselines [Directly addresses commonsense augmentation necessity, introduces TWC benchmark]",
            "Murugesan et al. (2020) Enhancing Text-based Reinforcement Learning Agents with Commonsense Knowledge [Demonstrates incremental vs. full knowledge provision, KG Evolve approach]",
            "Speer et al. (2017) ConceptNet 5.5: An Open Multilingual Graph of General Knowledge [Foundational commonsense knowledge base used in many augmentation approaches]",
            "Weston et al. (2014) Memory Networks [Demonstrates necessity of explicit memory structures for compositional reasoning, related to structured knowledge representation]"
        ]
    },
    "theory_type_general_specific": "general",
    "reflected_from_theory_index": 2,
    "type": "general"
}</code></pre>
        </div>
    </div>
</body>
</html>