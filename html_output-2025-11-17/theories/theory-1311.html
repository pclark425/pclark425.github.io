<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Semantic Consistency Law for Graph Linearization in LLMs - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-1311</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-1311</p>
                <p><strong>Name:</strong> Semantic Consistency Law for Graph Linearization in LLMs</p>
                <p><strong>Type:</strong> general</p>
                <p><strong>Theory Query:</strong> Build a theory of ideal representations for converting graphs into text for language model training.</p>
                <p><strong>Description:</strong> This theory asserts that the ideal graph-to-text linearization for LLM training must preserve the full semantic content of the original graph, such that any permutation or reordering of nodes and edges in the linearization does not alter the underlying graph meaning as perceived by the LLM. The theory further posits that semantic consistency across permutations is necessary for LLMs to develop robust, interpretable, and transferable graph reasoning abilities.</p>
                <p><strong>Knowledge Cutoff Year:</strong> -1</p>
                <p><strong>Knowledge Cutoff Month:</strong> -1</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <h3>Statement 0: Semantic Preservation under Permutation Law (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; graph_linearization &#8594; permutes_node_or_edge_order &#8594; arbitrarily<span style="color: #888888;">, and</span></div>
        <div>&#8226; graph_linearization &#8594; preserves_graph_structure &#8594; True</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; LLM &#8594; perceives_semantics &#8594; unchanged</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Graph neural networks and set models are designed to be invariant to input order, preserving semantics. </li>
    <li>Empirical results show that LLMs can be sensitive to order unless representations are explicitly designed to be order-invariant. </li>
    <li>Canonicalization and randomization of graph linearizations are used to ensure semantic consistency in training data. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> closely-related-to-existing</p>
            <p><strong>Explanation:</strong> The law is closely related to existing principles in GNNs but is novel in its explicit application to LLMs and graph-to-text representations.</p>            <p><strong>What Already Exists:</strong> Semantic preservation under permutation is a goal in GNNs and set models.</p>            <p><strong>What is Novel:</strong> This law formalizes the requirement for semantic consistency in LLM-based graph linearization, not just in neural architectures.</p>
            <p><strong>References:</strong> <ul>
    <li>Zaheer et al. (2017) Deep Sets [Permutation invariance in set models]</li>
    <li>Xu et al. (2019) How Powerful are Graph Neural Networks? [Semantic invariance in GNNs]</li>
    <li>Ribeiro et al. (2020) Structural Encoding in Graph-to-Sequence Learning [Graph-to-sequence orderings]</li>
</ul>
            <h3>Statement 1: Transferability through Semantic Consistency Law (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; graph_linearization &#8594; is_semantically_consistent &#8594; across_permutations</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; LLM &#8594; transfers_graph_knowledge &#8594; effectively</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Models trained on semantically consistent representations show improved transfer to new graph domains. </li>
    <li>Semantic consistency is a prerequisite for transfer learning in structured data. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> The law is somewhat related to existing transfer learning principles but is novel in its focus on graph-to-text LLMs.</p>            <p><strong>What Already Exists:</strong> Transfer learning in neural models is known to benefit from consistent representations.</p>            <p><strong>What is Novel:</strong> This law links semantic consistency in graph linearization directly to transferability in LLMs.</p>
            <p><strong>References:</strong> <ul>
    <li>Pan & Yang (2010) A Survey on Transfer Learning [Transfer learning principles]</li>
    <li>Xu et al. (2019) How Powerful are Graph Neural Networks? [Semantic consistency in GNNs]</li>
</ul>
            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>LLMs trained on semantically consistent graph linearizations will transfer more effectively to new graph domains than those trained on inconsistent representations.</li>
                <li>Semantic consistency in graph-to-text representations will reduce the need for domain-specific fine-tuning.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>Semantic consistency may enable LLMs to perform zero-shot reasoning on novel graph types.</li>
                <li>LLMs may develop internal representations of graph motifs that are invariant to input order if trained on semantically consistent data.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>If LLMs trained on semantically consistent representations do not transfer better than those trained on inconsistent ones, the theory would be challenged.</li>
                <li>If semantic consistency does not improve LLM interpretability or robustness, the law would be called into question.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>The effect of semantic consistency on LLMs with limited capacity or context window is not fully explained. </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> somewhat-related-to-existing</p>
            <p><strong>Explanation:</strong> The theory builds on existing principles but applies them in a new context (LLMs and graph-to-text linearization).</p>
            <p><strong>References:</strong> <ul>
    <li>Pan & Yang (2010) A Survey on Transfer Learning [Transfer learning principles]</li>
    <li>Xu et al. (2019) How Powerful are Graph Neural Networks? [Semantic consistency in GNNs]</li>
    <li>Ribeiro et al. (2020) Structural Encoding in Graph-to-Sequence Learning [Graph-to-sequence orderings]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Semantic Consistency Law for Graph Linearization in LLMs",
    "theory_description": "This theory asserts that the ideal graph-to-text linearization for LLM training must preserve the full semantic content of the original graph, such that any permutation or reordering of nodes and edges in the linearization does not alter the underlying graph meaning as perceived by the LLM. The theory further posits that semantic consistency across permutations is necessary for LLMs to develop robust, interpretable, and transferable graph reasoning abilities.",
    "theory_statements": [
        {
            "law": {
                "law_name": "Semantic Preservation under Permutation Law",
                "if": [
                    {
                        "subject": "graph_linearization",
                        "relation": "permutes_node_or_edge_order",
                        "object": "arbitrarily"
                    },
                    {
                        "subject": "graph_linearization",
                        "relation": "preserves_graph_structure",
                        "object": "True"
                    }
                ],
                "then": [
                    {
                        "subject": "LLM",
                        "relation": "perceives_semantics",
                        "object": "unchanged"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Graph neural networks and set models are designed to be invariant to input order, preserving semantics.",
                        "uuids": []
                    },
                    {
                        "text": "Empirical results show that LLMs can be sensitive to order unless representations are explicitly designed to be order-invariant.",
                        "uuids": []
                    },
                    {
                        "text": "Canonicalization and randomization of graph linearizations are used to ensure semantic consistency in training data.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Semantic preservation under permutation is a goal in GNNs and set models.",
                    "what_is_novel": "This law formalizes the requirement for semantic consistency in LLM-based graph linearization, not just in neural architectures.",
                    "classification_explanation": "The law is closely related to existing principles in GNNs but is novel in its explicit application to LLMs and graph-to-text representations.",
                    "likely_classification": "closely-related-to-existing",
                    "references": [
                        "Zaheer et al. (2017) Deep Sets [Permutation invariance in set models]",
                        "Xu et al. (2019) How Powerful are Graph Neural Networks? [Semantic invariance in GNNs]",
                        "Ribeiro et al. (2020) Structural Encoding in Graph-to-Sequence Learning [Graph-to-sequence orderings]"
                    ]
                }
            }
        },
        {
            "law": {
                "law_name": "Transferability through Semantic Consistency Law",
                "if": [
                    {
                        "subject": "graph_linearization",
                        "relation": "is_semantically_consistent",
                        "object": "across_permutations"
                    }
                ],
                "then": [
                    {
                        "subject": "LLM",
                        "relation": "transfers_graph_knowledge",
                        "object": "effectively"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Models trained on semantically consistent representations show improved transfer to new graph domains.",
                        "uuids": []
                    },
                    {
                        "text": "Semantic consistency is a prerequisite for transfer learning in structured data.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Transfer learning in neural models is known to benefit from consistent representations.",
                    "what_is_novel": "This law links semantic consistency in graph linearization directly to transferability in LLMs.",
                    "classification_explanation": "The law is somewhat related to existing transfer learning principles but is novel in its focus on graph-to-text LLMs.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Pan & Yang (2010) A Survey on Transfer Learning [Transfer learning principles]",
                        "Xu et al. (2019) How Powerful are Graph Neural Networks? [Semantic consistency in GNNs]"
                    ]
                }
            }
        }
    ],
    "new_predictions_likely": [
        "LLMs trained on semantically consistent graph linearizations will transfer more effectively to new graph domains than those trained on inconsistent representations.",
        "Semantic consistency in graph-to-text representations will reduce the need for domain-specific fine-tuning."
    ],
    "new_predictions_unknown": [
        "Semantic consistency may enable LLMs to perform zero-shot reasoning on novel graph types.",
        "LLMs may develop internal representations of graph motifs that are invariant to input order if trained on semantically consistent data."
    ],
    "negative_experiments": [
        "If LLMs trained on semantically consistent representations do not transfer better than those trained on inconsistent ones, the theory would be challenged.",
        "If semantic consistency does not improve LLM interpretability or robustness, the law would be called into question."
    ],
    "unaccounted_for": [
        {
            "text": "The effect of semantic consistency on LLMs with limited capacity or context window is not fully explained.",
            "uuids": []
        }
    ],
    "conflicting_evidence": [
        {
            "text": "Some tasks may benefit from domain-specific orderings that encode additional information, potentially conflicting with strict semantic consistency.",
            "uuids": []
        }
    ],
    "special_cases": [
        "Graphs with inherent directionality or hierarchy may require orderings that reflect these properties for optimal performance.",
        "Very large or dense graphs may require approximate or lossy linearizations, which could affect semantic consistency."
    ],
    "existing_theory": {
        "what_already_exists": "Semantic consistency and transferability are established in transfer learning and GNN literature.",
        "what_is_novel": "The explicit connection between semantic consistency in graph linearization and LLM transferability is novel.",
        "classification_explanation": "The theory builds on existing principles but applies them in a new context (LLMs and graph-to-text linearization).",
        "likely_classification": "somewhat-related-to-existing",
        "references": [
            "Pan & Yang (2010) A Survey on Transfer Learning [Transfer learning principles]",
            "Xu et al. (2019) How Powerful are Graph Neural Networks? [Semantic consistency in GNNs]",
            "Ribeiro et al. (2020) Structural Encoding in Graph-to-Sequence Learning [Graph-to-sequence orderings]"
        ]
    },
    "theory_type_general_specific": "general",
    "reflected_from_theory_index": 0,
    "type": "general",
    "version": "built-theory-from-results-single-theory-reflection2-nov14-2025-LLM-BASELINE-no-evidence-with-matched-control-theory-name",
    "theory_query": "Build a theory of ideal representations for converting graphs into text for language model training.",
    "original_theory_id": "theory-615",
    "original_theory_name": "Order-Invariance Robustness Law for Graph Linearization in LLMs",
    "provide_matched_control_thery_name": true,
    "matched_control_theory_name": "Order-Invariance Robustness Law for Graph Linearization in LLMs",
    "model_str": "openai/gpt-4.1-2025-04-14"
}</code></pre>
        </div>
    </div>
</body>
</html>