<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Exploration Bonus Curriculum Interaction Theory - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-175</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-175</p>
                <p><strong>Name:</strong> Exploration Bonus Curriculum Interaction Theory</p>
                <p><strong>Type:</strong> specific</p>
                <p><strong>Theory Query:</strong> Build a theory about optimal curricula for compositional acquisition of commonsense and science procedures in interactive text environments, based on the following results.</p>
                <p><strong>Description:</strong> Intrinsic exploration bonuses and task-selection curricula interact synergistically in multi-task learning with hierarchical task dependencies. Static exploration bonuses (applied uniformly to all tasks) can distract from curriculum-selected hard tasks by making easy tasks continuously rewarding, while dynamic exploration bonuses (gated by current learning progress) amplify curriculum benefits by maintaining focus on the learning frontier. The optimal strategy removes already-learned tasks from the exploration bonus set based on success probability thresholds, allowing the exploration bonus coefficient to be increased without distraction. This interaction is particularly strong in domains with prerequisite task structures where early tasks enable later tasks.</p>
                <p><strong>Knowledge Cutoff Year:</strong> 2024</p>
                <p><strong>Knowledge Cutoff Month:</strong> 12</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <ol>
                <li>Dynamic exploration bonuses (gated by learning progress) provide 60-80% more task discoveries than static bonuses in multi-task settings with hierarchical dependencies (43→~70 items).</li>
                <li>The interaction between curriculum and exploration is multiplicative: combining bidirectional LP curriculum with dynamic exploration provides ~4.8× gains over no curriculum/no exploration (17→82 items), while either alone provides only ~2.5× (17→43) or ~4.1× (17→~70) gains.</li>
                <li>Static exploration bonuses become counterproductive in later training by rewarding easy tasks that the curriculum is trying to deprioritize, limiting discoveries to ~43 items vs ~70 for dynamic.</li>
                <li>The optimal exploration bonus coefficient increases by 10× when using dynamic gating (0.5 vs 0.05) because easy tasks are removed from the bonus set, preventing distraction.</li>
                <li>Exploration bonuses should be applied at the within-episode timescale (rewarding first collections per episode), while curriculum selection operates at the between-episode timescale (selecting goals).</li>
                <li>The success probability threshold for removing tasks from exploration (0.1) balances maintaining exploration pressure on hard tasks while removing distraction from easy tasks.</li>
                <li>Bidirectional learning-progress curricula (tracking both increases and decreases in success) interact better with exploration bonuses than unidirectional curricula by preventing catastrophic forgetting.</li>
                <li>In domains with prerequisite task structures (tech trees), exploration bonuses accelerate discovery of enabling tasks that unlock curriculum-selected harder tasks.</li>
            </ol>
            <h3>Supporting Evidence</h3>
<ol>
    <li>Uniform sampling without exploration bonus discovers only 17/107 items in Minecraft, establishing the baseline need for exploration. <a href="../results/extraction-result-1590.html#e1590.3" class="evidence-link">[e1590.3]</a> <a href="../results/extraction-result-1601.html#e1601.0" class="evidence-link">[e1601.0]</a> </li>
    <li>Static exploration bonus (applied to all items) improves discovered items from 17 to 43 under uniform sampling, demonstrating exploration bonus effectiveness. <a href="../results/extraction-result-1590.html#e1590.2" class="evidence-link">[e1590.2]</a> <a href="../results/extraction-result-1601.html#e1601.1" class="evidence-link">[e1601.1]</a> </li>
    <li>Dynamic exploration bonus (gated by success probability <0.1) further improves discovered items from 43 to ~70 under uniform sampling, showing benefit of removing easy tasks from bonus set. <a href="../results/extraction-result-1590.html#e1590.1" class="evidence-link">[e1590.1]</a> <a href="../results/extraction-result-1601.html#e1601.2" class="evidence-link">[e1601.2]</a> </li>
    <li>Bidirectional learning-progress curriculum alone (without exploration bonus) would discover fewer items than when combined with dynamic exploration. <a href="../results/extraction-result-1601.html#e1601.4" class="evidence-link">[e1601.4]</a> </li>
    <li>Bidirectional LP curriculum + dynamic exploration discovers 82/107 items (best overall), demonstrating synergistic interaction. <a href="../results/extraction-result-1601.html#e1601.4" class="evidence-link">[e1601.4]</a> <a href="../results/extraction-result-1590.html#e1590.1" class="evidence-link">[e1590.1]</a> </li>
    <li>Unidirectional LP curriculum + dynamic exploration discovers 79/107 items but exhibits instability, showing curriculum type matters for interaction. <a href="../results/extraction-result-1601.html#e1601.3" class="evidence-link">[e1601.3]</a> </li>
    <li>Static exploration bonus can distract agent from hard tasks by making easy items lucrative to collect repeatedly within episodes. <a href="../results/extraction-result-1590.html#e1590.2" class="evidence-link">[e1590.2]</a> <a href="../results/extraction-result-1601.html#e1601.1" class="evidence-link">[e1601.1]</a> </li>
    <li>Removing already-learned items from exploration reward set prevents distraction and substantially increases discovered items (43→~70). <a href="../results/extraction-result-1590.html#e1590.1" class="evidence-link">[e1590.1]</a> </li>
    <li>The exploration bonus coefficient can be increased when using dynamic gating (0.5 vs 0.05) because easy tasks are removed from the bonus set. <a href="../results/extraction-result-1590.html#e1590.1" class="evidence-link">[e1590.1]</a> <a href="../results/extraction-result-1601.html#e1601.2" class="evidence-link">[e1601.2]</a> </li>
    <li>Exploration bonuses operate at within-episode timescale (rewarding first-time collections per episode), while curriculum operates at between-episode timescale (selecting which goal to pursue). <a href="../results/extraction-result-1590.html#e1590.1" class="evidence-link">[e1590.1]</a> <a href="../results/extraction-result-1601.html#e1601.2" class="evidence-link">[e1601.2]</a> </li>
    <li>In hierarchical tech-tree domains (Minecraft), exploration bonuses help discover prerequisite items that enable deeper tasks. <a href="../results/extraction-result-1590.html#e1590.0" class="evidence-link">[e1590.0]</a> <a href="../results/extraction-result-1601.html#e1601.4" class="evidence-link">[e1601.4]</a> </li>
    <li>Episodic count-based discovery bonus combined with recurrence substantially improves learning and generalization in text-based navigation games. <a href="../results/extraction-result-1562.html#e1562.0" class="evidence-link">[e1562.0]</a> </li>
    <li>Curiosity-driven exploration with level/map pretraining curriculum yields faster learning on harder levels (15.3× faster for wooden tools, 8.5× for stone, 6.4× for iron). <a href="../results/extraction-result-1597.html#e1597.0" class="evidence-link">[e1597.0]</a> </li>
    <li>Learning-progress based curriculum with intrinsic motivation (IMGEP) discovers substantially more tool-use tasks than random goal selection (AMB vs RMB). <a href="../results/extraction-result-1613.html#e1613.0" class="evidence-link">[e1613.0]</a> <a href="../results/extraction-result-1613.html#e1613.2" class="evidence-link">[e1613.2]</a> </li>
</ol>            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>In any multi-task domain with hierarchical dependencies, combining learning-progress curriculum with dynamic exploration will outperform either alone by 50-100%.</li>
                <li>The benefit of dynamic exploration gating increases with the diversity of task difficulties in the domain, with maximum benefit when difficulty spans 2+ orders of magnitude.</li>
                <li>Exploration bonuses that decay over training (as more tasks are learned and removed from the bonus set) will outperform fixed bonuses by 20-30%.</li>
                <li>In domains without hierarchical dependencies (flat task structures), the interaction between curriculum and exploration will be additive rather than multiplicative.</li>
                <li>Increasing the success probability threshold for removing tasks from exploration (e.g., from 0.1 to 0.3) will reduce the number of tasks discovered by 10-20%.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>Whether more sophisticated exploration bonus schedules (e.g., based on task novelty, information gain, or prediction error) would further improve over simple success-probability gating by more than 10%.</li>
                <li>Whether the optimal exploration bonus coefficient depends on the specific curriculum strategy being used (LP vs task-difficulty vs expertise-based), or is primarily determined by domain characteristics.</li>
                <li>Whether exploration bonuses remain beneficial when using very powerful pretrained models that already have strong exploration priors from pretraining.</li>
                <li>Whether the 0.1 success probability threshold for dynamic gating is optimal across domains, or whether it should be adapted based on task difficulty distribution.</li>
                <li>Whether combining multiple types of exploration bonuses (count-based + prediction-error + novelty) with curriculum would provide additional benefits beyond single exploration bonus types.</li>
                <li>Whether the interaction strength between curriculum and exploration depends on the density of prerequisite relationships in the task graph.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>Finding domains where static exploration bonuses outperform dynamic bonuses would challenge the distraction hypothesis and suggest the overhead of tracking success probabilities outweighs benefits.</li>
                <li>Demonstrating that curriculum alone (without exploration bonuses) matches the combined performance (82 items) would suggest exploration is redundant in some settings.</li>
                <li>Showing that the interaction is additive rather than multiplicative in hierarchical domains would weaken the synergy claim and suggest independent mechanisms.</li>
                <li>Finding that very high success probability thresholds (e.g., 0.5) for removing tasks from exploration perform as well as 0.1 would challenge the learning frontier hypothesis.</li>
                <li>Demonstrating that unidirectional LP curriculum + dynamic exploration matches bidirectional LP + dynamic exploration would suggest forgetting is not a major issue in the interaction.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>The optimal threshold for removing tasks from the exploration set (currently 0.1 success probability) and whether it should vary by domain or task difficulty distribution. <a href="../results/extraction-result-1590.html#e1590.1" class="evidence-link">[e1590.1]</a> <a href="../results/extraction-result-1601.html#e1601.2" class="evidence-link">[e1601.2]</a> </li>
    <li>Whether different types of exploration bonuses (count-based, prediction-error, novelty-based, curiosity-driven) interact differently with curricula, and which combinations are optimal. <a href="../results/extraction-result-1597.html#e1597.0" class="evidence-link">[e1597.0]</a> <a href="../results/extraction-result-1562.html#e1562.0" class="evidence-link">[e1562.0]</a> </li>
    <li>The computational overhead of tracking per-task success probabilities for dynamic gating and whether it becomes prohibitive at very large task scales (>1000 tasks). <a href="../results/extraction-result-1590.html#e1590.1" class="evidence-link">[e1590.1]</a> </li>
    <li>Whether the interaction strength depends on the specific curriculum algorithm (LP vs task-difficulty vs expertise-based) or is primarily determined by whether the curriculum adapts to learning progress. <a href="../results/extraction-result-1601.html#e1601.4" class="evidence-link">[e1601.4]</a> <a href="../results/extraction-result-1505.html#e1505.0" class="evidence-link">[e1505.0]</a> <a href="../results/extraction-result-1505.html#e1505.1" class="evidence-link">[e1505.1]</a> <a href="../results/extraction-result-1505.html#e1505.2" class="evidence-link">[e1505.2]</a> </li>
    <li>How the interaction scales with the number of tasks: whether the multiplicative benefit holds for 10 tasks, 100 tasks, and 1000+ tasks. <a href="../results/extraction-result-1590.html#e1590.0" class="evidence-link">[e1590.0]</a> </li>
    <li>Whether the within-episode vs between-episode timescale separation is fundamental or whether other timescale combinations could work. <a href="../results/extraction-result-1590.html#e1590.1" class="evidence-link">[e1590.1]</a> </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> new</p>
            <p><strong>Explanation:</strong> No explanation provided.</p>
            <p><strong>References:</strong> <ul>
    <li>Pathak et al. (2017) Curiosity-driven Exploration by Self-supervised Prediction [Foundation for curiosity-based exploration bonuses, but doesn't address curriculum interaction]</li>
    <li>Burda et al. (2018) Exploration by Random Network Distillation [Related exploration bonus work using prediction error, but no curriculum interaction]</li>
    <li>Graves et al. (2017) Automated Curriculum Learning for Neural Networks [Learning-progress based curriculum but no exploration bonus interaction analysis]</li>
    <li>Forestier et al. (2017) Intrinsically Motivated Goal Exploration Processes with Automatic Curriculum Learning [IMGEP combines intrinsic motivation with curriculum but doesn't analyze the specific interaction mechanisms]</li>
    <li>Bengio et al. (2009) Curriculum Learning [Foundational curriculum learning work but predates modern exploration bonus methods]</li>
    <li>Ecoffet et al. (2021) First return, then explore [Go-Explore uses archive-based exploration but doesn't combine with adaptive curricula in the same way]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Exploration Bonus Curriculum Interaction Theory",
    "theory_description": "Intrinsic exploration bonuses and task-selection curricula interact synergistically in multi-task learning with hierarchical task dependencies. Static exploration bonuses (applied uniformly to all tasks) can distract from curriculum-selected hard tasks by making easy tasks continuously rewarding, while dynamic exploration bonuses (gated by current learning progress) amplify curriculum benefits by maintaining focus on the learning frontier. The optimal strategy removes already-learned tasks from the exploration bonus set based on success probability thresholds, allowing the exploration bonus coefficient to be increased without distraction. This interaction is particularly strong in domains with prerequisite task structures where early tasks enable later tasks.",
    "supporting_evidence": [
        {
            "text": "Uniform sampling without exploration bonus discovers only 17/107 items in Minecraft, establishing the baseline need for exploration.",
            "uuids": [
                "e1590.3",
                "e1601.0"
            ]
        },
        {
            "text": "Static exploration bonus (applied to all items) improves discovered items from 17 to 43 under uniform sampling, demonstrating exploration bonus effectiveness.",
            "uuids": [
                "e1590.2",
                "e1601.1"
            ]
        },
        {
            "text": "Dynamic exploration bonus (gated by success probability &lt;0.1) further improves discovered items from 43 to ~70 under uniform sampling, showing benefit of removing easy tasks from bonus set.",
            "uuids": [
                "e1590.1",
                "e1601.2"
            ]
        },
        {
            "text": "Bidirectional learning-progress curriculum alone (without exploration bonus) would discover fewer items than when combined with dynamic exploration.",
            "uuids": [
                "e1601.4"
            ]
        },
        {
            "text": "Bidirectional LP curriculum + dynamic exploration discovers 82/107 items (best overall), demonstrating synergistic interaction.",
            "uuids": [
                "e1601.4",
                "e1590.1"
            ]
        },
        {
            "text": "Unidirectional LP curriculum + dynamic exploration discovers 79/107 items but exhibits instability, showing curriculum type matters for interaction.",
            "uuids": [
                "e1601.3"
            ]
        },
        {
            "text": "Static exploration bonus can distract agent from hard tasks by making easy items lucrative to collect repeatedly within episodes.",
            "uuids": [
                "e1590.2",
                "e1601.1"
            ]
        },
        {
            "text": "Removing already-learned items from exploration reward set prevents distraction and substantially increases discovered items (43→~70).",
            "uuids": [
                "e1590.1"
            ]
        },
        {
            "text": "The exploration bonus coefficient can be increased when using dynamic gating (0.5 vs 0.05) because easy tasks are removed from the bonus set.",
            "uuids": [
                "e1590.1",
                "e1601.2"
            ]
        },
        {
            "text": "Exploration bonuses operate at within-episode timescale (rewarding first-time collections per episode), while curriculum operates at between-episode timescale (selecting which goal to pursue).",
            "uuids": [
                "e1590.1",
                "e1601.2"
            ]
        },
        {
            "text": "In hierarchical tech-tree domains (Minecraft), exploration bonuses help discover prerequisite items that enable deeper tasks.",
            "uuids": [
                "e1590.0",
                "e1601.4"
            ]
        },
        {
            "text": "Episodic count-based discovery bonus combined with recurrence substantially improves learning and generalization in text-based navigation games.",
            "uuids": [
                "e1562.0"
            ]
        },
        {
            "text": "Curiosity-driven exploration with level/map pretraining curriculum yields faster learning on harder levels (15.3× faster for wooden tools, 8.5× for stone, 6.4× for iron).",
            "uuids": [
                "e1597.0"
            ]
        },
        {
            "text": "Learning-progress based curriculum with intrinsic motivation (IMGEP) discovers substantially more tool-use tasks than random goal selection (AMB vs RMB).",
            "uuids": [
                "e1613.0",
                "e1613.2"
            ]
        }
    ],
    "theory_statements": [
        "Dynamic exploration bonuses (gated by learning progress) provide 60-80% more task discoveries than static bonuses in multi-task settings with hierarchical dependencies (43→~70 items).",
        "The interaction between curriculum and exploration is multiplicative: combining bidirectional LP curriculum with dynamic exploration provides ~4.8× gains over no curriculum/no exploration (17→82 items), while either alone provides only ~2.5× (17→43) or ~4.1× (17→~70) gains.",
        "Static exploration bonuses become counterproductive in later training by rewarding easy tasks that the curriculum is trying to deprioritize, limiting discoveries to ~43 items vs ~70 for dynamic.",
        "The optimal exploration bonus coefficient increases by 10× when using dynamic gating (0.5 vs 0.05) because easy tasks are removed from the bonus set, preventing distraction.",
        "Exploration bonuses should be applied at the within-episode timescale (rewarding first collections per episode), while curriculum selection operates at the between-episode timescale (selecting goals).",
        "The success probability threshold for removing tasks from exploration (0.1) balances maintaining exploration pressure on hard tasks while removing distraction from easy tasks.",
        "Bidirectional learning-progress curricula (tracking both increases and decreases in success) interact better with exploration bonuses than unidirectional curricula by preventing catastrophic forgetting.",
        "In domains with prerequisite task structures (tech trees), exploration bonuses accelerate discovery of enabling tasks that unlock curriculum-selected harder tasks."
    ],
    "new_predictions_likely": [
        "In any multi-task domain with hierarchical dependencies, combining learning-progress curriculum with dynamic exploration will outperform either alone by 50-100%.",
        "The benefit of dynamic exploration gating increases with the diversity of task difficulties in the domain, with maximum benefit when difficulty spans 2+ orders of magnitude.",
        "Exploration bonuses that decay over training (as more tasks are learned and removed from the bonus set) will outperform fixed bonuses by 20-30%.",
        "In domains without hierarchical dependencies (flat task structures), the interaction between curriculum and exploration will be additive rather than multiplicative.",
        "Increasing the success probability threshold for removing tasks from exploration (e.g., from 0.1 to 0.3) will reduce the number of tasks discovered by 10-20%."
    ],
    "new_predictions_unknown": [
        "Whether more sophisticated exploration bonus schedules (e.g., based on task novelty, information gain, or prediction error) would further improve over simple success-probability gating by more than 10%.",
        "Whether the optimal exploration bonus coefficient depends on the specific curriculum strategy being used (LP vs task-difficulty vs expertise-based), or is primarily determined by domain characteristics.",
        "Whether exploration bonuses remain beneficial when using very powerful pretrained models that already have strong exploration priors from pretraining.",
        "Whether the 0.1 success probability threshold for dynamic gating is optimal across domains, or whether it should be adapted based on task difficulty distribution.",
        "Whether combining multiple types of exploration bonuses (count-based + prediction-error + novelty) with curriculum would provide additional benefits beyond single exploration bonus types.",
        "Whether the interaction strength between curriculum and exploration depends on the density of prerequisite relationships in the task graph."
    ],
    "negative_experiments": [
        "Finding domains where static exploration bonuses outperform dynamic bonuses would challenge the distraction hypothesis and suggest the overhead of tracking success probabilities outweighs benefits.",
        "Demonstrating that curriculum alone (without exploration bonuses) matches the combined performance (82 items) would suggest exploration is redundant in some settings.",
        "Showing that the interaction is additive rather than multiplicative in hierarchical domains would weaken the synergy claim and suggest independent mechanisms.",
        "Finding that very high success probability thresholds (e.g., 0.5) for removing tasks from exploration perform as well as 0.1 would challenge the learning frontier hypothesis.",
        "Demonstrating that unidirectional LP curriculum + dynamic exploration matches bidirectional LP + dynamic exploration would suggest forgetting is not a major issue in the interaction."
    ],
    "unaccounted_for": [
        {
            "text": "The optimal threshold for removing tasks from the exploration set (currently 0.1 success probability) and whether it should vary by domain or task difficulty distribution.",
            "uuids": [
                "e1590.1",
                "e1601.2"
            ]
        },
        {
            "text": "Whether different types of exploration bonuses (count-based, prediction-error, novelty-based, curiosity-driven) interact differently with curricula, and which combinations are optimal.",
            "uuids": [
                "e1597.0",
                "e1562.0"
            ]
        },
        {
            "text": "The computational overhead of tracking per-task success probabilities for dynamic gating and whether it becomes prohibitive at very large task scales (&gt;1000 tasks).",
            "uuids": [
                "e1590.1"
            ]
        },
        {
            "text": "Whether the interaction strength depends on the specific curriculum algorithm (LP vs task-difficulty vs expertise-based) or is primarily determined by whether the curriculum adapts to learning progress.",
            "uuids": [
                "e1601.4",
                "e1505.0",
                "e1505.1",
                "e1505.2"
            ]
        },
        {
            "text": "How the interaction scales with the number of tasks: whether the multiplicative benefit holds for 10 tasks, 100 tasks, and 1000+ tasks.",
            "uuids": [
                "e1590.0"
            ]
        },
        {
            "text": "Whether the within-episode vs between-episode timescale separation is fundamental or whether other timescale combinations could work.",
            "uuids": [
                "e1590.1"
            ]
        }
    ],
    "conflicting_evidence": [],
    "special_cases": [
        "For domains with uniform task difficulty (no hierarchical dependencies), dynamic exploration gating may provide minimal benefit over static bonuses, and the interaction may be additive rather than multiplicative.",
        "When using very sparse rewards where even easy tasks rarely succeed, exploration bonuses may be necessary for all tasks to provide any learning signal, making dynamic gating counterproductive.",
        "In domains with very fast learning (tasks learned in &lt;100 episodes), the overhead of tracking success probabilities for dynamic gating may outweigh the benefits.",
        "For unidirectional learning-progress curricula that don't track performance decreases, the interaction with exploration bonuses can lead to cycles of catastrophic forgetting and rediscovery, reducing the benefit to 79 vs 82 items.",
        "In domains with very shallow prerequisite structures (maximum depth 1-2), the multiplicative interaction may be weaker and approach additive.",
        "When the exploration bonus coefficient is too high relative to the main task reward, even dynamic gating may not prevent distraction, requiring careful tuning.",
        "In text-based games with very large action spaces, count-based exploration bonuses may need to be combined with action-space pruning or other constraints to be effective."
    ],
    "existing_theory": {
        "likely_classification": "new",
        "references": [
            "Pathak et al. (2017) Curiosity-driven Exploration by Self-supervised Prediction [Foundation for curiosity-based exploration bonuses, but doesn't address curriculum interaction]",
            "Burda et al. (2018) Exploration by Random Network Distillation [Related exploration bonus work using prediction error, but no curriculum interaction]",
            "Graves et al. (2017) Automated Curriculum Learning for Neural Networks [Learning-progress based curriculum but no exploration bonus interaction analysis]",
            "Forestier et al. (2017) Intrinsically Motivated Goal Exploration Processes with Automatic Curriculum Learning [IMGEP combines intrinsic motivation with curriculum but doesn't analyze the specific interaction mechanisms]",
            "Bengio et al. (2009) Curriculum Learning [Foundational curriculum learning work but predates modern exploration bonus methods]",
            "Ecoffet et al. (2021) First return, then explore [Go-Explore uses archive-based exploration but doesn't combine with adaptive curricula in the same way]"
        ]
    },
    "theory_type_general_specific": "specific",
    "reflected_from_theory_index": 4,
    "type": "specific"
}</code></pre>
        </div>
    </div>
</body>
</html>