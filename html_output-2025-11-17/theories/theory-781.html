<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Hierarchical Program Induction for LLM Arithmetic (General Theory) - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-781</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-781</p>
                <p><strong>Name:</strong> Hierarchical Program Induction for LLM Arithmetic (General Theory)</p>
                <p><strong>Type:</strong> general</p>
                <p><strong>Theory Query:</strong> Build a theory of how language models perform arithmetic.</p>
                <p><strong>Description:</strong> This theory proposes that LLMs solve arithmetic by inducing hierarchical, compositional programs that decompose complex arithmetic tasks into simpler subroutines, which are then solved recursively or sequentially. The LLM's transformer architecture supports this by enabling the reuse and recombination of learned subprograms, allowing for efficient generalization to arithmetic problems of varying complexity and structure.</p>
                <p><strong>Knowledge Cutoff Year:</strong> -1</p>
                <p><strong>Knowledge Cutoff Month:</strong> -1</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <h3>Statement 0: Hierarchical Decomposition of Arithmetic Problems (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; LLM &#8594; is_prompted_with &#8594; complex_arithmetic_problem</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; LLM &#8594; decomposes &#8594; problem_into_subproblems<span style="color: #888888;">, and</span></div>
        <div>&#8226; LLM &#8594; solves &#8594; subproblems_recursively</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>LLMs can solve multi-digit arithmetic by breaking down problems into digit-wise operations, as seen in chain-of-thought outputs. </li>
    <li>Transformer attention patterns in LLMs show hierarchical processing when solving arithmetic tasks. </li>
    <li>LLMs trained on code or algorithmic data can generalize to longer or more complex arithmetic problems than seen in training. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> The law is somewhat related to existing work on compositional generalization, but its application to LLM arithmetic is novel.</p>            <p><strong>What Already Exists:</strong> Hierarchical and compositional reasoning is a known property of neural networks and program synthesis models.</p>            <p><strong>What is Novel:</strong> This law applies hierarchical program induction specifically to LLM arithmetic, linking transformer architecture to compositional arithmetic reasoning.</p>
            <p><strong>References:</strong> <ul>
    <li>Lake et al. (2017) Building Machines That Learn and Think Like People [compositionality in program induction]</li>
    <li>Saxton et al. (2019) Analysing Mathematical Reasoning Abilities of Neural Models [hierarchical reasoning in neural models]</li>
    <li>Nye et al. (2021) Show Your Work: Scratchpads for Intermediate Computation with Language Models [LLMs use intermediate steps, hinting at hierarchical reasoning]</li>
</ul>
            <h3>Statement 1: Subprogram Reuse Enables Arithmetic Generalization (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; LLM &#8594; has_learned &#8594; arithmetic_subprograms<span style="color: #888888;">, and</span></div>
        <div>&#8226; LLM &#8594; is_prompted_with &#8594; novel_arithmetic_problem</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; LLM &#8594; reuses &#8594; subprograms_to_solve_problem</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>LLMs can generalize to arithmetic problems with more digits or different formats than seen in training, suggesting subprogram reuse. </li>
    <li>Analysis of LLM outputs shows repeated use of similar solution patterns across different arithmetic problems. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> closely-related-to-existing</p>
            <p><strong>Explanation:</strong> The law is closely related to existing work on compositionality, but its explicit application to LLM arithmetic is novel.</p>            <p><strong>What Already Exists:</strong> Subprogram reuse is a known property in program synthesis and algorithmic reasoning.</p>            <p><strong>What is Novel:</strong> This law posits that LLMs specifically leverage subprogram reuse for arithmetic generalization, enabled by their architecture.</p>
            <p><strong>References:</strong> <ul>
    <li>Lake et al. (2017) Building Machines That Learn and Think Like People [compositionality and subprogram reuse]</li>
    <li>Saxton et al. (2019) Analysing Mathematical Reasoning Abilities of Neural Models [generalization via subprogram reuse]</li>
</ul>
            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>LLMs will show improved generalization to longer or more complex arithmetic problems if trained with explicit hierarchical or compositional objectives.</li>
                <li>Analysis of LLM attention patterns during arithmetic will reveal modular, reusable subprograms corresponding to arithmetic operations.</li>
                <li>LLMs will make systematic errors when a required subprogram is missing or misapplied, leading to predictable error patterns.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>If LLMs are trained on entirely novel arithmetic operations (e.g., non-standard bases), they may induce new subprograms and generalize to unseen cases.</li>
                <li>LLMs may be able to transfer subprograms learned for arithmetic to other algorithmic domains (e.g., sorting, logic puzzles).</li>
                <li>If LLMs are architecturally modified to restrict subprogram reuse, their arithmetic generalization will degrade in novel ways.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>If LLMs do not show evidence of hierarchical decomposition or subprogram reuse in their activations or outputs, the theory would be challenged.</li>
                <li>If LLMs cannot generalize to longer or more complex arithmetic problems despite extensive training, the theory would be called into question.</li>
                <li>If LLMs' error patterns do not correspond to missing or misapplied subprograms, the theory would be weakened.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>Some LLMs may solve very simple arithmetic problems without hierarchical decomposition, possibly via direct pattern matching or memorization. </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> somewhat-related-to-existing</p>
            <p><strong>Explanation:</strong> The theory extends compositionality and program induction to the specific case of LLM arithmetic, which is a new, testable hypothesis.</p>
            <p><strong>References:</strong> <ul>
    <li>Lake et al. (2017) Building Machines That Learn and Think Like People [compositionality in program induction]</li>
    <li>Saxton et al. (2019) Analysing Mathematical Reasoning Abilities of Neural Models [hierarchical reasoning in neural models]</li>
    <li>Nye et al. (2021) Show Your Work: Scratchpads for Intermediate Computation with Language Models [LLMs use intermediate steps, hinting at hierarchical reasoning]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Hierarchical Program Induction for LLM Arithmetic (General Theory)",
    "theory_description": "This theory proposes that LLMs solve arithmetic by inducing hierarchical, compositional programs that decompose complex arithmetic tasks into simpler subroutines, which are then solved recursively or sequentially. The LLM's transformer architecture supports this by enabling the reuse and recombination of learned subprograms, allowing for efficient generalization to arithmetic problems of varying complexity and structure.",
    "theory_statements": [
        {
            "law": {
                "law_name": "Hierarchical Decomposition of Arithmetic Problems",
                "if": [
                    {
                        "subject": "LLM",
                        "relation": "is_prompted_with",
                        "object": "complex_arithmetic_problem"
                    }
                ],
                "then": [
                    {
                        "subject": "LLM",
                        "relation": "decomposes",
                        "object": "problem_into_subproblems"
                    },
                    {
                        "subject": "LLM",
                        "relation": "solves",
                        "object": "subproblems_recursively"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "LLMs can solve multi-digit arithmetic by breaking down problems into digit-wise operations, as seen in chain-of-thought outputs.",
                        "uuids": []
                    },
                    {
                        "text": "Transformer attention patterns in LLMs show hierarchical processing when solving arithmetic tasks.",
                        "uuids": []
                    },
                    {
                        "text": "LLMs trained on code or algorithmic data can generalize to longer or more complex arithmetic problems than seen in training.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Hierarchical and compositional reasoning is a known property of neural networks and program synthesis models.",
                    "what_is_novel": "This law applies hierarchical program induction specifically to LLM arithmetic, linking transformer architecture to compositional arithmetic reasoning.",
                    "classification_explanation": "The law is somewhat related to existing work on compositional generalization, but its application to LLM arithmetic is novel.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Lake et al. (2017) Building Machines That Learn and Think Like People [compositionality in program induction]",
                        "Saxton et al. (2019) Analysing Mathematical Reasoning Abilities of Neural Models [hierarchical reasoning in neural models]",
                        "Nye et al. (2021) Show Your Work: Scratchpads for Intermediate Computation with Language Models [LLMs use intermediate steps, hinting at hierarchical reasoning]"
                    ]
                }
            }
        },
        {
            "law": {
                "law_name": "Subprogram Reuse Enables Arithmetic Generalization",
                "if": [
                    {
                        "subject": "LLM",
                        "relation": "has_learned",
                        "object": "arithmetic_subprograms"
                    },
                    {
                        "subject": "LLM",
                        "relation": "is_prompted_with",
                        "object": "novel_arithmetic_problem"
                    }
                ],
                "then": [
                    {
                        "subject": "LLM",
                        "relation": "reuses",
                        "object": "subprograms_to_solve_problem"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "LLMs can generalize to arithmetic problems with more digits or different formats than seen in training, suggesting subprogram reuse.",
                        "uuids": []
                    },
                    {
                        "text": "Analysis of LLM outputs shows repeated use of similar solution patterns across different arithmetic problems.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Subprogram reuse is a known property in program synthesis and algorithmic reasoning.",
                    "what_is_novel": "This law posits that LLMs specifically leverage subprogram reuse for arithmetic generalization, enabled by their architecture.",
                    "classification_explanation": "The law is closely related to existing work on compositionality, but its explicit application to LLM arithmetic is novel.",
                    "likely_classification": "closely-related-to-existing",
                    "references": [
                        "Lake et al. (2017) Building Machines That Learn and Think Like People [compositionality and subprogram reuse]",
                        "Saxton et al. (2019) Analysing Mathematical Reasoning Abilities of Neural Models [generalization via subprogram reuse]"
                    ]
                }
            }
        }
    ],
    "new_predictions_likely": [
        "LLMs will show improved generalization to longer or more complex arithmetic problems if trained with explicit hierarchical or compositional objectives.",
        "Analysis of LLM attention patterns during arithmetic will reveal modular, reusable subprograms corresponding to arithmetic operations.",
        "LLMs will make systematic errors when a required subprogram is missing or misapplied, leading to predictable error patterns."
    ],
    "new_predictions_unknown": [
        "If LLMs are trained on entirely novel arithmetic operations (e.g., non-standard bases), they may induce new subprograms and generalize to unseen cases.",
        "LLMs may be able to transfer subprograms learned for arithmetic to other algorithmic domains (e.g., sorting, logic puzzles).",
        "If LLMs are architecturally modified to restrict subprogram reuse, their arithmetic generalization will degrade in novel ways."
    ],
    "negative_experiments": [
        "If LLMs do not show evidence of hierarchical decomposition or subprogram reuse in their activations or outputs, the theory would be challenged.",
        "If LLMs cannot generalize to longer or more complex arithmetic problems despite extensive training, the theory would be called into question.",
        "If LLMs' error patterns do not correspond to missing or misapplied subprograms, the theory would be weakened."
    ],
    "unaccounted_for": [
        {
            "text": "Some LLMs may solve very simple arithmetic problems without hierarchical decomposition, possibly via direct pattern matching or memorization.",
            "uuids": []
        }
    ],
    "conflicting_evidence": [
        {
            "text": "LLMs sometimes make errors inconsistent with hierarchical or compositional reasoning, such as random digit substitutions.",
            "uuids": []
        }
    ],
    "special_cases": [
        "For trivial arithmetic (e.g., 1+1), LLMs may not engage hierarchical decomposition.",
        "In cases where the arithmetic problem is ill-posed or ambiguous, hierarchical decomposition may not be possible."
    ],
    "existing_theory": {
        "what_already_exists": "Compositional and hierarchical reasoning is a known property in neural and program synthesis models.",
        "what_is_novel": "The explicit application of hierarchical program induction and subprogram reuse to LLM arithmetic is novel.",
        "classification_explanation": "The theory extends compositionality and program induction to the specific case of LLM arithmetic, which is a new, testable hypothesis.",
        "likely_classification": "somewhat-related-to-existing",
        "references": [
            "Lake et al. (2017) Building Machines That Learn and Think Like People [compositionality in program induction]",
            "Saxton et al. (2019) Analysing Mathematical Reasoning Abilities of Neural Models [hierarchical reasoning in neural models]",
            "Nye et al. (2021) Show Your Work: Scratchpads for Intermediate Computation with Language Models [LLMs use intermediate steps, hinting at hierarchical reasoning]"
        ]
    },
    "reflected_from_theory_index": 0,
    "type": "general",
    "version": "built-theory-from-results-single-theory-reflection2-nov14-2025-LLM-BASELINE-no-evidence-with-matched-control-theory-name",
    "theory_query": "Build a theory of how language models perform arithmetic.",
    "original_theory_id": "theory-581",
    "original_theory_name": "Program Synthesis and External Execution as a Mechanism for LLM Arithmetic",
    "provide_matched_control_thery_name": true,
    "matched_control_theory_name": "Program Synthesis and External Execution as a Mechanism for LLM Arithmetic",
    "model_str": "openai/gpt-4.1-2025-04-14"
}</code></pre>
        </div>
    </div>
</body>
</html>