<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Probabilistic Expectation Modeling for Anomaly Detection - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-1728</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-1728</p>
                <p><strong>Name:</strong> Probabilistic Expectation Modeling for Anomaly Detection</p>
                <p><strong>Type:</strong> general</p>
                <p><strong>Theory Query:</strong> Build a theory of how language models can be used for detecting anomalies in lists of data.</p>
                <p><strong>Description:</strong> Language models assign probabilities to sequences or elements based on learned distributions. When applied to lists, LMs can detect anomalies as elements with low conditional probability given the context of the list, capturing both surface-level and deeper statistical irregularities. This theory posits that LMs' probabilistic outputs can be directly used to flag anomalies, even in non-linguistic or structured data.</p>
                <p><strong>Knowledge Cutoff Year:</strong> -1</p>
                <p><strong>Knowledge Cutoff Month:</strong> -1</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <h3>Statement 0: Low Conditional Probability Flags Anomaly (quantitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; element &#8594; is_in &#8594; list<span style="color: #888888;">, and</span></div>
        <div>&#8226; language_model &#8594; assigns_conditional_probability &#8594; P(element|context)<span style="color: #888888;">, and</span></div>
        <div>&#8226; P(element|context) &#8594; is_much_lower_than &#8594; P(typical_element|context)</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; element &#8594; is_flagged_as &#8594; anomaly</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>LMs assign lower probabilities to out-of-place or rare items in a sequence, which can be used for anomaly detection. </li>
    <li>Perplexity-based anomaly detection is effective in both text and structured data. </li>
    <li>Empirical studies show that LMs' probability scores correlate with human judgments of anomaly in lists. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> closely-related-to-existing</p>
            <p><strong>Explanation:</strong> Closely related to existing work, but the extension to arbitrary lists and explicit use of LM probabilities is a new formalization.</p>            <p><strong>What Already Exists:</strong> Probability-based anomaly detection is well-known in statistics and NLP.</p>            <p><strong>What is Novel:</strong> The direct application of LM conditional probabilities to arbitrary list anomaly detection is a novel generalization.</p>
            <p><strong>References:</strong> <ul>
    <li>Goldstein & Uchida (2016) A Comparative Evaluation of Unsupervised Anomaly Detection Algorithms for Multivariate Data [Statistical anomaly detection]</li>
    <li>Zhou et al. (2023) Large Language Models are Zero-Shot Anomaly Detectors [LMs' probability scores for anomaly detection]</li>
</ul>
            <h3>Statement 1: Contextual Probability Modeling Captures Subtle Anomalies (quantitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; list &#8594; has_contextual_structure &#8594; C<span style="color: #888888;">, and</span></div>
        <div>&#8226; element &#8594; is_in &#8594; list<span style="color: #888888;">, and</span></div>
        <div>&#8226; language_model &#8594; models_contextual_probability &#8594; P(element|C)</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; element &#8594; is_flagged_as &#8594; anomaly_if_P_is_low</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>LMs can model context-dependent expectations, such as the next item in a sequence or a value in a table row. </li>
    <li>Contextual probability modeling allows LMs to detect anomalies that are not globally rare but are unexpected in a given context. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> closely-related-to-existing</p>
            <p><strong>Explanation:</strong> Closely related to existing work, but the generalization to arbitrary lists is novel.</p>            <p><strong>What Already Exists:</strong> Contextual probability modeling is standard in language modeling.</p>            <p><strong>What is Novel:</strong> The explicit use of contextual probability for anomaly detection in arbitrary lists is a new application.</p>
            <p><strong>References:</strong> <ul>
    <li>Radford et al. (2019) Language Models are Unsupervised Multitask Learners [Contextual probability in LMs]</li>
    <li>Zhou et al. (2023) Large Language Models are Zero-Shot Anomaly Detectors [LMs' probability scores for anomaly detection]</li>
</ul>
            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>If an element in a list has a much lower LM-assigned probability than others, it will be flagged as anomalous.</li>
                <li>LMs will detect contextually rare but globally common items as anomalies (e.g., 'banana' in a list of car brands).</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>If the LM is exposed to lists with adversarially manipulated probabilities (e.g., rare but contextually plausible items), its anomaly detection may be inconsistent.</li>
                <li>If the LM is applied to highly structured, non-linguistic data (e.g., sensor readings), its probability-based anomaly detection performance is uncertain.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>If LMs assign high probability to anomalous elements (as judged by humans), the theory is challenged.</li>
                <li>If LMs fail to distinguish between contextually rare and globally rare items, the theory's contextual modeling is called into question.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>Anomalies that are semantically inconsistent but statistically common may not be detected by probability modeling alone. </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> closely-related-to-existing</p>
            <p><strong>Explanation:</strong> Closely related to existing work, but the extension to arbitrary lists and explicit use of LM probabilities is a new formalization.</p>
            <p><strong>References:</strong> <ul>
    <li>Goldstein & Uchida (2016) A Comparative Evaluation of Unsupervised Anomaly Detection Algorithms for Multivariate Data [Statistical anomaly detection]</li>
    <li>Zhou et al. (2023) Large Language Models are Zero-Shot Anomaly Detectors [LMs' probability scores for anomaly detection]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Probabilistic Expectation Modeling for Anomaly Detection",
    "theory_description": "Language models assign probabilities to sequences or elements based on learned distributions. When applied to lists, LMs can detect anomalies as elements with low conditional probability given the context of the list, capturing both surface-level and deeper statistical irregularities. This theory posits that LMs' probabilistic outputs can be directly used to flag anomalies, even in non-linguistic or structured data.",
    "theory_statements": [
        {
            "law": {
                "law_name": "Low Conditional Probability Flags Anomaly",
                "if": [
                    {
                        "subject": "element",
                        "relation": "is_in",
                        "object": "list"
                    },
                    {
                        "subject": "language_model",
                        "relation": "assigns_conditional_probability",
                        "object": "P(element|context)"
                    },
                    {
                        "subject": "P(element|context)",
                        "relation": "is_much_lower_than",
                        "object": "P(typical_element|context)"
                    }
                ],
                "then": [
                    {
                        "subject": "element",
                        "relation": "is_flagged_as",
                        "object": "anomaly"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "LMs assign lower probabilities to out-of-place or rare items in a sequence, which can be used for anomaly detection.",
                        "uuids": []
                    },
                    {
                        "text": "Perplexity-based anomaly detection is effective in both text and structured data.",
                        "uuids": []
                    },
                    {
                        "text": "Empirical studies show that LMs' probability scores correlate with human judgments of anomaly in lists.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "quantitative",
                "existing_law": {
                    "what_already_exists": "Probability-based anomaly detection is well-known in statistics and NLP.",
                    "what_is_novel": "The direct application of LM conditional probabilities to arbitrary list anomaly detection is a novel generalization.",
                    "classification_explanation": "Closely related to existing work, but the extension to arbitrary lists and explicit use of LM probabilities is a new formalization.",
                    "likely_classification": "closely-related-to-existing",
                    "references": [
                        "Goldstein & Uchida (2016) A Comparative Evaluation of Unsupervised Anomaly Detection Algorithms for Multivariate Data [Statistical anomaly detection]",
                        "Zhou et al. (2023) Large Language Models are Zero-Shot Anomaly Detectors [LMs' probability scores for anomaly detection]"
                    ]
                }
            }
        },
        {
            "law": {
                "law_name": "Contextual Probability Modeling Captures Subtle Anomalies",
                "if": [
                    {
                        "subject": "list",
                        "relation": "has_contextual_structure",
                        "object": "C"
                    },
                    {
                        "subject": "element",
                        "relation": "is_in",
                        "object": "list"
                    },
                    {
                        "subject": "language_model",
                        "relation": "models_contextual_probability",
                        "object": "P(element|C)"
                    }
                ],
                "then": [
                    {
                        "subject": "element",
                        "relation": "is_flagged_as",
                        "object": "anomaly_if_P_is_low"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "LMs can model context-dependent expectations, such as the next item in a sequence or a value in a table row.",
                        "uuids": []
                    },
                    {
                        "text": "Contextual probability modeling allows LMs to detect anomalies that are not globally rare but are unexpected in a given context.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "quantitative",
                "existing_law": {
                    "what_already_exists": "Contextual probability modeling is standard in language modeling.",
                    "what_is_novel": "The explicit use of contextual probability for anomaly detection in arbitrary lists is a new application.",
                    "classification_explanation": "Closely related to existing work, but the generalization to arbitrary lists is novel.",
                    "likely_classification": "closely-related-to-existing",
                    "references": [
                        "Radford et al. (2019) Language Models are Unsupervised Multitask Learners [Contextual probability in LMs]",
                        "Zhou et al. (2023) Large Language Models are Zero-Shot Anomaly Detectors [LMs' probability scores for anomaly detection]"
                    ]
                }
            }
        }
    ],
    "new_predictions_likely": [
        "If an element in a list has a much lower LM-assigned probability than others, it will be flagged as anomalous.",
        "LMs will detect contextually rare but globally common items as anomalies (e.g., 'banana' in a list of car brands)."
    ],
    "new_predictions_unknown": [
        "If the LM is exposed to lists with adversarially manipulated probabilities (e.g., rare but contextually plausible items), its anomaly detection may be inconsistent.",
        "If the LM is applied to highly structured, non-linguistic data (e.g., sensor readings), its probability-based anomaly detection performance is uncertain."
    ],
    "negative_experiments": [
        "If LMs assign high probability to anomalous elements (as judged by humans), the theory is challenged.",
        "If LMs fail to distinguish between contextually rare and globally rare items, the theory's contextual modeling is called into question."
    ],
    "unaccounted_for": [
        {
            "text": "Anomalies that are semantically inconsistent but statistically common may not be detected by probability modeling alone.",
            "uuids": []
        }
    ],
    "conflicting_evidence": [
        {
            "text": "LMs trained on biased or incomplete data may assign high probability to anomalous elements.",
            "uuids": []
        }
    ],
    "special_cases": [
        "Lists with uniform probability distributions may not yield clear anomaly signals.",
        "If the LM's training data contains systematic anomalies, its probability estimates may be unreliable."
    ],
    "existing_theory": {
        "what_already_exists": "Probability-based anomaly detection is well-known in statistics and NLP.",
        "what_is_novel": "The direct application of LM conditional probabilities to arbitrary list anomaly detection is a novel generalization.",
        "classification_explanation": "Closely related to existing work, but the extension to arbitrary lists and explicit use of LM probabilities is a new formalization.",
        "likely_classification": "closely-related-to-existing",
        "references": [
            "Goldstein & Uchida (2016) A Comparative Evaluation of Unsupervised Anomaly Detection Algorithms for Multivariate Data [Statistical anomaly detection]",
            "Zhou et al. (2023) Large Language Models are Zero-Shot Anomaly Detectors [LMs' probability scores for anomaly detection]"
        ]
    },
    "reflected_from_theory_index": 1,
    "type": "general",
    "version": "built-theory-from-results-single-theory-reflection2-nov14-2025-LLM-BASELINE-no-evidence-without-matched-control-theory-name",
    "theory_query": "Build a theory of how language models can be used for detecting anomalies in lists of data.",
    "original_theory_id": "theory-642",
    "original_theory_name": "Generalized Language Model Representation and Adaptation Theory for Anomaly Detection in Lists and Tabular Data",
    "provide_matched_control_thery_name": false,
    "matched_control_theory_name": null,
    "model_str": "openai/gpt-4.1-2025-04-14"
}</code></pre>
        </div>
    </div>
</body>
</html>