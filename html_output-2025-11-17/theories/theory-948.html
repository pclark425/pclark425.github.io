<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Hierarchical Episodic-Semantic Memory Theory for LLM Agents in Text Games - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-948</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-948</p>
                <p><strong>Name:</strong> Hierarchical Episodic-Semantic Memory Theory for LLM Agents in Text Games</p>
                <p><strong>Type:</strong> general</p>
                <p><strong>Theory Query:</strong> Build a theory of how LLM agents for text games can best use memory to solve text game tasks.</p>
                <p><strong>Description:</strong> This theory posits that LLM agents achieve optimal performance in text games by dynamically constructing and utilizing a hierarchical memory system, where episodic memory encodes temporally-ordered, context-rich experiences, and semantic memory abstracts generalizable knowledge, with bidirectional interaction between the two enabling both flexible adaptation and efficient planning.</p>
                <p><strong>Knowledge Cutoff Year:</strong> -1</p>
                <p><strong>Knowledge Cutoff Month:</strong> -1</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <h3>Statement 0: Hierarchical Memory Construction (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; LLM agent &#8594; engages_in &#8594; text game task</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; LLM agent &#8594; constructs &#8594; episodic memory (ordered sequence of events, actions, and observations)<span style="color: #888888;">, and</span></div>
        <div>&#8226; LLM agent &#8594; constructs &#8594; semantic memory (abstracted rules, facts, and regularities)</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Human cognition and animal learning show distinct but interacting episodic and semantic memory systems, with episodic memory supporting event recall and semantic memory supporting generalization. </li>
    <li>LLM agents with memory modules (e.g., memory-augmented transformers) outperform those without in tasks requiring long-term dependencies and generalization. </li>
    <li>Text games often require both the recall of specific past events (e.g., locations of objects) and the application of general rules (e.g., how to open a door), suggesting the need for both memory types. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> While hierarchical memory is known in neuroscience and some AI, its formalization and operationalization for LLM agents in text games, with explicit bidirectional interaction, is new.</p>            <p><strong>What Already Exists:</strong> Hierarchical memory systems are well-established in cognitive neuroscience and have been explored in AI (e.g., memory-augmented neural networks).</p>            <p><strong>What is Novel:</strong> The explicit application of a bidirectional, dynamically-constructed episodic-semantic hierarchy to LLM agents in text games, with mechanisms for abstraction and context-sensitive retrieval, is novel.</p>
            <p><strong>References:</strong> <ul>
    <li>Tulving (1972) Episodic and semantic memory [establishes distinction in human memory]</li>
    <li>Graves et al. (2016) Hybrid computing using a neural network with dynamic external memory [memory-augmented neural networks]</li>
    <li>Khandelwal et al. (2019) Generalization through Memorization: Nearest Neighbor Language Models [nearest-neighbor memory in LMs, but not hierarchical or bidirectional]</li>
</ul>
            <h3>Statement 1: Bidirectional Memory Interaction for Adaptive Planning (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; LLM agent &#8594; faces &#8594; novel or ambiguous game state<span style="color: #888888;">, and</span></div>
        <div>&#8226; LLM agent &#8594; has &#8594; hierarchical episodic-semantic memory</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; LLM agent &#8594; retrieves &#8594; relevant episodic traces<span style="color: #888888;">, and</span></div>
        <div>&#8226; LLM agent &#8594; abstracts &#8594; semantic rules from episodic traces<span style="color: #888888;">, and</span></div>
        <div>&#8226; LLM agent &#8594; applies &#8594; semantic rules to guide action selection<span style="color: #888888;">, and</span></div>
        <div>&#8226; LLM agent &#8594; updates &#8594; episodic memory with new outcomes</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Human problem-solving involves recalling specific experiences and abstracting general rules, with evidence for bidirectional flow between episodic and semantic memory. </li>
    <li>LLM agents with retrieval-augmented generation or memory replay mechanisms show improved adaptation to novel tasks and environments. </li>
    <li>Text games often present novel situations where both specific past experiences and general rules must be combined for effective planning. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> The general idea is related to existing cognitive theories, but its formalization and application to LLM agent planning in text games is new.</p>            <p><strong>What Already Exists:</strong> Bidirectional interaction between episodic and semantic memory is theorized in cognitive science, and retrieval-augmented LMs exist.</p>            <p><strong>What is Novel:</strong> The explicit operationalization of this bidirectional process for adaptive planning in LLM agents for text games, including dynamic abstraction and updating, is novel.</p>
            <p><strong>References:</strong> <ul>
    <li>Moscovitch et al. (2016) Episodic memory and beyond: The hippocampus and neocortex in transformation [bidirectional memory interaction in humans]</li>
    <li>Lewis et al. (2020) Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks [retrieval-augmented LMs, but not hierarchical or bidirectional]</li>
</ul>
            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>LLM agents equipped with both episodic and semantic memory modules, with mechanisms for abstraction and retrieval, will outperform agents with only one type of memory on text games requiring both recall of specific events and generalization.</li>
                <li>Agents that can update semantic memory based on episodic experiences will adapt more quickly to novel game mechanics or rules than agents with static semantic memory.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>If an LLM agent's episodic and semantic memory modules are allowed to interact recursively (i.e., semantic memory influences episodic encoding, and vice versa), emergent behaviors such as creative problem-solving or analogical reasoning may arise.</li>
                <li>In highly stochastic or adversarial text games, the balance between episodic and semantic memory utilization may shift dynamically, potentially leading to new forms of meta-learning.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>If agents with only episodic or only semantic memory perform equally well as those with both, the necessity of hierarchical memory is called into question.</li>
                <li>If bidirectional interaction between memory types does not improve adaptation or planning, the theory's core mechanism is challenged.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>The role of working memory or short-term context windows in LLM agents is not explicitly addressed. </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> somewhat-related-to-existing</p>
            <p><strong>Explanation:</strong> The theory synthesizes known memory architectures with novel mechanisms and application to LLM agents in text games.</p>
            <p><strong>References:</strong> <ul>
    <li>Tulving (1972) Episodic and semantic memory [episodic/semantic distinction]</li>
    <li>Graves et al. (2016) Hybrid computing using a neural network with dynamic external memory [memory-augmented neural networks]</li>
    <li>Lewis et al. (2020) Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks [retrieval-augmented LMs]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Hierarchical Episodic-Semantic Memory Theory for LLM Agents in Text Games",
    "theory_description": "This theory posits that LLM agents achieve optimal performance in text games by dynamically constructing and utilizing a hierarchical memory system, where episodic memory encodes temporally-ordered, context-rich experiences, and semantic memory abstracts generalizable knowledge, with bidirectional interaction between the two enabling both flexible adaptation and efficient planning.",
    "theory_statements": [
        {
            "law": {
                "law_name": "Hierarchical Memory Construction",
                "if": [
                    {
                        "subject": "LLM agent",
                        "relation": "engages_in",
                        "object": "text game task"
                    }
                ],
                "then": [
                    {
                        "subject": "LLM agent",
                        "relation": "constructs",
                        "object": "episodic memory (ordered sequence of events, actions, and observations)"
                    },
                    {
                        "subject": "LLM agent",
                        "relation": "constructs",
                        "object": "semantic memory (abstracted rules, facts, and regularities)"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Human cognition and animal learning show distinct but interacting episodic and semantic memory systems, with episodic memory supporting event recall and semantic memory supporting generalization.",
                        "uuids": []
                    },
                    {
                        "text": "LLM agents with memory modules (e.g., memory-augmented transformers) outperform those without in tasks requiring long-term dependencies and generalization.",
                        "uuids": []
                    },
                    {
                        "text": "Text games often require both the recall of specific past events (e.g., locations of objects) and the application of general rules (e.g., how to open a door), suggesting the need for both memory types.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Hierarchical memory systems are well-established in cognitive neuroscience and have been explored in AI (e.g., memory-augmented neural networks).",
                    "what_is_novel": "The explicit application of a bidirectional, dynamically-constructed episodic-semantic hierarchy to LLM agents in text games, with mechanisms for abstraction and context-sensitive retrieval, is novel.",
                    "classification_explanation": "While hierarchical memory is known in neuroscience and some AI, its formalization and operationalization for LLM agents in text games, with explicit bidirectional interaction, is new.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Tulving (1972) Episodic and semantic memory [establishes distinction in human memory]",
                        "Graves et al. (2016) Hybrid computing using a neural network with dynamic external memory [memory-augmented neural networks]",
                        "Khandelwal et al. (2019) Generalization through Memorization: Nearest Neighbor Language Models [nearest-neighbor memory in LMs, but not hierarchical or bidirectional]"
                    ]
                }
            }
        },
        {
            "law": {
                "law_name": "Bidirectional Memory Interaction for Adaptive Planning",
                "if": [
                    {
                        "subject": "LLM agent",
                        "relation": "faces",
                        "object": "novel or ambiguous game state"
                    },
                    {
                        "subject": "LLM agent",
                        "relation": "has",
                        "object": "hierarchical episodic-semantic memory"
                    }
                ],
                "then": [
                    {
                        "subject": "LLM agent",
                        "relation": "retrieves",
                        "object": "relevant episodic traces"
                    },
                    {
                        "subject": "LLM agent",
                        "relation": "abstracts",
                        "object": "semantic rules from episodic traces"
                    },
                    {
                        "subject": "LLM agent",
                        "relation": "applies",
                        "object": "semantic rules to guide action selection"
                    },
                    {
                        "subject": "LLM agent",
                        "relation": "updates",
                        "object": "episodic memory with new outcomes"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Human problem-solving involves recalling specific experiences and abstracting general rules, with evidence for bidirectional flow between episodic and semantic memory.",
                        "uuids": []
                    },
                    {
                        "text": "LLM agents with retrieval-augmented generation or memory replay mechanisms show improved adaptation to novel tasks and environments.",
                        "uuids": []
                    },
                    {
                        "text": "Text games often present novel situations where both specific past experiences and general rules must be combined for effective planning.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Bidirectional interaction between episodic and semantic memory is theorized in cognitive science, and retrieval-augmented LMs exist.",
                    "what_is_novel": "The explicit operationalization of this bidirectional process for adaptive planning in LLM agents for text games, including dynamic abstraction and updating, is novel.",
                    "classification_explanation": "The general idea is related to existing cognitive theories, but its formalization and application to LLM agent planning in text games is new.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Moscovitch et al. (2016) Episodic memory and beyond: The hippocampus and neocortex in transformation [bidirectional memory interaction in humans]",
                        "Lewis et al. (2020) Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks [retrieval-augmented LMs, but not hierarchical or bidirectional]"
                    ]
                }
            }
        }
    ],
    "new_predictions_likely": [
        "LLM agents equipped with both episodic and semantic memory modules, with mechanisms for abstraction and retrieval, will outperform agents with only one type of memory on text games requiring both recall of specific events and generalization.",
        "Agents that can update semantic memory based on episodic experiences will adapt more quickly to novel game mechanics or rules than agents with static semantic memory."
    ],
    "new_predictions_unknown": [
        "If an LLM agent's episodic and semantic memory modules are allowed to interact recursively (i.e., semantic memory influences episodic encoding, and vice versa), emergent behaviors such as creative problem-solving or analogical reasoning may arise.",
        "In highly stochastic or adversarial text games, the balance between episodic and semantic memory utilization may shift dynamically, potentially leading to new forms of meta-learning."
    ],
    "negative_experiments": [
        "If agents with only episodic or only semantic memory perform equally well as those with both, the necessity of hierarchical memory is called into question.",
        "If bidirectional interaction between memory types does not improve adaptation or planning, the theory's core mechanism is challenged."
    ],
    "unaccounted_for": [
        {
            "text": "The role of working memory or short-term context windows in LLM agents is not explicitly addressed.",
            "uuids": []
        }
    ],
    "conflicting_evidence": [
        {
            "text": "Some LLM agents with simple context window replay (no explicit memory module) have achieved strong performance on certain text games, suggesting that hierarchical memory may not always be necessary.",
            "uuids": []
        }
    ],
    "special_cases": [
        "In extremely simple or deterministic text games, semantic memory may suffice and episodic memory may be redundant.",
        "In games with rapidly changing rules, episodic memory may dominate due to lack of stable abstractions."
    ],
    "existing_theory": {
        "what_already_exists": "Hierarchical memory systems and episodic/semantic distinction are established in cognitive science and some AI literature.",
        "what_is_novel": "The explicit, operational theory of hierarchical, bidirectional memory for LLM agents in text games, with dynamic abstraction and updating, is new.",
        "classification_explanation": "The theory synthesizes known memory architectures with novel mechanisms and application to LLM agents in text games.",
        "likely_classification": "somewhat-related-to-existing",
        "references": [
            "Tulving (1972) Episodic and semantic memory [episodic/semantic distinction]",
            "Graves et al. (2016) Hybrid computing using a neural network with dynamic external memory [memory-augmented neural networks]",
            "Lewis et al. (2020) Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks [retrieval-augmented LMs]"
        ]
    },
    "reflected_from_theory_index": 0,
    "type": "general",
    "version": "built-theory-from-results-single-theory-reflection2-nov14-2025-LLM-BASELINE-no-evidence-without-matched-control-theory-name",
    "theory_query": "Build a theory of how LLM agents for text games can best use memory to solve text game tasks.",
    "original_theory_id": "theory-592",
    "original_theory_name": "Hybrid Memory Architecture Principle for LLM Agents",
    "provide_matched_control_thery_name": false,
    "matched_control_theory_name": null,
    "model_str": "openai/gpt-4.1-2025-04-14"
}</code></pre>
        </div>
    </div>
</body>
</html>