<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Format-Driven Reasoning Pathways Theory - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-1888</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-1888</p>
                <p><strong>Name:</strong> Format-Driven Reasoning Pathways Theory</p>
                <p><strong>Type:</strong> general</p>
                <p><strong>Theory Query:</strong> Build a theory of how problem presentation format affects LLM performance.</p>
                <p><strong>Description:</strong> This theory proposes that the format in which a problem is presented activates specific reasoning pathways within an LLM, biasing the model toward certain types of solution strategies (e.g., retrieval, stepwise reasoning, or pattern completion). The format thus acts as a control signal, shaping not only the output but the internal process by which the LLM arrives at its answer.</p>
                <p><strong>Knowledge Cutoff Year:</strong> -1</p>
                <p><strong>Knowledge Cutoff Month:</strong> -1</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <h3>Statement 0: Format-Activated Reasoning Law (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; problem_presentation_format &#8594; contains &#8594; stepwise_cues</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; LLM_reasoning_pathway &#8594; is_activated &#8594; stepwise_reasoning<span style="color: #888888;">, and</span></div>
        <div>&#8226; LLM_output &#8594; is_structured_as &#8594; stepwise_solution</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Chain-of-thought prompting leads LLMs to produce stepwise, logical solutions. </li>
    <li>Direct-answer formats elicit brief, retrieval-based responses. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> The mapping from format to internal reasoning pathway is a novel formalization.</p>            <p><strong>What Already Exists:</strong> Prompt format is known to affect the reasoning style of LLM outputs.</p>            <p><strong>What is Novel:</strong> This law formalizes the effect as a mapping from format cues to internal reasoning pathways.</p>
            <p><strong>References:</strong> <ul>
    <li>Wei et al. (2022) Chain-of-Thought Prompting Elicits Reasoning in Large Language Models [Prompt format and reasoning style]</li>
    <li>Kojima et al. (2022) Large Language Models are Zero-Shot Reasoners [Prompt cues and reasoning activation]</li>
</ul>
            <h3>Statement 1: Format-Driven Solution Bias Law (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; problem_presentation_format &#8594; contains &#8594; retrieval_cues</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; LLM_reasoning_pathway &#8594; is_activated &#8594; retrieval_based<span style="color: #888888;">, and</span></div>
        <div>&#8226; LLM_output &#8594; is_structured_as &#8594; direct_answer</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Short, direct prompts elicit brief, factoid-style answers from LLMs. </li>
    <li>Adding stepwise cues to the same problem leads to more elaborate, reasoned responses. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> The explicit mapping from format to internal solution bias is new.</p>            <p><strong>What Already Exists:</strong> Prompt cues are known to affect output style.</p>            <p><strong>What is Novel:</strong> This law frames the effect as a bias in the internal solution strategy, not just output style.</p>
            <p><strong>References:</strong> <ul>
    <li>Wei et al. (2022) Chain-of-Thought Prompting Elicits Reasoning in Large Language Models [Prompt cues and reasoning style]</li>
    <li>Kojima et al. (2022) Large Language Models are Zero-Shot Reasoners [Prompt cues and reasoning activation]</li>
</ul>
            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>If a problem is presented with explicit stepwise cues, LLMs will produce more stepwise, logical solutions.</li>
                <li>If a problem is presented in a direct-answer format, LLMs will produce shorter, less reasoned outputs.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>If a problem is presented with conflicting cues (e.g., both stepwise and direct-answer), will LLMs blend reasoning styles or default to one?</li>
                <li>If LLMs are trained to ignore format cues, can they be made format-invariant in their reasoning pathways?</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>If LLMs do not change their reasoning style in response to format cues, the theory would be challenged.</li>
                <li>If the same format elicits different reasoning pathways across repeated trials, the theory would be called into question.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>Cases where LLMs produce stepwise reasoning even in the absence of explicit cues. </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> somewhat-related-to-existing</p>
            <p><strong>Explanation:</strong> The theory is somewhat related to existing work but formalizes the mapping from format to internal reasoning pathway.</p>
            <p><strong>References:</strong> <ul>
    <li>Wei et al. (2022) Chain-of-Thought Prompting Elicits Reasoning in Large Language Models [Prompt format and reasoning style]</li>
    <li>Kojima et al. (2022) Large Language Models are Zero-Shot Reasoners [Prompt cues and reasoning activation]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Format-Driven Reasoning Pathways Theory",
    "theory_description": "This theory proposes that the format in which a problem is presented activates specific reasoning pathways within an LLM, biasing the model toward certain types of solution strategies (e.g., retrieval, stepwise reasoning, or pattern completion). The format thus acts as a control signal, shaping not only the output but the internal process by which the LLM arrives at its answer.",
    "theory_statements": [
        {
            "law": {
                "law_name": "Format-Activated Reasoning Law",
                "if": [
                    {
                        "subject": "problem_presentation_format",
                        "relation": "contains",
                        "object": "stepwise_cues"
                    }
                ],
                "then": [
                    {
                        "subject": "LLM_reasoning_pathway",
                        "relation": "is_activated",
                        "object": "stepwise_reasoning"
                    },
                    {
                        "subject": "LLM_output",
                        "relation": "is_structured_as",
                        "object": "stepwise_solution"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Chain-of-thought prompting leads LLMs to produce stepwise, logical solutions.",
                        "uuids": []
                    },
                    {
                        "text": "Direct-answer formats elicit brief, retrieval-based responses.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Prompt format is known to affect the reasoning style of LLM outputs.",
                    "what_is_novel": "This law formalizes the effect as a mapping from format cues to internal reasoning pathways.",
                    "classification_explanation": "The mapping from format to internal reasoning pathway is a novel formalization.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Wei et al. (2022) Chain-of-Thought Prompting Elicits Reasoning in Large Language Models [Prompt format and reasoning style]",
                        "Kojima et al. (2022) Large Language Models are Zero-Shot Reasoners [Prompt cues and reasoning activation]"
                    ]
                }
            }
        },
        {
            "law": {
                "law_name": "Format-Driven Solution Bias Law",
                "if": [
                    {
                        "subject": "problem_presentation_format",
                        "relation": "contains",
                        "object": "retrieval_cues"
                    }
                ],
                "then": [
                    {
                        "subject": "LLM_reasoning_pathway",
                        "relation": "is_activated",
                        "object": "retrieval_based"
                    },
                    {
                        "subject": "LLM_output",
                        "relation": "is_structured_as",
                        "object": "direct_answer"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Short, direct prompts elicit brief, factoid-style answers from LLMs.",
                        "uuids": []
                    },
                    {
                        "text": "Adding stepwise cues to the same problem leads to more elaborate, reasoned responses.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Prompt cues are known to affect output style.",
                    "what_is_novel": "This law frames the effect as a bias in the internal solution strategy, not just output style.",
                    "classification_explanation": "The explicit mapping from format to internal solution bias is new.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Wei et al. (2022) Chain-of-Thought Prompting Elicits Reasoning in Large Language Models [Prompt cues and reasoning style]",
                        "Kojima et al. (2022) Large Language Models are Zero-Shot Reasoners [Prompt cues and reasoning activation]"
                    ]
                }
            }
        }
    ],
    "new_predictions_likely": [
        "If a problem is presented with explicit stepwise cues, LLMs will produce more stepwise, logical solutions.",
        "If a problem is presented in a direct-answer format, LLMs will produce shorter, less reasoned outputs."
    ],
    "new_predictions_unknown": [
        "If a problem is presented with conflicting cues (e.g., both stepwise and direct-answer), will LLMs blend reasoning styles or default to one?",
        "If LLMs are trained to ignore format cues, can they be made format-invariant in their reasoning pathways?"
    ],
    "negative_experiments": [
        "If LLMs do not change their reasoning style in response to format cues, the theory would be challenged.",
        "If the same format elicits different reasoning pathways across repeated trials, the theory would be called into question."
    ],
    "unaccounted_for": [
        {
            "text": "Cases where LLMs produce stepwise reasoning even in the absence of explicit cues.",
            "uuids": []
        }
    ],
    "conflicting_evidence": [
        {
            "text": "Some LLMs show mixed reasoning styles regardless of format cues, especially after extensive instruction tuning.",
            "uuids": []
        }
    ],
    "special_cases": [
        "LLMs with strong instruction tuning may override format-driven reasoning biases.",
        "Highly ambiguous or contradictory formats may produce unpredictable reasoning pathways."
    ],
    "existing_theory": {
        "what_already_exists": "Prompt format is known to affect output style and reasoning.",
        "what_is_novel": "The explicit mapping from format to internal reasoning pathway is a new formalization.",
        "classification_explanation": "The theory is somewhat related to existing work but formalizes the mapping from format to internal reasoning pathway.",
        "likely_classification": "somewhat-related-to-existing",
        "references": [
            "Wei et al. (2022) Chain-of-Thought Prompting Elicits Reasoning in Large Language Models [Prompt format and reasoning style]",
            "Kojima et al. (2022) Large Language Models are Zero-Shot Reasoners [Prompt cues and reasoning activation]"
        ]
    },
    "reflected_from_theory_index": 3,
    "type": "general",
    "version": "built-theory-from-results-single-theory-reflection2-nov14-2025-LLM-BASELINE-no-evidence-without-matched-control-theory-name",
    "theory_query": "Build a theory of how problem presentation format affects LLM performance.",
    "original_theory_id": "theory-652",
    "original_theory_name": "Prompt Format as a High-Dimensional Control Signal for LLM Computation",
    "provide_matched_control_thery_name": false,
    "matched_control_theory_name": null,
    "model_str": "openai/gpt-4.1-2025-04-14"
}</code></pre>
        </div>
    </div>
</body>
</html>