<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Objective-Relevant Uncertainty Principle - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-432</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-432</p>
                <p><strong>Name:</strong> Objective-Relevant Uncertainty Principle</p>
                <p><strong>Type:</strong> specific</p>
                <p><strong>Theory Query:</strong> Build a theory of optimal resource allocation in automated scientific discovery systems, balancing computational cost of evaluation against expected information gain, probability of breakthrough discoveries, and diversity of explored hypotheses under budget constraints, based on the following results.</p>
                <p><strong>Description:</strong> For goal-driven discovery and optimization, allocating experiments to reduce objective-relevant uncertainty (uncertainty that impacts the operational objective or decision quality) is substantially more efficient than reducing generic model uncertainty. Objective-relevant uncertainty can be quantified as: (1) expected regret reduction (MOCU framework), (2) expected improvement in objective value (EI, KG), (3) expected reduction in decision error, or (4) value of information for the specific task. Methods that explicitly target objective-relevant uncertainty achieve 2-5x better sample efficiency than generic uncertainty reduction (entropy, variance maximization) in optimization and decision-making tasks. The efficiency gap is largest when: objectives are localized in the search space, the model has parameters irrelevant to the objective, or when cost-per-experiment varies. This principle unifies several successful acquisition strategies (EI, KG, MOCU, task-specific UCB) and explains why they outperform generic information-maximizing approaches in goal-driven settings.</p>
                <p><strong>Knowledge Cutoff Year:</strong> 2024</p>
                <p><strong>Knowledge Cutoff Month:</strong> 12</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <ol>
                <li>For goal-driven tasks, reducing objective-relevant uncertainty achieves 2-5x better sample efficiency than reducing generic model uncertainty</li>
                <li>Objective-relevant uncertainty is the portion of model uncertainty that impacts: (1) the operational objective value, (2) decision quality, (3) expected regret, or (4) discovery rate of targets</li>
                <li>Generic uncertainty reduction (entropy, variance) can waste 50-90% of budget on regions that don't affect the objective when objectives are localized</li>
                <li>The optimal allocation targets experiments that maximize expected reduction in objective-relevant uncertainty per unit cost</li>
                <li>Objective-relevant uncertainty can be quantified via: (1) expected regret reduction (MOCU), (2) expected improvement (EI), (3) value of information for decisions (KG), (4) expected reduction in decision error, (5) entropy about the optimum location (MES)</li>
                <li>The efficiency gap between generic and objective-relevant uncertainty reduction is largest when: (1) objectives are localized in space, (2) model has irrelevant parameters, (3) search space has irrelevant dimensions, (4) cost-per-experiment varies significantly</li>
                <li>Cost-normalization of information gain (information per unit cost) is essential for objective-relevant allocation when experiment costs vary</li>
                <li>Budget-aware lookahead (considering remaining budget when selecting experiments) naturally induces objective-relevant allocation by focusing on terminal utility</li>
                <li>For optimization tasks, uncertainty about the optimum location/value is more relevant than uncertainty about the entire function</li>
                <li>For decision tasks, uncertainty about decision-relevant parameters is more important than uncertainty about all model parameters</li>
                <li>Objective-relevant uncertainty naturally decreases as search progresses and the objective region is identified, enabling adaptive exploration-exploitation</li>
            </ol>
            <h3>Supporting Evidence</h3>
<ol>
    <li>MOCU framework quantifies objective-relevant uncertainty (expected regret) and achieves ~5x reduction in iterations vs exploitation/random in SMA example (2 iterations vs >10 for baselines) <a href="../results/extraction-result-2485.html#e2485.0" class="evidence-link">[e2485.0]</a> </li>
    <li>MOCU-based OED outperforms entropy-based selection in Kuramoto synchronization task by reducing objective-relevant uncertainty faster <a href="../results/extraction-result-2485.html#e2485.0" class="evidence-link">[e2485.0]</a> </li>
    <li>EI (expected improvement) outperforms pure variance maximization (MaxVar) by focusing on improvement-relevant uncertainty rather than global model uncertainty <a href="../results/extraction-result-2617.html#e2617.1" class="evidence-link">[e2617.1]</a> <a href="../results/extraction-result-2635.html#e2635.1" class="evidence-link">[e2635.1]</a> </li>
    <li>MaxVar (pure posterior variance) is consistently outperformed by BEACON's novelty-based acquisition which targets behavior-discovery-relevant uncertainty <a href="../results/extraction-result-2456.html#e2456.2" class="evidence-link">[e2456.2]</a> </li>
    <li>Task-specific acquisition functions in BO (EI, PI, UCB) outperform generic uncertainty sampling in optimization tasks across multiple domains <a href="../results/extraction-result-2493.html#e2493.0" class="evidence-link">[e2493.0]</a> </li>
    <li>TDUE-BO's threshold-based switching from exploration to exploitation (UCB to EI) achieves 20-38% faster convergence by focusing on task-relevant uncertainty reduction <a href="../results/extraction-result-2410.html#e2410.0" class="evidence-link">[e2410.0]</a> </li>
    <li>Cost-aware query policies that normalize information gain by action cost outperform generic information maximization, achieving ~10x reduction in travel distance for similar RMSE <a href="../results/extraction-result-2494.html#e2494.2" class="evidence-link">[e2494.2]</a> </li>
    <li>Knowledge Gradient (KG) methods that quantify value of information for decisions outperform generic exploration in ranking-and-selection problems <a href="../results/extraction-result-2595.html#e2595.1" class="evidence-link">[e2595.1]</a> <a href="../results/extraction-result-2506.html#e2506.12" class="evidence-link">[e2506.12]</a> </li>
    <li>Dual-GP observer-constrained BO that focuses on quality-relevant uncertainty (via SSI or human scores) achieves faster convergence and lower RMSE than generic GP-BO <a href="../results/extraction-result-2405.html#e2405.0" class="evidence-link">[e2405.0]</a> <a href="../results/extraction-result-2405.html#e2405.1" class="evidence-link">[e2405.1]</a> </li>
    <li>UoS (Uncertainty of Surrogate) method that balances model uncertainty with utility uncertainty outperforms pure exploration and pure exploitation <a href="../results/extraction-result-2506.html#e2506.6" class="evidence-link">[e2506.6]</a> </li>
    <li>Model Entropy (ME) combined with exploitation (PEE framework) achieves 2-4% revenue improvement over pure exploitation by targeting parameter-relevant uncertainty <a href="../results/extraction-result-2506.html#e2506.3" class="evidence-link">[e2506.3]</a> <a href="../results/extraction-result-2506.html#e2506.7" class="evidence-link">[e2506.7]</a> </li>
    <li>GP-UCB with information-theoretic regret bounds demonstrates that cumulative regret depends on information gain about the objective maximum, not generic model uncertainty <a href="../results/extraction-result-2584.html#e2584.2" class="evidence-link">[e2584.2]</a> </li>
    <li>MFMES (multifidelity max-value entropy search) that measures entropy reduction about the global minimum per unit cost outperforms methods that don't account for objective-relevance <a href="../results/extraction-result-2493.html#e2493.7" class="evidence-link">[e2493.7]</a> </li>
    <li>Review explicitly notes that entropy may not align with operational objectives and can waste budget reducing irrelevant uncertainty <a href="../results/extraction-result-2485.html#e2485.0" class="evidence-link">[e2485.0]</a> </li>
    <li>Paper contrasts MOCU (objective-aware) with entropy and predictive variance, arguing entropy can waste budget on irrelevant uncertainty <a href="../results/extraction-result-2485.html#e2485.0" class="evidence-link">[e2485.0]</a> </li>
    <li>ENS (Efficient Nonmyopic Search) budget-aware policy that maximizes expected terminal utility (expected targets found) outperforms myopic uncertainty-based policies <a href="../results/extraction-result-2496.html#e2496.1" class="evidence-link">[e2496.1]</a> </li>
</ol>            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>Learned objective-relevance functions (from meta-learning across tasks) would improve allocation efficiency by 20-40% vs hand-designed metrics by automatically identifying task-relevant features</li>
                <li>Adaptive objective-relevance weighting (changing as search progresses and objective region is identified) would outperform fixed weighting by 15-30%</li>
                <li>Multi-objective extensions of MOCU (reducing uncertainty relevant to multiple objectives simultaneously) would improve Pareto front discovery efficiency by 2-3x</li>
                <li>Objective-relevant uncertainty for safety-critical tasks (uncertainty about constraint satisfaction) would enable 30-50% more efficient safe exploration</li>
                <li>Combining objective-relevant uncertainty with diversity promotion would achieve better coverage of high-performing regions than either alone</li>
                <li>In multi-fidelity settings, allocating low-fidelity evaluations to reduce objective-relevant uncertainty would be 3-5x more efficient than uniform low-fidelity sampling</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>Whether objective-relevant uncertainty principles extend to open-ended discovery tasks without clear objectives (e.g., pure scientific exploration)</li>
                <li>Whether there exist tasks where generic uncertainty reduction is provably optimal (beyond pure model learning)</li>
                <li>Whether objective-relevant uncertainty can be effectively estimated when the objective function is unknown, noisy, or changing over time</li>
                <li>Whether the principle extends to multi-agent settings where different agents have different, potentially conflicting objectives</li>
                <li>Whether objective-relevant uncertainty can be efficiently computed for very high-dimensional objectives or complex constraint sets</li>
                <li>Whether the 2-5x efficiency gains hold in extremely high-dimensional spaces (>1000 dimensions) or with very limited budgets (<10 experiments)</li>
                <li>Whether objective-relevance can be learned online during the search without requiring prior knowledge of the objective structure</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>Finding tasks where generic uncertainty reduction consistently outperforms objective-relevant approaches would challenge the principle's generality</li>
                <li>Demonstrating that the computational cost of estimating objective-relevance outweighs the experimental savings would limit practical applicability</li>
                <li>Showing that objective-relevant and generic uncertainty are always equivalent (or nearly so) would make the distinction unnecessary</li>
                <li>Finding that random sampling performs as well as objective-relevant allocation in goal-driven tasks would undermine the theory</li>
                <li>Demonstrating that objective-relevant methods fail catastrophically when the objective is misspecified would limit robustness</li>
                <li>Finding cases where pure exploitation (ignoring all uncertainty) outperforms objective-relevant uncertainty reduction would challenge the value of uncertainty quantification</li>
                <li>Showing that the efficiency gains disappear when experiments are very cheap (computational cost dominates) would limit the scope</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>The theory doesn't fully address how to define objective-relevance for multi-objective problems with conflicting goals or unknown preference weights <a href="../results/extraction-result-2485.html#e2485.0" class="evidence-link">[e2485.0]</a> <a href="../results/extraction-result-2423.html#e2423.0" class="evidence-link">[e2423.0]</a> </li>
    <li>Optimal strategies when the objective function is learned, noisy, or changes over time need more theoretical analysis <a href="../results/extraction-result-2456.html#e2456.2" class="evidence-link">[e2456.2]</a> <a href="../results/extraction-result-2410.html#e2410.0" class="evidence-link">[e2410.0]</a> </li>
    <li>The role of model misspecification in determining objective-relevance is not fully characterized - when is the surrogate's notion of relevance trustworthy? <a href="../results/extraction-result-2485.html#e2485.0" class="evidence-link">[e2485.0]</a> <a href="../results/extraction-result-2405.html#e2405.0" class="evidence-link">[e2405.0]</a> </li>
    <li>How to balance objective-relevant uncertainty with diversity/coverage objectives in discovery tasks is not fully resolved <a href="../results/extraction-result-2456.html#e2456.2" class="evidence-link">[e2456.2]</a> <a href="../results/extraction-result-2422.html#e2422.2" class="evidence-link">[e2422.2]</a> </li>
    <li>The computational complexity of computing objective-relevant uncertainty for complex objectives is not fully analyzed <a href="../results/extraction-result-2485.html#e2485.0" class="evidence-link">[e2485.0]</a> <a href="../results/extraction-result-2493.html#e2493.7" class="evidence-link">[e2493.7]</a> </li>
    <li>How objective-relevance interacts with batch selection and parallel evaluation is not fully characterized <a href="../results/extraction-result-2622.html#e2622.0" class="evidence-link">[e2622.0]</a> <a href="../results/extraction-result-2635.html#e2635.6" class="evidence-link">[e2635.6]</a> </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> closely-related-to-existing</p>
            <p><strong>Explanation:</strong> No explanation provided.</p>
            <p><strong>References:</strong> <ul>
    <li>Frazier et al. (2009) The Knowledge-Gradient Policy for Correlated Normal Beliefs [Value of information for decisions, knowledge gradient]</li>
    <li>Hennig & Schuler (2012) Entropy Search for Information-Efficient Global Optimization [Information-theoretic BO, entropy about optimum]</li>
    <li>Russo & Van Roy (2014) Learning to Optimize via Information-Directed Sampling [Information-directed sampling, regret-information tradeoff]</li>
    <li>Settles (2009) Active Learning Literature Survey [Task-specific vs generic uncertainty in active learning]</li>
    <li>Srinivas et al. (2010) Gaussian Process Optimization in the Bandit Setting: No Regret and Experimental Design [GP-UCB, information gain bounds]</li>
    <li>Jones et al. (1998) Efficient Global Optimization of Expensive Black-Box Functions [Expected Improvement, improvement-focused allocation]</li>
    <li>Howard (1966) Information Value Theory [Value of information, decision-theoretic foundations]</li>
    <li>Mockus (1974) On Bayesian Methods for Seeking the Extremum [Bayesian optimization, objective-focused search]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Objective-Relevant Uncertainty Principle",
    "theory_description": "For goal-driven discovery and optimization, allocating experiments to reduce objective-relevant uncertainty (uncertainty that impacts the operational objective or decision quality) is substantially more efficient than reducing generic model uncertainty. Objective-relevant uncertainty can be quantified as: (1) expected regret reduction (MOCU framework), (2) expected improvement in objective value (EI, KG), (3) expected reduction in decision error, or (4) value of information for the specific task. Methods that explicitly target objective-relevant uncertainty achieve 2-5x better sample efficiency than generic uncertainty reduction (entropy, variance maximization) in optimization and decision-making tasks. The efficiency gap is largest when: objectives are localized in the search space, the model has parameters irrelevant to the objective, or when cost-per-experiment varies. This principle unifies several successful acquisition strategies (EI, KG, MOCU, task-specific UCB) and explains why they outperform generic information-maximizing approaches in goal-driven settings.",
    "supporting_evidence": [
        {
            "text": "MOCU framework quantifies objective-relevant uncertainty (expected regret) and achieves ~5x reduction in iterations vs exploitation/random in SMA example (2 iterations vs &gt;10 for baselines)",
            "uuids": [
                "e2485.0"
            ]
        },
        {
            "text": "MOCU-based OED outperforms entropy-based selection in Kuramoto synchronization task by reducing objective-relevant uncertainty faster",
            "uuids": [
                "e2485.0"
            ]
        },
        {
            "text": "EI (expected improvement) outperforms pure variance maximization (MaxVar) by focusing on improvement-relevant uncertainty rather than global model uncertainty",
            "uuids": [
                "e2617.1",
                "e2635.1"
            ]
        },
        {
            "text": "MaxVar (pure posterior variance) is consistently outperformed by BEACON's novelty-based acquisition which targets behavior-discovery-relevant uncertainty",
            "uuids": [
                "e2456.2"
            ]
        },
        {
            "text": "Task-specific acquisition functions in BO (EI, PI, UCB) outperform generic uncertainty sampling in optimization tasks across multiple domains",
            "uuids": [
                "e2493.0"
            ]
        },
        {
            "text": "TDUE-BO's threshold-based switching from exploration to exploitation (UCB to EI) achieves 20-38% faster convergence by focusing on task-relevant uncertainty reduction",
            "uuids": [
                "e2410.0"
            ]
        },
        {
            "text": "Cost-aware query policies that normalize information gain by action cost outperform generic information maximization, achieving ~10x reduction in travel distance for similar RMSE",
            "uuids": [
                "e2494.2"
            ]
        },
        {
            "text": "Knowledge Gradient (KG) methods that quantify value of information for decisions outperform generic exploration in ranking-and-selection problems",
            "uuids": [
                "e2595.1",
                "e2506.12"
            ]
        },
        {
            "text": "Dual-GP observer-constrained BO that focuses on quality-relevant uncertainty (via SSI or human scores) achieves faster convergence and lower RMSE than generic GP-BO",
            "uuids": [
                "e2405.0",
                "e2405.1"
            ]
        },
        {
            "text": "UoS (Uncertainty of Surrogate) method that balances model uncertainty with utility uncertainty outperforms pure exploration and pure exploitation",
            "uuids": [
                "e2506.6"
            ]
        },
        {
            "text": "Model Entropy (ME) combined with exploitation (PEE framework) achieves 2-4% revenue improvement over pure exploitation by targeting parameter-relevant uncertainty",
            "uuids": [
                "e2506.3",
                "e2506.7"
            ]
        },
        {
            "text": "GP-UCB with information-theoretic regret bounds demonstrates that cumulative regret depends on information gain about the objective maximum, not generic model uncertainty",
            "uuids": [
                "e2584.2"
            ]
        },
        {
            "text": "MFMES (multifidelity max-value entropy search) that measures entropy reduction about the global minimum per unit cost outperforms methods that don't account for objective-relevance",
            "uuids": [
                "e2493.7"
            ]
        },
        {
            "text": "Review explicitly notes that entropy may not align with operational objectives and can waste budget reducing irrelevant uncertainty",
            "uuids": [
                "e2485.0"
            ]
        },
        {
            "text": "Paper contrasts MOCU (objective-aware) with entropy and predictive variance, arguing entropy can waste budget on irrelevant uncertainty",
            "uuids": [
                "e2485.0"
            ]
        },
        {
            "text": "ENS (Efficient Nonmyopic Search) budget-aware policy that maximizes expected terminal utility (expected targets found) outperforms myopic uncertainty-based policies",
            "uuids": [
                "e2496.1"
            ]
        }
    ],
    "theory_statements": [
        "For goal-driven tasks, reducing objective-relevant uncertainty achieves 2-5x better sample efficiency than reducing generic model uncertainty",
        "Objective-relevant uncertainty is the portion of model uncertainty that impacts: (1) the operational objective value, (2) decision quality, (3) expected regret, or (4) discovery rate of targets",
        "Generic uncertainty reduction (entropy, variance) can waste 50-90% of budget on regions that don't affect the objective when objectives are localized",
        "The optimal allocation targets experiments that maximize expected reduction in objective-relevant uncertainty per unit cost",
        "Objective-relevant uncertainty can be quantified via: (1) expected regret reduction (MOCU), (2) expected improvement (EI), (3) value of information for decisions (KG), (4) expected reduction in decision error, (5) entropy about the optimum location (MES)",
        "The efficiency gap between generic and objective-relevant uncertainty reduction is largest when: (1) objectives are localized in space, (2) model has irrelevant parameters, (3) search space has irrelevant dimensions, (4) cost-per-experiment varies significantly",
        "Cost-normalization of information gain (information per unit cost) is essential for objective-relevant allocation when experiment costs vary",
        "Budget-aware lookahead (considering remaining budget when selecting experiments) naturally induces objective-relevant allocation by focusing on terminal utility",
        "For optimization tasks, uncertainty about the optimum location/value is more relevant than uncertainty about the entire function",
        "For decision tasks, uncertainty about decision-relevant parameters is more important than uncertainty about all model parameters",
        "Objective-relevant uncertainty naturally decreases as search progresses and the objective region is identified, enabling adaptive exploration-exploitation"
    ],
    "new_predictions_likely": [
        "Learned objective-relevance functions (from meta-learning across tasks) would improve allocation efficiency by 20-40% vs hand-designed metrics by automatically identifying task-relevant features",
        "Adaptive objective-relevance weighting (changing as search progresses and objective region is identified) would outperform fixed weighting by 15-30%",
        "Multi-objective extensions of MOCU (reducing uncertainty relevant to multiple objectives simultaneously) would improve Pareto front discovery efficiency by 2-3x",
        "Objective-relevant uncertainty for safety-critical tasks (uncertainty about constraint satisfaction) would enable 30-50% more efficient safe exploration",
        "Combining objective-relevant uncertainty with diversity promotion would achieve better coverage of high-performing regions than either alone",
        "In multi-fidelity settings, allocating low-fidelity evaluations to reduce objective-relevant uncertainty would be 3-5x more efficient than uniform low-fidelity sampling"
    ],
    "new_predictions_unknown": [
        "Whether objective-relevant uncertainty principles extend to open-ended discovery tasks without clear objectives (e.g., pure scientific exploration)",
        "Whether there exist tasks where generic uncertainty reduction is provably optimal (beyond pure model learning)",
        "Whether objective-relevant uncertainty can be effectively estimated when the objective function is unknown, noisy, or changing over time",
        "Whether the principle extends to multi-agent settings where different agents have different, potentially conflicting objectives",
        "Whether objective-relevant uncertainty can be efficiently computed for very high-dimensional objectives or complex constraint sets",
        "Whether the 2-5x efficiency gains hold in extremely high-dimensional spaces (&gt;1000 dimensions) or with very limited budgets (&lt;10 experiments)",
        "Whether objective-relevance can be learned online during the search without requiring prior knowledge of the objective structure"
    ],
    "negative_experiments": [
        "Finding tasks where generic uncertainty reduction consistently outperforms objective-relevant approaches would challenge the principle's generality",
        "Demonstrating that the computational cost of estimating objective-relevance outweighs the experimental savings would limit practical applicability",
        "Showing that objective-relevant and generic uncertainty are always equivalent (or nearly so) would make the distinction unnecessary",
        "Finding that random sampling performs as well as objective-relevant allocation in goal-driven tasks would undermine the theory",
        "Demonstrating that objective-relevant methods fail catastrophically when the objective is misspecified would limit robustness",
        "Finding cases where pure exploitation (ignoring all uncertainty) outperforms objective-relevant uncertainty reduction would challenge the value of uncertainty quantification",
        "Showing that the efficiency gains disappear when experiments are very cheap (computational cost dominates) would limit the scope"
    ],
    "unaccounted_for": [
        {
            "text": "The theory doesn't fully address how to define objective-relevance for multi-objective problems with conflicting goals or unknown preference weights",
            "uuids": [
                "e2485.0",
                "e2423.0"
            ]
        },
        {
            "text": "Optimal strategies when the objective function is learned, noisy, or changes over time need more theoretical analysis",
            "uuids": [
                "e2456.2",
                "e2410.0"
            ]
        },
        {
            "text": "The role of model misspecification in determining objective-relevance is not fully characterized - when is the surrogate's notion of relevance trustworthy?",
            "uuids": [
                "e2485.0",
                "e2405.0"
            ]
        },
        {
            "text": "How to balance objective-relevant uncertainty with diversity/coverage objectives in discovery tasks is not fully resolved",
            "uuids": [
                "e2456.2",
                "e2422.2"
            ]
        },
        {
            "text": "The computational complexity of computing objective-relevant uncertainty for complex objectives is not fully analyzed",
            "uuids": [
                "e2485.0",
                "e2493.7"
            ]
        },
        {
            "text": "How objective-relevance interacts with batch selection and parallel evaluation is not fully characterized",
            "uuids": [
                "e2622.0",
                "e2635.6"
            ]
        }
    ],
    "conflicting_evidence": [
        {
            "text": "Pure uncertainty sampling works well in some active learning tasks where the goal is model accuracy across the entire space (not localized objectives)",
            "uuids": [
                "e2412.3",
                "e2524.3"
            ]
        },
        {
            "text": "Entropy-based methods can work well in information-theoretic settings and for pure exploration tasks without specific objectives",
            "uuids": [
                "e2635.1",
                "e2493.7"
            ]
        },
        {
            "text": "MaxVar can be effective for building accurate global surrogate models when the objective is uniform coverage",
            "uuids": [
                "e2456.2"
            ]
        },
        {
            "text": "In some high-dimensional problems, generic uncertainty reduction via random sampling can be competitive with sophisticated methods due to curse of dimensionality",
            "uuids": [
                "e2608.0"
            ]
        },
        {
            "text": "For novelty search and quality-diversity tasks, generic diversity metrics can outperform objective-focused methods",
            "uuids": [
                "e2456.2",
                "e2477.1"
            ]
        }
    ],
    "special_cases": [
        "For pure model learning tasks (no specific objective, goal is accurate prediction everywhere), generic uncertainty reduction is appropriate and optimal",
        "When the objective is uniform over the space (e.g., finding all points above a threshold), objective-relevant and generic uncertainty largely coincide",
        "For safety-critical tasks, uncertainty relevant to safety constraints may be more important than objective-relevant uncertainty for performance",
        "In multi-task settings, uncertainty relevant to transfer learning may differ from single-task objective-relevance",
        "When computational cost dominates experimental cost, the overhead of computing objective-relevance may not be justified",
        "For very small budgets (&lt;5-10 experiments), the benefits of objective-relevant allocation may not materialize due to insufficient data",
        "When the objective is highly multimodal with many local optima, generic exploration may be needed initially before objective-relevance can be estimated",
        "For discovery tasks seeking diverse high-quality solutions (quality-diversity), a hybrid of objective-relevant and diversity-promoting allocation is needed",
        "When the surrogate model is severely misspecified, objective-relevance estimates may be unreliable and generic exploration may be safer",
        "In sequential decision problems with long horizons, objective-relevance must account for value of information over multiple steps (nonmyopic)"
    ],
    "existing_theory": {
        "likely_classification": "closely-related-to-existing",
        "references": [
            "Frazier et al. (2009) The Knowledge-Gradient Policy for Correlated Normal Beliefs [Value of information for decisions, knowledge gradient]",
            "Hennig & Schuler (2012) Entropy Search for Information-Efficient Global Optimization [Information-theoretic BO, entropy about optimum]",
            "Russo & Van Roy (2014) Learning to Optimize via Information-Directed Sampling [Information-directed sampling, regret-information tradeoff]",
            "Settles (2009) Active Learning Literature Survey [Task-specific vs generic uncertainty in active learning]",
            "Srinivas et al. (2010) Gaussian Process Optimization in the Bandit Setting: No Regret and Experimental Design [GP-UCB, information gain bounds]",
            "Jones et al. (1998) Efficient Global Optimization of Expensive Black-Box Functions [Expected Improvement, improvement-focused allocation]",
            "Howard (1966) Information Value Theory [Value of information, decision-theoretic foundations]",
            "Mockus (1974) On Bayesian Methods for Seeking the Extremum [Bayesian optimization, objective-focused search]"
        ]
    },
    "theory_type_general_specific": "specific",
    "reflected_from_theory_index": 6,
    "type": "specific"
}</code></pre>
        </div>
    </div>
</body>
</html>