<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Hierarchical Episodic-Semantic Memory Theory for LLM Agents in Text Games - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-978</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-978</p>
                <p><strong>Name:</strong> Hierarchical Episodic-Semantic Memory Theory for LLM Agents in Text Games</p>
                <p><strong>Type:</strong> general</p>
                <p><strong>Theory Query:</strong> Build a theory of how LLM agents for text games can best use memory to solve text game tasks.</p>
                <p><strong>Description:</strong> This theory posits that LLM agents achieve optimal performance in text games by dynamically constructing and utilizing a hierarchical memory system, where episodic memory encodes temporally ordered, context-rich experiences, and semantic memory abstracts generalizable knowledge. Bidirectional interaction between these memory types enables the agent to flexibly retrieve, update, and generalize from both, supporting efficient planning, adaptation, and task completion in complex, partially observable environments.</p>
                <p><strong>Knowledge Cutoff Year:</strong> -1</p>
                <p><strong>Knowledge Cutoff Month:</strong> -1</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <h3>Statement 0: Hierarchical Memory Construction (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; LLM agent &#8594; engages_in &#8594; text game session</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; LLM agent &#8594; constructs &#8594; episodic memory (ordered sequence of events, actions, and observations)<span style="color: #888888;">, and</span></div>
        <div>&#8226; LLM agent &#8594; constructs &#8594; semantic memory (abstracted rules, object properties, and world knowledge)</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Human cognition relies on both episodic and semantic memory for problem-solving and adaptation in narrative tasks. </li>
    <li>LLM agents with persistent memory modules outperform those with only short-term context windows in multi-step text games. </li>
    <li>Memory-augmented neural architectures (e.g., Memory Networks, Differentiable Neural Computers) show improved performance on tasks requiring long-term dependencies. </li>
    <li>Text games often require recalling both specific past events (e.g., which doors have been opened) and general rules (e.g., keys open doors). </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> While hierarchical memory is known in cognitive science and some AI, its formalization and operationalization for LLM agents in text games, especially with dynamic abstraction and bidirectional flow, is new.</p>            <p><strong>What Already Exists:</strong> Hierarchical memory systems (episodic/semantic) are well-established in cognitive science and have inspired some AI architectures.</p>            <p><strong>What is Novel:</strong> The explicit application of a dynamic, bidirectionally interacting hierarchical memory system to LLM agents in text games, with mechanisms for abstraction and generalization, is novel.</p>
            <p><strong>References:</strong> <ul>
    <li>Tulving (1972) Episodic and semantic memory [Foundational distinction in human memory]</li>
    <li>Khandelwal et al. (2019) Generalization through Memorization: Nearest Neighbor Language Models [Nearest neighbor memory in LMs]</li>
    <li>Madotto et al. (2020) Memory Grounded Conversational Reasoning [Memory-augmented dialogue agents]</li>
</ul>
            <h3>Statement 1: Bidirectional Memory Utilization for Planning and Adaptation (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; LLM agent &#8594; faces &#8594; novel or ambiguous game state<span style="color: #888888;">, and</span></div>
        <div>&#8226; LLM agent &#8594; has_access_to &#8594; episodic and semantic memory</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; LLM agent &#8594; retrieves &#8594; relevant episodic traces and semantic abstractions<span style="color: #888888;">, and</span></div>
        <div>&#8226; LLM agent &#8594; updates &#8594; semantic memory with new generalizations from episodic experiences<span style="color: #888888;">, and</span></div>
        <div>&#8226; LLM agent &#8594; adapts &#8594; future actions based on integrated memory</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Agents that can generalize from past experiences and update their knowledge base adapt more effectively to new game scenarios. </li>
    <li>Human players use both specific memories and general knowledge to solve puzzles and adapt to surprises in interactive fiction. </li>
    <li>Bidirectional interaction between episodic and semantic memory is theorized in cognitive neuroscience. </li>
    <li>LLM agents with memory-augmented architectures (e.g., ReAct, Memory Transformers) show improved adaptation and planning in text-based environments. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> The general principle is inspired by cognitive science, but its application and formalization for LLM agent memory in text games is new.</p>            <p><strong>What Already Exists:</strong> Bidirectional interaction between episodic and semantic memory is theorized in cognitive neuroscience.</p>            <p><strong>What is Novel:</strong> The explicit operationalization of this bidirectional process for LLM agents in text games, including dynamic updating and abstraction, is novel.</p>
            <p><strong>References:</strong> <ul>
    <li>McClelland et al. (1995) Why there are complementary learning systems in the hippocampus and neocortex [Bidirectional memory interaction in humans]</li>
    <li>Yao et al. (2023) ReAct: Synergizing Reasoning and Acting in Language Models [LLM agents with memory and reasoning]</li>
    <li>Shin et al. (2023) Memory in Language Models: An Empirical Study of Long-Context Learning [Empirical study of LLM memory]</li>
</ul>
            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>LLM agents with explicit hierarchical memory modules (episodic and semantic) will outperform agents with only one type of memory or with flat memory in multi-step, partially observable text games.</li>
                <li>Agents that can abstract general rules from episodic traces will adapt more quickly to novel puzzles or game mechanics than agents that only memorize past actions.</li>
                <li>Hierarchical memory agents will require fewer training episodes to reach optimal performance in games with recurring but contextually variable challenges.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>If an LLM agent's semantic memory is allowed to self-organize and restructure during gameplay, it may develop emergent strategies or concepts not present in its pretraining data.</li>
                <li>Bidirectional memory flow may enable agents to transfer knowledge across unrelated games, leading to zero-shot generalization in highly novel environments.</li>
                <li>Hierarchical memory systems may enable agents to develop meta-cognitive strategies, such as learning to learn, within the context of text games.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>If agents with only episodic or only semantic memory perform equally well as those with hierarchical memory, the theory's necessity is called into question.</li>
                <li>If bidirectional updating between episodic and semantic memory does not improve adaptation or planning, the theory's core mechanism is challenged.</li>
                <li>If hierarchical memory agents fail to outperform context-window-only agents in complex, partially observable games, the theory is undermined.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>The impact of memory corruption or forgetting on agent performance is not explicitly addressed. </li>
    <li>The role of working memory or attention mechanisms in mediating memory retrieval is not specified. </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> somewhat-related-to-existing</p>
            <p><strong>Explanation:</strong> The theory draws on cognitive science but is novel in its formalization and application to LLM agent design for text games.</p>
            <p><strong>References:</strong> <ul>
    <li>Tulving (1972) Episodic and semantic memory [Human memory systems]</li>
    <li>McClelland et al. (1995) Complementary learning systems [Bidirectional memory interaction]</li>
    <li>Khandelwal et al. (2019) Nearest Neighbor Language Models [Memory in LMs]</li>
    <li>Yao et al. (2023) ReAct [LLM agents with memory and reasoning]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Hierarchical Episodic-Semantic Memory Theory for LLM Agents in Text Games",
    "theory_description": "This theory posits that LLM agents achieve optimal performance in text games by dynamically constructing and utilizing a hierarchical memory system, where episodic memory encodes temporally ordered, context-rich experiences, and semantic memory abstracts generalizable knowledge. Bidirectional interaction between these memory types enables the agent to flexibly retrieve, update, and generalize from both, supporting efficient planning, adaptation, and task completion in complex, partially observable environments.",
    "theory_statements": [
        {
            "law": {
                "law_name": "Hierarchical Memory Construction",
                "if": [
                    {
                        "subject": "LLM agent",
                        "relation": "engages_in",
                        "object": "text game session"
                    }
                ],
                "then": [
                    {
                        "subject": "LLM agent",
                        "relation": "constructs",
                        "object": "episodic memory (ordered sequence of events, actions, and observations)"
                    },
                    {
                        "subject": "LLM agent",
                        "relation": "constructs",
                        "object": "semantic memory (abstracted rules, object properties, and world knowledge)"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Human cognition relies on both episodic and semantic memory for problem-solving and adaptation in narrative tasks.",
                        "uuids": []
                    },
                    {
                        "text": "LLM agents with persistent memory modules outperform those with only short-term context windows in multi-step text games.",
                        "uuids": []
                    },
                    {
                        "text": "Memory-augmented neural architectures (e.g., Memory Networks, Differentiable Neural Computers) show improved performance on tasks requiring long-term dependencies.",
                        "uuids": []
                    },
                    {
                        "text": "Text games often require recalling both specific past events (e.g., which doors have been opened) and general rules (e.g., keys open doors).",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Hierarchical memory systems (episodic/semantic) are well-established in cognitive science and have inspired some AI architectures.",
                    "what_is_novel": "The explicit application of a dynamic, bidirectionally interacting hierarchical memory system to LLM agents in text games, with mechanisms for abstraction and generalization, is novel.",
                    "classification_explanation": "While hierarchical memory is known in cognitive science and some AI, its formalization and operationalization for LLM agents in text games, especially with dynamic abstraction and bidirectional flow, is new.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Tulving (1972) Episodic and semantic memory [Foundational distinction in human memory]",
                        "Khandelwal et al. (2019) Generalization through Memorization: Nearest Neighbor Language Models [Nearest neighbor memory in LMs]",
                        "Madotto et al. (2020) Memory Grounded Conversational Reasoning [Memory-augmented dialogue agents]"
                    ]
                }
            }
        },
        {
            "law": {
                "law_name": "Bidirectional Memory Utilization for Planning and Adaptation",
                "if": [
                    {
                        "subject": "LLM agent",
                        "relation": "faces",
                        "object": "novel or ambiguous game state"
                    },
                    {
                        "subject": "LLM agent",
                        "relation": "has_access_to",
                        "object": "episodic and semantic memory"
                    }
                ],
                "then": [
                    {
                        "subject": "LLM agent",
                        "relation": "retrieves",
                        "object": "relevant episodic traces and semantic abstractions"
                    },
                    {
                        "subject": "LLM agent",
                        "relation": "updates",
                        "object": "semantic memory with new generalizations from episodic experiences"
                    },
                    {
                        "subject": "LLM agent",
                        "relation": "adapts",
                        "object": "future actions based on integrated memory"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Agents that can generalize from past experiences and update their knowledge base adapt more effectively to new game scenarios.",
                        "uuids": []
                    },
                    {
                        "text": "Human players use both specific memories and general knowledge to solve puzzles and adapt to surprises in interactive fiction.",
                        "uuids": []
                    },
                    {
                        "text": "Bidirectional interaction between episodic and semantic memory is theorized in cognitive neuroscience.",
                        "uuids": []
                    },
                    {
                        "text": "LLM agents with memory-augmented architectures (e.g., ReAct, Memory Transformers) show improved adaptation and planning in text-based environments.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Bidirectional interaction between episodic and semantic memory is theorized in cognitive neuroscience.",
                    "what_is_novel": "The explicit operationalization of this bidirectional process for LLM agents in text games, including dynamic updating and abstraction, is novel.",
                    "classification_explanation": "The general principle is inspired by cognitive science, but its application and formalization for LLM agent memory in text games is new.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "McClelland et al. (1995) Why there are complementary learning systems in the hippocampus and neocortex [Bidirectional memory interaction in humans]",
                        "Yao et al. (2023) ReAct: Synergizing Reasoning and Acting in Language Models [LLM agents with memory and reasoning]",
                        "Shin et al. (2023) Memory in Language Models: An Empirical Study of Long-Context Learning [Empirical study of LLM memory]"
                    ]
                }
            }
        }
    ],
    "new_predictions_likely": [
        "LLM agents with explicit hierarchical memory modules (episodic and semantic) will outperform agents with only one type of memory or with flat memory in multi-step, partially observable text games.",
        "Agents that can abstract general rules from episodic traces will adapt more quickly to novel puzzles or game mechanics than agents that only memorize past actions.",
        "Hierarchical memory agents will require fewer training episodes to reach optimal performance in games with recurring but contextually variable challenges."
    ],
    "new_predictions_unknown": [
        "If an LLM agent's semantic memory is allowed to self-organize and restructure during gameplay, it may develop emergent strategies or concepts not present in its pretraining data.",
        "Bidirectional memory flow may enable agents to transfer knowledge across unrelated games, leading to zero-shot generalization in highly novel environments.",
        "Hierarchical memory systems may enable agents to develop meta-cognitive strategies, such as learning to learn, within the context of text games."
    ],
    "negative_experiments": [
        "If agents with only episodic or only semantic memory perform equally well as those with hierarchical memory, the theory's necessity is called into question.",
        "If bidirectional updating between episodic and semantic memory does not improve adaptation or planning, the theory's core mechanism is challenged.",
        "If hierarchical memory agents fail to outperform context-window-only agents in complex, partially observable games, the theory is undermined."
    ],
    "unaccounted_for": [
        {
            "text": "The impact of memory corruption or forgetting on agent performance is not explicitly addressed.",
            "uuids": []
        },
        {
            "text": "The role of working memory or attention mechanisms in mediating memory retrieval is not specified.",
            "uuids": []
        }
    ],
    "conflicting_evidence": [
        {
            "text": "Some LLM agents with only context window memory have achieved strong performance on simple text games, suggesting hierarchical memory may not always be necessary.",
            "uuids": []
        }
    ],
    "special_cases": [
        "In extremely simple or deterministic games, hierarchical memory may provide little or no advantage.",
        "If the game world is fully observable and static, semantic abstraction may be less critical."
    ],
    "existing_theory": {
        "what_already_exists": "Hierarchical memory systems and their cognitive roles are well-studied in neuroscience and psychology, and some memory-augmented neural architectures exist.",
        "what_is_novel": "The formal, operational theory of hierarchical, bidirectionally interacting episodic-semantic memory for LLM agents in text games, with explicit mechanisms for abstraction and generalization, is new.",
        "classification_explanation": "The theory draws on cognitive science but is novel in its formalization and application to LLM agent design for text games.",
        "likely_classification": "somewhat-related-to-existing",
        "references": [
            "Tulving (1972) Episodic and semantic memory [Human memory systems]",
            "McClelland et al. (1995) Complementary learning systems [Bidirectional memory interaction]",
            "Khandelwal et al. (2019) Nearest Neighbor Language Models [Memory in LMs]",
            "Yao et al. (2023) ReAct [LLM agents with memory and reasoning]"
        ]
    },
    "reflected_from_theory_index": 0,
    "type": "general",
    "version": "built-theory-from-results-single-theory-reflection2-nov14-2025-LLM-BASELINE-no-evidence-without-matched-control-theory-name",
    "theory_query": "Build a theory of how LLM agents for text games can best use memory to solve text game tasks.",
    "original_theory_id": "theory-594",
    "original_theory_name": "Structured and Interpretable Memory Representations Enable Efficient Planning, Exploration, and Error Recovery in LLM Agents for Text Games",
    "provide_matched_control_thery_name": false,
    "matched_control_theory_name": null,
    "model_str": "openai/gpt-4.1-2025-04-14"
}</code></pre>
        </div>
    </div>
</body>
</html>