<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Observed Instruction Template Dominance in Instruction-Tuned LLMs - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-654</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-654</p>
                <p><strong>Name:</strong> Observed Instruction Template Dominance in Instruction-Tuned LLMs</p>
                <p><strong>Type:</strong> specific</p>
                <p><strong>Theory Query:</strong> Build a theory of how problem presentation format affects LLM performance, based on the following results.</p>
                <p><strong>Description:</strong> This theory asserts that for instruction-tuned LLMs, the presence of an instruction template observed during fine-tuning exerts a dominant influence on model behavior, such that even semantically-inappropriate but observed instructions can outperform semantically-correct but unobserved instructions. The model's mapping from instruction to task behavior is thus more strongly determined by template familiarity than by semantic appropriateness, especially for classification tasks. This effect is a consequence of the model's reliance on surface-form pattern matching learned during instruction tuning.</p>
                <p><strong>Knowledge Cutoff Year:</strong> 2024</p>
                <p><strong>Knowledge Cutoff Month:</strong> 6</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <h3>Statement 0: Observed Instruction Template Outperforms Unobserved Semantically-Correct Instructions (quantitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; instruction_template &#8594; was_observed &#8594; during instruction tuning<span style="color: #888888;">, and</span></div>
        <div>&#8226; instruction_template &#8594; is_semantically_inappropriate &#8594; for the current task<span style="color: #888888;">, and</span></div>
        <div>&#8226; alternative_instruction &#8594; is_semantically_correct &#8594; but unobserved during tuning</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; LLM &#8594; achieves_higher_accuracy_with &#8594; observed-inappropriate template than with unobserved-correct template</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Incorrect-but-observed instructions outperformed collected-unobserved (semantically-correct) instructions in the 'Closer Look' experiment; observed-instruction templates consistently outperformed unobserved ones across models and datasets. <a href="../results/extraction-result-5808.html#e5808.1" class="evidence-link">[e5808.1]</a> <a href="../results/extraction-result-5808.html#e5808.0" class="evidence-link">[e5808.0]</a> </li>
    <li>Aggregated averages (Table 16): Closest (observed appropriate) overall ≈ 60.45%; Incorrect (observed but inappropriate) ≈ 57.4%; Collected (novel/unobserved appropriate) ≈ 56.8%; Task Designer ≈ 56.4%; Negated ≈ 30.0%; Nonsensical ≈ 39.3%. <a href="../results/extraction-result-5808.html#e5808.1" class="evidence-link">[e5808.1]</a> </li>
    <li>Observed instructions reduce accuracy drop compared to unobserved instructions; 'unobserved instructions reduce accuracy by over five points across models' (text). Table 3 shows per-model overall drops: Flan-T5-3B Δ -3.1 pp, Alpaca-7B Δ -5.6 pp, T0++11B Δ -2.8 pp, Flan-T5-11B Δ -2.2 pp, Alpaca-13B Δ -5.2 pp. <a href="../results/extraction-result-5808.html#e5808.0" class="evidence-link">[e5808.0]</a> </li>
    <li>Instruction-tuned models implicitly rely on instruction phrasings observed during fine-tuning; semantic/representational divergence between novel and training instructions causes degradation. Classification tasks appear more sensitive. Models do not fully generalize to natural paraphrases even if semantically equivalent. <a href="../results/extraction-result-5808.html#e5808.0" class="evidence-link">[e5808.0]</a> </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: green; font-weight: bold;">new</span></p>
            <p><strong>Explanation:</strong> This is a new, empirically supported law that extends prior work on instruction tuning and prompt diversity, but makes a novel, counterintuitive prediction about the dominance of observed templates even when semantically inappropriate.</p>            <p><strong>What Already Exists:</strong> Instruction tuning and prompt diversity are known to affect generalization, and prior work has shown that models are sensitive to prompt wording and template familiarity.</p>            <p><strong>What is Novel:</strong> The explicit prediction and empirical demonstration that observed-inappropriate > unobserved-correct, and the dominance of template familiarity over semantics, is novel. The law formalizes the surface-form over semantic mapping in instruction-tuned LLMs.</p>
            <p><strong>References:</strong> <ul>
    <li>Wang et al. (2023) Evaluating the Zero-shot Robustness of Instruction-tuned Language Models [empirical basis]</li>
    <li>Mishra et al. (2022) Cross-task Generalization via Declarative Instructions [prompt diversity, but not this specific effect]</li>
</ul>
            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>If a new instruction-tuned model is evaluated on a task with an observed-inappropriate template and an unobserved-correct template, the observed-inappropriate template will yield higher accuracy.</li>
                <li>If instruction-tuning is performed with a small set of templates, the model will be brittle to novel instruction phrasings, even if semantically correct.</li>
                <li>If a model is evaluated on a classification task with a negated or nonsensical instruction that was observed during training, it will still perform better than with a semantically-correct but unobserved instruction.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>If a model is instruction-tuned with adversarially misleading templates, it may learn to perform the wrong task when those templates are used, even if the user provides a correct instruction.</li>
                <li>If a model is trained with a very large and diverse set of instruction templates, the dominance of observed-inappropriate templates may diminish, but the effect may persist for rare or edge-case tasks.</li>
                <li>If instruction-tuning is performed with both correct and incorrect templates for the same task, the model may become confused or exhibit unpredictable behavior when presented with either template.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>If a model consistently prefers semantically-correct but unobserved instructions over observed-inappropriate ones, this would falsify the theory.</li>
                <li>If the effect is not observed for generative or open-ended tasks, the theory may need to be restricted to classification or structured tasks.</li>
                <li>If increasing the diversity of instruction templates during fine-tuning eliminates the observed-inappropriate > unobserved-correct effect even for rare tasks, the theory would need to be revised.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>MMLU exhibited much smaller degradation with unobserved instructions, suggesting task/domain dependence. <a href="../results/extraction-result-5808.html#e5808.0" class="evidence-link">[e5808.0]</a> </li>
    <li>For some settings (e.g., T0++ on MMLU), unobserved instructions produced equal or slightly higher accuracy, indicating that the effect is not universal. <a href="../results/extraction-result-5808.html#e5808.0" class="evidence-link">[e5808.0]</a> </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> new</p>
            <p><strong>Explanation:</strong> This is a new, empirically supported law that extends prior work on instruction tuning and prompt diversity, but makes a novel, counterintuitive prediction about the dominance of observed templates even when semantically inappropriate.</p>
            <p><strong>References:</strong> <ul>
    <li>Wang et al. (2023) Evaluating the Zero-shot Robustness of Instruction-tuned Language Models [empirical basis]</li>
    <li>Mishra et al. (2022) Cross-task Generalization via Declarative Instructions [prompt diversity, but not this specific effect]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Observed Instruction Template Dominance in Instruction-Tuned LLMs",
    "theory_description": "This theory asserts that for instruction-tuned LLMs, the presence of an instruction template observed during fine-tuning exerts a dominant influence on model behavior, such that even semantically-inappropriate but observed instructions can outperform semantically-correct but unobserved instructions. The model's mapping from instruction to task behavior is thus more strongly determined by template familiarity than by semantic appropriateness, especially for classification tasks. This effect is a consequence of the model's reliance on surface-form pattern matching learned during instruction tuning.",
    "theory_statements": [
        {
            "law": {
                "law_name": "Observed Instruction Template Outperforms Unobserved Semantically-Correct Instructions",
                "if": [
                    {
                        "subject": "instruction_template",
                        "relation": "was_observed",
                        "object": "during instruction tuning"
                    },
                    {
                        "subject": "instruction_template",
                        "relation": "is_semantically_inappropriate",
                        "object": "for the current task"
                    },
                    {
                        "subject": "alternative_instruction",
                        "relation": "is_semantically_correct",
                        "object": "but unobserved during tuning"
                    }
                ],
                "then": [
                    {
                        "subject": "LLM",
                        "relation": "achieves_higher_accuracy_with",
                        "object": "observed-inappropriate template than with unobserved-correct template"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Incorrect-but-observed instructions outperformed collected-unobserved (semantically-correct) instructions in the 'Closer Look' experiment; observed-instruction templates consistently outperformed unobserved ones across models and datasets.",
                        "uuids": [
                            "e5808.1",
                            "e5808.0"
                        ]
                    },
                    {
                        "text": "Aggregated averages (Table 16): Closest (observed appropriate) overall ≈ 60.45%; Incorrect (observed but inappropriate) ≈ 57.4%; Collected (novel/unobserved appropriate) ≈ 56.8%; Task Designer ≈ 56.4%; Negated ≈ 30.0%; Nonsensical ≈ 39.3%.",
                        "uuids": [
                            "e5808.1"
                        ]
                    },
                    {
                        "text": "Observed instructions reduce accuracy drop compared to unobserved instructions; 'unobserved instructions reduce accuracy by over five points across models' (text). Table 3 shows per-model overall drops: Flan-T5-3B Δ -3.1 pp, Alpaca-7B Δ -5.6 pp, T0++11B Δ -2.8 pp, Flan-T5-11B Δ -2.2 pp, Alpaca-13B Δ -5.2 pp.",
                        "uuids": [
                            "e5808.0"
                        ]
                    },
                    {
                        "text": "Instruction-tuned models implicitly rely on instruction phrasings observed during fine-tuning; semantic/representational divergence between novel and training instructions causes degradation. Classification tasks appear more sensitive. Models do not fully generalize to natural paraphrases even if semantically equivalent.",
                        "uuids": [
                            "e5808.0"
                        ]
                    }
                ],
                "qual_or_quant": "quantitative",
                "existing_law": {
                    "what_already_exists": "Instruction tuning and prompt diversity are known to affect generalization, and prior work has shown that models are sensitive to prompt wording and template familiarity.",
                    "what_is_novel": "The explicit prediction and empirical demonstration that observed-inappropriate &gt; unobserved-correct, and the dominance of template familiarity over semantics, is novel. The law formalizes the surface-form over semantic mapping in instruction-tuned LLMs.",
                    "classification_explanation": "This is a new, empirically supported law that extends prior work on instruction tuning and prompt diversity, but makes a novel, counterintuitive prediction about the dominance of observed templates even when semantically inappropriate.",
                    "likely_classification": "new",
                    "references": [
                        "Wang et al. (2023) Evaluating the Zero-shot Robustness of Instruction-tuned Language Models [empirical basis]",
                        "Mishra et al. (2022) Cross-task Generalization via Declarative Instructions [prompt diversity, but not this specific effect]"
                    ]
                }
            }
        }
    ],
    "new_predictions_likely": [
        "If a new instruction-tuned model is evaluated on a task with an observed-inappropriate template and an unobserved-correct template, the observed-inappropriate template will yield higher accuracy.",
        "If instruction-tuning is performed with a small set of templates, the model will be brittle to novel instruction phrasings, even if semantically correct.",
        "If a model is evaluated on a classification task with a negated or nonsensical instruction that was observed during training, it will still perform better than with a semantically-correct but unobserved instruction."
    ],
    "new_predictions_unknown": [
        "If a model is instruction-tuned with adversarially misleading templates, it may learn to perform the wrong task when those templates are used, even if the user provides a correct instruction.",
        "If a model is trained with a very large and diverse set of instruction templates, the dominance of observed-inappropriate templates may diminish, but the effect may persist for rare or edge-case tasks.",
        "If instruction-tuning is performed with both correct and incorrect templates for the same task, the model may become confused or exhibit unpredictable behavior when presented with either template."
    ],
    "negative_experiments": [
        "If a model consistently prefers semantically-correct but unobserved instructions over observed-inappropriate ones, this would falsify the theory.",
        "If the effect is not observed for generative or open-ended tasks, the theory may need to be restricted to classification or structured tasks.",
        "If increasing the diversity of instruction templates during fine-tuning eliminates the observed-inappropriate &gt; unobserved-correct effect even for rare tasks, the theory would need to be revised."
    ],
    "unaccounted_for": [
        {
            "text": "MMLU exhibited much smaller degradation with unobserved instructions, suggesting task/domain dependence.",
            "uuids": [
                "e5808.0"
            ]
        },
        {
            "text": "For some settings (e.g., T0++ on MMLU), unobserved instructions produced equal or slightly higher accuracy, indicating that the effect is not universal.",
            "uuids": [
                "e5808.0"
            ]
        }
    ],
    "conflicting_evidence": [
        {
            "text": "For some settings (e.g., T0++ on MMLU), unobserved instructions produced equal or slightly higher accuracy, indicating that the effect is not universal.",
            "uuids": [
                "e5808.0"
            ]
        }
    ],
    "special_cases": [
        "Tasks with high semantic similarity between observed and unobserved instructions may not exhibit the effect.",
        "Generative or open-ended tasks may be less sensitive to template familiarity.",
        "If the unobserved instruction is nearly identical in surface form to an observed template, the effect may be minimal or absent.",
        "Instruction-tuned models with extremely broad and diverse template coverage may show reduced or eliminated template-dominance effects."
    ],
    "existing_theory": {
        "what_already_exists": "Instruction tuning and prompt diversity are known to affect generalization, and prior work has shown that models are sensitive to prompt wording and template familiarity.",
        "what_is_novel": "The explicit law that observed-inappropriate &gt; unobserved-correct, and the dominance of template familiarity over semantics, is new. The theory formalizes and predicts a counterintuitive effect not previously articulated.",
        "classification_explanation": "This is a new, empirically supported law that extends prior work on instruction tuning and prompt diversity, but makes a novel, counterintuitive prediction about the dominance of observed templates even when semantically inappropriate.",
        "likely_classification": "new",
        "references": [
            "Wang et al. (2023) Evaluating the Zero-shot Robustness of Instruction-tuned Language Models [empirical basis]",
            "Mishra et al. (2022) Cross-task Generalization via Declarative Instructions [prompt diversity, but not this specific effect]"
        ]
    },
    "reflected_from_theory_index": 2,
    "version": "built-theory-from-results-single-theory-reflection2-nov14-2025",
    "type": "specific"
}</code></pre>
        </div>
    </div>
</body>
</html>