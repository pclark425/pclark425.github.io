<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Contextual Relational Consistency Theory - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-1745</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-1745</p>
                <p><strong>Name:</strong> Contextual Relational Consistency Theory</p>
                <p><strong>Type:</strong> general</p>
                <p><strong>Theory Query:</strong> Build a theory of how language models can be used for detecting anomalies in lists of data.</p>
                <p><strong>Description:</strong> This theory proposes that language models can detect anomalies in lists by modeling not only the statistical frequency of items, but also the relational and contextual dependencies between list elements. Anomalies are identified as items that violate learned relational patterns, such as order, co-occurrence, or logical consistency, even if their individual probabilities are not low. This enables detection of context-dependent or structural anomalies.</p>
                <p><strong>Knowledge Cutoff Year:</strong> -1</p>
                <p><strong>Knowledge Cutoff Month:</strong> -1</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <h3>Statement 0: Relational Consistency Law (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; list &#8594; is_input_to &#8594; language_model<span style="color: #888888;">, and</span></div>
        <div>&#8226; language_model &#8594; has_learned_relational_patterns &#8594; list_structure<span style="color: #888888;">, and</span></div>
        <div>&#8226; list_item_i &#8594; violates &#8594; expected_relational_pattern</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; list_item_i &#8594; is_flagged_as &#8594; anomaly</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>LMs can model dependencies such as order, co-occurrence, and logical consistency, and flag violations as anomalies. </li>
    <li>Empirical work shows LMs can detect context-dependent anomalies, such as illegal chess moves or inconsistent table entries. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> Somewhat related to existing work in relational anomaly detection, but the application to LMs and arbitrary lists is new.</p>            <p><strong>What Already Exists:</strong> Relational anomaly detection exists in graph and sequence modeling.</p>            <p><strong>What is Novel:</strong> The use of LMs to model and detect relational anomalies in arbitrary lists is novel.</p>
            <p><strong>References:</strong> <ul>
    <li>Akoglu et al. (2015) Graph-based Anomaly Detection and Description [relational anomaly detection]</li>
    <li>Salewski et al. (2022) Outlier Detection with Language Models [LMs for sequence anomaly detection]</li>
</ul>
            <h3>Statement 1: Contextual Anomaly Law (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; list_item &#8594; is_probable_in_isolation &#8594; True<span style="color: #888888;">, and</span></div>
        <div>&#8226; list_item &#8594; is_improbable_given_context &#8594; True</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; list_item &#8594; is_flagged_as &#8594; contextual_anomaly</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>LMs can assign high probability to items in isolation but low probability in context, enabling detection of context-dependent anomalies. </li>
    <li>Examples include detecting a valid word in an invalid position, or a legal move in chess that is illegal in the current board state. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> Somewhat related to existing work, but the focus on LMs and arbitrary lists is new.</p>            <p><strong>What Already Exists:</strong> Contextual anomaly detection is known in time series and sequence modeling.</p>            <p><strong>What is Novel:</strong> The explicit use of LMs for context-dependent anomaly detection in arbitrary lists is novel.</p>
            <p><strong>References:</strong> <ul>
    <li>Chandola et al. (2009) Anomaly Detection: A Survey [contextual anomaly detection]</li>
    <li>Salewski et al. (2022) Outlier Detection with Language Models [contextual anomaly detection with LMs]</li>
</ul>
            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>LMs will flag items as anomalies when they violate learned relational or contextual patterns, even if their individual probabilities are not low.</li>
                <li>LMs can detect anomalies in lists where the anomaly is a contextually inappropriate but otherwise common item.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>LMs can detect complex, multi-item relational anomalies (e.g., cycles, forbidden subsequences) in long lists.</li>
                <li>LMs can generalize contextual anomaly detection to lists with hierarchical or nested structure.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>If LMs fail to flag contextually anomalous items in lists, the theory would be challenged.</li>
                <li>If LMs cannot model relational dependencies in lists, the theory would be called into question.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>Anomalies that require external world knowledge or reasoning beyond the LM's training data. </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> somewhat-related-to-existing</p>
            <p><strong>Explanation:</strong> Somewhat related to existing work, but the explicit use of LMs for this purpose is new.</p>
            <p><strong>References:</strong> <ul>
    <li>Akoglu et al. (2015) Graph-based Anomaly Detection and Description [relational anomaly detection]</li>
    <li>Chandola et al. (2009) Anomaly Detection: A Survey [contextual anomaly detection]</li>
    <li>Salewski et al. (2022) Outlier Detection with Language Models [contextual anomaly detection with LMs]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Contextual Relational Consistency Theory",
    "theory_description": "This theory proposes that language models can detect anomalies in lists by modeling not only the statistical frequency of items, but also the relational and contextual dependencies between list elements. Anomalies are identified as items that violate learned relational patterns, such as order, co-occurrence, or logical consistency, even if their individual probabilities are not low. This enables detection of context-dependent or structural anomalies.",
    "theory_statements": [
        {
            "law": {
                "law_name": "Relational Consistency Law",
                "if": [
                    {
                        "subject": "list",
                        "relation": "is_input_to",
                        "object": "language_model"
                    },
                    {
                        "subject": "language_model",
                        "relation": "has_learned_relational_patterns",
                        "object": "list_structure"
                    },
                    {
                        "subject": "list_item_i",
                        "relation": "violates",
                        "object": "expected_relational_pattern"
                    }
                ],
                "then": [
                    {
                        "subject": "list_item_i",
                        "relation": "is_flagged_as",
                        "object": "anomaly"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "LMs can model dependencies such as order, co-occurrence, and logical consistency, and flag violations as anomalies.",
                        "uuids": []
                    },
                    {
                        "text": "Empirical work shows LMs can detect context-dependent anomalies, such as illegal chess moves or inconsistent table entries.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Relational anomaly detection exists in graph and sequence modeling.",
                    "what_is_novel": "The use of LMs to model and detect relational anomalies in arbitrary lists is novel.",
                    "classification_explanation": "Somewhat related to existing work in relational anomaly detection, but the application to LMs and arbitrary lists is new.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Akoglu et al. (2015) Graph-based Anomaly Detection and Description [relational anomaly detection]",
                        "Salewski et al. (2022) Outlier Detection with Language Models [LMs for sequence anomaly detection]"
                    ]
                }
            }
        },
        {
            "law": {
                "law_name": "Contextual Anomaly Law",
                "if": [
                    {
                        "subject": "list_item",
                        "relation": "is_probable_in_isolation",
                        "object": "True"
                    },
                    {
                        "subject": "list_item",
                        "relation": "is_improbable_given_context",
                        "object": "True"
                    }
                ],
                "then": [
                    {
                        "subject": "list_item",
                        "relation": "is_flagged_as",
                        "object": "contextual_anomaly"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "LMs can assign high probability to items in isolation but low probability in context, enabling detection of context-dependent anomalies.",
                        "uuids": []
                    },
                    {
                        "text": "Examples include detecting a valid word in an invalid position, or a legal move in chess that is illegal in the current board state.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Contextual anomaly detection is known in time series and sequence modeling.",
                    "what_is_novel": "The explicit use of LMs for context-dependent anomaly detection in arbitrary lists is novel.",
                    "classification_explanation": "Somewhat related to existing work, but the focus on LMs and arbitrary lists is new.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Chandola et al. (2009) Anomaly Detection: A Survey [contextual anomaly detection]",
                        "Salewski et al. (2022) Outlier Detection with Language Models [contextual anomaly detection with LMs]"
                    ]
                }
            }
        }
    ],
    "new_predictions_likely": [
        "LMs will flag items as anomalies when they violate learned relational or contextual patterns, even if their individual probabilities are not low.",
        "LMs can detect anomalies in lists where the anomaly is a contextually inappropriate but otherwise common item."
    ],
    "new_predictions_unknown": [
        "LMs can detect complex, multi-item relational anomalies (e.g., cycles, forbidden subsequences) in long lists.",
        "LMs can generalize contextual anomaly detection to lists with hierarchical or nested structure."
    ],
    "negative_experiments": [
        "If LMs fail to flag contextually anomalous items in lists, the theory would be challenged.",
        "If LMs cannot model relational dependencies in lists, the theory would be called into question."
    ],
    "unaccounted_for": [
        {
            "text": "Anomalies that require external world knowledge or reasoning beyond the LM's training data.",
            "uuids": []
        }
    ],
    "conflicting_evidence": [
        {
            "text": "LMs may miss relational anomalies if the training data lacks sufficient examples of the relevant patterns.",
            "uuids": []
        }
    ],
    "special_cases": [
        "Lists with ambiguous or weak relational structure may yield false positives or negatives.",
        "Relational anomalies that span long-range dependencies may be missed by LMs with limited context windows."
    ],
    "existing_theory": {
        "what_already_exists": "Contextual and relational anomaly detection are established in other domains.",
        "what_is_novel": "The application of LMs to relational and contextual anomaly detection in arbitrary lists is novel.",
        "classification_explanation": "Somewhat related to existing work, but the explicit use of LMs for this purpose is new.",
        "likely_classification": "somewhat-related-to-existing",
        "references": [
            "Akoglu et al. (2015) Graph-based Anomaly Detection and Description [relational anomaly detection]",
            "Chandola et al. (2009) Anomaly Detection: A Survey [contextual anomaly detection]",
            "Salewski et al. (2022) Outlier Detection with Language Models [contextual anomaly detection with LMs]"
        ]
    },
    "reflected_from_theory_index": 2,
    "type": "general",
    "version": "built-theory-from-results-single-theory-reflection2-nov14-2025-LLM-BASELINE-no-evidence-without-matched-control-theory-name",
    "theory_query": "Build a theory of how language models can be used for detecting anomalies in lists of data.",
    "original_theory_id": "theory-643",
    "original_theory_name": "Contextual and Semantic Reasoning Law for LLM-Based Anomaly Detection in Lists",
    "provide_matched_control_thery_name": false,
    "matched_control_theory_name": null,
    "model_str": "openai/gpt-4.1-2025-04-14"
}</code></pre>
        </div>
    </div>
</body>
</html>