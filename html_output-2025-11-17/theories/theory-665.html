<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LLM-SR Programmatic Equation Discovery Law - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-665</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-665</p>
                <p><strong>Name:</strong> LLM-SR Programmatic Equation Discovery Law</p>
                <p><strong>Type:</strong> specific</p>
                <p><strong>Theory Query:</strong> Build a theory of how large language models (LLMs) can be used to distill quantitative laws from large numbers of scholarly input papers, based on the following results.</p>
                <p><strong>Description:</strong> This theory asserts that representing candidate scientific equations as executable programs (e.g., Python code skeletons) and leveraging LLMs to generate and document these programmatic representations, followed by external parameter optimization and fitness evaluation, enables the efficient discovery of interpretable, high-fidelity symbolic equations from data. The iterative use of an experience buffer (in-context examples) further accelerates convergence and improves generalization, especially in out-of-domain (OOD) settings. The approach is robust across multiple scientific domains, but its effectiveness depends on the validity of generated code, the diversity of in-context examples, and the absence of direct memorization from pretraining data.</p>
                <p><strong>Knowledge Cutoff Year:</strong> 2024</p>
                <p><strong>Knowledge Cutoff Month:</strong> 6</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <h3>Statement 0: Programmatic Equation Generation and Optimization Law (quantitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; LLM &#8594; is_prompted_to &#8594; generate programmatic equation skeletons with placeholders<span style="color: #888888;">, and</span></div>
        <div>&#8226; external_optimizer &#8594; can_optimize &#8594; numeric parameters in generated code<span style="color: #888888;">, and</span></div>
        <div>&#8226; experience_buffer &#8594; stores &#8594; high-scoring programmatic equations as in-context examples</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; LLM+optimizer+buffer system &#8594; can_discover &#8594; interpretable, high-fidelity symbolic equations that generalize to OOD data</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>LLM-SR (GPT-3.5 and Mixtral) discovered equations with substantially lower NMSE than baselines across four benchmarks, with strong OOD generalization and rapid convergence. <a href="../results/extraction-result-5880.html#e5880.0" class="evidence-link">[e5880.0]</a> </li>
    <li>LLM-SR uses LLMs to generate programmatic equation skeletons (Python code with placeholders), which are then optimized for numeric parameters using external optimizers (numpy+BFGS or torch+Adam), and high-scoring skeletons are stored in an experience buffer for in-context prompting. <a href="../results/extraction-result-5880.html#e5880.0" class="evidence-link">[e5880.0]</a> </li>
    <li>The approach outperformed multiple symbolic regression baselines (PySR, uDSR, DSR, NeSymReS, E2E, GPlearn) in both in-domain and OOD settings, with much lower normalized MSE and higher sample efficiency. <a href="../results/extraction-result-5880.html#e5880.0" class="evidence-link">[e5880.0]</a> </li>
    <li>The experience buffer, which stores high-scoring programmatic equations as in-context examples, accelerates convergence and improves the quality of discovered equations. <a href="../results/extraction-result-5880.html#e5880.0" class="evidence-link">[e5880.0]</a> </li>
    <li>The method is robust across multiple scientific domains, including nonlinear oscillators, E. coli growth, and experimental stress-strain data. <a href="../results/extraction-result-5880.html#e5880.0" class="evidence-link">[e5880.0]</a> </li>
    <li>The approach is sensitive to the validity of LLM-generated code; invalid or non-executable code can undermine the process. <a href="../results/extraction-result-5880.html#e5880.0" class="evidence-link">[e5880.0]</a> </li>
    <li>If the LLM's pretraining corpus contains the target equation verbatim, the system may recite rather than discover, which is a limitation noted in the evidence. <a href="../results/extraction-result-5880.html#e5880.1" class="evidence-link">[e5880.1]</a> </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> While symbolic regression and code generation exist, the LLM-driven, programmatic, and buffer-augmented approach for scientific law discovery, as exemplified by LLM-SR, is a new paradigm that leverages LLMs' generative and in-context learning capabilities in a closed-loop with external optimization.</p>            <p><strong>What Already Exists:</strong> Symbolic regression, program synthesis, and code generation are established; LLMs have been used for code generation and symbolic regression in prior work.</p>            <p><strong>What is Novel:</strong> The explicit use of LLMs to generate programmatic equation skeletons, combined with an experience buffer and external parameter optimization, for efficient, interpretable equation discovery with strong OOD generalization is novel.</p>
            <p><strong>References:</strong> <ul>
    <li>Valipour et al. (2024) LLM-SR: Scientific Equation Discovery via Programming with Large Language Models [LLM+program synthesis+external evaluation]</li>
    <li>SymbolicGPT (2023) SymbolicGPT: A generative transformer model for symbolic regression [related, but does not use programmatic skeletons with buffer-augmented in-context learning]</li>
    <li>AI Feynman 2.0 (2023) AI Feynman 2.0: Pareto-optimal symbolic regression exploiting graph modularity [classical symbolic regression, not LLM-driven or programmatic]</li>
</ul>
            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>Applying the LLM-SR programmatic approach to new scientific domains (e.g., epidemiology, ecology) will yield interpretable equations that outperform classical symbolic regression baselines in both in-domain and OOD generalization.</li>
                <li>Increasing the diversity and quality of in-context examples in the experience buffer will accelerate convergence and improve the quality of discovered equations.</li>
                <li>The approach will remain robust as long as the LLM can generate valid, executable code and the external optimizer can efficiently optimize parameters.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>The LLM-SR approach may discover fundamentally new forms of equations or mechanisms in domains where human intuition is limited, potentially leading to new scientific insights.</li>
                <li>The programmatic representation may enable the discovery of hybrid symbolic-numeric laws that are not easily expressible in closed-form equations.</li>
                <li>In domains with highly non-differentiable or non-programmable relationships, the approach may fail or require significant adaptation.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>If the LLM-SR approach fails to outperform classical symbolic regression baselines in accuracy or generalization across diverse domains, the theory would be undermined.</li>
                <li>If the experience buffer does not improve convergence or generalization, the buffer-augmented law is called into question.</li>
                <li>If LLM-generated code is frequently invalid or non-executable, or if parameter optimization fails due to poor code structure, the approach may not yield interpretable or accurate equations.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>Direct extraction of empirical rules or features from literature or data without programmatic representation, as in LLM4SD or literature-synthesized rule pipelines. <a href="../results/extraction-result-5980.html#e5980.0" class="evidence-link">[e5980.0]</a> <a href="../results/extraction-result-5980.html#e5980.1" class="evidence-link">[e5980.1]</a> </li>
    <li>Approaches that use LLMs for knowledge synthesis, feature extraction, or hypothesis generation from literature without explicit programmatic equation generation (e.g., Galactica, LLM4SD, LLMs for knowledge synthesis in chemistry). <a href="../results/extraction-result-5980.html#e5980.1" class="evidence-link">[e5980.1]</a> <a href="../results/extraction-result-5879.html#e5879.3" class="evidence-link">[e5879.3]</a> <a href="../results/extraction-result-5974.html#e5974.0" class="evidence-link">[e5974.0]</a> <a href="../results/extraction-result-5974.html#e5974.1" class="evidence-link">[e5974.1]</a> </li>
    <li>Classical symbolic regression and program synthesis methods that do not use LLMs or experience buffers (e.g., AI Feynman 2.0, BACON, Langley 1981, ProGED). <a href="../results/extraction-result-5881.html#e5881.4" class="evidence-link">[e5881.4]</a> <a href="../results/extraction-result-5942.html#e5942.0" class="evidence-link">[e5942.0]</a> <a href="../results/extraction-result-5942.html#e5942.1" class="evidence-link">[e5942.1]</a> <a href="../results/extraction-result-5981.html#e5981.6" class="evidence-link">[e5981.6]</a> </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> somewhat-related-to-existing</p>
            <p><strong>Explanation:</strong> This theory formalizes a new, LLM-centric paradigm for programmatic equation discovery, as exemplified by LLM-SR, which is distinct from classical symbolic regression and prior LLM-based approaches that do not use programmatic skeletons or experience buffers.</p>
            <p><strong>References:</strong> <ul>
    <li>Valipour et al. (2024) LLM-SR: Scientific Equation Discovery via Programming with Large Language Models [LLM+program synthesis+external evaluation]</li>
    <li>SymbolicGPT (2023) SymbolicGPT: A generative transformer model for symbolic regression [related, but does not use programmatic skeletons with buffer-augmented in-context learning]</li>
    <li>AI Feynman 2.0 (2023) AI Feynman 2.0: Pareto-optimal symbolic regression exploiting graph modularity [classical symbolic regression, not LLM-driven or programmatic]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "LLM-SR Programmatic Equation Discovery Law",
    "theory_description": "This theory asserts that representing candidate scientific equations as executable programs (e.g., Python code skeletons) and leveraging LLMs to generate and document these programmatic representations, followed by external parameter optimization and fitness evaluation, enables the efficient discovery of interpretable, high-fidelity symbolic equations from data. The iterative use of an experience buffer (in-context examples) further accelerates convergence and improves generalization, especially in out-of-domain (OOD) settings. The approach is robust across multiple scientific domains, but its effectiveness depends on the validity of generated code, the diversity of in-context examples, and the absence of direct memorization from pretraining data.",
    "theory_statements": [
        {
            "law": {
                "law_name": "Programmatic Equation Generation and Optimization Law",
                "if": [
                    {
                        "subject": "LLM",
                        "relation": "is_prompted_to",
                        "object": "generate programmatic equation skeletons with placeholders"
                    },
                    {
                        "subject": "external_optimizer",
                        "relation": "can_optimize",
                        "object": "numeric parameters in generated code"
                    },
                    {
                        "subject": "experience_buffer",
                        "relation": "stores",
                        "object": "high-scoring programmatic equations as in-context examples"
                    }
                ],
                "then": [
                    {
                        "subject": "LLM+optimizer+buffer system",
                        "relation": "can_discover",
                        "object": "interpretable, high-fidelity symbolic equations that generalize to OOD data"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "LLM-SR (GPT-3.5 and Mixtral) discovered equations with substantially lower NMSE than baselines across four benchmarks, with strong OOD generalization and rapid convergence.",
                        "uuids": [
                            "e5880.0"
                        ]
                    },
                    {
                        "text": "LLM-SR uses LLMs to generate programmatic equation skeletons (Python code with placeholders), which are then optimized for numeric parameters using external optimizers (numpy+BFGS or torch+Adam), and high-scoring skeletons are stored in an experience buffer for in-context prompting.",
                        "uuids": [
                            "e5880.0"
                        ]
                    },
                    {
                        "text": "The approach outperformed multiple symbolic regression baselines (PySR, uDSR, DSR, NeSymReS, E2E, GPlearn) in both in-domain and OOD settings, with much lower normalized MSE and higher sample efficiency.",
                        "uuids": [
                            "e5880.0"
                        ]
                    },
                    {
                        "text": "The experience buffer, which stores high-scoring programmatic equations as in-context examples, accelerates convergence and improves the quality of discovered equations.",
                        "uuids": [
                            "e5880.0"
                        ]
                    },
                    {
                        "text": "The method is robust across multiple scientific domains, including nonlinear oscillators, E. coli growth, and experimental stress-strain data.",
                        "uuids": [
                            "e5880.0"
                        ]
                    },
                    {
                        "text": "The approach is sensitive to the validity of LLM-generated code; invalid or non-executable code can undermine the process.",
                        "uuids": [
                            "e5880.0"
                        ]
                    },
                    {
                        "text": "If the LLM's pretraining corpus contains the target equation verbatim, the system may recite rather than discover, which is a limitation noted in the evidence.",
                        "uuids": [
                            "e5880.1"
                        ]
                    }
                ],
                "qual_or_quant": "quantitative",
                "existing_law": {
                    "what_already_exists": "Symbolic regression, program synthesis, and code generation are established; LLMs have been used for code generation and symbolic regression in prior work.",
                    "what_is_novel": "The explicit use of LLMs to generate programmatic equation skeletons, combined with an experience buffer and external parameter optimization, for efficient, interpretable equation discovery with strong OOD generalization is novel.",
                    "classification_explanation": "While symbolic regression and code generation exist, the LLM-driven, programmatic, and buffer-augmented approach for scientific law discovery, as exemplified by LLM-SR, is a new paradigm that leverages LLMs' generative and in-context learning capabilities in a closed-loop with external optimization.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Valipour et al. (2024) LLM-SR: Scientific Equation Discovery via Programming with Large Language Models [LLM+program synthesis+external evaluation]",
                        "SymbolicGPT (2023) SymbolicGPT: A generative transformer model for symbolic regression [related, but does not use programmatic skeletons with buffer-augmented in-context learning]",
                        "AI Feynman 2.0 (2023) AI Feynman 2.0: Pareto-optimal symbolic regression exploiting graph modularity [classical symbolic regression, not LLM-driven or programmatic]"
                    ]
                }
            }
        }
    ],
    "new_predictions_likely": [
        "Applying the LLM-SR programmatic approach to new scientific domains (e.g., epidemiology, ecology) will yield interpretable equations that outperform classical symbolic regression baselines in both in-domain and OOD generalization.",
        "Increasing the diversity and quality of in-context examples in the experience buffer will accelerate convergence and improve the quality of discovered equations.",
        "The approach will remain robust as long as the LLM can generate valid, executable code and the external optimizer can efficiently optimize parameters."
    ],
    "new_predictions_unknown": [
        "The LLM-SR approach may discover fundamentally new forms of equations or mechanisms in domains where human intuition is limited, potentially leading to new scientific insights.",
        "The programmatic representation may enable the discovery of hybrid symbolic-numeric laws that are not easily expressible in closed-form equations.",
        "In domains with highly non-differentiable or non-programmable relationships, the approach may fail or require significant adaptation."
    ],
    "negative_experiments": [
        "If the LLM-SR approach fails to outperform classical symbolic regression baselines in accuracy or generalization across diverse domains, the theory would be undermined.",
        "If the experience buffer does not improve convergence or generalization, the buffer-augmented law is called into question.",
        "If LLM-generated code is frequently invalid or non-executable, or if parameter optimization fails due to poor code structure, the approach may not yield interpretable or accurate equations."
    ],
    "unaccounted_for": [
        {
            "text": "Direct extraction of empirical rules or features from literature or data without programmatic representation, as in LLM4SD or literature-synthesized rule pipelines.",
            "uuids": [
                "e5980.0",
                "e5980.1"
            ]
        },
        {
            "text": "Approaches that use LLMs for knowledge synthesis, feature extraction, or hypothesis generation from literature without explicit programmatic equation generation (e.g., Galactica, LLM4SD, LLMs for knowledge synthesis in chemistry).",
            "uuids": [
                "e5980.1",
                "e5879.3",
                "e5974.0",
                "e5974.1"
            ]
        },
        {
            "text": "Classical symbolic regression and program synthesis methods that do not use LLMs or experience buffers (e.g., AI Feynman 2.0, BACON, Langley 1981, ProGED).",
            "uuids": [
                "e5881.4",
                "e5942.0",
                "e5942.1",
                "e5981.6"
            ]
        }
    ],
    "conflicting_evidence": [
        {
            "text": "If LLM-generated code is invalid or non-executable, or if parameter optimization fails due to poor code structure, the approach may not yield interpretable or accurate equations.",
            "uuids": [
                "e5880.0"
            ]
        },
        {
            "text": "If the LLM's pretraining corpus contains the target equation verbatim, the system may recite rather than discover, which undermines claims of genuine discovery.",
            "uuids": [
                "e5880.1",
                "e5981.0"
            ]
        }
    ],
    "special_cases": [
        "Domains with highly non-differentiable or non-programmable relationships may not benefit from programmatic equation representation.",
        "If the LLM's pretraining corpus contains the target equation verbatim, the system may recite rather than discover.",
        "The approach may be less effective in domains where the mapping from data to symbolic law is not easily expressible in code or where external optimization is intractable."
    ],
    "existing_theory": {
        "what_already_exists": "Symbolic regression, program synthesis, and code generation are established; LLMs have been used for code generation and symbolic regression in prior work.",
        "what_is_novel": "The LLM-driven, programmatic, and buffer-augmented approach for efficient, interpretable scientific law discovery with strong OOD generalization is novel.",
        "classification_explanation": "This theory formalizes a new, LLM-centric paradigm for programmatic equation discovery, as exemplified by LLM-SR, which is distinct from classical symbolic regression and prior LLM-based approaches that do not use programmatic skeletons or experience buffers.",
        "likely_classification": "somewhat-related-to-existing",
        "references": [
            "Valipour et al. (2024) LLM-SR: Scientific Equation Discovery via Programming with Large Language Models [LLM+program synthesis+external evaluation]",
            "SymbolicGPT (2023) SymbolicGPT: A generative transformer model for symbolic regression [related, but does not use programmatic skeletons with buffer-augmented in-context learning]",
            "AI Feynman 2.0 (2023) AI Feynman 2.0: Pareto-optimal symbolic regression exploiting graph modularity [classical symbolic regression, not LLM-driven or programmatic]"
        ]
    },
    "theory_type_general_specific": "specific",
    "reflected_from_theory_index": 2,
    "version": "built-theory-from-results-single-theory-reflection2-nov14-2025",
    "type": "specific"
}</code></pre>
        </div>
    </div>
</body>
</html>