<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Unified Language Model Representation Theory for Anomaly Detection in Lists and Sequences - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-644</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-644</p>
                <p><strong>Name:</strong> Unified Language Model Representation Theory for Anomaly Detection in Lists and Sequences</p>
                <p><strong>Type:</strong> general</p>
                <p><strong>Theory Query:</strong> Build a theory of how language models can be used for detecting anomalies in lists of data, based on the following results.</p>
                <p><strong>Description:</strong> This theory posits that large language models (LLMs), when provided with serialized representations of structured data (lists, tables, sequences), can serve as universal anomaly detectors by leveraging their pre-trained knowledge of statistical, syntactic, and semantic regularities. The LLM's ability to model context, token dependencies, and distributional density enables detection of a wide range of anomaly types (point, contextual, sequential, semantic) across diverse data modalities (tabular, time series, logs, categorical lists) without explicit feature engineering or domain-specific adaptation. The theory further asserts that the effectiveness of LLM-based anomaly detection is modulated by the alignment between the data serialization, the LLM's pretraining domain, and the anomaly's manifestation in the serialized context.</p>
                <p><strong>Knowledge Cutoff Year:</strong> 2024</p>
                <p><strong>Knowledge Cutoff Month:</strong> 6</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <h3>Statement 0: LLM Contextual Density Law (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; data_list &#8594; is_serialized_to_text &#8594; LLM_input<span style="color: #888888;">, and</span></div>
        <div>&#8226; LLM &#8594; is_prompted_with &#8594; LLM_input</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; LLM &#8594; assigns_lower_likelihood &#8594; outlier_elements_in_data_list<span style="color: #888888;">, and</span></div>
        <div>&#8226; LLM &#8594; can_flag &#8594; anomalous_elements_by_low_likelihood</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>LLMs (GPT-4, GPT-3.5, Mistral, Llama2) detect point outliers in tabular data via zero-shot prompt-based detection, assigning lower likelihood to low-density regions. <a href="../results/extraction-result-5643.html#e5643.0" class="evidence-link">[e5643.0]</a> <a href="../results/extraction-result-5643.html#e5643.1" class="evidence-link">[e5643.1]</a> <a href="../results/extraction-result-5643.html#e5643.2" class="evidence-link">[e5643.2]</a> <a href="../results/extraction-result-5643.html#e5643.3" class="evidence-link">[e5643.3]</a> <a href="../results/extraction-result-5643.html#e5643.4" class="evidence-link">[e5643.4]</a> <a href="../results/extraction-result-5643.html#e5643.5" class="evidence-link">[e5643.5]</a> </li>
    <li>LLMs can detect anomalies in time series and logs by scoring low-likelihood tokens or sequences (e.g., LogGPT, LogBERT, LAnoBERT, LLMTIME). <a href="../results/extraction-result-5738.html#e5738.0" class="evidence-link">[e5738.0]</a> <a href="../results/extraction-result-5736.html#e5736.0" class="evidence-link">[e5736.0]</a> <a href="../results/extraction-result-5742.html#e5742.0" class="evidence-link">[e5742.0]</a> <a href="../results/extraction-result-5732.html#e5732.1" class="evidence-link">[e5732.1]</a> </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> While the use of LMs for anomaly detection in text/logs is established, the generalization to arbitrary list/tabular/time-series data via serialization and prompt-based LLMs is a new, unifying perspective.</p>            <p><strong>What Already Exists:</strong> Language models have been used for next-token prediction and anomaly detection in text and logs, and density estimation is a classical approach in anomaly detection.</p>            <p><strong>What is Novel:</strong> The extension of this principle to arbitrary serialized lists/tables, and the assertion that LLMs can serve as universal anomaly detectors across modalities via prompt-based or zero-shot use, is novel.</p>
            <p><strong>References:</strong> <ul>
    <li>Tuor et al. (2017) Recurrent Neural Network Language Models for Open Vocabulary Event-Level Cyber Anomaly Detection [LMs for log anomaly detection]</li>
    <li>Guo et al. (2021) LogBERT: Log Anomaly Detection via BERT [BERT for log anomaly detection]</li>
    <li>Narayan et al. (2022) Can Foundation Models Wrangle Your Data? [LLMs for tabular data cleaning]</li>
    <li>Bakumenko et al. (2024) Advancing Anomaly Detection: Non-Semantic Financial Data Encoding With Large Language Models [LLM embeddings for tabular anomaly detection]</li>
</ul>
            <h3>Statement 1: Serialization-Alignment Law (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; structured_data &#8594; is_serialized_to_text &#8594; LLM_input<span style="color: #888888;">, and</span></div>
        <div>&#8226; LLM &#8594; is_prompted_with &#8594; LLM_input</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; anomaly_detection_performance &#8594; is_maximized_when &#8594; serialization_matches_LLM_pretraining_domain_and_data_semantics</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Performance of LLM-based anomaly detection depends on serialization choices (e.g., per-feature, per-row, digit tokenization, prompt templates), with misalignment leading to factual errors or degraded detection. <a href="../results/extraction-result-5643.html#e5643.2" class="evidence-link">[e5643.2]</a> <a href="../results/extraction-result-5643.html#e5643.3" class="evidence-link">[e5643.3]</a> <a href="../results/extraction-result-5732.html#e5732.0" class="evidence-link">[e5732.0]</a> <a href="../results/extraction-result-5732.html#e5732.1" class="evidence-link">[e5732.1]</a> <a href="../results/extraction-result-5643.html#e5643.4" class="evidence-link">[e5643.4]</a> <a href="../results/extraction-result-5643.html#e5643.5" class="evidence-link">[e5643.5]</a> </li>
    <li>TabLLM and related works note that prompt design and serialization affect LLM performance on tabular data. <a href="../results/extraction-result-5688.html#e5688.5" class="evidence-link">[e5688.5]</a> <a href="../results/extraction-result-5745.html#e5745.0" class="evidence-link">[e5745.0]</a> </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> While prompt/serialization effects are known in NLP, their formalization as a law governing anomaly detection performance in LLMs for structured data is novel.</p>            <p><strong>What Already Exists:</strong> Prompt engineering and serialization are known to affect LLM performance in NLP tasks.</p>            <p><strong>What is Novel:</strong> The explicit law that anomaly detection effectiveness in LLMs is a function of serialization alignment with both data semantics and LLM pretraining is new in the context of anomaly detection across arbitrary lists/tables.</p>
            <p><strong>References:</strong> <ul>
    <li>Dinh et al. (2022) LIFT: Language-interfaced fine-tuning for non-language machine learning tasks [serialization and sample efficiency]</li>
    <li>Narayan et al. (2022) Can Foundation Models Wrangle Your Data? [serialization for tabular data cleaning]</li>
    <li>Bakumenko et al. (2024) Advancing Anomaly Detection: Non-Semantic Financial Data Encoding With Large Language Models [prompt/serialization effects]</li>
</ul>
            <h3>Statement 2: Modality-Transfer Law (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; LLM &#8594; is_pretrained_on &#8594; large_textual_corpora<span style="color: #888888;">, and</span></div>
        <div>&#8226; structured_data &#8594; is_serialized_to_text &#8594; LLM_input</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; LLM &#8594; can_transfer_anomaly_detection_capabilities &#8594; non-textual_modalities (tabular, time series, logs)</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>LLMs pretrained on text can detect anomalies in tabular data, time series, and logs when data is serialized to text (e.g., GPT-4, Mistral, BERT, RoBERTa, SBERT, etc.). <a href="../results/extraction-result-5643.html#e5643.0" class="evidence-link">[e5643.0]</a> <a href="../results/extraction-result-5643.html#e5643.1" class="evidence-link">[e5643.1]</a> <a href="../results/extraction-result-5643.html#e5643.3" class="evidence-link">[e5643.3]</a> <a href="../results/extraction-result-5643.html#e5643.4" class="evidence-link">[e5643.4]</a> <a href="../results/extraction-result-5643.html#e5643.5" class="evidence-link">[e5643.5]</a> <a href="../results/extraction-result-5732.html#e5732.1" class="evidence-link">[e5732.1]</a> <a href="../results/extraction-result-5676.html#e5676.0" class="evidence-link">[e5676.0]</a> <a href="../results/extraction-result-5676.html#e5676.1" class="evidence-link">[e5676.1]</a> <a href="../results/extraction-result-5676.html#e5676.2" class="evidence-link">[e5676.2]</a> <a href="../results/extraction-result-5676.html#e5676.3" class="evidence-link">[e5676.3]</a> <a href="../results/extraction-result-5738.html#e5738.0" class="evidence-link">[e5738.0]</a> <a href="../results/extraction-result-5736.html#e5736.0" class="evidence-link">[e5736.0]</a> <a href="../results/extraction-result-5742.html#e5742.0" class="evidence-link">[e5742.0]</a> </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> While transfer learning is established, the explicit generalization to anomaly detection in arbitrary serialized data is new.</p>            <p><strong>What Already Exists:</strong> Transfer learning from text to other modalities is a known research area, but not formalized for anomaly detection in this way.</p>            <p><strong>What is Novel:</strong> The law that LLMs can serve as universal anomaly detectors for any data modality that can be serialized to text, due to their pretraining, is novel.</p>
            <p><strong>References:</strong> <ul>
    <li>Narayan et al. (2022) Can Foundation Models Wrangle Your Data? [LLMs for tabular data cleaning]</li>
    <li>Bakumenko et al. (2024) Advancing Anomaly Detection: Non-Semantic Financial Data Encoding With Large Language Models [LLM embeddings for tabular anomaly detection]</li>
    <li>Guo et al. (2021) LogBERT: Log Anomaly Detection via BERT [BERT for log anomaly detection]</li>
</ul>
            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>If a new data modality (e.g., sensor readings, event logs, or categorical lists) is serialized to text and provided to a sufficiently large LLM, the LLM will be able to detect point and contextual anomalies without additional training.</li>
                <li>If the serialization format is changed to more closely match the LLM's pretraining data (e.g., using natural language templates), anomaly detection performance will improve.</li>
                <li>If an LLM is fine-tuned on a small number of labeled anomalies in a new domain, its anomaly detection performance will surpass zero-shot performance.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>If a highly structured, non-linguistic data type (e.g., high-dimensional tensors, graphs) is serialized to text, will LLMs still detect anomalies as effectively as in tabular or sequential data?</li>
                <li>If an LLM is prompted with a serialization that intentionally obfuscates feature semantics (e.g., random column order, arbitrary field names), will it still detect anomalies, or will performance degrade sharply?</li>
                <li>If an LLM is used to detect anomalies in data distributions that are adversarially designed to mimic normality in the serialized text, will it be robust or easily fooled?</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>If an LLM is provided with a list of data serialized in a way that is completely misaligned with its pretraining (e.g., binary encoding, or random token order), and it still detects anomalies as well as with aligned serialization, this would call the serialization-alignment law into question.</li>
                <li>If an LLM is unable to detect anomalies in a data modality (e.g., time series) even when serialized to text, this would challenge the modality-transfer law.</li>
                <li>If LLMs assign high likelihood to known anomalies in serialized data, this would challenge the contextual density law.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>Cases where LLMs hallucinate or omit features in tabular data, leading to biased or incorrect anomaly detection results. <a href="../results/extraction-result-5745.html#e5745.0" class="evidence-link">[e5745.0]</a> </li>
    <li>Instances where LLMs require fine-tuning or human-in-the-loop guidance to achieve high anomaly detection performance, suggesting zero-shot limits. <a href="../results/extraction-result-5623.html#e5623.0" class="evidence-link">[e5623.0]</a> <a href="../results/extraction-result-5623.html#e5623.1" class="evidence-link">[e5623.1]</a> <a href="../results/extraction-result-5623.html#e5623.2" class="evidence-link">[e5623.2]</a> </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> somewhat-related-to-existing</p>
            <p><strong>Explanation:</strong> This theory synthesizes and generalizes prior work on LMs for anomaly detection, extending it to a universal, serialization-driven framework for arbitrary data types.</p>
            <p><strong>References:</strong> <ul>
    <li>Tuor et al. (2017) Recurrent Neural Network Language Models for Open Vocabulary Event-Level Cyber Anomaly Detection [LMs for log anomaly detection]</li>
    <li>Guo et al. (2021) LogBERT: Log Anomaly Detection via BERT [BERT for log anomaly detection]</li>
    <li>Narayan et al. (2022) Can Foundation Models Wrangle Your Data? [LLMs for tabular data cleaning]</li>
    <li>Bakumenko et al. (2024) Advancing Anomaly Detection: Non-Semantic Financial Data Encoding With Large Language Models [LLM embeddings for tabular anomaly detection]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Unified Language Model Representation Theory for Anomaly Detection in Lists and Sequences",
    "theory_description": "This theory posits that large language models (LLMs), when provided with serialized representations of structured data (lists, tables, sequences), can serve as universal anomaly detectors by leveraging their pre-trained knowledge of statistical, syntactic, and semantic regularities. The LLM's ability to model context, token dependencies, and distributional density enables detection of a wide range of anomaly types (point, contextual, sequential, semantic) across diverse data modalities (tabular, time series, logs, categorical lists) without explicit feature engineering or domain-specific adaptation. The theory further asserts that the effectiveness of LLM-based anomaly detection is modulated by the alignment between the data serialization, the LLM's pretraining domain, and the anomaly's manifestation in the serialized context.",
    "theory_statements": [
        {
            "law": {
                "law_name": "LLM Contextual Density Law",
                "if": [
                    {
                        "subject": "data_list",
                        "relation": "is_serialized_to_text",
                        "object": "LLM_input"
                    },
                    {
                        "subject": "LLM",
                        "relation": "is_prompted_with",
                        "object": "LLM_input"
                    }
                ],
                "then": [
                    {
                        "subject": "LLM",
                        "relation": "assigns_lower_likelihood",
                        "object": "outlier_elements_in_data_list"
                    },
                    {
                        "subject": "LLM",
                        "relation": "can_flag",
                        "object": "anomalous_elements_by_low_likelihood"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "LLMs (GPT-4, GPT-3.5, Mistral, Llama2) detect point outliers in tabular data via zero-shot prompt-based detection, assigning lower likelihood to low-density regions.",
                        "uuids": [
                            "e5643.0",
                            "e5643.1",
                            "e5643.2",
                            "e5643.3",
                            "e5643.4",
                            "e5643.5"
                        ]
                    },
                    {
                        "text": "LLMs can detect anomalies in time series and logs by scoring low-likelihood tokens or sequences (e.g., LogGPT, LogBERT, LAnoBERT, LLMTIME).",
                        "uuids": [
                            "e5738.0",
                            "e5736.0",
                            "e5742.0",
                            "e5732.1"
                        ]
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Language models have been used for next-token prediction and anomaly detection in text and logs, and density estimation is a classical approach in anomaly detection.",
                    "what_is_novel": "The extension of this principle to arbitrary serialized lists/tables, and the assertion that LLMs can serve as universal anomaly detectors across modalities via prompt-based or zero-shot use, is novel.",
                    "classification_explanation": "While the use of LMs for anomaly detection in text/logs is established, the generalization to arbitrary list/tabular/time-series data via serialization and prompt-based LLMs is a new, unifying perspective.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Tuor et al. (2017) Recurrent Neural Network Language Models for Open Vocabulary Event-Level Cyber Anomaly Detection [LMs for log anomaly detection]",
                        "Guo et al. (2021) LogBERT: Log Anomaly Detection via BERT [BERT for log anomaly detection]",
                        "Narayan et al. (2022) Can Foundation Models Wrangle Your Data? [LLMs for tabular data cleaning]",
                        "Bakumenko et al. (2024) Advancing Anomaly Detection: Non-Semantic Financial Data Encoding With Large Language Models [LLM embeddings for tabular anomaly detection]"
                    ]
                }
            }
        },
        {
            "law": {
                "law_name": "Serialization-Alignment Law",
                "if": [
                    {
                        "subject": "structured_data",
                        "relation": "is_serialized_to_text",
                        "object": "LLM_input"
                    },
                    {
                        "subject": "LLM",
                        "relation": "is_prompted_with",
                        "object": "LLM_input"
                    }
                ],
                "then": [
                    {
                        "subject": "anomaly_detection_performance",
                        "relation": "is_maximized_when",
                        "object": "serialization_matches_LLM_pretraining_domain_and_data_semantics"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Performance of LLM-based anomaly detection depends on serialization choices (e.g., per-feature, per-row, digit tokenization, prompt templates), with misalignment leading to factual errors or degraded detection.",
                        "uuids": [
                            "e5643.2",
                            "e5643.3",
                            "e5732.0",
                            "e5732.1",
                            "e5643.4",
                            "e5643.5"
                        ]
                    },
                    {
                        "text": "TabLLM and related works note that prompt design and serialization affect LLM performance on tabular data.",
                        "uuids": [
                            "e5688.5",
                            "e5745.0"
                        ]
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Prompt engineering and serialization are known to affect LLM performance in NLP tasks.",
                    "what_is_novel": "The explicit law that anomaly detection effectiveness in LLMs is a function of serialization alignment with both data semantics and LLM pretraining is new in the context of anomaly detection across arbitrary lists/tables.",
                    "classification_explanation": "While prompt/serialization effects are known in NLP, their formalization as a law governing anomaly detection performance in LLMs for structured data is novel.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Dinh et al. (2022) LIFT: Language-interfaced fine-tuning for non-language machine learning tasks [serialization and sample efficiency]",
                        "Narayan et al. (2022) Can Foundation Models Wrangle Your Data? [serialization for tabular data cleaning]",
                        "Bakumenko et al. (2024) Advancing Anomaly Detection: Non-Semantic Financial Data Encoding With Large Language Models [prompt/serialization effects]"
                    ]
                }
            }
        },
        {
            "law": {
                "law_name": "Modality-Transfer Law",
                "if": [
                    {
                        "subject": "LLM",
                        "relation": "is_pretrained_on",
                        "object": "large_textual_corpora"
                    },
                    {
                        "subject": "structured_data",
                        "relation": "is_serialized_to_text",
                        "object": "LLM_input"
                    }
                ],
                "then": [
                    {
                        "subject": "LLM",
                        "relation": "can_transfer_anomaly_detection_capabilities",
                        "object": "non-textual_modalities (tabular, time series, logs)"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "LLMs pretrained on text can detect anomalies in tabular data, time series, and logs when data is serialized to text (e.g., GPT-4, Mistral, BERT, RoBERTa, SBERT, etc.).",
                        "uuids": [
                            "e5643.0",
                            "e5643.1",
                            "e5643.3",
                            "e5643.4",
                            "e5643.5",
                            "e5732.1",
                            "e5676.0",
                            "e5676.1",
                            "e5676.2",
                            "e5676.3",
                            "e5738.0",
                            "e5736.0",
                            "e5742.0"
                        ]
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Transfer learning from text to other modalities is a known research area, but not formalized for anomaly detection in this way.",
                    "what_is_novel": "The law that LLMs can serve as universal anomaly detectors for any data modality that can be serialized to text, due to their pretraining, is novel.",
                    "classification_explanation": "While transfer learning is established, the explicit generalization to anomaly detection in arbitrary serialized data is new.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Narayan et al. (2022) Can Foundation Models Wrangle Your Data? [LLMs for tabular data cleaning]",
                        "Bakumenko et al. (2024) Advancing Anomaly Detection: Non-Semantic Financial Data Encoding With Large Language Models [LLM embeddings for tabular anomaly detection]",
                        "Guo et al. (2021) LogBERT: Log Anomaly Detection via BERT [BERT for log anomaly detection]"
                    ]
                }
            }
        }
    ],
    "new_predictions_likely": [
        "If a new data modality (e.g., sensor readings, event logs, or categorical lists) is serialized to text and provided to a sufficiently large LLM, the LLM will be able to detect point and contextual anomalies without additional training.",
        "If the serialization format is changed to more closely match the LLM's pretraining data (e.g., using natural language templates), anomaly detection performance will improve.",
        "If an LLM is fine-tuned on a small number of labeled anomalies in a new domain, its anomaly detection performance will surpass zero-shot performance."
    ],
    "new_predictions_unknown": [
        "If a highly structured, non-linguistic data type (e.g., high-dimensional tensors, graphs) is serialized to text, will LLMs still detect anomalies as effectively as in tabular or sequential data?",
        "If an LLM is prompted with a serialization that intentionally obfuscates feature semantics (e.g., random column order, arbitrary field names), will it still detect anomalies, or will performance degrade sharply?",
        "If an LLM is used to detect anomalies in data distributions that are adversarially designed to mimic normality in the serialized text, will it be robust or easily fooled?"
    ],
    "negative_experiments": [
        "If an LLM is provided with a list of data serialized in a way that is completely misaligned with its pretraining (e.g., binary encoding, or random token order), and it still detects anomalies as well as with aligned serialization, this would call the serialization-alignment law into question.",
        "If an LLM is unable to detect anomalies in a data modality (e.g., time series) even when serialized to text, this would challenge the modality-transfer law.",
        "If LLMs assign high likelihood to known anomalies in serialized data, this would challenge the contextual density law."
    ],
    "unaccounted_for": [
        {
            "text": "Cases where LLMs hallucinate or omit features in tabular data, leading to biased or incorrect anomaly detection results.",
            "uuids": [
                "e5745.0"
            ]
        },
        {
            "text": "Instances where LLMs require fine-tuning or human-in-the-loop guidance to achieve high anomaly detection performance, suggesting zero-shot limits.",
            "uuids": [
                "e5623.0",
                "e5623.1",
                "e5623.2"
            ]
        }
    ],
    "conflicting_evidence": [
        {
            "text": "LLMs sometimes produce high false positive rates or low specificity in zero-shot anomaly detection, especially in logs and time series.",
            "uuids": [
                "e5738.0",
                "e5660.0",
                "e5660.2",
                "e5660.3"
            ]
        },
        {
            "text": "LLMs may underperform compared to specialized deep learning models or classical baselines in some settings (e.g., AER for time series, LogCluster for logs).",
            "uuids": [
                "e5660.2",
                "e5641.0",
                "e5594.0"
            ]
        }
    ],
    "special_cases": [
        "LLMs may fail to detect anomalies that do not manifest as low-likelihood tokens in the serialized context (e.g., subtle distributional shifts, adversarially crafted anomalies).",
        "LLMs' performance may degrade for very large or high-dimensional data due to context window and tokenization limits.",
        "LLMs may be less effective for modalities with semantics not represented in pretraining (e.g., raw binary data, non-English logs if not in pretraining)."
    ],
    "existing_theory": {
        "what_already_exists": "Language models have been used for anomaly detection in text, logs, and some structured data, and prompt engineering is known to affect LLM performance.",
        "what_is_novel": "The unification of LLM-based anomaly detection across arbitrary serialized lists/tables/sequences, and the formalization of serialization-alignment and modality-transfer as governing laws, is novel.",
        "classification_explanation": "This theory synthesizes and generalizes prior work on LMs for anomaly detection, extending it to a universal, serialization-driven framework for arbitrary data types.",
        "likely_classification": "somewhat-related-to-existing",
        "references": [
            "Tuor et al. (2017) Recurrent Neural Network Language Models for Open Vocabulary Event-Level Cyber Anomaly Detection [LMs for log anomaly detection]",
            "Guo et al. (2021) LogBERT: Log Anomaly Detection via BERT [BERT for log anomaly detection]",
            "Narayan et al. (2022) Can Foundation Models Wrangle Your Data? [LLMs for tabular data cleaning]",
            "Bakumenko et al. (2024) Advancing Anomaly Detection: Non-Semantic Financial Data Encoding With Large Language Models [LLM embeddings for tabular anomaly detection]"
        ]
    },
    "theory_type_general_specific": "general",
    "version": "built-theory-from-results-single-theory-reflection2-nov14-2025",
    "type": "general"
}</code></pre>
        </div>
    </div>
</body>
</html>