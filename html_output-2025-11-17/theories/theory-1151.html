<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Prompt Decomposition and Iterative Composition Law: Information Preservation Principle - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-1151</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-1151</p>
                <p><strong>Name:</strong> Prompt Decomposition and Iterative Composition Law: Information Preservation Principle</p>
                <p><strong>Type:</strong> general</p>
                <p><strong>Theory Query:</strong> Build a theory of how language models can best perform strict logical reasoning.</p>
                <p><strong>Description:</strong> This theory asserts that for language models to perform strict logical reasoning, the decomposition and iterative composition process must preserve all relevant information from the original problem and intermediate steps. Any loss or distortion of information during decomposition or composition leads to logical errors or incomplete reasoning.</p>
                <p><strong>Knowledge Cutoff Year:</strong> -1</p>
                <p><strong>Knowledge Cutoff Month:</strong> -1</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <h3>Statement 0: Information Preservation Law (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; decomposition_process &#8594; preserves_all_relevant_information &#8594; True<span style="color: #888888;">, and</span></div>
        <div>&#8226; composition_process &#8594; preserves_all_relevant_information &#8594; True</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; language_model &#8594; performs_strict_logical_reasoning &#8594; with_high_accuracy</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Loss of information during stepwise reasoning leads to logical errors or incomplete solutions. </li>
    <li>Prompts that require explicit restatement of all relevant facts at each step improve logical accuracy. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> While information preservation is fundamental in logic, its explicit application to LM prompt design is new.</p>            <p><strong>What Already Exists:</strong> Information preservation is a known principle in formal logic and mathematics.</p>            <p><strong>What is Novel:</strong> The explicit application of information preservation to prompt decomposition and iterative composition in LMs is novel.</p>
            <p><strong>References:</strong> <ul>
    <li>Nye et al. (2021) Show Your Work: Scratchpads for Intermediate Computation with Language Models [Intermediate steps for verifiability]</li>
    <li>Wei et al. (2022) Chain-of-Thought Prompting Elicits Reasoning in Large Language Models [Stepwise reasoning, but not formalized as information preservation]</li>
</ul>
            <h3>Statement 1: Information Loss Error Law (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; decomposition_or_composition_process &#8594; loses_relevant_information &#8594; True</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; language_model &#8594; produces_logical_errors &#8594; with_high_probability</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Empirical studies show that omitted facts or steps in reasoning chains lead to incorrect answers. </li>
    <li>Ambiguous or incomplete intermediate representations correlate with logical failure. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> This law extends the information preservation principle to the specific context of LM prompt engineering.</p>            <p><strong>What Already Exists:</strong> Information loss is known to cause errors in formal logic and computation.</p>            <p><strong>What is Novel:</strong> The explicit link between information loss in prompt decomposition/composition and LM logical errors is novel.</p>
            <p><strong>References:</strong> <ul>
    <li>Nye et al. (2021) Show Your Work: Scratchpads for Intermediate Computation with Language Models [Intermediate steps for verifiability]</li>
    <li>Wei et al. (2022) Chain-of-Thought Prompting Elicits Reasoning in Large Language Models [Stepwise reasoning, but not formalized as information preservation]</li>
</ul>
            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>If prompts require explicit restatement of all relevant facts at each step, logical accuracy will increase.</li>
                <li>If information is omitted or distorted during decomposition or composition, logical errors will increase.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>If LMs are trained to automatically detect and recover lost information during reasoning, logical accuracy may improve beyond current benchmarks.</li>
                <li>If information preservation is enforced at the representation level (not just prompt level), LMs may develop new forms of robust logical inference.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>If LMs perform strict logical reasoning despite information loss during decomposition or composition, the theory would be challenged.</li>
                <li>If explicit information preservation does not improve logical accuracy, the theory would be called into question.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>Some LMs may recover lost information through world knowledge or context, even if not explicitly preserved in the prompt. </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> somewhat-related-to-existing</p>
            <p><strong>Explanation:</strong> This is a new formalization of information preservation as a necessary condition for strict logical reasoning in LMs.</p>
            <p><strong>References:</strong> <ul>
    <li>Nye et al. (2021) Show Your Work: Scratchpads for Intermediate Computation with Language Models [Intermediate steps for verifiability]</li>
    <li>Wei et al. (2022) Chain-of-Thought Prompting Elicits Reasoning in Large Language Models [Stepwise reasoning, but not formalized as information preservation]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Prompt Decomposition and Iterative Composition Law: Information Preservation Principle",
    "theory_description": "This theory asserts that for language models to perform strict logical reasoning, the decomposition and iterative composition process must preserve all relevant information from the original problem and intermediate steps. Any loss or distortion of information during decomposition or composition leads to logical errors or incomplete reasoning.",
    "theory_statements": [
        {
            "law": {
                "law_name": "Information Preservation Law",
                "if": [
                    {
                        "subject": "decomposition_process",
                        "relation": "preserves_all_relevant_information",
                        "object": "True"
                    },
                    {
                        "subject": "composition_process",
                        "relation": "preserves_all_relevant_information",
                        "object": "True"
                    }
                ],
                "then": [
                    {
                        "subject": "language_model",
                        "relation": "performs_strict_logical_reasoning",
                        "object": "with_high_accuracy"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Loss of information during stepwise reasoning leads to logical errors or incomplete solutions.",
                        "uuids": []
                    },
                    {
                        "text": "Prompts that require explicit restatement of all relevant facts at each step improve logical accuracy.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Information preservation is a known principle in formal logic and mathematics.",
                    "what_is_novel": "The explicit application of information preservation to prompt decomposition and iterative composition in LMs is novel.",
                    "classification_explanation": "While information preservation is fundamental in logic, its explicit application to LM prompt design is new.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Nye et al. (2021) Show Your Work: Scratchpads for Intermediate Computation with Language Models [Intermediate steps for verifiability]",
                        "Wei et al. (2022) Chain-of-Thought Prompting Elicits Reasoning in Large Language Models [Stepwise reasoning, but not formalized as information preservation]"
                    ]
                }
            }
        },
        {
            "law": {
                "law_name": "Information Loss Error Law",
                "if": [
                    {
                        "subject": "decomposition_or_composition_process",
                        "relation": "loses_relevant_information",
                        "object": "True"
                    }
                ],
                "then": [
                    {
                        "subject": "language_model",
                        "relation": "produces_logical_errors",
                        "object": "with_high_probability"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Empirical studies show that omitted facts or steps in reasoning chains lead to incorrect answers.",
                        "uuids": []
                    },
                    {
                        "text": "Ambiguous or incomplete intermediate representations correlate with logical failure.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Information loss is known to cause errors in formal logic and computation.",
                    "what_is_novel": "The explicit link between information loss in prompt decomposition/composition and LM logical errors is novel.",
                    "classification_explanation": "This law extends the information preservation principle to the specific context of LM prompt engineering.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Nye et al. (2021) Show Your Work: Scratchpads for Intermediate Computation with Language Models [Intermediate steps for verifiability]",
                        "Wei et al. (2022) Chain-of-Thought Prompting Elicits Reasoning in Large Language Models [Stepwise reasoning, but not formalized as information preservation]"
                    ]
                }
            }
        }
    ],
    "new_predictions_likely": [
        "If prompts require explicit restatement of all relevant facts at each step, logical accuracy will increase.",
        "If information is omitted or distorted during decomposition or composition, logical errors will increase."
    ],
    "new_predictions_unknown": [
        "If LMs are trained to automatically detect and recover lost information during reasoning, logical accuracy may improve beyond current benchmarks.",
        "If information preservation is enforced at the representation level (not just prompt level), LMs may develop new forms of robust logical inference."
    ],
    "negative_experiments": [
        "If LMs perform strict logical reasoning despite information loss during decomposition or composition, the theory would be challenged.",
        "If explicit information preservation does not improve logical accuracy, the theory would be called into question."
    ],
    "unaccounted_for": [
        {
            "text": "Some LMs may recover lost information through world knowledge or context, even if not explicitly preserved in the prompt.",
            "uuids": []
        }
    ],
    "conflicting_evidence": [
        {
            "text": "There are cases where LMs infer correct answers despite incomplete intermediate representations, suggesting robustness in some settings.",
            "uuids": []
        }
    ],
    "special_cases": [
        "For tasks where all relevant information is trivially preserved, explicit enforcement may be unnecessary.",
        "For LMs with strong context retention, information loss may be less critical."
    ],
    "existing_theory": {
        "what_already_exists": "Information preservation is a known principle in logic and computation, but not formalized for LM prompt decomposition/composition.",
        "what_is_novel": "The explicit application of information preservation to prompt decomposition and iterative composition in LMs is novel.",
        "classification_explanation": "This is a new formalization of information preservation as a necessary condition for strict logical reasoning in LMs.",
        "likely_classification": "somewhat-related-to-existing",
        "references": [
            "Nye et al. (2021) Show Your Work: Scratchpads for Intermediate Computation with Language Models [Intermediate steps for verifiability]",
            "Wei et al. (2022) Chain-of-Thought Prompting Elicits Reasoning in Large Language Models [Stepwise reasoning, but not formalized as information preservation]"
        ]
    },
    "reflected_from_theory_index": 3,
    "type": "general",
    "version": "built-theory-from-results-single-theory-reflection2-nov14-2025-LLM-BASELINE-no-evidence-with-matched-control-theory-name",
    "theory_query": "Build a theory of how language models can best perform strict logical reasoning.",
    "original_theory_id": "theory-604",
    "original_theory_name": "Prompt Decomposition and Iterative Composition Law",
    "provide_matched_control_thery_name": true,
    "matched_control_theory_name": "Prompt Decomposition and Iterative Composition Law",
    "model_str": "openai/gpt-4.1-2025-04-14"
}</code></pre>
        </div>
    </div>
</body>
</html>