<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Memory Structure-Task Alignment Theory - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-452</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-452</p>
                <p><strong>Name:</strong> Memory Structure-Task Alignment Theory</p>
                <p><strong>Type:</strong> specific</p>
                <p><strong>Theory Query:</strong> Build a theory of how LLM-based agents can most effectively be augmented with memory to solve text games, based on the following results.</p>
                <p><strong>Description:</strong> The effectiveness of memory augmentation in LLM-based text game agents is fundamentally determined by the alignment between memory structure and task structure. Different task types require different memory organizations: spatial navigation tasks benefit from graph-based spatial memory that preserves topological relationships; social deduction tasks benefit from relationship-centric memory that tracks agent interactions and beliefs; procedural tasks benefit from hierarchical memory organized by subgoals; and knowledge-intensive tasks benefit from semantic memory with fact-based retrieval. This theory posits that there is no universally optimal memory architecture - instead, memory structure must be matched to the relational and temporal structure of the task domain. Misalignment between memory structure and task structure leads to inefficient retrieval, missed dependencies, and suboptimal performance even when memory capacity is adequate. The theory further predicts that the magnitude of improvement from structured memory scales with task complexity and the degree of structural dependencies in the task.</p>
                <p><strong>Knowledge Cutoff Year:</strong> 2025</p>
                <p><strong>Knowledge Cutoff Month:</strong> 11</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <h3>Statement 0: Law 0</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; task &#8594; requires &#8594; spatial reasoning and navigation<span style="color: #888888;">, and</span></div>
        <div>&#8226; agent &#8594; uses &#8594; graph-based spatial memory</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; agent &#8594; outperforms agents using &#8594; unstructured or sequential memory<span style="color: #888888;">, and</span></div>
        <div>&#8226; performance advantage &#8594; is typically &#8594; 30-100% relative improvement</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>AriGraph with knowledge graph memory achieved 1.0 normalized score on Treasure Hunt while full history achieved 0.47 and RAG achieved 0.33, demonstrating 113% improvement over full history and 203% over RAG <a href="../results/extraction-result-2945.html#e2945.0" class="evidence-link">[e2945.0]</a> <a href="../results/extraction-result-2945.html#e2945.1" class="evidence-link">[e2945.1]</a> <a href="../results/extraction-result-2945.html#e2945.2" class="evidence-link">[e2945.2]</a> </li>
    <li>GATA with graph-based belief memory achieved +24.2% average relative improvement over text-only Tr-DQN baseline across TextWorld difficulty levels <a href="../results/extraction-result-2968.html#e2968.0" class="evidence-link">[e2968.0]</a> </li>
    <li>KG-A2C with knowledge graph substantially outperformed TDQN baseline on 23/28 Jericho games, demonstrating consistent advantage of graph structure for interactive fiction navigation <a href="../results/extraction-result-2972.html#e2972.0" class="evidence-link">[e2972.0]</a> <a href="../results/extraction-result-2972.html#e2972.3" class="evidence-link">[e2972.3]</a> </li>
    <li>Ariadne with AriGraph (Room obs + graph) recovered performance comparable to NetPlay with oracle Level obs memory, achieving similar scores and levels completed <a href="../results/extraction-result-2945.html#e2945.6" class="evidence-link">[e2945.6]</a> </li>
    <li>GATA-GTF with ground-truth graph achieved substantially higher performance than learned-belief agents, with average relative improvement of +81.6% over Tr-DQN, showing upper bound of graph-based memory <a href="../results/extraction-result-2968.html#e2968.2" class="evidence-link">[e2968.2]</a> </li>
    <li>KG-DQN with knowledge graph construction from observations aided partial-observability handling in text-adventure games <a href="../results/extraction-result-2976.html#e2976.3" class="evidence-link">[e2976.3]</a> </li>
    <li>Dynamic Belief Graphs approach learns structured, dynamic belief representations for text-based games to capture relational information <a href="../results/extraction-result-2969.html#e2969.2" class="evidence-link">[e2969.2]</a> <a href="../results/extraction-result-2901.html#e2901.2" class="evidence-link">[e2901.2]</a> </li>
    <li>S2ERS with entity-relation graph for spatial relationships improved success rate by ~29.2% and optimal rate by ~20.0% over best baseline in maze navigation <a href="../results/extraction-result-2934.html#e2934.0" class="evidence-link">[e2934.0]</a> </li>
    <li>NetPlay with Level obs (oracle spatial memory) achieved 675.33 average score vs 341.67 with Room obs only, demonstrating ~98% improvement from spatial memory <a href="../results/extraction-result-2945.html#e2945.6" class="evidence-link">[e2945.6]</a> </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p class="empty-note">No existing law comparison provided.</p>
            <h3>Statement 1: Law 1</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; task &#8594; requires &#8594; multi-step hierarchical planning<span style="color: #888888;">, and</span></div>
        <div>&#8226; agent &#8594; uses &#8594; hierarchical subgoal-chunked memory</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; agent &#8594; achieves &#8594; higher task completion rate<span style="color: #888888;">, and</span></div>
        <div>&#8226; agent &#8594; reduces &#8594; redundant exploration and token usage by 30-70%</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>HIAGENT with hierarchical subgoal memory doubled success rate from 21% to 42% (+21 pp) and reduced average steps by 3.8 while reducing context tokens by ~35% <a href="../results/extraction-result-2937.html#e2937.0" class="evidence-link">[e2937.0]</a> </li>
    <li>SWIFTSAGE with action-buffer and hierarchical planning improved overall score from 49.22 (SWIFT-only) to 84.68 (+35.46 points, ~72% relative improvement) on ScienceWorld <a href="../results/extraction-result-2977.html#e2977.0" class="evidence-link">[e2977.0]</a> <a href="../results/extraction-result-2977.html#e2977.1" class="evidence-link">[e2977.1]</a> </li>
    <li>LLaMA-Rider with subtask relabeling memory improved success rate from ~20% to ~34% (+14 pp) and accomplished 25/30 tasks vs 16/30 without subtask memory <a href="../results/extraction-result-2917.html#e2917.0" class="evidence-link">[e2917.0]</a> </li>
    <li>DEPS uses plan-based short-term memory where plans act as transient memory guiding immediate actions in multi-step Minecraft tasks <a href="../results/extraction-result-2931.html#e2931.0" class="evidence-link">[e2931.0]</a> </li>
    <li>Ghost in Minecraft uses text-based knowledge and memory to handle long-horizon tasks and adapt to uncertainty in open-world environment <a href="../results/extraction-result-2931.html#e2931.5" class="evidence-link">[e2931.5]</a> <a href="../results/extraction-result-2930.html#e2930.2" class="evidence-link">[e2930.2]</a> </li>
    <li>HiAgent uses sub-goals as memory chunks to manage working memory, maintaining task continuity and coherence in long-horizon tasks <a href="../results/extraction-result-2942.html#e2942.1" class="evidence-link">[e2942.1]</a> </li>
    <li>ReadAgent with episodic gist memory improved by +12.97% LLM rating and +31.98% ROUGE-L over best retrieval baseline on NarrativeQA, enabling 3.5-20x effective context length <a href="../results/extraction-result-2929.html#e2929.0" class="evidence-link">[e2929.0]</a> </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p class="empty-note">No existing law comparison provided.</p>
            <h3>Statement 2: Law 2</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; task &#8594; requires &#8594; social reasoning and relationship tracking<span style="color: #888888;">, and</span></div>
        <div>&#8226; agent &#8594; uses &#8594; relationship-centric social memory</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; agent &#8594; maintains &#8594; consistent social behavior<span style="color: #888888;">, and</span></div>
        <div>&#8226; agent &#8594; improves &#8594; information gathering accuracy by 15-20 percentage points</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>ThinkThrice with per-agent relationship memory improved factual QA accuracy from 0.305 (no memory) to 0.498 (full system) in Jubensha multi-agent mystery game <a href="../results/extraction-result-2966.html#e2966.0" class="evidence-link">[e2966.0]</a> </li>
    <li>AGA with Social Memory (relationship & feeling summaries) maintained comparable human-likeness while reducing tokens to 31.1% of baseline in generative agents simulation <a href="../results/extraction-result-2949.html#e2949.1" class="evidence-link">[e2949.1]</a> <a href="../results/extraction-result-2949.html#e2949.0" class="evidence-link">[e2949.0]</a> </li>
    <li>AMONGAGENTS with summarized interaction memory and planner module improved win rates and task completion in text-based Among Us <a href="../results/extraction-result-2915.html#e2915.0" class="evidence-link">[e2915.0]</a> </li>
    <li>WarAgent with Board (external relations) and Stick (internal state) memory achieved 77.78% alliance accuracy and 54.60% war-declaration accuracy in WWI simulation <a href="../results/extraction-result-2898.html#e2898.0" class="evidence-link">[e2898.0]</a> </li>
    <li>Generative Agents with persistent memory streams enable coherent personas and emergent social dynamics like information diffusion and cooperative gatherings <a href="../results/extraction-result-2923.html#e2923.0" class="evidence-link">[e2923.0]</a> <a href="../results/extraction-result-2949.html#e2949.0" class="evidence-link">[e2949.0]</a> </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p class="empty-note">No existing law comparison provided.</p>
            <h3>Statement 3: Law 3</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; task &#8594; requires &#8594; procedural skill execution<span style="color: #888888;">, and</span></div>
        <div>&#8226; agent &#8594; uses &#8594; case-based procedural memory</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; agent &#8594; reduces &#8594; redundant LLM calls by 60-70%<span style="color: #888888;">, and</span></div>
        <div>&#8226; agent &#8594; improves &#8594; execution consistency</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>AGA with Lifestyle Policy (case-based plan memory) reduced tokens to 40.2% of baseline while maintaining performance in VirtualHome <a href="../results/extraction-result-2949.html#e2949.1" class="evidence-link">[e2949.1]</a> </li>
    <li>Voyager with skill library (procedural memory) enables lifelong learning and skill reuse in open-ended Minecraft, improving sample efficiency <a href="../results/extraction-result-2902.html#e2902.1" class="evidence-link">[e2902.1]</a> <a href="../results/extraction-result-2940.html#e2940.1" class="evidence-link">[e2940.1]</a> <a href="../results/extraction-result-2930.html#e2930.3" class="evidence-link">[e2930.3]</a> </li>
    <li>CB-GDA with case-based memory (PCB and MCB) outperformed rule-based GDA and non-GDA replanning in complex adversarial gaming scenarios <a href="../results/extraction-result-2910.html#e2910.1" class="evidence-link">[e2910.1]</a> </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p class="empty-note">No existing law comparison provided.</p>
            <h3>Statement 4: Law 4</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; memory structure &#8594; misaligns with &#8594; task structure<span style="color: #888888;">, and</span></div>
        <div>&#8226; agent &#8594; attempts to use &#8594; misaligned memory</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; agent &#8594; performs worse than or equal to &#8594; simpler aligned memory or no explicit memory<span style="color: #888888;">, and</span></div>
        <div>&#8226; retrieval &#8594; returns &#8594; irrelevant or incomplete information</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Unstructured full history memory achieved only 0.47 on Treasure Hunt vs 1.0 for graph-based AriGraph, despite containing all information <a href="../results/extraction-result-2945.html#e2945.1" class="evidence-link">[e2945.1]</a> </li>
    <li>Simple short-history augmentation (1 past obs + 5 actions) degraded WebShop performance from 59.9 to 57.3, showing naive memory can hurt <a href="../results/extraction-result-2943.html#e2943.0" class="evidence-link">[e2943.0]</a> </li>
    <li>Flat episodic memory (Simulacra-style) achieved only 0.40 on Treasure Hunt vs 1.0 for graph memory, showing unstructured memory fails on relational tasks <a href="../results/extraction-result-2945.html#e2945.4" class="evidence-link">[e2945.4]</a> </li>
    <li>GATA with learned belief graphs largely ignored textual instructions and failed to complete tasks, showing graph memory alone insufficient without proper task alignment <a href="../results/extraction-result-2960.html#e2960.0" class="evidence-link">[e2960.0]</a> </li>
    <li>MemWalker hierarchical summary tree had high search failure rate (~8.6%) and underperformed ReadAgent by ~20 pp on QuALITY due to traversal unreliability <a href="../results/extraction-result-2929.html#e2929.1" class="evidence-link">[e2929.1]</a> </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p class="empty-note">No existing law comparison provided.</p>
            <h3>Statement 5: Law 5</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; task &#8594; has &#8594; high structural complexity<span style="color: #888888;">, and</span></div>
        <div>&#8226; memory structure &#8594; matches &#8594; task structure</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; performance improvement &#8594; scales with &#8594; task complexity<span style="color: #888888;">, and</span></div>
        <div>&#8226; improvement magnitude &#8594; is larger for &#8594; harder task variants</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>HIAGENT showed larger relative improvements on complex tasks (2.3x SR improvement) vs composite tasks (1.3x SR improvement) <a href="../results/extraction-result-2937.html#e2937.0" class="evidence-link">[e2937.0]</a> </li>
    <li>AriGraph achieved 1.0 on Treasure Hunt but only 0.52 on Cooking Hard, showing structure helps more when task structure is clearer <a href="../results/extraction-result-2945.html#e2945.0" class="evidence-link">[e2945.0]</a> </li>
    <li>GATA improvements over text-only baseline were larger on higher difficulty TextWorld levels <a href="../results/extraction-result-2968.html#e2968.0" class="evidence-link">[e2968.0]</a> </li>
    <li>MC-DML with cross-trial memory showed larger absolute improvements on harder Jericho games (e.g., Zork1 +10.33 points) <a href="../results/extraction-result-2927.html#e2927.0" class="evidence-link">[e2927.0]</a> </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p class="empty-note">No existing law comparison provided.</p>
            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>For puzzle games requiring causal reasoning (e.g., if-then dependencies), memory structured as causal graphs will outperform both spatial graphs and sequential memory by 40-80%</li>
                <li>For time-sensitive games with deadlines and temporal constraints, memory with explicit temporal indexing and deadline tracking will outperform memory organized by other dimensions by 30-50%</li>
                <li>For games with inventory management and item transformations, memory structured around object properties and transformation rules will outperform location-based memory by 25-60%</li>
                <li>For dialogue-heavy games requiring conversation history, memory structured as dialogue trees with speaker attribution will outperform flat sequential memory by 20-40%</li>
                <li>For games with multiple parallel objectives, memory structured with explicit goal-tracking will outperform single-thread memory by 35-70%</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>Whether a single adaptive memory structure that dynamically reorganizes based on detected task patterns could match or exceed task-specific memory structures across diverse game types</li>
                <li>Whether hybrid memory structures (e.g., combining spatial graphs with temporal sequences and social relationships) provide benefits proportional to their added complexity, or if they introduce interference</li>
                <li>Whether LLMs can learn to automatically infer optimal memory structure from task descriptions or early gameplay experience without explicit programming</li>
                <li>Whether the optimal memory structure changes during gameplay as the agent learns more about the environment, or if initial structure choice determines long-term performance</li>
                <li>Whether memory structure alignment is more important for smaller LLMs (which may have less implicit reasoning capacity) than for larger LLMs</li>
                <li>Whether certain memory structures are inherently more sample-efficient during learning, independent of task alignment</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>Finding spatial navigation tasks where unstructured sequential memory consistently outperforms graph-based memory would challenge the structure-alignment principle</li>
                <li>Demonstrating that a single universal memory structure performs optimally across all task types (spatial, social, procedural, temporal) would invalidate the need for task-specific memory design</li>
                <li>Showing that randomly structured memory performs as well as task-aligned memory on complex tasks would question the importance of structural alignment</li>
                <li>Finding cases where adding more structure-aligned memory consistently degrades performance would challenge the theory's core premise</li>
                <li>Demonstrating that memory structure has no effect on performance when controlling for memory capacity would invalidate the structure-task alignment hypothesis</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>How to automatically determine optimal memory structure from task characteristics without manual design or extensive trial-and-error </li>
    <li>The computational costs and trade-offs of maintaining multiple memory structures simultaneously for multi-faceted tasks </li>
    <li>Why some simple prompt-based memory approaches (like ReAct with thoughts) perform well across diverse tasks without explicit structure <a href="../results/extraction-result-2971.html#e2971.0" class="evidence-link">[e2971.0]</a> </li>
    <li>How reflection-based memory (storing self-critiques) relates to structural memory and whether they are complementary or substitutable <a href="../results/extraction-result-2933.html#e2933.0" class="evidence-link">[e2933.0]</a> <a href="../results/extraction-result-2907.html#e2907.0" class="evidence-link">[e2907.0]</a> <a href="../results/extraction-result-2927.html#e2927.0" class="evidence-link">[e2927.0]</a> <a href="../results/extraction-result-2941.html#e2941.0" class="evidence-link">[e2941.0]</a> </li>
    <li>Whether certain LLM architectures or sizes are more or less dependent on structured external memory <a href="../results/extraction-result-2974.html#e2974.0" class="evidence-link">[e2974.0]</a> <a href="../results/extraction-result-2974.html#e2974.2" class="evidence-link">[e2974.2]</a> </li>
    <li>How memory structure interacts with other agent components like planning modules and action selection mechanisms <a href="../results/extraction-result-2977.html#e2977.0" class="evidence-link">[e2977.0]</a> <a href="../results/extraction-result-2935.html#e2935.1" class="evidence-link">[e2935.1]</a> </li>
    <li>Why some agents with minimal memory (like CALM with 2-step window) can still achieve reasonable performance <a href="../results/extraction-result-2973.html#e2973.0" class="evidence-link">[e2973.0]</a> </li>
    <li>How to handle tasks that require multiple types of structure simultaneously (e.g., spatial + social + temporal) </li>
    <li>Whether memory structure requirements change as agents gain more experience in an environment </li>
    <li>How partial observability affects the relative importance of memory structure <a href="../results/extraction-result-2968.html#e2968.0" class="evidence-link">[e2968.0]</a> <a href="../results/extraction-result-2972.html#e2972.0" class="evidence-link">[e2972.0]</a> </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> new</p>
            <p><strong>Explanation:</strong> No explanation provided.</p>
            <p><strong>References:</strong> <ul>
    <li>Adhikari et al. (2020) Learning Dynamic Belief Graphs to Generalize on Text-Based Games [Demonstrates graph-based memory benefits for text games but doesn't formalize the general structure-task alignment principle or compare across memory types]</li>
    <li>Ammanabrolu et al. (2020) Graph Constrained Reinforcement Learning for Natural Language Action Spaces [Shows knowledge graph advantages for action generation but doesn't theorize about when different structures are optimal]</li>
    <li>Hu et al. (2024) AriGraph: Learning Knowledge Graph World Models with Episodic Memory for LLM Agents [Demonstrates graph memory advantages and compares to some alternatives, but doesn't formalize the general principle of structure-task alignment]</li>
    <li>Hausknecht et al. (2020) Learning Dynamic Belief Graphs to Generalize on Text-Based Games [Proposes dynamic belief graphs but focuses on single memory type rather than alignment principle]</li>
    <li>Park et al. (2023) Generative Agents: Interactive Simulacra of Human Behavior [Demonstrates episodic memory for social simulation but doesn't compare structural alternatives or formalize alignment]</li>
    <li>Wang et al. (2024) HiAgent: Hierarchical Working Memory Management [Shows hierarchical memory benefits but doesn't formalize when hierarchical vs other structures are optimal]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Memory Structure-Task Alignment Theory",
    "theory_description": "The effectiveness of memory augmentation in LLM-based text game agents is fundamentally determined by the alignment between memory structure and task structure. Different task types require different memory organizations: spatial navigation tasks benefit from graph-based spatial memory that preserves topological relationships; social deduction tasks benefit from relationship-centric memory that tracks agent interactions and beliefs; procedural tasks benefit from hierarchical memory organized by subgoals; and knowledge-intensive tasks benefit from semantic memory with fact-based retrieval. This theory posits that there is no universally optimal memory architecture - instead, memory structure must be matched to the relational and temporal structure of the task domain. Misalignment between memory structure and task structure leads to inefficient retrieval, missed dependencies, and suboptimal performance even when memory capacity is adequate. The theory further predicts that the magnitude of improvement from structured memory scales with task complexity and the degree of structural dependencies in the task.",
    "theory_statements": [
        {
            "law": {
                "if": [
                    {
                        "subject": "task",
                        "relation": "requires",
                        "object": "spatial reasoning and navigation"
                    },
                    {
                        "subject": "agent",
                        "relation": "uses",
                        "object": "graph-based spatial memory"
                    }
                ],
                "then": [
                    {
                        "subject": "agent",
                        "relation": "outperforms agents using",
                        "object": "unstructured or sequential memory"
                    },
                    {
                        "subject": "performance advantage",
                        "relation": "is typically",
                        "object": "30-100% relative improvement"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "AriGraph with knowledge graph memory achieved 1.0 normalized score on Treasure Hunt while full history achieved 0.47 and RAG achieved 0.33, demonstrating 113% improvement over full history and 203% over RAG",
                        "uuids": [
                            "e2945.0",
                            "e2945.1",
                            "e2945.2"
                        ]
                    },
                    {
                        "text": "GATA with graph-based belief memory achieved +24.2% average relative improvement over text-only Tr-DQN baseline across TextWorld difficulty levels",
                        "uuids": [
                            "e2968.0"
                        ]
                    },
                    {
                        "text": "KG-A2C with knowledge graph substantially outperformed TDQN baseline on 23/28 Jericho games, demonstrating consistent advantage of graph structure for interactive fiction navigation",
                        "uuids": [
                            "e2972.0",
                            "e2972.3"
                        ]
                    },
                    {
                        "text": "Ariadne with AriGraph (Room obs + graph) recovered performance comparable to NetPlay with oracle Level obs memory, achieving similar scores and levels completed",
                        "uuids": [
                            "e2945.6"
                        ]
                    },
                    {
                        "text": "GATA-GTF with ground-truth graph achieved substantially higher performance than learned-belief agents, with average relative improvement of +81.6% over Tr-DQN, showing upper bound of graph-based memory",
                        "uuids": [
                            "e2968.2"
                        ]
                    },
                    {
                        "text": "KG-DQN with knowledge graph construction from observations aided partial-observability handling in text-adventure games",
                        "uuids": [
                            "e2976.3"
                        ]
                    },
                    {
                        "text": "Dynamic Belief Graphs approach learns structured, dynamic belief representations for text-based games to capture relational information",
                        "uuids": [
                            "e2969.2",
                            "e2901.2"
                        ]
                    },
                    {
                        "text": "S2ERS with entity-relation graph for spatial relationships improved success rate by ~29.2% and optimal rate by ~20.0% over best baseline in maze navigation",
                        "uuids": [
                            "e2934.0"
                        ]
                    },
                    {
                        "text": "NetPlay with Level obs (oracle spatial memory) achieved 675.33 average score vs 341.67 with Room obs only, demonstrating ~98% improvement from spatial memory",
                        "uuids": [
                            "e2945.6"
                        ]
                    }
                ]
            }
        },
        {
            "law": {
                "if": [
                    {
                        "subject": "task",
                        "relation": "requires",
                        "object": "multi-step hierarchical planning"
                    },
                    {
                        "subject": "agent",
                        "relation": "uses",
                        "object": "hierarchical subgoal-chunked memory"
                    }
                ],
                "then": [
                    {
                        "subject": "agent",
                        "relation": "achieves",
                        "object": "higher task completion rate"
                    },
                    {
                        "subject": "agent",
                        "relation": "reduces",
                        "object": "redundant exploration and token usage by 30-70%"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "HIAGENT with hierarchical subgoal memory doubled success rate from 21% to 42% (+21 pp) and reduced average steps by 3.8 while reducing context tokens by ~35%",
                        "uuids": [
                            "e2937.0"
                        ]
                    },
                    {
                        "text": "SWIFTSAGE with action-buffer and hierarchical planning improved overall score from 49.22 (SWIFT-only) to 84.68 (+35.46 points, ~72% relative improvement) on ScienceWorld",
                        "uuids": [
                            "e2977.0",
                            "e2977.1"
                        ]
                    },
                    {
                        "text": "LLaMA-Rider with subtask relabeling memory improved success rate from ~20% to ~34% (+14 pp) and accomplished 25/30 tasks vs 16/30 without subtask memory",
                        "uuids": [
                            "e2917.0"
                        ]
                    },
                    {
                        "text": "DEPS uses plan-based short-term memory where plans act as transient memory guiding immediate actions in multi-step Minecraft tasks",
                        "uuids": [
                            "e2931.0"
                        ]
                    },
                    {
                        "text": "Ghost in Minecraft uses text-based knowledge and memory to handle long-horizon tasks and adapt to uncertainty in open-world environment",
                        "uuids": [
                            "e2931.5",
                            "e2930.2"
                        ]
                    },
                    {
                        "text": "HiAgent uses sub-goals as memory chunks to manage working memory, maintaining task continuity and coherence in long-horizon tasks",
                        "uuids": [
                            "e2942.1"
                        ]
                    },
                    {
                        "text": "ReadAgent with episodic gist memory improved by +12.97% LLM rating and +31.98% ROUGE-L over best retrieval baseline on NarrativeQA, enabling 3.5-20x effective context length",
                        "uuids": [
                            "e2929.0"
                        ]
                    }
                ]
            }
        },
        {
            "law": {
                "if": [
                    {
                        "subject": "task",
                        "relation": "requires",
                        "object": "social reasoning and relationship tracking"
                    },
                    {
                        "subject": "agent",
                        "relation": "uses",
                        "object": "relationship-centric social memory"
                    }
                ],
                "then": [
                    {
                        "subject": "agent",
                        "relation": "maintains",
                        "object": "consistent social behavior"
                    },
                    {
                        "subject": "agent",
                        "relation": "improves",
                        "object": "information gathering accuracy by 15-20 percentage points"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "ThinkThrice with per-agent relationship memory improved factual QA accuracy from 0.305 (no memory) to 0.498 (full system) in Jubensha multi-agent mystery game",
                        "uuids": [
                            "e2966.0"
                        ]
                    },
                    {
                        "text": "AGA with Social Memory (relationship & feeling summaries) maintained comparable human-likeness while reducing tokens to 31.1% of baseline in generative agents simulation",
                        "uuids": [
                            "e2949.1",
                            "e2949.0"
                        ]
                    },
                    {
                        "text": "AMONGAGENTS with summarized interaction memory and planner module improved win rates and task completion in text-based Among Us",
                        "uuids": [
                            "e2915.0"
                        ]
                    },
                    {
                        "text": "WarAgent with Board (external relations) and Stick (internal state) memory achieved 77.78% alliance accuracy and 54.60% war-declaration accuracy in WWI simulation",
                        "uuids": [
                            "e2898.0"
                        ]
                    },
                    {
                        "text": "Generative Agents with persistent memory streams enable coherent personas and emergent social dynamics like information diffusion and cooperative gatherings",
                        "uuids": [
                            "e2923.0",
                            "e2949.0"
                        ]
                    }
                ]
            }
        },
        {
            "law": {
                "if": [
                    {
                        "subject": "task",
                        "relation": "requires",
                        "object": "procedural skill execution"
                    },
                    {
                        "subject": "agent",
                        "relation": "uses",
                        "object": "case-based procedural memory"
                    }
                ],
                "then": [
                    {
                        "subject": "agent",
                        "relation": "reduces",
                        "object": "redundant LLM calls by 60-70%"
                    },
                    {
                        "subject": "agent",
                        "relation": "improves",
                        "object": "execution consistency"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "AGA with Lifestyle Policy (case-based plan memory) reduced tokens to 40.2% of baseline while maintaining performance in VirtualHome",
                        "uuids": [
                            "e2949.1"
                        ]
                    },
                    {
                        "text": "Voyager with skill library (procedural memory) enables lifelong learning and skill reuse in open-ended Minecraft, improving sample efficiency",
                        "uuids": [
                            "e2902.1",
                            "e2940.1",
                            "e2930.3"
                        ]
                    },
                    {
                        "text": "CB-GDA with case-based memory (PCB and MCB) outperformed rule-based GDA and non-GDA replanning in complex adversarial gaming scenarios",
                        "uuids": [
                            "e2910.1"
                        ]
                    }
                ]
            }
        },
        {
            "law": {
                "if": [
                    {
                        "subject": "memory structure",
                        "relation": "misaligns with",
                        "object": "task structure"
                    },
                    {
                        "subject": "agent",
                        "relation": "attempts to use",
                        "object": "misaligned memory"
                    }
                ],
                "then": [
                    {
                        "subject": "agent",
                        "relation": "performs worse than or equal to",
                        "object": "simpler aligned memory or no explicit memory"
                    },
                    {
                        "subject": "retrieval",
                        "relation": "returns",
                        "object": "irrelevant or incomplete information"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Unstructured full history memory achieved only 0.47 on Treasure Hunt vs 1.0 for graph-based AriGraph, despite containing all information",
                        "uuids": [
                            "e2945.1"
                        ]
                    },
                    {
                        "text": "Simple short-history augmentation (1 past obs + 5 actions) degraded WebShop performance from 59.9 to 57.3, showing naive memory can hurt",
                        "uuids": [
                            "e2943.0"
                        ]
                    },
                    {
                        "text": "Flat episodic memory (Simulacra-style) achieved only 0.40 on Treasure Hunt vs 1.0 for graph memory, showing unstructured memory fails on relational tasks",
                        "uuids": [
                            "e2945.4"
                        ]
                    },
                    {
                        "text": "GATA with learned belief graphs largely ignored textual instructions and failed to complete tasks, showing graph memory alone insufficient without proper task alignment",
                        "uuids": [
                            "e2960.0"
                        ]
                    },
                    {
                        "text": "MemWalker hierarchical summary tree had high search failure rate (~8.6%) and underperformed ReadAgent by ~20 pp on QuALITY due to traversal unreliability",
                        "uuids": [
                            "e2929.1"
                        ]
                    }
                ]
            }
        },
        {
            "law": {
                "if": [
                    {
                        "subject": "task",
                        "relation": "has",
                        "object": "high structural complexity"
                    },
                    {
                        "subject": "memory structure",
                        "relation": "matches",
                        "object": "task structure"
                    }
                ],
                "then": [
                    {
                        "subject": "performance improvement",
                        "relation": "scales with",
                        "object": "task complexity"
                    },
                    {
                        "subject": "improvement magnitude",
                        "relation": "is larger for",
                        "object": "harder task variants"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "HIAGENT showed larger relative improvements on complex tasks (2.3x SR improvement) vs composite tasks (1.3x SR improvement)",
                        "uuids": [
                            "e2937.0"
                        ]
                    },
                    {
                        "text": "AriGraph achieved 1.0 on Treasure Hunt but only 0.52 on Cooking Hard, showing structure helps more when task structure is clearer",
                        "uuids": [
                            "e2945.0"
                        ]
                    },
                    {
                        "text": "GATA improvements over text-only baseline were larger on higher difficulty TextWorld levels",
                        "uuids": [
                            "e2968.0"
                        ]
                    },
                    {
                        "text": "MC-DML with cross-trial memory showed larger absolute improvements on harder Jericho games (e.g., Zork1 +10.33 points)",
                        "uuids": [
                            "e2927.0"
                        ]
                    }
                ]
            }
        }
    ],
    "new_predictions_likely": [
        "For puzzle games requiring causal reasoning (e.g., if-then dependencies), memory structured as causal graphs will outperform both spatial graphs and sequential memory by 40-80%",
        "For time-sensitive games with deadlines and temporal constraints, memory with explicit temporal indexing and deadline tracking will outperform memory organized by other dimensions by 30-50%",
        "For games with inventory management and item transformations, memory structured around object properties and transformation rules will outperform location-based memory by 25-60%",
        "For dialogue-heavy games requiring conversation history, memory structured as dialogue trees with speaker attribution will outperform flat sequential memory by 20-40%",
        "For games with multiple parallel objectives, memory structured with explicit goal-tracking will outperform single-thread memory by 35-70%"
    ],
    "new_predictions_unknown": [
        "Whether a single adaptive memory structure that dynamically reorganizes based on detected task patterns could match or exceed task-specific memory structures across diverse game types",
        "Whether hybrid memory structures (e.g., combining spatial graphs with temporal sequences and social relationships) provide benefits proportional to their added complexity, or if they introduce interference",
        "Whether LLMs can learn to automatically infer optimal memory structure from task descriptions or early gameplay experience without explicit programming",
        "Whether the optimal memory structure changes during gameplay as the agent learns more about the environment, or if initial structure choice determines long-term performance",
        "Whether memory structure alignment is more important for smaller LLMs (which may have less implicit reasoning capacity) than for larger LLMs",
        "Whether certain memory structures are inherently more sample-efficient during learning, independent of task alignment"
    ],
    "negative_experiments": [
        "Finding spatial navigation tasks where unstructured sequential memory consistently outperforms graph-based memory would challenge the structure-alignment principle",
        "Demonstrating that a single universal memory structure performs optimally across all task types (spatial, social, procedural, temporal) would invalidate the need for task-specific memory design",
        "Showing that randomly structured memory performs as well as task-aligned memory on complex tasks would question the importance of structural alignment",
        "Finding cases where adding more structure-aligned memory consistently degrades performance would challenge the theory's core premise",
        "Demonstrating that memory structure has no effect on performance when controlling for memory capacity would invalidate the structure-task alignment hypothesis"
    ],
    "unaccounted_for": [
        {
            "text": "How to automatically determine optimal memory structure from task characteristics without manual design or extensive trial-and-error",
            "uuids": []
        },
        {
            "text": "The computational costs and trade-offs of maintaining multiple memory structures simultaneously for multi-faceted tasks",
            "uuids": []
        },
        {
            "text": "Why some simple prompt-based memory approaches (like ReAct with thoughts) perform well across diverse tasks without explicit structure",
            "uuids": [
                "e2971.0"
            ]
        },
        {
            "text": "How reflection-based memory (storing self-critiques) relates to structural memory and whether they are complementary or substitutable",
            "uuids": [
                "e2933.0",
                "e2907.0",
                "e2927.0",
                "e2941.0"
            ]
        },
        {
            "text": "Whether certain LLM architectures or sizes are more or less dependent on structured external memory",
            "uuids": [
                "e2974.0",
                "e2974.2"
            ]
        },
        {
            "text": "How memory structure interacts with other agent components like planning modules and action selection mechanisms",
            "uuids": [
                "e2977.0",
                "e2935.1"
            ]
        },
        {
            "text": "Why some agents with minimal memory (like CALM with 2-step window) can still achieve reasonable performance",
            "uuids": [
                "e2973.0"
            ]
        },
        {
            "text": "How to handle tasks that require multiple types of structure simultaneously (e.g., spatial + social + temporal)",
            "uuids": []
        },
        {
            "text": "Whether memory structure requirements change as agents gain more experience in an environment",
            "uuids": []
        },
        {
            "text": "How partial observability affects the relative importance of memory structure",
            "uuids": [
                "e2968.0",
                "e2972.0"
            ]
        }
    ],
    "conflicting_evidence": [
        {
            "text": "ReAct with simple thought-based memory (no explicit structure) achieved 71% success on ALFWorld, competitive with structured approaches, suggesting structure may not always be critical",
            "uuids": [
                "e2971.0"
            ]
        },
        {
            "text": "GATA with graph-based memory failed to improve performance when the graph updater was inaccurate or when policy didn't exploit graph relations, showing structure alone is insufficient",
            "uuids": [
                "e2960.0"
            ]
        },
        {
            "text": "Simple short-term prompt memory (3 obs + 2 actions) in GFlan-T5 achieved 0.82 success, outperforming some structured approaches, suggesting capacity may matter more than structure for some tasks",
            "uuids": [
                "e2974.0"
            ]
        },
        {
            "text": "NPAE-Flan-T5 with same memory structure as GFlan-T5 but without pretraining failed completely, suggesting LLM capabilities matter more than memory structure",
            "uuids": [
                "e2974.2"
            ]
        },
        {
            "text": "ChatGPT with walkthrough-fed memory showed strong memorization but poor generalization, suggesting memory content and retrieval quality may matter more than structure",
            "uuids": [
                "e2978.2"
            ]
        },
        {
            "text": "Some agents with no explicit memory mechanism (like constrained-prompt LLM agents) performed reasonably on symbolic tasks, questioning necessity of explicit memory",
            "uuids": [
                "e2901.0"
            ]
        }
    ],
    "special_cases": [
        "For very small state spaces or short episodes (&lt;10 steps), the benefits of structured memory may not justify the implementation complexity and overhead",
        "In fully observable environments where all information is always available, spatial graph structure may provide minimal advantage over sequential memory",
        "For tasks with frequently changing structure or non-stationary dynamics, rigid memory structures may be less effective than adaptive unstructured memory",
        "When the LLM has strong pretraining on similar tasks, the need for explicit structured memory may be reduced as the model can leverage internal representations",
        "For tasks where the optimal structure is unclear or mixed (e.g., requiring both spatial and social reasoning), hybrid or flexible memory may be necessary",
        "When memory capacity is severely limited (e.g., &lt;5 entries), structure may matter less than what specific information is retained",
        "For very large LLMs (e.g., GPT-4), the relative benefit of structured memory may be smaller as the model has more internal capacity for implicit structure",
        "In tasks with high stochasticity or randomness, memory structure may be less important than memory update frequency and recency weighting",
        "When retrieval mechanisms are poor or noisy, even well-structured memory may fail to provide benefits",
        "For tasks requiring real-time response, the computational cost of maintaining complex memory structures may outweigh their benefits"
    ],
    "existing_theory": {
        "likely_classification": "new",
        "references": [
            "Adhikari et al. (2020) Learning Dynamic Belief Graphs to Generalize on Text-Based Games [Demonstrates graph-based memory benefits for text games but doesn't formalize the general structure-task alignment principle or compare across memory types]",
            "Ammanabrolu et al. (2020) Graph Constrained Reinforcement Learning for Natural Language Action Spaces [Shows knowledge graph advantages for action generation but doesn't theorize about when different structures are optimal]",
            "Hu et al. (2024) AriGraph: Learning Knowledge Graph World Models with Episodic Memory for LLM Agents [Demonstrates graph memory advantages and compares to some alternatives, but doesn't formalize the general principle of structure-task alignment]",
            "Hausknecht et al. (2020) Learning Dynamic Belief Graphs to Generalize on Text-Based Games [Proposes dynamic belief graphs but focuses on single memory type rather than alignment principle]",
            "Park et al. (2023) Generative Agents: Interactive Simulacra of Human Behavior [Demonstrates episodic memory for social simulation but doesn't compare structural alternatives or formalize alignment]",
            "Wang et al. (2024) HiAgent: Hierarchical Working Memory Management [Shows hierarchical memory benefits but doesn't formalize when hierarchical vs other structures are optimal]"
        ]
    },
    "theory_type_general_specific": "specific",
    "reflected_from_theory_index": 1,
    "type": "specific"
}</code></pre>
        </div>
    </div>
</body>
</html>