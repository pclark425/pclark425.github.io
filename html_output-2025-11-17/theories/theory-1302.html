<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Semantic Fidelity Theory of Graph-to-Text Representation - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-1302</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-1302</p>
                <p><strong>Name:</strong> Semantic Fidelity Theory of Graph-to-Text Representation</p>
                <p><strong>Type:</strong> general</p>
                <p><strong>Theory Query:</strong> Build a theory of ideal representations for converting graphs into text for language model training.</p>
                <p><strong>Description:</strong> This theory posits that the ideal representation for converting graphs into text for language model training is one that maximizes semantic fidelity: the preservation and explicit encoding of all graph semantics (nodes, edges, attributes, and higher-order structures) in a form that is both interpretable and compositional for language models. The theory asserts that representations which maintain explicit, lossless mappings between graph elements and their textual counterparts enable language models to learn graph-structured reasoning and generalize to unseen graph types.</p>
                <p><strong>Knowledge Cutoff Year:</strong> -1</p>
                <p><strong>Knowledge Cutoff Month:</strong> -1</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <h3>Statement 0: Semantic Preservation Law (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; graph_representation &#8594; encodes &#8594; all_graph_elements_explicitly<span style="color: #888888;">, and</span></div>
        <div>&#8226; graph_representation &#8594; preserves &#8594; graph_structure_and_attributes</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; language_model &#8594; can_learn &#8594; graph_semantics_and_reasoning<span style="color: #888888;">, and</span></div>
        <div>&#8226; graph_to_text_conversion &#8594; is_lossless &#8594; True</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Empirical studies show that explicit, structured graph encodings (e.g., linearized triples, adjacency lists with attributes) improve downstream reasoning and QA performance over bag-of-edges or naive text serialization. </li>
    <li>Lossy or ambiguous representations (e.g., simple node lists) result in degraded model performance and inability to reconstruct the original graph. </li>
    <li>Explicit encodings such as RDF triples are widely used in knowledge graph-to-text tasks and are shown to preserve semantics for both humans and models. </li>
    <li>Graph-to-text models trained on lossless representations can reconstruct the original graph with high accuracy, while those trained on lossy representations cannot. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> While related to existing work on structured data-to-text and semantic parsing, the explicit requirement for lossless, compositional, and fully interpretable representations is a novel, formalized principle.</p>            <p><strong>What Already Exists:</strong> Existing work recognizes that preserving graph structure in text improves model performance, and that explicit encodings (e.g., RDF triples) are beneficial.</p>            <p><strong>What is Novel:</strong> The law formalizes the necessity of explicit, lossless, and compositional encoding for ideal graph-to-text conversion, extending beyond current practice to require full semantic preservation.</p>
            <p><strong>References:</strong> <ul>
    <li>Koncel-Kedziorski et al. (2019) Text Generation from Knowledge Graphs with Graph Transformers [Shows benefit of explicit graph encodings]</li>
    <li>Ribeiro et al. (2020) Beyond Accuracy: Behavioral Testing of NLP Models with CheckList [Highlights importance of semantic preservation in model evaluation]</li>
    <li>Gardent et al. (2017) The WebNLG Challenge: Generating Text from RDF Data [RDF triples as explicit, lossless representations]</li>
</ul>
            <h3>Statement 1: Compositionality and Interpretability Law (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; graph_representation &#8594; is_compositional &#8594; True<span style="color: #888888;">, and</span></div>
        <div>&#8226; graph_representation &#8594; is_interpretable &#8594; True</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; language_model &#8594; can_generalize &#8594; to_unseen_graph_structures<span style="color: #888888;">, and</span></div>
        <div>&#8226; model_training &#8594; is_sample_efficient &#8594; True</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Compositional representations (e.g., nested or recursive text forms) allow models to learn reusable graph patterns and generalize to larger or novel graphs. </li>
    <li>Interpretability in representation (e.g., human-readable, modular) correlates with improved debugging and transfer learning. </li>
    <li>Studies in compositional generalization show that models trained on modular, interpretable representations require fewer examples to generalize to new structures. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> The law synthesizes two desiderata into a formal requirement for graph-to-text conversion, which is not explicitly stated in prior work.</p>            <p><strong>What Already Exists:</strong> Compositionality is a known desideratum in representation learning, and interpretability is valued in explainable AI.</p>            <p><strong>What is Novel:</strong> This law asserts that both compositionality and interpretability are necessary and jointly sufficient for ideal graph-to-text representations in language model training.</p>
            <p><strong>References:</strong> <ul>
    <li>Lake et al. (2017) Building Machines That Learn and Think Like People [Compositionality in learning]</li>
    <li>Doshi-Velez & Kim (2017) Towards a Rigorous Science of Interpretable Machine Learning [Interpretability in ML]</li>
    <li>Furrer et al. (2022) Compositional Generalization in Semantic Parsing [Compositionality in structured-to-text tasks]</li>
</ul>
            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>If a new graph domain (e.g., chemical molecules) is encoded with explicit, compositional, and interpretable text, language models will generalize to novel molecules with minimal additional training.</li>
                <li>Lossless, explicit graph-to-text representations will enable language models to reconstruct the original graph with high fidelity, even for large or complex graphs.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>For highly cyclic or self-referential graphs, explicit compositional representations may reach a complexity threshold where language models fail to generalize, revealing limits of compositionality.</li>
                <li>If a language model is trained on a fully lossless, interpretable graph-to-text representation, it may develop emergent abilities for graph isomorphism detection or subgraph matching, even without explicit supervision.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>If a language model trained on explicit, lossless graph-to-text representations fails to reconstruct the original graph or reason about graph structure, the theory is called into question.</li>
                <li>If compositional and interpretable representations do not improve generalization or sample efficiency over naive encodings, the theory is challenged.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>The impact of representation length and verbosity on model efficiency and scalability is not fully addressed. </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> somewhat-related-to-existing</p>
            <p><strong>Explanation:</strong> The theory synthesizes and formalizes desiderata from multiple subfields into a unified, testable framework for graph-to-text representation.</p>
            <p><strong>References:</strong> <ul>
    <li>Koncel-Kedziorski et al. (2019) Text Generation from Knowledge Graphs with Graph Transformers [Explicit encodings]</li>
    <li>Lake et al. (2017) Building Machines That Learn and Think Like People [Compositionality]</li>
    <li>Doshi-Velez & Kim (2017) Towards a Rigorous Science of Interpretable Machine Learning [Interpretability]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Semantic Fidelity Theory of Graph-to-Text Representation",
    "theory_description": "This theory posits that the ideal representation for converting graphs into text for language model training is one that maximizes semantic fidelity: the preservation and explicit encoding of all graph semantics (nodes, edges, attributes, and higher-order structures) in a form that is both interpretable and compositional for language models. The theory asserts that representations which maintain explicit, lossless mappings between graph elements and their textual counterparts enable language models to learn graph-structured reasoning and generalize to unseen graph types.",
    "theory_statements": [
        {
            "law": {
                "law_name": "Semantic Preservation Law",
                "if": [
                    {
                        "subject": "graph_representation",
                        "relation": "encodes",
                        "object": "all_graph_elements_explicitly"
                    },
                    {
                        "subject": "graph_representation",
                        "relation": "preserves",
                        "object": "graph_structure_and_attributes"
                    }
                ],
                "then": [
                    {
                        "subject": "language_model",
                        "relation": "can_learn",
                        "object": "graph_semantics_and_reasoning"
                    },
                    {
                        "subject": "graph_to_text_conversion",
                        "relation": "is_lossless",
                        "object": "True"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Empirical studies show that explicit, structured graph encodings (e.g., linearized triples, adjacency lists with attributes) improve downstream reasoning and QA performance over bag-of-edges or naive text serialization.",
                        "uuids": []
                    },
                    {
                        "text": "Lossy or ambiguous representations (e.g., simple node lists) result in degraded model performance and inability to reconstruct the original graph.",
                        "uuids": []
                    },
                    {
                        "text": "Explicit encodings such as RDF triples are widely used in knowledge graph-to-text tasks and are shown to preserve semantics for both humans and models.",
                        "uuids": []
                    },
                    {
                        "text": "Graph-to-text models trained on lossless representations can reconstruct the original graph with high accuracy, while those trained on lossy representations cannot.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Existing work recognizes that preserving graph structure in text improves model performance, and that explicit encodings (e.g., RDF triples) are beneficial.",
                    "what_is_novel": "The law formalizes the necessity of explicit, lossless, and compositional encoding for ideal graph-to-text conversion, extending beyond current practice to require full semantic preservation.",
                    "classification_explanation": "While related to existing work on structured data-to-text and semantic parsing, the explicit requirement for lossless, compositional, and fully interpretable representations is a novel, formalized principle.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Koncel-Kedziorski et al. (2019) Text Generation from Knowledge Graphs with Graph Transformers [Shows benefit of explicit graph encodings]",
                        "Ribeiro et al. (2020) Beyond Accuracy: Behavioral Testing of NLP Models with CheckList [Highlights importance of semantic preservation in model evaluation]",
                        "Gardent et al. (2017) The WebNLG Challenge: Generating Text from RDF Data [RDF triples as explicit, lossless representations]"
                    ]
                }
            }
        },
        {
            "law": {
                "law_name": "Compositionality and Interpretability Law",
                "if": [
                    {
                        "subject": "graph_representation",
                        "relation": "is_compositional",
                        "object": "True"
                    },
                    {
                        "subject": "graph_representation",
                        "relation": "is_interpretable",
                        "object": "True"
                    }
                ],
                "then": [
                    {
                        "subject": "language_model",
                        "relation": "can_generalize",
                        "object": "to_unseen_graph_structures"
                    },
                    {
                        "subject": "model_training",
                        "relation": "is_sample_efficient",
                        "object": "True"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Compositional representations (e.g., nested or recursive text forms) allow models to learn reusable graph patterns and generalize to larger or novel graphs.",
                        "uuids": []
                    },
                    {
                        "text": "Interpretability in representation (e.g., human-readable, modular) correlates with improved debugging and transfer learning.",
                        "uuids": []
                    },
                    {
                        "text": "Studies in compositional generalization show that models trained on modular, interpretable representations require fewer examples to generalize to new structures.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Compositionality is a known desideratum in representation learning, and interpretability is valued in explainable AI.",
                    "what_is_novel": "This law asserts that both compositionality and interpretability are necessary and jointly sufficient for ideal graph-to-text representations in language model training.",
                    "classification_explanation": "The law synthesizes two desiderata into a formal requirement for graph-to-text conversion, which is not explicitly stated in prior work.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Lake et al. (2017) Building Machines That Learn and Think Like People [Compositionality in learning]",
                        "Doshi-Velez & Kim (2017) Towards a Rigorous Science of Interpretable Machine Learning [Interpretability in ML]",
                        "Furrer et al. (2022) Compositional Generalization in Semantic Parsing [Compositionality in structured-to-text tasks]"
                    ]
                }
            }
        }
    ],
    "new_predictions_likely": [
        "If a new graph domain (e.g., chemical molecules) is encoded with explicit, compositional, and interpretable text, language models will generalize to novel molecules with minimal additional training.",
        "Lossless, explicit graph-to-text representations will enable language models to reconstruct the original graph with high fidelity, even for large or complex graphs."
    ],
    "new_predictions_unknown": [
        "For highly cyclic or self-referential graphs, explicit compositional representations may reach a complexity threshold where language models fail to generalize, revealing limits of compositionality.",
        "If a language model is trained on a fully lossless, interpretable graph-to-text representation, it may develop emergent abilities for graph isomorphism detection or subgraph matching, even without explicit supervision."
    ],
    "negative_experiments": [
        "If a language model trained on explicit, lossless graph-to-text representations fails to reconstruct the original graph or reason about graph structure, the theory is called into question.",
        "If compositional and interpretable representations do not improve generalization or sample efficiency over naive encodings, the theory is challenged."
    ],
    "unaccounted_for": [
        {
            "text": "The impact of representation length and verbosity on model efficiency and scalability is not fully addressed.",
            "uuids": []
        }
    ],
    "conflicting_evidence": [
        {
            "text": "Some studies show that highly compressed or learned representations (e.g., graph embeddings) can outperform explicit encodings in certain tasks, suggesting that lossless explicitness may not always be optimal.",
            "uuids": []
        }
    ],
    "special_cases": [
        "Graphs with extremely high degree or dense connectivity may require alternative representations to avoid combinatorial explosion.",
        "Graphs with non-symbolic attributes (e.g., images, continuous values) may not be fully captured by text-based explicit encodings."
    ],
    "existing_theory": {
        "what_already_exists": "Explicit, structured encodings are known to improve model performance, and compositionality/interpretability are valued in representation learning.",
        "what_is_novel": "The formalization of semantic fidelity as the central criterion, and the joint necessity of compositionality and interpretability for ideal graph-to-text conversion, is novel.",
        "classification_explanation": "The theory synthesizes and formalizes desiderata from multiple subfields into a unified, testable framework for graph-to-text representation.",
        "likely_classification": "somewhat-related-to-existing",
        "references": [
            "Koncel-Kedziorski et al. (2019) Text Generation from Knowledge Graphs with Graph Transformers [Explicit encodings]",
            "Lake et al. (2017) Building Machines That Learn and Think Like People [Compositionality]",
            "Doshi-Velez & Kim (2017) Towards a Rigorous Science of Interpretable Machine Learning [Interpretability]"
        ]
    },
    "reflected_from_theory_index": 0,
    "type": "general",
    "version": "built-theory-from-results-single-theory-reflection2-nov14-2025-LLM-BASELINE-no-evidence-without-matched-control-theory-name",
    "theory_query": "Build a theory of ideal representations for converting graphs into text for language model training.",
    "original_theory_id": "theory-615",
    "original_theory_name": "Order-Invariance Robustness Law for Graph Linearization in LLMs",
    "provide_matched_control_thery_name": false,
    "matched_control_theory_name": null,
    "model_str": "openai/gpt-4.1-2025-04-14"
}</code></pre>
        </div>
    </div>
</body>
</html>