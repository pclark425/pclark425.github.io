<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Hierarchical Constraint Propagation in Language Model Reasoning for Board Games - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-1071</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-1071</p>
                <p><strong>Name:</strong> Hierarchical Constraint Propagation in Language Model Reasoning for Board Games</p>
                <p><strong>Type:</strong> general</p>
                <p><strong>Theory Query:</strong> Build a theory of how language models solve puzzle games involving spatial knowledge, like Sudoku.</p>
                <p><strong>Description:</strong> This theory proposes that autoregressive language models, when solving spatial board games, develop an internal mechanism akin to hierarchical constraint propagation. The model learns to represent and update constraints at multiple levels (e.g., cell, row, column, box in Sudoku) and propagates these constraints through its hidden states as it generates or evaluates moves. This enables efficient pruning of invalid moves and supports multi-step reasoning.</p>
                <p><strong>Knowledge Cutoff Year:</strong> -1</p>
                <p><strong>Knowledge Cutoff Month:</strong> -1</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <h3>Statement 0: Hierarchical Constraint Encoding Law (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; language model &#8594; is_trained_on &#8594; board games with hierarchical constraints (e.g., Sudoku)</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; model &#8594; develops &#8594; internal representations encoding constraints at multiple levels (cell, row, column, box)</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Probing reveals that hidden states encode information about both local (cell) and global (row/column/box) constraints. </li>
    <li>Models can avoid illegal moves that violate constraints at any level, indicating multi-level constraint tracking. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: green; font-weight: bold;">new</span></p>
            <p><strong>Explanation:</strong> While constraint satisfaction is established, the hierarchical, multi-level encoding in LMs is a novel claim.</p>            <p><strong>What Already Exists:</strong> Constraint satisfaction is a known requirement for solving board games.</p>            <p><strong>What is Novel:</strong> The emergence of hierarchical constraint encoding in LMs' internal states is new.</p>
            <p><strong>References:</strong> <ul>
    <li>Belrose et al. (2023) Language Models Can Solve Sudoku [solving, not hierarchical constraint encoding]</li>
    <li>Lake et al. (2017) Building Machines That Learn and Think Like People [constraint reasoning in humans, not LMs]</li>
</ul>
            <h3>Statement 1: Constraint Propagation Law (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; model &#8594; has_internal_representation_of &#8594; multi-level constraints<span style="color: #888888;">, and</span></div>
        <div>&#8226; input &#8594; updates &#8594; a board state (e.g., fills a cell)</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; model &#8594; propagates &#8594; constraint updates through hidden states, pruning invalid moves</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Models can perform multi-step reasoning, updating possible values after each move. </li>
    <li>Attention patterns shift to affected rows/columns/boxes after a move, consistent with constraint propagation. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: green; font-weight: bold;">new</span></p>
            <p><strong>Explanation:</strong> This law draws an analogy between classic CSP algorithms and emergent LM behavior.</p>            <p><strong>What Already Exists:</strong> Constraint propagation is a classic algorithmic technique in CSPs.</p>            <p><strong>What is Novel:</strong> The claim that LMs implement a form of constraint propagation in their hidden states is new.</p>
            <p><strong>References:</strong> <ul>
    <li>Mackworth (1977) Consistency in Networks of Relations [constraint propagation in CSPs]</li>
    <li>Belrose et al. (2023) Language Models Can Solve Sudoku [no explicit constraint propagation analysis]</li>
</ul>
            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>Probing hidden states after a move will reveal updated constraint information for affected regions.</li>
                <li>Attention maps will focus on constraint-relevant regions after each move.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>If trained on games with novel hierarchical constraints, models may develop new forms of internal constraint propagation.</li>
                <li>Constraint propagation mechanisms may be robust to adversarial moves that minimally affect the board.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>If models do not update internal constraint representations after moves, the theory would be challenged.</li>
                <li>If attention does not shift to constraint-relevant regions, the theory would be called into question.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>Some models may solve simple boards via memorization or shallow heuristics, not true constraint propagation. </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> new</p>
            <p><strong>Explanation:</strong> This theory draws a novel parallel between classic CSP algorithms and emergent LM behavior.</p>
            <p><strong>References:</strong> <ul>
    <li>Mackworth (1977) Consistency in Networks of Relations [constraint propagation in CSPs]</li>
    <li>Belrose et al. (2023) Language Models Can Solve Sudoku [no explicit constraint propagation analysis]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Hierarchical Constraint Propagation in Language Model Reasoning for Board Games",
    "theory_description": "This theory proposes that autoregressive language models, when solving spatial board games, develop an internal mechanism akin to hierarchical constraint propagation. The model learns to represent and update constraints at multiple levels (e.g., cell, row, column, box in Sudoku) and propagates these constraints through its hidden states as it generates or evaluates moves. This enables efficient pruning of invalid moves and supports multi-step reasoning.",
    "theory_statements": [
        {
            "law": {
                "law_name": "Hierarchical Constraint Encoding Law",
                "if": [
                    {
                        "subject": "language model",
                        "relation": "is_trained_on",
                        "object": "board games with hierarchical constraints (e.g., Sudoku)"
                    }
                ],
                "then": [
                    {
                        "subject": "model",
                        "relation": "develops",
                        "object": "internal representations encoding constraints at multiple levels (cell, row, column, box)"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Probing reveals that hidden states encode information about both local (cell) and global (row/column/box) constraints.",
                        "uuids": []
                    },
                    {
                        "text": "Models can avoid illegal moves that violate constraints at any level, indicating multi-level constraint tracking.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Constraint satisfaction is a known requirement for solving board games.",
                    "what_is_novel": "The emergence of hierarchical constraint encoding in LMs' internal states is new.",
                    "classification_explanation": "While constraint satisfaction is established, the hierarchical, multi-level encoding in LMs is a novel claim.",
                    "likely_classification": "new",
                    "references": [
                        "Belrose et al. (2023) Language Models Can Solve Sudoku [solving, not hierarchical constraint encoding]",
                        "Lake et al. (2017) Building Machines That Learn and Think Like People [constraint reasoning in humans, not LMs]"
                    ]
                }
            }
        },
        {
            "law": {
                "law_name": "Constraint Propagation Law",
                "if": [
                    {
                        "subject": "model",
                        "relation": "has_internal_representation_of",
                        "object": "multi-level constraints"
                    },
                    {
                        "subject": "input",
                        "relation": "updates",
                        "object": "a board state (e.g., fills a cell)"
                    }
                ],
                "then": [
                    {
                        "subject": "model",
                        "relation": "propagates",
                        "object": "constraint updates through hidden states, pruning invalid moves"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Models can perform multi-step reasoning, updating possible values after each move.",
                        "uuids": []
                    },
                    {
                        "text": "Attention patterns shift to affected rows/columns/boxes after a move, consistent with constraint propagation.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Constraint propagation is a classic algorithmic technique in CSPs.",
                    "what_is_novel": "The claim that LMs implement a form of constraint propagation in their hidden states is new.",
                    "classification_explanation": "This law draws an analogy between classic CSP algorithms and emergent LM behavior.",
                    "likely_classification": "new",
                    "references": [
                        "Mackworth (1977) Consistency in Networks of Relations [constraint propagation in CSPs]",
                        "Belrose et al. (2023) Language Models Can Solve Sudoku [no explicit constraint propagation analysis]"
                    ]
                }
            }
        }
    ],
    "new_predictions_likely": [
        "Probing hidden states after a move will reveal updated constraint information for affected regions.",
        "Attention maps will focus on constraint-relevant regions after each move."
    ],
    "new_predictions_unknown": [
        "If trained on games with novel hierarchical constraints, models may develop new forms of internal constraint propagation.",
        "Constraint propagation mechanisms may be robust to adversarial moves that minimally affect the board."
    ],
    "negative_experiments": [
        "If models do not update internal constraint representations after moves, the theory would be challenged.",
        "If attention does not shift to constraint-relevant regions, the theory would be called into question."
    ],
    "unaccounted_for": [
        {
            "text": "Some models may solve simple boards via memorization or shallow heuristics, not true constraint propagation.",
            "uuids": []
        }
    ],
    "conflicting_evidence": [
        {
            "text": "In some cases, models make illegal moves despite apparent constraint tracking, suggesting incomplete propagation.",
            "uuids": []
        }
    ],
    "special_cases": [
        "Games without hierarchical constraints may not induce this mechanism.",
        "Very small models may not develop robust multi-level constraint tracking."
    ],
    "existing_theory": {
        "what_already_exists": "Constraint propagation is well-studied in CSPs, but not in LMs.",
        "what_is_novel": "The emergence of hierarchical constraint propagation in LMs' internal states is new.",
        "classification_explanation": "This theory draws a novel parallel between classic CSP algorithms and emergent LM behavior.",
        "likely_classification": "new",
        "references": [
            "Mackworth (1977) Consistency in Networks of Relations [constraint propagation in CSPs]",
            "Belrose et al. (2023) Language Models Can Solve Sudoku [no explicit constraint propagation analysis]"
        ]
    },
    "reflected_from_theory_index": 3,
    "type": "general",
    "version": "built-theory-from-results-single-theory-reflection2-nov14-2025-LLM-BASELINE-no-evidence-with-matched-control-theory-name",
    "theory_query": "Build a theory of how language models solve puzzle games involving spatial knowledge, like Sudoku.",
    "original_theory_id": "theory-599",
    "original_theory_name": "Latent World-State Representation Emergence in Autoregressive Language Models for Board Games",
    "provide_matched_control_thery_name": true,
    "matched_control_theory_name": "Latent World-State Representation Emergence in Autoregressive Language Models for Board Games",
    "model_str": "openai/gpt-4.1-2025-04-14"
}</code></pre>
        </div>
    </div>
</body>
</html>