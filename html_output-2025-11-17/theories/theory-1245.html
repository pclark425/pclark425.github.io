<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Semantic Fidelity Theory of Graph-to-Text Representation - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-1245</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-1245</p>
                <p><strong>Name:</strong> Semantic Fidelity Theory of Graph-to-Text Representation</p>
                <p><strong>Type:</strong> general</p>
                <p><strong>Theory Query:</strong> Build a theory of ideal representations for converting graphs into text for language model training.</p>
                <p><strong>Description:</strong> This theory posits that the ideal representation for converting graphs into text for language model training is one that maximizes semantic fidelity: the preservation and explicit encoding of all graph semantics (nodes, edges, attributes, and higher-order structures) in a form that is both interpretable and learnable by language models. The theory asserts that representations which maintain the full spectrum of graph meaning, including implicit and explicit relationships, will enable language models to generalize, reason, and generate text that accurately reflects the underlying graph structure.</p>
                <p><strong>Knowledge Cutoff Year:</strong> -1</p>
                <p><strong>Knowledge Cutoff Month:</strong> -1</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <h3>Statement 0: Semantic Preservation Law (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; graph_to_text_representation &#8594; encodes &#8594; all_graph_semantics</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; language_model_trained_on_representation &#8594; achieves &#8594; maximal_graph_understanding</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Lossy representations (e.g., simple edge lists) lead to information loss and reduced downstream performance. </li>
    <li>Graph neural networks and structured encodings that preserve node/edge/attribute information outperform bag-of-edges or adjacency-only approaches. </li>
    <li>Textual representations that explicitly encode graph structure (e.g., via serialization or templates) enable LMs to reconstruct the original graph more accurately. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> While semantic preservation is valued in other domains, its formalization as the core law for graph-to-text LM representation is new.</p>            <p><strong>What Already Exists:</strong> Semantic preservation is a guiding principle in data serialization and some graph neural network approaches.</p>            <p><strong>What is Novel:</strong> The explicit application of semantic fidelity as the central criterion for graph-to-text LM training is novel.</p>
            <p><strong>References:</strong> <ul>
    <li>Vashishth et al. (2020) Composition-based Multi-Relational Graph Convolutional Networks [Semantic composition in GNNs]</li>
    <li>Koncel-Kedziorski et al. (2019) Text Generation from Knowledge Graphs with Graph Transformers [Graph semantics in text generation]</li>
    <li>Ribeiro et al. (2020) Structural Encoding in Language Models [Explicit structure encoding for LMs]</li>
</ul>
            <h3>Statement 1: Learnability-Interpretability Tradeoff Law (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; graph_to_text_representation &#8594; increases &#8594; semantic_explicitness<span style="color: #888888;">, and</span></div>
        <div>&#8226; graph_to_text_representation &#8594; increases &#8594; representation_complexity</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; language_model &#8594; may_experience &#8594; diminishing_returns_in_performance</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Highly explicit representations (e.g., verbose templates) can overwhelm LMs and reduce generalization. </li>
    <li>There is a tradeoff between interpretability (for humans and models) and the learnability of the representation. </li>
    <li>Empirical studies show that overly complex encodings can lead to overfitting or information overload. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> The law is conceptually related to known tradeoffs but is newly formalized for this domain.</p>            <p><strong>What Already Exists:</strong> Tradeoffs between interpretability and learnability are discussed in ML and NLP literature.</p>            <p><strong>What is Novel:</strong> The explicit framing of this tradeoff for graph-to-text LM representations is novel.</p>
            <p><strong>References:</strong> <ul>
    <li>Doshi-Velez & Kim (2017) Towards A Rigorous Science of Interpretable Machine Learning [Interpretability vs. complexity]</li>
    <li>Koncel-Kedziorski et al. (2019) Text Generation from Knowledge Graphs with Graph Transformers [Graph-to-text complexity]</li>
    <li>Ribeiro et al. (2020) Structural Encoding in Language Models [Encoding complexity and LM performance]</li>
</ul>
            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>Representations that encode all node, edge, and attribute semantics will enable LMs to reconstruct graphs with higher accuracy than those using partial or lossy encodings.</li>
                <li>There will be a point of diminishing returns where increasing representation explicitness no longer improves, or may even harm, LM performance.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>The optimal balance between semantic explicitness and representation complexity for maximal LM performance is unknown and may vary by graph domain.</li>
                <li>It is unknown whether LMs can learn to infer implicit graph semantics from minimal representations if given sufficient data.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>If LMs trained on semantically complete representations do not outperform those trained on lossy representations, the theory would be challenged.</li>
                <li>If increasing explicitness always improves performance with no diminishing returns, the tradeoff law would be called into question.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>The theory does not address the impact of pretraining or transfer learning on the ability of LMs to learn from different graph-to-text representations. </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> somewhat-related-to-existing</p>
            <p><strong>Explanation:</strong> The theory synthesizes known principles into a new, formal framework for this specific application.</p>
            <p><strong>References:</strong> <ul>
    <li>Vashishth et al. (2020) Composition-based Multi-Relational Graph Convolutional Networks [Semantic composition in GNNs]</li>
    <li>Koncel-Kedziorski et al. (2019) Text Generation from Knowledge Graphs with Graph Transformers [Graph semantics in text generation]</li>
    <li>Doshi-Velez & Kim (2017) Towards A Rigorous Science of Interpretable Machine Learning [Interpretability vs. complexity]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Semantic Fidelity Theory of Graph-to-Text Representation",
    "theory_description": "This theory posits that the ideal representation for converting graphs into text for language model training is one that maximizes semantic fidelity: the preservation and explicit encoding of all graph semantics (nodes, edges, attributes, and higher-order structures) in a form that is both interpretable and learnable by language models. The theory asserts that representations which maintain the full spectrum of graph meaning, including implicit and explicit relationships, will enable language models to generalize, reason, and generate text that accurately reflects the underlying graph structure.",
    "theory_statements": [
        {
            "law": {
                "law_name": "Semantic Preservation Law",
                "if": [
                    {
                        "subject": "graph_to_text_representation",
                        "relation": "encodes",
                        "object": "all_graph_semantics"
                    }
                ],
                "then": [
                    {
                        "subject": "language_model_trained_on_representation",
                        "relation": "achieves",
                        "object": "maximal_graph_understanding"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Lossy representations (e.g., simple edge lists) lead to information loss and reduced downstream performance.",
                        "uuids": []
                    },
                    {
                        "text": "Graph neural networks and structured encodings that preserve node/edge/attribute information outperform bag-of-edges or adjacency-only approaches.",
                        "uuids": []
                    },
                    {
                        "text": "Textual representations that explicitly encode graph structure (e.g., via serialization or templates) enable LMs to reconstruct the original graph more accurately.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Semantic preservation is a guiding principle in data serialization and some graph neural network approaches.",
                    "what_is_novel": "The explicit application of semantic fidelity as the central criterion for graph-to-text LM training is novel.",
                    "classification_explanation": "While semantic preservation is valued in other domains, its formalization as the core law for graph-to-text LM representation is new.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Vashishth et al. (2020) Composition-based Multi-Relational Graph Convolutional Networks [Semantic composition in GNNs]",
                        "Koncel-Kedziorski et al. (2019) Text Generation from Knowledge Graphs with Graph Transformers [Graph semantics in text generation]",
                        "Ribeiro et al. (2020) Structural Encoding in Language Models [Explicit structure encoding for LMs]"
                    ]
                }
            }
        },
        {
            "law": {
                "law_name": "Learnability-Interpretability Tradeoff Law",
                "if": [
                    {
                        "subject": "graph_to_text_representation",
                        "relation": "increases",
                        "object": "semantic_explicitness"
                    },
                    {
                        "subject": "graph_to_text_representation",
                        "relation": "increases",
                        "object": "representation_complexity"
                    }
                ],
                "then": [
                    {
                        "subject": "language_model",
                        "relation": "may_experience",
                        "object": "diminishing_returns_in_performance"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Highly explicit representations (e.g., verbose templates) can overwhelm LMs and reduce generalization.",
                        "uuids": []
                    },
                    {
                        "text": "There is a tradeoff between interpretability (for humans and models) and the learnability of the representation.",
                        "uuids": []
                    },
                    {
                        "text": "Empirical studies show that overly complex encodings can lead to overfitting or information overload.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Tradeoffs between interpretability and learnability are discussed in ML and NLP literature.",
                    "what_is_novel": "The explicit framing of this tradeoff for graph-to-text LM representations is novel.",
                    "classification_explanation": "The law is conceptually related to known tradeoffs but is newly formalized for this domain.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Doshi-Velez & Kim (2017) Towards A Rigorous Science of Interpretable Machine Learning [Interpretability vs. complexity]",
                        "Koncel-Kedziorski et al. (2019) Text Generation from Knowledge Graphs with Graph Transformers [Graph-to-text complexity]",
                        "Ribeiro et al. (2020) Structural Encoding in Language Models [Encoding complexity and LM performance]"
                    ]
                }
            }
        }
    ],
    "new_predictions_likely": [
        "Representations that encode all node, edge, and attribute semantics will enable LMs to reconstruct graphs with higher accuracy than those using partial or lossy encodings.",
        "There will be a point of diminishing returns where increasing representation explicitness no longer improves, or may even harm, LM performance."
    ],
    "new_predictions_unknown": [
        "The optimal balance between semantic explicitness and representation complexity for maximal LM performance is unknown and may vary by graph domain.",
        "It is unknown whether LMs can learn to infer implicit graph semantics from minimal representations if given sufficient data."
    ],
    "negative_experiments": [
        "If LMs trained on semantically complete representations do not outperform those trained on lossy representations, the theory would be challenged.",
        "If increasing explicitness always improves performance with no diminishing returns, the tradeoff law would be called into question."
    ],
    "unaccounted_for": [
        {
            "text": "The theory does not address the impact of pretraining or transfer learning on the ability of LMs to learn from different graph-to-text representations.",
            "uuids": []
        }
    ],
    "conflicting_evidence": [
        {
            "text": "Some studies show that minimal representations suffice for certain simple graph tasks, challenging the necessity of full semantic fidelity.",
            "uuids": []
        }
    ],
    "special_cases": [
        "For extremely large or dense graphs, full semantic encoding may be computationally infeasible.",
        "For graphs with highly regular structure, minimal representations may suffice."
    ],
    "existing_theory": {
        "what_already_exists": "Semantic preservation and tradeoffs are discussed in data serialization and ML interpretability.",
        "what_is_novel": "Their formalization as core laws for graph-to-text LM representation is new.",
        "classification_explanation": "The theory synthesizes known principles into a new, formal framework for this specific application.",
        "likely_classification": "somewhat-related-to-existing",
        "references": [
            "Vashishth et al. (2020) Composition-based Multi-Relational Graph Convolutional Networks [Semantic composition in GNNs]",
            "Koncel-Kedziorski et al. (2019) Text Generation from Knowledge Graphs with Graph Transformers [Graph semantics in text generation]",
            "Doshi-Velez & Kim (2017) Towards A Rigorous Science of Interpretable Machine Learning [Interpretability vs. complexity]"
        ]
    },
    "reflected_from_theory_index": 3,
    "type": "general",
    "version": "built-theory-from-results-single-theory-reflection2-nov14-2025-LLM-BASELINE-no-evidence-without-matched-control-theory-name",
    "theory_query": "Build a theory of ideal representations for converting graphs into text for language model training.",
    "original_theory_id": "theory-611",
    "original_theory_name": "Multimodal Alignment and Compactness Principle for Graph-to-Text Representations",
    "provide_matched_control_thery_name": false,
    "matched_control_theory_name": null,
    "model_str": "openai/gpt-4.1-2025-04-14"
}</code></pre>
        </div>
    </div>
</body>
</html>