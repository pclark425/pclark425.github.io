<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Uncertainty Propagation Hierarchy Theory - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-113</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-113</p>
                <p><strong>Name:</strong> Uncertainty Propagation Hierarchy Theory</p>
                <p><strong>Type:</strong> general</p>
                <p><strong>Theory Query:</strong> Build a theory about probabilistic symbolic world models for text environments that integrate LLM uncertainty into planning, based on the following results.</p>
                <p><strong>Description:</strong> Effective integration of LLM uncertainty into planning for partially observable, stochastic, or ambiguous environments requires explicit probabilistic modeling at multiple hierarchical levels: (1) LLM output uncertainty (multiple samples, confidence scores, parser distributions), (2) state/belief uncertainty (distributions over possible world states), and (3) planning/search uncertainty (stochastic search, bounded rationality, resource limits). Systems that model uncertainty only at the action-selection level (e.g., Boltzmann policies over fixed Q-values) fail to capture planning-level bounded rationality and perform significantly worse at explaining suboptimal or failed behavior than systems that model search-level uncertainty. The most effective approaches use Monte Carlo methods (SMC, MCMC, particle filters) to maintain explicit belief distributions over symbolic states and integrate LLM sampling uncertainty into these distributions. However, for fully observable deterministic domains with reliable LLM outputs, deterministic symbolic approaches can achieve comparable or superior performance with lower computational cost.</p>
                <p><strong>Knowledge Cutoff Year:</strong> 2024</p>
                <p><strong>Knowledge Cutoff Month:</strong> 12</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <ol>
                <li>In partially observable or ambiguous domains, uncertainty should be modeled at multiple hierarchical levels: LLM outputs (sampling distributions), world states (belief distributions), and planning/search processes (stochastic search, resource bounds)</li>
                <li>Monte Carlo methods (SMC, MCMC, particle filters) are effective for maintaining belief distributions over symbolic states when exact enumeration is intractable</li>
                <li>Modeling only action-selection uncertainty (Boltzmann policies over fixed values) is insufficient for explaining bounded rationality in planning; search-level uncertainty (stochastic expansion, limited budgets) better captures suboptimal and failed plans</li>
                <li>LLM output uncertainty can be quantified through multiple sampling and used to weight hypotheses in belief distributions (e.g., normalized counts, importance weights, confidence scores)</li>
                <li>Continuous/soft belief representations (real-valued strengths) are more robust to accumulated prediction errors than discrete symbolic representations in long-horizon tasks with imperfect state estimation</li>
                <li>Planning-level uncertainty (search noise parameter gamma, sampled node budget eta) better explains suboptimal behavior than action-level noise alone, as demonstrated by SIPS outperforming BIRL</li>
                <li>For fully observable deterministic domains with reliable LLM outputs, deterministic symbolic approaches (PDDL with classical planners) can achieve high performance (95%+ success) without probabilistic belief tracking</li>
                <li>The computational cost of probabilistic uncertainty propagation (SMC/MCMC) can be managed through: exact enumeration for small hypothesis spaces, particle approximations for medium spaces, and efficient caching/memoization for LLM-based inference</li>
                <li>Formal probabilistic frameworks (Feynman-Kac models, probabilistic programs) enable compositional specification of uncertainty sources and principled posterior inference</li>
            </ol>
            <h3>Supporting Evidence</h3>
<ol>
    <li>SIPS models planning-level uncertainty (stochastic A*, search budget via negative binomial) and outperforms BIRL which models only action-selection noise: SIPS achieves Q3 posterior 0.61 vs BIRL-oracle 0.42 and BIRL-unbiased 0.33 on Doors,Keys&Gems, with much faster runtime (AC=0.86s vs 154s for unbiased BIRL) <a href="../results/extraction-result-1006.html#e1006.0" class="evidence-link">[e1006.0]</a> <a href="../results/extraction-result-1006.html#e1006.7" class="evidence-link">[e1006.7]</a> <a href="../results/extraction-result-1006.html#e1006.4" class="evidence-link">[e1006.4]</a> </li>
    <li>RAP uses Monte Carlo sampling from LLM to build probabilistic state-transition confidence and integrates it into MCTS rewards, achieving 51.6% accuracy on GSM8K vs 29.4% for single-sample CoT and 46.8% for CoT+self-consistency; ablations show state-transition confidence reward improves math task performance <a href="../results/extraction-result-970.html#e970.0" class="evidence-link">[e970.0]</a> </li>
    <li>LLM-MCTS samples LLM multiple times (M samples) to build empirical probability distributions over object locations (normalized counts with floor probability 1e-3) and action suggestions, achieving 91.4% success on simple tasks vs 0% for uniform prior UCT; ablation shows uniform state prior yields near-zero success (3.2% or 0%) <a href="../results/extraction-result-972.html#e972.0" class="evidence-link">[e972.0]</a> </li>
    <li>Grammar-constrained SMC decoding produces weighted samples (n_sigma particles) representing parser uncertainty and achieves ~91% semantic equivalence vs lower for unconstrained sampling; SMC avoids greedy dead-ends and length bias of beam search <a href="../results/extraction-result-852.html#e852.3" class="evidence-link">[e852.3]</a> <a href="../results/extraction-result-977.html#e977.0" class="evidence-link">[e977.0]</a> <a href="../results/extraction-result-977.html#e977.1" class="evidence-link">[e977.1]</a> </li>
    <li>SMC steering framework (Feynman-Kac Transformer models) provides formal probabilistic framework where M_t kernels and G_t potentials define filtering posteriors; enables unbiased marginal likelihood estimation and posterior sampling with importance weights <a href="../results/extraction-result-977.html#e977.0" class="evidence-link">[e977.0]</a> <a href="../results/extraction-result-977.html#e977.2" class="evidence-link">[e977.2]</a> </li>
    <li>GATA uses continuous-valued belief graphs (real-valued adjacency tensor in [-1,1]) representing soft/graded beliefs and outperforms discrete symbolic updaters (GATA-GTP) which are more brittle to accumulated errors; continuous GATA achieves +24.2% relative improvement over text-only baseline <a href="../results/extraction-result-980.html#e980.0" class="evidence-link">[e980.0]</a> <a href="../results/extraction-result-980.html#e980.1" class="evidence-link">[e980.1]</a> </li>
    <li>PWM/PWL uses MCMC (Metropolis-Hastings) over probabilistic theories (Dirichlet process prior over axioms) and achieves R=0.927 correlation with human judgments vs R=0.658 for GPT-4 direct and R=0.100 for GPT-3.5 <a href="../results/extraction-result-843.html#e843.0" class="evidence-link">[e843.0]</a> </li>
    <li>Church probabilistic programs with MCMC inference (rejection sampling, collapsed rejection, MCMC over computation traces) enable planning-as-inference with explicit uncertainty modeling via reward-to-probability transformation <a href="../results/extraction-result-965.html#e965.0" class="evidence-link">[e965.0]</a> <a href="../results/extraction-result-965.html#e965.2" class="evidence-link">[e965.2]</a> <a href="../results/extraction-result-965.html#e965.3" class="evidence-link">[e965.3]</a> </li>
    <li>DPmem (Dirichlet-process stochastic memoizer) provides nonparametric uncertainty over persistent assignments and latent clustering, enabling unbounded latent categories in probabilistic symbolic world models <a href="../results/extraction-result-965.html#e965.1" class="evidence-link">[e965.1]</a> </li>
    <li>NIPE uses probabilistic generative models over maps (sampling valid grid-world maps) and Bayesian inverse planning (Boltzmann policy over A*-derived Q-values) to achieve R=0.927 vs R=0.658 for GPT-4 and R=0.100 for GPT-3.5 <a href="../results/extraction-result-845.html#e845.0" class="evidence-link">[e845.0]</a> </li>
    <li>LaBToM with belief-space inference (BSIPS exact enumeration, Q_MDP approximation, discrete belief distributions as k-particle sets) achieves r=0.76 correlation with humans; Non-Planning ablation (Manhattan heuristic instead of Q_MDP) drops to r=0.40 overall and r=0.07 on initial beliefs; True-Belief ablation (no epistemic uncertainty) drops to r=0.10 <a href="../results/extraction-result-852.html#e852.0" class="evidence-link">[e852.0]</a> <a href="../results/extraction-result-852.html#e852.1" class="evidence-link">[e852.1]</a> <a href="../results/extraction-result-852.html#e852.4" class="evidence-link">[e852.4]</a> </li>
    <li>BSIPS performs exact Bayesian inference by enumerating hypotheses (G × S0 × B0) with discrete belief distributions (k particles over ns states), achieving tractable exact posterior computation for experimental scenarios (120-5490 hypotheses, ~0.1-20s per action) <a href="../results/extraction-result-852.html#e852.1" class="evidence-link">[e852.1]</a> </li>
    <li>Gen probabilistic programming system enables exact enumeration and SMC/MCMC inference over symbolic hypotheses, providing extensible substrate for integrating symbolic world models with belief-state uncertainty <a href="../results/extraction-result-852.html#e852.5" class="evidence-link">[e852.5]</a> <a href="../results/extraction-result-1006.html#e1006.3" class="evidence-link">[e1006.3]</a> </li>
</ol>            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>A system that samples an LLM 10 times and maintains a particle filter (N=100 particles) over states will outperform single-sample approaches by >20% absolute accuracy on tasks with ambiguous observations and partial observability (e.g., text-based games with hidden state)</li>
                <li>Modeling search budget uncertainty (negative binomial distribution over node expansions) will better predict human planning errors (correlation r>0.6) than modeling only action noise (r<0.4) in goal inference tasks</li>
                <li>SMC-based belief tracking with resampling (ESS threshold) will be more robust to accumulated errors (maintaining >50% accuracy after 20 steps) than deterministic symbolic state tracking (<30% accuracy) in long-horizon tasks with noisy observations</li>
                <li>Grammar-constrained SMC decoding will achieve >85% semantic equivalence on epistemic language parsing vs <60% for unconstrained sampling, with the gap widening for compositionally complex expressions</li>
                <li>Continuous belief graphs (real-valued [-1,1] strengths) will outperform discrete belief graphs by >15% relative improvement in partially observable text games with >100 entities</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>Whether the computational cost of Monte Carlo uncertainty propagation (SMC with N=1000 particles) can be reduced to <100ms per decision for real-time interactive applications through GPU acceleration and approximate inference</li>
                <li>The optimal number of LLM samples/particles needed for different types of uncertainty may vary dramatically by domain: it's unknown whether a universal scaling law exists or if domain-specific tuning is always necessary</li>
                <li>Whether learned uncertainty estimates from LLMs (e.g., token-level confidence scores, self-evaluation) are well-calibrated enough to use directly as importance weights or require recalibration via held-out data</li>
                <li>Whether hierarchical uncertainty propagation (LLM→state→planning) provides benefits over flat uncertainty modeling (direct LLM→action) in domains with complex causal structure but deterministic transitions</li>
                <li>The extent to which nonparametric uncertainty methods (DPmem, Dirichlet processes) scale to large-scale text environments with thousands of entities and relations</li>
                <li>Whether hybrid approaches that switch between probabilistic and deterministic reasoning based on estimated uncertainty levels can achieve the best of both worlds (accuracy and efficiency)</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>Finding that single-sample LLM outputs with no uncertainty modeling perform as well as (within 5% of) multi-sample probabilistic approaches on partially observable tasks would challenge the core premise of the theory</li>
                <li>Demonstrating that action-level noise models (Boltzmann over fixed Q-values) explain human suboptimal behavior as well as (r>0.55) planning-level uncertainty models (stochastic search) would weaken the hierarchical necessity claim</li>
                <li>Showing that deterministic symbolic state tracking is as robust as (within 10% accuracy of) probabilistic belief tracking in long-horizon noisy environments would challenge the soft-belief advantage claim</li>
                <li>Finding that computational cost of probabilistic methods scales prohibitively (>10x slower) even with optimizations, making them impractical for real applications, would limit practical applicability</li>
                <li>Demonstrating that LLM uncertainty estimates are so poorly calibrated (calibration error >0.3) that they provide no benefit over uniform weighting would challenge the LLM-sampling integration approach</li>
                <li>Showing that the benefits of uncertainty modeling disappear (no significant difference) when LLM accuracy exceeds 95% would suggest a threshold effect not captured by the theory</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>The theory doesn't specify how to optimally combine different sources of uncertainty (LLM sampling variance, observation noise, model uncertainty, search stochasticity) - whether they should be multiplied, added, or combined through more complex functions <a href="../results/extraction-result-1006.html#e1006.0" class="evidence-link">[e1006.0]</a> <a href="../results/extraction-result-970.html#e970.0" class="evidence-link">[e970.0]</a> <a href="../results/extraction-result-972.html#e972.0" class="evidence-link">[e972.0]</a> <a href="../results/extraction-result-845.html#e845.0" class="evidence-link">[e845.0]</a> </li>
    <li>The computational trade-offs between different Monte Carlo methods (SMC vs MCMC vs particle filters vs exact enumeration) are not fully characterized - when to use which method based on hypothesis space size, available compute, and required accuracy <a href="../results/extraction-result-965.html#e965.0" class="evidence-link">[e965.0]</a> <a href="../results/extraction-result-1006.html#e1006.0" class="evidence-link">[e1006.0]</a> <a href="../results/extraction-result-843.html#e843.0" class="evidence-link">[e843.0]</a> <a href="../results/extraction-result-852.html#e852.1" class="evidence-link">[e852.1]</a> <a href="../results/extraction-result-977.html#e977.0" class="evidence-link">[e977.0]</a> </li>
    <li>The theory doesn't explain why some deterministic approaches (Worldformer graph prediction, Q*BERT KG construction) achieve good performance without explicit probabilistic belief tracking - what domain properties enable this <a href="../results/extraction-result-851.html#e851.0" class="evidence-link">[e851.0]</a> <a href="../results/extraction-result-967.html#e967.0" class="evidence-link">[e967.0]</a> </li>
    <li>The relationship between LLM model size/capability and the necessity of uncertainty modeling is unclear - do more capable LLMs reduce the need for explicit uncertainty propagation <a href="../results/extraction-result-970.html#e970.0" class="evidence-link">[e970.0]</a> <a href="../results/extraction-result-972.html#e972.0" class="evidence-link">[e972.0]</a> <a href="../results/extraction-result-843.html#e843.0" class="evidence-link">[e843.0]</a> </li>
    <li>The theory doesn't address how to handle uncertainty in the world model structure itself (e.g., which predicates/relations to include) vs uncertainty in world model parameters/states <a href="../results/extraction-result-843.html#e843.0" class="evidence-link">[e843.0]</a> <a href="../results/extraction-result-965.html#e965.1" class="evidence-link">[e965.1]</a> </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> closely-related-to-existing</p>
            <p><strong>Explanation:</strong> No explanation provided.</p>
            <p><strong>References:</strong> <ul>
    <li>Zhi-Xuan et al. (2020) Online Bayesian Goal Inference for Boundedly-Rational Planning Agents [Models planning-level uncertainty with stochastic search and bounded rationality, but doesn't integrate LLMs or address LLM output uncertainty]</li>
    <li>Hao et al. (2023) Reasoning with Language Model is Planning with World Model [Uses LLM uncertainty in MCTS with confidence-based rewards, but doesn't formulate general hierarchical framework or compare levels]</li>
    <li>Goodman et al. (2008) Church: a language for generative models [Probabilistic programming framework with MCMC inference for planning-as-inference, but not LLM-specific and predates modern LLMs]</li>
    <li>Adhikari et al. (2020) Learning Dynamic Belief Graphs to Generalize on Text-Based Games [Continuous belief graphs for partial observability, but doesn't explicitly integrate LLM uncertainty or compare uncertainty modeling levels]</li>
    <li>Lew et al. (2023) Sequential Monte Carlo Steering of Large Language Models using Probabilistic Programs [SMC framework for LLM uncertainty with Feynman-Kac models, but focuses on constrained generation rather than planning hierarchy]</li>
    <li>Kaelbling & Lozano-Pérez (2013) Integrated task and motion planning in belief space [Belief-space planning for robotics with probabilistic state uncertainty, but doesn't address LLM integration or text environments]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Uncertainty Propagation Hierarchy Theory",
    "theory_description": "Effective integration of LLM uncertainty into planning for partially observable, stochastic, or ambiguous environments requires explicit probabilistic modeling at multiple hierarchical levels: (1) LLM output uncertainty (multiple samples, confidence scores, parser distributions), (2) state/belief uncertainty (distributions over possible world states), and (3) planning/search uncertainty (stochastic search, bounded rationality, resource limits). Systems that model uncertainty only at the action-selection level (e.g., Boltzmann policies over fixed Q-values) fail to capture planning-level bounded rationality and perform significantly worse at explaining suboptimal or failed behavior than systems that model search-level uncertainty. The most effective approaches use Monte Carlo methods (SMC, MCMC, particle filters) to maintain explicit belief distributions over symbolic states and integrate LLM sampling uncertainty into these distributions. However, for fully observable deterministic domains with reliable LLM outputs, deterministic symbolic approaches can achieve comparable or superior performance with lower computational cost.",
    "supporting_evidence": [
        {
            "text": "SIPS models planning-level uncertainty (stochastic A*, search budget via negative binomial) and outperforms BIRL which models only action-selection noise: SIPS achieves Q3 posterior 0.61 vs BIRL-oracle 0.42 and BIRL-unbiased 0.33 on Doors,Keys&Gems, with much faster runtime (AC=0.86s vs 154s for unbiased BIRL)",
            "uuids": [
                "e1006.0",
                "e1006.7",
                "e1006.4"
            ]
        },
        {
            "text": "RAP uses Monte Carlo sampling from LLM to build probabilistic state-transition confidence and integrates it into MCTS rewards, achieving 51.6% accuracy on GSM8K vs 29.4% for single-sample CoT and 46.8% for CoT+self-consistency; ablations show state-transition confidence reward improves math task performance",
            "uuids": [
                "e970.0"
            ]
        },
        {
            "text": "LLM-MCTS samples LLM multiple times (M samples) to build empirical probability distributions over object locations (normalized counts with floor probability 1e-3) and action suggestions, achieving 91.4% success on simple tasks vs 0% for uniform prior UCT; ablation shows uniform state prior yields near-zero success (3.2% or 0%)",
            "uuids": [
                "e972.0"
            ]
        },
        {
            "text": "Grammar-constrained SMC decoding produces weighted samples (n_sigma particles) representing parser uncertainty and achieves ~91% semantic equivalence vs lower for unconstrained sampling; SMC avoids greedy dead-ends and length bias of beam search",
            "uuids": [
                "e852.3",
                "e977.0",
                "e977.1"
            ]
        },
        {
            "text": "SMC steering framework (Feynman-Kac Transformer models) provides formal probabilistic framework where M_t kernels and G_t potentials define filtering posteriors; enables unbiased marginal likelihood estimation and posterior sampling with importance weights",
            "uuids": [
                "e977.0",
                "e977.2"
            ]
        },
        {
            "text": "GATA uses continuous-valued belief graphs (real-valued adjacency tensor in [-1,1]) representing soft/graded beliefs and outperforms discrete symbolic updaters (GATA-GTP) which are more brittle to accumulated errors; continuous GATA achieves +24.2% relative improvement over text-only baseline",
            "uuids": [
                "e980.0",
                "e980.1"
            ]
        },
        {
            "text": "PWM/PWL uses MCMC (Metropolis-Hastings) over probabilistic theories (Dirichlet process prior over axioms) and achieves R=0.927 correlation with human judgments vs R=0.658 for GPT-4 direct and R=0.100 for GPT-3.5",
            "uuids": [
                "e843.0"
            ]
        },
        {
            "text": "Church probabilistic programs with MCMC inference (rejection sampling, collapsed rejection, MCMC over computation traces) enable planning-as-inference with explicit uncertainty modeling via reward-to-probability transformation",
            "uuids": [
                "e965.0",
                "e965.2",
                "e965.3"
            ]
        },
        {
            "text": "DPmem (Dirichlet-process stochastic memoizer) provides nonparametric uncertainty over persistent assignments and latent clustering, enabling unbounded latent categories in probabilistic symbolic world models",
            "uuids": [
                "e965.1"
            ]
        },
        {
            "text": "NIPE uses probabilistic generative models over maps (sampling valid grid-world maps) and Bayesian inverse planning (Boltzmann policy over A*-derived Q-values) to achieve R=0.927 vs R=0.658 for GPT-4 and R=0.100 for GPT-3.5",
            "uuids": [
                "e845.0"
            ]
        },
        {
            "text": "LaBToM with belief-space inference (BSIPS exact enumeration, Q_MDP approximation, discrete belief distributions as k-particle sets) achieves r=0.76 correlation with humans; Non-Planning ablation (Manhattan heuristic instead of Q_MDP) drops to r=0.40 overall and r=0.07 on initial beliefs; True-Belief ablation (no epistemic uncertainty) drops to r=0.10",
            "uuids": [
                "e852.0",
                "e852.1",
                "e852.4"
            ]
        },
        {
            "text": "BSIPS performs exact Bayesian inference by enumerating hypotheses (G × S0 × B0) with discrete belief distributions (k particles over ns states), achieving tractable exact posterior computation for experimental scenarios (120-5490 hypotheses, ~0.1-20s per action)",
            "uuids": [
                "e852.1"
            ]
        },
        {
            "text": "Gen probabilistic programming system enables exact enumeration and SMC/MCMC inference over symbolic hypotheses, providing extensible substrate for integrating symbolic world models with belief-state uncertainty",
            "uuids": [
                "e852.5",
                "e1006.3"
            ]
        }
    ],
    "theory_statements": [
        "In partially observable or ambiguous domains, uncertainty should be modeled at multiple hierarchical levels: LLM outputs (sampling distributions), world states (belief distributions), and planning/search processes (stochastic search, resource bounds)",
        "Monte Carlo methods (SMC, MCMC, particle filters) are effective for maintaining belief distributions over symbolic states when exact enumeration is intractable",
        "Modeling only action-selection uncertainty (Boltzmann policies over fixed values) is insufficient for explaining bounded rationality in planning; search-level uncertainty (stochastic expansion, limited budgets) better captures suboptimal and failed plans",
        "LLM output uncertainty can be quantified through multiple sampling and used to weight hypotheses in belief distributions (e.g., normalized counts, importance weights, confidence scores)",
        "Continuous/soft belief representations (real-valued strengths) are more robust to accumulated prediction errors than discrete symbolic representations in long-horizon tasks with imperfect state estimation",
        "Planning-level uncertainty (search noise parameter gamma, sampled node budget eta) better explains suboptimal behavior than action-level noise alone, as demonstrated by SIPS outperforming BIRL",
        "For fully observable deterministic domains with reliable LLM outputs, deterministic symbolic approaches (PDDL with classical planners) can achieve high performance (95%+ success) without probabilistic belief tracking",
        "The computational cost of probabilistic uncertainty propagation (SMC/MCMC) can be managed through: exact enumeration for small hypothesis spaces, particle approximations for medium spaces, and efficient caching/memoization for LLM-based inference",
        "Formal probabilistic frameworks (Feynman-Kac models, probabilistic programs) enable compositional specification of uncertainty sources and principled posterior inference"
    ],
    "new_predictions_likely": [
        "A system that samples an LLM 10 times and maintains a particle filter (N=100 particles) over states will outperform single-sample approaches by &gt;20% absolute accuracy on tasks with ambiguous observations and partial observability (e.g., text-based games with hidden state)",
        "Modeling search budget uncertainty (negative binomial distribution over node expansions) will better predict human planning errors (correlation r&gt;0.6) than modeling only action noise (r&lt;0.4) in goal inference tasks",
        "SMC-based belief tracking with resampling (ESS threshold) will be more robust to accumulated errors (maintaining &gt;50% accuracy after 20 steps) than deterministic symbolic state tracking (&lt;30% accuracy) in long-horizon tasks with noisy observations",
        "Grammar-constrained SMC decoding will achieve &gt;85% semantic equivalence on epistemic language parsing vs &lt;60% for unconstrained sampling, with the gap widening for compositionally complex expressions",
        "Continuous belief graphs (real-valued [-1,1] strengths) will outperform discrete belief graphs by &gt;15% relative improvement in partially observable text games with &gt;100 entities"
    ],
    "new_predictions_unknown": [
        "Whether the computational cost of Monte Carlo uncertainty propagation (SMC with N=1000 particles) can be reduced to &lt;100ms per decision for real-time interactive applications through GPU acceleration and approximate inference",
        "The optimal number of LLM samples/particles needed for different types of uncertainty may vary dramatically by domain: it's unknown whether a universal scaling law exists or if domain-specific tuning is always necessary",
        "Whether learned uncertainty estimates from LLMs (e.g., token-level confidence scores, self-evaluation) are well-calibrated enough to use directly as importance weights or require recalibration via held-out data",
        "Whether hierarchical uncertainty propagation (LLM→state→planning) provides benefits over flat uncertainty modeling (direct LLM→action) in domains with complex causal structure but deterministic transitions",
        "The extent to which nonparametric uncertainty methods (DPmem, Dirichlet processes) scale to large-scale text environments with thousands of entities and relations",
        "Whether hybrid approaches that switch between probabilistic and deterministic reasoning based on estimated uncertainty levels can achieve the best of both worlds (accuracy and efficiency)"
    ],
    "negative_experiments": [
        "Finding that single-sample LLM outputs with no uncertainty modeling perform as well as (within 5% of) multi-sample probabilistic approaches on partially observable tasks would challenge the core premise of the theory",
        "Demonstrating that action-level noise models (Boltzmann over fixed Q-values) explain human suboptimal behavior as well as (r&gt;0.55) planning-level uncertainty models (stochastic search) would weaken the hierarchical necessity claim",
        "Showing that deterministic symbolic state tracking is as robust as (within 10% accuracy of) probabilistic belief tracking in long-horizon noisy environments would challenge the soft-belief advantage claim",
        "Finding that computational cost of probabilistic methods scales prohibitively (&gt;10x slower) even with optimizations, making them impractical for real applications, would limit practical applicability",
        "Demonstrating that LLM uncertainty estimates are so poorly calibrated (calibration error &gt;0.3) that they provide no benefit over uniform weighting would challenge the LLM-sampling integration approach",
        "Showing that the benefits of uncertainty modeling disappear (no significant difference) when LLM accuracy exceeds 95% would suggest a threshold effect not captured by the theory"
    ],
    "unaccounted_for": [
        {
            "text": "The theory doesn't specify how to optimally combine different sources of uncertainty (LLM sampling variance, observation noise, model uncertainty, search stochasticity) - whether they should be multiplied, added, or combined through more complex functions",
            "uuids": [
                "e1006.0",
                "e970.0",
                "e972.0",
                "e845.0"
            ]
        },
        {
            "text": "The computational trade-offs between different Monte Carlo methods (SMC vs MCMC vs particle filters vs exact enumeration) are not fully characterized - when to use which method based on hypothesis space size, available compute, and required accuracy",
            "uuids": [
                "e965.0",
                "e1006.0",
                "e843.0",
                "e852.1",
                "e977.0"
            ]
        },
        {
            "text": "The theory doesn't explain why some deterministic approaches (Worldformer graph prediction, Q*BERT KG construction) achieve good performance without explicit probabilistic belief tracking - what domain properties enable this",
            "uuids": [
                "e851.0",
                "e967.0"
            ]
        },
        {
            "text": "The relationship between LLM model size/capability and the necessity of uncertainty modeling is unclear - do more capable LLMs reduce the need for explicit uncertainty propagation",
            "uuids": [
                "e970.0",
                "e972.0",
                "e843.0"
            ]
        },
        {
            "text": "The theory doesn't address how to handle uncertainty in the world model structure itself (e.g., which predicates/relations to include) vs uncertainty in world model parameters/states",
            "uuids": [
                "e843.0",
                "e965.1"
            ]
        }
    ],
    "conflicting_evidence": [
        {
            "text": "GPT-3+ASP achieves 99.99% accuracy on bAbI and 100% on multiple CLUTRR-S categories using deterministic ASP reasoning without probabilistic belief tracking, suggesting deterministic symbolic reasoning suffices for some domains",
            "uuids": [
                "e1004.0"
            ]
        },
        {
            "text": "BeSimulator achieves 13.60-24.80% absolute accuracy improvements with deterministic state updates and iterative correction (reflective feedback) rather than probabilistic beliefs, showing iterative refinement can substitute for uncertainty modeling",
            "uuids": [
                "e842.0",
                "e842.1"
            ]
        },
        {
            "text": "LLM+P achieves 90-95% success on multiple planning domains using deterministic PDDL with classical planners (Fast Downward), with failures primarily due to LLM mis-specification rather than lack of probabilistic reasoning",
            "uuids": [
                "e974.0",
                "e1001.0",
                "e971.0"
            ]
        },
        {
            "text": "Classical planner with LLM-acquired PDDL achieves ~95% success on sampled tasks using deterministic domain models and Fast Downward search, suggesting explicit probabilistic transitions are not necessary when domain models are accurate",
            "uuids": [
                "e971.1"
            ]
        },
        {
            "text": "AutoTAMP achieves high success rates (e.g., HouseWorld2 ~83.5%, Rover ~79.7%) using deterministic STL planning with syntax/semantic correction, without probabilistic belief-state planning",
            "uuids": [
                "e975.0"
            ]
        },
        {
            "text": "Worldformer achieves 39.15% graph-level EM and 52.45% token-level F1 on knowledge graph prediction using deterministic graph-difference prediction without explicit probabilistic beliefs",
            "uuids": [
                "e851.0"
            ]
        }
    ],
    "special_cases": [
        "For fully observable, deterministic domains with reliable LLM outputs (&gt;95% accuracy), probabilistic uncertainty modeling provides minimal benefits and deterministic symbolic approaches are more efficient",
        "When LLM outputs are highly confident and accurate (confidence &gt;0.9, accuracy &gt;90%), single-sample approaches may suffice and multi-sample overhead is not justified",
        "For real-time applications with strict latency constraints (&lt;100ms per decision), approximate uncertainty methods (particle filters with N&lt;50) or deterministic approaches may be necessary despite lower accuracy",
        "In domains where iterative correction/refinement is possible (e.g., with validator feedback), deterministic approaches with repair loops can achieve comparable performance to probabilistic methods",
        "For small hypothesis spaces (H&lt;1000), exact enumeration is more efficient than Monte Carlo approximation and should be preferred",
        "When computational resources are severely limited, hierarchical uncertainty modeling may need to be simplified to single-level (e.g., only state uncertainty, not planning uncertainty)",
        "In domains with very sparse observations or high observation noise (&gt;50% error rate), even sophisticated probabilistic methods may fail and domain-specific heuristics become necessary"
    ],
    "existing_theory": {
        "likely_classification": "closely-related-to-existing",
        "references": [
            "Zhi-Xuan et al. (2020) Online Bayesian Goal Inference for Boundedly-Rational Planning Agents [Models planning-level uncertainty with stochastic search and bounded rationality, but doesn't integrate LLMs or address LLM output uncertainty]",
            "Hao et al. (2023) Reasoning with Language Model is Planning with World Model [Uses LLM uncertainty in MCTS with confidence-based rewards, but doesn't formulate general hierarchical framework or compare levels]",
            "Goodman et al. (2008) Church: a language for generative models [Probabilistic programming framework with MCMC inference for planning-as-inference, but not LLM-specific and predates modern LLMs]",
            "Adhikari et al. (2020) Learning Dynamic Belief Graphs to Generalize on Text-Based Games [Continuous belief graphs for partial observability, but doesn't explicitly integrate LLM uncertainty or compare uncertainty modeling levels]",
            "Lew et al. (2023) Sequential Monte Carlo Steering of Large Language Models using Probabilistic Programs [SMC framework for LLM uncertainty with Feynman-Kac models, but focuses on constrained generation rather than planning hierarchy]",
            "Kaelbling & Lozano-Pérez (2013) Integrated task and motion planning in belief space [Belief-space planning for robotics with probabilistic state uncertainty, but doesn't address LLM integration or text environments]"
        ]
    },
    "theory_type_general_specific": "general",
    "reflected_from_theory_index": 1,
    "type": "general"
}</code></pre>
        </div>
    </div>
</body>
</html>