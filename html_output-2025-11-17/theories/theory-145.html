<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Action Space Pruning via Knowledge Graph Theory - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-145</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-145</p>
                <p><strong>Name:</strong> Action Space Pruning via Knowledge Graph Theory</p>
                <p><strong>Type:</strong> specific</p>
                <p><strong>Theory Query:</strong> Build a theory about navigation complexity in text worlds that relates graph-topology features (diameter, clustering, dead-ends, door constraints) to exploration efficiency and optimal policy structure, based on the following results.</p>
                <p><strong>Description:</strong> In text-based games with large combinatorial action spaces, pruning actions based on a dynamically constructed knowledge graph dramatically improves exploration efficiency and learning speed. The knowledge graph encodes entities, relations, and state information extracted from observations, and actions are pruned by checking whether their object arguments exist in the graph and are relevant to the current state. This pruning reduces the effective branching factor from exponential (template × vocabulary combinations) to linear (entities present in current context), enabling tractable exploration and faster convergence. The effectiveness of pruning depends critically on: (1) the accuracy of knowledge graph construction from noisy text, (2) the availability of valid-action supervision or other guidance signals during training, and (3) the ratio of vocabulary size to typical number of relevant entities per state. The theory predicts that pruning benefits scale super-linearly with vocabulary size and number of object slots, but only when combined with appropriate training signals.</p>
                <p><strong>Knowledge Cutoff Year:</strong> 2024</p>
                <p><strong>Knowledge Cutoff Month:</strong> 12</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <ol>
                <li>Action space size grows as O(|templates| × |vocabulary|^k) where k is the number of object slots, making unpruned exploration intractable when |vocabulary| > 100 and k ≥ 2.</li>
                <li>Knowledge-graph-based pruning reduces effective action space to O(|templates| × |entities_in_graph|^k) where |entities_in_graph| << |vocabulary|, typically by a factor of 10-100x.</li>
                <li>The reduction in exploration time is proportional to the ratio of pruned to unpruned action space size, but only when combined with appropriate training signals (e.g., valid-action supervision, intrinsic KG-growth rewards).</li>
                <li>Pruning based on entity presence in the knowledge graph can maintain high action coverage (>90% of truly valid actions retained) when the knowledge graph is accurately constructed.</li>
                <li>The benefits of action pruning increase super-linearly with vocabulary size and number of object slots, with the greatest benefits observed when |vocabulary| > 500 and k ≥ 2.</li>
                <li>Knowledge graph construction accuracy is critical: errors in entity extraction or relation identification can lead to incorrect pruning that removes valid actions or retains invalid ones.</li>
                <li>Pruning effectiveness depends on the ratio of vocabulary size to typical number of relevant entities per state; games where most vocabulary items are relevant at most states see minimal benefit.</li>
                <li>Continuous belief graphs (as in GATA) can provide similar pruning benefits to discrete KGs while being more robust to individual extraction errors, but at the cost of interpretability.</li>
                <li>Combining KG-based pruning with other exploration strategies (e.g., intrinsic rewards for KG growth, archival methods using KG as state representation) provides synergistic benefits beyond pruning alone.</li>
            </ol>
            <h3>Supporting Evidence</h3>
<ol>
    <li>KG-DQN with graph-based action pruning converges ~40% faster than LSTM-DQN in TextWorld games with branching factors of 143-562. <a href="../results/extraction-result-1349.html#e1349.1" class="evidence-link">[e1349.1]</a> </li>
    <li>KG-A2C with graph mask achieves score of 34 on Zork1 vs 9.9 for TDQN without graph constraints, demonstrating pruning benefits in complex games. <a href="../results/extraction-result-1205.html#e1205.0" class="evidence-link">[e1205.0]</a> </li>
    <li>Removing the graph mask from KG-A2C slows learning but can reach similar asymptotic scores, showing pruning primarily aids exploration speed rather than final capability. <a href="../results/extraction-result-1205.html#e1205.0" class="evidence-link">[e1205.0]</a> </li>
    <li>Template-based action space (structured) is necessary for tractable exploration; word-level sequence generation performs much worse due to combinatorial explosion. <a href="../results/extraction-result-1205.html#e1205.0" class="evidence-link">[e1205.0]</a> </li>
    <li>Valid-action supervision (using oracle valid actions during training) is critical for KG-A2C; without it (KG-A2C-unsupervised), the agent fails to learn, indicating pruning alone is insufficient. <a href="../results/extraction-result-1205.html#e1205.0" class="evidence-link">[e1205.0]</a> </li>
    <li>GATA with knowledge-graph-based entity constraints achieves +24.2% relative improvement over text-only baselines in TextWorld cooking games. <a href="../results/extraction-result-1374.html#e1374.1" class="evidence-link">[e1374.1]</a> </li>
    <li>In Jericho games, choice-based agents (DRRN) that score over pruned valid actions outperform template-based agents (TDQN) that must score over full combinatorial space, with TDQN suffering from Q-value overestimation due to max over large action sets. <a href="../results/extraction-result-1372.html#e1372.0" class="evidence-link">[e1372.0]</a> </li>
    <li>NESTA uses action pruning based on lifted rules and abstract meaning representations, achieving best performance across TextWorld difficulty levels including hard two-room tasks. <a href="../results/extraction-result-1199.html#e1199.1" class="evidence-link">[e1199.1]</a> </li>
    <li>Q*BERT uses intrinsic rewards based on knowledge graph growth (new entities/relations discovered) to guide exploration, showing that KG-based signals improve bottleneck crossing. <a href="../results/extraction-result-1184.html#e1184.1" class="evidence-link">[e1184.1]</a> </li>
    <li>GO!Q*BERT combines KG-based exploration with Go-Explore style archival methods, using KG snapshots as cell representations to better identify promising states. <a href="../results/extraction-result-1220.html#e1220.2" class="evidence-link">[e1220.2]</a> </li>
    <li>KG-A2C uses Graph Attention Networks (GAT) to embed the knowledge graph, with graph-derived masks restricting object choices to entities present in the graph. <a href="../results/extraction-result-1205.html#e1205.0" class="evidence-link">[e1205.0]</a> <a href="../results/extraction-result-1205.html#e1205.1" class="evidence-link">[e1205.1]</a> </li>
    <li>GATA learns continuous-valued belief graphs that are denser and less interpretable than discrete KGs but still provide structural constraints; discrete graph updates (GATA-GTP) can underperform due to error accumulation. <a href="../results/extraction-result-1374.html#e1374.1" class="evidence-link">[e1374.1]</a> </li>
    <li>In TextWorld games with 10-20 rooms and branching factors 143-562, KG-DQN's action pruning via graph scoring and top-k selection enables convergence where baselines struggle. <a href="../results/extraction-result-1349.html#e1349.1" class="evidence-link">[e1349.1]</a> </li>
    <li>Jericho framework provides valid-action detection which enables choice-based methods; games with large template/vocabulary counts (e.g., Zork1: |T|=237, |V|=697) particularly benefit from pruning. <a href="../results/extraction-result-1372.html#e1372.0" class="evidence-link">[e1372.0]</a> </li>
</ol>            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>In a text game with vocabulary size 1000 and 2-object actions, knowledge-graph pruning will reduce exploration time by >10x compared to unpruned exploration, assuming accurate entity extraction.</li>
                <li>Increasing vocabulary size from 500 to 2000 while holding game complexity constant will increase the performance gap between pruned and unpruned agents by >50%.</li>
                <li>Knowledge-graph pruning combined with valid-action supervision will maintain >90% recall of truly valid actions while reducing action space by >95% in typical games.</li>
                <li>Games with higher entity-to-vocabulary ratios (more entities relevant per state) will show smaller benefits from pruning, with diminishing returns when ratio exceeds 0.3.</li>
                <li>Combining KG-based pruning with intrinsic rewards for discovering new entities/relations will improve performance by an additional 20-30% over pruning alone.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>There may be a vocabulary size threshold (possibly around 5000-10000 words) beyond which even knowledge-graph pruning becomes insufficient and additional abstraction (e.g., hierarchical action spaces, learned action embeddings) is needed.</li>
                <li>The optimal pruning strategy may vary significantly across different types of text games: puzzle-heavy games may benefit from stricter pruning (higher precision, lower recall) while exploration-heavy games may need looser pruning (higher recall, lower precision).</li>
                <li>Incorrect pruning (removing valid actions) may have non-linear negative effects that compound over long episodes, potentially creating unrecoverable states where the agent cannot progress.</li>
                <li>The computational cost of knowledge graph construction and maintenance may become a bottleneck in games with very high entity turnover or complex relation extraction requirements, potentially offsetting pruning benefits.</li>
                <li>Learned continuous belief graphs (like GATA's) may eventually outperform discrete KGs as model capacity and training data increase, but the crossover point is unknown.</li>
                <li>The interaction between KG-based pruning and other exploration bonuses (curiosity, count-based, etc.) may be non-additive, with potential for both synergy and interference.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>Finding text games where unpruned exploration consistently outperforms knowledge-graph pruning (when both have equal training time/data) would challenge the core efficiency claim.</li>
                <li>Demonstrating that pruning reduces action coverage below 70% in typical games would contradict the coverage maintenance claim.</li>
                <li>Showing that the benefits of pruning do not increase with vocabulary size (or increase only linearly) would invalidate the super-linear scaling claim.</li>
                <li>Finding that KG-based pruning without any additional training signals (no valid-action supervision, no intrinsic rewards) can match supervised methods would challenge the necessity of auxiliary signals.</li>
                <li>Demonstrating that simple heuristic pruning (e.g., based on word frequency or recency) performs as well as KG-based pruning would question the value of explicit graph construction.</li>
                <li>Finding games where the computational cost of KG construction exceeds the exploration savings from pruning would challenge the practical utility claim.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>The theory doesn't specify how to handle actions that require entities not yet discovered or mentioned in observations, which may be critical for progress in some games. </li>
    <li>The computational cost of knowledge graph construction and maintenance is not characterized, including the cost of entity extraction, relation identification, and graph updates. </li>
    <li>How to handle ambiguous or incorrect entity extraction from noisy text is not addressed, including strategies for error recovery and confidence-based pruning. </li>
    <li>The theory doesn't account for games with synonyms or multiple names for the same entity, which could lead to duplicate entities in the graph or missed pruning opportunities. </li>
    <li>The interaction between pruning and partial observability is not fully characterized - how does pruning perform when the agent has incomplete information about the game state? </li>
    <li>The theory doesn't address how to handle procedurally generated content where entity sets change dramatically between episodes or within episodes. </li>
    <li>The optimal balance between pruning aggressiveness (precision vs. recall) for different game types and stages of learning is not specified. </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> new</p>
            <p><strong>Explanation:</strong> No explanation provided.</p>
            <p><strong>References:</strong> <ul>
    <li>Ammanabrolu & Hausknecht (2020) Graph Constrained Reinforcement Learning for Natural Language Action Spaces [Demonstrates graph-based pruning in practice but doesn't formalize the scaling theory or characterize when/why it works]</li>
    <li>Hausknecht et al. (2019) Interactive Fiction Games: A Colossal Adventure [Discusses action space challenges and provides Jericho framework but doesn't provide formal pruning theory]</li>
    <li>Côté et al. (2018) TextWorld: A Learning Environment for Text-based Games [Provides environment and discusses action space complexity but doesn't formalize pruning benefits or scaling laws]</li>
    <li>Adhikari et al. (2020) Learning Dynamic Belief Graphs to Generalize on Text-Based Games [GATA paper, explores continuous belief graphs as alternative to discrete KGs but doesn't formalize pruning theory]</li>
    <li>Ammanabrolu et al. (2020) How to Avoid Being Eaten by a Grue [Discusses exploration strategies including KG-based methods but focuses on bottleneck detection rather than pruning theory]</li>
    <li>Xu et al. (2023) Learning Symbolic Rules over Abstract Meaning Representations for Textual Reinforcement Learning [NESTA paper, uses action pruning via lifted rules but doesn't formalize general pruning theory]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Action Space Pruning via Knowledge Graph Theory",
    "theory_description": "In text-based games with large combinatorial action spaces, pruning actions based on a dynamically constructed knowledge graph dramatically improves exploration efficiency and learning speed. The knowledge graph encodes entities, relations, and state information extracted from observations, and actions are pruned by checking whether their object arguments exist in the graph and are relevant to the current state. This pruning reduces the effective branching factor from exponential (template × vocabulary combinations) to linear (entities present in current context), enabling tractable exploration and faster convergence. The effectiveness of pruning depends critically on: (1) the accuracy of knowledge graph construction from noisy text, (2) the availability of valid-action supervision or other guidance signals during training, and (3) the ratio of vocabulary size to typical number of relevant entities per state. The theory predicts that pruning benefits scale super-linearly with vocabulary size and number of object slots, but only when combined with appropriate training signals.",
    "supporting_evidence": [
        {
            "text": "KG-DQN with graph-based action pruning converges ~40% faster than LSTM-DQN in TextWorld games with branching factors of 143-562.",
            "uuids": [
                "e1349.1"
            ]
        },
        {
            "text": "KG-A2C with graph mask achieves score of 34 on Zork1 vs 9.9 for TDQN without graph constraints, demonstrating pruning benefits in complex games.",
            "uuids": [
                "e1205.0"
            ]
        },
        {
            "text": "Removing the graph mask from KG-A2C slows learning but can reach similar asymptotic scores, showing pruning primarily aids exploration speed rather than final capability.",
            "uuids": [
                "e1205.0"
            ]
        },
        {
            "text": "Template-based action space (structured) is necessary for tractable exploration; word-level sequence generation performs much worse due to combinatorial explosion.",
            "uuids": [
                "e1205.0"
            ]
        },
        {
            "text": "Valid-action supervision (using oracle valid actions during training) is critical for KG-A2C; without it (KG-A2C-unsupervised), the agent fails to learn, indicating pruning alone is insufficient.",
            "uuids": [
                "e1205.0"
            ]
        },
        {
            "text": "GATA with knowledge-graph-based entity constraints achieves +24.2% relative improvement over text-only baselines in TextWorld cooking games.",
            "uuids": [
                "e1374.1"
            ]
        },
        {
            "text": "In Jericho games, choice-based agents (DRRN) that score over pruned valid actions outperform template-based agents (TDQN) that must score over full combinatorial space, with TDQN suffering from Q-value overestimation due to max over large action sets.",
            "uuids": [
                "e1372.0"
            ]
        },
        {
            "text": "NESTA uses action pruning based on lifted rules and abstract meaning representations, achieving best performance across TextWorld difficulty levels including hard two-room tasks.",
            "uuids": [
                "e1199.1"
            ]
        },
        {
            "text": "Q*BERT uses intrinsic rewards based on knowledge graph growth (new entities/relations discovered) to guide exploration, showing that KG-based signals improve bottleneck crossing.",
            "uuids": [
                "e1184.1"
            ]
        },
        {
            "text": "GO!Q*BERT combines KG-based exploration with Go-Explore style archival methods, using KG snapshots as cell representations to better identify promising states.",
            "uuids": [
                "e1220.2"
            ]
        },
        {
            "text": "KG-A2C uses Graph Attention Networks (GAT) to embed the knowledge graph, with graph-derived masks restricting object choices to entities present in the graph.",
            "uuids": [
                "e1205.0",
                "e1205.1"
            ]
        },
        {
            "text": "GATA learns continuous-valued belief graphs that are denser and less interpretable than discrete KGs but still provide structural constraints; discrete graph updates (GATA-GTP) can underperform due to error accumulation.",
            "uuids": [
                "e1374.1"
            ]
        },
        {
            "text": "In TextWorld games with 10-20 rooms and branching factors 143-562, KG-DQN's action pruning via graph scoring and top-k selection enables convergence where baselines struggle.",
            "uuids": [
                "e1349.1"
            ]
        },
        {
            "text": "Jericho framework provides valid-action detection which enables choice-based methods; games with large template/vocabulary counts (e.g., Zork1: |T|=237, |V|=697) particularly benefit from pruning.",
            "uuids": [
                "e1372.0"
            ]
        }
    ],
    "theory_statements": [
        "Action space size grows as O(|templates| × |vocabulary|^k) where k is the number of object slots, making unpruned exploration intractable when |vocabulary| &gt; 100 and k ≥ 2.",
        "Knowledge-graph-based pruning reduces effective action space to O(|templates| × |entities_in_graph|^k) where |entities_in_graph| &lt;&lt; |vocabulary|, typically by a factor of 10-100x.",
        "The reduction in exploration time is proportional to the ratio of pruned to unpruned action space size, but only when combined with appropriate training signals (e.g., valid-action supervision, intrinsic KG-growth rewards).",
        "Pruning based on entity presence in the knowledge graph can maintain high action coverage (&gt;90% of truly valid actions retained) when the knowledge graph is accurately constructed.",
        "The benefits of action pruning increase super-linearly with vocabulary size and number of object slots, with the greatest benefits observed when |vocabulary| &gt; 500 and k ≥ 2.",
        "Knowledge graph construction accuracy is critical: errors in entity extraction or relation identification can lead to incorrect pruning that removes valid actions or retains invalid ones.",
        "Pruning effectiveness depends on the ratio of vocabulary size to typical number of relevant entities per state; games where most vocabulary items are relevant at most states see minimal benefit.",
        "Continuous belief graphs (as in GATA) can provide similar pruning benefits to discrete KGs while being more robust to individual extraction errors, but at the cost of interpretability.",
        "Combining KG-based pruning with other exploration strategies (e.g., intrinsic rewards for KG growth, archival methods using KG as state representation) provides synergistic benefits beyond pruning alone."
    ],
    "new_predictions_likely": [
        "In a text game with vocabulary size 1000 and 2-object actions, knowledge-graph pruning will reduce exploration time by &gt;10x compared to unpruned exploration, assuming accurate entity extraction.",
        "Increasing vocabulary size from 500 to 2000 while holding game complexity constant will increase the performance gap between pruned and unpruned agents by &gt;50%.",
        "Knowledge-graph pruning combined with valid-action supervision will maintain &gt;90% recall of truly valid actions while reducing action space by &gt;95% in typical games.",
        "Games with higher entity-to-vocabulary ratios (more entities relevant per state) will show smaller benefits from pruning, with diminishing returns when ratio exceeds 0.3.",
        "Combining KG-based pruning with intrinsic rewards for discovering new entities/relations will improve performance by an additional 20-30% over pruning alone."
    ],
    "new_predictions_unknown": [
        "There may be a vocabulary size threshold (possibly around 5000-10000 words) beyond which even knowledge-graph pruning becomes insufficient and additional abstraction (e.g., hierarchical action spaces, learned action embeddings) is needed.",
        "The optimal pruning strategy may vary significantly across different types of text games: puzzle-heavy games may benefit from stricter pruning (higher precision, lower recall) while exploration-heavy games may need looser pruning (higher recall, lower precision).",
        "Incorrect pruning (removing valid actions) may have non-linear negative effects that compound over long episodes, potentially creating unrecoverable states where the agent cannot progress.",
        "The computational cost of knowledge graph construction and maintenance may become a bottleneck in games with very high entity turnover or complex relation extraction requirements, potentially offsetting pruning benefits.",
        "Learned continuous belief graphs (like GATA's) may eventually outperform discrete KGs as model capacity and training data increase, but the crossover point is unknown.",
        "The interaction between KG-based pruning and other exploration bonuses (curiosity, count-based, etc.) may be non-additive, with potential for both synergy and interference."
    ],
    "negative_experiments": [
        "Finding text games where unpruned exploration consistently outperforms knowledge-graph pruning (when both have equal training time/data) would challenge the core efficiency claim.",
        "Demonstrating that pruning reduces action coverage below 70% in typical games would contradict the coverage maintenance claim.",
        "Showing that the benefits of pruning do not increase with vocabulary size (or increase only linearly) would invalidate the super-linear scaling claim.",
        "Finding that KG-based pruning without any additional training signals (no valid-action supervision, no intrinsic rewards) can match supervised methods would challenge the necessity of auxiliary signals.",
        "Demonstrating that simple heuristic pruning (e.g., based on word frequency or recency) performs as well as KG-based pruning would question the value of explicit graph construction.",
        "Finding games where the computational cost of KG construction exceeds the exploration savings from pruning would challenge the practical utility claim."
    ],
    "unaccounted_for": [
        {
            "text": "The theory doesn't specify how to handle actions that require entities not yet discovered or mentioned in observations, which may be critical for progress in some games.",
            "uuids": []
        },
        {
            "text": "The computational cost of knowledge graph construction and maintenance is not characterized, including the cost of entity extraction, relation identification, and graph updates.",
            "uuids": []
        },
        {
            "text": "How to handle ambiguous or incorrect entity extraction from noisy text is not addressed, including strategies for error recovery and confidence-based pruning.",
            "uuids": []
        },
        {
            "text": "The theory doesn't account for games with synonyms or multiple names for the same entity, which could lead to duplicate entities in the graph or missed pruning opportunities.",
            "uuids": []
        },
        {
            "text": "The interaction between pruning and partial observability is not fully characterized - how does pruning perform when the agent has incomplete information about the game state?",
            "uuids": []
        },
        {
            "text": "The theory doesn't address how to handle procedurally generated content where entity sets change dramatically between episodes or within episodes.",
            "uuids": []
        },
        {
            "text": "The optimal balance between pruning aggressiveness (precision vs. recall) for different game types and stages of learning is not specified.",
            "uuids": []
        }
    ],
    "conflicting_evidence": [
        {
            "text": "In some simple games (e.g., navigation-heavy games with small vocabularies), random exploration can succeed without pruning, suggesting the benefits are task-dependent and may not apply universally.",
            "uuids": [
                "e1258.5"
            ]
        },
        {
            "text": "Valid-action supervision (oracle) is required for KG-A2C to work; KG-A2C-unsupervised fails completely, suggesting that pruning alone is insufficient without additional guidance signals.",
            "uuids": [
                "e1205.0"
            ]
        },
        {
            "text": "In Anchorhead, all agents (including those with KG-based pruning) achieved zero score, suggesting that pruning doesn't help when the fundamental exploration problem is too hard or rewards are too sparse.",
            "uuids": [
                "e1372.7"
            ]
        },
        {
            "text": "GATA's continuous belief graphs sometimes outperform discrete KGs, and discrete graph updates (GATA-GTP) can underperform due to error accumulation, suggesting that the discrete graph representation may not always be optimal.",
            "uuids": [
                "e1374.1"
            ]
        },
        {
            "text": "Removing the graph mask from KG-A2C can still reach similar asymptotic scores (though slower), suggesting that pruning may not be necessary for final performance, only for learning speed.",
            "uuids": [
                "e1205.0"
            ]
        }
    ],
    "special_cases": [
        "In games with very small vocabularies (&lt; 50 words) and few object slots (k=1), the overhead of knowledge graph construction may outweigh pruning benefits, and simple template-based methods may suffice.",
        "In games where most actions are valid at most states (high action validity ratio &gt; 0.5), pruning provides minimal benefit and may even hurt by removing occasionally-useful exploratory actions.",
        "In games with highly dynamic entity sets (e.g., procedurally generated content, entities that appear/disappear frequently), knowledge graph maintenance may become a bottleneck and reduce pruning effectiveness.",
        "In games with significant partial observability, pruning based on observed entities may be too aggressive and remove actions that would reveal new information.",
        "In games with complex linguistic phenomena (synonyms, pronouns, implicit references), entity extraction errors may accumulate and degrade pruning quality over time.",
        "In games with very sparse rewards and long dependency chains (like Anchorhead), even optimal pruning may be insufficient without additional exploration strategies or domain knowledge.",
        "In early stages of learning when the knowledge graph is incomplete, overly aggressive pruning may prevent discovery of critical entities or relations needed for progress.",
        "In games where the optimal strategy requires trying 'invalid' actions to trigger special responses or easter eggs, pruning may remove these exploratory opportunities."
    ],
    "existing_theory": {
        "likely_classification": "new",
        "references": [
            "Ammanabrolu & Hausknecht (2020) Graph Constrained Reinforcement Learning for Natural Language Action Spaces [Demonstrates graph-based pruning in practice but doesn't formalize the scaling theory or characterize when/why it works]",
            "Hausknecht et al. (2019) Interactive Fiction Games: A Colossal Adventure [Discusses action space challenges and provides Jericho framework but doesn't provide formal pruning theory]",
            "Côté et al. (2018) TextWorld: A Learning Environment for Text-based Games [Provides environment and discusses action space complexity but doesn't formalize pruning benefits or scaling laws]",
            "Adhikari et al. (2020) Learning Dynamic Belief Graphs to Generalize on Text-Based Games [GATA paper, explores continuous belief graphs as alternative to discrete KGs but doesn't formalize pruning theory]",
            "Ammanabrolu et al. (2020) How to Avoid Being Eaten by a Grue [Discusses exploration strategies including KG-based methods but focuses on bottleneck detection rather than pruning theory]",
            "Xu et al. (2023) Learning Symbolic Rules over Abstract Meaning Representations for Textual Reinforcement Learning [NESTA paper, uses action pruning via lifted rules but doesn't formalize general pruning theory]"
        ]
    },
    "theory_type_general_specific": "specific",
    "reflected_from_theory_index": 5,
    "type": "specific"
}</code></pre>
        </div>
    </div>
</body>
</html>