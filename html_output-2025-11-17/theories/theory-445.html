<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Commonsense Knowledge Integration Theory - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-445</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-445</p>
                <p><strong>Name:</strong> Commonsense Knowledge Integration Theory</p>
                <p><strong>Type:</strong> specific</p>
                <p><strong>Theory Query:</strong> Build a theory of how language model agents can best use memory when solving text games, based on the following results.</p>
                <p><strong>Description:</strong> For text-based games requiring commonsense reasoning about object affordances, typical locations, and thematic relationships, agents that integrate external commonsense knowledge bases (like ConceptNet) into their memory systems achieve better generalization to unseen objects and scenarios. The effectiveness critically depends on: (1) selective, relevance-based retrieval of commonsense facts rather than full graph inclusion, (2) dynamic integration that evolves with observed game state and discovered entities, (3) semantic and thematic alignment between the knowledge base domain and the game domain, and (4) the extraction method used (QA-based inference outperforms rule-based extraction). The benefits are most pronounced when training data lacks sufficient coverage of required commonsense relationships, but diminish when the game domain diverges significantly from real-world knowledge or when sufficient exploration data is available.</p>
                <p><strong>Knowledge Cutoff Year:</strong> 2024</p>
                <p><strong>Knowledge Cutoff Month:</strong> 12</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <h3>Statement 0: Law 0</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; task &#8594; requires &#8594; commonsense knowledge about object locations or affordances<span style="color: #888888;">, and</span></div>
        <div>&#8226; training data &#8594; does not contain &#8594; sufficient examples of required commonsense<span style="color: #888888;">, and</span></div>
        <div>&#8226; agent &#8594; integrates &#8594; external commonsense knowledge base with selective retrieval</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; agent &#8594; achieves better generalization to &#8594; unseen objects and scenarios<span style="color: #888888;">, and</span></div>
        <div>&#8226; agent &#8594; outperforms &#8594; agents without external knowledge</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>TextWorld Commonsense requires external commonsense KB (ConceptNet) for generalization to held-out objects because object-location mappings are held out across splits <a href="../results/extraction-result-2726.html#e2726.2" class="evidence-link">[e2726.2]</a> </li>
    <li>COMET-A2C augmenting KG with commonsense HasA inferences improved robustness to missing mentions, enabling completion of bathroom tasks <a href="../results/extraction-result-2698.html#e2698.2" class="evidence-link">[e2698.2]</a> </li>
    <li>Q*BERT with QA-based commonsense inference achieved faster convergence in missing-observation conditions compared to unaugmented baselines <a href="../results/extraction-result-2698.html#e2698.2" class="evidence-link">[e2698.2]</a> </li>
    <li>KG-DQN with belief graphs helps prune action space and enable efficient exploration by tracking discovered affordances <a href="../results/extraction-result-2765.html#e2765.2" class="evidence-link">[e2765.2]</a> </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p class="empty-note">No existing law comparison provided.</p>
            <h3>Statement 1: Law 1</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; agent &#8594; uses &#8594; full commonsense knowledge graph without filtering<span style="color: #888888;">, and</span></div>
        <div>&#8226; knowledge graph &#8594; contains &#8594; many irrelevant facts for current task</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; agent performance &#8594; degrades due to &#8594; noise and irrelevant information overwhelming exploration<span style="color: #888888;">, and</span></div>
        <div>&#8226; agent &#8594; performs worse than &#8594; agents with selective commonsense retrieval</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>KG_Full with complete ConceptNet subgraph underperformed KG_Evolve due to overwhelming irrelevant knowledge causing noisy exploration <a href="../results/extraction-result-2764.html#e2764.2" class="evidence-link">[e2764.2]</a> </li>
    <li>Providing full commonsense graph upfront can be counterproductive because agent is overwhelmed by irrelevant knowledge, leading to worse performance than focused/evolving access <a href="../results/extraction-result-2764.html#e2764.2" class="evidence-link">[e2764.2]</a> </li>
    <li>Large/full graphs contain much irrelevant information which increases noise in exploration and learning; scalability and pruning become issues <a href="../results/extraction-result-2764.html#e2764.2" class="evidence-link">[e2764.2]</a> </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p class="empty-note">No existing law comparison provided.</p>
            <h3>Statement 2: Law 2</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; commonsense knowledge &#8594; is dynamically retrieved based on &#8594; currently observed entities<span style="color: #888888;">, and</span></div>
        <div>&#8226; retrieval &#8594; evolves with &#8594; game state progression and discovered entities</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; agent &#8594; achieves better performance than &#8594; static full-graph approaches<span style="color: #888888;">, and</span></div>
        <div>&#8226; agent &#8594; maintains &#8594; focused and relevant knowledge throughout gameplay</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>KG_Evolve with dynamic commonsense retrieval outperformed KG_Full static approach in Kitchen Cleanup task <a href="../results/extraction-result-2764.html#e2764.2" class="evidence-link">[e2764.2]</a> </li>
    <li>Q*BERT with QA-based dynamic inference outperformed static rule-based extraction, achieving faster sample efficiency <a href="../results/extraction-result-2698.html#e2698.2" class="evidence-link">[e2698.2]</a> <a href="../results/extraction-result-2710.html#e2710.0" class="evidence-link">[e2710.0]</a> </li>
    <li>Focused/evolving access to commonsense mitigates noise from irrelevant knowledge <a href="../results/extraction-result-2764.html#e2764.2" class="evidence-link">[e2764.2]</a> </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p class="empty-note">No existing law comparison provided.</p>
            <h3>Statement 3: Law 3</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; commonsense extraction &#8594; uses &#8594; QA-based inference methods<span style="color: #888888;">, and</span></div>
        <div>&#8226; QA model &#8594; is fine-tuned on &#8594; domain-relevant question-answering data</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; extracted commonsense &#8594; is more relevant and accurate than &#8594; rule-based or OpenIE extraction<span style="color: #888888;">, and</span></div>
        <div>&#8226; agent &#8594; achieves faster learning and better sample efficiency than &#8594; agents using rule-based extraction</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Q*BERT using ALBERT-based QA extraction achieved faster sample efficiency compared to KG-A2C's OpenIE-based extraction <a href="../results/extraction-result-2710.html#e2710.0" class="evidence-link">[e2710.0]</a> </li>
    <li>QA-based KG extraction improves sample efficiency compared to prior OpenIE-based KG extraction; quality of QA (EM/F1) correlates with game performance <a href="../results/extraction-result-2710.html#e2710.0" class="evidence-link">[e2710.0]</a> </li>
    <li>Q*BERT with diverse QA-based inferences gave faster convergence in missing-data setting compared to COMET's narrower HasA-focused inferences <a href="../results/extraction-result-2698.html#e2698.2" class="evidence-link">[e2698.2]</a> </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p class="empty-note">No existing law comparison provided.</p>
            <h3>Statement 4: Law 4</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; game domain &#8594; has thematic commonsense that diverges from &#8594; everyday real-world knowledge<span style="color: #888888;">, and</span></div>
        <div>&#8226; commonsense knowledge base &#8594; is aligned with &#8594; game's thematic domain</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; agent &#8594; achieves better coherence and genre-appropriate behavior than &#8594; agents using generic real-world commonsense</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>AskBERT using thematic commonsense for fairy-tale genre produced more coherent and genre-appropriate worlds than random-link graphs, particularly where thematic commonsense diverges from everyday knowledge <a href="../results/extraction-result-2721.html#e2721.1" class="evidence-link">[e2721.1]</a> </li>
    <li>Filling in knowledge graphs using thematically relevant (QA-inferred) commonsense improves perceived coherence and genre adherence for generated worlds <a href="../results/extraction-result-2721.html#e2721.1" class="evidence-link">[e2721.1]</a> </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p class="empty-note">No existing law comparison provided.</p>
            <h3>Statement 5: Law 5</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; commonsense inference &#8594; focuses narrowly on &#8594; single relation type (e.g., HasA only)<span style="color: #888888;">, and</span></div>
        <div>&#8226; task &#8594; requires &#8594; diverse types of commonsense relations</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; agent &#8594; converges more slowly than &#8594; agents with diverse commonsense inference<span style="color: #888888;">, and</span></div>
        <div>&#8226; agent &#8594; may fail to recover from &#8594; situations requiring non-covered relation types</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>COMET-A2C focusing primarily on HasA relations converged more slowly than Q*BERT with diverse inferences in extreme missing-observation condition <a href="../results/extraction-result-2698.html#e2698.2" class="evidence-link">[e2698.2]</a> </li>
    <li>Q*BERT-style diverse inferences give faster convergence in missing-data setting; narrower focus on HasA can make convergence slower <a href="../results/extraction-result-2698.html#e2698.2" class="evidence-link">[e2698.2]</a> </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p class="empty-note">No existing law comparison provided.</p>
            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>Agents with domain-specific commonsense knowledge bases (e.g., medical knowledge for hospital games, culinary knowledge for cooking games) will outperform those with general-purpose knowledge bases in specialized game genres</li>
                <li>Learned relevance filtering for commonsense facts (using attention mechanisms or learned retrieval) will outperform hand-crafted filtering rules across diverse game types</li>
                <li>Multi-hop commonsense reasoning (chaining multiple commonsense facts, e.g., 'knife is sharp' + 'sharp objects can cut' → 'knife can cut') will be necessary for complex puzzle-solving tasks requiring causal reasoning</li>
                <li>Commonsense knowledge will provide diminishing returns as the amount of in-game exploration data increases, with a crossover point where exploration-learned knowledge becomes sufficient</li>
                <li>Hybrid approaches that combine learned world models from experience with commonsense priors will outperform either approach alone, especially in early stages of learning</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>Whether commonsense knowledge integration provides benefits in fantasy or science fiction settings where real-world commonsense may actively mislead (e.g., magic systems, alien physics)</li>
                <li>Whether the benefits of commonsense knowledge scale linearly with knowledge base size or show diminishing returns after a certain coverage threshold</li>
                <li>Whether agents can learn to identify when commonsense knowledge is unreliable or contradicts observed evidence, and appropriately weight or ignore it</li>
                <li>Whether commonsense knowledge helps more in games with sparse rewards vs. dense rewards, or if the benefit is independent of reward structure</li>
                <li>Whether pre-training language models on game-specific corpora can internalize commonsense knowledge sufficiently to eliminate the need for explicit external knowledge bases</li>
                <li>Whether commonsense knowledge integration helps agents recover from mistakes or dead-ends more effectively than pure exploration-based approaches</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>Finding tasks where commonsense knowledge consistently harms performance (e.g., by introducing incorrect assumptions about game mechanics) would identify important boundary conditions and failure modes</li>
                <li>Demonstrating that learned world models from experience alone match or exceed commonsense-augmented agents given sufficient training time would question the necessity of external knowledge for long-term performance</li>
                <li>Showing that commonsense knowledge provides no benefit when sufficient training data is available would limit its applicability to low-data regimes only</li>
                <li>Finding that random or adversarially-selected 'commonsense' facts perform as well as curated knowledge would suggest the benefits come from increased exploration rather than semantic content</li>
                <li>Demonstrating that commonsense knowledge integration increases brittleness or reduces robustness to distribution shift would reveal important trade-offs</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>How to handle conflicts between commonsense knowledge and observed game mechanics is not well addressed (e.g., when game rules violate real-world physics or logic) <a href="../results/extraction-result-2698.html#e2698.2" class="evidence-link">[e2698.2]</a> </li>
    <li>The optimal granularity and specificity of commonsense facts for different game types is unclear (e.g., high-level vs. fine-grained relations) <a href="../results/extraction-result-2764.html#e2764.2" class="evidence-link">[e2764.2]</a> </li>
    <li>How to automatically select the most relevant commonsense knowledge base for a new game domain is not established <a href="../results/extraction-result-2726.html#e2726.2" class="evidence-link">[e2726.2]</a> </li>
    <li>The interaction between commonsense knowledge and other memory mechanisms (e.g., episodic memory, working memory) is not fully characterized <a href="../results/extraction-result-2698.html#e2698.2" class="evidence-link">[e2698.2]</a> <a href="../results/extraction-result-2764.html#e2764.2" class="evidence-link">[e2764.2]</a> </li>
    <li>How exploration bias from BERT-based policy shaping interacts with commonsense knowledge is unclear; KG-A2C-BERT showed that exploration bias alone is ineffective without underlying entity knowledge <a href="../results/extraction-result-2698.html#e2698.3" class="evidence-link">[e2698.3]</a> </li>
    <li>The computational and memory overhead of different commonsense integration strategies is not systematically compared <a href="../results/extraction-result-2764.html#e2764.2" class="evidence-link">[e2764.2]</a> </li>
    <li>How to balance between commonsense priors and observed evidence when they conflict is not well-defined <a href="../results/extraction-result-2698.html#e2698.2" class="evidence-link">[e2698.2]</a> </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> closely-related-to-existing</p>
            <p><strong>Explanation:</strong> No explanation provided.</p>
            <p><strong>References:</strong> <ul>
    <li>Murugesan et al. (2020) Text-based RL Agents with Commonsense Knowledge [Introduced commonsense integration for text games, established TextWorld Commonsense benchmark]</li>
    <li>Ammanabrolu et al. (2020) Playing Text-Based Games with Common Sense [COMET-based commonsense augmentation, Q*BERT with QA-based inference]</li>
    <li>Adhikari et al. (2020) Learning dynamic belief graphs to generalize on text-based games [Dynamic knowledge graph construction and commonsense integration]</li>
    <li>Speer et al. (2017) ConceptNet 5.5: An Open Multilingual Graph of General Knowledge [ConceptNet knowledge base used in multiple text-game agents]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Commonsense Knowledge Integration Theory",
    "theory_description": "For text-based games requiring commonsense reasoning about object affordances, typical locations, and thematic relationships, agents that integrate external commonsense knowledge bases (like ConceptNet) into their memory systems achieve better generalization to unseen objects and scenarios. The effectiveness critically depends on: (1) selective, relevance-based retrieval of commonsense facts rather than full graph inclusion, (2) dynamic integration that evolves with observed game state and discovered entities, (3) semantic and thematic alignment between the knowledge base domain and the game domain, and (4) the extraction method used (QA-based inference outperforms rule-based extraction). The benefits are most pronounced when training data lacks sufficient coverage of required commonsense relationships, but diminish when the game domain diverges significantly from real-world knowledge or when sufficient exploration data is available.",
    "theory_statements": [
        {
            "law": {
                "if": [
                    {
                        "subject": "task",
                        "relation": "requires",
                        "object": "commonsense knowledge about object locations or affordances"
                    },
                    {
                        "subject": "training data",
                        "relation": "does not contain",
                        "object": "sufficient examples of required commonsense"
                    },
                    {
                        "subject": "agent",
                        "relation": "integrates",
                        "object": "external commonsense knowledge base with selective retrieval"
                    }
                ],
                "then": [
                    {
                        "subject": "agent",
                        "relation": "achieves better generalization to",
                        "object": "unseen objects and scenarios"
                    },
                    {
                        "subject": "agent",
                        "relation": "outperforms",
                        "object": "agents without external knowledge"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "TextWorld Commonsense requires external commonsense KB (ConceptNet) for generalization to held-out objects because object-location mappings are held out across splits",
                        "uuids": [
                            "e2726.2"
                        ]
                    },
                    {
                        "text": "COMET-A2C augmenting KG with commonsense HasA inferences improved robustness to missing mentions, enabling completion of bathroom tasks",
                        "uuids": [
                            "e2698.2"
                        ]
                    },
                    {
                        "text": "Q*BERT with QA-based commonsense inference achieved faster convergence in missing-observation conditions compared to unaugmented baselines",
                        "uuids": [
                            "e2698.2"
                        ]
                    },
                    {
                        "text": "KG-DQN with belief graphs helps prune action space and enable efficient exploration by tracking discovered affordances",
                        "uuids": [
                            "e2765.2"
                        ]
                    }
                ]
            }
        },
        {
            "law": {
                "if": [
                    {
                        "subject": "agent",
                        "relation": "uses",
                        "object": "full commonsense knowledge graph without filtering"
                    },
                    {
                        "subject": "knowledge graph",
                        "relation": "contains",
                        "object": "many irrelevant facts for current task"
                    }
                ],
                "then": [
                    {
                        "subject": "agent performance",
                        "relation": "degrades due to",
                        "object": "noise and irrelevant information overwhelming exploration"
                    },
                    {
                        "subject": "agent",
                        "relation": "performs worse than",
                        "object": "agents with selective commonsense retrieval"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "KG_Full with complete ConceptNet subgraph underperformed KG_Evolve due to overwhelming irrelevant knowledge causing noisy exploration",
                        "uuids": [
                            "e2764.2"
                        ]
                    },
                    {
                        "text": "Providing full commonsense graph upfront can be counterproductive because agent is overwhelmed by irrelevant knowledge, leading to worse performance than focused/evolving access",
                        "uuids": [
                            "e2764.2"
                        ]
                    },
                    {
                        "text": "Large/full graphs contain much irrelevant information which increases noise in exploration and learning; scalability and pruning become issues",
                        "uuids": [
                            "e2764.2"
                        ]
                    }
                ]
            }
        },
        {
            "law": {
                "if": [
                    {
                        "subject": "commonsense knowledge",
                        "relation": "is dynamically retrieved based on",
                        "object": "currently observed entities"
                    },
                    {
                        "subject": "retrieval",
                        "relation": "evolves with",
                        "object": "game state progression and discovered entities"
                    }
                ],
                "then": [
                    {
                        "subject": "agent",
                        "relation": "achieves better performance than",
                        "object": "static full-graph approaches"
                    },
                    {
                        "subject": "agent",
                        "relation": "maintains",
                        "object": "focused and relevant knowledge throughout gameplay"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "KG_Evolve with dynamic commonsense retrieval outperformed KG_Full static approach in Kitchen Cleanup task",
                        "uuids": [
                            "e2764.2"
                        ]
                    },
                    {
                        "text": "Q*BERT with QA-based dynamic inference outperformed static rule-based extraction, achieving faster sample efficiency",
                        "uuids": [
                            "e2698.2",
                            "e2710.0"
                        ]
                    },
                    {
                        "text": "Focused/evolving access to commonsense mitigates noise from irrelevant knowledge",
                        "uuids": [
                            "e2764.2"
                        ]
                    }
                ]
            }
        },
        {
            "law": {
                "if": [
                    {
                        "subject": "commonsense extraction",
                        "relation": "uses",
                        "object": "QA-based inference methods"
                    },
                    {
                        "subject": "QA model",
                        "relation": "is fine-tuned on",
                        "object": "domain-relevant question-answering data"
                    }
                ],
                "then": [
                    {
                        "subject": "extracted commonsense",
                        "relation": "is more relevant and accurate than",
                        "object": "rule-based or OpenIE extraction"
                    },
                    {
                        "subject": "agent",
                        "relation": "achieves faster learning and better sample efficiency than",
                        "object": "agents using rule-based extraction"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Q*BERT using ALBERT-based QA extraction achieved faster sample efficiency compared to KG-A2C's OpenIE-based extraction",
                        "uuids": [
                            "e2710.0"
                        ]
                    },
                    {
                        "text": "QA-based KG extraction improves sample efficiency compared to prior OpenIE-based KG extraction; quality of QA (EM/F1) correlates with game performance",
                        "uuids": [
                            "e2710.0"
                        ]
                    },
                    {
                        "text": "Q*BERT with diverse QA-based inferences gave faster convergence in missing-data setting compared to COMET's narrower HasA-focused inferences",
                        "uuids": [
                            "e2698.2"
                        ]
                    }
                ]
            }
        },
        {
            "law": {
                "if": [
                    {
                        "subject": "game domain",
                        "relation": "has thematic commonsense that diverges from",
                        "object": "everyday real-world knowledge"
                    },
                    {
                        "subject": "commonsense knowledge base",
                        "relation": "is aligned with",
                        "object": "game's thematic domain"
                    }
                ],
                "then": [
                    {
                        "subject": "agent",
                        "relation": "achieves better coherence and genre-appropriate behavior than",
                        "object": "agents using generic real-world commonsense"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "AskBERT using thematic commonsense for fairy-tale genre produced more coherent and genre-appropriate worlds than random-link graphs, particularly where thematic commonsense diverges from everyday knowledge",
                        "uuids": [
                            "e2721.1"
                        ]
                    },
                    {
                        "text": "Filling in knowledge graphs using thematically relevant (QA-inferred) commonsense improves perceived coherence and genre adherence for generated worlds",
                        "uuids": [
                            "e2721.1"
                        ]
                    }
                ]
            }
        },
        {
            "law": {
                "if": [
                    {
                        "subject": "commonsense inference",
                        "relation": "focuses narrowly on",
                        "object": "single relation type (e.g., HasA only)"
                    },
                    {
                        "subject": "task",
                        "relation": "requires",
                        "object": "diverse types of commonsense relations"
                    }
                ],
                "then": [
                    {
                        "subject": "agent",
                        "relation": "converges more slowly than",
                        "object": "agents with diverse commonsense inference"
                    },
                    {
                        "subject": "agent",
                        "relation": "may fail to recover from",
                        "object": "situations requiring non-covered relation types"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "COMET-A2C focusing primarily on HasA relations converged more slowly than Q*BERT with diverse inferences in extreme missing-observation condition",
                        "uuids": [
                            "e2698.2"
                        ]
                    },
                    {
                        "text": "Q*BERT-style diverse inferences give faster convergence in missing-data setting; narrower focus on HasA can make convergence slower",
                        "uuids": [
                            "e2698.2"
                        ]
                    }
                ]
            }
        }
    ],
    "new_predictions_likely": [
        "Agents with domain-specific commonsense knowledge bases (e.g., medical knowledge for hospital games, culinary knowledge for cooking games) will outperform those with general-purpose knowledge bases in specialized game genres",
        "Learned relevance filtering for commonsense facts (using attention mechanisms or learned retrieval) will outperform hand-crafted filtering rules across diverse game types",
        "Multi-hop commonsense reasoning (chaining multiple commonsense facts, e.g., 'knife is sharp' + 'sharp objects can cut' → 'knife can cut') will be necessary for complex puzzle-solving tasks requiring causal reasoning",
        "Commonsense knowledge will provide diminishing returns as the amount of in-game exploration data increases, with a crossover point where exploration-learned knowledge becomes sufficient",
        "Hybrid approaches that combine learned world models from experience with commonsense priors will outperform either approach alone, especially in early stages of learning"
    ],
    "new_predictions_unknown": [
        "Whether commonsense knowledge integration provides benefits in fantasy or science fiction settings where real-world commonsense may actively mislead (e.g., magic systems, alien physics)",
        "Whether the benefits of commonsense knowledge scale linearly with knowledge base size or show diminishing returns after a certain coverage threshold",
        "Whether agents can learn to identify when commonsense knowledge is unreliable or contradicts observed evidence, and appropriately weight or ignore it",
        "Whether commonsense knowledge helps more in games with sparse rewards vs. dense rewards, or if the benefit is independent of reward structure",
        "Whether pre-training language models on game-specific corpora can internalize commonsense knowledge sufficiently to eliminate the need for explicit external knowledge bases",
        "Whether commonsense knowledge integration helps agents recover from mistakes or dead-ends more effectively than pure exploration-based approaches"
    ],
    "negative_experiments": [
        "Finding tasks where commonsense knowledge consistently harms performance (e.g., by introducing incorrect assumptions about game mechanics) would identify important boundary conditions and failure modes",
        "Demonstrating that learned world models from experience alone match or exceed commonsense-augmented agents given sufficient training time would question the necessity of external knowledge for long-term performance",
        "Showing that commonsense knowledge provides no benefit when sufficient training data is available would limit its applicability to low-data regimes only",
        "Finding that random or adversarially-selected 'commonsense' facts perform as well as curated knowledge would suggest the benefits come from increased exploration rather than semantic content",
        "Demonstrating that commonsense knowledge integration increases brittleness or reduces robustness to distribution shift would reveal important trade-offs"
    ],
    "unaccounted_for": [
        {
            "text": "How to handle conflicts between commonsense knowledge and observed game mechanics is not well addressed (e.g., when game rules violate real-world physics or logic)",
            "uuids": [
                "e2698.2"
            ]
        },
        {
            "text": "The optimal granularity and specificity of commonsense facts for different game types is unclear (e.g., high-level vs. fine-grained relations)",
            "uuids": [
                "e2764.2"
            ]
        },
        {
            "text": "How to automatically select the most relevant commonsense knowledge base for a new game domain is not established",
            "uuids": [
                "e2726.2"
            ]
        },
        {
            "text": "The interaction between commonsense knowledge and other memory mechanisms (e.g., episodic memory, working memory) is not fully characterized",
            "uuids": [
                "e2698.2",
                "e2764.2"
            ]
        },
        {
            "text": "How exploration bias from BERT-based policy shaping interacts with commonsense knowledge is unclear; KG-A2C-BERT showed that exploration bias alone is ineffective without underlying entity knowledge",
            "uuids": [
                "e2698.3"
            ]
        },
        {
            "text": "The computational and memory overhead of different commonsense integration strategies is not systematically compared",
            "uuids": [
                "e2764.2"
            ]
        },
        {
            "text": "How to balance between commonsense priors and observed evidence when they conflict is not well-defined",
            "uuids": [
                "e2698.2"
            ]
        }
    ],
    "conflicting_evidence": [
        {
            "text": "Some agents achieved good performance without external commonsense knowledge through sufficient exploration and episodic discovery bonuses",
            "uuids": [
                "e2767.2"
            ]
        },
        {
            "text": "In some games, rule-based extraction (OpenIE5) produced more relations than neural AskBERT graphs, suggesting hand-crafted rules can sometimes outperform learned approaches",
            "uuids": [
                "e2721.1"
            ]
        },
        {
            "text": "KG-A2C-BERT with exploration bias provided no benefit when agent lacked underlying entities in knowledge graph, suggesting commonsense alone is insufficient without proper state representation",
            "uuids": [
                "e2698.3"
            ]
        }
    ],
    "special_cases": [
        "In fantasy or fictional settings where real-world commonsense may be misleading or incorrect (e.g., magic systems, alternate physics), commonsense knowledge may need to be disabled or heavily filtered",
        "For games with explicit tutorials or instructions that provide all necessary knowledge, commonsense knowledge may be redundant and add unnecessary computational overhead",
        "In very simple games with limited object types and straightforward mechanics, the overhead of commonsense knowledge integration may not be justified by performance gains",
        "When game domains have strong thematic divergence from real-world knowledge (e.g., fairy tales, science fiction), domain-specific or thematic commonsense is necessary rather than generic real-world knowledge",
        "In games where observations are complete and unambiguous, commonsense knowledge provides less benefit than in games with missing mentions or partial observability",
        "For deterministic games with small state spaces, exhaustive exploration may be more efficient than commonsense-guided exploration",
        "When the commonsense knowledge base has poor coverage of the game domain, integration may hurt more than help by introducing irrelevant or misleading information"
    ],
    "existing_theory": {
        "likely_classification": "closely-related-to-existing",
        "references": [
            "Murugesan et al. (2020) Text-based RL Agents with Commonsense Knowledge [Introduced commonsense integration for text games, established TextWorld Commonsense benchmark]",
            "Ammanabrolu et al. (2020) Playing Text-Based Games with Common Sense [COMET-based commonsense augmentation, Q*BERT with QA-based inference]",
            "Adhikari et al. (2020) Learning dynamic belief graphs to generalize on text-based games [Dynamic knowledge graph construction and commonsense integration]",
            "Speer et al. (2017) ConceptNet 5.5: An Open Multilingual Graph of General Knowledge [ConceptNet knowledge base used in multiple text-game agents]"
        ]
    },
    "theory_type_general_specific": "specific",
    "reflected_from_theory_index": 4,
    "type": "specific"
}</code></pre>
        </div>
    </div>
</body>
</html>