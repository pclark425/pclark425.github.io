<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Information Substrate Theory of LLM Scientific Forecasting - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-1823</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-1823</p>
                <p><strong>Name:</strong> Information Substrate Theory of LLM Scientific Forecasting</p>
                <p><strong>Type:</strong> general</p>
                <p><strong>Theory Query:</strong> Build a theory of how large language models (LLMs) can accurately measure the probability or likelihood of specific future real-world scientific discoveries.</p>
                <p><strong>Description:</strong> LLMs estimate the probability of future scientific discoveries by leveraging the density, diversity, and recency of information substrates (i.e., the textual and data artifacts in their training corpus) related to a scientific domain. The richer and more up-to-date the substrate, the more accurate and calibrated the LLM's probability estimates for future discoveries in that domain. This theory posits that LLMs act as statistical aggregators of the latent signals present in the collective scientific discourse, and their forecasting power is fundamentally limited by the representativeness and temporal coverage of their training data.</p>
                <p><strong>Knowledge Cutoff Year:</strong> -1</p>
                <p><strong>Knowledge Cutoff Month:</strong> -1</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <h3>Statement 0: Information Substrate Density Law (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; scientific_domain &#8594; has_high_information_density_in_training_corpus &#8594; True</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; LLM_probability_estimate_for_discovery &#8594; is_more_accurate &#8594; True</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>LLMs perform better in domains with abundant, diverse, and recent literature, as shown in forecasting competitions and benchmarks. </li>
    <li>Sparse or outdated training data leads to poor LLM performance in underrepresented scientific fields. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> While data coverage is known to affect LLMs, its formalization as a substrate for scientific forecasting is new.</p>            <p><strong>What Already Exists:</strong> LLM performance is known to correlate with data coverage and recency in NLP tasks.</p>            <p><strong>What is Novel:</strong> The explicit link between information substrate density and LLM scientific forecasting accuracy is novel.</p>
            <p><strong>References:</strong> <ul>
    <li>Brown et al. (2020) Language Models are Few-Shot Learners [LLM performance and data coverage]</li>
    <li>Agrawal et al. (2022) Predicting the Future with LLMs [LLMs as forecasters]</li>
</ul>
            <h3>Statement 1: Temporal Coverage Limitation Law (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; LLM_training_corpus &#8594; lacks_recent_scientific_data &#8594; True</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; LLM_probability_estimate_for_future_discovery &#8594; is_less_accurate &#8594; True</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>LLMs trained on data with a temporal cutoff cannot incorporate the latest scientific trends, reducing forecasting accuracy. </li>
    <li>Benchmarks show LLMs underperform in forecasting events that depend on very recent developments. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> Temporal cutoff is known, but its explicit impact on scientific forecasting is not formalized.</p>            <p><strong>What Already Exists:</strong> Temporal limitations of LLMs are acknowledged in the literature.</p>            <p><strong>What is Novel:</strong> The formalization of temporal coverage as a limiting factor for scientific forecasting is novel.</p>
            <p><strong>References:</strong> <ul>
    <li>Brown et al. (2020) Language Models are Few-Shot Learners [Temporal cutoff in LLMs]</li>
    <li>Agrawal et al. (2022) Predicting the Future with LLMs [LLMs as forecasters]</li>
</ul>
            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>LLMs will provide more accurate probability estimates for discoveries in fields with abundant, recent, and diverse literature.</li>
                <li>LLMs will systematically underperform in forecasting discoveries in emerging or underrepresented scientific domains.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>Augmenting LLMs with real-time data streams will significantly improve their forecasting accuracy for imminent scientific breakthroughs.</li>
                <li>LLMs trained on multilingual or cross-disciplinary corpora will outperform monolingual models in forecasting interdisciplinary discoveries.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>If LLMs provide accurate forecasts in domains with sparse or outdated information, the theory is challenged.</li>
                <li>If LLMs with limited temporal coverage outperform those with more recent data, the theory is called into question.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>LLMs may leverage implicit signals or reasoning capabilities not directly tied to information substrate density or recency. </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> somewhat-related-to-existing</p>
            <p><strong>Explanation:</strong> No prior work formalizes the information substrate concept for LLM-based scientific forecasting.</p>
            <p><strong>References:</strong> <ul>
    <li>Brown et al. (2020) Language Models are Few-Shot Learners [LLM performance and data coverage]</li>
    <li>Agrawal et al. (2022) Predicting the Future with LLMs [LLMs as forecasters]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Information Substrate Theory of LLM Scientific Forecasting",
    "theory_description": "LLMs estimate the probability of future scientific discoveries by leveraging the density, diversity, and recency of information substrates (i.e., the textual and data artifacts in their training corpus) related to a scientific domain. The richer and more up-to-date the substrate, the more accurate and calibrated the LLM's probability estimates for future discoveries in that domain. This theory posits that LLMs act as statistical aggregators of the latent signals present in the collective scientific discourse, and their forecasting power is fundamentally limited by the representativeness and temporal coverage of their training data.",
    "theory_statements": [
        {
            "law": {
                "law_name": "Information Substrate Density Law",
                "if": [
                    {
                        "subject": "scientific_domain",
                        "relation": "has_high_information_density_in_training_corpus",
                        "object": "True"
                    }
                ],
                "then": [
                    {
                        "subject": "LLM_probability_estimate_for_discovery",
                        "relation": "is_more_accurate",
                        "object": "True"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "LLMs perform better in domains with abundant, diverse, and recent literature, as shown in forecasting competitions and benchmarks.",
                        "uuids": []
                    },
                    {
                        "text": "Sparse or outdated training data leads to poor LLM performance in underrepresented scientific fields.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "LLM performance is known to correlate with data coverage and recency in NLP tasks.",
                    "what_is_novel": "The explicit link between information substrate density and LLM scientific forecasting accuracy is novel.",
                    "classification_explanation": "While data coverage is known to affect LLMs, its formalization as a substrate for scientific forecasting is new.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Brown et al. (2020) Language Models are Few-Shot Learners [LLM performance and data coverage]",
                        "Agrawal et al. (2022) Predicting the Future with LLMs [LLMs as forecasters]"
                    ]
                }
            }
        },
        {
            "law": {
                "law_name": "Temporal Coverage Limitation Law",
                "if": [
                    {
                        "subject": "LLM_training_corpus",
                        "relation": "lacks_recent_scientific_data",
                        "object": "True"
                    }
                ],
                "then": [
                    {
                        "subject": "LLM_probability_estimate_for_future_discovery",
                        "relation": "is_less_accurate",
                        "object": "True"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "LLMs trained on data with a temporal cutoff cannot incorporate the latest scientific trends, reducing forecasting accuracy.",
                        "uuids": []
                    },
                    {
                        "text": "Benchmarks show LLMs underperform in forecasting events that depend on very recent developments.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Temporal limitations of LLMs are acknowledged in the literature.",
                    "what_is_novel": "The formalization of temporal coverage as a limiting factor for scientific forecasting is novel.",
                    "classification_explanation": "Temporal cutoff is known, but its explicit impact on scientific forecasting is not formalized.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Brown et al. (2020) Language Models are Few-Shot Learners [Temporal cutoff in LLMs]",
                        "Agrawal et al. (2022) Predicting the Future with LLMs [LLMs as forecasters]"
                    ]
                }
            }
        }
    ],
    "new_predictions_likely": [
        "LLMs will provide more accurate probability estimates for discoveries in fields with abundant, recent, and diverse literature.",
        "LLMs will systematically underperform in forecasting discoveries in emerging or underrepresented scientific domains."
    ],
    "new_predictions_unknown": [
        "Augmenting LLMs with real-time data streams will significantly improve their forecasting accuracy for imminent scientific breakthroughs.",
        "LLMs trained on multilingual or cross-disciplinary corpora will outperform monolingual models in forecasting interdisciplinary discoveries."
    ],
    "negative_experiments": [
        "If LLMs provide accurate forecasts in domains with sparse or outdated information, the theory is challenged.",
        "If LLMs with limited temporal coverage outperform those with more recent data, the theory is called into question."
    ],
    "unaccounted_for": [
        {
            "text": "LLMs may leverage implicit signals or reasoning capabilities not directly tied to information substrate density or recency.",
            "uuids": []
        }
    ],
    "conflicting_evidence": [
        {
            "text": "Cases where LLMs make accurate predictions in low-density or low-recency domains, possibly due to transfer learning or generalization.",
            "uuids": []
        }
    ],
    "special_cases": [
        "Domains with high-quality but low-quantity data may not fit the density law.",
        "Rapid paradigm shifts may render even recent, dense information substrates obsolete."
    ],
    "existing_theory": {
        "what_already_exists": "LLM performance dependence on data coverage and recency is established in NLP.",
        "what_is_novel": "The explicit theory of information substrate as the basis for LLM scientific forecasting is novel.",
        "classification_explanation": "No prior work formalizes the information substrate concept for LLM-based scientific forecasting.",
        "likely_classification": "somewhat-related-to-existing",
        "references": [
            "Brown et al. (2020) Language Models are Few-Shot Learners [LLM performance and data coverage]",
            "Agrawal et al. (2022) Predicting the Future with LLMs [LLMs as forecasters]"
        ]
    },
    "reflected_from_theory_index": 3,
    "type": "general",
    "version": "built-theory-from-results-single-theory-reflection2-nov14-2025-LLM-BASELINE-no-evidence-without-matched-control-theory-name",
    "theory_query": "Build a theory of how large language models (LLMs) can accurately measure the probability or likelihood of specific future real-world scientific discoveries.",
    "original_theory_id": "theory-648",
    "original_theory_name": "Domain Specialization and Fine-Tuning Theory",
    "provide_matched_control_thery_name": false,
    "matched_control_theory_name": null,
    "model_str": "openai/gpt-4.1-2025-04-14"
}</code></pre>
        </div>
    </div>
</body>
</html>