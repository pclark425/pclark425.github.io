<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Structured Decomposition Theory - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-114</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-114</p>
                <p><strong>Name:</strong> Structured Decomposition Theory</p>
                <p><strong>Type:</strong> general</p>
                <p><strong>Theory Query:</strong> Build a theory about probabilistic symbolic world models for text environments that integrate LLM uncertainty into planning, based on the following results.</p>
                <p><strong>Description:</strong> Breaking down complex reasoning and simulation tasks into structured sub-problems significantly improves LLM reliability and accuracy when the decomposition aligns with the task structure. Effective decomposition strategies include: (1) multi-task learning that exploits shared structure across related tasks, (2) step-by-step reasoning chains that make intermediate steps explicit (CoT, CBS), (3) set-of-sequences representations that handle unordered outputs with permutation-invariant losses, (4) modular policy chaining that breaks long-horizon tasks into sub-goals with intrinsic motivation, and (5) iterative refinement with structured feedback loops (syntax, semantics, execution validation). The benefits are particularly pronounced for tasks requiring: handling indirect effects, maintaining consistency across multiple predictions, scaling to long horizons, and avoiding error accumulation. However, decomposition must be matched to task structure—inappropriate decomposition can introduce overhead without benefits, and overly fine-grained decomposition can lose important holistic context.</p>
                <p><strong>Knowledge Cutoff Year:</strong> 2024</p>
                <p><strong>Knowledge Cutoff Month:</strong> 12</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <ol>
                <li>Structured decomposition of complex tasks into sub-problems improves LLM reliability and accuracy when decomposition aligns with task structure</li>
                <li>Multi-task learning with related tasks improves performance on individual tasks through shared representations and regularization effects</li>
                <li>Explicit reasoning chains (step-by-step decomposition) reduce errors, improve interpretability, and enable detection of indirect effects</li>
                <li>Grammar constraints and formal languages prevent syntax errors and improve semantic accuracy by restricting the output space</li>
                <li>Set-based representations with permutation-invariant losses handle unordered outputs better than sequence models by avoiding spurious ordering dependencies</li>
                <li>Modular policy chaining with intrinsic motivation enables solving long-horizon tasks by breaking them into manageable sub-goals and providing intermediate rewards</li>
                <li>Iterative refinement with structured feedback (syntax, semantics, execution validation) improves output quality by catching and correcting errors early</li>
                <li>Structured belief representations (graphs, symbolic states) improve sample efficiency and generalization in partially observable environments</li>
                <li>The granularity of decomposition should match task complexity—too coarse loses benefits, too fine loses context</li>
                <li>Computational overhead of structured approaches must be balanced against accuracy benefits through efficient implementations (caching, reuse)</li>
                <li>Proposal design in structured inference (choosing proposals closer to posterior) substantially affects computational efficiency and accuracy</li>
            </ol>
            <h3>Supporting Evidence</h3>
<ol>
    <li>Worldformer with multi-task learning (joint KG and action prediction) and Set-of-Sequences loss achieves 39.15% graph EM vs 14.29% for single-task Seq2Seq; ablations show removing multi-task or SOS causes significant drops <a href="../results/extraction-result-851.html#e851.0" class="evidence-link">[e851.0]</a> <a href="../results/extraction-result-851.html#e851.3" class="evidence-link">[e851.3]</a> </li>
    <li>BeSimulator's Chain of Behavior Simulation (4-phase: consider-decide-capture-transfer) substantially improves accuracy vs single-phase prompting, especially for detecting indirect state changes; ablation shows single-phase still beats CoT by ~13.07% but full CBS yields highest accuracy <a href="../results/extraction-result-842.html#e842.0" class="evidence-link">[e842.0]</a> <a href="../results/extraction-result-842.html#e842.1" class="evidence-link">[e842.1]</a> </li>
    <li>MC!Q*BERT with modular policy chaining, graph-based intrinsic motivation, and structured exploration outperforms baselines on 8/9 games; ablation shows intrinsic motivation is crucial for clearing bottlenecks <a href="../results/extraction-result-967.html#e967.1" class="evidence-link">[e967.1]</a> </li>
    <li>Grammar-constrained SMC decoding into ELoT achieves ~91% semantic equivalence vs lower for unconstrained generation; structured representation improves translation accuracy by up to 2.4× vs lowered form <a href="../results/extraction-result-852.html#e852.3" class="evidence-link">[e852.3]</a> <a href="../results/extraction-result-852.html#e852.2" class="evidence-link">[e852.2]</a> <a href="../results/extraction-result-852.html#e852.0" class="evidence-link">[e852.0]</a> </li>
    <li>AutoTAMP with iterative syntax/semantic checking achieves ~83.5% success (HouseWorld2) vs lower for unconstrained translation; structured validation loop is critical <a href="../results/extraction-result-975.html#e975.0" class="evidence-link">[e975.0]</a> </li>
    <li>GPT-4 generalized planning with automated debugging (4 feedback types: Python exceptions, timeouts, syntax, semantics via VAL) achieves 0.90-1.00 success on multiple domains; 'No Debug' ablation dramatically lowers success, showing iterative refinement is critical <a href="../results/extraction-result-973.html#e973.0" class="evidence-link">[e973.0]</a> </li>
    <li>RAP with explicit textual state representation and MCTS decomposition achieves 51.6% on GSM8K vs 29.4% for unstructured CoT; ablations show state-transition confidence and self-evaluation rewards (uncertainty-aware decomposition) improve performance <a href="../results/extraction-result-970.html#e970.0" class="evidence-link">[e970.0]</a> </li>
    <li>LaBToM with compositional ELoT representation achieves r=0.76 with human judgments vs r=0.52 for GPT-4o baseline; grammar-constrained parsing into structured representation yields better semantic accuracy <a href="../results/extraction-result-852.html#e852.0" class="evidence-link">[e852.0]</a> <a href="../results/extraction-result-852.html#e852.2" class="evidence-link">[e852.2]</a> <a href="../results/extraction-result-852.html#e852.3" class="evidence-link">[e852.3]</a> </li>
    <li>SIPS with sequential plan extension and data-driven rejuvenation proposals achieves better accuracy and runtime than BIRL baselines; structured incremental planning with MH rejuvenation maintains hypothesis diversity <a href="../results/extraction-result-1006.html#e1006.0" class="evidence-link">[e1006.0]</a> <a href="../results/extraction-result-1006.html#e1006.5" class="evidence-link">[e1006.5]</a> </li>
    <li>PWM/PWL with structured abductive inference (MCMC over proof/theory space with multiple proposal types) outperforms neural baselines on zero-shot QA; structured probabilistic reasoning with explicit proof decomposition enables better generalization <a href="../results/extraction-result-843.html#e843.0" class="evidence-link">[e843.0]</a> </li>
    <li>NIPE's modular pipeline (LLM translation → probabilistic scene generation → Bayesian inverse planning) achieves R=0.927 correlation with human judgments vs R=0.658 for GPT-4 direct; structured decomposition into translation, world model, and planning modules improves reliability <a href="../results/extraction-result-845.html#e845.0" class="evidence-link">[e845.0]</a> </li>
    <li>LLM+P with structured pipeline (NL→PDDL translation + classical planner + plan translation) achieves 90% success (BlocksWorld) vs 15-30% for LLM-alone; contextual examples crucial for reliable translation <a href="../results/extraction-result-974.html#e974.0" class="evidence-link">[e974.0]</a> <a href="../results/extraction-result-1001.html#e1001.0" class="evidence-link">[e1001.0]</a> </li>
    <li>LLM-acquired PDDL with iterative correction (validator feedback + LLM repair) achieves ~95% planning success vs <50% for LLM-modulo-planner; structured validation and correction loop is essential <a href="../results/extraction-result-971.html#e971.0" class="evidence-link">[e971.0]</a> <a href="../results/extraction-result-971.html#e971.2" class="evidence-link">[e971.2]</a> </li>
    <li>SMC steering with structured Feynman-Kac formulation and efficient caching enables tractable constrained generation; proposal design (choosing M_t closer to posterior) substantially affects estimator quality <a href="../results/extraction-result-977.html#e977.0" class="evidence-link">[e977.0]</a> <a href="../results/extraction-result-977.html#e977.1" class="evidence-link">[e977.1]</a> <a href="../results/extraction-result-977.html#e977.2" class="evidence-link">[e977.2]</a> </li>
    <li>GATA with continuous belief-graph representation and self-supervised pretraining (OG+COC) achieves +24.2% relative improvement over text-only baseline; structured belief representation with multi-objective pretraining improves generalization <a href="../results/extraction-result-980.html#e980.0" class="evidence-link">[e980.0]</a> </li>
    <li>Q*BERT with QA-based KG construction reaches asymptotic performance faster than KG-A2C; structured symbolic memory (KG) improves sample efficiency <a href="../results/extraction-result-967.html#e967.0" class="evidence-link">[e967.0]</a> </li>
    <li>LLM-MCTS with structured belief construction (sampling LLM multiple times, mapping to canonical symbols) and MCTS planning achieves 91.4% success (Simple tasks) vs 0% for UCT without LLM priors; structured world model construction is essential <a href="../results/extraction-result-972.html#e972.0" class="evidence-link">[e972.0]</a> </li>
</ol>            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>A system that decomposes action simulation into consider-decide-capture-transfer phases will detect more indirect effects than single-phase simulation across diverse domains</li>
                <li>Multi-task training on related symbolic prediction tasks (e.g., KG prediction + action prediction) will improve performance on each individual task compared to single-task training</li>
                <li>Grammar-constrained generation will have fewer syntax errors than unconstrained generation for formal languages (PDDL, STL, code)</li>
                <li>Iterative refinement with validator feedback will improve plan quality more than single-shot generation across planning domains</li>
                <li>Modular policy chaining with graph-based intrinsic rewards will solve more long-horizon tasks than monolithic policies</li>
                <li>Set-of-sequences losses will outperform standard sequence losses for tasks with unordered outputs (sets of triples, sets of actions)</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>The optimal granularity of decomposition (how many sub-steps) for different types of tasks and whether it can be learned automatically</li>
                <li>Whether learned decomposition strategies (e.g., via meta-learning) can match or exceed hand-designed decompositions across diverse domains</li>
                <li>The extent to which decomposition benefits transfer across different domains (e.g., from text games to robotics to mathematical reasoning)</li>
                <li>Whether there exists a universal decomposition strategy that works well across all task types or if domain-specific decomposition is necessary</li>
                <li>The computational trade-off point where structured approaches become more efficient than unstructured approaches despite higher per-step cost</li>
                <li>Whether decomposition benefits scale predictably with task complexity or if there are phase transitions</li>
                <li>How to automatically determine when a task requires decomposition vs. when direct generation is sufficient</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>Finding tasks where unstructured generation consistently outperforms structured decomposition would challenge the generality of the theory</li>
                <li>Demonstrating that single-task learning performs as well as multi-task learning when controlling for model capacity would weaken the shared-representation claim</li>
                <li>Showing that grammar constraints reduce rather than improve accuracy on formal language generation would challenge the constraint benefit</li>
                <li>Finding that iterative refinement with feedback does not improve quality beyond initial generation would challenge the refinement benefit</li>
                <li>Demonstrating that fine-grained decomposition consistently outperforms coarse-grained decomposition regardless of task structure would challenge the alignment principle</li>
                <li>Showing that computational overhead of structured approaches never pays off in terms of accuracy would challenge practical applicability</li>
                <li>Finding that modular approaches do not improve over monolithic approaches on long-horizon tasks would challenge the modularity benefit</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>The theory doesn't specify how to automatically determine optimal decomposition strategies for new tasks or how to learn decomposition from data <a href="../results/extraction-result-842.html#e842.1" class="evidence-link">[e842.1]</a> <a href="../results/extraction-result-851.html#e851.0" class="evidence-link">[e851.0]</a> <a href="../results/extraction-result-973.html#e973.0" class="evidence-link">[e973.0]</a> <a href="../results/extraction-result-970.html#e970.0" class="evidence-link">[e970.0]</a> </li>
    <li>The computational overhead of structured approaches vs their accuracy benefits is not fully characterized across different scales and domains <a href="../results/extraction-result-852.html#e852.3" class="evidence-link">[e852.3]</a> <a href="../results/extraction-result-975.html#e975.0" class="evidence-link">[e975.0]</a> <a href="../results/extraction-result-977.html#e977.0" class="evidence-link">[e977.0]</a> <a href="../results/extraction-result-977.html#e977.1" class="evidence-link">[e977.1]</a> </li>
    <li>The theory doesn't explain why some structured approaches (e.g., GATA-GTP discrete updater) are more brittle than others (e.g., GATA continuous) <a href="../results/extraction-result-980.html#e980.1" class="evidence-link">[e980.1]</a> <a href="../results/extraction-result-980.html#e980.0" class="evidence-link">[e980.0]</a> </li>
    <li>The interaction between different types of structure (multi-task, step-by-step, modular) is not fully characterized <a href="../results/extraction-result-851.html#e851.0" class="evidence-link">[e851.0]</a> <a href="../results/extraction-result-842.html#e842.0" class="evidence-link">[e842.0]</a> <a href="../results/extraction-result-967.html#e967.1" class="evidence-link">[e967.1]</a> </li>
    <li>The theory doesn't fully explain when caching and reuse strategies are most beneficial for structured approaches <a href="../results/extraction-result-977.html#e977.1" class="evidence-link">[e977.1]</a> <a href="../results/extraction-result-977.html#e977.0" class="evidence-link">[e977.0]</a> </li>
    <li>The role of pretraining and self-supervised objectives in structured approaches is not fully integrated into the theory <a href="../results/extraction-result-980.html#e980.0" class="evidence-link">[e980.0]</a> <a href="../results/extraction-result-851.html#e851.0" class="evidence-link">[e851.0]</a> </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> closely-related-to-existing</p>
            <p><strong>Explanation:</strong> No explanation provided.</p>
            <p><strong>References:</strong> <ul>
    <li>Wei et al. (2022) Chain-of-Thought Prompting Elicits Reasoning in Large Language Models [CoT as step-by-step decomposition, but not formalized as general decomposition theory]</li>
    <li>Yao et al. (2023) Tree of Thoughts: Deliberate Problem Solving with Large Language Models [Structured search/deliberation but different focus and mixed results]</li>
    <li>Muennighoff et al. (2023) Scaling Data-Constrained Language Models [Multi-task learning benefits but not LLM-specific decomposition theory]</li>
    <li>Khot et al. (2023) Decomposed Prompting: A Modular Approach for Solving Complex Tasks [Explicit decomposition framework but narrower scope]</li>
    <li>Zhou et al. (2023) Least-to-Most Prompting Enables Complex Reasoning in Large Language Models [Sequential decomposition but specific to certain reasoning tasks]</li>
    <li>Press et al. (2023) Measuring and Narrowing the Compositionality Gap in Language Models [Compositionality and decomposition but focused on gap analysis]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Structured Decomposition Theory",
    "theory_description": "Breaking down complex reasoning and simulation tasks into structured sub-problems significantly improves LLM reliability and accuracy when the decomposition aligns with the task structure. Effective decomposition strategies include: (1) multi-task learning that exploits shared structure across related tasks, (2) step-by-step reasoning chains that make intermediate steps explicit (CoT, CBS), (3) set-of-sequences representations that handle unordered outputs with permutation-invariant losses, (4) modular policy chaining that breaks long-horizon tasks into sub-goals with intrinsic motivation, and (5) iterative refinement with structured feedback loops (syntax, semantics, execution validation). The benefits are particularly pronounced for tasks requiring: handling indirect effects, maintaining consistency across multiple predictions, scaling to long horizons, and avoiding error accumulation. However, decomposition must be matched to task structure—inappropriate decomposition can introduce overhead without benefits, and overly fine-grained decomposition can lose important holistic context.",
    "supporting_evidence": [
        {
            "text": "Worldformer with multi-task learning (joint KG and action prediction) and Set-of-Sequences loss achieves 39.15% graph EM vs 14.29% for single-task Seq2Seq; ablations show removing multi-task or SOS causes significant drops",
            "uuids": [
                "e851.0",
                "e851.3"
            ]
        },
        {
            "text": "BeSimulator's Chain of Behavior Simulation (4-phase: consider-decide-capture-transfer) substantially improves accuracy vs single-phase prompting, especially for detecting indirect state changes; ablation shows single-phase still beats CoT by ~13.07% but full CBS yields highest accuracy",
            "uuids": [
                "e842.0",
                "e842.1"
            ]
        },
        {
            "text": "MC!Q*BERT with modular policy chaining, graph-based intrinsic motivation, and structured exploration outperforms baselines on 8/9 games; ablation shows intrinsic motivation is crucial for clearing bottlenecks",
            "uuids": [
                "e967.1"
            ]
        },
        {
            "text": "Grammar-constrained SMC decoding into ELoT achieves ~91% semantic equivalence vs lower for unconstrained generation; structured representation improves translation accuracy by up to 2.4× vs lowered form",
            "uuids": [
                "e852.3",
                "e852.2",
                "e852.0"
            ]
        },
        {
            "text": "AutoTAMP with iterative syntax/semantic checking achieves ~83.5% success (HouseWorld2) vs lower for unconstrained translation; structured validation loop is critical",
            "uuids": [
                "e975.0"
            ]
        },
        {
            "text": "GPT-4 generalized planning with automated debugging (4 feedback types: Python exceptions, timeouts, syntax, semantics via VAL) achieves 0.90-1.00 success on multiple domains; 'No Debug' ablation dramatically lowers success, showing iterative refinement is critical",
            "uuids": [
                "e973.0"
            ]
        },
        {
            "text": "RAP with explicit textual state representation and MCTS decomposition achieves 51.6% on GSM8K vs 29.4% for unstructured CoT; ablations show state-transition confidence and self-evaluation rewards (uncertainty-aware decomposition) improve performance",
            "uuids": [
                "e970.0"
            ]
        },
        {
            "text": "LaBToM with compositional ELoT representation achieves r=0.76 with human judgments vs r=0.52 for GPT-4o baseline; grammar-constrained parsing into structured representation yields better semantic accuracy",
            "uuids": [
                "e852.0",
                "e852.2",
                "e852.3"
            ]
        },
        {
            "text": "SIPS with sequential plan extension and data-driven rejuvenation proposals achieves better accuracy and runtime than BIRL baselines; structured incremental planning with MH rejuvenation maintains hypothesis diversity",
            "uuids": [
                "e1006.0",
                "e1006.5"
            ]
        },
        {
            "text": "PWM/PWL with structured abductive inference (MCMC over proof/theory space with multiple proposal types) outperforms neural baselines on zero-shot QA; structured probabilistic reasoning with explicit proof decomposition enables better generalization",
            "uuids": [
                "e843.0"
            ]
        },
        {
            "text": "NIPE's modular pipeline (LLM translation → probabilistic scene generation → Bayesian inverse planning) achieves R=0.927 correlation with human judgments vs R=0.658 for GPT-4 direct; structured decomposition into translation, world model, and planning modules improves reliability",
            "uuids": [
                "e845.0"
            ]
        },
        {
            "text": "LLM+P with structured pipeline (NL→PDDL translation + classical planner + plan translation) achieves 90% success (BlocksWorld) vs 15-30% for LLM-alone; contextual examples crucial for reliable translation",
            "uuids": [
                "e974.0",
                "e1001.0"
            ]
        },
        {
            "text": "LLM-acquired PDDL with iterative correction (validator feedback + LLM repair) achieves ~95% planning success vs &lt;50% for LLM-modulo-planner; structured validation and correction loop is essential",
            "uuids": [
                "e971.0",
                "e971.2"
            ]
        },
        {
            "text": "SMC steering with structured Feynman-Kac formulation and efficient caching enables tractable constrained generation; proposal design (choosing M_t closer to posterior) substantially affects estimator quality",
            "uuids": [
                "e977.0",
                "e977.1",
                "e977.2"
            ]
        },
        {
            "text": "GATA with continuous belief-graph representation and self-supervised pretraining (OG+COC) achieves +24.2% relative improvement over text-only baseline; structured belief representation with multi-objective pretraining improves generalization",
            "uuids": [
                "e980.0"
            ]
        },
        {
            "text": "Q*BERT with QA-based KG construction reaches asymptotic performance faster than KG-A2C; structured symbolic memory (KG) improves sample efficiency",
            "uuids": [
                "e967.0"
            ]
        },
        {
            "text": "LLM-MCTS with structured belief construction (sampling LLM multiple times, mapping to canonical symbols) and MCTS planning achieves 91.4% success (Simple tasks) vs 0% for UCT without LLM priors; structured world model construction is essential",
            "uuids": [
                "e972.0"
            ]
        }
    ],
    "theory_statements": [
        "Structured decomposition of complex tasks into sub-problems improves LLM reliability and accuracy when decomposition aligns with task structure",
        "Multi-task learning with related tasks improves performance on individual tasks through shared representations and regularization effects",
        "Explicit reasoning chains (step-by-step decomposition) reduce errors, improve interpretability, and enable detection of indirect effects",
        "Grammar constraints and formal languages prevent syntax errors and improve semantic accuracy by restricting the output space",
        "Set-based representations with permutation-invariant losses handle unordered outputs better than sequence models by avoiding spurious ordering dependencies",
        "Modular policy chaining with intrinsic motivation enables solving long-horizon tasks by breaking them into manageable sub-goals and providing intermediate rewards",
        "Iterative refinement with structured feedback (syntax, semantics, execution validation) improves output quality by catching and correcting errors early",
        "Structured belief representations (graphs, symbolic states) improve sample efficiency and generalization in partially observable environments",
        "The granularity of decomposition should match task complexity—too coarse loses benefits, too fine loses context",
        "Computational overhead of structured approaches must be balanced against accuracy benefits through efficient implementations (caching, reuse)",
        "Proposal design in structured inference (choosing proposals closer to posterior) substantially affects computational efficiency and accuracy"
    ],
    "new_predictions_likely": [
        "A system that decomposes action simulation into consider-decide-capture-transfer phases will detect more indirect effects than single-phase simulation across diverse domains",
        "Multi-task training on related symbolic prediction tasks (e.g., KG prediction + action prediction) will improve performance on each individual task compared to single-task training",
        "Grammar-constrained generation will have fewer syntax errors than unconstrained generation for formal languages (PDDL, STL, code)",
        "Iterative refinement with validator feedback will improve plan quality more than single-shot generation across planning domains",
        "Modular policy chaining with graph-based intrinsic rewards will solve more long-horizon tasks than monolithic policies",
        "Set-of-sequences losses will outperform standard sequence losses for tasks with unordered outputs (sets of triples, sets of actions)"
    ],
    "new_predictions_unknown": [
        "The optimal granularity of decomposition (how many sub-steps) for different types of tasks and whether it can be learned automatically",
        "Whether learned decomposition strategies (e.g., via meta-learning) can match or exceed hand-designed decompositions across diverse domains",
        "The extent to which decomposition benefits transfer across different domains (e.g., from text games to robotics to mathematical reasoning)",
        "Whether there exists a universal decomposition strategy that works well across all task types or if domain-specific decomposition is necessary",
        "The computational trade-off point where structured approaches become more efficient than unstructured approaches despite higher per-step cost",
        "Whether decomposition benefits scale predictably with task complexity or if there are phase transitions",
        "How to automatically determine when a task requires decomposition vs. when direct generation is sufficient"
    ],
    "negative_experiments": [
        "Finding tasks where unstructured generation consistently outperforms structured decomposition would challenge the generality of the theory",
        "Demonstrating that single-task learning performs as well as multi-task learning when controlling for model capacity would weaken the shared-representation claim",
        "Showing that grammar constraints reduce rather than improve accuracy on formal language generation would challenge the constraint benefit",
        "Finding that iterative refinement with feedback does not improve quality beyond initial generation would challenge the refinement benefit",
        "Demonstrating that fine-grained decomposition consistently outperforms coarse-grained decomposition regardless of task structure would challenge the alignment principle",
        "Showing that computational overhead of structured approaches never pays off in terms of accuracy would challenge practical applicability",
        "Finding that modular approaches do not improve over monolithic approaches on long-horizon tasks would challenge the modularity benefit"
    ],
    "unaccounted_for": [
        {
            "text": "The theory doesn't specify how to automatically determine optimal decomposition strategies for new tasks or how to learn decomposition from data",
            "uuids": [
                "e842.1",
                "e851.0",
                "e973.0",
                "e970.0"
            ]
        },
        {
            "text": "The computational overhead of structured approaches vs their accuracy benefits is not fully characterized across different scales and domains",
            "uuids": [
                "e852.3",
                "e975.0",
                "e977.0",
                "e977.1"
            ]
        },
        {
            "text": "The theory doesn't explain why some structured approaches (e.g., GATA-GTP discrete updater) are more brittle than others (e.g., GATA continuous)",
            "uuids": [
                "e980.1",
                "e980.0"
            ]
        },
        {
            "text": "The interaction between different types of structure (multi-task, step-by-step, modular) is not fully characterized",
            "uuids": [
                "e851.0",
                "e842.0",
                "e967.1"
            ]
        },
        {
            "text": "The theory doesn't fully explain when caching and reuse strategies are most beneficial for structured approaches",
            "uuids": [
                "e977.1",
                "e977.0"
            ]
        },
        {
            "text": "The role of pretraining and self-supervised objectives in structured approaches is not fully integrated into the theory",
            "uuids": [
                "e980.0",
                "e851.0"
            ]
        }
    ],
    "conflicting_evidence": [
        {
            "text": "Some simple tasks may not benefit from decomposition and may be solved more efficiently with direct generation (e.g., GPT-3+ASP on simple bAbI tasks achieves near-perfect accuracy without complex decomposition)",
            "uuids": [
                "e1004.0"
            ]
        },
        {
            "text": "GATA-GTP discrete updater (structured command generation) is more brittle than GATA continuous updater, suggesting that some forms of structure can be counterproductive",
            "uuids": [
                "e980.1",
                "e980.0"
            ]
        },
        {
            "text": "Tree of Thoughts (structured deliberation) performs poorly on long-horizon planning tasks, timing out frequently, suggesting structure alone is insufficient",
            "uuids": [
                "e1001.3"
            ]
        },
        {
            "text": "Some unstructured baselines (e.g., UnifiedQA) perform well on certain QA subsets, suggesting decomposition is not always necessary",
            "uuids": [
                "e843.4"
            ]
        },
        {
            "text": "LLM-modulo-planner with structured feedback loops still underperforms classical planners, suggesting iterative refinement has limits",
            "uuids": [
                "e971.2"
            ]
        }
    ],
    "special_cases": [
        "For very simple tasks with short horizons, the overhead of decomposition may outweigh benefits and direct generation may be more efficient",
        "When tasks have strong sequential dependencies that cannot be parallelized, certain decomposition strategies (e.g., multi-task learning) may not be applicable",
        "For tasks requiring holistic reasoning or global optimization, excessive decomposition may lose important context and lead to suboptimal solutions",
        "Discrete/symbolic decomposition strategies may be more brittle than continuous/soft decomposition strategies due to error accumulation",
        "The benefits of decomposition may depend on the quality of the base model—stronger models may need less decomposition",
        "Decomposition strategies that work well for one domain (e.g., text games) may not transfer directly to other domains (e.g., mathematical reasoning) without adaptation",
        "When computational resources are severely limited, structured approaches may be impractical despite accuracy benefits",
        "For tasks with high inherent uncertainty, structured approaches may need to be combined with probabilistic reasoning to be effective"
    ],
    "existing_theory": {
        "likely_classification": "closely-related-to-existing",
        "references": [
            "Wei et al. (2022) Chain-of-Thought Prompting Elicits Reasoning in Large Language Models [CoT as step-by-step decomposition, but not formalized as general decomposition theory]",
            "Yao et al. (2023) Tree of Thoughts: Deliberate Problem Solving with Large Language Models [Structured search/deliberation but different focus and mixed results]",
            "Muennighoff et al. (2023) Scaling Data-Constrained Language Models [Multi-task learning benefits but not LLM-specific decomposition theory]",
            "Khot et al. (2023) Decomposed Prompting: A Modular Approach for Solving Complex Tasks [Explicit decomposition framework but narrower scope]",
            "Zhou et al. (2023) Least-to-Most Prompting Enables Complex Reasoning in Large Language Models [Sequential decomposition but specific to certain reasoning tasks]",
            "Press et al. (2023) Measuring and Narrowing the Compositionality Gap in Language Models [Compositionality and decomposition but focused on gap analysis]"
        ]
    },
    "theory_type_general_specific": "general",
    "reflected_from_theory_index": 2,
    "type": "general"
}</code></pre>
        </div>
    </div>
</body>
</html>