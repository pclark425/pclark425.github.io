<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Cost-Aware Adaptive Resource Allocation Theory - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-308</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-308</p>
                <p><strong>Name:</strong> Cost-Aware Adaptive Resource Allocation Theory</p>
                <p><strong>Type:</strong> specific</p>
                <p><strong>Theory Query:</strong> Build a theory of how adaptive experimental design works for AI agents operating in unknown environments.. Please focus on creating new theories that have not been proposed before in the literature.</p>
                <p><strong>Description:</strong> This theory proposes that AI agents operating in unknown environments adaptively allocate experimental resources by maintaining dynamic cost-benefit models that integrate multiple factors: (1) the expected information gain from experiments, (2) the resource costs of conducting experiments, (3) the remaining resource budget and exhaustion horizon, (4) the uncertainty in cost estimates themselves, and (5) the opportunity cost of resource expenditure. The theory predicts that optimal agents implement a multi-tiered allocation strategy where resources are partitioned into exploration budgets, exploitation budgets, and reserve budgets, with dynamic reallocation based on learning progress. Critically, the theory posits that agents exhibit 'cost-adaptive' behavior where experimental selection criteria shift from information-maximizing to cost-efficiency-maximizing as resources deplete. The theory further predicts that agents maintain probabilistic models of resource exhaustion horizons and modulate their risk tolerance, planning depth, and exploration-exploitation balance as functions of both absolute resource levels and the rate of resource consumption. Agents are predicted to exhibit discontinuous strategy transitions at critical resource thresholds and to allocate resources to 'meta-experiments' that reduce future costs or improve cost estimation accuracy.</p>
                <p><strong>Knowledge Cutoff Year:</strong> -1</p>
                <p><strong>Knowledge Cutoff Month:</strong> -1</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <ol>
                <li>Agents maintain a dynamic cost-benefit model for each potential experiment: V(e,t) = I(e,t) / C(e,t)^α, where I(e,t) is the expected information gain, C(e,t) is the expected cost, α ≥ 1 is a cost-sensitivity parameter that increases as resources deplete, and t represents the current time/state.</li>
                <li>The cost-sensitivity parameter α evolves as a function of resource depletion: α(t) = α_min + (α_max - α_min) * (1 - B_remaining(t) / B_total)^β, where B_remaining is the remaining budget, B_total is the initial budget, and β > 0 controls the rate of sensitivity increase.</li>
                <li>Agents partition their resource budget into three dynamic pools: exploration budget B_explore(t), exploitation budget B_exploit(t), and reserve budget B_reserve(t), with B_explore + B_exploit + B_reserve = B_remaining, and the allocation fractions change as learning progresses.</li>
                <li>The exploration budget fraction decreases over time according to: f_explore(t) = max(f_min, f_initial * exp(-λ * progress(t))), where progress(t) measures cumulative information gain or model confidence, and λ controls the decay rate.</li>
                <li>Agents maintain a probabilistic model of resource exhaustion: P(T_exhaust | current_state), where T_exhaust is the time until resource depletion, conditioned on current resource levels, consumption rates, and planned experiments.</li>
                <li>Risk tolerance τ in experimental selection decreases as the exhaustion horizon shortens: τ(t) = τ_max * (E[T_exhaust(t)] / T_total)^γ, where γ > 0 controls the rate of risk aversion increase and E[T_exhaust] is the expected time to exhaustion.</li>
                <li>Agents exhibit discrete strategy transitions at critical resource thresholds θ_i ∈ {0.75, 0.5, 0.25, 0.1} * B_total, switching from strategy S_i to S_{i+1}, where strategies differ in their exploration-exploitation balance, planning depth, and cost sensitivity.</li>
                <li>The planning horizon H for experimental sequences is bounded by the exhaustion horizon: H(t) = min(H_max, κ * E[T_exhaust(t)]), where κ is a proportionality constant and H_max is the maximum planning depth.</li>
                <li>Agents allocate a fraction of resources to 'meta-experiments' that improve cost estimation or reduce future costs: f_meta(t) = α_meta * (B_remaining(t) / B_total) * uncertainty_cost(t), where uncertainty_cost measures the uncertainty in cost estimates.</li>
                <li>The value of information for an experiment is discounted by its opportunity cost: V_adjusted(e,t) = V(e,t) - λ_opp * C(e,t) * E[value_future_experiments | B_remaining - C(e,t)], where λ_opp weights the opportunity cost.</li>
                <li>In multi-resource scenarios, agents plan around the most constraining resource: R_constraining(t) = argmin_r (B_r(t) / rate_r(t)), where B_r is the budget for resource r and rate_r is its consumption rate.</li>
                <li>Agents implement cost-adaptive acquisition functions that interpolate between pure information gain and cost-efficiency: a(e,t) = (1 - w(t)) * I(e,t) + w(t) * (I(e,t) / C(e,t)), where w(t) increases from 0 to 1 as resources deplete.</li>
            </ol>
            <h3>Supporting Evidence</h3>
<ol>
    <li>Finite-horizon reinforcement learning demonstrates that optimal policies depend critically on the remaining time or resource horizon, with different strategies optimal at different horizons. </li>
    <li>Anytime algorithms show that computational resource allocation depends on the remaining time budget, with different algorithm configurations optimal for different time horizons. </li>
    <li>Human decision-making research demonstrates deadline effects where strategy and risk tolerance change as deadlines approach, suggesting biological precedent for horizon-aware resource allocation. </li>
    <li>Bayesian optimization and active learning literature shows that acquisition functions can be modified to account for evaluation costs, leading to cost-aware experimental design. </li>
    <li>Multi-armed bandit algorithms with costs demonstrate that optimal exploration-exploitation strategies must account for the cost of pulling arms, not just their expected rewards. </li>
    <li>Resource-constrained planning in robotics shows that agents must balance information gathering with resource preservation to ensure mission completion. </li>
    <li>Economic theory of resource allocation under scarcity provides foundational principles for optimal allocation when resources are limited and have opportunity costs. </li>
</ol>            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>Agents given identical total budgets but different cost structures (e.g., uniform costs vs. highly variable costs) will exhibit different experimental strategies, with variable-cost environments leading to more conservative early exploration to preserve resources for potentially expensive but informative experiments.</li>
                <li>In environments where cost estimation uncertainty is high, agents will initially conduct cheap experiments to calibrate their cost models before committing to expensive experiments, even if the cheap experiments provide less information.</li>
                <li>Agents that maintain explicit reserve budgets will outperform agents that don't in environments with occasional high-cost but high-value experimental opportunities, as reserves enable opportunistic exploitation.</li>
                <li>When given the option to purchase 'cost information' (e.g., learning the cost of an experiment before conducting it), agents will preferentially purchase this information when resource budgets are low and cost uncertainty is high.</li>
                <li>Agents operating under tight resource constraints will exhibit more 'bursty' experimental patterns, conducting clusters of cheap experiments interspersed with occasional expensive experiments, rather than uniform sampling.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>Whether agents should use optimistic or pessimistic cost estimates when planning under uncertainty is unclear - optimistic estimates encourage exploration but risk premature exhaustion, while pessimistic estimates ensure completion but may be overly conservative and miss high-value opportunities.</li>
                <li>The optimal number and placement of resource threshold transitions (θ_i) may depend on environment complexity in non-obvious ways - it's unknown whether fixed thresholds or adaptive thresholds based on learning progress perform better.</li>
                <li>In environments where experiments can have cascading effects on future costs (e.g., learning that reduces future experimental costs), whether agents should invest heavily in cost-reduction experiments early or late in the budget cycle is unclear and may depend on the discount rate and cost-reduction magnitude.</li>
                <li>Whether maintaining separate exploration, exploitation, and reserve budgets provides advantages over unified budget management is unknown, particularly in highly dynamic environments where the optimal allocation changes rapidly.</li>
                <li>The interaction between cost-aware allocation and multi-objective optimization (e.g., simultaneously optimizing for information gain, cost efficiency, and robustness) may produce emergent behaviors that are difficult to predict, particularly regarding which objective dominates at different resource levels.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>If agents that explicitly model costs and exhaustion horizons perform no better than agents using myopic, cost-agnostic strategies in resource-constrained environments, this would challenge the theory's core premise that cost-awareness provides adaptive advantages.</li>
                <li>If maintaining separate budget pools (exploration, exploitation, reserve) leads to worse performance than unified budget management, this would contradict the theory's prediction about the value of budget partitioning.</li>
                <li>If cost-sensitivity parameter α does not need to increase as resources deplete (i.e., constant α performs as well or better), this would challenge the theory's prediction about adaptive cost-sensitivity modulation.</li>
                <li>If agents do not exhibit discrete strategy transitions at resource thresholds but instead show continuous strategy evolution, this would contradict the theory's prediction of discontinuous threshold effects.</li>
                <li>If allocating resources to meta-experiments (cost estimation, cost reduction) does not improve overall performance compared to allocating all resources to direct information-gathering experiments, this would challenge the theory's prediction about the value of meta-experimentation.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>The theory does not fully specify how agents should handle multiple simultaneous resource types with different exhaustion horizons, criticality levels, and substitutability relationships (e.g., time vs. computation vs. energy). </li>
    <li>The interaction between cost-aware allocation and unexpected resource windfalls or cost reductions (e.g., discovering more efficient experiments mid-stream) is not fully addressed, particularly regarding how quickly agents should update their allocation strategies. </li>
    <li>The theory does not specify how agents should handle correlated costs (e.g., experiments that share setup costs or can be batched) versus independent costs, which could significantly affect optimal allocation strategies. </li>
    <li>The optimal balance between exploration of the experimental space and exploration of the cost structure itself is not fully characterized, particularly in environments where cost functions are non-stationary. </li>
    <li>The theory does not address how agents should handle irreversible resource commitments versus reversible ones, which may require different allocation strategies. </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> new</p>
            <p><strong>Explanation:</strong> No explanation provided.</p>
            <p><strong>References:</strong> <ul>
    <li>Sutton and Barto (2018) Reinforcement Learning: An Introduction [Discusses finite-horizon MDPs and resource-constrained RL but not comprehensive cost-aware adaptive allocation theory for experimental design]</li>
    <li>Zilberstein (1996) Using Anytime Algorithms in Intelligent Systems [Discusses time-dependent algorithm selection but not multi-faceted cost-aware resource allocation with dynamic budget partitioning]</li>
    <li>Snoek et al. (2012) Practical Bayesian Optimization of Machine Learning Algorithms [Discusses cost-aware acquisition functions but not the full adaptive allocation framework with horizon planning and budget partitioning]</li>
    <li>Guha and Munagala (2007) Approximation Algorithms for Budgeted Learning Problems [Addresses budgeted learning but focuses on approximation algorithms rather than adaptive allocation strategies]</li>
    <li>Hollinger and Sukhatme (2014) Sampling-based Robotic Information Gathering Algorithms [Discusses resource-constrained information gathering but not the comprehensive theory of adaptive cost-aware allocation with dynamic strategy transitions]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Cost-Aware Adaptive Resource Allocation Theory",
    "theory_description": "This theory proposes that AI agents operating in unknown environments adaptively allocate experimental resources by maintaining dynamic cost-benefit models that integrate multiple factors: (1) the expected information gain from experiments, (2) the resource costs of conducting experiments, (3) the remaining resource budget and exhaustion horizon, (4) the uncertainty in cost estimates themselves, and (5) the opportunity cost of resource expenditure. The theory predicts that optimal agents implement a multi-tiered allocation strategy where resources are partitioned into exploration budgets, exploitation budgets, and reserve budgets, with dynamic reallocation based on learning progress. Critically, the theory posits that agents exhibit 'cost-adaptive' behavior where experimental selection criteria shift from information-maximizing to cost-efficiency-maximizing as resources deplete. The theory further predicts that agents maintain probabilistic models of resource exhaustion horizons and modulate their risk tolerance, planning depth, and exploration-exploitation balance as functions of both absolute resource levels and the rate of resource consumption. Agents are predicted to exhibit discontinuous strategy transitions at critical resource thresholds and to allocate resources to 'meta-experiments' that reduce future costs or improve cost estimation accuracy.",
    "supporting_evidence": [
        {
            "text": "Finite-horizon reinforcement learning demonstrates that optimal policies depend critically on the remaining time or resource horizon, with different strategies optimal at different horizons.",
            "citations": [
                "Sutton and Barto (2018) Reinforcement Learning: An Introduction, MIT Press",
                "Bertsekas (2012) Dynamic Programming and Optimal Control, Athena Scientific"
            ]
        },
        {
            "text": "Anytime algorithms show that computational resource allocation depends on the remaining time budget, with different algorithm configurations optimal for different time horizons.",
            "citations": [
                "Zilberstein (1996) Using Anytime Algorithms in Intelligent Systems, AI Magazine",
                "Hansen and Zilberstein (2001) Monitoring and Control of Anytime Algorithms: A Dynamic Programming Approach, Artificial Intelligence"
            ]
        },
        {
            "text": "Human decision-making research demonstrates deadline effects where strategy and risk tolerance change as deadlines approach, suggesting biological precedent for horizon-aware resource allocation.",
            "citations": [
                "Ariely and Wertenbroch (2002) Procrastination, Deadlines, and Performance: Self-Control by Precommitment, Psychological Science"
            ]
        },
        {
            "text": "Bayesian optimization and active learning literature shows that acquisition functions can be modified to account for evaluation costs, leading to cost-aware experimental design.",
            "citations": [
                "Snoek et al. (2012) Practical Bayesian Optimization of Machine Learning Algorithms, NIPS",
                "Settles (2009) Active Learning Literature Survey, Computer Sciences Technical Report"
            ]
        },
        {
            "text": "Multi-armed bandit algorithms with costs demonstrate that optimal exploration-exploitation strategies must account for the cost of pulling arms, not just their expected rewards.",
            "citations": [
                "Tran-Thanh et al. (2012) Efficient Thompson Sampling for Online Matrix-Factorization Recommendation, NIPS",
                "Guha and Munagala (2007) Approximation Algorithms for Budgeted Learning Problems, STOC"
            ]
        },
        {
            "text": "Resource-constrained planning in robotics shows that agents must balance information gathering with resource preservation to ensure mission completion.",
            "citations": [
                "Hollinger and Sukhatme (2014) Sampling-based Robotic Information Gathering Algorithms, International Journal of Robotics Research"
            ]
        },
        {
            "text": "Economic theory of resource allocation under scarcity provides foundational principles for optimal allocation when resources are limited and have opportunity costs.",
            "citations": [
                "Mas-Colell et al. (1995) Microeconomic Theory, Oxford University Press"
            ]
        }
    ],
    "theory_statements": [
        "Agents maintain a dynamic cost-benefit model for each potential experiment: V(e,t) = I(e,t) / C(e,t)^α, where I(e,t) is the expected information gain, C(e,t) is the expected cost, α ≥ 1 is a cost-sensitivity parameter that increases as resources deplete, and t represents the current time/state.",
        "The cost-sensitivity parameter α evolves as a function of resource depletion: α(t) = α_min + (α_max - α_min) * (1 - B_remaining(t) / B_total)^β, where B_remaining is the remaining budget, B_total is the initial budget, and β &gt; 0 controls the rate of sensitivity increase.",
        "Agents partition their resource budget into three dynamic pools: exploration budget B_explore(t), exploitation budget B_exploit(t), and reserve budget B_reserve(t), with B_explore + B_exploit + B_reserve = B_remaining, and the allocation fractions change as learning progresses.",
        "The exploration budget fraction decreases over time according to: f_explore(t) = max(f_min, f_initial * exp(-λ * progress(t))), where progress(t) measures cumulative information gain or model confidence, and λ controls the decay rate.",
        "Agents maintain a probabilistic model of resource exhaustion: P(T_exhaust | current_state), where T_exhaust is the time until resource depletion, conditioned on current resource levels, consumption rates, and planned experiments.",
        "Risk tolerance τ in experimental selection decreases as the exhaustion horizon shortens: τ(t) = τ_max * (E[T_exhaust(t)] / T_total)^γ, where γ &gt; 0 controls the rate of risk aversion increase and E[T_exhaust] is the expected time to exhaustion.",
        "Agents exhibit discrete strategy transitions at critical resource thresholds θ_i ∈ {0.75, 0.5, 0.25, 0.1} * B_total, switching from strategy S_i to S_{i+1}, where strategies differ in their exploration-exploitation balance, planning depth, and cost sensitivity.",
        "The planning horizon H for experimental sequences is bounded by the exhaustion horizon: H(t) = min(H_max, κ * E[T_exhaust(t)]), where κ is a proportionality constant and H_max is the maximum planning depth.",
        "Agents allocate a fraction of resources to 'meta-experiments' that improve cost estimation or reduce future costs: f_meta(t) = α_meta * (B_remaining(t) / B_total) * uncertainty_cost(t), where uncertainty_cost measures the uncertainty in cost estimates.",
        "The value of information for an experiment is discounted by its opportunity cost: V_adjusted(e,t) = V(e,t) - λ_opp * C(e,t) * E[value_future_experiments | B_remaining - C(e,t)], where λ_opp weights the opportunity cost.",
        "In multi-resource scenarios, agents plan around the most constraining resource: R_constraining(t) = argmin_r (B_r(t) / rate_r(t)), where B_r is the budget for resource r and rate_r is its consumption rate.",
        "Agents implement cost-adaptive acquisition functions that interpolate between pure information gain and cost-efficiency: a(e,t) = (1 - w(t)) * I(e,t) + w(t) * (I(e,t) / C(e,t)), where w(t) increases from 0 to 1 as resources deplete."
    ],
    "new_predictions_likely": [
        "Agents given identical total budgets but different cost structures (e.g., uniform costs vs. highly variable costs) will exhibit different experimental strategies, with variable-cost environments leading to more conservative early exploration to preserve resources for potentially expensive but informative experiments.",
        "In environments where cost estimation uncertainty is high, agents will initially conduct cheap experiments to calibrate their cost models before committing to expensive experiments, even if the cheap experiments provide less information.",
        "Agents that maintain explicit reserve budgets will outperform agents that don't in environments with occasional high-cost but high-value experimental opportunities, as reserves enable opportunistic exploitation.",
        "When given the option to purchase 'cost information' (e.g., learning the cost of an experiment before conducting it), agents will preferentially purchase this information when resource budgets are low and cost uncertainty is high.",
        "Agents operating under tight resource constraints will exhibit more 'bursty' experimental patterns, conducting clusters of cheap experiments interspersed with occasional expensive experiments, rather than uniform sampling."
    ],
    "new_predictions_unknown": [
        "Whether agents should use optimistic or pessimistic cost estimates when planning under uncertainty is unclear - optimistic estimates encourage exploration but risk premature exhaustion, while pessimistic estimates ensure completion but may be overly conservative and miss high-value opportunities.",
        "The optimal number and placement of resource threshold transitions (θ_i) may depend on environment complexity in non-obvious ways - it's unknown whether fixed thresholds or adaptive thresholds based on learning progress perform better.",
        "In environments where experiments can have cascading effects on future costs (e.g., learning that reduces future experimental costs), whether agents should invest heavily in cost-reduction experiments early or late in the budget cycle is unclear and may depend on the discount rate and cost-reduction magnitude.",
        "Whether maintaining separate exploration, exploitation, and reserve budgets provides advantages over unified budget management is unknown, particularly in highly dynamic environments where the optimal allocation changes rapidly.",
        "The interaction between cost-aware allocation and multi-objective optimization (e.g., simultaneously optimizing for information gain, cost efficiency, and robustness) may produce emergent behaviors that are difficult to predict, particularly regarding which objective dominates at different resource levels."
    ],
    "negative_experiments": [
        "If agents that explicitly model costs and exhaustion horizons perform no better than agents using myopic, cost-agnostic strategies in resource-constrained environments, this would challenge the theory's core premise that cost-awareness provides adaptive advantages.",
        "If maintaining separate budget pools (exploration, exploitation, reserve) leads to worse performance than unified budget management, this would contradict the theory's prediction about the value of budget partitioning.",
        "If cost-sensitivity parameter α does not need to increase as resources deplete (i.e., constant α performs as well or better), this would challenge the theory's prediction about adaptive cost-sensitivity modulation.",
        "If agents do not exhibit discrete strategy transitions at resource thresholds but instead show continuous strategy evolution, this would contradict the theory's prediction of discontinuous threshold effects.",
        "If allocating resources to meta-experiments (cost estimation, cost reduction) does not improve overall performance compared to allocating all resources to direct information-gathering experiments, this would challenge the theory's prediction about the value of meta-experimentation."
    ],
    "unaccounted_for": [
        {
            "text": "The theory does not fully specify how agents should handle multiple simultaneous resource types with different exhaustion horizons, criticality levels, and substitutability relationships (e.g., time vs. computation vs. energy).",
            "citations": []
        },
        {
            "text": "The interaction between cost-aware allocation and unexpected resource windfalls or cost reductions (e.g., discovering more efficient experiments mid-stream) is not fully addressed, particularly regarding how quickly agents should update their allocation strategies.",
            "citations": []
        },
        {
            "text": "The theory does not specify how agents should handle correlated costs (e.g., experiments that share setup costs or can be batched) versus independent costs, which could significantly affect optimal allocation strategies.",
            "citations": []
        },
        {
            "text": "The optimal balance between exploration of the experimental space and exploration of the cost structure itself is not fully characterized, particularly in environments where cost functions are non-stationary.",
            "citations": []
        },
        {
            "text": "The theory does not address how agents should handle irreversible resource commitments versus reversible ones, which may require different allocation strategies.",
            "citations": []
        }
    ],
    "conflicting_evidence": [],
    "special_cases": [
        "When resources are unlimited (B_remaining → ∞), the theory predicts that α → α_min, planning horizon reaches maximum H_max, risk tolerance reaches maximum τ_max, and the agent behaves as a pure information-maximizer ignoring costs.",
        "When resources are nearly exhausted (B_remaining → 0), the theory predicts that α → α_max, planning horizon H → 1 (myopic), risk tolerance τ → 0, and the agent selects only the cheapest experiments with guaranteed minimal information gain.",
        "For resources that regenerate over time (e.g., renewable energy budgets), the exhaustion horizon becomes periodic and the theory predicts cyclical strategy patterns synchronized with regeneration cycles.",
        "In environments where all experiments have identical costs, the theory reduces to standard information-maximizing experimental design, with cost-awareness providing no additional advantage.",
        "When cost uncertainty is zero (perfect cost knowledge), the meta-experiment allocation fraction f_meta → 0, and agents allocate all resources to direct information-gathering experiments.",
        "In multi-resource scenarios where one resource is vastly more constraining than others, the theory predicts that agents effectively ignore non-constraining resources and optimize solely for the constraining resource.",
        "When the cost-benefit ratio is constant across all experiments (I(e)/C(e) = constant), the theory predicts that agents revert to random or uniform sampling strategies, as cost-awareness provides no discriminative power."
    ],
    "existing_theory": {
        "likely_classification": "new",
        "references": [
            "Sutton and Barto (2018) Reinforcement Learning: An Introduction [Discusses finite-horizon MDPs and resource-constrained RL but not comprehensive cost-aware adaptive allocation theory for experimental design]",
            "Zilberstein (1996) Using Anytime Algorithms in Intelligent Systems [Discusses time-dependent algorithm selection but not multi-faceted cost-aware resource allocation with dynamic budget partitioning]",
            "Snoek et al. (2012) Practical Bayesian Optimization of Machine Learning Algorithms [Discusses cost-aware acquisition functions but not the full adaptive allocation framework with horizon planning and budget partitioning]",
            "Guha and Munagala (2007) Approximation Algorithms for Budgeted Learning Problems [Addresses budgeted learning but focuses on approximation algorithms rather than adaptive allocation strategies]",
            "Hollinger and Sukhatme (2014) Sampling-based Robotic Information Gathering Algorithms [Discusses resource-constrained information gathering but not the comprehensive theory of adaptive cost-aware allocation with dynamic strategy transitions]"
        ]
    },
    "theory_type_general_specific": "specific",
    "reflected_from_theory_index": 2,
    "theory_query": "Build a theory of how adaptive experimental design works for AI agents operating in unknown environments.. Please focus on creating new theories that have not been proposed before in the literature.",
    "generation_mode": "llm_baseline_no_evidence",
    "original_theory_id": "theory-136",
    "original_theory_name": "Cost-Aware Adaptive Resource Allocation Theory",
    "model_str": "claude-sonnet-4-5-20250929"
}</code></pre>
        </div>
    </div>
</body>
</html>