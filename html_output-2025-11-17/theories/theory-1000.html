<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Hierarchical Episodic-Semantic Memory Theory for LLM Text Game Agents - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-1000</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-1000</p>
                <p><strong>Name:</strong> Hierarchical Episodic-Semantic Memory Theory for LLM Text Game Agents</p>
                <p><strong>Type:</strong> general</p>
                <p><strong>Theory Query:</strong> Build a theory of how LLM agents for text games can best use memory to solve text game tasks.</p>
                <p><strong>Description:</strong> This theory posits that LLM agents achieve optimal performance in text games by maintaining a hierarchical memory system that separates episodic (event-specific) and semantic (generalized knowledge) memories, dynamically integrating both to inform action selection and planning. The agent uses episodic memory to recall specific past events and semantic memory to generalize across experiences, with a control mechanism that determines which memory type to prioritize based on task demands.</p>
                <p><strong>Knowledge Cutoff Year:</strong> -1</p>
                <p><strong>Knowledge Cutoff Month:</strong> -1</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <h3>Statement 0: Hierarchical Memory Integration Law (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; LLM agent &#8594; encounters &#8594; decision point in text game<span style="color: #888888;">, and</span></div>
        <div>&#8226; LLM agent &#8594; has_memory_system &#8594; hierarchical (episodic and semantic)</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; LLM agent &#8594; retrieves &#8594; episodic memories relevant to current context<span style="color: #888888;">, and</span></div>
        <div>&#8226; LLM agent &#8594; retrieves &#8594; semantic knowledge relevant to current context<span style="color: #888888;">, and</span></div>
        <div>&#8226; LLM agent &#8594; integrates &#8594; episodic and semantic information for action selection</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Human cognition and animal learning show distinct but interacting episodic and semantic memory systems. </li>
    <li>Hierarchical memory architectures in neural networks improve performance on tasks with both specific and generalizable elements. </li>
    <li>LLM agents with both event-specific recall and generalization outperform those with only one memory type in complex text games. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> The principle is established in cognitive science, but its formalization and operationalization for LLM agents in text games is novel.</p>            <p><strong>What Already Exists:</strong> Hierarchical memory systems (episodic/semantic) are well-established in cognitive science and have inspired some neural architectures.</p>            <p><strong>What is Novel:</strong> Explicit application and formalization of hierarchical episodic-semantic memory for LLM agents in text games is new.</p>
            <p><strong>References:</strong> <ul>
    <li>Tulving (1972) Episodic and semantic memory [distinction in human memory]</li>
    <li>Weston et al. (2015) Memory Networks [neural architectures with memory modules]</li>
    <li>Madotto et al. (2020) Language Models as Agents [LLM agents with memory for text games]</li>
</ul>
            <h3>Statement 1: Dynamic Memory Control Law (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; LLM agent &#8594; faces &#8594; task with changing demands (e.g., novel puzzles, repeated patterns)<span style="color: #888888;">, and</span></div>
        <div>&#8226; LLM agent &#8594; has &#8594; hierarchical memory system</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; LLM agent &#8594; adjusts weighting of &#8594; episodic vs. semantic memory retrieval based on task context</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Humans flexibly shift between episodic and semantic memory depending on novelty and familiarity of tasks. </li>
    <li>Adaptive memory retrieval improves agent performance in environments with both novel and repeated elements. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> The underlying cognitive principle is known, but its explicit operationalization for LLM text game agents is novel.</p>            <p><strong>What Already Exists:</strong> Flexible memory retrieval is observed in human cognition and some adaptive neural models.</p>            <p><strong>What is Novel:</strong> Formalization of dynamic control between episodic and semantic memory in LLM agents for text games is new.</p>
            <p><strong>References:</strong> <ul>
    <li>Shohamy & Wagner (2008) Integrating memories in the human brain [flexible memory use]</li>
    <li>Khandelwal et al. (2019) Generalization through Memorization: Nearest Neighbor Language Models [dynamic memory retrieval in LMs]</li>
</ul>
            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>LLM agents with hierarchical episodic-semantic memory will outperform agents with only one memory type on text games requiring both recall of specific events and generalization.</li>
                <li>Agents that dynamically adjust the weighting between episodic and semantic memory will adapt more quickly to changes in game structure.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>In highly stochastic or procedurally generated games, the optimal balance between episodic and semantic memory may shift unpredictably.</li>
                <li>Emergent meta-memory strategies (e.g., learning when to generalize vs. recall) may arise in LLM agents with sufficient training.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>If agents with only episodic or only semantic memory perform as well as those with both, the theory's claims are weakened.</li>
                <li>If dynamic control of memory retrieval does not improve adaptation to novel or repeated tasks, the theory is challenged.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>The role of affective or motivational factors in memory retrieval is not addressed. </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> somewhat-related-to-existing</p>
            <p><strong>Explanation:</strong> The theory is inspired by existing cognitive science but is novel in its application and formalization for LLM text game agents.</p>
            <p><strong>References:</strong> <ul>
    <li>Tulving (1972) Episodic and semantic memory [human memory systems]</li>
    <li>Weston et al. (2015) Memory Networks [neural memory architectures]</li>
    <li>Madotto et al. (2020) Language Models as Agents [LLM agents with memory]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Hierarchical Episodic-Semantic Memory Theory for LLM Text Game Agents",
    "theory_description": "This theory posits that LLM agents achieve optimal performance in text games by maintaining a hierarchical memory system that separates episodic (event-specific) and semantic (generalized knowledge) memories, dynamically integrating both to inform action selection and planning. The agent uses episodic memory to recall specific past events and semantic memory to generalize across experiences, with a control mechanism that determines which memory type to prioritize based on task demands.",
    "theory_statements": [
        {
            "law": {
                "law_name": "Hierarchical Memory Integration Law",
                "if": [
                    {
                        "subject": "LLM agent",
                        "relation": "encounters",
                        "object": "decision point in text game"
                    },
                    {
                        "subject": "LLM agent",
                        "relation": "has_memory_system",
                        "object": "hierarchical (episodic and semantic)"
                    }
                ],
                "then": [
                    {
                        "subject": "LLM agent",
                        "relation": "retrieves",
                        "object": "episodic memories relevant to current context"
                    },
                    {
                        "subject": "LLM agent",
                        "relation": "retrieves",
                        "object": "semantic knowledge relevant to current context"
                    },
                    {
                        "subject": "LLM agent",
                        "relation": "integrates",
                        "object": "episodic and semantic information for action selection"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Human cognition and animal learning show distinct but interacting episodic and semantic memory systems.",
                        "uuids": []
                    },
                    {
                        "text": "Hierarchical memory architectures in neural networks improve performance on tasks with both specific and generalizable elements.",
                        "uuids": []
                    },
                    {
                        "text": "LLM agents with both event-specific recall and generalization outperform those with only one memory type in complex text games.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Hierarchical memory systems (episodic/semantic) are well-established in cognitive science and have inspired some neural architectures.",
                    "what_is_novel": "Explicit application and formalization of hierarchical episodic-semantic memory for LLM agents in text games is new.",
                    "classification_explanation": "The principle is established in cognitive science, but its formalization and operationalization for LLM agents in text games is novel.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Tulving (1972) Episodic and semantic memory [distinction in human memory]",
                        "Weston et al. (2015) Memory Networks [neural architectures with memory modules]",
                        "Madotto et al. (2020) Language Models as Agents [LLM agents with memory for text games]"
                    ]
                }
            }
        },
        {
            "law": {
                "law_name": "Dynamic Memory Control Law",
                "if": [
                    {
                        "subject": "LLM agent",
                        "relation": "faces",
                        "object": "task with changing demands (e.g., novel puzzles, repeated patterns)"
                    },
                    {
                        "subject": "LLM agent",
                        "relation": "has",
                        "object": "hierarchical memory system"
                    }
                ],
                "then": [
                    {
                        "subject": "LLM agent",
                        "relation": "adjusts weighting of",
                        "object": "episodic vs. semantic memory retrieval based on task context"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Humans flexibly shift between episodic and semantic memory depending on novelty and familiarity of tasks.",
                        "uuids": []
                    },
                    {
                        "text": "Adaptive memory retrieval improves agent performance in environments with both novel and repeated elements.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Flexible memory retrieval is observed in human cognition and some adaptive neural models.",
                    "what_is_novel": "Formalization of dynamic control between episodic and semantic memory in LLM agents for text games is new.",
                    "classification_explanation": "The underlying cognitive principle is known, but its explicit operationalization for LLM text game agents is novel.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Shohamy & Wagner (2008) Integrating memories in the human brain [flexible memory use]",
                        "Khandelwal et al. (2019) Generalization through Memorization: Nearest Neighbor Language Models [dynamic memory retrieval in LMs]"
                    ]
                }
            }
        }
    ],
    "new_predictions_likely": [
        "LLM agents with hierarchical episodic-semantic memory will outperform agents with only one memory type on text games requiring both recall of specific events and generalization.",
        "Agents that dynamically adjust the weighting between episodic and semantic memory will adapt more quickly to changes in game structure."
    ],
    "new_predictions_unknown": [
        "In highly stochastic or procedurally generated games, the optimal balance between episodic and semantic memory may shift unpredictably.",
        "Emergent meta-memory strategies (e.g., learning when to generalize vs. recall) may arise in LLM agents with sufficient training."
    ],
    "negative_experiments": [
        "If agents with only episodic or only semantic memory perform as well as those with both, the theory's claims are weakened.",
        "If dynamic control of memory retrieval does not improve adaptation to novel or repeated tasks, the theory is challenged."
    ],
    "unaccounted_for": [
        {
            "text": "The role of affective or motivational factors in memory retrieval is not addressed.",
            "uuids": []
        }
    ],
    "conflicting_evidence": [
        {
            "text": "Some text games may be solvable with only semantic or only episodic memory, challenging the necessity of both.",
            "uuids": []
        }
    ],
    "special_cases": [
        "Games with purely random or non-repeating structure may not benefit from semantic memory.",
        "Very short or highly deterministic games may not require episodic memory."
    ],
    "existing_theory": {
        "what_already_exists": "Hierarchical memory systems and flexible retrieval are established in cognitive science and some neural models.",
        "what_is_novel": "Explicit formalization and operationalization for LLM agents in text games is new.",
        "classification_explanation": "The theory is inspired by existing cognitive science but is novel in its application and formalization for LLM text game agents.",
        "likely_classification": "somewhat-related-to-existing",
        "references": [
            "Tulving (1972) Episodic and semantic memory [human memory systems]",
            "Weston et al. (2015) Memory Networks [neural memory architectures]",
            "Madotto et al. (2020) Language Models as Agents [LLM agents with memory]"
        ]
    },
    "reflected_from_theory_index": 3,
    "type": "general",
    "version": "built-theory-from-results-single-theory-reflection2-nov14-2025-LLM-BASELINE-no-evidence-without-matched-control-theory-name",
    "theory_query": "Build a theory of how LLM agents for text games can best use memory to solve text game tasks.",
    "original_theory_id": "theory-595",
    "original_theory_name": "Hybrid Memory Architectures Enable Robust Long-Horizon Reasoning and Generalization in LLM Agents for Text Games",
    "provide_matched_control_thery_name": false,
    "matched_control_theory_name": null,
    "model_str": "openai/gpt-4.1-2025-04-14"
}</code></pre>
        </div>
    </div>
</body>
</html>