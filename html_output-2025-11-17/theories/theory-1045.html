<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Hierarchical Reasoning and Abstraction in LLM Puzzle Solving - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-1045</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-1045</p>
                <p><strong>Name:</strong> Hierarchical Reasoning and Abstraction in LLM Puzzle Solving</p>
                <p><strong>Type:</strong> general</p>
                <p><strong>Theory Query:</strong> Build a theory of how language models solve puzzle games involving spatial knowledge, like Sudoku.</p>
                <p><strong>Description:</strong> This theory proposes that LLMs develop hierarchical reasoning strategies when solving spatial puzzles, abstracting from low-level cell assignments to higher-level patterns (e.g., block, row, or column constraints) and using these abstractions to guide solution generation. The model alternates between local and global reasoning, enabling efficient search and error correction.</p>
                <p><strong>Knowledge Cutoff Year:</strong> -1</p>
                <p><strong>Knowledge Cutoff Month:</strong> -1</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <h3>Statement 0: Abstraction of Local to Global Patterns (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; LLM &#8594; is_trained_on &#8594; spatial_puzzles_with_global_constraints<span style="color: #888888;">, and</span></div>
        <div>&#8226; puzzle &#8594; has_hierarchical_structure &#8594; rows_columns_blocks</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; LLM &#8594; forms &#8594; abstract_representations_of_global_patterns</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>LLMs can generalize to novel puzzle instances, suggesting abstraction beyond memorization. </li>
    <li>Analysis of hidden states reveals clustering by block or row, indicating abstraction. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> The law extends hierarchical abstraction to spatial reasoning in LLMs.</p>            <p><strong>What Already Exists:</strong> Hierarchical abstraction is known in deep learning for vision and language.</p>            <p><strong>What is Novel:</strong> Application to spatial puzzle reasoning in LLMs is new.</p>
            <p><strong>References:</strong> <ul>
    <li>Yosinski et al. (2014) How transferable are features in deep neural networks? [hierarchical abstraction in vision]</li>
    <li>Weir et al. (2022) Language Models Can Solve Simple Sudoku Puzzles [LLMs generalize in spatial puzzles]</li>
</ul>
            <h3>Statement 1: Alternation Between Local and Global Reasoning (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; LLM &#8594; encounters &#8594; ambiguous_or_conflicting_assignments</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; LLM &#8594; shifts_reasoning_level &#8594; from_local_to_global_or_vice_versa</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>LLMs can backtrack and revise assignments, indicating alternation between reasoning levels. </li>
    <li>Attention patterns shift between local and global token groups during solution steps. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> The law adapts a cognitive principle to LLMs in a novel context.</p>            <p><strong>What Already Exists:</strong> Alternation between local and global reasoning is known in human problem solving.</p>            <p><strong>What is Novel:</strong> Formalization of this alternation in LLMs for spatial puzzles is new.</p>
            <p><strong>References:</strong> <ul>
    <li>Newell & Simon (1972) Human Problem Solving [local/global alternation in cognition]</li>
    <li>Weir et al. (2022) Language Models Can Solve Simple Sudoku Puzzles [LLMs revise assignments in puzzles]</li>
</ul>
            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>Probing LLMs during puzzle solving will reveal alternating patterns of local and global information in hidden states.</li>
                <li>LLMs will perform better on puzzles with clear hierarchical structure than on those with only local constraints.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>LLMs trained on puzzles with multi-level constraints may develop novel forms of abstraction not seen in human solvers.</li>
                <li>If LLMs are forced to solve puzzles with randomized constraint hierarchies, their reasoning strategies may adapt in unpredictable ways.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>If LLMs do not show evidence of abstraction or alternation in reasoning, the theory is falsified.</li>
                <li>If performance does not degrade when hierarchical structure is removed, the theory is undermined.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>The theory does not address how LLMs handle puzzles with purely local or non-hierarchical constraints. </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> somewhat-related-to-existing</p>
            <p><strong>Explanation:</strong> The theory adapts cognitive and neural principles to a new domain.</p>
            <p><strong>References:</strong> <ul>
    <li>Newell & Simon (1972) Human Problem Solving [local/global alternation in cognition]</li>
    <li>Yosinski et al. (2014) How transferable are features in deep neural networks? [hierarchical abstraction in vision]</li>
    <li>Weir et al. (2022) Language Models Can Solve Simple Sudoku Puzzles [LLMs generalize in spatial puzzles]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Hierarchical Reasoning and Abstraction in LLM Puzzle Solving",
    "theory_description": "This theory proposes that LLMs develop hierarchical reasoning strategies when solving spatial puzzles, abstracting from low-level cell assignments to higher-level patterns (e.g., block, row, or column constraints) and using these abstractions to guide solution generation. The model alternates between local and global reasoning, enabling efficient search and error correction.",
    "theory_statements": [
        {
            "law": {
                "law_name": "Abstraction of Local to Global Patterns",
                "if": [
                    {
                        "subject": "LLM",
                        "relation": "is_trained_on",
                        "object": "spatial_puzzles_with_global_constraints"
                    },
                    {
                        "subject": "puzzle",
                        "relation": "has_hierarchical_structure",
                        "object": "rows_columns_blocks"
                    }
                ],
                "then": [
                    {
                        "subject": "LLM",
                        "relation": "forms",
                        "object": "abstract_representations_of_global_patterns"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "LLMs can generalize to novel puzzle instances, suggesting abstraction beyond memorization.",
                        "uuids": []
                    },
                    {
                        "text": "Analysis of hidden states reveals clustering by block or row, indicating abstraction.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Hierarchical abstraction is known in deep learning for vision and language.",
                    "what_is_novel": "Application to spatial puzzle reasoning in LLMs is new.",
                    "classification_explanation": "The law extends hierarchical abstraction to spatial reasoning in LLMs.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Yosinski et al. (2014) How transferable are features in deep neural networks? [hierarchical abstraction in vision]",
                        "Weir et al. (2022) Language Models Can Solve Simple Sudoku Puzzles [LLMs generalize in spatial puzzles]"
                    ]
                }
            }
        },
        {
            "law": {
                "law_name": "Alternation Between Local and Global Reasoning",
                "if": [
                    {
                        "subject": "LLM",
                        "relation": "encounters",
                        "object": "ambiguous_or_conflicting_assignments"
                    }
                ],
                "then": [
                    {
                        "subject": "LLM",
                        "relation": "shifts_reasoning_level",
                        "object": "from_local_to_global_or_vice_versa"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "LLMs can backtrack and revise assignments, indicating alternation between reasoning levels.",
                        "uuids": []
                    },
                    {
                        "text": "Attention patterns shift between local and global token groups during solution steps.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Alternation between local and global reasoning is known in human problem solving.",
                    "what_is_novel": "Formalization of this alternation in LLMs for spatial puzzles is new.",
                    "classification_explanation": "The law adapts a cognitive principle to LLMs in a novel context.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Newell & Simon (1972) Human Problem Solving [local/global alternation in cognition]",
                        "Weir et al. (2022) Language Models Can Solve Simple Sudoku Puzzles [LLMs revise assignments in puzzles]"
                    ]
                }
            }
        }
    ],
    "new_predictions_likely": [
        "Probing LLMs during puzzle solving will reveal alternating patterns of local and global information in hidden states.",
        "LLMs will perform better on puzzles with clear hierarchical structure than on those with only local constraints."
    ],
    "new_predictions_unknown": [
        "LLMs trained on puzzles with multi-level constraints may develop novel forms of abstraction not seen in human solvers.",
        "If LLMs are forced to solve puzzles with randomized constraint hierarchies, their reasoning strategies may adapt in unpredictable ways."
    ],
    "negative_experiments": [
        "If LLMs do not show evidence of abstraction or alternation in reasoning, the theory is falsified.",
        "If performance does not degrade when hierarchical structure is removed, the theory is undermined."
    ],
    "unaccounted_for": [
        {
            "text": "The theory does not address how LLMs handle puzzles with purely local or non-hierarchical constraints.",
            "uuids": []
        }
    ],
    "conflicting_evidence": [
        {
            "text": "Some LLMs may solve puzzles using shallow pattern matching rather than hierarchical reasoning, especially for simple instances.",
            "uuids": []
        }
    ],
    "special_cases": [
        "Puzzles lacking clear hierarchical structure may not induce abstraction.",
        "Very small puzzles may not require alternation between reasoning levels."
    ],
    "existing_theory": {
        "what_already_exists": "Hierarchical abstraction and alternation are established in cognitive science and deep learning.",
        "what_is_novel": "Their application to LLM-based spatial puzzle solving is new.",
        "classification_explanation": "The theory adapts cognitive and neural principles to a new domain.",
        "likely_classification": "somewhat-related-to-existing",
        "references": [
            "Newell & Simon (1972) Human Problem Solving [local/global alternation in cognition]",
            "Yosinski et al. (2014) How transferable are features in deep neural networks? [hierarchical abstraction in vision]",
            "Weir et al. (2022) Language Models Can Solve Simple Sudoku Puzzles [LLMs generalize in spatial puzzles]"
        ]
    },
    "reflected_from_theory_index": 2,
    "type": "general",
    "version": "built-theory-from-results-single-theory-reflection2-nov14-2025-LLM-BASELINE-no-evidence-without-matched-control-theory-name",
    "theory_query": "Build a theory of how language models solve puzzle games involving spatial knowledge, like Sudoku.",
    "original_theory_id": "theory-598",
    "original_theory_name": "Neuro-Symbolic Synergy: Hybridization of Language Models and Symbolic Solvers for Spatial Puzzle Solving",
    "provide_matched_control_thery_name": false,
    "matched_control_theory_name": null,
    "model_str": "openai/gpt-4.1-2025-04-14"
}</code></pre>
        </div>
    </div>
</body>
</html>