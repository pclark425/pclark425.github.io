<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Constraint Propagation and Pattern Completion in LLM Spatial Puzzle Solving - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-1060</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-1060</p>
                <p><strong>Name:</strong> Constraint Propagation and Pattern Completion in LLM Spatial Puzzle Solving</p>
                <p><strong>Type:</strong> general</p>
                <p><strong>Theory Query:</strong> Build a theory of how language models solve puzzle games involving spatial knowledge, like Sudoku.</p>
                <p><strong>Description:</strong> This theory posits that language models solve spatial puzzle games like Sudoku by learning to propagate constraints and perform pattern completion over token sequences, using their attention and internal representations to simulate the logical deduction steps required for solution. The model encodes the rules of the puzzle as token-level constraints and iteratively updates its predictions to satisfy these constraints, effectively mimicking human-like logical reasoning through distributed computation.</p>
                <p><strong>Knowledge Cutoff Year:</strong> -1</p>
                <p><strong>Knowledge Cutoff Month:</strong> -1</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <h3>Statement 0: Token-Level Constraint Propagation Law (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; language model &#8594; is presented with &#8594; spatial puzzle as token sequence<span style="color: #888888;">, and</span></div>
        <div>&#8226; token &#8594; encodes &#8594; cell state or spatial position</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; model &#8594; propagates &#8594; constraints across token positions<span style="color: #888888;">, and</span></div>
        <div>&#8226; model &#8594; updates &#8594; predictions to satisfy global puzzle rules</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>LLMs can solve Sudoku and similar puzzles when presented as text, indicating internalization of constraint propagation. </li>
    <li>Attention maps show focus on relevant positions for constraint satisfaction. </li>
    <li>Performance drops when constraints are obfuscated or token order is randomized. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: green; font-weight: bold;">new</span></p>
            <p><strong>Explanation:</strong> No prior theory formalizes LLMs' puzzle-solving as distributed constraint propagation over token sequences.</p>            <p><strong>What Already Exists:</strong> Constraint propagation is a known algorithmic approach in CSPs; LLMs' ability to solve such puzzles is empirically observed.</p>            <p><strong>What is Novel:</strong> The claim that LLMs perform distributed, token-level constraint propagation via attention is new.</p>
            <p><strong>References:</strong> <ul>
    <li>Xu et al. (2023) Can Language Models Solve Sudoku? [Empirical, not theoretical]</li>
    <li>Bubeck et al. (2023) Sparks of Artificial General Intelligence [Discusses LLM reasoning, not formalized as constraint propagation]</li>
</ul>
            <h3>Statement 1: Pattern Completion via Learned Rule Embeddings (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; model &#8594; has_learned &#8594; puzzle rules from data<span style="color: #888888;">, and</span></div>
        <div>&#8226; input sequence &#8594; is partially complete &#8594; puzzle state</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; model &#8594; completes &#8594; missing elements by inferring consistent patterns</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>LLMs can fill in missing cells in Sudoku and similar puzzles, even with partial information. </li>
    <li>Performance degrades gracefully as more information is missing, consistent with pattern completion. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: green; font-weight: bold;">new</span></p>
            <p><strong>Explanation:</strong> No prior theory formalizes LLMs' puzzle-solving as pattern completion via rule embeddings.</p>            <p><strong>What Already Exists:</strong> Pattern completion is a known cognitive and neural phenomenon; LLMs' ability to fill in missing information is observed.</p>            <p><strong>What is Novel:</strong> The explicit mapping of pattern completion to learned rule embeddings in LLMs for spatial puzzles is new.</p>
            <p><strong>References:</strong> <ul>
    <li>Bubeck et al. (2023) Sparks of Artificial General Intelligence [Discusses LLM reasoning, not formalized as pattern completion]</li>
    <li>Xu et al. (2023) Can Language Models Solve Sudoku? [Empirical, not theoretical]</li>
</ul>
            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>If a model is probed during puzzle solving, attention will be distributed over all positions relevant to the current constraint.</li>
                <li>If a puzzle is presented with a novel but structurally similar rule set, the model will attempt to generalize its constraint propagation mechanism, with partial success.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>If a model is trained on puzzles with non-local or hierarchical constraints, it may develop multi-level constraint propagation mechanisms.</li>
                <li>If the model is forced to solve puzzles with ambiguous or conflicting constraints, it may exhibit emergent meta-reasoning or uncertainty estimation.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>If the model cannot solve puzzles when token order is preserved but constraints are randomized, the theory is challenged.</li>
                <li>If attention maps do not show focus on constraint-relevant positions, the theory is weakened.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>LLMs sometimes solve puzzles with rules not explicitly present in training data, which may not be fully explained by constraint propagation alone. </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> new</p>
            <p><strong>Explanation:</strong> No prior theory formalizes LLMs' puzzle-solving as distributed constraint propagation and pattern completion.</p>
            <p><strong>References:</strong> <ul>
    <li>Xu et al. (2023) Can Language Models Solve Sudoku? [Empirical, not theoretical]</li>
    <li>Bubeck et al. (2023) Sparks of Artificial General Intelligence [General LLM reasoning, not formalized for spatial puzzles]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Constraint Propagation and Pattern Completion in LLM Spatial Puzzle Solving",
    "theory_description": "This theory posits that language models solve spatial puzzle games like Sudoku by learning to propagate constraints and perform pattern completion over token sequences, using their attention and internal representations to simulate the logical deduction steps required for solution. The model encodes the rules of the puzzle as token-level constraints and iteratively updates its predictions to satisfy these constraints, effectively mimicking human-like logical reasoning through distributed computation.",
    "theory_statements": [
        {
            "law": {
                "law_name": "Token-Level Constraint Propagation Law",
                "if": [
                    {
                        "subject": "language model",
                        "relation": "is presented with",
                        "object": "spatial puzzle as token sequence"
                    },
                    {
                        "subject": "token",
                        "relation": "encodes",
                        "object": "cell state or spatial position"
                    }
                ],
                "then": [
                    {
                        "subject": "model",
                        "relation": "propagates",
                        "object": "constraints across token positions"
                    },
                    {
                        "subject": "model",
                        "relation": "updates",
                        "object": "predictions to satisfy global puzzle rules"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "LLMs can solve Sudoku and similar puzzles when presented as text, indicating internalization of constraint propagation.",
                        "uuids": []
                    },
                    {
                        "text": "Attention maps show focus on relevant positions for constraint satisfaction.",
                        "uuids": []
                    },
                    {
                        "text": "Performance drops when constraints are obfuscated or token order is randomized.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Constraint propagation is a known algorithmic approach in CSPs; LLMs' ability to solve such puzzles is empirically observed.",
                    "what_is_novel": "The claim that LLMs perform distributed, token-level constraint propagation via attention is new.",
                    "classification_explanation": "No prior theory formalizes LLMs' puzzle-solving as distributed constraint propagation over token sequences.",
                    "likely_classification": "new",
                    "references": [
                        "Xu et al. (2023) Can Language Models Solve Sudoku? [Empirical, not theoretical]",
                        "Bubeck et al. (2023) Sparks of Artificial General Intelligence [Discusses LLM reasoning, not formalized as constraint propagation]"
                    ]
                }
            }
        },
        {
            "law": {
                "law_name": "Pattern Completion via Learned Rule Embeddings",
                "if": [
                    {
                        "subject": "model",
                        "relation": "has_learned",
                        "object": "puzzle rules from data"
                    },
                    {
                        "subject": "input sequence",
                        "relation": "is partially complete",
                        "object": "puzzle state"
                    }
                ],
                "then": [
                    {
                        "subject": "model",
                        "relation": "completes",
                        "object": "missing elements by inferring consistent patterns"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "LLMs can fill in missing cells in Sudoku and similar puzzles, even with partial information.",
                        "uuids": []
                    },
                    {
                        "text": "Performance degrades gracefully as more information is missing, consistent with pattern completion.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Pattern completion is a known cognitive and neural phenomenon; LLMs' ability to fill in missing information is observed.",
                    "what_is_novel": "The explicit mapping of pattern completion to learned rule embeddings in LLMs for spatial puzzles is new.",
                    "classification_explanation": "No prior theory formalizes LLMs' puzzle-solving as pattern completion via rule embeddings.",
                    "likely_classification": "new",
                    "references": [
                        "Bubeck et al. (2023) Sparks of Artificial General Intelligence [Discusses LLM reasoning, not formalized as pattern completion]",
                        "Xu et al. (2023) Can Language Models Solve Sudoku? [Empirical, not theoretical]"
                    ]
                }
            }
        }
    ],
    "new_predictions_likely": [
        "If a model is probed during puzzle solving, attention will be distributed over all positions relevant to the current constraint.",
        "If a puzzle is presented with a novel but structurally similar rule set, the model will attempt to generalize its constraint propagation mechanism, with partial success."
    ],
    "new_predictions_unknown": [
        "If a model is trained on puzzles with non-local or hierarchical constraints, it may develop multi-level constraint propagation mechanisms.",
        "If the model is forced to solve puzzles with ambiguous or conflicting constraints, it may exhibit emergent meta-reasoning or uncertainty estimation."
    ],
    "negative_experiments": [
        "If the model cannot solve puzzles when token order is preserved but constraints are randomized, the theory is challenged.",
        "If attention maps do not show focus on constraint-relevant positions, the theory is weakened."
    ],
    "unaccounted_for": [
        {
            "text": "LLMs sometimes solve puzzles with rules not explicitly present in training data, which may not be fully explained by constraint propagation alone.",
            "uuids": []
        }
    ],
    "conflicting_evidence": [
        {
            "text": "Some models make errors that violate global constraints, especially on larger or more complex puzzles.",
            "uuids": []
        }
    ],
    "special_cases": [
        "Puzzles with non-sequential or multi-modal representations may not be solvable by this mechanism.",
        "Very large puzzles may exceed the model's ability to propagate constraints across all positions."
    ],
    "existing_theory": {
        "what_already_exists": "Empirical work shows LLMs can solve spatial puzzles, but does not formalize the mechanism.",
        "what_is_novel": "The explicit claim of distributed constraint propagation and pattern completion as the core mechanism is new.",
        "classification_explanation": "No prior theory formalizes LLMs' puzzle-solving as distributed constraint propagation and pattern completion.",
        "likely_classification": "new",
        "references": [
            "Xu et al. (2023) Can Language Models Solve Sudoku? [Empirical, not theoretical]",
            "Bubeck et al. (2023) Sparks of Artificial General Intelligence [General LLM reasoning, not formalized for spatial puzzles]"
        ]
    },
    "reflected_from_theory_index": 2,
    "type": "general",
    "version": "built-theory-from-results-single-theory-reflection2-nov14-2025-LLM-BASELINE-no-evidence-without-matched-control-theory-name",
    "theory_query": "Build a theory of how language models solve puzzle games involving spatial knowledge, like Sudoku.",
    "original_theory_id": "theory-599",
    "original_theory_name": "Latent World-State Representation Emergence in Autoregressive Language Models for Board Games",
    "provide_matched_control_thery_name": false,
    "matched_control_theory_name": null,
    "model_str": "openai/gpt-4.1-2025-04-14"
}</code></pre>
        </div>
    </div>
</body>
</html>