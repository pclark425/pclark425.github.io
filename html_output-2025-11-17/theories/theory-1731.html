<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Language Model Statistical Expectation Theory for Anomaly Detection - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-1731</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-1731</p>
                <p><strong>Name:</strong> Language Model Statistical Expectation Theory for Anomaly Detection</p>
                <p><strong>Type:</strong> general</p>
                <p><strong>Theory Query:</strong> Build a theory of how language models can be used for detecting anomalies in lists of data.</p>
                <p><strong>Description:</strong> This theory posits that language models (LMs) encode statistical expectations about the structure and content of lists, and that anomalies can be detected by identifying elements that violate these learned expectations. The LM's internal probability distributions, when applied to list elements, reveal outliers as those with low likelihood or high surprisal relative to the model's learned distribution for similar contexts.</p>
                <p><strong>Knowledge Cutoff Year:</strong> -1</p>
                <p><strong>Knowledge Cutoff Month:</strong> -1</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <h3>Statement 0: Low Likelihood Indicates Anomaly (quantitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; element &#8594; is_in &#8594; list<span style="color: #888888;">, and</span></div>
        <div>&#8226; language_model &#8594; assigns_probability &#8594; p<span style="color: #888888;">, and</span></div>
        <div>&#8226; p &#8594; is_much_lower_than &#8594; mean_probability_of_typical_elements</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; element &#8594; is_flagged_as &#8594; anomaly</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Language models assign lower probabilities to out-of-distribution or unexpected tokens and sequences. </li>
    <li>Anomalous elements in lists (e.g., a non-animal in a list of animals) receive lower likelihoods from LMs. </li>
    <li>Surprisal-based anomaly detection is effective in both text and structured data. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> closely-related-to-existing</p>
            <p><strong>Explanation:</strong> Closely related to existing work in language modeling and anomaly detection, but the generalization to arbitrary list anomaly detection is new.</p>            <p><strong>What Already Exists:</strong> LMs assign probabilities to tokens and sequences, and low-probability events are considered surprising.</p>            <p><strong>What is Novel:</strong> The explicit use of LM probability assignments for anomaly detection in arbitrary lists is a novel generalization.</p>
            <p><strong>References:</strong> <ul>
    <li>Goldstein & Uchida (2016) A Comparative Evaluation of Unsupervised Anomaly Detection Algorithms for Multivariate Data [Surprisal and likelihood-based anomaly detection]</li>
    <li>Radford et al. (2019) Language Models are Unsupervised Multitask Learners [LMs encode statistical expectations]</li>
    <li>Hendrycks & Gimpel (2017) A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks [Low likelihood signals OOD]</li>
</ul>
            <h3>Statement 1: Contextual Consistency Governs Anomaly Detection (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; element &#8594; is_in &#8594; list<span style="color: #888888;">, and</span></div>
        <div>&#8226; language_model &#8594; has_contextual_expectation &#8594; C<span style="color: #888888;">, and</span></div>
        <div>&#8226; element &#8594; violates &#8594; C</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; element &#8594; is_flagged_as &#8594; anomaly</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>LMs use context to predict next tokens; elements inconsistent with context are assigned lower probabilities. </li>
    <li>Contextual anomaly detection is effective in sequential and list data. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> Somewhat related to existing work, but the explicit generalization to list anomaly detection is new.</p>            <p><strong>What Already Exists:</strong> Contextual prediction is a core function of LMs.</p>            <p><strong>What is Novel:</strong> The formalization of contextual violation as a general anomaly detection mechanism in lists is novel.</p>
            <p><strong>References:</strong> <ul>
    <li>Devlin et al. (2018) BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding [Contextual prediction in LMs]</li>
    <li>Chandola et al. (2009) Anomaly Detection: A Survey [Contextual anomaly detection]</li>
</ul>
            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>If a list of US state names contains a non-state word, the LM will assign it a much lower probability and flag it as an anomaly.</li>
                <li>If a list of dates contains a string in an unexpected format, the LM will assign it low likelihood and flag it as anomalous.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>If a list contains elements that are rare but not semantically anomalous, the LM may or may not flag them as anomalies depending on its training data.</li>
                <li>If the LM is exposed to adversarially constructed lists, its probability assignments may not reliably indicate anomalies.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>If elements with low LM-assigned probability are not actually anomalous, the theory is challenged.</li>
                <li>If elements that violate context are not flagged as anomalies by the LM, the theory is called into question.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>Anomalies that are subtle and do not significantly affect LM probability assignments may not be detected. </li>
    <li>LMs trained on highly heterogeneous data may have diffuse expectations, reducing anomaly detection accuracy. </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> closely-related-to-existing</p>
            <p><strong>Explanation:</strong> Closely related to existing work, but the generalization and formalization for list anomaly detection is new.</p>
            <p><strong>References:</strong> <ul>
    <li>Goldstein & Uchida (2016) A Comparative Evaluation of Unsupervised Anomaly Detection Algorithms for Multivariate Data [Surprisal and likelihood-based anomaly detection]</li>
    <li>Radford et al. (2019) Language Models are Unsupervised Multitask Learners [LMs encode statistical expectations]</li>
    <li>Hendrycks & Gimpel (2017) A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks [Low likelihood signals OOD]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Language Model Statistical Expectation Theory for Anomaly Detection",
    "theory_description": "This theory posits that language models (LMs) encode statistical expectations about the structure and content of lists, and that anomalies can be detected by identifying elements that violate these learned expectations. The LM's internal probability distributions, when applied to list elements, reveal outliers as those with low likelihood or high surprisal relative to the model's learned distribution for similar contexts.",
    "theory_statements": [
        {
            "law": {
                "law_name": "Low Likelihood Indicates Anomaly",
                "if": [
                    {
                        "subject": "element",
                        "relation": "is_in",
                        "object": "list"
                    },
                    {
                        "subject": "language_model",
                        "relation": "assigns_probability",
                        "object": "p"
                    },
                    {
                        "subject": "p",
                        "relation": "is_much_lower_than",
                        "object": "mean_probability_of_typical_elements"
                    }
                ],
                "then": [
                    {
                        "subject": "element",
                        "relation": "is_flagged_as",
                        "object": "anomaly"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Language models assign lower probabilities to out-of-distribution or unexpected tokens and sequences.",
                        "uuids": []
                    },
                    {
                        "text": "Anomalous elements in lists (e.g., a non-animal in a list of animals) receive lower likelihoods from LMs.",
                        "uuids": []
                    },
                    {
                        "text": "Surprisal-based anomaly detection is effective in both text and structured data.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "quantitative",
                "existing_law": {
                    "what_already_exists": "LMs assign probabilities to tokens and sequences, and low-probability events are considered surprising.",
                    "what_is_novel": "The explicit use of LM probability assignments for anomaly detection in arbitrary lists is a novel generalization.",
                    "classification_explanation": "Closely related to existing work in language modeling and anomaly detection, but the generalization to arbitrary list anomaly detection is new.",
                    "likely_classification": "closely-related-to-existing",
                    "references": [
                        "Goldstein & Uchida (2016) A Comparative Evaluation of Unsupervised Anomaly Detection Algorithms for Multivariate Data [Surprisal and likelihood-based anomaly detection]",
                        "Radford et al. (2019) Language Models are Unsupervised Multitask Learners [LMs encode statistical expectations]",
                        "Hendrycks & Gimpel (2017) A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks [Low likelihood signals OOD]"
                    ]
                }
            }
        },
        {
            "law": {
                "law_name": "Contextual Consistency Governs Anomaly Detection",
                "if": [
                    {
                        "subject": "element",
                        "relation": "is_in",
                        "object": "list"
                    },
                    {
                        "subject": "language_model",
                        "relation": "has_contextual_expectation",
                        "object": "C"
                    },
                    {
                        "subject": "element",
                        "relation": "violates",
                        "object": "C"
                    }
                ],
                "then": [
                    {
                        "subject": "element",
                        "relation": "is_flagged_as",
                        "object": "anomaly"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "LMs use context to predict next tokens; elements inconsistent with context are assigned lower probabilities.",
                        "uuids": []
                    },
                    {
                        "text": "Contextual anomaly detection is effective in sequential and list data.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Contextual prediction is a core function of LMs.",
                    "what_is_novel": "The formalization of contextual violation as a general anomaly detection mechanism in lists is novel.",
                    "classification_explanation": "Somewhat related to existing work, but the explicit generalization to list anomaly detection is new.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Devlin et al. (2018) BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding [Contextual prediction in LMs]",
                        "Chandola et al. (2009) Anomaly Detection: A Survey [Contextual anomaly detection]"
                    ]
                }
            }
        }
    ],
    "new_predictions_likely": [
        "If a list of US state names contains a non-state word, the LM will assign it a much lower probability and flag it as an anomaly.",
        "If a list of dates contains a string in an unexpected format, the LM will assign it low likelihood and flag it as anomalous."
    ],
    "new_predictions_unknown": [
        "If a list contains elements that are rare but not semantically anomalous, the LM may or may not flag them as anomalies depending on its training data.",
        "If the LM is exposed to adversarially constructed lists, its probability assignments may not reliably indicate anomalies."
    ],
    "negative_experiments": [
        "If elements with low LM-assigned probability are not actually anomalous, the theory is challenged.",
        "If elements that violate context are not flagged as anomalies by the LM, the theory is called into question."
    ],
    "unaccounted_for": [
        {
            "text": "Anomalies that are subtle and do not significantly affect LM probability assignments may not be detected.",
            "uuids": []
        },
        {
            "text": "LMs trained on highly heterogeneous data may have diffuse expectations, reducing anomaly detection accuracy.",
            "uuids": []
        }
    ],
    "conflicting_evidence": [
        {
            "text": "Some LMs produce poorly calibrated probabilities for rare or OOD elements, leading to false negatives or positives.",
            "uuids": []
        }
    ],
    "special_cases": [
        "Lists with highly diverse or multi-modal elements may not have strong statistical expectations, reducing anomaly detection power.",
        "If the LM's training data is biased or incomplete, its expectations may not match the true distribution of normal elements."
    ],
    "existing_theory": {
        "what_already_exists": "LMs encode statistical expectations and assign probabilities to sequences; surprisal and likelihood-based anomaly detection are established.",
        "what_is_novel": "The explicit, general application of LM statistical expectations to anomaly detection in arbitrary lists is novel.",
        "classification_explanation": "Closely related to existing work, but the generalization and formalization for list anomaly detection is new.",
        "likely_classification": "closely-related-to-existing",
        "references": [
            "Goldstein & Uchida (2016) A Comparative Evaluation of Unsupervised Anomaly Detection Algorithms for Multivariate Data [Surprisal and likelihood-based anomaly detection]",
            "Radford et al. (2019) Language Models are Unsupervised Multitask Learners [LMs encode statistical expectations]",
            "Hendrycks & Gimpel (2017) A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks [Low likelihood signals OOD]"
        ]
    },
    "reflected_from_theory_index": 3,
    "type": "general",
    "version": "built-theory-from-results-single-theory-reflection2-nov14-2025-LLM-BASELINE-no-evidence-without-matched-control-theory-name",
    "theory_query": "Build a theory of how language models can be used for detecting anomalies in lists of data.",
    "original_theory_id": "theory-642",
    "original_theory_name": "Generalized Language Model Representation and Adaptation Theory for Anomaly Detection in Lists and Tabular Data",
    "provide_matched_control_thery_name": false,
    "matched_control_theory_name": null,
    "model_str": "openai/gpt-4.1-2025-04-14"
}</code></pre>
        </div>
    </div>
</body>
</html>