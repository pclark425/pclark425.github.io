<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Multi-Environment Invariance Theory for Spurious Signal Detection - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-291</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-291</p>
                <p><strong>Name:</strong> Multi-Environment Invariance Theory for Spurious Signal Detection</p>
                <p><strong>Type:</strong> specific</p>
                <p><strong>Theory Query:</strong> Build a theory of distractor-robust causal discovery in open-ended virtual labs, including methods to detect, downweight, and refute spurious signals during inquiry.. Please focus on creating new theories that have not been proposed before in the literature.</p>
                <p><strong>Description:</strong> This theory proposes that spurious signals can be systematically detected and refuted by testing whether observed relationships remain invariant (stable) across multiple diverse environments. True causal relationships exhibit invariance: they maintain their strength and direction across different contexts, boundary conditions, and environmental parameters. In contrast, spurious correlations arise from environment-specific confounders and therefore vary or disappear when environmental conditions change. The theory provides a computational framework for: (1) quantifying relationship invariance across environments using statistical tests and effect size stability metrics, (2) strategically selecting or synthesizing environments that maximize the discriminative power between invariant causal and variant spurious relationships, and (3) using invariance violations as evidence to downweight or refute suspected spurious signals. The theory integrates principles from invariant causal prediction, transfer learning, and robust statistics to create a principled approach for distractor-robust causal discovery in open-ended virtual laboratories where learners can manipulate environmental conditions.</p>
                <p><strong>Knowledge Cutoff Year:</strong> -1</p>
                <p><strong>Knowledge Cutoff Month:</strong> -1</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <ol>
                <li>A relationship R between variables X and Y is classified as likely causal if it exhibits invariance: the effect size and direction remain stable (within statistical bounds) across k ≥ 3 diverse environments, where diversity is measured by variance in potential confounders.</li>
                <li>A relationship R is classified as likely spurious if it exhibits significant variance across environments: the effect size changes by >50% or the relationship direction reverses in at least one environment, or the relationship becomes statistically non-significant in ≥30% of tested environments.</li>
                <li>The invariance score I(R) for a relationship R across environments E₁, E₂, ..., Eₖ is quantified as: I(R) = 1 - (σ(β)/μ(|β|)), where β represents effect sizes across environments, σ is standard deviation, and μ is mean. Higher scores (approaching 1) indicate greater invariance.</li>
                <li>The discriminative power D(E_new) of adding a new environment for distinguishing causal from spurious relationships is: D(E_new) = Σᵢ |Var(Rᵢ | E₁...Eₖ ∪ E_new) - Var(Rᵢ | E₁...Eₖ)|, summed over suspected relationships, where Var represents variance in effect estimates.</li>
                <li>Optimal environment selection for spurious signal detection prioritizes environments that: (a) maximize differences in confounder distributions from previous environments, (b) maintain feasibility of measuring the same outcome variables, and (c) are predicted to show divergent patterns for causal vs. spurious hypotheses.</li>
                <li>A confidence threshold for causal classification requires: invariance score I(R) > 0.7 AND statistical significance in ≥80% of environments AND effect size coefficient of variation CV < 0.3 across environments.</li>
                <li>Spurious signals can be systematically downweighted using a Bayesian updating scheme where prior probability of causality P(causal|R) is multiplied by an invariance likelihood ratio: LR = P(observed invariance|causal) / P(observed invariance|spurious), with typical values LR > 5 for stable relationships and LR < 0.2 for variant relationships.</li>
                <li>The minimum number of environments needed for reliable spurious signal detection scales with the number of potential confounders C as: k_min ≈ 2 + log₂(C), ensuring sufficient diversity to decorrelate confounders from causal pathways.</li>
            </ol>
            <h3>Supporting Evidence</h3>
<ol>
    <li>Invariant Causal Prediction (ICP) methods successfully identify causal variables by finding predictors whose relationships remain stable across different environments or experimental conditions </li>
    <li>Transfer learning research demonstrates that features that generalize across domains are more likely to capture true underlying relationships rather than domain-specific artifacts </li>
    <li>Causal relationships are characterized by stability and autonomy across interventions and context changes, while spurious correlations are fragile to such changes </li>
    <li>Robustness and stability of statistical relationships across subpopulations or conditions is a key principle in causal inference and epidemiology </li>
    <li>Meta-analysis and systematic review methods that examine consistency of effects across studies provide stronger evidence for causal claims than single-study results </li>
    <li>Active learning and optimal experimental design can guide selection of test conditions that maximize information gain </li>
    <li>Distributional robustness and out-of-distribution generalization are key challenges in machine learning that relate to identifying stable vs. spurious patterns </li>
</ol>            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>In virtual lab experiments, relationships that maintain effect sizes within ±20% across 4-5 diverse environments will be correctly identified as causal by learners 85-95% of the time, compared to 40-60% accuracy for relationships tested in only 1-2 environments.</li>
                <li>Spurious correlations induced by hidden confounders will show effect size reductions of >50% or direction reversals when tested in environments where the confounder distribution is substantially altered (e.g., shifted by >1 standard deviation).</li>
                <li>Learners explicitly taught to test relationship stability across environments will detect spurious signals 3-5x faster than learners using traditional controlled variable strategies, requiring 5-8 experiments vs. 15-25 experiments on average.</li>
                <li>Computational tools that automatically calculate and display invariance scores across tested environments will improve learners' causal inference accuracy by 30-50% compared to learners who must manually track and compare results across environments.</li>
                <li>In scenarios with 2-3 potential confounders, testing relationships across 4-5 strategically selected diverse environments will achieve >90% accuracy in distinguishing causal from spurious relationships, comparable to testing 10+ randomly selected environments.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>Whether human learners can intuitively estimate relationship invariance across environments without explicit computational support, or whether this requires training in statistical thinking about effect size stability.</li>
                <li>Whether there exist classes of spurious relationships (e.g., those arising from complex multi-way interactions) that maintain apparent invariance across typical environment variations, requiring more sophisticated testing strategies.</li>
                <li>Whether the cognitive load of simultaneously tracking relationship stability across multiple environments interferes with learning, or whether it promotes deeper causal reasoning and metacognitive awareness.</li>
                <li>Whether collaborative groups can collectively identify optimal environment sequences for invariance testing better than individuals, potentially through complementary hypotheses about which environmental variations matter most.</li>
                <li>Whether the invariance principle generalizes effectively to domains with continuous outcomes and non-linear relationships, or whether it requires adaptation for complex functional forms.</li>
                <li>Whether learners develop transferable skills in invariance-based reasoning that apply to real-world causal inference tasks outside virtual lab contexts, or whether the strategy remains context-specific.</li>
                <li>Whether there are fundamental limits to the number of environments that learners can effectively reason about simultaneously, potentially requiring hierarchical or sequential invariance testing strategies for complex scenarios.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>If true causal relationships frequently show high variance (>50% effect size changes) across diverse environments in virtual labs, the invariance principle would be unreliable for causal identification.</li>
                <li>If spurious correlations often maintain stability across 4-5 diverse environments due to persistent confounding structures, the theory's discriminative power would be insufficient.</li>
                <li>If learners cannot reliably identify which environmental variations are 'diverse enough' to test invariance, the practical applicability would be limited without computational guidance.</li>
                <li>If the computational cost of testing relationships across multiple environments exceeds learners' time or cognitive budgets, making single-environment controlled experiments more practical despite lower accuracy.</li>
                <li>If invariance scores calculated from small samples in each environment are too noisy to reliably distinguish causal from spurious relationships, requiring prohibitively large sample sizes per environment.</li>
                <li>If learners misinterpret invariance violations (e.g., due to measurement error or sampling variability) as evidence against causality when relationships are actually causal, leading to false negatives.</li>
                <li>If the theory's quantitative thresholds (e.g., I(R) > 0.7, CV < 0.3) are too stringent or too lenient for typical virtual lab scenarios, requiring substantial calibration for practical use.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>The theory does not fully specify how to handle non-linear relationships where effect sizes may legitimately vary across environments due to ceiling/floor effects or interaction terms rather than spuriousness. </li>
    <li>Practical constraints on environment construction (feasibility, cost, time) are not integrated into the environment selection framework, which may limit applicability in resource-constrained settings. </li>
    <li>The theory does not address how to handle measurement error or noise that varies across environments, which could be misinterpreted as invariance violations. </li>
    <li>Social and collaborative aspects of multi-environment testing in group inquiry settings are not addressed, including how to coordinate environment selection and share invariance evidence. </li>
    <li>The theory does not specify how to handle temporal dynamics where relationships may change over time within an environment, complicating invariance assessment. </li>
    <li>Edge cases where multiple spurious relationships coincidentally show similar invariance patterns, potentially leading to false positives, are not fully addressed. </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> new</p>
            <p><strong>Explanation:</strong> No explanation provided.</p>
            <p><strong>References:</strong> <ul>
    <li>Peters et al. (2016) Causal inference by using invariant prediction: identification and confidence intervals [Invariant Causal Prediction (ICP) method for causal discovery, but focused on automated statistical algorithms rather than human inquiry learning in virtual labs]</li>
    <li>Arjovsky et al. (2019) Invariant Risk Minimization [Uses invariance principle for machine learning robustness, but not applied to educational contexts or spurious signal detection in inquiry learning]</li>
    <li>Schölkopf et al. (2012) On causal and anticausal learning [Discusses stability of causal vs. anticausal relationships, but not specifically about multi-environment testing strategies for learners]</li>
    <li>Ben-David et al. (2010) A theory of learning from different domains [Transfer learning theory about domain invariance, but focused on machine learning generalization rather than causal discovery in inquiry]</li>
    <li>Rosenbaum (2010) Design of Observational Studies [Discusses robustness and sensitivity analysis in causal inference, but not specifically about multi-environment invariance testing in virtual labs]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Multi-Environment Invariance Theory for Spurious Signal Detection",
    "theory_description": "This theory proposes that spurious signals can be systematically detected and refuted by testing whether observed relationships remain invariant (stable) across multiple diverse environments. True causal relationships exhibit invariance: they maintain their strength and direction across different contexts, boundary conditions, and environmental parameters. In contrast, spurious correlations arise from environment-specific confounders and therefore vary or disappear when environmental conditions change. The theory provides a computational framework for: (1) quantifying relationship invariance across environments using statistical tests and effect size stability metrics, (2) strategically selecting or synthesizing environments that maximize the discriminative power between invariant causal and variant spurious relationships, and (3) using invariance violations as evidence to downweight or refute suspected spurious signals. The theory integrates principles from invariant causal prediction, transfer learning, and robust statistics to create a principled approach for distractor-robust causal discovery in open-ended virtual laboratories where learners can manipulate environmental conditions.",
    "supporting_evidence": [
        {
            "text": "Invariant Causal Prediction (ICP) methods successfully identify causal variables by finding predictors whose relationships remain stable across different environments or experimental conditions",
            "citations": [
                "Peters et al. (2016) Causal inference by using invariant prediction: identification and confidence intervals, Journal of the Royal Statistical Society Series B",
                "Heinze-Deml et al. (2018) Invariant Causal Prediction for Nonlinear Models, Journal of Causal Inference"
            ]
        },
        {
            "text": "Transfer learning research demonstrates that features that generalize across domains are more likely to capture true underlying relationships rather than domain-specific artifacts",
            "citations": [
                "Ben-David et al. (2010) A theory of learning from different domains, Machine Learning",
                "Ganin et al. (2016) Domain-Adversarial Training of Neural Networks, Journal of Machine Learning Research"
            ]
        },
        {
            "text": "Causal relationships are characterized by stability and autonomy across interventions and context changes, while spurious correlations are fragile to such changes",
            "citations": [
                "Pearl (2009) Causality: Models, Reasoning, and Inference, Cambridge University Press",
                "Schölkopf et al. (2012) On causal and anticausal learning, Proceedings of ICML"
            ]
        },
        {
            "text": "Robustness and stability of statistical relationships across subpopulations or conditions is a key principle in causal inference and epidemiology",
            "citations": [
                "Rosenbaum (2010) Design of Observational Studies, Springer",
                "VanderWeele & Hernán (2012) Results on differential and dependent measurement error of the exposure and the outcome using signed directed acyclic graphs, American Journal of Epidemiology"
            ]
        },
        {
            "text": "Meta-analysis and systematic review methods that examine consistency of effects across studies provide stronger evidence for causal claims than single-study results",
            "citations": [
                "Higgins & Thompson (2002) Quantifying heterogeneity in a meta-analysis, Statistics in Medicine",
                "Ioannidis (2005) Why most published research findings are false, PLoS Medicine"
            ]
        },
        {
            "text": "Active learning and optimal experimental design can guide selection of test conditions that maximize information gain",
            "citations": [
                "Settles (2009) Active Learning Literature Survey, Computer Sciences Technical Report",
                "Chaloner & Verdinelli (1995) Bayesian Experimental Design: A Review, Statistical Science"
            ]
        },
        {
            "text": "Distributional robustness and out-of-distribution generalization are key challenges in machine learning that relate to identifying stable vs. spurious patterns",
            "citations": [
                "Arjovsky et al. (2019) Invariant Risk Minimization, arXiv preprint",
                "Sagawa et al. (2020) Distributionally Robust Neural Networks for Group Shifts, ICLR"
            ]
        }
    ],
    "theory_statements": [
        "A relationship R between variables X and Y is classified as likely causal if it exhibits invariance: the effect size and direction remain stable (within statistical bounds) across k ≥ 3 diverse environments, where diversity is measured by variance in potential confounders.",
        "A relationship R is classified as likely spurious if it exhibits significant variance across environments: the effect size changes by &gt;50% or the relationship direction reverses in at least one environment, or the relationship becomes statistically non-significant in ≥30% of tested environments.",
        "The invariance score I(R) for a relationship R across environments E₁, E₂, ..., Eₖ is quantified as: I(R) = 1 - (σ(β)/μ(|β|)), where β represents effect sizes across environments, σ is standard deviation, and μ is mean. Higher scores (approaching 1) indicate greater invariance.",
        "The discriminative power D(E_new) of adding a new environment for distinguishing causal from spurious relationships is: D(E_new) = Σᵢ |Var(Rᵢ | E₁...Eₖ ∪ E_new) - Var(Rᵢ | E₁...Eₖ)|, summed over suspected relationships, where Var represents variance in effect estimates.",
        "Optimal environment selection for spurious signal detection prioritizes environments that: (a) maximize differences in confounder distributions from previous environments, (b) maintain feasibility of measuring the same outcome variables, and (c) are predicted to show divergent patterns for causal vs. spurious hypotheses.",
        "A confidence threshold for causal classification requires: invariance score I(R) &gt; 0.7 AND statistical significance in ≥80% of environments AND effect size coefficient of variation CV &lt; 0.3 across environments.",
        "Spurious signals can be systematically downweighted using a Bayesian updating scheme where prior probability of causality P(causal|R) is multiplied by an invariance likelihood ratio: LR = P(observed invariance|causal) / P(observed invariance|spurious), with typical values LR &gt; 5 for stable relationships and LR &lt; 0.2 for variant relationships.",
        "The minimum number of environments needed for reliable spurious signal detection scales with the number of potential confounders C as: k_min ≈ 2 + log₂(C), ensuring sufficient diversity to decorrelate confounders from causal pathways."
    ],
    "new_predictions_likely": [
        "In virtual lab experiments, relationships that maintain effect sizes within ±20% across 4-5 diverse environments will be correctly identified as causal by learners 85-95% of the time, compared to 40-60% accuracy for relationships tested in only 1-2 environments.",
        "Spurious correlations induced by hidden confounders will show effect size reductions of &gt;50% or direction reversals when tested in environments where the confounder distribution is substantially altered (e.g., shifted by &gt;1 standard deviation).",
        "Learners explicitly taught to test relationship stability across environments will detect spurious signals 3-5x faster than learners using traditional controlled variable strategies, requiring 5-8 experiments vs. 15-25 experiments on average.",
        "Computational tools that automatically calculate and display invariance scores across tested environments will improve learners' causal inference accuracy by 30-50% compared to learners who must manually track and compare results across environments.",
        "In scenarios with 2-3 potential confounders, testing relationships across 4-5 strategically selected diverse environments will achieve &gt;90% accuracy in distinguishing causal from spurious relationships, comparable to testing 10+ randomly selected environments."
    ],
    "new_predictions_unknown": [
        "Whether human learners can intuitively estimate relationship invariance across environments without explicit computational support, or whether this requires training in statistical thinking about effect size stability.",
        "Whether there exist classes of spurious relationships (e.g., those arising from complex multi-way interactions) that maintain apparent invariance across typical environment variations, requiring more sophisticated testing strategies.",
        "Whether the cognitive load of simultaneously tracking relationship stability across multiple environments interferes with learning, or whether it promotes deeper causal reasoning and metacognitive awareness.",
        "Whether collaborative groups can collectively identify optimal environment sequences for invariance testing better than individuals, potentially through complementary hypotheses about which environmental variations matter most.",
        "Whether the invariance principle generalizes effectively to domains with continuous outcomes and non-linear relationships, or whether it requires adaptation for complex functional forms.",
        "Whether learners develop transferable skills in invariance-based reasoning that apply to real-world causal inference tasks outside virtual lab contexts, or whether the strategy remains context-specific.",
        "Whether there are fundamental limits to the number of environments that learners can effectively reason about simultaneously, potentially requiring hierarchical or sequential invariance testing strategies for complex scenarios."
    ],
    "negative_experiments": [
        "If true causal relationships frequently show high variance (&gt;50% effect size changes) across diverse environments in virtual labs, the invariance principle would be unreliable for causal identification.",
        "If spurious correlations often maintain stability across 4-5 diverse environments due to persistent confounding structures, the theory's discriminative power would be insufficient.",
        "If learners cannot reliably identify which environmental variations are 'diverse enough' to test invariance, the practical applicability would be limited without computational guidance.",
        "If the computational cost of testing relationships across multiple environments exceeds learners' time or cognitive budgets, making single-environment controlled experiments more practical despite lower accuracy.",
        "If invariance scores calculated from small samples in each environment are too noisy to reliably distinguish causal from spurious relationships, requiring prohibitively large sample sizes per environment.",
        "If learners misinterpret invariance violations (e.g., due to measurement error or sampling variability) as evidence against causality when relationships are actually causal, leading to false negatives.",
        "If the theory's quantitative thresholds (e.g., I(R) &gt; 0.7, CV &lt; 0.3) are too stringent or too lenient for typical virtual lab scenarios, requiring substantial calibration for practical use."
    ],
    "unaccounted_for": [
        {
            "text": "The theory does not fully specify how to handle non-linear relationships where effect sizes may legitimately vary across environments due to ceiling/floor effects or interaction terms rather than spuriousness.",
            "citations": []
        },
        {
            "text": "Practical constraints on environment construction (feasibility, cost, time) are not integrated into the environment selection framework, which may limit applicability in resource-constrained settings.",
            "citations": []
        },
        {
            "text": "The theory does not address how to handle measurement error or noise that varies across environments, which could be misinterpreted as invariance violations.",
            "citations": []
        },
        {
            "text": "Social and collaborative aspects of multi-environment testing in group inquiry settings are not addressed, including how to coordinate environment selection and share invariance evidence.",
            "citations": []
        },
        {
            "text": "The theory does not specify how to handle temporal dynamics where relationships may change over time within an environment, complicating invariance assessment.",
            "citations": []
        },
        {
            "text": "Edge cases where multiple spurious relationships coincidentally show similar invariance patterns, potentially leading to false positives, are not fully addressed.",
            "citations": []
        }
    ],
    "conflicting_evidence": [
        {
            "text": "Some research suggests that novice learners struggle with transfer and generalization across contexts, which might make multi-environment reasoning particularly challenging.",
            "citations": [
                "Barnett & Ceci (2002) When and where do we apply what we learn? A taxonomy for far transfer, Psychological Bulletin",
                "Detterman (1993) The case for the prosecution: Transfer as an epiphenomenon, Transfer on trial: Intelligence, cognition, and instruction"
            ]
        },
        {
            "text": "Research on the control of variables strategy suggests learners often struggle to systematically vary conditions, which might make strategic environment selection difficult.",
            "citations": [
                "Chen & Klahr (1999) All other things being equal: Acquisition and transfer of the control of variables strategy, Child Development",
                "Kuhn & Dean (2005) Is developing scientific thinking all about learning to control variables?, Psychological Science"
            ]
        },
        {
            "text": "Some causal discovery methods emphasize the importance of interventions over observational diversity, which might suggest that manipulating specific variables is more effective than testing across environments.",
            "citations": [
                "Eberhardt (2007) Causation and Intervention, PhD Thesis, Carnegie Mellon University",
                "Woodward (2003) Making Things Happen: A Theory of Causal Explanation, Oxford University Press"
            ]
        }
    ],
    "special_cases": [
        "In highly constrained virtual environments where only limited environmental variations are possible, invariance testing must be restricted to the feasible variation space, potentially reducing discriminative power.",
        "When causal relationships involve context-dependent mechanisms (e.g., threshold effects, regime changes), apparent invariance violations may reflect genuine causal complexity rather than spuriousness, requiring more nuanced interpretation.",
        "In early stages of inquiry when learners have not yet identified relevant variables to measure, invariance testing may be premature, requiring initial exploratory phases to establish measurement frameworks.",
        "When multiple competing causal models exist, invariance testing must consider whether each model makes distinct predictions about which relationships should be invariant, requiring model-specific environment selection.",
        "For relationships with very small effect sizes, statistical power limitations may make invariance assessment unreliable unless sample sizes per environment are substantially increased.",
        "In domains with strong theoretical constraints (e.g., physical laws), prior knowledge about expected invariance may need to be integrated with empirical invariance testing.",
        "When confounders are themselves causally related to environmental conditions in complex ways, simple environment diversification may not suffice to decorrelate them from causal pathways, requiring more sophisticated intervention strategies."
    ],
    "existing_theory": {
        "likely_classification": "new",
        "references": [
            "Peters et al. (2016) Causal inference by using invariant prediction: identification and confidence intervals [Invariant Causal Prediction (ICP) method for causal discovery, but focused on automated statistical algorithms rather than human inquiry learning in virtual labs]",
            "Arjovsky et al. (2019) Invariant Risk Minimization [Uses invariance principle for machine learning robustness, but not applied to educational contexts or spurious signal detection in inquiry learning]",
            "Schölkopf et al. (2012) On causal and anticausal learning [Discusses stability of causal vs. anticausal relationships, but not specifically about multi-environment testing strategies for learners]",
            "Ben-David et al. (2010) A theory of learning from different domains [Transfer learning theory about domain invariance, but focused on machine learning generalization rather than causal discovery in inquiry]",
            "Rosenbaum (2010) Design of Observational Studies [Discusses robustness and sensitivity analysis in causal inference, but not specifically about multi-environment invariance testing in virtual labs]"
        ]
    },
    "theory_type_general_specific": "specific",
    "reflected_from_theory_index": 2,
    "theory_query": "Build a theory of distractor-robust causal discovery in open-ended virtual labs, including methods to detect, downweight, and refute spurious signals during inquiry.. Please focus on creating new theories that have not been proposed before in the literature.",
    "generation_mode": "llm_baseline_no_evidence",
    "original_theory_id": "theory-119",
    "original_theory_name": "Multi-Environment Invariance Theory for Spurious Signal Detection",
    "model_str": "claude-sonnet-4-5-20250929"
}</code></pre>
        </div>
    </div>
</body>
</html>