<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LLM-Augmented Scientific Consensus Formation Theory - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-2125</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-2125</p>
                <p><strong>Name:</strong> LLM-Augmented Scientific Consensus Formation Theory</p>
                <p><strong>Type:</strong> general</p>
                <p><strong>Theory Query:</strong> Build a theory of how large language models (LLMs) can be used to distill theories from large numbers of scholarly papers, given a specific topic or query.</p>
                <p><strong>Description:</strong> This theory proposes that LLMs can facilitate the formation of scientific consensus by aggregating, weighting, and reconciling evidence from large numbers of papers, identifying robust findings, and highlighting areas of uncertainty or debate. LLMs can model the strength of evidence, detect consensus clusters, and flag outlier or weakly supported claims, thus accelerating the convergence toward reliable scientific knowledge.</p>
                <p><strong>Knowledge Cutoff Year:</strong> -1</p>
                <p><strong>Knowledge Cutoff Month:</strong> -1</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <h3>Statement 0: Evidence Aggregation and Weighting Law (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; LLM &#8594; extracts &#8594; claims_and_evidence_from_many_papers</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; LLM &#8594; aggregates &#8594; evidence_supporting_each_claim<span style="color: #888888;">, and</span></div>
        <div>&#8226; LLM &#8594; assigns &#8594; confidence_weights_to_claims</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Meta-analyses aggregate evidence to assess claim robustness. </li>
    <li>LLMs can perform evidence extraction and basic weighting in biomedical literature mining. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> closely-related-to-existing</p>
            <p><strong>Explanation:</strong> The law extends meta-analytic principles to automated, LLM-based consensus formation.</p>            <p><strong>What Already Exists:</strong> Evidence aggregation and weighting are core to meta-analysis; LLMs can extract and summarize evidence.</p>            <p><strong>What is Novel:</strong> Automated, large-scale, LLM-driven evidence aggregation and weighting across entire literatures is new.</p>
            <p><strong>References:</strong> <ul>
    <li>Glass (1976) Primary, Secondary, and Meta-Analysis of Research [Meta-analysis]</li>
    <li>Lee et al. (2020) BioBERT: a pre-trained biomedical language representation model for biomedical text mining [LLM evidence extraction]</li>
</ul>
            <h3>Statement 1: Consensus and Outlier Detection Law (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; LLM &#8594; has_weighted &#8594; claims_across_corpus</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; LLM &#8594; identifies &#8594; consensus_clusters_of_strongly_supported_claims<span style="color: #888888;">, and</span></div>
        <div>&#8226; LLM &#8594; flags &#8594; outlier_or_weakly_supported_claims</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Consensus formation is a key process in science; LLMs can cluster and classify claims. </li>
    <li>Outlier detection is used in data mining and meta-analysis to identify anomalous results. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> closely-related-to-existing</p>
            <p><strong>Explanation:</strong> The law adapts existing consensus and outlier detection to LLM-based, automated scientific synthesis.</p>            <p><strong>What Already Exists:</strong> Consensus and outlier detection are established in meta-analysis and data mining.</p>            <p><strong>What is Novel:</strong> LLM-driven, automated consensus and outlier detection at the scale of entire literatures is new.</p>
            <p><strong>References:</strong> <ul>
    <li>Ioannidis (2005) Why Most Published Research Findings Are False [Consensus and outlier issues in science]</li>
    <li>Lee et al. (2020) BioBERT: a pre-trained biomedical language representation model for biomedical text mining [LLM evidence extraction]</li>
</ul>
            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>LLMs will be able to identify robust, consensus-supported findings in a field more rapidly than traditional meta-analyses.</li>
                <li>LLMs will flag weakly supported or anomalous claims, prompting further investigation or replication.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>LLMs may reveal hidden consensus or persistent uncertainty in fields previously thought to be settled.</li>
                <li>LLMs could identify systematic biases in the literature that affect consensus formation.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>If LLMs fail to distinguish between strongly and weakly supported claims, the theory is challenged.</li>
                <li>If LLM consensus clusters do not align with expert consensus, the theory is falsified.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>The effect of publication bias and selective reporting on LLM-driven consensus is not fully addressed. </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> closely-related-to-existing</p>
            <p><strong>Explanation:</strong> The theory extends meta-analytic and data mining principles to LLM-based, automated scientific synthesis.</p>
            <p><strong>References:</strong> <ul>
    <li>Glass (1976) Primary, Secondary, and Meta-Analysis of Research [Meta-analysis]</li>
    <li>Ioannidis (2005) Why Most Published Research Findings Are False [Consensus and outlier issues in science]</li>
    <li>Lee et al. (2020) BioBERT: a pre-trained biomedical language representation model for biomedical text mining [LLM evidence extraction]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "LLM-Augmented Scientific Consensus Formation Theory",
    "theory_description": "This theory proposes that LLMs can facilitate the formation of scientific consensus by aggregating, weighting, and reconciling evidence from large numbers of papers, identifying robust findings, and highlighting areas of uncertainty or debate. LLMs can model the strength of evidence, detect consensus clusters, and flag outlier or weakly supported claims, thus accelerating the convergence toward reliable scientific knowledge.",
    "theory_statements": [
        {
            "law": {
                "law_name": "Evidence Aggregation and Weighting Law",
                "if": [
                    {
                        "subject": "LLM",
                        "relation": "extracts",
                        "object": "claims_and_evidence_from_many_papers"
                    }
                ],
                "then": [
                    {
                        "subject": "LLM",
                        "relation": "aggregates",
                        "object": "evidence_supporting_each_claim"
                    },
                    {
                        "subject": "LLM",
                        "relation": "assigns",
                        "object": "confidence_weights_to_claims"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Meta-analyses aggregate evidence to assess claim robustness.",
                        "uuids": []
                    },
                    {
                        "text": "LLMs can perform evidence extraction and basic weighting in biomedical literature mining.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Evidence aggregation and weighting are core to meta-analysis; LLMs can extract and summarize evidence.",
                    "what_is_novel": "Automated, large-scale, LLM-driven evidence aggregation and weighting across entire literatures is new.",
                    "classification_explanation": "The law extends meta-analytic principles to automated, LLM-based consensus formation.",
                    "likely_classification": "closely-related-to-existing",
                    "references": [
                        "Glass (1976) Primary, Secondary, and Meta-Analysis of Research [Meta-analysis]",
                        "Lee et al. (2020) BioBERT: a pre-trained biomedical language representation model for biomedical text mining [LLM evidence extraction]"
                    ]
                }
            }
        },
        {
            "law": {
                "law_name": "Consensus and Outlier Detection Law",
                "if": [
                    {
                        "subject": "LLM",
                        "relation": "has_weighted",
                        "object": "claims_across_corpus"
                    }
                ],
                "then": [
                    {
                        "subject": "LLM",
                        "relation": "identifies",
                        "object": "consensus_clusters_of_strongly_supported_claims"
                    },
                    {
                        "subject": "LLM",
                        "relation": "flags",
                        "object": "outlier_or_weakly_supported_claims"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Consensus formation is a key process in science; LLMs can cluster and classify claims.",
                        "uuids": []
                    },
                    {
                        "text": "Outlier detection is used in data mining and meta-analysis to identify anomalous results.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Consensus and outlier detection are established in meta-analysis and data mining.",
                    "what_is_novel": "LLM-driven, automated consensus and outlier detection at the scale of entire literatures is new.",
                    "classification_explanation": "The law adapts existing consensus and outlier detection to LLM-based, automated scientific synthesis.",
                    "likely_classification": "closely-related-to-existing",
                    "references": [
                        "Ioannidis (2005) Why Most Published Research Findings Are False [Consensus and outlier issues in science]",
                        "Lee et al. (2020) BioBERT: a pre-trained biomedical language representation model for biomedical text mining [LLM evidence extraction]"
                    ]
                }
            }
        }
    ],
    "new_predictions_likely": [
        "LLMs will be able to identify robust, consensus-supported findings in a field more rapidly than traditional meta-analyses.",
        "LLMs will flag weakly supported or anomalous claims, prompting further investigation or replication."
    ],
    "new_predictions_unknown": [
        "LLMs may reveal hidden consensus or persistent uncertainty in fields previously thought to be settled.",
        "LLMs could identify systematic biases in the literature that affect consensus formation."
    ],
    "negative_experiments": [
        "If LLMs fail to distinguish between strongly and weakly supported claims, the theory is challenged.",
        "If LLM consensus clusters do not align with expert consensus, the theory is falsified."
    ],
    "unaccounted_for": [
        {
            "text": "The effect of publication bias and selective reporting on LLM-driven consensus is not fully addressed.",
            "uuids": []
        }
    ],
    "conflicting_evidence": [
        {
            "text": "LLMs may be misled by highly cited but methodologically weak studies.",
            "uuids": []
        }
    ],
    "special_cases": [
        "Fields with little replication or high heterogeneity may limit consensus detection.",
        "Rapidly evolving literatures may challenge the stability of consensus clusters."
    ],
    "existing_theory": {
        "what_already_exists": "Consensus formation and outlier detection are established in meta-analysis and data mining.",
        "what_is_novel": "Automated, LLM-driven consensus formation and outlier detection at scale is new.",
        "classification_explanation": "The theory extends meta-analytic and data mining principles to LLM-based, automated scientific synthesis.",
        "likely_classification": "closely-related-to-existing",
        "references": [
            "Glass (1976) Primary, Secondary, and Meta-Analysis of Research [Meta-analysis]",
            "Ioannidis (2005) Why Most Published Research Findings Are False [Consensus and outlier issues in science]",
            "Lee et al. (2020) BioBERT: a pre-trained biomedical language representation model for biomedical text mining [LLM evidence extraction]"
        ]
    },
    "reflected_from_theory_index": 3,
    "type": "general",
    "version": "built-theory-from-results-single-theory-reflection2-nov14-2025-LLM-BASELINE-no-evidence-without-matched-control-theory-name",
    "theory_query": "Build a theory of how large language models (LLMs) can be used to distill theories from large numbers of scholarly papers, given a specific topic or query.",
    "original_theory_id": "theory-668",
    "original_theory_name": "Hybrid Modular Orchestration Theory (HMOT)",
    "provide_matched_control_thery_name": false,
    "matched_control_theory_name": null,
    "model_str": "openai/gpt-4.1-2025-04-14"
}</code></pre>
        </div>
    </div>
</body>
</html>