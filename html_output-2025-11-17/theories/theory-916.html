<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Hierarchical Episodic-Semantic Memory Theory for LLM Agents in Text Games - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-916</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-916</p>
                <p><strong>Name:</strong> Hierarchical Episodic-Semantic Memory Theory for LLM Agents in Text Games</p>
                <p><strong>Type:</strong> general</p>
                <p><strong>Theory Query:</strong> Build a theory of how LLM agents for text games can best use memory to solve text game tasks.</p>
                <p><strong>Description:</strong> This theory posits that LLM agents can best solve text game tasks by maintaining a hierarchical memory system that separates and dynamically integrates episodic (event-based, context-specific) and semantic (generalized, abstracted) memories. The agent should use episodic memory to track recent, contextually relevant events and semantic memory to store generalized knowledge, rules, and strategies. The agent's performance is maximized when it can flexibly retrieve, update, and reconcile these two memory types based on the demands of the current game state.</p>
                <p><strong>Knowledge Cutoff Year:</strong> -1</p>
                <p><strong>Knowledge Cutoff Month:</strong> -1</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <h3>Statement 0: Hierarchical Memory Integration Law (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; LLM agent &#8594; maintains &#8594; episodic memory<span style="color: #888888;">, and</span></div>
        <div>&#8226; LLM agent &#8594; maintains &#8594; semantic memory<span style="color: #888888;">, and</span></div>
        <div>&#8226; text game task &#8594; requires &#8594; contextual reasoning and generalization</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; LLM agent &#8594; achieves &#8594; higher task performance</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Human cognition leverages both episodic and semantic memory for complex reasoning and problem-solving. </li>
    <li>LLM agents with memory modules that separate recent context from general knowledge outperform those with flat memory. </li>
    <li>Hierarchical memory architectures in neural networks enable better handling of long-term dependencies and generalization. </li>
    <li>Text games often require both remembering specific past events (e.g., which doors are locked) and applying general rules (e.g., keys open doors). </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> While the episodic-semantic distinction is known, its hierarchical, dynamic integration for LLM agents in interactive text environments is a new application.</p>            <p><strong>What Already Exists:</strong> The separation of episodic and semantic memory is well-established in cognitive science and has been explored in some neural architectures.</p>            <p><strong>What is Novel:</strong> The explicit hierarchical integration and dynamic reconciliation of these memory types for LLM agents in text games is novel.</p>
            <p><strong>References:</strong> <ul>
    <li>Tulving (1972) Episodic and semantic memory [establishes the distinction in human memory]</li>
    <li>Graves et al. (2016) Hybrid computing using a neural network with dynamic external memory [neural memory architectures]</li>
    <li>Madotto et al. (2020) Memory Grounded Conversational Reasoning [memory in dialogue agents, but not hierarchical or text-game specific]</li>
</ul>
            <h3>Statement 1: Dynamic Memory Reconciliation Law (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; LLM agent &#8594; detects &#8594; conflict or ambiguity between episodic and semantic memory</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; LLM agent &#8594; prioritizes &#8594; episodic memory for immediate context<span style="color: #888888;">, and</span></div>
        <div>&#8226; LLM agent &#8594; updates &#8594; semantic memory if new patterns are consistently observed</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Humans resolve memory conflicts by prioritizing recent, context-specific information but update general knowledge when patterns persist. </li>
    <li>LLM agents that adapt their general knowledge based on repeated episodic experiences show improved generalization. </li>
    <li>Dynamic memory updating is critical for adapting to new rules or exceptions in text games. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> The principle is inspired by human cognition, but its application and formalization for LLM agent memory management is new.</p>            <p><strong>What Already Exists:</strong> Conflict resolution between memory types is discussed in cognitive science, but not formalized for LLM agents.</p>            <p><strong>What is Novel:</strong> The law's explicit operationalization for LLM agents in text games, including when and how to update semantic memory, is novel.</p>
            <p><strong>References:</strong> <ul>
    <li>McClelland et al. (1995) Why there are complementary learning systems in the hippocampus and neocortex [complementary learning systems]</li>
    <li>Khandelwal et al. (2019) Generalization through Memorization: Nearest Neighbor Language Models [memory in LMs, but not hierarchical or dynamic reconciliation]</li>
</ul>
            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>LLM agents with explicit hierarchical episodic-semantic memory modules will outperform agents with only flat or undifferentiated memory on multi-step text game tasks.</li>
                <li>When a text game introduces a novel rule, agents with dynamic memory reconciliation will adapt more quickly than those with static memory.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>If an LLM agent is given a memory system that can dynamically reweight episodic and semantic memory based on task uncertainty, it may develop emergent meta-reasoning strategies.</li>
                <li>Hierarchical memory systems may enable LLM agents to transfer strategies across different text games with minimal retraining.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>If agents with hierarchical episodic-semantic memory do not outperform flat-memory agents on context-dependent tasks, the theory is called into question.</li>
                <li>If dynamic reconciliation between memory types leads to catastrophic forgetting or instability, the theory's assumptions may be flawed.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>The impact of memory system size and computational constraints on agent performance is not addressed. </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> somewhat-related-to-existing</p>
            <p><strong>Explanation:</strong> The theory builds on cognitive science but introduces a new operational framework for LLM agents in interactive environments.</p>
            <p><strong>References:</strong> <ul>
    <li>Tulving (1972) Episodic and semantic memory [episodic/semantic distinction]</li>
    <li>Graves et al. (2016) Hybrid computing using a neural network with dynamic external memory [neural memory architectures]</li>
    <li>Madotto et al. (2020) Memory Grounded Conversational Reasoning [memory in dialogue agents]</li>
    <li>Khandelwal et al. (2019) Generalization through Memorization: Nearest Neighbor Language Models [memory in LMs]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Hierarchical Episodic-Semantic Memory Theory for LLM Agents in Text Games",
    "theory_description": "This theory posits that LLM agents can best solve text game tasks by maintaining a hierarchical memory system that separates and dynamically integrates episodic (event-based, context-specific) and semantic (generalized, abstracted) memories. The agent should use episodic memory to track recent, contextually relevant events and semantic memory to store generalized knowledge, rules, and strategies. The agent's performance is maximized when it can flexibly retrieve, update, and reconcile these two memory types based on the demands of the current game state.",
    "theory_statements": [
        {
            "law": {
                "law_name": "Hierarchical Memory Integration Law",
                "if": [
                    {
                        "subject": "LLM agent",
                        "relation": "maintains",
                        "object": "episodic memory"
                    },
                    {
                        "subject": "LLM agent",
                        "relation": "maintains",
                        "object": "semantic memory"
                    },
                    {
                        "subject": "text game task",
                        "relation": "requires",
                        "object": "contextual reasoning and generalization"
                    }
                ],
                "then": [
                    {
                        "subject": "LLM agent",
                        "relation": "achieves",
                        "object": "higher task performance"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Human cognition leverages both episodic and semantic memory for complex reasoning and problem-solving.",
                        "uuids": []
                    },
                    {
                        "text": "LLM agents with memory modules that separate recent context from general knowledge outperform those with flat memory.",
                        "uuids": []
                    },
                    {
                        "text": "Hierarchical memory architectures in neural networks enable better handling of long-term dependencies and generalization.",
                        "uuids": []
                    },
                    {
                        "text": "Text games often require both remembering specific past events (e.g., which doors are locked) and applying general rules (e.g., keys open doors).",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "The separation of episodic and semantic memory is well-established in cognitive science and has been explored in some neural architectures.",
                    "what_is_novel": "The explicit hierarchical integration and dynamic reconciliation of these memory types for LLM agents in text games is novel.",
                    "classification_explanation": "While the episodic-semantic distinction is known, its hierarchical, dynamic integration for LLM agents in interactive text environments is a new application.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Tulving (1972) Episodic and semantic memory [establishes the distinction in human memory]",
                        "Graves et al. (2016) Hybrid computing using a neural network with dynamic external memory [neural memory architectures]",
                        "Madotto et al. (2020) Memory Grounded Conversational Reasoning [memory in dialogue agents, but not hierarchical or text-game specific]"
                    ]
                }
            }
        },
        {
            "law": {
                "law_name": "Dynamic Memory Reconciliation Law",
                "if": [
                    {
                        "subject": "LLM agent",
                        "relation": "detects",
                        "object": "conflict or ambiguity between episodic and semantic memory"
                    }
                ],
                "then": [
                    {
                        "subject": "LLM agent",
                        "relation": "prioritizes",
                        "object": "episodic memory for immediate context"
                    },
                    {
                        "subject": "LLM agent",
                        "relation": "updates",
                        "object": "semantic memory if new patterns are consistently observed"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Humans resolve memory conflicts by prioritizing recent, context-specific information but update general knowledge when patterns persist.",
                        "uuids": []
                    },
                    {
                        "text": "LLM agents that adapt their general knowledge based on repeated episodic experiences show improved generalization.",
                        "uuids": []
                    },
                    {
                        "text": "Dynamic memory updating is critical for adapting to new rules or exceptions in text games.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Conflict resolution between memory types is discussed in cognitive science, but not formalized for LLM agents.",
                    "what_is_novel": "The law's explicit operationalization for LLM agents in text games, including when and how to update semantic memory, is novel.",
                    "classification_explanation": "The principle is inspired by human cognition, but its application and formalization for LLM agent memory management is new.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "McClelland et al. (1995) Why there are complementary learning systems in the hippocampus and neocortex [complementary learning systems]",
                        "Khandelwal et al. (2019) Generalization through Memorization: Nearest Neighbor Language Models [memory in LMs, but not hierarchical or dynamic reconciliation]"
                    ]
                }
            }
        }
    ],
    "new_predictions_likely": [
        "LLM agents with explicit hierarchical episodic-semantic memory modules will outperform agents with only flat or undifferentiated memory on multi-step text game tasks.",
        "When a text game introduces a novel rule, agents with dynamic memory reconciliation will adapt more quickly than those with static memory."
    ],
    "new_predictions_unknown": [
        "If an LLM agent is given a memory system that can dynamically reweight episodic and semantic memory based on task uncertainty, it may develop emergent meta-reasoning strategies.",
        "Hierarchical memory systems may enable LLM agents to transfer strategies across different text games with minimal retraining."
    ],
    "negative_experiments": [
        "If agents with hierarchical episodic-semantic memory do not outperform flat-memory agents on context-dependent tasks, the theory is called into question.",
        "If dynamic reconciliation between memory types leads to catastrophic forgetting or instability, the theory's assumptions may be flawed."
    ],
    "unaccounted_for": [
        {
            "text": "The impact of memory system size and computational constraints on agent performance is not addressed.",
            "uuids": []
        }
    ],
    "conflicting_evidence": [
        {
            "text": "Some LLM agents with simple context windows have achieved strong performance on certain text games, suggesting hierarchical memory may not always be necessary.",
            "uuids": []
        }
    ],
    "special_cases": [
        "In highly deterministic or short-horizon games, flat memory may suffice.",
        "If the game world is fully observable at each step, episodic memory may be less critical."
    ],
    "existing_theory": {
        "what_already_exists": "Episodic and semantic memory separation is established in cognitive science and some neural architectures.",
        "what_is_novel": "The hierarchical, dynamic integration and reconciliation of these memory types for LLM agents in text games is novel.",
        "classification_explanation": "The theory builds on cognitive science but introduces a new operational framework for LLM agents in interactive environments.",
        "likely_classification": "somewhat-related-to-existing",
        "references": [
            "Tulving (1972) Episodic and semantic memory [episodic/semantic distinction]",
            "Graves et al. (2016) Hybrid computing using a neural network with dynamic external memory [neural memory architectures]",
            "Madotto et al. (2020) Memory Grounded Conversational Reasoning [memory in dialogue agents]",
            "Khandelwal et al. (2019) Generalization through Memorization: Nearest Neighbor Language Models [memory in LMs]"
        ]
    },
    "reflected_from_theory_index": 0,
    "type": "general",
    "version": "built-theory-from-results-single-theory-reflection2-nov14-2025-LLM-BASELINE-no-evidence-without-matched-control-theory-name",
    "theory_query": "Build a theory of how LLM agents for text games can best use memory to solve text game tasks.",
    "original_theory_id": "theory-590",
    "original_theory_name": "Structured and Modular Memory Enables Generalization and Robustness in LLM Text Game Agents",
    "provide_matched_control_thery_name": false,
    "matched_control_theory_name": null,
    "model_str": "openai/gpt-4.1-2025-04-14"
}</code></pre>
        </div>
    </div>
</body>
</html>