<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LLM-Augmented Symbolic Discovery Pipeline Theory - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-521</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-521</p>
                <p><strong>Name:</strong> LLM-Augmented Symbolic Discovery Pipeline Theory</p>
                <p><strong>Type:</strong> general</p>
                <p><strong>Theory Query:</strong> Build a theory of how large language models (LLMs) can be used to distill quantitative laws from large numbers of scholarly input papers, based on the following results.</p>
                <p><strong>Description:</strong> Large language models (LLMs) can serve as generative engines for candidate symbolic expressions, programmatic models, or hypotheses, but robust distillation of quantitative laws from large scholarly corpora requires their integration with external evaluators, retrieval-augmented pipelines, and iterative optimization loops. LLMs alone excel at memorization, extraction, and creative proposal, but only when paired with systematic evaluation, parameter optimization, and context-aware retrieval can they reliably discover, validate, and generalize new quantitative laws from heterogeneous scientific literature and data.</p>
                <p><strong>Knowledge Cutoff Year:</strong> 2024</p>
                <p><strong>Knowledge Cutoff Month:</strong> 6</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <h3>Statement 0: LLM Proposal + External Evaluation Law (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; LLM &#8594; is_used_as &#8594; generator_of_candidate_models_or_equations<span style="color: #888888;">, and</span></div>
        <div>&#8226; external_evaluator &#8594; is_available &#8594; for_scoring_candidate_models</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; LLM+evaluator_pipeline &#8594; can_discover &#8594; novel_quantitative_laws_or_models</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>FunSearch, LLM-SR, ICSR, BoxLM, SGA, and SymbolicGPT all use LLMs to generate candidate programs/equations and external evaluators (objective functions, simulation, or parameter optimization) to select and refine discoveries, leading to new mathematical constructions and improved model discovery. <a href="../results/extraction-result-3653.html#e3653.0" class="evidence-link">[e3653.0]</a> <a href="../results/extraction-result-3652.html#e3652.0" class="evidence-link">[e3652.0]</a> <a href="../results/extraction-result-3647.html#e3647.0" class="evidence-link">[e3647.0]</a> <a href="../results/extraction-result-3824.html#e3824.0" class="evidence-link">[e3824.0]</a> <a href="../results/extraction-result-3654.html#e3654.0" class="evidence-link">[e3654.0]</a> <a href="../results/extraction-result-3812.html#e3812.0" class="evidence-link">[e3812.0]</a> </li>
    <li>Evolution-through-LLM, Language-model Crossover, and Meyerson2023_symbolic_regression demonstrate LLMs as mutation/crossover operators in evolutionary pipelines, with external evaluators selecting for high-performing symbolic expressions. <a href="../results/extraction-result-3653.html#e3653.2" class="evidence-link">[e3653.2]</a> <a href="../results/extraction-result-3653.html#e3653.3" class="evidence-link">[e3653.3]</a> <a href="../results/extraction-result-3813.html#e3813.0" class="evidence-link">[e3813.0]</a> </li>
    <li>SGA's bilevel optimization framework shows that LLMs proposing symbolic hypotheses, when paired with differentiable simulation and parameter optimization, outperform both LLM-only and classical symbolic regression baselines. <a href="../results/extraction-result-3654.html#e3654.0" class="evidence-link">[e3654.0]</a> </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p class="empty-note">No existing law comparison provided.</p>
            <h3>Statement 1: Retrieval-Augmented and Modular Pipeline Law (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; LLM_pipeline &#8594; incorporates &#8594; retrieval-augmentation_and_modular_reasoning_steps<span style="color: #888888;">, and</span></div>
        <div>&#8226; input &#8594; is &#8594; large_scholarly_corpus_or_multi-document_dataset</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; pipeline &#8594; can_extract_and_standardize &#8594; quantitative_results_and_relationships_across_documents</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>TrialMind and DATAVOYAGER use retrieval-augmented generation, chain-of-thought prompting, and programmatic standardization to extract, standardize, and synthesize quantitative results from large numbers of papers, outperforming vanilla LLM prompting. <a href="../results/extraction-result-3820.html#e3820.0" class="evidence-link">[e3820.0]</a> <a href="../results/extraction-result-3823.html#e3823.0" class="evidence-link">[e3823.0]</a> </li>
    <li>Wang et al. 2023b and Materials text-mining (Kononova et al.) highlight the importance of accurate retrieval, information extraction, and multi-step reasoning for linking datasets to scientific literature and surfacing candidate quantitative relationships. <a href="../results/extraction-result-3823.html#e3823.5" class="evidence-link">[e3823.5]</a> <a href="../results/extraction-result-3817.html#e3817.4" class="evidence-link">[e3817.4]</a> </li>
    <li>LLM-based literature knowledge extraction (mentioned) and LLM-based theory ingestion (proposed) suggest that LLMs, when combined with retrieval and modular reasoning, could distill theoretical frameworks and equations from large corpora. <a href="../results/extraction-result-3648.html#e3648.1" class="evidence-link">[e3648.1]</a> <a href="../results/extraction-result-3807.html#e3807.1" class="evidence-link">[e3807.1]</a> </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p class="empty-note">No existing law comparison provided.</p>
            <h3>Statement 2: LLM Memorization vs. Discovery Law (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; LLM &#8594; is_trained_on &#8594; large_scientific_corpus<span style="color: #888888;">, and</span></div>
        <div>&#8226; task &#8594; is &#8594; extraction_of_known_equations_or_facts</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; LLM &#8594; can_memorize_and_recall &#8594; known_equations_and_facts</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Galactica and LaTeX Equation Probe show high accuracy in recalling known equations, but do not demonstrate novel law discovery from literature. <a href="../results/extraction-result-3821.html#e3821.0" class="evidence-link">[e3821.0]</a> <a href="../results/extraction-result-3821.html#e3821.3" class="evidence-link">[e3821.3]</a> </li>
    <li>Chemical Reaction / Domain Probe and Extraction vs Discovery Note show that LLMs can extract and reproduce equations and relations present in the training corpus, but do not present a pipeline for discovering new quantitative laws by aggregating and symbolically regressing across many heterogeneous papers. <a href="../results/extraction-result-3821.html#e3821.1" class="evidence-link">[e3821.1]</a> <a href="../results/extraction-result-3821.html#e3821.3" class="evidence-link">[e3821.3]</a> </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p class="empty-note">No existing law comparison provided.</p>
            <h3>Statement 3: Iterative Proposal-Critique-Refinement Law (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; LLM_pipeline &#8594; uses &#8594; iterative_propose_and_critique_loops</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; pipeline &#8594; improves &#8594; quality_and_generalizability_of_discovered_laws</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>BoxLM, AutoStat-LLM, and OPRO demonstrate that iterative propose-critique-refine cycles with LLMs and evaluators lead to improved model discovery and optimization. <a href="../results/extraction-result-3824.html#e3824.0" class="evidence-link">[e3824.0]</a> <a href="../results/extraction-result-3655.html#e3655.0" class="evidence-link">[e3655.0]</a> <a href="../results/extraction-result-3647.html#e3647.2" class="evidence-link">[e3647.2]</a> </li>
    <li>ICSR and LLM-SR use optimization-by-prompting and iterative refinement, leading to improved symbolic regression and equation discovery performance. <a href="../results/extraction-result-3647.html#e3647.0" class="evidence-link">[e3647.0]</a> <a href="../results/extraction-result-3652.html#e3652.0" class="evidence-link">[e3652.0]</a> </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p class="empty-note">No existing law comparison provided.</p>
            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>If a new LLM-based pipeline is constructed that combines LLM proposal, retrieval-augmented context, and external evaluators, it will outperform vanilla LLM prompting on quantitative law extraction from a new scientific domain.</li>
                <li>LLM+evaluator pipelines will be able to discover new, interpretable symbolic relationships in domains where sufficient numeric data and evaluators are available, even if the LLM was not explicitly fine-tuned for that domain.</li>
                <li>Iterative propose-critique-refine cycles will yield more generalizable and lower-complexity equations than single-pass LLM generation or classical symbolic regression in noisy or high-dimensional settings.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>A fully autonomous LLM+retrieval+evaluator pipeline, given access to the entire arXiv or PubMed corpus, will be able to rediscover or even surpass some human-discovered physical laws (e.g., in materials science or biology) without human intervention.</li>
                <li>LLM-augmented pipelines will be able to synthesize cross-domain quantitative laws (e.g., linking chemistry and physics) by aggregating and reasoning over heterogeneous literature, leading to new scientific insights not previously known.</li>
                <li>LLM+evaluator pipelines, when applied to multi-modal scientific corpora (text, tables, figures), will be able to extract and formalize new quantitative relationships that are not explicitly stated in any single paper.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>If an LLM+evaluator pipeline fails to outperform vanilla LLM prompting or classical symbolic regression on a new domain, this would challenge the necessity of the modular pipeline.</li>
                <li>If LLMs, even when paired with retrieval and evaluators, consistently fail to generalize or discover new laws in domains with abundant data, this would call into question the theory's generality.</li>
                <li>If iterative propose-critique-refine cycles do not improve the quality or generalizability of discovered laws compared to single-pass LLM generation, the value of iterative refinement would be undermined.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>Cases where LLMs are fine-tuned on simulation pairs (e.g., FT-LLM for metasurfaces) but do not yield improved physical explanations or interpretable laws, suggesting that fine-tuning alone is insufficient for discovery. <a href="../results/extraction-result-3648.html#e3648.0" class="evidence-link">[e3648.0]</a> </li>
    <li>MeLM and similar models can learn implicit operator mappings from data but do not produce explicit symbolic laws or equations, indicating a gap between predictive modeling and symbolic law extraction. <a href="../results/extraction-result-3807.html#e3807.0" class="evidence-link">[e3807.0]</a> </li>
    <li>Transformer-symbol bootstrap and Transforming-the-Bootstrap show that domain-specific Transformers can learn to predict symbolic coefficients in highly structured physics problems, but do not generalize to law discovery from heterogeneous literature. <a href="../results/extraction-result-3811.html#e3811.0" class="evidence-link">[e3811.0]</a> <a href="../results/extraction-result-3655.html#e3655.1" class="evidence-link">[e3655.1]</a> </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> closely-related-to-existing</p>
            <p><strong>Explanation:</strong> No explanation provided.</p>
            <p><strong>References:</strong> <ul>
    <li>Romera-Paredes et al. (2023) Mathematical discoveries from program search with large language models [LLM+evaluator program search, FunSearch]</li>
    <li>Shojaee et al. (2024) Scientific equation discovery via programming with large language models [LLM-SR, programmatic equation discovery]</li>
    <li>Meyerson et al. (2023) Language model crossover: Variation through few-shot prompting [LLM as crossover/mutation operator in symbolic regression]</li>
    <li>Schmidt & Lipson (2009) Distilling free-form natural laws from experimental data [classical symbolic regression, not LLM-based but similar in spirit]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "LLM-Augmented Symbolic Discovery Pipeline Theory",
    "theory_description": "Large language models (LLMs) can serve as generative engines for candidate symbolic expressions, programmatic models, or hypotheses, but robust distillation of quantitative laws from large scholarly corpora requires their integration with external evaluators, retrieval-augmented pipelines, and iterative optimization loops. LLMs alone excel at memorization, extraction, and creative proposal, but only when paired with systematic evaluation, parameter optimization, and context-aware retrieval can they reliably discover, validate, and generalize new quantitative laws from heterogeneous scientific literature and data.",
    "theory_statements": [
        {
            "law": {
                "law_name": "LLM Proposal + External Evaluation Law",
                "if": [
                    {
                        "subject": "LLM",
                        "relation": "is_used_as",
                        "object": "generator_of_candidate_models_or_equations"
                    },
                    {
                        "subject": "external_evaluator",
                        "relation": "is_available",
                        "object": "for_scoring_candidate_models"
                    }
                ],
                "then": [
                    {
                        "subject": "LLM+evaluator_pipeline",
                        "relation": "can_discover",
                        "object": "novel_quantitative_laws_or_models"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "FunSearch, LLM-SR, ICSR, BoxLM, SGA, and SymbolicGPT all use LLMs to generate candidate programs/equations and external evaluators (objective functions, simulation, or parameter optimization) to select and refine discoveries, leading to new mathematical constructions and improved model discovery.",
                        "uuids": [
                            "e3653.0",
                            "e3652.0",
                            "e3647.0",
                            "e3824.0",
                            "e3654.0",
                            "e3812.0"
                        ]
                    },
                    {
                        "text": "Evolution-through-LLM, Language-model Crossover, and Meyerson2023_symbolic_regression demonstrate LLMs as mutation/crossover operators in evolutionary pipelines, with external evaluators selecting for high-performing symbolic expressions.",
                        "uuids": [
                            "e3653.2",
                            "e3653.3",
                            "e3813.0"
                        ]
                    },
                    {
                        "text": "SGA's bilevel optimization framework shows that LLMs proposing symbolic hypotheses, when paired with differentiable simulation and parameter optimization, outperform both LLM-only and classical symbolic regression baselines.",
                        "uuids": [
                            "e3654.0"
                        ]
                    }
                ],
                "qual_or_quant": "qualitative"
            }
        },
        {
            "law": {
                "law_name": "Retrieval-Augmented and Modular Pipeline Law",
                "if": [
                    {
                        "subject": "LLM_pipeline",
                        "relation": "incorporates",
                        "object": "retrieval-augmentation_and_modular_reasoning_steps"
                    },
                    {
                        "subject": "input",
                        "relation": "is",
                        "object": "large_scholarly_corpus_or_multi-document_dataset"
                    }
                ],
                "then": [
                    {
                        "subject": "pipeline",
                        "relation": "can_extract_and_standardize",
                        "object": "quantitative_results_and_relationships_across_documents"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "TrialMind and DATAVOYAGER use retrieval-augmented generation, chain-of-thought prompting, and programmatic standardization to extract, standardize, and synthesize quantitative results from large numbers of papers, outperforming vanilla LLM prompting.",
                        "uuids": [
                            "e3820.0",
                            "e3823.0"
                        ]
                    },
                    {
                        "text": "Wang et al. 2023b and Materials text-mining (Kononova et al.) highlight the importance of accurate retrieval, information extraction, and multi-step reasoning for linking datasets to scientific literature and surfacing candidate quantitative relationships.",
                        "uuids": [
                            "e3823.5",
                            "e3817.4"
                        ]
                    },
                    {
                        "text": "LLM-based literature knowledge extraction (mentioned) and LLM-based theory ingestion (proposed) suggest that LLMs, when combined with retrieval and modular reasoning, could distill theoretical frameworks and equations from large corpora.",
                        "uuids": [
                            "e3648.1",
                            "e3807.1"
                        ]
                    }
                ],
                "qual_or_quant": "qualitative"
            }
        },
        {
            "law": {
                "law_name": "LLM Memorization vs. Discovery Law",
                "if": [
                    {
                        "subject": "LLM",
                        "relation": "is_trained_on",
                        "object": "large_scientific_corpus"
                    },
                    {
                        "subject": "task",
                        "relation": "is",
                        "object": "extraction_of_known_equations_or_facts"
                    }
                ],
                "then": [
                    {
                        "subject": "LLM",
                        "relation": "can_memorize_and_recall",
                        "object": "known_equations_and_facts"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Galactica and LaTeX Equation Probe show high accuracy in recalling known equations, but do not demonstrate novel law discovery from literature.",
                        "uuids": [
                            "e3821.0",
                            "e3821.3"
                        ]
                    },
                    {
                        "text": "Chemical Reaction / Domain Probe and Extraction vs Discovery Note show that LLMs can extract and reproduce equations and relations present in the training corpus, but do not present a pipeline for discovering new quantitative laws by aggregating and symbolically regressing across many heterogeneous papers.",
                        "uuids": [
                            "e3821.1",
                            "e3821.3"
                        ]
                    }
                ],
                "qual_or_quant": "qualitative"
            }
        },
        {
            "law": {
                "law_name": "Iterative Proposal-Critique-Refinement Law",
                "if": [
                    {
                        "subject": "LLM_pipeline",
                        "relation": "uses",
                        "object": "iterative_propose_and_critique_loops"
                    }
                ],
                "then": [
                    {
                        "subject": "pipeline",
                        "relation": "improves",
                        "object": "quality_and_generalizability_of_discovered_laws"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "BoxLM, AutoStat-LLM, and OPRO demonstrate that iterative propose-critique-refine cycles with LLMs and evaluators lead to improved model discovery and optimization.",
                        "uuids": [
                            "e3824.0",
                            "e3655.0",
                            "e3647.2"
                        ]
                    },
                    {
                        "text": "ICSR and LLM-SR use optimization-by-prompting and iterative refinement, leading to improved symbolic regression and equation discovery performance.",
                        "uuids": [
                            "e3647.0",
                            "e3652.0"
                        ]
                    }
                ],
                "qual_or_quant": "qualitative"
            }
        }
    ],
    "new_predictions_likely": [
        "If a new LLM-based pipeline is constructed that combines LLM proposal, retrieval-augmented context, and external evaluators, it will outperform vanilla LLM prompting on quantitative law extraction from a new scientific domain.",
        "LLM+evaluator pipelines will be able to discover new, interpretable symbolic relationships in domains where sufficient numeric data and evaluators are available, even if the LLM was not explicitly fine-tuned for that domain.",
        "Iterative propose-critique-refine cycles will yield more generalizable and lower-complexity equations than single-pass LLM generation or classical symbolic regression in noisy or high-dimensional settings."
    ],
    "new_predictions_unknown": [
        "A fully autonomous LLM+retrieval+evaluator pipeline, given access to the entire arXiv or PubMed corpus, will be able to rediscover or even surpass some human-discovered physical laws (e.g., in materials science or biology) without human intervention.",
        "LLM-augmented pipelines will be able to synthesize cross-domain quantitative laws (e.g., linking chemistry and physics) by aggregating and reasoning over heterogeneous literature, leading to new scientific insights not previously known.",
        "LLM+evaluator pipelines, when applied to multi-modal scientific corpora (text, tables, figures), will be able to extract and formalize new quantitative relationships that are not explicitly stated in any single paper."
    ],
    "negative_experiments": [
        "If an LLM+evaluator pipeline fails to outperform vanilla LLM prompting or classical symbolic regression on a new domain, this would challenge the necessity of the modular pipeline.",
        "If LLMs, even when paired with retrieval and evaluators, consistently fail to generalize or discover new laws in domains with abundant data, this would call into question the theory's generality.",
        "If iterative propose-critique-refine cycles do not improve the quality or generalizability of discovered laws compared to single-pass LLM generation, the value of iterative refinement would be undermined."
    ],
    "unaccounted_for": [
        {
            "text": "Cases where LLMs are fine-tuned on simulation pairs (e.g., FT-LLM for metasurfaces) but do not yield improved physical explanations or interpretable laws, suggesting that fine-tuning alone is insufficient for discovery.",
            "uuids": [
                "e3648.0"
            ]
        },
        {
            "text": "MeLM and similar models can learn implicit operator mappings from data but do not produce explicit symbolic laws or equations, indicating a gap between predictive modeling and symbolic law extraction.",
            "uuids": [
                "e3807.0"
            ]
        },
        {
            "text": "Transformer-symbol bootstrap and Transforming-the-Bootstrap show that domain-specific Transformers can learn to predict symbolic coefficients in highly structured physics problems, but do not generalize to law discovery from heterogeneous literature.",
            "uuids": [
                "e3811.0",
                "e3655.1"
            ]
        }
    ],
    "conflicting_evidence": [
        {
            "text": "LLMs trained on large corpora can hallucinate or produce invalid outputs, and sometimes fail to generalize to out-of-distribution data, as seen in FT-LLM, GPT-4, and other studies.",
            "uuids": [
                "e3648.0",
                "e3817.0",
                "e3823.1"
            ]
        },
        {
            "text": "TrialMind and GPT-4 baseline show that vanilla LLM prompting without retrieval, chain-of-thought, or programmatic standardization performs poorly on extraction and standardization tasks, indicating that LLMs alone are insufficient for robust law extraction.",
            "uuids": [
                "e3820.1"
            ]
        }
    ],
    "special_cases": [
        "Domains with insufficient numeric data or lacking robust evaluators may not benefit from LLM+evaluator pipelines.",
        "Tasks requiring high-precision arithmetic or formal symbolic manipulation may require additional tool integration (e.g., Wolfram, code execution modules).",
        "LLM-based pipelines may be limited by context window size, especially for high-dimensional or long-horizon tasks.",
        "Fine-tuning LLMs on narrow simulation datasets may improve predictive accuracy but not interpretability or law discovery."
    ],
    "existing_theory": {
        "likely_classification": "closely-related-to-existing",
        "references": [
            "Romera-Paredes et al. (2023) Mathematical discoveries from program search with large language models [LLM+evaluator program search, FunSearch]",
            "Shojaee et al. (2024) Scientific equation discovery via programming with large language models [LLM-SR, programmatic equation discovery]",
            "Meyerson et al. (2023) Language model crossover: Variation through few-shot prompting [LLM as crossover/mutation operator in symbolic regression]",
            "Schmidt & Lipson (2009) Distilling free-form natural laws from experimental data [classical symbolic regression, not LLM-based but similar in spirit]"
        ]
    },
    "reflected_from_theory_index": 0,
    "version": "built-theory-from-results-single-theory-reflection2-nov13-2025",
    "type": "general"
}</code></pre>
        </div>
    </div>
</body>
</html>