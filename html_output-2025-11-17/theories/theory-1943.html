<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Prompt Formatting Induces Degeneration and Output Validity Collapse: Information Bottleneck Theory - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-1943</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-1943</p>
                <p><strong>Name:</strong> Prompt Formatting Induces Degeneration and Output Validity Collapse: Information Bottleneck Theory</p>
                <p><strong>Type:</strong> general</p>
                <p><strong>Theory Query:</strong> Build a theory of how problem presentation format affects LLM performance.</p>
                <p><strong>Description:</strong> This theory proposes that prompt formatting acts as an information bottleneck for LLMs. When prompts are formatted in ways that compress, obscure, or overload the information (e.g., through excessive length, poor structure, or ambiguous task boundaries), the effective information transmitted to the LLM is reduced. This bottleneck leads to degeneration and output validity collapse, as the model is forced to interpolate or hallucinate missing or ambiguous information. The theory predicts that optimizing prompt formatting to maximize information clarity and minimize bottleneck effects will improve output validity.</p>
                <p><strong>Knowledge Cutoff Year:</strong> -1</p>
                <p><strong>Knowledge Cutoff Month:</strong> -1</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <h3>Statement 0: Prompt-Induced Information Bottleneck Increases Degeneration (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; prompt_format &#8594; has_property &#8594; information bottleneck (e.g., excessive compression, ambiguity, overload)</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; LLM_output &#8594; has_increased &#8594; degeneration (hallucination, off-task responses, incoherence)</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>LLMs hallucinate or interpolate when given prompts with missing, compressed, or ambiguous information. </li>
    <li>Prompt engineering guides recommend maximizing information clarity to reduce errors. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> The law adapts information bottleneck theory to the context of LLM prompt formatting.</p>            <p><strong>What Already Exists:</strong> Information bottleneck theory is known in information theory and neural networks.</p>            <p><strong>What is Novel:</strong> The application of information bottleneck theory to prompt formatting and LLM degeneration is new.</p>
            <p><strong>References:</strong> <ul>
    <li>Tishby et al. (2000) The Information Bottleneck Method [Information bottleneck theory]</li>
    <li>Zhou et al. (2023) LLM Prompt Engineering: A Survey [Prompt engineering best practices]</li>
</ul>
            <h3>Statement 1: Maximizing Prompt Information Clarity Reduces Degeneration (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; prompt_format &#8594; maximizes &#8594; information clarity and explicitness</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; LLM_output &#8594; has_decreased &#8594; degeneration (hallucination, off-task responses, incoherence)</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Clear, explicit prompts lead to more accurate and valid LLM outputs. </li>
    <li>Prompt engineering best practices emphasize information clarity. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> closely-related-to-existing</p>
            <p><strong>Explanation:</strong> The law formalizes the effect of information clarity on degeneration via the bottleneck analogy.</p>            <p><strong>What Already Exists:</strong> Prompt engineering best practices recommend clarity.</p>            <p><strong>What is Novel:</strong> The explicit link to information bottleneck and output degeneration is new.</p>
            <p><strong>References:</strong> <ul>
    <li>Zhou et al. (2023) LLM Prompt Engineering: A Survey [Prompt engineering best practices]</li>
    <li>Tishby et al. (2000) The Information Bottleneck Method [Information bottleneck theory]</li>
</ul>
            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>LLMs will show reduced degeneration when prompts are reformatted to maximize information clarity and minimize ambiguity.</li>
                <li>Prompts that compress or obscure information (e.g., through excessive abbreviation or poor structure) will increase hallucination and off-task responses.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>There may exist a quantifiable information bottleneck threshold for each LLM, above which degeneration increases sharply.</li>
                <li>Advanced LLMs with better information extraction capabilities may be less sensitive to prompt-induced bottlenecks.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>If LLMs do not show increased degeneration with information bottlenecked prompts, the theory would be challenged.</li>
                <li>If maximizing information clarity does not reduce degeneration, the law would be called into question.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>Cases where LLMs extract relevant information from highly compressed or ambiguous prompts without degeneration. </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> somewhat-related-to-existing</p>
            <p><strong>Explanation:</strong> The theory adapts information bottleneck theory to the context of LLM prompt formatting and degeneration.</p>
            <p><strong>References:</strong> <ul>
    <li>Tishby et al. (2000) The Information Bottleneck Method [Information bottleneck theory]</li>
    <li>Zhou et al. (2023) LLM Prompt Engineering: A Survey [Prompt engineering best practices]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Prompt Formatting Induces Degeneration and Output Validity Collapse: Information Bottleneck Theory",
    "theory_description": "This theory proposes that prompt formatting acts as an information bottleneck for LLMs. When prompts are formatted in ways that compress, obscure, or overload the information (e.g., through excessive length, poor structure, or ambiguous task boundaries), the effective information transmitted to the LLM is reduced. This bottleneck leads to degeneration and output validity collapse, as the model is forced to interpolate or hallucinate missing or ambiguous information. The theory predicts that optimizing prompt formatting to maximize information clarity and minimize bottleneck effects will improve output validity.",
    "theory_statements": [
        {
            "law": {
                "law_name": "Prompt-Induced Information Bottleneck Increases Degeneration",
                "if": [
                    {
                        "subject": "prompt_format",
                        "relation": "has_property",
                        "object": "information bottleneck (e.g., excessive compression, ambiguity, overload)"
                    }
                ],
                "then": [
                    {
                        "subject": "LLM_output",
                        "relation": "has_increased",
                        "object": "degeneration (hallucination, off-task responses, incoherence)"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "LLMs hallucinate or interpolate when given prompts with missing, compressed, or ambiguous information.",
                        "uuids": []
                    },
                    {
                        "text": "Prompt engineering guides recommend maximizing information clarity to reduce errors.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Information bottleneck theory is known in information theory and neural networks.",
                    "what_is_novel": "The application of information bottleneck theory to prompt formatting and LLM degeneration is new.",
                    "classification_explanation": "The law adapts information bottleneck theory to the context of LLM prompt formatting.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Tishby et al. (2000) The Information Bottleneck Method [Information bottleneck theory]",
                        "Zhou et al. (2023) LLM Prompt Engineering: A Survey [Prompt engineering best practices]"
                    ]
                }
            }
        },
        {
            "law": {
                "law_name": "Maximizing Prompt Information Clarity Reduces Degeneration",
                "if": [
                    {
                        "subject": "prompt_format",
                        "relation": "maximizes",
                        "object": "information clarity and explicitness"
                    }
                ],
                "then": [
                    {
                        "subject": "LLM_output",
                        "relation": "has_decreased",
                        "object": "degeneration (hallucination, off-task responses, incoherence)"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Clear, explicit prompts lead to more accurate and valid LLM outputs.",
                        "uuids": []
                    },
                    {
                        "text": "Prompt engineering best practices emphasize information clarity.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Prompt engineering best practices recommend clarity.",
                    "what_is_novel": "The explicit link to information bottleneck and output degeneration is new.",
                    "classification_explanation": "The law formalizes the effect of information clarity on degeneration via the bottleneck analogy.",
                    "likely_classification": "closely-related-to-existing",
                    "references": [
                        "Zhou et al. (2023) LLM Prompt Engineering: A Survey [Prompt engineering best practices]",
                        "Tishby et al. (2000) The Information Bottleneck Method [Information bottleneck theory]"
                    ]
                }
            }
        }
    ],
    "new_predictions_likely": [
        "LLMs will show reduced degeneration when prompts are reformatted to maximize information clarity and minimize ambiguity.",
        "Prompts that compress or obscure information (e.g., through excessive abbreviation or poor structure) will increase hallucination and off-task responses."
    ],
    "new_predictions_unknown": [
        "There may exist a quantifiable information bottleneck threshold for each LLM, above which degeneration increases sharply.",
        "Advanced LLMs with better information extraction capabilities may be less sensitive to prompt-induced bottlenecks."
    ],
    "negative_experiments": [
        "If LLMs do not show increased degeneration with information bottlenecked prompts, the theory would be challenged.",
        "If maximizing information clarity does not reduce degeneration, the law would be called into question."
    ],
    "unaccounted_for": [
        {
            "text": "Cases where LLMs extract relevant information from highly compressed or ambiguous prompts without degeneration.",
            "uuids": []
        }
    ],
    "conflicting_evidence": [
        {
            "text": "Some LLMs with advanced reasoning or context reconstruction can handle information bottlenecks without increased degeneration.",
            "uuids": []
        }
    ],
    "special_cases": [
        "LLMs trained on highly compressed or ambiguous data may develop robustness to information bottlenecks.",
        "Prompts with explicit redundancy or error correction may mitigate bottleneck effects."
    ],
    "existing_theory": {
        "what_already_exists": "Information bottleneck theory and prompt engineering best practices are known.",
        "what_is_novel": "The application of information bottleneck theory to prompt formatting and LLM degeneration is new.",
        "classification_explanation": "The theory adapts information bottleneck theory to the context of LLM prompt formatting and degeneration.",
        "likely_classification": "somewhat-related-to-existing",
        "references": [
            "Tishby et al. (2000) The Information Bottleneck Method [Information bottleneck theory]",
            "Zhou et al. (2023) LLM Prompt Engineering: A Survey [Prompt engineering best practices]"
        ]
    },
    "reflected_from_theory_index": 3,
    "type": "general",
    "version": "built-theory-from-results-single-theory-reflection2-nov14-2025-LLM-BASELINE-no-evidence-with-matched-control-theory-name",
    "theory_query": "Build a theory of how problem presentation format affects LLM performance.",
    "original_theory_id": "theory-655",
    "original_theory_name": "Prompt Formatting Induces Degeneration and Output Validity Collapse",
    "provide_matched_control_thery_name": true,
    "matched_control_theory_name": "Prompt Formatting Induces Degeneration and Output Validity Collapse",
    "model_str": "openai/gpt-4.1-2025-04-14"
}</code></pre>
        </div>
    </div>
</body>
</html>