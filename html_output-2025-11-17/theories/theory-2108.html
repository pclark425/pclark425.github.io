<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Semantic Network Activation Theory - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-2108</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-2108</p>
                <p><strong>Name:</strong> Semantic Network Activation Theory</p>
                <p><strong>Type:</strong> general</p>
                <p><strong>Theory Query:</strong> Build a theory of how large language models (LLMs) can be used to distill theories from large numbers of scholarly papers, given a specific topic or query.</p>
                <p><strong>Description:</strong> This theory proposes that LLMs distill theories from scholarly papers by activating and traversing internal semantic networks that encode relationships between concepts, evidence, and hypotheses. When given a topic or query, the LLM activates relevant nodes and propagates activation through the network, aggregating and weighting evidence based on semantic proximity, citation strength, and contextual relevance. The resulting theory statements emerge from the most strongly activated and coherently connected subgraphs, enabling the LLM to synthesize integrative, evidence-based theories.</p>
                <p><strong>Knowledge Cutoff Year:</strong> -1</p>
                <p><strong>Knowledge Cutoff Month:</strong> -1</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <h3>Statement 0: Semantic Activation by Query (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; LLM &#8594; receives &#8594; topic or query</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; LLM &#8594; activates &#8594; semantic network nodes relevant to query</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>LLMs encode knowledge as distributed semantic representations, and can retrieve relevant concepts in response to queries. </li>
    <li>Neural network models have been shown to activate concept clusters in response to input prompts. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> Semantic activation is established, but its application to LLM-driven theory distillation is new.</p>            <p><strong>What Already Exists:</strong> Semantic activation and distributed representations are established in neural network theory.</p>            <p><strong>What is Novel:</strong> The explicit mapping of this process to theory distillation from scholarly corpora is novel.</p>
            <p><strong>References:</strong> <ul>
    <li>Mikolov et al. (2013) Efficient Estimation of Word Representations in Vector Space [semantic representations]</li>
    <li>Bommasani et al. (2021) On the Opportunities and Risks of Foundation Models [LLM knowledge encoding]</li>
</ul>
            <h3>Statement 1: Evidence Aggregation via Network Propagation (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; semantic network nodes &#8594; are_activated &#8594; by query</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; LLM &#8594; propagates &#8594; activation to connected evidence nodes<span style="color: #888888;">, and</span></div>
        <div>&#8226; LLM &#8594; aggregates &#8594; evidence weighted by semantic and citation strength<span style="color: #888888;">, and</span></div>
        <div>&#8226; LLM &#8594; generates &#8594; theory statements from most strongly connected subgraphs</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Graph-based and attention-based models aggregate evidence by propagating activation through semantic and citation networks. </li>
    <li>LLMs can synthesize integrative statements by combining evidence from semantically related sources. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> Related to graph-based models, but its explicit role in LLM theory distillation is new.</p>            <p><strong>What Already Exists:</strong> Evidence aggregation via network propagation is established in graph neural networks and citation analysis.</p>            <p><strong>What is Novel:</strong> The application of this mechanism to LLM-driven theory distillation is novel.</p>
            <p><strong>References:</strong> <ul>
    <li>Kipf & Welling (2017) Semi-Supervised Classification with Graph Convolutional Networks [network propagation]</li>
    <li>Cohan et al. (2020) SPECTER: Document-level Representation Learning using Citation-informed Transformers [citation-based evidence aggregation]</li>
</ul>
            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>If an LLM is given a query closely matching a well-connected semantic cluster, it will generate theory statements that integrate evidence from that cluster.</li>
                <li>If citation strength is artificially increased for certain evidence, the LLM will weight that evidence more heavily in theory synthesis.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>LLMs may be able to discover novel connections between distant semantic clusters, leading to unexpected theory synthesis.</li>
                <li>Semantic network activation may enable LLMs to identify and resolve conflicting evidence by tracing citation and semantic paths.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>If LLMs fail to aggregate evidence from semantically related sources, the theory is called into question.</li>
                <li>If LLMs ignore citation strength or semantic proximity in theory synthesis, the evidence aggregation law is challenged.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>The role of non-textual evidence (e.g., figures, tables) in semantic network activation is not addressed. </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> somewhat-related-to-existing</p>
            <p><strong>Explanation:</strong> While related to existing models, the theory's application to LLM theory distillation is new.</p>
            <p><strong>References:</strong> <ul>
    <li>Mikolov et al. (2013) Efficient Estimation of Word Representations in Vector Space [semantic representations]</li>
    <li>Kipf & Welling (2017) Semi-Supervised Classification with Graph Convolutional Networks [network propagation]</li>
    <li>Cohan et al. (2020) SPECTER: Document-level Representation Learning using Citation-informed Transformers [citation-based evidence aggregation]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Semantic Network Activation Theory",
    "theory_description": "This theory proposes that LLMs distill theories from scholarly papers by activating and traversing internal semantic networks that encode relationships between concepts, evidence, and hypotheses. When given a topic or query, the LLM activates relevant nodes and propagates activation through the network, aggregating and weighting evidence based on semantic proximity, citation strength, and contextual relevance. The resulting theory statements emerge from the most strongly activated and coherently connected subgraphs, enabling the LLM to synthesize integrative, evidence-based theories.",
    "theory_statements": [
        {
            "law": {
                "law_name": "Semantic Activation by Query",
                "if": [
                    {
                        "subject": "LLM",
                        "relation": "receives",
                        "object": "topic or query"
                    }
                ],
                "then": [
                    {
                        "subject": "LLM",
                        "relation": "activates",
                        "object": "semantic network nodes relevant to query"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "LLMs encode knowledge as distributed semantic representations, and can retrieve relevant concepts in response to queries.",
                        "uuids": []
                    },
                    {
                        "text": "Neural network models have been shown to activate concept clusters in response to input prompts.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Semantic activation and distributed representations are established in neural network theory.",
                    "what_is_novel": "The explicit mapping of this process to theory distillation from scholarly corpora is novel.",
                    "classification_explanation": "Semantic activation is established, but its application to LLM-driven theory distillation is new.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Mikolov et al. (2013) Efficient Estimation of Word Representations in Vector Space [semantic representations]",
                        "Bommasani et al. (2021) On the Opportunities and Risks of Foundation Models [LLM knowledge encoding]"
                    ]
                }
            }
        },
        {
            "law": {
                "law_name": "Evidence Aggregation via Network Propagation",
                "if": [
                    {
                        "subject": "semantic network nodes",
                        "relation": "are_activated",
                        "object": "by query"
                    }
                ],
                "then": [
                    {
                        "subject": "LLM",
                        "relation": "propagates",
                        "object": "activation to connected evidence nodes"
                    },
                    {
                        "subject": "LLM",
                        "relation": "aggregates",
                        "object": "evidence weighted by semantic and citation strength"
                    },
                    {
                        "subject": "LLM",
                        "relation": "generates",
                        "object": "theory statements from most strongly connected subgraphs"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Graph-based and attention-based models aggregate evidence by propagating activation through semantic and citation networks.",
                        "uuids": []
                    },
                    {
                        "text": "LLMs can synthesize integrative statements by combining evidence from semantically related sources.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Evidence aggregation via network propagation is established in graph neural networks and citation analysis.",
                    "what_is_novel": "The application of this mechanism to LLM-driven theory distillation is novel.",
                    "classification_explanation": "Related to graph-based models, but its explicit role in LLM theory distillation is new.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Kipf & Welling (2017) Semi-Supervised Classification with Graph Convolutional Networks [network propagation]",
                        "Cohan et al. (2020) SPECTER: Document-level Representation Learning using Citation-informed Transformers [citation-based evidence aggregation]"
                    ]
                }
            }
        }
    ],
    "new_predictions_likely": [
        "If an LLM is given a query closely matching a well-connected semantic cluster, it will generate theory statements that integrate evidence from that cluster.",
        "If citation strength is artificially increased for certain evidence, the LLM will weight that evidence more heavily in theory synthesis."
    ],
    "new_predictions_unknown": [
        "LLMs may be able to discover novel connections between distant semantic clusters, leading to unexpected theory synthesis.",
        "Semantic network activation may enable LLMs to identify and resolve conflicting evidence by tracing citation and semantic paths."
    ],
    "negative_experiments": [
        "If LLMs fail to aggregate evidence from semantically related sources, the theory is called into question.",
        "If LLMs ignore citation strength or semantic proximity in theory synthesis, the evidence aggregation law is challenged."
    ],
    "unaccounted_for": [
        {
            "text": "The role of non-textual evidence (e.g., figures, tables) in semantic network activation is not addressed.",
            "uuids": []
        }
    ],
    "conflicting_evidence": [
        {
            "text": "LLMs sometimes generate theory statements that do not reflect the strongest semantic or citation connections, possibly due to training data biases.",
            "uuids": []
        }
    ],
    "special_cases": [
        "In sparsely connected semantic networks, theory synthesis may be limited or fragmented.",
        "If the query activates multiple, weakly connected clusters, the LLM may generate disjointed or ambiguous theories."
    ],
    "existing_theory": {
        "what_already_exists": "Semantic network activation and evidence aggregation are established in neural and graph-based models.",
        "what_is_novel": "The explicit application of these mechanisms to LLM-driven theory distillation from scholarly corpora is novel.",
        "classification_explanation": "While related to existing models, the theory's application to LLM theory distillation is new.",
        "likely_classification": "somewhat-related-to-existing",
        "references": [
            "Mikolov et al. (2013) Efficient Estimation of Word Representations in Vector Space [semantic representations]",
            "Kipf & Welling (2017) Semi-Supervised Classification with Graph Convolutional Networks [network propagation]",
            "Cohan et al. (2020) SPECTER: Document-level Representation Learning using Citation-informed Transformers [citation-based evidence aggregation]"
        ]
    },
    "reflected_from_theory_index": 2,
    "type": "general",
    "version": "built-theory-from-results-single-theory-reflection2-nov14-2025-LLM-BASELINE-no-evidence-without-matched-control-theory-name",
    "theory_query": "Build a theory of how large language models (LLMs) can be used to distill theories from large numbers of scholarly papers, given a specific topic or query.",
    "original_theory_id": "theory-667",
    "original_theory_name": "Iterative Retrieval-Augmented Synthesis Theory (IRAST)",
    "provide_matched_control_thery_name": false,
    "matched_control_theory_name": null,
    "model_str": "openai/gpt-4.1-2025-04-14"
}</code></pre>
        </div>
    </div>
</body>
</html>