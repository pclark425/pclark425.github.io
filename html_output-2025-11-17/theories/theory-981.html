<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Hierarchical Episodic-Semantic Memory Theory for LLM Agents in Text Games - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-981</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-981</p>
                <p><strong>Name:</strong> Hierarchical Episodic-Semantic Memory Theory for LLM Agents in Text Games</p>
                <p><strong>Type:</strong> general</p>
                <p><strong>Theory Query:</strong> Build a theory of how LLM agents for text games can best use memory to solve text game tasks.</p>
                <p><strong>Description:</strong> This theory posits that LLM agents perform best in text games when their memory is organized into a hierarchical structure, separating episodic (event-based, temporally ordered) and semantic (fact-based, generalized) memory. The agent dynamically transitions information between these layers, abstracting repeated patterns or facts from episodic traces into semantic memory, and using semantic memory to guide retrieval and interpretation of episodic details.</p>
                <p><strong>Knowledge Cutoff Year:</strong> -1</p>
                <p><strong>Knowledge Cutoff Month:</strong> -1</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <h3>Statement 0: Episodic-to-Semantic Abstraction (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; LLM agent &#8594; observes &#8594; repeated events or patterns in episodic memory</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; LLM agent &#8594; abstracts &#8594; generalized facts or rules into semantic memory</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Human memory research shows episodic experiences are abstracted into semantic knowledge over time. </li>
    <li>Neural architectures with separate episodic and semantic modules improve generalization in sequential tasks. </li>
    <li>LLM agents that extract rules from repeated game events perform better in novel situations. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> closely-related-to-existing</p>
            <p><strong>Explanation:</strong> The separation is known, but its operationalization for LLM agent memory management in text games is new.</p>            <p><strong>What Already Exists:</strong> Episodic and semantic memory separation is well-established in cognitive science.</p>            <p><strong>What is Novel:</strong> The explicit, dynamic abstraction of rules from episodic to semantic memory in LLM agents for text games is novel.</p>
            <p><strong>References:</strong> <ul>
    <li>Tulving (1972) Episodic and semantic memory [Human memory systems]</li>
    <li>Pritzel et al. (2017) Neural Episodic Control [Episodic memory in RL agents]</li>
    <li>Madotto et al. (2020) Memory Grounded Conversational Reasoning [LLM agents with memory modules]</li>
</ul>
            <h3>Statement 1: Semantic-Guided Episodic Retrieval (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; LLM agent &#8594; faces &#8594; decision requiring context from past events<span style="color: #888888;">, and</span></div>
        <div>&#8226; LLM agent &#8594; has &#8594; semantic memory of relevant rules or facts</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; LLM agent &#8594; uses &#8594; semantic memory to guide retrieval of relevant episodic traces</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Human recall is often guided by semantic cues to retrieve specific episodic memories. </li>
    <li>Hierarchical memory retrieval improves performance in multi-stage reasoning tasks. </li>
    <li>LLM agents with semantic-guided episodic retrieval solve long-horizon puzzles more efficiently. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> closely-related-to-existing</p>
            <p><strong>Explanation:</strong> The mechanism is known in humans, but its formalization for LLM agent memory in text games is new.</p>            <p><strong>What Already Exists:</strong> Semantic cueing of episodic retrieval is established in psychology.</p>            <p><strong>What is Novel:</strong> The explicit use of semantic memory to guide episodic retrieval in LLM agents for text games is novel.</p>
            <p><strong>References:</strong> <ul>
    <li>Tulving (1983) Elements of Episodic Memory [Semantic-episodic interaction]</li>
    <li>Pritzel et al. (2017) Neural Episodic Control [Episodic memory in RL agents]</li>
    <li>Madotto et al. (2020) Memory Grounded Conversational Reasoning [LLM agents with memory modules]</li>
</ul>
            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>LLM agents with hierarchical episodic-semantic memory will outperform flat memory agents in games requiring both pattern abstraction and specific recall.</li>
                <li>Agents that abstract rules from repeated events will generalize better to novel but structurally similar puzzles.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>If agents can autonomously discover new semantic categories from episodic traces, they may develop emergent conceptual understanding.</li>
                <li>Hierarchical memory may enable transfer learning across unrelated games if abstracted semantic knowledge is sufficiently general.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>If flat memory agents perform as well as hierarchical memory agents in complex games, the theory's core claim is undermined.</li>
                <li>If abstraction from episodic to semantic memory leads to loss of critical detail and reduced performance, the theory is challenged.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>The theory does not address how to resolve conflicts between episodic and semantic memory (e.g., when a new event contradicts an abstracted rule). </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> closely-related-to-existing</p>
            <p><strong>Explanation:</strong> The theory builds on known memory systems but formalizes and extends them for LLM agent design in text games.</p>
            <p><strong>References:</strong> <ul>
    <li>Tulving (1972) Episodic and semantic memory [Human memory systems]</li>
    <li>Pritzel et al. (2017) Neural Episodic Control [Episodic memory in RL agents]</li>
    <li>Madotto et al. (2020) Memory Grounded Conversational Reasoning [LLM agents with memory modules]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Hierarchical Episodic-Semantic Memory Theory for LLM Agents in Text Games",
    "theory_description": "This theory posits that LLM agents perform best in text games when their memory is organized into a hierarchical structure, separating episodic (event-based, temporally ordered) and semantic (fact-based, generalized) memory. The agent dynamically transitions information between these layers, abstracting repeated patterns or facts from episodic traces into semantic memory, and using semantic memory to guide retrieval and interpretation of episodic details.",
    "theory_statements": [
        {
            "law": {
                "law_name": "Episodic-to-Semantic Abstraction",
                "if": [
                    {
                        "subject": "LLM agent",
                        "relation": "observes",
                        "object": "repeated events or patterns in episodic memory"
                    }
                ],
                "then": [
                    {
                        "subject": "LLM agent",
                        "relation": "abstracts",
                        "object": "generalized facts or rules into semantic memory"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Human memory research shows episodic experiences are abstracted into semantic knowledge over time.",
                        "uuids": []
                    },
                    {
                        "text": "Neural architectures with separate episodic and semantic modules improve generalization in sequential tasks.",
                        "uuids": []
                    },
                    {
                        "text": "LLM agents that extract rules from repeated game events perform better in novel situations.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Episodic and semantic memory separation is well-established in cognitive science.",
                    "what_is_novel": "The explicit, dynamic abstraction of rules from episodic to semantic memory in LLM agents for text games is novel.",
                    "classification_explanation": "The separation is known, but its operationalization for LLM agent memory management in text games is new.",
                    "likely_classification": "closely-related-to-existing",
                    "references": [
                        "Tulving (1972) Episodic and semantic memory [Human memory systems]",
                        "Pritzel et al. (2017) Neural Episodic Control [Episodic memory in RL agents]",
                        "Madotto et al. (2020) Memory Grounded Conversational Reasoning [LLM agents with memory modules]"
                    ]
                }
            }
        },
        {
            "law": {
                "law_name": "Semantic-Guided Episodic Retrieval",
                "if": [
                    {
                        "subject": "LLM agent",
                        "relation": "faces",
                        "object": "decision requiring context from past events"
                    },
                    {
                        "subject": "LLM agent",
                        "relation": "has",
                        "object": "semantic memory of relevant rules or facts"
                    }
                ],
                "then": [
                    {
                        "subject": "LLM agent",
                        "relation": "uses",
                        "object": "semantic memory to guide retrieval of relevant episodic traces"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Human recall is often guided by semantic cues to retrieve specific episodic memories.",
                        "uuids": []
                    },
                    {
                        "text": "Hierarchical memory retrieval improves performance in multi-stage reasoning tasks.",
                        "uuids": []
                    },
                    {
                        "text": "LLM agents with semantic-guided episodic retrieval solve long-horizon puzzles more efficiently.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Semantic cueing of episodic retrieval is established in psychology.",
                    "what_is_novel": "The explicit use of semantic memory to guide episodic retrieval in LLM agents for text games is novel.",
                    "classification_explanation": "The mechanism is known in humans, but its formalization for LLM agent memory in text games is new.",
                    "likely_classification": "closely-related-to-existing",
                    "references": [
                        "Tulving (1983) Elements of Episodic Memory [Semantic-episodic interaction]",
                        "Pritzel et al. (2017) Neural Episodic Control [Episodic memory in RL agents]",
                        "Madotto et al. (2020) Memory Grounded Conversational Reasoning [LLM agents with memory modules]"
                    ]
                }
            }
        }
    ],
    "new_predictions_likely": [
        "LLM agents with hierarchical episodic-semantic memory will outperform flat memory agents in games requiring both pattern abstraction and specific recall.",
        "Agents that abstract rules from repeated events will generalize better to novel but structurally similar puzzles."
    ],
    "new_predictions_unknown": [
        "If agents can autonomously discover new semantic categories from episodic traces, they may develop emergent conceptual understanding.",
        "Hierarchical memory may enable transfer learning across unrelated games if abstracted semantic knowledge is sufficiently general."
    ],
    "negative_experiments": [
        "If flat memory agents perform as well as hierarchical memory agents in complex games, the theory's core claim is undermined.",
        "If abstraction from episodic to semantic memory leads to loss of critical detail and reduced performance, the theory is challenged."
    ],
    "unaccounted_for": [
        {
            "text": "The theory does not address how to resolve conflicts between episodic and semantic memory (e.g., when a new event contradicts an abstracted rule).",
            "uuids": []
        }
    ],
    "conflicting_evidence": [
        {
            "text": "Some simple games are solved efficiently by agents with only episodic or only semantic memory, suggesting hierarchy may not always be necessary.",
            "uuids": []
        }
    ],
    "special_cases": [
        "In games with little repetition or abstraction opportunity, semantic memory may be less useful.",
        "If episodic traces are too sparse or noisy, abstraction may be unreliable."
    ],
    "existing_theory": {
        "what_already_exists": "Hierarchical memory structures and episodic-semantic separation are established in cognitive science and some neural architectures.",
        "what_is_novel": "The explicit, dynamic abstraction and semantic-guided retrieval for LLM agent memory in text games is new.",
        "classification_explanation": "The theory builds on known memory systems but formalizes and extends them for LLM agent design in text games.",
        "likely_classification": "closely-related-to-existing",
        "references": [
            "Tulving (1972) Episodic and semantic memory [Human memory systems]",
            "Pritzel et al. (2017) Neural Episodic Control [Episodic memory in RL agents]",
            "Madotto et al. (2020) Memory Grounded Conversational Reasoning [LLM agents with memory modules]"
        ]
    },
    "reflected_from_theory_index": 1,
    "type": "general",
    "version": "built-theory-from-results-single-theory-reflection2-nov14-2025-LLM-BASELINE-no-evidence-without-matched-control-theory-name",
    "theory_query": "Build a theory of how LLM agents for text games can best use memory to solve text game tasks.",
    "original_theory_id": "theory-594",
    "original_theory_name": "Structured and Interpretable Memory Representations Enable Efficient Planning, Exploration, and Error Recovery in LLM Agents for Text Games",
    "provide_matched_control_thery_name": false,
    "matched_control_theory_name": null,
    "model_str": "openai/gpt-4.1-2025-04-14"
}</code></pre>
        </div>
    </div>
</body>
</html>