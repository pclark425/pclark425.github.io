<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Multimodal Alignment and Compactness Principle for Graph-to-Text Representations - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-611</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-611</p>
                <p><strong>Name:</strong> Multimodal Alignment and Compactness Principle for Graph-to-Text Representations</p>
                <p><strong>Type:</strong> general</p>
                <p><strong>Theory Query:</strong> Build a theory of ideal representations for converting graphs into text for language model training, based on the following results.</p>
                <p><strong>Description:</strong> This theory posits that the ideal representation for converting graphs into text for language model training is one that achieves a balance between multimodal alignment (structural, semantic, and textual signals) and compactness (token efficiency), with explicit mechanisms for aligning graph structure and text at multiple levels of granularity. The theory asserts that representations which (a) preserve explicit graph structure (e.g., via adjacency, motif, or Levi transformations), (b) integrate or align textual attributes or summaries, and (c) maintain compactness to fit within LLM context windows, will consistently outperform purely linearized or purely textualized approaches, especially as graph size and complexity increase. Furthermore, the theory claims that hybrid or composite encodings (e.g., motif+text, node descriptors+adjacency+summarization, or learned soft-token graph prompts) that allow for flexible integration of modalities and granularity will generalize better across tasks and domains.</p>
                <p><strong>Knowledge Cutoff Year:</strong> 2024</p>
                <p><strong>Knowledge Cutoff Month:</strong> 6</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <h3>Statement 0: Multimodal Alignment Law (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; graph representation &#8594; integrates &#8594; both explicit structural signals and semantic/textual attributes</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; language model &#8594; achieves &#8594; higher performance on graph reasoning and generation tasks</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Structured-Textual Graph (G_ST) representations that combine node/edge structure with textual attributes enable improved explainability and transferability, outperforming purely structural or purely textual encodings. <a href="../results/extraction-result-5223.html#e5223.5" class="evidence-link">[e5223.5]</a> </li>
    <li>GLaM-Combined encoding (node descriptors + adjacency + summarization) outperforms single-modality encodings on fact recall and multi-hop reasoning. <a href="../results/extraction-result-5356.html#e5356.5" class="evidence-link">[e5356.5]</a> </li>
    <li>Motif-based encodings, when combined with text or image, correct errors and improve performance on hard graph problems. <a href="../results/extraction-result-5357.html#e5357.1" class="evidence-link">[e5357.1]</a> </li>
    <li>Prompt graph representations (PromptGraph) that allow textual features as node/label features support flexible in-context learning and outperform contrastive and no-pretrain baselines. <a href="../results/extraction-result-5363.html#e5363.0" class="evidence-link">[e5363.0]</a> </li>
    <li>GraphTMI shows that combining text, motif, and image modalities can correct errors and denials, and that image+text combinations outperform single modalities in some settings. <a href="../results/extraction-result-5252.html#e5252.8" class="evidence-link">[e5252.8]</a> </li>
    <li>TAPE and LLM-based pipelines that use LLM-generated explanations as node features for GNNs achieve strong performance, indicating the benefit of integrating LLM text with graph structure. <a href="../results/extraction-result-5379.html#e5379.3" class="evidence-link">[e5379.3]</a> <a href="../results/extraction-result-5234.html#e5234.1" class="evidence-link">[e5234.1]</a> </li>
    <li>GraphToken (learned soft-token encoding) and GNP (graph neural prompt) approaches that align graph structure with LLM embedding space outperform text-only or structure-only baselines. <a href="../results/extraction-result-5237.html#e5237.3" class="evidence-link">[e5237.3]</a> <a href="../results/extraction-result-5349.html#e5349.0" class="evidence-link">[e5349.0]</a> </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> While multimodal learning is established, the explicit claim that optimal graph-to-text representations require explicit, aligned integration of structure and text at multiple levels is a novel synthesis across recent empirical findings.</p>            <p><strong>What Already Exists:</strong> Prior work has shown that combining structure and text can improve performance (e.g., GNNs with text features, multimodal learning).</p>            <p><strong>What is Novel:</strong> This law generalizes the necessity of explicit multimodal alignment (not just concatenation) and posits that such alignment is a necessary condition for optimal graph-to-text representations in LLMs, especially as graph complexity increases.</p>
            <p><strong>References:</strong> <ul>
    <li>Wang et al. (2024) Towards Versatile Graph Learning Approach: from the Perspective of Large Language Models [G_ST, multimodal alignment]</li>
    <li>Zhang et al. (2024) GLaM: Fine-Tuning Large Language Models for Domain Knowledge Graph Alignment [composite encodings]</li>
    <li>Wang et al. (2023) Which Modality should I use - Text, Motif, or Image? [multimodal comparison]</li>
    <li>Chen et al. (2020) KG-BART: Knowledge Graph-Augmented BART for Generative Commonsense Reasoning [SCI/CSD alignment]</li>
</ul>
            <h3>Statement 1: Compactness-Expressivity Tradeoff Law (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; graph-to-text representation &#8594; is &#8594; compact (token-efficient) and preserves salient structure</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; LLM &#8594; achieves &#8594; higher accuracy and lower denial/mismatch rates on large or complex graphs</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Adjacency list and motif encodings outperform verbose plain-text or edge-list serializations in both accuracy and token efficiency, especially as graph size increases. <a href="../results/extraction-result-5365.html#e5365.1" class="evidence-link">[e5365.1]</a> <a href="../results/extraction-result-5357.html#e5357.1" class="evidence-link">[e5357.1]</a> </li>
    <li>Tuple linearization (edge-list with node count) enables scaling to 100-node graphs, outperforming sentence-per-edge approaches limited to <20 nodes. <a href="../results/extraction-result-5383.html#e5383.0" class="evidence-link">[e5383.0]</a> </li>
    <li>Textualized Graph (flattening) is only practical when paired with retrieval/subgraph selection due to token limits. <a href="../results/extraction-result-5257.html#e5257.0" class="evidence-link">[e5257.0]</a> </li>
    <li>Motif encodings are more compact than full adjacency for conveying salient local patterns and are especially effective on 'hard' graphs with high motif count/low homophily. <a href="../results/extraction-result-5357.html#e5357.1" class="evidence-link">[e5357.1]</a> </li>
    <li>GraphML and GML encodings, while expressive, are verbose and can cause token overflow, leading to higher denial rates and lower performance on large graphs. <a href="../results/extraction-result-5361.html#e5361.3" class="evidence-link">[e5361.3]</a> <a href="../results/extraction-result-5389.html#e5389.4" class="evidence-link">[e5389.4]</a> </li>
    <li>Ego-graph summarization and k-hop subgraph sampling are used to reduce context size and maintain performance, showing that compactness is necessary for scalability. <a href="../results/extraction-result-5367.html#e5367.2" class="evidence-link">[e5367.2]</a> <a href="../results/extraction-result-5243.html#e5243.5" class="evidence-link">[e5243.5]</a> </li>
    <li>GraphWiz's tuple linearization allows LLMs to handle larger graphs and outperforms more verbose sentence-per-edge encodings. <a href="../results/extraction-result-5383.html#e5383.0" class="evidence-link">[e5383.0]</a> </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> While compactness is a known concern, the explicit tradeoff with expressivity and its centrality to graph-to-text representation optimality in LLMs is a novel, general principle abstracted from recent empirical studies.</p>            <p><strong>What Already Exists:</strong> Token efficiency and compactness are recognized as important in NLP and LLM prompting.</p>            <p><strong>What is Novel:</strong> This law formalizes the tradeoff as a governing principle for graph-to-text representations, asserting that compactness is not just a practical concern but a necessary property for scalable, high-fidelity graph-to-text conversion in LLMs.</p>
            <p><strong>References:</strong> <ul>
    <li>Wang et al. (2023) Which Modality should I use - Text, Motif, or Image? [compactness vs informativeness]</li>
    <li>Zhou et al. (2024) GraphWiz: An Instruction-Following Language Model for Graph Problems [tuple linearization]</li>
    <li>Zhang et al. (2024) G-Retriever: Retrieval-Augmented Generation for Textual Graph Understanding [retrieval for compactness]</li>
</ul>
            <h3>Statement 2: Granularity Alignment Law (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; representation &#8594; aligns &#8594; graph elements and text at matching levels of granularity (e.g., subword, node, motif, subgraph)</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; model &#8594; achieves &#8594; improved transferability and robustness across tasks and domains</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>SCI/CSD modules that align subword tokens with KG concept representations outperform naive approaches that copy concept embeddings to all subword positions. <a href="../results/extraction-result-5382.html#e5382.2" class="evidence-link">[e5382.2]</a> </li>
    <li>Motif encodings that attach motif lists to query nodes outperform counts-only or global motif statistics, especially on hard tasks. <a href="../results/extraction-result-5357.html#e5357.1" class="evidence-link">[e5357.1]</a> </li>
    <li>Node descriptor encodings (LLM-generated summaries) improve performance on graphs with unfamiliar node labels. <a href="../results/extraction-result-5356.html#e5356.3" class="evidence-link">[e5356.3]</a> </li>
    <li>BPE-subword-graph extension for AMR graphs improves handling of rare words and reduces data sparsity by aligning graph nodes with subword units. <a href="../results/extraction-result-5354.html#e5354.1" class="evidence-link">[e5354.1]</a> </li>
    <li>SCI/CSD granularity alignment in KG-BART reduces naive copying and improves performance over baseline approaches. <a href="../results/extraction-result-5382.html#e5382.2" class="evidence-link">[e5382.2]</a> </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> While alignment at the token or entity level is known, the explicit generalization to arbitrary granularity (subword, motif, subgraph) and its impact on transferability is a novel synthesis.</p>            <p><strong>What Already Exists:</strong> Granularity alignment is discussed in multimodal learning and some graph-text alignment work.</p>            <p><strong>What is Novel:</strong> This law generalizes the necessity of matching granularity between graph and text representations as a core design principle for robust graph-to-text conversion.</p>
            <p><strong>References:</strong> <ul>
    <li>Chen et al. (2020) KG-BART: Knowledge Graph-Augmented BART for Generative Commonsense Reasoning [SCI/CSD]</li>
    <li>Wang et al. (2023) Which Modality should I use - Text, Motif, or Image? [motif granularity]</li>
    <li>Zhang et al. (2024) GLaM: Fine-Tuning Large Language Models for Domain Knowledge Graph Alignment [node descriptors]</li>
</ul>
            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>Hybrid representations that combine motif-based summaries with adjacency lists and node descriptors will outperform any single-modality or single-granularity encoding on node classification and multi-hop reasoning tasks in large, heterogeneous graphs.</li>
                <li>For graphs with high structural complexity (e.g., many motifs, high degree), compact motif+adjacency+text encodings will yield lower denial and mismatch rates in LLM-based node classification than plain adjacency or edge-list encodings.</li>
                <li>Incorporating subword-level alignment (e.g., SCI/CSD) into graph-to-text pipelines for domains with complex entity names (e.g., biomedical KGs) will improve downstream text generation and entity linking accuracy.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>A fully end-to-end learned representation that dynamically selects the optimal granularity and modality (e.g., motif, adjacency, text, image) per instance will outperform all static encodings, but may require new model architectures.</li>
                <li>In extremely large graphs (e.g., >10,000 nodes), a hybrid motif+retrieval+summarization approach will scale better than any current method, but it is unknown if LLMs can maintain reasoning fidelity at this scale.</li>
                <li>If a representation is constructed that aligns graph structure, motif, and text with visual (image) encodings, multimodal LLMs will be able to perform zero-shot graph reasoning tasks that are currently unsolved.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>If a purely linearized edge-list encoding (without motif or text augmentation) outperforms motif+text or multimodal encodings on large, complex graphs, this would challenge the theory.</li>
                <li>If increasing the compactness of a representation (e.g., by aggressive summarization) leads to a consistent drop in accuracy even when salient structure is preserved, the compactness-expressivity tradeoff law would be called into question.</li>
                <li>If granularity alignment (e.g., SCI/CSD) does not improve or even harms performance on tasks with complex tokenization, the granularity alignment law would be weakened.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>Image-based encodings (GraphTMI) sometimes outperform text and motif encodings, especially for large graphs, but the theory does not fully explain the conditions under which image modality is optimal. <a href="../results/extraction-result-5252.html#e5252.8" class="evidence-link">[e5252.8]</a> </li>
    <li>Some retrieval-augmented approaches (e.g., G-Retriever) achieve large gains by combining retrieval and textualization, which may not fit neatly into the multimodal alignment framework. <a href="../results/extraction-result-5257.html#e5257.0" class="evidence-link">[e5257.0]</a> </li>
    <li>Prefix-tuning integration and soft-prompt methods (e.g., SOFT-PROMPT, prefix-tuning of graph embeddings) can sometimes achieve competitive results without explicit multimodal alignment, especially on small graphs. <a href="../results/extraction-result-5237.html#e5237.2" class="evidence-link">[e5237.2]</a> <a href="../results/extraction-result-5230.html#e5230.3" class="evidence-link">[e5230.3]</a> </li>
    <li>Motif encodings have higher mismatch rates in some datasets, indicating that multimodal alignment does not always guarantee improved performance. <a href="../results/extraction-result-5357.html#e5357.1" class="evidence-link">[e5357.1]</a> </li>
    <li>Attribute-only or text-only encodings (e.g., LM baselines) can outperform structure-aware encodings for attribute-rich node classification, suggesting that structure is not always necessary. <a href="../results/extraction-result-5253.html#e5253.3" class="evidence-link">[e5253.3]</a> </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> somewhat-related-to-existing</p>
            <p><strong>Explanation:</strong> This theory generalizes and unifies several strands of recent empirical work into a new, overarching framework for graph-to-text representation design.</p>
            <p><strong>References:</strong> <ul>
    <li>Wang et al. (2024) Towards Versatile Graph Learning Approach: from the Perspective of Large Language Models [G_ST, multimodal alignment]</li>
    <li>Zhang et al. (2024) GLaM: Fine-Tuning Large Language Models for Domain Knowledge Graph Alignment [composite encodings]</li>
    <li>Wang et al. (2023) Which Modality should I use - Text, Motif, or Image? [multimodal comparison]</li>
    <li>Chen et al. (2020) KG-BART: Knowledge Graph-Augmented BART for Generative Commonsense Reasoning [granularity alignment]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Multimodal Alignment and Compactness Principle for Graph-to-Text Representations",
    "theory_description": "This theory posits that the ideal representation for converting graphs into text for language model training is one that achieves a balance between multimodal alignment (structural, semantic, and textual signals) and compactness (token efficiency), with explicit mechanisms for aligning graph structure and text at multiple levels of granularity. The theory asserts that representations which (a) preserve explicit graph structure (e.g., via adjacency, motif, or Levi transformations), (b) integrate or align textual attributes or summaries, and (c) maintain compactness to fit within LLM context windows, will consistently outperform purely linearized or purely textualized approaches, especially as graph size and complexity increase. Furthermore, the theory claims that hybrid or composite encodings (e.g., motif+text, node descriptors+adjacency+summarization, or learned soft-token graph prompts) that allow for flexible integration of modalities and granularity will generalize better across tasks and domains.",
    "theory_statements": [
        {
            "law": {
                "law_name": "Multimodal Alignment Law",
                "if": [
                    {
                        "subject": "graph representation",
                        "relation": "integrates",
                        "object": "both explicit structural signals and semantic/textual attributes"
                    }
                ],
                "then": [
                    {
                        "subject": "language model",
                        "relation": "achieves",
                        "object": "higher performance on graph reasoning and generation tasks"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Structured-Textual Graph (G_ST) representations that combine node/edge structure with textual attributes enable improved explainability and transferability, outperforming purely structural or purely textual encodings.",
                        "uuids": [
                            "e5223.5"
                        ]
                    },
                    {
                        "text": "GLaM-Combined encoding (node descriptors + adjacency + summarization) outperforms single-modality encodings on fact recall and multi-hop reasoning.",
                        "uuids": [
                            "e5356.5"
                        ]
                    },
                    {
                        "text": "Motif-based encodings, when combined with text or image, correct errors and improve performance on hard graph problems.",
                        "uuids": [
                            "e5357.1"
                        ]
                    },
                    {
                        "text": "Prompt graph representations (PromptGraph) that allow textual features as node/label features support flexible in-context learning and outperform contrastive and no-pretrain baselines.",
                        "uuids": [
                            "e5363.0"
                        ]
                    },
                    {
                        "text": "GraphTMI shows that combining text, motif, and image modalities can correct errors and denials, and that image+text combinations outperform single modalities in some settings.",
                        "uuids": [
                            "e5252.8"
                        ]
                    },
                    {
                        "text": "TAPE and LLM-based pipelines that use LLM-generated explanations as node features for GNNs achieve strong performance, indicating the benefit of integrating LLM text with graph structure.",
                        "uuids": [
                            "e5379.3",
                            "e5234.1"
                        ]
                    },
                    {
                        "text": "GraphToken (learned soft-token encoding) and GNP (graph neural prompt) approaches that align graph structure with LLM embedding space outperform text-only or structure-only baselines.",
                        "uuids": [
                            "e5237.3",
                            "e5349.0"
                        ]
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Prior work has shown that combining structure and text can improve performance (e.g., GNNs with text features, multimodal learning).",
                    "what_is_novel": "This law generalizes the necessity of explicit multimodal alignment (not just concatenation) and posits that such alignment is a necessary condition for optimal graph-to-text representations in LLMs, especially as graph complexity increases.",
                    "classification_explanation": "While multimodal learning is established, the explicit claim that optimal graph-to-text representations require explicit, aligned integration of structure and text at multiple levels is a novel synthesis across recent empirical findings.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Wang et al. (2024) Towards Versatile Graph Learning Approach: from the Perspective of Large Language Models [G_ST, multimodal alignment]",
                        "Zhang et al. (2024) GLaM: Fine-Tuning Large Language Models for Domain Knowledge Graph Alignment [composite encodings]",
                        "Wang et al. (2023) Which Modality should I use - Text, Motif, or Image? [multimodal comparison]",
                        "Chen et al. (2020) KG-BART: Knowledge Graph-Augmented BART for Generative Commonsense Reasoning [SCI/CSD alignment]"
                    ]
                }
            }
        },
        {
            "law": {
                "law_name": "Compactness-Expressivity Tradeoff Law",
                "if": [
                    {
                        "subject": "graph-to-text representation",
                        "relation": "is",
                        "object": "compact (token-efficient) and preserves salient structure"
                    }
                ],
                "then": [
                    {
                        "subject": "LLM",
                        "relation": "achieves",
                        "object": "higher accuracy and lower denial/mismatch rates on large or complex graphs"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Adjacency list and motif encodings outperform verbose plain-text or edge-list serializations in both accuracy and token efficiency, especially as graph size increases.",
                        "uuids": [
                            "e5365.1",
                            "e5357.1"
                        ]
                    },
                    {
                        "text": "Tuple linearization (edge-list with node count) enables scaling to 100-node graphs, outperforming sentence-per-edge approaches limited to &lt;20 nodes.",
                        "uuids": [
                            "e5383.0"
                        ]
                    },
                    {
                        "text": "Textualized Graph (flattening) is only practical when paired with retrieval/subgraph selection due to token limits.",
                        "uuids": [
                            "e5257.0"
                        ]
                    },
                    {
                        "text": "Motif encodings are more compact than full adjacency for conveying salient local patterns and are especially effective on 'hard' graphs with high motif count/low homophily.",
                        "uuids": [
                            "e5357.1"
                        ]
                    },
                    {
                        "text": "GraphML and GML encodings, while expressive, are verbose and can cause token overflow, leading to higher denial rates and lower performance on large graphs.",
                        "uuids": [
                            "e5361.3",
                            "e5389.4"
                        ]
                    },
                    {
                        "text": "Ego-graph summarization and k-hop subgraph sampling are used to reduce context size and maintain performance, showing that compactness is necessary for scalability.",
                        "uuids": [
                            "e5367.2",
                            "e5243.5"
                        ]
                    },
                    {
                        "text": "GraphWiz's tuple linearization allows LLMs to handle larger graphs and outperforms more verbose sentence-per-edge encodings.",
                        "uuids": [
                            "e5383.0"
                        ]
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Token efficiency and compactness are recognized as important in NLP and LLM prompting.",
                    "what_is_novel": "This law formalizes the tradeoff as a governing principle for graph-to-text representations, asserting that compactness is not just a practical concern but a necessary property for scalable, high-fidelity graph-to-text conversion in LLMs.",
                    "classification_explanation": "While compactness is a known concern, the explicit tradeoff with expressivity and its centrality to graph-to-text representation optimality in LLMs is a novel, general principle abstracted from recent empirical studies.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Wang et al. (2023) Which Modality should I use - Text, Motif, or Image? [compactness vs informativeness]",
                        "Zhou et al. (2024) GraphWiz: An Instruction-Following Language Model for Graph Problems [tuple linearization]",
                        "Zhang et al. (2024) G-Retriever: Retrieval-Augmented Generation for Textual Graph Understanding [retrieval for compactness]"
                    ]
                }
            }
        },
        {
            "law": {
                "law_name": "Granularity Alignment Law",
                "if": [
                    {
                        "subject": "representation",
                        "relation": "aligns",
                        "object": "graph elements and text at matching levels of granularity (e.g., subword, node, motif, subgraph)"
                    }
                ],
                "then": [
                    {
                        "subject": "model",
                        "relation": "achieves",
                        "object": "improved transferability and robustness across tasks and domains"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "SCI/CSD modules that align subword tokens with KG concept representations outperform naive approaches that copy concept embeddings to all subword positions.",
                        "uuids": [
                            "e5382.2"
                        ]
                    },
                    {
                        "text": "Motif encodings that attach motif lists to query nodes outperform counts-only or global motif statistics, especially on hard tasks.",
                        "uuids": [
                            "e5357.1"
                        ]
                    },
                    {
                        "text": "Node descriptor encodings (LLM-generated summaries) improve performance on graphs with unfamiliar node labels.",
                        "uuids": [
                            "e5356.3"
                        ]
                    },
                    {
                        "text": "BPE-subword-graph extension for AMR graphs improves handling of rare words and reduces data sparsity by aligning graph nodes with subword units.",
                        "uuids": [
                            "e5354.1"
                        ]
                    },
                    {
                        "text": "SCI/CSD granularity alignment in KG-BART reduces naive copying and improves performance over baseline approaches.",
                        "uuids": [
                            "e5382.2"
                        ]
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Granularity alignment is discussed in multimodal learning and some graph-text alignment work.",
                    "what_is_novel": "This law generalizes the necessity of matching granularity between graph and text representations as a core design principle for robust graph-to-text conversion.",
                    "classification_explanation": "While alignment at the token or entity level is known, the explicit generalization to arbitrary granularity (subword, motif, subgraph) and its impact on transferability is a novel synthesis.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Chen et al. (2020) KG-BART: Knowledge Graph-Augmented BART for Generative Commonsense Reasoning [SCI/CSD]",
                        "Wang et al. (2023) Which Modality should I use - Text, Motif, or Image? [motif granularity]",
                        "Zhang et al. (2024) GLaM: Fine-Tuning Large Language Models for Domain Knowledge Graph Alignment [node descriptors]"
                    ]
                }
            }
        }
    ],
    "new_predictions_likely": [
        "Hybrid representations that combine motif-based summaries with adjacency lists and node descriptors will outperform any single-modality or single-granularity encoding on node classification and multi-hop reasoning tasks in large, heterogeneous graphs.",
        "For graphs with high structural complexity (e.g., many motifs, high degree), compact motif+adjacency+text encodings will yield lower denial and mismatch rates in LLM-based node classification than plain adjacency or edge-list encodings.",
        "Incorporating subword-level alignment (e.g., SCI/CSD) into graph-to-text pipelines for domains with complex entity names (e.g., biomedical KGs) will improve downstream text generation and entity linking accuracy."
    ],
    "new_predictions_unknown": [
        "A fully end-to-end learned representation that dynamically selects the optimal granularity and modality (e.g., motif, adjacency, text, image) per instance will outperform all static encodings, but may require new model architectures.",
        "In extremely large graphs (e.g., &gt;10,000 nodes), a hybrid motif+retrieval+summarization approach will scale better than any current method, but it is unknown if LLMs can maintain reasoning fidelity at this scale.",
        "If a representation is constructed that aligns graph structure, motif, and text with visual (image) encodings, multimodal LLMs will be able to perform zero-shot graph reasoning tasks that are currently unsolved."
    ],
    "negative_experiments": [
        "If a purely linearized edge-list encoding (without motif or text augmentation) outperforms motif+text or multimodal encodings on large, complex graphs, this would challenge the theory.",
        "If increasing the compactness of a representation (e.g., by aggressive summarization) leads to a consistent drop in accuracy even when salient structure is preserved, the compactness-expressivity tradeoff law would be called into question.",
        "If granularity alignment (e.g., SCI/CSD) does not improve or even harms performance on tasks with complex tokenization, the granularity alignment law would be weakened."
    ],
    "unaccounted_for": [
        {
            "text": "Image-based encodings (GraphTMI) sometimes outperform text and motif encodings, especially for large graphs, but the theory does not fully explain the conditions under which image modality is optimal.",
            "uuids": [
                "e5252.8"
            ]
        },
        {
            "text": "Some retrieval-augmented approaches (e.g., G-Retriever) achieve large gains by combining retrieval and textualization, which may not fit neatly into the multimodal alignment framework.",
            "uuids": [
                "e5257.0"
            ]
        },
        {
            "text": "Prefix-tuning integration and soft-prompt methods (e.g., SOFT-PROMPT, prefix-tuning of graph embeddings) can sometimes achieve competitive results without explicit multimodal alignment, especially on small graphs.",
            "uuids": [
                "e5237.2",
                "e5230.3"
            ]
        },
        {
            "text": "Motif encodings have higher mismatch rates in some datasets, indicating that multimodal alignment does not always guarantee improved performance.",
            "uuids": [
                "e5357.1"
            ]
        },
        {
            "text": "Attribute-only or text-only encodings (e.g., LM baselines) can outperform structure-aware encodings for attribute-rich node classification, suggesting that structure is not always necessary.",
            "uuids": [
                "e5253.3"
            ]
        }
    ],
    "conflicting_evidence": [
        {
            "text": "In some datasets, text-only or attribute-only encodings (e.g., LM baselines) outperform structure-aware encodings for attribute-rich node classification, suggesting that structure is not always necessary.",
            "uuids": [
                "e5253.3"
            ]
        },
        {
            "text": "Motif encodings have higher mismatch rates in some datasets, indicating that multimodal alignment does not always guarantee improved performance.",
            "uuids": [
                "e5357.1"
            ]
        },
        {
            "text": "In PubMed, adding 2-hop neighbor summaries (ego-graph summarization) decreased zero-shot node classification accuracy, showing that more structure is not always better.",
            "uuids": [
                "e5367.2"
            ]
        }
    ],
    "special_cases": [
        "For extremely sparse graphs or graphs with little motif structure, motif-based encodings may provide little benefit.",
        "In domains where node/edge textual attributes are absent or uninformative, multimodal alignment may not be possible, and structure-only encodings may be optimal.",
        "For very small graphs, the overhead of multimodal or composite encodings may outweigh their benefits.",
        "In highly attribute-rich graphs, text-only or attribute-only encodings may suffice and outperform structure-aware methods."
    ],
    "existing_theory": {
        "what_already_exists": "Multimodal learning and the importance of structure and text in graph representations are established, as are compactness and token efficiency concerns.",
        "what_is_novel": "The explicit synthesis of multimodal alignment, compactness, and granularity alignment as governing principles for ideal graph-to-text representations in LLMs is novel.",
        "classification_explanation": "This theory generalizes and unifies several strands of recent empirical work into a new, overarching framework for graph-to-text representation design.",
        "likely_classification": "somewhat-related-to-existing",
        "references": [
            "Wang et al. (2024) Towards Versatile Graph Learning Approach: from the Perspective of Large Language Models [G_ST, multimodal alignment]",
            "Zhang et al. (2024) GLaM: Fine-Tuning Large Language Models for Domain Knowledge Graph Alignment [composite encodings]",
            "Wang et al. (2023) Which Modality should I use - Text, Motif, or Image? [multimodal comparison]",
            "Chen et al. (2020) KG-BART: Knowledge Graph-Augmented BART for Generative Commonsense Reasoning [granularity alignment]"
        ]
    },
    "reflected_from_theory_index": 0,
    "version": "built-theory-from-results-single-theory-reflection2-nov14-2025",
    "type": "general"
}</code></pre>
        </div>
    </div>
</body>
</html>