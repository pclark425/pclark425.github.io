<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Generative Expectation Violation Theory - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-1700</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-1700</p>
                <p><strong>Name:</strong> Generative Expectation Violation Theory</p>
                <p><strong>Type:</strong> general</p>
                <p><strong>Theory Query:</strong> Build a theory of how language models can be used for detecting anomalies in lists of data.</p>
                <p><strong>Description:</strong> This theory proposes that language models can be used for anomaly detection in lists by leveraging their generative capabilities: the LM generates expectations for each item in the list, and items that significantly violate these expectations (as measured by low generation probability or high surprise) are flagged as anomalies.</p>
                <p><strong>Knowledge Cutoff Year:</strong> -1</p>
                <p><strong>Knowledge Cutoff Month:</strong> -1</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <h3>Statement 0: Expectation Violation Law (quantitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; language model &#8594; is_conditioned_on &#8594; list_context<span style="color: #888888;">, and</span></div>
        <div>&#8226; item &#8594; is_part_of &#8594; list<span style="color: #888888;">, and</span></div>
        <div>&#8226; item &#8594; has_generation_probability &#8594; p<span style="color: #888888;">, and</span></div>
        <div>&#8226; p &#8594; is_much_lower_than &#8594; expected_probability_for_list_items</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; item &#8594; is_flagged_as &#8594; anomaly</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Language models can generate or score items given context, and low probability indicates unexpectedness. </li>
    <li>Anomalies are often associated with low generative likelihood in model-based anomaly detection. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> closely-related-to-existing</p>
            <p><strong>Explanation:</strong> Closely related to existing likelihood-based anomaly detection, but the systematic use of LM generative expectations for lists is novel.</p>            <p><strong>What Already Exists:</strong> Likelihood-based anomaly detection is established in generative models.</p>            <p><strong>What is Novel:</strong> The explicit use of LM generative expectations for anomaly detection in arbitrary lists is a new generalization.</p>
            <p><strong>References:</strong> <ul>
    <li>Hendrycks & Gimpel (2017) A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks [likelihood-based anomaly detection]</li>
    <li>Goldblum et al. (2020) Adversarially Robust Distillation: Detecting Anomalies in Neural Language Models [token-level anomaly detection]</li>
</ul>
            <h3>Statement 1: Surprise Accumulation Law (quantitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; language model &#8594; is_applied_to &#8594; list<span style="color: #888888;">, and</span></div>
        <div>&#8226; item &#8594; is_part_of &#8594; list<span style="color: #888888;">, and</span></div>
        <div>&#8226; item &#8594; has_tokens &#8594; tokens<span style="color: #888888;">, and</span></div>
        <div>&#8226; tokens &#8594; have_surprise_values &#8594; s_i<span style="color: #888888;">, and</span></div>
        <div>&#8226; sum(s_i) &#8594; exceeds &#8594; threshold_for_list</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; item &#8594; is_flagged_as &#8594; anomaly</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Token-level surprise (negative log-likelihood) is a standard measure of unexpectedness in LMs. </li>
    <li>Accumulated surprise across tokens can indicate global anomalies in items. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> closely-related-to-existing</p>
            <p><strong>Explanation:</strong> Closely related to existing work, but the systematic use for list anomaly detection is novel.</p>            <p><strong>What Already Exists:</strong> Surprise and negative log-likelihood are used in anomaly detection.</p>            <p><strong>What is Novel:</strong> The explicit accumulation of token-level surprise for anomaly detection in arbitrary lists is a new application.</p>
            <p><strong>References:</strong> <ul>
    <li>Hendrycks & Gimpel (2017) A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks [likelihood-based anomaly detection]</li>
    <li>Goldblum et al. (2020) Adversarially Robust Distillation: Detecting Anomalies in Neural Language Models [token-level anomaly detection]</li>
</ul>
            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>If a list contains an item with a sequence that is highly unlikely given the rest of the list, the LM will assign it low generation probability and flag it as anomalous.</li>
                <li>If the LM is applied to lists of code, syntactically invalid code will have high accumulated surprise and be detected as an anomaly.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>If anomalies are distributed across many low-surprise tokens, the aggregate surprise may not be sufficient for detection.</li>
                <li>If adversarially crafted anomalies mimic the generative expectations of the LM, detection may fail.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>If items with low generation probability are not anomalous, the theory's mechanism is challenged.</li>
                <li>If anomalies do not result in high surprise, the theory is undermined.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>Anomalies that do not manifest as low generation probability or high surprise, such as global semantic anomalies. </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> closely-related-to-existing</p>
            <p><strong>Explanation:</strong> The theory generalizes existing likelihood-based anomaly detection to the LM context for lists, which is a novel application.</p>
            <p><strong>References:</strong> <ul>
    <li>Hendrycks & Gimpel (2017) A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks [likelihood-based anomaly detection]</li>
    <li>Goldblum et al. (2020) Adversarially Robust Distillation: Detecting Anomalies in Neural Language Models [token-level anomaly detection]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Generative Expectation Violation Theory",
    "theory_description": "This theory proposes that language models can be used for anomaly detection in lists by leveraging their generative capabilities: the LM generates expectations for each item in the list, and items that significantly violate these expectations (as measured by low generation probability or high surprise) are flagged as anomalies.",
    "theory_statements": [
        {
            "law": {
                "law_name": "Expectation Violation Law",
                "if": [
                    {
                        "subject": "language model",
                        "relation": "is_conditioned_on",
                        "object": "list_context"
                    },
                    {
                        "subject": "item",
                        "relation": "is_part_of",
                        "object": "list"
                    },
                    {
                        "subject": "item",
                        "relation": "has_generation_probability",
                        "object": "p"
                    },
                    {
                        "subject": "p",
                        "relation": "is_much_lower_than",
                        "object": "expected_probability_for_list_items"
                    }
                ],
                "then": [
                    {
                        "subject": "item",
                        "relation": "is_flagged_as",
                        "object": "anomaly"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Language models can generate or score items given context, and low probability indicates unexpectedness.",
                        "uuids": []
                    },
                    {
                        "text": "Anomalies are often associated with low generative likelihood in model-based anomaly detection.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "quantitative",
                "existing_law": {
                    "what_already_exists": "Likelihood-based anomaly detection is established in generative models.",
                    "what_is_novel": "The explicit use of LM generative expectations for anomaly detection in arbitrary lists is a new generalization.",
                    "classification_explanation": "Closely related to existing likelihood-based anomaly detection, but the systematic use of LM generative expectations for lists is novel.",
                    "likely_classification": "closely-related-to-existing",
                    "references": [
                        "Hendrycks & Gimpel (2017) A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks [likelihood-based anomaly detection]",
                        "Goldblum et al. (2020) Adversarially Robust Distillation: Detecting Anomalies in Neural Language Models [token-level anomaly detection]"
                    ]
                }
            }
        },
        {
            "law": {
                "law_name": "Surprise Accumulation Law",
                "if": [
                    {
                        "subject": "language model",
                        "relation": "is_applied_to",
                        "object": "list"
                    },
                    {
                        "subject": "item",
                        "relation": "is_part_of",
                        "object": "list"
                    },
                    {
                        "subject": "item",
                        "relation": "has_tokens",
                        "object": "tokens"
                    },
                    {
                        "subject": "tokens",
                        "relation": "have_surprise_values",
                        "object": "s_i"
                    },
                    {
                        "subject": "sum(s_i)",
                        "relation": "exceeds",
                        "object": "threshold_for_list"
                    }
                ],
                "then": [
                    {
                        "subject": "item",
                        "relation": "is_flagged_as",
                        "object": "anomaly"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Token-level surprise (negative log-likelihood) is a standard measure of unexpectedness in LMs.",
                        "uuids": []
                    },
                    {
                        "text": "Accumulated surprise across tokens can indicate global anomalies in items.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "quantitative",
                "existing_law": {
                    "what_already_exists": "Surprise and negative log-likelihood are used in anomaly detection.",
                    "what_is_novel": "The explicit accumulation of token-level surprise for anomaly detection in arbitrary lists is a new application.",
                    "classification_explanation": "Closely related to existing work, but the systematic use for list anomaly detection is novel.",
                    "likely_classification": "closely-related-to-existing",
                    "references": [
                        "Hendrycks & Gimpel (2017) A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks [likelihood-based anomaly detection]",
                        "Goldblum et al. (2020) Adversarially Robust Distillation: Detecting Anomalies in Neural Language Models [token-level anomaly detection]"
                    ]
                }
            }
        }
    ],
    "new_predictions_likely": [
        "If a list contains an item with a sequence that is highly unlikely given the rest of the list, the LM will assign it low generation probability and flag it as anomalous.",
        "If the LM is applied to lists of code, syntactically invalid code will have high accumulated surprise and be detected as an anomaly."
    ],
    "new_predictions_unknown": [
        "If anomalies are distributed across many low-surprise tokens, the aggregate surprise may not be sufficient for detection.",
        "If adversarially crafted anomalies mimic the generative expectations of the LM, detection may fail."
    ],
    "negative_experiments": [
        "If items with low generation probability are not anomalous, the theory's mechanism is challenged.",
        "If anomalies do not result in high surprise, the theory is undermined."
    ],
    "unaccounted_for": [
        {
            "text": "Anomalies that do not manifest as low generation probability or high surprise, such as global semantic anomalies.",
            "uuids": []
        }
    ],
    "conflicting_evidence": [
        {
            "text": "Rare but valid items may have low generation probability, leading to false positives.",
            "uuids": []
        }
    ],
    "special_cases": [
        "Lists with high diversity or rare valid items may lead to high false positive rates.",
        "Tokenization artifacts may cause spurious surprise unrelated to true anomalies."
    ],
    "existing_theory": {
        "what_already_exists": "Likelihood-based anomaly detection is established in generative models.",
        "what_is_novel": "The systematic use of LM generative expectations for anomaly detection in arbitrary lists is a new generalization.",
        "classification_explanation": "The theory generalizes existing likelihood-based anomaly detection to the LM context for lists, which is a novel application.",
        "likely_classification": "closely-related-to-existing",
        "references": [
            "Hendrycks & Gimpel (2017) A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks [likelihood-based anomaly detection]",
            "Goldblum et al. (2020) Adversarially Robust Distillation: Detecting Anomalies in Neural Language Models [token-level anomaly detection]"
        ]
    },
    "reflected_from_theory_index": 3,
    "type": "general",
    "version": "built-theory-from-results-single-theory-reflection2-nov14-2025-LLM-BASELINE-no-evidence-without-matched-control-theory-name",
    "theory_query": "Build a theory of how language models can be used for detecting anomalies in lists of data.",
    "original_theory_id": "theory-640",
    "original_theory_name": "LLM Representation and Prompt-Engineering Theory for Anomaly Detection",
    "provide_matched_control_thery_name": false,
    "matched_control_theory_name": null,
    "model_str": "openai/gpt-4.1-2025-04-14"
}</code></pre>
        </div>
    </div>
</body>
</html>