<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Knowledge Graph Belief State Theory for Text-Based Interactive Environments - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-115</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-115</p>
                <p><strong>Name:</strong> Knowledge Graph Belief State Theory for Text-Based Interactive Environments</p>
                <p><strong>Type:</strong> specific</p>
                <p><strong>Theory Query:</strong> Build a theory about probabilistic symbolic world models for text environments that integrate LLM uncertainty into planning, based on the following results.</p>
                <p><strong>Description:</strong> For text-based interactive environments with partial observability, knowledge graphs provide an effective intermediate representation that bridges textual observations and symbolic planning. The optimal approach combines: (1) learned graph construction from text using neural methods (QA-based extraction, relation prediction, or sequence-to-sequence generation), (2) continuous-valued (soft) belief graphs that encode relation strengths as real numbers rather than discrete binary relations, which are more robust to prediction errors and gracefully handle uncertainty, (3) graph-structured state encoding for downstream planning or policy learning, and (4) training strategies that account for the set-based nature of graphs (permutation invariance) and leverage multi-task learning. Pre-training graph updaters with self-supervised objectives (observation generation, contrastive classification) improves downstream task performance. Combining graph representations with raw text observations provides additional robustness to graph prediction errors. Graph-based intrinsic motivation (rewarding discovery of new edges/facts) improves exploration in sparse-reward environments.</p>
                <p><strong>Knowledge Cutoff Year:</strong> 2024</p>
                <p><strong>Knowledge Cutoff Month:</strong> 12</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <ol>
                <li>Knowledge graphs provide effective structured state representations for partially observable text-based environments, bridging textual observations and symbolic planning</li>
                <li>Continuous-valued (soft) belief graphs with real-valued relation strengths are more robust to prediction errors and error accumulation than discrete binary symbolic graphs</li>
                <li>Learned neural graph construction methods (QA-based extraction, sequence-to-sequence generation) can approximate ground-truth graphs sufficiently well for downstream planning and policy learning</li>
                <li>Self-supervised pre-training of graph updaters with observation generation and contrastive objectives improves downstream task performance</li>
                <li>Graph-based intrinsic motivation (rewarding discovery of novel edges/facts) improves exploration efficiency in sparse-reward text environments</li>
                <li>Combining graph representations with raw text observations provides robustness to graph prediction errors and improves overall performance</li>
                <li>Predicting graph differences (deltas) between successive states is more effective than predicting full graphs at each timestep</li>
                <li>Multi-task training (joint graph prediction and action generation) with permutation-invariant losses (e.g., Set-of-Sequences) improves graph construction quality</li>
                <li>The performance gap between learned graphs and oracle ground-truth graphs indicates substantial room for improvement in graph construction methods</li>
                <li>Graph masking (constraining action selection to entities present in the KG) helps focus policy learning on relevant objects and actions</li>
            </ol>
            <h3>Supporting Evidence</h3>
<ol>
    <li>GATA with continuous belief graphs achieves +24.2% relative improvement over text-only transformer baselines (Tr-DQN) on TextWorld across difficulty levels <a href="../results/extraction-result-980.html#e980.0" class="evidence-link">[e980.0]</a> </li>
    <li>GATA-GTP (discrete command-generation updater) is more brittle and often underperforms continuous GATA due to error accumulation from discrete predictions <a href="../results/extraction-result-980.html#e980.1" class="evidence-link">[e980.1]</a> <a href="../results/extraction-result-980.html#e980.3" class="evidence-link">[e980.3]</a> </li>
    <li>GATA-GTF (oracle with ground-truth full graphs) achieves +81.6% average improvement over text baselines, demonstrating the upper bound value of accurate graph representations <a href="../results/extraction-result-980.html#e980.2" class="evidence-link">[e980.2]</a> </li>
    <li>Pre-training GATA's graph updater with both Observation Generation (OG) and Contrastive Observation Classification (COC) self-supervised objectives improves downstream RL performance <a href="../results/extraction-result-980.html#e980.0" class="evidence-link">[e980.0]</a> </li>
    <li>Worldformer predicting graph differences (G_{t+1}-G_t) achieves 39.15% graph-level EM compared to 14.29% for single-task Seq2Seq and 24.06% for GATA-W on JerichoWorld <a href="../results/extraction-result-851.html#e851.0" class="evidence-link">[e851.0]</a> </li>
    <li>Worldformer's multi-task training (joint KG prediction and valid-action generation) with Set-of-Sequences (SOS) loss significantly improves performance; ablations show removing any component causes substantial drops <a href="../results/extraction-result-851.html#e851.0" class="evidence-link">[e851.0]</a> </li>
    <li>Q*BERT with QA-based KG construction (ALBERT fine-tuned on Jericho-QA) achieves faster sample efficiency than text-only baselines and comparable asymptotic scores to KG-A2C on 7/9 games <a href="../results/extraction-result-967.html#e967.0" class="evidence-link">[e967.0]</a> <a href="../results/extraction-result-851.html#e851.1" class="evidence-link">[e851.1]</a> </li>
    <li>MC!Q*BERT with graph-based intrinsic motivation (rewarding newly discovered KG edges) outperforms baselines on 8/9 evaluated games and successfully clears bottlenecks that other methods fail on <a href="../results/extraction-result-967.html#e967.1" class="evidence-link">[e967.1]</a> </li>
    <li>Adding raw text observations to GATA's action selector (alongside the belief graph) improves performance by mitigating accumulated graph prediction errors <a href="../results/extraction-result-980.html#e980.0" class="evidence-link">[e980.0]</a> </li>
    <li>Q*BERT achieves token-level F1 of ~55.74% on JerichoWorld KG prediction, competitive with other learned approaches <a href="../results/extraction-result-851.html#e851.1" class="evidence-link">[e851.1]</a> </li>
    <li>Worldformer achieves token-level EM 51.32% and F1 52.45% on JerichoWorld, demonstrating effective learned graph construction <a href="../results/extraction-result-851.html#e851.0" class="evidence-link">[e851.0]</a> </li>
    <li>Graph masking (constraining action selection to entities in the KG) helps Q*BERT and related methods focus on relevant objects <a href="../results/extraction-result-967.html#e967.0" class="evidence-link">[e967.0]</a> </li>
    <li>JerichoWorld dataset provides ground-truth KG states (24,198 training, 7,836 test instances) enabling supervised learning of graph construction <a href="../results/extraction-result-992.html#e992.0" class="evidence-link">[e992.0]</a> </li>
    <li>CALM (GPT-2 tuned on human transcripts) achieves ~13.79% valid-action EM and ~19.11% F1, showing transfer learning can help but is outperformed by structured approaches <a href="../results/extraction-result-851.html#e851.5" class="evidence-link">[e851.5]</a> </li>
</ol>            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>A continuous belief graph trained with self-supervised pre-training will be more robust to noisy observations than a discrete symbolic graph in new partially observable text environments</li>
                <li>Pre-training a graph updater with self-supervised objectives (OG+COC) will improve zero-shot transfer performance to unseen text games from the same distribution</li>
                <li>Graph-based intrinsic rewards will improve exploration efficiency in text games with sparse rewards and long-horizon dependencies</li>
                <li>Multi-task training with SOS loss will outperform single-task training for graph construction in new text-based environments</li>
                <li>Combining learned KG representations with raw text will outperform either representation alone in environments with complex state spaces</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>Whether learned graph representations can fully replace hand-crafted symbolic representations for complex multi-agent planning tasks requiring theory of mind</li>
                <li>The optimal balance between graph structure complexity and raw text for different types of text environments (e.g., puzzle-solving vs. exploration vs. social interaction)</li>
                <li>Whether graph neural network architectures can be improved to better handle highly dynamic graphs where most edges change at each timestep</li>
                <li>Whether continuous belief graphs can effectively represent and reason about abstract concepts (e.g., emotions, intentions) that don't map cleanly to entity-relation-entity triples</li>
                <li>The extent to which graph-based intrinsic motivation scales to very large state spaces with thousands of potential entities and relations</li>
                <li>Whether pre-training on one type of text environment (e.g., TextWorld) transfers effectively to fundamentally different types (e.g., social deduction games, narrative-heavy interactive fiction)</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>Finding text environments where graph representations provide no benefit over raw text (or perform worse) would challenge the generality of the theory</li>
                <li>Demonstrating that discrete binary graphs are as robust as continuous belief graphs across multiple environments would weaken the continuous representation claim</li>
                <li>Showing that graph-based intrinsic motivation doesn't improve exploration in sparse-reward environments would challenge that component of the theory</li>
                <li>Finding that single-task training outperforms multi-task training for graph construction would challenge the multi-task learning claim</li>
                <li>Demonstrating that predicting full graphs is as effective as predicting graph differences would challenge the delta-prediction claim</li>
                <li>Showing that self-supervised pre-training provides no benefit for graph updaters would challenge the pre-training component</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>The theory doesn't specify how to determine optimal graph structure (what entity types and relation types to include) for new domains without ground-truth supervision <a href="../results/extraction-result-980.html#e980.0" class="evidence-link">[e980.0]</a> <a href="../results/extraction-result-851.html#e851.0" class="evidence-link">[e851.0]</a> <a href="../results/extraction-result-992.html#e992.0" class="evidence-link">[e992.0]</a> </li>
    <li>The trade-offs between graph construction accuracy and downstream task performance are not fully characterized - high token-level F1 doesn't always correlate with high task success <a href="../results/extraction-result-967.html#e967.0" class="evidence-link">[e967.0]</a> <a href="../results/extraction-result-980.html#e980.0" class="evidence-link">[e980.0]</a> <a href="../results/extraction-result-851.html#e851.1" class="evidence-link">[e851.1]</a> </li>
    <li>The theory doesn't explain why QA-based methods achieve high token-level metrics but lower graph-level metrics, or the implications of over-extraction <a href="../results/extraction-result-851.html#e851.1" class="evidence-link">[e851.1]</a> </li>
    <li>The optimal architecture choices for graph encoders (e.g., R-GCN vs. other GNN variants) are not specified <a href="../results/extraction-result-980.html#e980.0" class="evidence-link">[e980.0]</a> <a href="../results/extraction-result-967.html#e967.0" class="evidence-link">[e967.0]</a> </li>
    <li>The theory doesn't address how to handle temporal dynamics in graphs (e.g., when to delete old information vs. maintain history) <a href="../results/extraction-result-980.html#e980.0" class="evidence-link">[e980.0]</a> <a href="../results/extraction-result-851.html#e851.0" class="evidence-link">[e851.0]</a> </li>
    <li>The relationship between graph size/complexity and computational efficiency is not characterized <a href="../results/extraction-result-992.html#e992.0" class="evidence-link">[e992.0]</a> <a href="../results/extraction-result-851.html#e851.0" class="evidence-link">[e851.0]</a> </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> closely-related-to-existing</p>
            <p><strong>Explanation:</strong> No explanation provided.</p>
            <p><strong>References:</strong> <ul>
    <li>Adhikari et al. (2020) Learning Dynamic Belief Graphs to Generalize on Text-Based Games [Proposes dynamic belief graphs for text games but doesn't formulate the continuous vs discrete distinction or the comprehensive training strategy]</li>
    <li>Ammanabrolu & Hausknecht (2020) Graph Constrained Reinforcement Learning for Natural Language Action Spaces [Introduces KG-based RL for text games (KG-A2C, KG-DQN) but doesn't focus on belief-state representations or continuous graphs]</li>
    <li>Ammanabrolu et al. (2020) How to Avoid Being Eaten by a Grue: Structured Exploration Strategies for Textual Worlds [Proposes graph-based exploration strategies including intrinsic motivation but doesn't formulate the broader theory of continuous belief graphs]</li>
    <li>Ammanabrolu et al. (2021) Modeling Worlds in Text [Introduces JerichoWorld dataset and baselines but doesn't propose the continuous belief graph theory]</li>
    <li>Murugesan et al. (2021) Learning Knowledge Graph-based World Models of Textual Environments [Proposes Worldformer with multi-task learning and graph-difference prediction but doesn't focus on continuous belief representations]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Knowledge Graph Belief State Theory for Text-Based Interactive Environments",
    "theory_description": "For text-based interactive environments with partial observability, knowledge graphs provide an effective intermediate representation that bridges textual observations and symbolic planning. The optimal approach combines: (1) learned graph construction from text using neural methods (QA-based extraction, relation prediction, or sequence-to-sequence generation), (2) continuous-valued (soft) belief graphs that encode relation strengths as real numbers rather than discrete binary relations, which are more robust to prediction errors and gracefully handle uncertainty, (3) graph-structured state encoding for downstream planning or policy learning, and (4) training strategies that account for the set-based nature of graphs (permutation invariance) and leverage multi-task learning. Pre-training graph updaters with self-supervised objectives (observation generation, contrastive classification) improves downstream task performance. Combining graph representations with raw text observations provides additional robustness to graph prediction errors. Graph-based intrinsic motivation (rewarding discovery of new edges/facts) improves exploration in sparse-reward environments.",
    "supporting_evidence": [
        {
            "text": "GATA with continuous belief graphs achieves +24.2% relative improvement over text-only transformer baselines (Tr-DQN) on TextWorld across difficulty levels",
            "uuids": [
                "e980.0"
            ]
        },
        {
            "text": "GATA-GTP (discrete command-generation updater) is more brittle and often underperforms continuous GATA due to error accumulation from discrete predictions",
            "uuids": [
                "e980.1",
                "e980.3"
            ]
        },
        {
            "text": "GATA-GTF (oracle with ground-truth full graphs) achieves +81.6% average improvement over text baselines, demonstrating the upper bound value of accurate graph representations",
            "uuids": [
                "e980.2"
            ]
        },
        {
            "text": "Pre-training GATA's graph updater with both Observation Generation (OG) and Contrastive Observation Classification (COC) self-supervised objectives improves downstream RL performance",
            "uuids": [
                "e980.0"
            ]
        },
        {
            "text": "Worldformer predicting graph differences (G_{t+1}-G_t) achieves 39.15% graph-level EM compared to 14.29% for single-task Seq2Seq and 24.06% for GATA-W on JerichoWorld",
            "uuids": [
                "e851.0"
            ]
        },
        {
            "text": "Worldformer's multi-task training (joint KG prediction and valid-action generation) with Set-of-Sequences (SOS) loss significantly improves performance; ablations show removing any component causes substantial drops",
            "uuids": [
                "e851.0"
            ]
        },
        {
            "text": "Q*BERT with QA-based KG construction (ALBERT fine-tuned on Jericho-QA) achieves faster sample efficiency than text-only baselines and comparable asymptotic scores to KG-A2C on 7/9 games",
            "uuids": [
                "e967.0",
                "e851.1"
            ]
        },
        {
            "text": "MC!Q*BERT with graph-based intrinsic motivation (rewarding newly discovered KG edges) outperforms baselines on 8/9 evaluated games and successfully clears bottlenecks that other methods fail on",
            "uuids": [
                "e967.1"
            ]
        },
        {
            "text": "Adding raw text observations to GATA's action selector (alongside the belief graph) improves performance by mitigating accumulated graph prediction errors",
            "uuids": [
                "e980.0"
            ]
        },
        {
            "text": "Q*BERT achieves token-level F1 of ~55.74% on JerichoWorld KG prediction, competitive with other learned approaches",
            "uuids": [
                "e851.1"
            ]
        },
        {
            "text": "Worldformer achieves token-level EM 51.32% and F1 52.45% on JerichoWorld, demonstrating effective learned graph construction",
            "uuids": [
                "e851.0"
            ]
        },
        {
            "text": "Graph masking (constraining action selection to entities in the KG) helps Q*BERT and related methods focus on relevant objects",
            "uuids": [
                "e967.0"
            ]
        },
        {
            "text": "JerichoWorld dataset provides ground-truth KG states (24,198 training, 7,836 test instances) enabling supervised learning of graph construction",
            "uuids": [
                "e992.0"
            ]
        },
        {
            "text": "CALM (GPT-2 tuned on human transcripts) achieves ~13.79% valid-action EM and ~19.11% F1, showing transfer learning can help but is outperformed by structured approaches",
            "uuids": [
                "e851.5"
            ]
        }
    ],
    "theory_statements": [
        "Knowledge graphs provide effective structured state representations for partially observable text-based environments, bridging textual observations and symbolic planning",
        "Continuous-valued (soft) belief graphs with real-valued relation strengths are more robust to prediction errors and error accumulation than discrete binary symbolic graphs",
        "Learned neural graph construction methods (QA-based extraction, sequence-to-sequence generation) can approximate ground-truth graphs sufficiently well for downstream planning and policy learning",
        "Self-supervised pre-training of graph updaters with observation generation and contrastive objectives improves downstream task performance",
        "Graph-based intrinsic motivation (rewarding discovery of novel edges/facts) improves exploration efficiency in sparse-reward text environments",
        "Combining graph representations with raw text observations provides robustness to graph prediction errors and improves overall performance",
        "Predicting graph differences (deltas) between successive states is more effective than predicting full graphs at each timestep",
        "Multi-task training (joint graph prediction and action generation) with permutation-invariant losses (e.g., Set-of-Sequences) improves graph construction quality",
        "The performance gap between learned graphs and oracle ground-truth graphs indicates substantial room for improvement in graph construction methods",
        "Graph masking (constraining action selection to entities present in the KG) helps focus policy learning on relevant objects and actions"
    ],
    "new_predictions_likely": [
        "A continuous belief graph trained with self-supervised pre-training will be more robust to noisy observations than a discrete symbolic graph in new partially observable text environments",
        "Pre-training a graph updater with self-supervised objectives (OG+COC) will improve zero-shot transfer performance to unseen text games from the same distribution",
        "Graph-based intrinsic rewards will improve exploration efficiency in text games with sparse rewards and long-horizon dependencies",
        "Multi-task training with SOS loss will outperform single-task training for graph construction in new text-based environments",
        "Combining learned KG representations with raw text will outperform either representation alone in environments with complex state spaces"
    ],
    "new_predictions_unknown": [
        "Whether learned graph representations can fully replace hand-crafted symbolic representations for complex multi-agent planning tasks requiring theory of mind",
        "The optimal balance between graph structure complexity and raw text for different types of text environments (e.g., puzzle-solving vs. exploration vs. social interaction)",
        "Whether graph neural network architectures can be improved to better handle highly dynamic graphs where most edges change at each timestep",
        "Whether continuous belief graphs can effectively represent and reason about abstract concepts (e.g., emotions, intentions) that don't map cleanly to entity-relation-entity triples",
        "The extent to which graph-based intrinsic motivation scales to very large state spaces with thousands of potential entities and relations",
        "Whether pre-training on one type of text environment (e.g., TextWorld) transfers effectively to fundamentally different types (e.g., social deduction games, narrative-heavy interactive fiction)"
    ],
    "negative_experiments": [
        "Finding text environments where graph representations provide no benefit over raw text (or perform worse) would challenge the generality of the theory",
        "Demonstrating that discrete binary graphs are as robust as continuous belief graphs across multiple environments would weaken the continuous representation claim",
        "Showing that graph-based intrinsic motivation doesn't improve exploration in sparse-reward environments would challenge that component of the theory",
        "Finding that single-task training outperforms multi-task training for graph construction would challenge the multi-task learning claim",
        "Demonstrating that predicting full graphs is as effective as predicting graph differences would challenge the delta-prediction claim",
        "Showing that self-supervised pre-training provides no benefit for graph updaters would challenge the pre-training component"
    ],
    "unaccounted_for": [
        {
            "text": "The theory doesn't specify how to determine optimal graph structure (what entity types and relation types to include) for new domains without ground-truth supervision",
            "uuids": [
                "e980.0",
                "e851.0",
                "e992.0"
            ]
        },
        {
            "text": "The trade-offs between graph construction accuracy and downstream task performance are not fully characterized - high token-level F1 doesn't always correlate with high task success",
            "uuids": [
                "e967.0",
                "e980.0",
                "e851.1"
            ]
        },
        {
            "text": "The theory doesn't explain why QA-based methods achieve high token-level metrics but lower graph-level metrics, or the implications of over-extraction",
            "uuids": [
                "e851.1"
            ]
        },
        {
            "text": "The optimal architecture choices for graph encoders (e.g., R-GCN vs. other GNN variants) are not specified",
            "uuids": [
                "e980.0",
                "e967.0"
            ]
        },
        {
            "text": "The theory doesn't address how to handle temporal dynamics in graphs (e.g., when to delete old information vs. maintain history)",
            "uuids": [
                "e980.0",
                "e851.0"
            ]
        },
        {
            "text": "The relationship between graph size/complexity and computational efficiency is not characterized",
            "uuids": [
                "e992.0",
                "e851.0"
            ]
        }
    ],
    "conflicting_evidence": [
        {
            "text": "Rules-based information extraction with OpenIE achieves only 4.70% graph-level EM and 17.50% token-level F1, suggesting that simple symbolic extraction is insufficient",
            "uuids": [
                "e851.4",
                "e992.0"
            ]
        },
        {
            "text": "Some text environments may have structure that doesn't map well to entity-relation-entity knowledge graphs (e.g., continuous spatial relationships, temporal sequences)",
            "uuids": [
                "e992.0"
            ]
        },
        {
            "text": "QA-based approaches can over-extract information, achieving high token-level recall but lower precision, which may not always benefit downstream tasks",
            "uuids": [
                "e851.1"
            ]
        },
        {
            "text": "The large performance gap between learned graphs (39.15% EM) and oracle graphs (+81.6% improvement) suggests current methods may be fundamentally limited",
            "uuids": [
                "e980.2",
                "e851.0"
            ]
        }
    ],
    "special_cases": [
        "For fully observable environments, belief graphs may not provide benefits over deterministic symbolic graphs, as uncertainty is not a factor",
        "For environments with very complex relational structure (many entity types, many relation types), graph representations may become unwieldy and difficult to learn accurately",
        "For short-horizon tasks with simple state spaces, the overhead of graph construction and encoding may outweigh benefits compared to direct text processing",
        "For environments where most state information is hidden and must be inferred (rather than observed), graph construction from observations alone may be insufficient",
        "Different game genres may benefit differently: exploration-heavy games may benefit more from graph-based intrinsic motivation, while puzzle games may benefit more from accurate graph construction",
        "The effectiveness of continuous vs. discrete graphs may depend on the noise level in observations and the frequency of state changes",
        "Multi-task training benefits may be reduced when the auxiliary tasks (e.g., valid-action prediction) are not well-aligned with the primary task"
    ],
    "existing_theory": {
        "likely_classification": "closely-related-to-existing",
        "references": [
            "Adhikari et al. (2020) Learning Dynamic Belief Graphs to Generalize on Text-Based Games [Proposes dynamic belief graphs for text games but doesn't formulate the continuous vs discrete distinction or the comprehensive training strategy]",
            "Ammanabrolu & Hausknecht (2020) Graph Constrained Reinforcement Learning for Natural Language Action Spaces [Introduces KG-based RL for text games (KG-A2C, KG-DQN) but doesn't focus on belief-state representations or continuous graphs]",
            "Ammanabrolu et al. (2020) How to Avoid Being Eaten by a Grue: Structured Exploration Strategies for Textual Worlds [Proposes graph-based exploration strategies including intrinsic motivation but doesn't formulate the broader theory of continuous belief graphs]",
            "Ammanabrolu et al. (2021) Modeling Worlds in Text [Introduces JerichoWorld dataset and baselines but doesn't propose the continuous belief graph theory]",
            "Murugesan et al. (2021) Learning Knowledge Graph-based World Models of Textual Environments [Proposes Worldformer with multi-task learning and graph-difference prediction but doesn't focus on continuous belief representations]"
        ]
    },
    "theory_type_general_specific": "specific",
    "reflected_from_theory_index": 3,
    "type": "specific"
}</code></pre>
        </div>
    </div>
</body>
</html>