<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Hierarchical Curriculum Necessity Theory - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-333</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-333</p>
                <p><strong>Name:</strong> Hierarchical Curriculum Necessity Theory</p>
                <p><strong>Type:</strong> general</p>
                <p><strong>Theory Query:</strong> Build a theory about optimal curricula for compositional acquisition of commonsense and science procedures in interactive text environments.. Please focus on creating new theories that have not been proposed before in the literature.</p>
                <p><strong>Description:</strong> This theory posits that for compositional acquisition of complex procedures in interactive text environments, a hierarchical curriculum structure is necessary for sample-efficient learning when task complexity exceeds certain thresholds. The theory states that complex procedures must be decomposed into prerequisite sub-skills that are learned in a specific dependency order, where higher-level skills cannot be efficiently acquired without first mastering their constituent lower-level components. This necessity arises from the compositional nature of procedural knowledge in text-based environments, where the state-action space for complex tasks becomes too large to explore efficiently without first constraining it through mastery of sub-procedures. The theory predicts that flat (non-hierarchical) curricula will show dramatically reduced sample efficiency (polynomial to exponential scaling differences) for tasks beyond a complexity threshold, while hierarchical curricula that respect skill dependencies will maintain more favorable scaling properties. The necessity is strongest under conditions of limited model capacity, sparse rewards, and deep compositional structure.</p>
                <p><strong>Knowledge Cutoff Year:</strong> -1</p>
                <p><strong>Knowledge Cutoff Month:</strong> -1</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <ol>
                <li>For complex procedures P that can be decomposed into sub-procedures {S1, S2, ..., Sn} with dependency relationships, there exists a complexity threshold C_threshold (determined by factors including compositional depth, state-space size, and reward sparsity) above which learning P directly requires substantially more samples (often orders of magnitude) than learning through a hierarchical curriculum that respects dependencies.</li>
                <li>The optimal curriculum structure can be represented as a directed acyclic graph (DAG) where nodes represent skills and edges represent prerequisite relationships, and learning efficiency is improved when the curriculum ordering approximates a topological sort of this DAG, with efficiency gains increasing with the strength of the dependency relationships.</li>
                <li>Sub-skills that are compositionally reused across multiple higher-level procedures should be learned to a functional competency threshold before those higher-level procedures are introduced, with the required competency level depending on how critical the sub-skill is to the higher-level task.</li>
                <li>The benefit of hierarchical structure (relative to flat curricula) increases with: (a) the depth of compositional dependencies, (b) the sparsity of reward signals, (c) the size of the state-action space, and (d) limitations in model capacity and prior knowledge.</li>
                <li>Violation of strong prerequisite ordering (learning higher-level skills before critical prerequisites) results in significant sample inefficiency that manifests as slower learning, higher variance, and potential learning plateaus, though the severity depends on the strength of the dependency relationship.</li>
            </ol>
            <h3>Supporting Evidence</h3>
<ol>
    <li>Curriculum learning approaches show significant improvements in sample efficiency for reinforcement learning tasks, with benefits increasing as task complexity grows </li>
    <li>Hierarchical task decomposition in curriculum design shows improved learning efficiency in complex interactive environments, particularly for compositional tasks </li>
    <li>Transfer learning success depends critically on the structural alignment between source and target tasks, suggesting that skill dependencies matter for learning efficiency </li>
    <li>Compositional generalization in language-based tasks requires systematic exposure to constituent components, with failure modes when components are not properly learned </li>
    <li>Starting with simpler tasks and gradually increasing complexity (a form of hierarchical curriculum) enables learning in neural networks that would otherwise fail </li>
    <li>Automatic curriculum generation methods that respect task structure and dependencies outperform random or flat orderings in reinforcement learning domains </li>
</ol>            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>In interactive text-based science experiment domains requiring multi-step procedures (e.g., measuring pH, then titration, then analysis), agents trained first on individual measurement skills before combined procedures will reach target performance levels with substantially fewer training episodes than agents trained on the full task from the start, with the gap widening as procedure complexity increases.</li>
                <li>For commonsense tasks in text environments requiring multiple levels of skill composition (e.g., 'make breakfast' requiring 'cook eggs' requiring 'crack eggs' requiring 'grasp objects'), a curriculum respecting all compositional levels will outperform curricula with fewer levels of hierarchy in sample efficiency, with benefits most pronounced for agents with limited model capacity.</li>
                <li>Agents trained on a curriculum that violates strong dependency order (teaching complex skills before critical prerequisites) will show learning curves with longer plateaus and higher variance compared to properly ordered curricula, which will show more consistent improvement.</li>
                <li>The performance gap between hierarchical and flat curricula will be measurable even for moderately simple tasks (2-3 sub-skills with clear dependencies) and will grow with the number of compositional levels, particularly in sparse reward settings.</li>
                <li>In text-based interactive environments with procedural tasks, curriculum learning approaches that explicitly model skill dependencies will achieve target performance with fewer environment interactions than approaches that use random or difficulty-based orderings without considering compositional structure.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>There may exist a critical 'composition depth' threshold (potentially 5-7 levels depending on domain and architecture) beyond which even optimal hierarchical curricula fail to enable learning within practical sample budgets for current model architectures, suggesting fundamental limits on compositional learning depth.</li>
                <li>Hierarchical curricula might enable zero-shot or few-shot generalization to novel procedure combinations that were never seen during training, but only if the curriculum structure matches the underlying causal and compositional structure of the domain - mismatched hierarchies might actually harm generalization compared to flat curricula.</li>
                <li>The necessity of hierarchical structure might diminish or disappear for sufficiently large language models with extensive pre-training (e.g., models with 100B+ parameters trained on diverse procedural text), suggesting the theory applies primarily to sample-efficient learning regimes or smaller models without extensive prior knowledge.</li>
                <li>Automatically discovered curriculum hierarchies (through meta-learning, curriculum generation algorithms, or analysis of human learning data) might reveal non-obvious skill dependencies and compositional structures that outperform expert-designed hierarchies, potentially discovering that some seemingly complex skills are actually primitive and vice versa.</li>
                <li>The interaction between curriculum structure and exploration strategy may be critical - hierarchical curricula might only show strong benefits when paired with appropriate exploration methods that can exploit the compositional structure.</li>
                <li>In highly interactive text environments with rich natural language feedback, the necessity of explicit hierarchical curricula might be reduced because the language feedback itself provides implicit curriculum structure through graded hints and explanations.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>Finding a complex compositional task in an interactive text environment (with 4+ levels of clear dependencies and sparse rewards) where a flat curriculum achieves comparable sample efficiency to an optimal hierarchical curriculum would challenge the necessity claim for that complexity regime.</li>
                <li>Demonstrating successful and sample-efficient learning of a higher-level skill without any prior exposure to its constituent sub-skills (when those sub-skills have clear prerequisite relationships) would violate the prerequisite dependency assumption.</li>
                <li>Showing that randomizing the order of skill presentation in a curriculum produces statistically equivalent results to a carefully ordered hierarchical curriculum (controlling for total training time and task exposure) would suggest the hierarchical structure is not necessary.</li>
                <li>Finding that agents can learn complex multi-step procedures in text environments efficiently by only observing complete task demonstrations without any curriculum structure or sub-skill training would challenge the theory's core claims about compositional learning necessity.</li>
                <li>Demonstrating that a very large pre-trained language model can learn complex compositional procedures in text environments with flat curricula as efficiently as smaller models with hierarchical curricula would suggest the necessity is contingent on model capacity rather than fundamental.</li>
                <li>Finding cases where violating prerequisite order (teaching complex skills first) actually improves learning efficiency compared to respecting dependencies would directly contradict the theory.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>The theory does not specify how to automatically discover the optimal hierarchical structure for a given domain - it assumes the skill decomposition and dependencies are known, can be determined through domain analysis, or can be learned, but does not provide a method for doing so. </li>
    <li>The role of model architecture and its interaction with curriculum structure is not fully specified - different architectures (e.g., modular networks, transformers, recurrent networks) may have different sensitivities to curriculum structure. </li>
    <li>The role of exploration strategies and their interaction with curriculum structure is not fully specified in the theory - optimal exploration may differ between hierarchical and flat curricula. </li>
    <li>The theory does not account for partial skill mastery or fuzzy prerequisite relationships where skills may be partially learned in parallel or where dependencies are probabilistic rather than absolute. </li>
    <li>The specific characteristics of interactive text environments (natural language state/action spaces, partial observability, linguistic ambiguity) and how they interact with curriculum structure are not fully elaborated. </li>
    <li>The theory does not fully address how reward structure (dense vs. sparse, shaped vs. unshaped) interacts with the necessity of hierarchical curricula, though it acknowledges reward sparsity as a factor. </li>
    <li>The role of prior knowledge from pre-training (especially for language models) and how it affects the necessity of hierarchical curricula is acknowledged but not fully theorized. </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> closely-related-to-existing</p>
            <p><strong>Explanation:</strong> No explanation provided.</p>
            <p><strong>References:</strong> <ul>
    <li>Elman (1993) Learning and development in neural networks: the importance of starting small [Early foundational work showing benefits of curriculum learning, but focused on benefits rather than necessity]</li>
    <li>Bengio et al. (2009) Curriculum Learning [Foundational work on curriculum learning showing benefits across domains, but does not make strong necessity claims or focus on hierarchical structure]</li>
    <li>Narvekar et al. (2020) Curriculum Learning for Reinforcement Learning Domains: A Framework and Survey [Comprehensive survey of curriculum learning in RL, discusses benefits and methods but does not propose a necessity theory]</li>
    <li>Florensa et al. (2017) Reverse Curriculum Generation for Reinforcement Learning [Automatic curriculum generation respecting task structure, but does not frame as necessity theory]</li>
    <li>Andreas et al. (2017) Modular Multitask Reinforcement Learning with Policy Sketches [Hierarchical task decomposition showing benefits, but not framed as necessity theory]</li>
    <li>Tessler et al. (2017) A Deep Hierarchical Approach to Lifelong Learning in Minecraft [Demonstrates hierarchical curriculum benefits in complex environment, but does not make necessity claims]</li>
    <li>Eppe et al. (2022) Intelligent Problem-Solving as Integrated Hierarchical Reinforcement Learning [Recent work on hierarchical learning but focused on problem-solving architecture rather than curriculum necessity]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Hierarchical Curriculum Necessity Theory",
    "theory_description": "This theory posits that for compositional acquisition of complex procedures in interactive text environments, a hierarchical curriculum structure is necessary for sample-efficient learning when task complexity exceeds certain thresholds. The theory states that complex procedures must be decomposed into prerequisite sub-skills that are learned in a specific dependency order, where higher-level skills cannot be efficiently acquired without first mastering their constituent lower-level components. This necessity arises from the compositional nature of procedural knowledge in text-based environments, where the state-action space for complex tasks becomes too large to explore efficiently without first constraining it through mastery of sub-procedures. The theory predicts that flat (non-hierarchical) curricula will show dramatically reduced sample efficiency (polynomial to exponential scaling differences) for tasks beyond a complexity threshold, while hierarchical curricula that respect skill dependencies will maintain more favorable scaling properties. The necessity is strongest under conditions of limited model capacity, sparse rewards, and deep compositional structure.",
    "supporting_evidence": [
        {
            "text": "Curriculum learning approaches show significant improvements in sample efficiency for reinforcement learning tasks, with benefits increasing as task complexity grows",
            "citations": [
                "Narvekar et al. (2020) Curriculum Learning for Reinforcement Learning Domains: A Framework and Survey",
                "Bengio et al. (2009) Curriculum Learning"
            ]
        },
        {
            "text": "Hierarchical task decomposition in curriculum design shows improved learning efficiency in complex interactive environments, particularly for compositional tasks",
            "citations": [
                "Andreas et al. (2017) Modular Multitask Reinforcement Learning with Policy Sketches",
                "Tessler et al. (2017) A Deep Hierarchical Approach to Lifelong Learning in Minecraft"
            ]
        },
        {
            "text": "Transfer learning success depends critically on the structural alignment between source and target tasks, suggesting that skill dependencies matter for learning efficiency",
            "citations": [
                "Taylor and Stone (2009) Transfer Learning for Reinforcement Learning Domains: A Survey"
            ]
        },
        {
            "text": "Compositional generalization in language-based tasks requires systematic exposure to constituent components, with failure modes when components are not properly learned",
            "citations": [
                "Lake and Baroni (2018) Generalization without Systematicity: On the Compositional Skills of Sequence-to-Sequence Recurrent Networks"
            ]
        },
        {
            "text": "Starting with simpler tasks and gradually increasing complexity (a form of hierarchical curriculum) enables learning in neural networks that would otherwise fail",
            "citations": [
                "Elman (1993) Learning and development in neural networks: the importance of starting small"
            ]
        },
        {
            "text": "Automatic curriculum generation methods that respect task structure and dependencies outperform random or flat orderings in reinforcement learning domains",
            "citations": [
                "Florensa et al. (2017) Reverse Curriculum Generation for Reinforcement Learning"
            ]
        }
    ],
    "theory_statements": [
        "For complex procedures P that can be decomposed into sub-procedures {S1, S2, ..., Sn} with dependency relationships, there exists a complexity threshold C_threshold (determined by factors including compositional depth, state-space size, and reward sparsity) above which learning P directly requires substantially more samples (often orders of magnitude) than learning through a hierarchical curriculum that respects dependencies.",
        "The optimal curriculum structure can be represented as a directed acyclic graph (DAG) where nodes represent skills and edges represent prerequisite relationships, and learning efficiency is improved when the curriculum ordering approximates a topological sort of this DAG, with efficiency gains increasing with the strength of the dependency relationships.",
        "Sub-skills that are compositionally reused across multiple higher-level procedures should be learned to a functional competency threshold before those higher-level procedures are introduced, with the required competency level depending on how critical the sub-skill is to the higher-level task.",
        "The benefit of hierarchical structure (relative to flat curricula) increases with: (a) the depth of compositional dependencies, (b) the sparsity of reward signals, (c) the size of the state-action space, and (d) limitations in model capacity and prior knowledge.",
        "Violation of strong prerequisite ordering (learning higher-level skills before critical prerequisites) results in significant sample inefficiency that manifests as slower learning, higher variance, and potential learning plateaus, though the severity depends on the strength of the dependency relationship."
    ],
    "new_predictions_likely": [
        "In interactive text-based science experiment domains requiring multi-step procedures (e.g., measuring pH, then titration, then analysis), agents trained first on individual measurement skills before combined procedures will reach target performance levels with substantially fewer training episodes than agents trained on the full task from the start, with the gap widening as procedure complexity increases.",
        "For commonsense tasks in text environments requiring multiple levels of skill composition (e.g., 'make breakfast' requiring 'cook eggs' requiring 'crack eggs' requiring 'grasp objects'), a curriculum respecting all compositional levels will outperform curricula with fewer levels of hierarchy in sample efficiency, with benefits most pronounced for agents with limited model capacity.",
        "Agents trained on a curriculum that violates strong dependency order (teaching complex skills before critical prerequisites) will show learning curves with longer plateaus and higher variance compared to properly ordered curricula, which will show more consistent improvement.",
        "The performance gap between hierarchical and flat curricula will be measurable even for moderately simple tasks (2-3 sub-skills with clear dependencies) and will grow with the number of compositional levels, particularly in sparse reward settings.",
        "In text-based interactive environments with procedural tasks, curriculum learning approaches that explicitly model skill dependencies will achieve target performance with fewer environment interactions than approaches that use random or difficulty-based orderings without considering compositional structure."
    ],
    "new_predictions_unknown": [
        "There may exist a critical 'composition depth' threshold (potentially 5-7 levels depending on domain and architecture) beyond which even optimal hierarchical curricula fail to enable learning within practical sample budgets for current model architectures, suggesting fundamental limits on compositional learning depth.",
        "Hierarchical curricula might enable zero-shot or few-shot generalization to novel procedure combinations that were never seen during training, but only if the curriculum structure matches the underlying causal and compositional structure of the domain - mismatched hierarchies might actually harm generalization compared to flat curricula.",
        "The necessity of hierarchical structure might diminish or disappear for sufficiently large language models with extensive pre-training (e.g., models with 100B+ parameters trained on diverse procedural text), suggesting the theory applies primarily to sample-efficient learning regimes or smaller models without extensive prior knowledge.",
        "Automatically discovered curriculum hierarchies (through meta-learning, curriculum generation algorithms, or analysis of human learning data) might reveal non-obvious skill dependencies and compositional structures that outperform expert-designed hierarchies, potentially discovering that some seemingly complex skills are actually primitive and vice versa.",
        "The interaction between curriculum structure and exploration strategy may be critical - hierarchical curricula might only show strong benefits when paired with appropriate exploration methods that can exploit the compositional structure.",
        "In highly interactive text environments with rich natural language feedback, the necessity of explicit hierarchical curricula might be reduced because the language feedback itself provides implicit curriculum structure through graded hints and explanations."
    ],
    "negative_experiments": [
        "Finding a complex compositional task in an interactive text environment (with 4+ levels of clear dependencies and sparse rewards) where a flat curriculum achieves comparable sample efficiency to an optimal hierarchical curriculum would challenge the necessity claim for that complexity regime.",
        "Demonstrating successful and sample-efficient learning of a higher-level skill without any prior exposure to its constituent sub-skills (when those sub-skills have clear prerequisite relationships) would violate the prerequisite dependency assumption.",
        "Showing that randomizing the order of skill presentation in a curriculum produces statistically equivalent results to a carefully ordered hierarchical curriculum (controlling for total training time and task exposure) would suggest the hierarchical structure is not necessary.",
        "Finding that agents can learn complex multi-step procedures in text environments efficiently by only observing complete task demonstrations without any curriculum structure or sub-skill training would challenge the theory's core claims about compositional learning necessity.",
        "Demonstrating that a very large pre-trained language model can learn complex compositional procedures in text environments with flat curricula as efficiently as smaller models with hierarchical curricula would suggest the necessity is contingent on model capacity rather than fundamental.",
        "Finding cases where violating prerequisite order (teaching complex skills first) actually improves learning efficiency compared to respecting dependencies would directly contradict the theory."
    ],
    "unaccounted_for": [
        {
            "text": "The theory does not specify how to automatically discover the optimal hierarchical structure for a given domain - it assumes the skill decomposition and dependencies are known, can be determined through domain analysis, or can be learned, but does not provide a method for doing so.",
            "citations": []
        },
        {
            "text": "The role of model architecture and its interaction with curriculum structure is not fully specified - different architectures (e.g., modular networks, transformers, recurrent networks) may have different sensitivities to curriculum structure.",
            "citations": []
        },
        {
            "text": "The role of exploration strategies and their interaction with curriculum structure is not fully specified in the theory - optimal exploration may differ between hierarchical and flat curricula.",
            "citations": []
        },
        {
            "text": "The theory does not account for partial skill mastery or fuzzy prerequisite relationships where skills may be partially learned in parallel or where dependencies are probabilistic rather than absolute.",
            "citations": []
        },
        {
            "text": "The specific characteristics of interactive text environments (natural language state/action spaces, partial observability, linguistic ambiguity) and how they interact with curriculum structure are not fully elaborated.",
            "citations": []
        },
        {
            "text": "The theory does not fully address how reward structure (dense vs. sparse, shaped vs. unshaped) interacts with the necessity of hierarchical curricula, though it acknowledges reward sparsity as a factor.",
            "citations": []
        },
        {
            "text": "The role of prior knowledge from pre-training (especially for language models) and how it affects the necessity of hierarchical curricula is acknowledged but not fully theorized.",
            "citations": []
        }
    ],
    "conflicting_evidence": [
        {
            "text": "Some end-to-end learning approaches have shown success on extremely complex tasks without explicit hierarchical curriculum structure, suggesting that with sufficient compute and samples, hierarchical curricula may not be strictly necessary.",
            "citations": [
                "Vinyals et al. (2019) Grandmaster level in StarCraft II using multi-agent reinforcement learning",
                "OpenAI et al. (2019) Dota 2 with Large Scale Deep Reinforcement Learning"
            ]
        },
        {
            "text": "Meta-learning approaches can sometimes enable rapid adaptation to complex tasks without hierarchical curriculum exposure during meta-training, suggesting alternative paths to compositional learning.",
            "citations": [
                "Finn et al. (2017) Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks"
            ]
        },
        {
            "text": "Large language models with extensive pre-training have shown ability to perform complex multi-step reasoning and procedural tasks with minimal task-specific training, potentially reducing the necessity of explicit hierarchical curricula.",
            "citations": [
                "Brown et al. (2020) Language Models are Few-Shot Learners",
                "Wei et al. (2022) Chain-of-Thought Prompting Elicits Reasoning in Large Language Models"
            ]
        }
    ],
    "special_cases": [
        "For tasks with very shallow compositional structure (1-2 levels) or weak dependency relationships, the benefits of hierarchical curricula may be marginal and not strictly necessary, with flat curricula achieving comparable efficiency.",
        "In domains with dense reward signals and small state-action spaces, flat curricula may be sufficient even for moderately complex tasks, as the learning signal is strong enough to guide exploration without curriculum structure.",
        "When using very large pre-trained language models with extensive prior knowledge of procedures and commonsense reasoning, the necessity of hierarchical structure may be substantially reduced as the model already possesses relevant sub-skills and compositional knowledge.",
        "For tasks where sub-skills can be learned implicitly through repeated exposure to the full task (i.e., where the full task provides sufficient learning signal for sub-skills), explicit hierarchical curriculum may not be necessary, though it may still improve efficiency.",
        "In settings with unlimited computational resources and training time, the necessity claim weakens to an efficiency claim - hierarchical curricula may not be necessary for eventual success but remain beneficial for sample efficiency.",
        "For highly modular architectures that explicitly represent sub-skills (e.g., modular policy networks), the benefits of hierarchical curricula may be amplified, while for monolithic architectures, the benefits may be reduced.",
        "In interactive text environments with rich natural language feedback and explanations, the environment itself may provide implicit curriculum structure that reduces the necessity of explicit hierarchical curriculum design."
    ],
    "existing_theory": {
        "likely_classification": "closely-related-to-existing",
        "references": [
            "Elman (1993) Learning and development in neural networks: the importance of starting small [Early foundational work showing benefits of curriculum learning, but focused on benefits rather than necessity]",
            "Bengio et al. (2009) Curriculum Learning [Foundational work on curriculum learning showing benefits across domains, but does not make strong necessity claims or focus on hierarchical structure]",
            "Narvekar et al. (2020) Curriculum Learning for Reinforcement Learning Domains: A Framework and Survey [Comprehensive survey of curriculum learning in RL, discusses benefits and methods but does not propose a necessity theory]",
            "Florensa et al. (2017) Reverse Curriculum Generation for Reinforcement Learning [Automatic curriculum generation respecting task structure, but does not frame as necessity theory]",
            "Andreas et al. (2017) Modular Multitask Reinforcement Learning with Policy Sketches [Hierarchical task decomposition showing benefits, but not framed as necessity theory]",
            "Tessler et al. (2017) A Deep Hierarchical Approach to Lifelong Learning in Minecraft [Demonstrates hierarchical curriculum benefits in complex environment, but does not make necessity claims]",
            "Eppe et al. (2022) Intelligent Problem-Solving as Integrated Hierarchical Reinforcement Learning [Recent work on hierarchical learning but focused on problem-solving architecture rather than curriculum necessity]"
        ]
    },
    "theory_type_general_specific": "general",
    "reflected_from_theory_index": 0,
    "theory_query": "Build a theory about optimal curricula for compositional acquisition of commonsense and science procedures in interactive text environments.. Please focus on creating new theories that have not been proposed before in the literature.",
    "generation_mode": "llm_baseline_no_evidence",
    "original_theory_id": "theory-171",
    "original_theory_name": "Hierarchical Curriculum Necessity Theory",
    "model_str": "claude-sonnet-4-5-20250929"
}</code></pre>
        </div>
    </div>
</body>
</html>