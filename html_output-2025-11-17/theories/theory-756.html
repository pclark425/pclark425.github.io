<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Pattern-Completion Theory - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-756</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-756</p>
                <p><strong>Name:</strong> Pattern-Completion Theory</p>
                <p><strong>Type:</strong> general</p>
                <p><strong>Theory Query:</strong> Build a theory of how language models perform arithmetic.</p>
                <p><strong>Description:</strong> Language models perform arithmetic primarily by leveraging statistical regularities and patterns in the training data, completing token sequences based on observed co-occurrences, rather than by executing explicit algorithmic procedures. This theory posits that arithmetic ability in LLMs is a byproduct of next-token prediction, with accuracy determined by the frequency and consistency of arithmetic patterns in the training corpus.</p>
                <p><strong>Knowledge Cutoff Year:</strong> -1</p>
                <p><strong>Knowledge Cutoff Month:</strong> -1</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <h3>Statement 0: Statistical Pattern Completion (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; language model &#8594; is_trained_on &#8594; large text corpus<span style="color: #888888;">, and</span></div>
        <div>&#8226; arithmetic query &#8594; is_presented_to &#8594; language model</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; language model &#8594; predicts_answer &#8594; by completing token sequence using statistical regularities</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>LLMs perform well on arithmetic problems that are common in their training data, and poorly on rare or out-of-distribution problems. </li>
    <li>Performance on arithmetic degrades for longer numbers or novel formats, suggesting reliance on pattern completion rather than algorithmic computation. </li>
    <li>LLMs often produce plausible but incorrect answers for arithmetic queries outside their training distribution, consistent with pattern-based completion. </li>
    <li>When arithmetic queries are phrased in unfamiliar formats, LLMs' accuracy drops sharply, indicating lack of underlying algorithmic generalization. </li>
    <li>LLMs can be tricked into producing incorrect arithmetic answers by priming with incorrect examples, showing susceptibility to local context patterns. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> While related to existing work on LLMs' pattern-matching abilities, this law formalizes the mechanism for arithmetic as pattern completion, which is a novel, explicit framing.</p>            <p><strong>What Already Exists:</strong> It is known that LLMs are trained for next-token prediction and can leverage statistical regularities for many tasks.</p>            <p><strong>What is Novel:</strong> This law explicitly frames arithmetic performance as a direct consequence of pattern completion, not algorithmic reasoning, and predicts systematic failure modes.</p>
            <p><strong>References:</strong> <ul>
    <li>Marcus & Davis (2020) GPT-3, Bloviator: OpenAI’s language generator has no idea what it’s talking about [Discusses pattern-matching in LLMs]</li>
    <li>Wei et al. (2022) Emergent Abilities of Large Language Models [Notes LLMs' surprising abilities, but does not formalize arithmetic as pattern completion]</li>
    <li>Brown et al. (2020) Language Models are Few-Shot Learners [Describes next-token prediction and pattern learning in LLMs]</li>
</ul>
            <h3>Statement 1: Frequency-Dependent Arithmetic Accuracy (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; arithmetic problem &#8594; is_frequent_in &#8594; training data</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; language model &#8594; is_more_likely_to_answer_correctly &#8594; arithmetic problem</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>LLMs are more accurate on arithmetic facts (e.g., '2+2=4') that are common in text, and less accurate on rare or large-number problems. </li>
    <li>Accuracy of LLMs on arithmetic tasks correlates with the frequency of those problems in the training data. </li>
    <li>LLMs show a smooth gradient of accuracy as arithmetic problems become less frequent, rather than a sharp drop-off, indicating frequency-based interpolation. </li>
    <li>When arithmetic facts are deliberately mislabelled in synthetic training data, LLMs reproduce those errors, showing dependence on observed frequencies. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> closely-related-to-existing</p>
            <p><strong>Explanation:</strong> The frequency-accuracy link is known, but its explicit application to arithmetic as a general law is novel.</p>            <p><strong>What Already Exists:</strong> It is observed that LLMs are better at frequent facts, and this is often attributed to memorization.</p>            <p><strong>What is Novel:</strong> This law generalizes the effect to all arithmetic, predicting a smooth accuracy gradient based on frequency, not just memorized facts.</p>
            <p><strong>References:</strong> <ul>
    <li>Brown et al. (2020) Language Models are Few-Shot Learners [Notes frequency effects in LLM performance]</li>
    <li>Patel et al. (2022) Are Emergent Abilities of Large Language Models a Mirage? [Discusses frequency and interpolation in LLMs]</li>
    <li>Wei et al. (2022) Emergent Abilities of Large Language Models [Discusses frequency and interpolation in LLMs]</li>
</ul>
            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>LLMs will perform better on arithmetic problems that are more common in their training data, regardless of the underlying operation.</li>
                <li>If a new arithmetic format (e.g., 'add(12,34)=') is introduced, LLMs will initially perform poorly until exposed to sufficient examples.</li>
                <li>LLMs will make systematic errors on rare or out-of-distribution arithmetic problems, often producing plausible but incorrect answers.</li>
                <li>Priming LLMs with incorrect arithmetic examples will bias their subsequent answers toward those errors.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>If an LLM is trained on a synthetic corpus where arithmetic problems are deliberately mislabelled, it will learn to reproduce those errors, indicating lack of true algorithmic understanding.</li>
                <li>If a model is trained on a corpus with a non-standard arithmetic system (e.g., base-7), it will perform arithmetic according to the most frequent patterns in the data, not according to base-10 rules.</li>
                <li>If a sufficiently large and diverse LLM is trained, it may begin to show partial generalization to arithmetic formats not seen in training, suggesting emergent algorithmic reasoning.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>If an LLM can consistently solve novel, large-number arithmetic problems with high accuracy, this would contradict the pattern-completion theory.</li>
                <li>If LLMs can generalize to new arithmetic formats without exposure, this would challenge the theory.</li>
                <li>If LLMs can resist priming with incorrect arithmetic examples and still produce correct answers, this would challenge the theory.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>Some LLMs show partial generalization to arithmetic formats not seen in training, suggesting possible emergent algorithmic reasoning. </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> closely-related-to-existing</p>
            <p><strong>Explanation:</strong> The theory is closely related to existing work on LLMs' reliance on statistical regularities, but its explicit application to arithmetic is novel.</p>
            <p><strong>References:</strong> <ul>
    <li>Marcus & Davis (2020) GPT-3, Bloviator: OpenAI’s language generator has no idea what it’s talking about [Pattern-matching in LLMs]</li>
    <li>Brown et al. (2020) Language Models are Few-Shot Learners [Frequency effects in LLMs]</li>
    <li>Patel et al. (2022) Are Emergent Abilities of Large Language Models a Mirage? [Interpolation and frequency effects]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Pattern-Completion Theory",
    "theory_description": "Language models perform arithmetic primarily by leveraging statistical regularities and patterns in the training data, completing token sequences based on observed co-occurrences, rather than by executing explicit algorithmic procedures. This theory posits that arithmetic ability in LLMs is a byproduct of next-token prediction, with accuracy determined by the frequency and consistency of arithmetic patterns in the training corpus.",
    "theory_statements": [
        {
            "law": {
                "law_name": "Statistical Pattern Completion",
                "if": [
                    {
                        "subject": "language model",
                        "relation": "is_trained_on",
                        "object": "large text corpus"
                    },
                    {
                        "subject": "arithmetic query",
                        "relation": "is_presented_to",
                        "object": "language model"
                    }
                ],
                "then": [
                    {
                        "subject": "language model",
                        "relation": "predicts_answer",
                        "object": "by completing token sequence using statistical regularities"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "LLMs perform well on arithmetic problems that are common in their training data, and poorly on rare or out-of-distribution problems.",
                        "uuids": []
                    },
                    {
                        "text": "Performance on arithmetic degrades for longer numbers or novel formats, suggesting reliance on pattern completion rather than algorithmic computation.",
                        "uuids": []
                    },
                    {
                        "text": "LLMs often produce plausible but incorrect answers for arithmetic queries outside their training distribution, consistent with pattern-based completion.",
                        "uuids": []
                    },
                    {
                        "text": "When arithmetic queries are phrased in unfamiliar formats, LLMs' accuracy drops sharply, indicating lack of underlying algorithmic generalization.",
                        "uuids": []
                    },
                    {
                        "text": "LLMs can be tricked into producing incorrect arithmetic answers by priming with incorrect examples, showing susceptibility to local context patterns.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "It is known that LLMs are trained for next-token prediction and can leverage statistical regularities for many tasks.",
                    "what_is_novel": "This law explicitly frames arithmetic performance as a direct consequence of pattern completion, not algorithmic reasoning, and predicts systematic failure modes.",
                    "classification_explanation": "While related to existing work on LLMs' pattern-matching abilities, this law formalizes the mechanism for arithmetic as pattern completion, which is a novel, explicit framing.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Marcus & Davis (2020) GPT-3, Bloviator: OpenAI’s language generator has no idea what it’s talking about [Discusses pattern-matching in LLMs]",
                        "Wei et al. (2022) Emergent Abilities of Large Language Models [Notes LLMs' surprising abilities, but does not formalize arithmetic as pattern completion]",
                        "Brown et al. (2020) Language Models are Few-Shot Learners [Describes next-token prediction and pattern learning in LLMs]"
                    ]
                }
            }
        },
        {
            "law": {
                "law_name": "Frequency-Dependent Arithmetic Accuracy",
                "if": [
                    {
                        "subject": "arithmetic problem",
                        "relation": "is_frequent_in",
                        "object": "training data"
                    }
                ],
                "then": [
                    {
                        "subject": "language model",
                        "relation": "is_more_likely_to_answer_correctly",
                        "object": "arithmetic problem"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "LLMs are more accurate on arithmetic facts (e.g., '2+2=4') that are common in text, and less accurate on rare or large-number problems.",
                        "uuids": []
                    },
                    {
                        "text": "Accuracy of LLMs on arithmetic tasks correlates with the frequency of those problems in the training data.",
                        "uuids": []
                    },
                    {
                        "text": "LLMs show a smooth gradient of accuracy as arithmetic problems become less frequent, rather than a sharp drop-off, indicating frequency-based interpolation.",
                        "uuids": []
                    },
                    {
                        "text": "When arithmetic facts are deliberately mislabelled in synthetic training data, LLMs reproduce those errors, showing dependence on observed frequencies.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "It is observed that LLMs are better at frequent facts, and this is often attributed to memorization.",
                    "what_is_novel": "This law generalizes the effect to all arithmetic, predicting a smooth accuracy gradient based on frequency, not just memorized facts.",
                    "classification_explanation": "The frequency-accuracy link is known, but its explicit application to arithmetic as a general law is novel.",
                    "likely_classification": "closely-related-to-existing",
                    "references": [
                        "Brown et al. (2020) Language Models are Few-Shot Learners [Notes frequency effects in LLM performance]",
                        "Patel et al. (2022) Are Emergent Abilities of Large Language Models a Mirage? [Discusses frequency and interpolation in LLMs]",
                        "Wei et al. (2022) Emergent Abilities of Large Language Models [Discusses frequency and interpolation in LLMs]"
                    ]
                }
            }
        }
    ],
    "new_predictions_likely": [
        "LLMs will perform better on arithmetic problems that are more common in their training data, regardless of the underlying operation.",
        "If a new arithmetic format (e.g., 'add(12,34)=') is introduced, LLMs will initially perform poorly until exposed to sufficient examples.",
        "LLMs will make systematic errors on rare or out-of-distribution arithmetic problems, often producing plausible but incorrect answers.",
        "Priming LLMs with incorrect arithmetic examples will bias their subsequent answers toward those errors."
    ],
    "new_predictions_unknown": [
        "If an LLM is trained on a synthetic corpus where arithmetic problems are deliberately mislabelled, it will learn to reproduce those errors, indicating lack of true algorithmic understanding.",
        "If a model is trained on a corpus with a non-standard arithmetic system (e.g., base-7), it will perform arithmetic according to the most frequent patterns in the data, not according to base-10 rules.",
        "If a sufficiently large and diverse LLM is trained, it may begin to show partial generalization to arithmetic formats not seen in training, suggesting emergent algorithmic reasoning."
    ],
    "negative_experiments": [
        "If an LLM can consistently solve novel, large-number arithmetic problems with high accuracy, this would contradict the pattern-completion theory.",
        "If LLMs can generalize to new arithmetic formats without exposure, this would challenge the theory.",
        "If LLMs can resist priming with incorrect arithmetic examples and still produce correct answers, this would challenge the theory."
    ],
    "unaccounted_for": [
        {
            "text": "Some LLMs show partial generalization to arithmetic formats not seen in training, suggesting possible emergent algorithmic reasoning.",
            "uuids": []
        }
    ],
    "conflicting_evidence": [
        {
            "text": "There are cases where LLMs can perform multi-step arithmetic with accuracy exceeding what would be expected from pattern completion alone.",
            "uuids": []
        }
    ],
    "special_cases": [
        "Very large models with extensive training may develop partial algorithmic reasoning, blurring the line between pattern completion and true computation.",
        "Fine-tuned models on arithmetic-specific data may show different behavior.",
        "Models with explicit architectural modifications (e.g., external memory or calculator modules) may not follow this theory."
    ],
    "existing_theory": {
        "what_already_exists": "Pattern-matching and frequency effects in LLMs are well-documented, but not always formalized as the primary mechanism for arithmetic.",
        "what_is_novel": "This theory explicitly frames arithmetic in LLMs as a pattern-completion process, predicting systematic error patterns and failure modes.",
        "classification_explanation": "The theory is closely related to existing work on LLMs' reliance on statistical regularities, but its explicit application to arithmetic is novel.",
        "likely_classification": "closely-related-to-existing",
        "references": [
            "Marcus & Davis (2020) GPT-3, Bloviator: OpenAI’s language generator has no idea what it’s talking about [Pattern-matching in LLMs]",
            "Brown et al. (2020) Language Models are Few-Shot Learners [Frequency effects in LLMs]",
            "Patel et al. (2022) Are Emergent Abilities of Large Language Models a Mirage? [Interpolation and frequency effects]"
        ]
    },
    "reflected_from_theory_index": 0,
    "type": "general",
    "version": "built-theory-from-results-single-theory-reflection2-nov14-2025-LLM-BASELINE-no-evidence-without-matched-control-theory-name",
    "theory_query": "Build a theory of how language models perform arithmetic.",
    "original_theory_id": "theory-580",
    "original_theory_name": "Emergent Algorithmic Reasoning via Chain-of-Thought and Program Synthesis in Large Language Models",
    "provide_matched_control_thery_name": false,
    "matched_control_theory_name": null,
    "model_str": "openai/gpt-4.1-2025-04-14"
}</code></pre>
        </div>
    </div>
</body>
</html>