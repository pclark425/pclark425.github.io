<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Cognitive Alignment Theory of Graph-to-Text Representation - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-1272</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-1272</p>
                <p><strong>Name:</strong> Cognitive Alignment Theory of Graph-to-Text Representation</p>
                <p><strong>Type:</strong> general</p>
                <p><strong>Theory Query:</strong> Build a theory of ideal representations for converting graphs into text for language model training.</p>
                <p><strong>Description:</strong> This theory posits that the ideal representation for converting graphs into text for language model (LM) training is one that aligns with human cognitive strategies for understanding and describing graphs. Such representations should leverage natural language patterns, narrative orderings, and salient substructures to facilitate both model learning and human interpretability, thereby improving both model performance and explainability.</p>
                <p><strong>Knowledge Cutoff Year:</strong> -1</p>
                <p><strong>Knowledge Cutoff Month:</strong> -1</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <h3>Statement 0: Cognitive Salience Law (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; graph_representation &#8594; orders &#8594; elements_by_cognitive_salience<span style="color: #888888;">, and</span></div>
        <div>&#8226; graph_representation &#8594; uses &#8594; natural_language_patterns</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; language_model &#8594; learns &#8594; graph-to-text_mappings_more_efficiently<span style="color: #888888;">, and</span></div>
        <div>&#8226; generated_text &#8594; is_more_interpretable &#8594; to_humans</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Human annotators prefer graph-to-text outputs that follow natural narrative order and highlight salient nodes/edges. </li>
    <li>LMs trained on cognitively-aligned representations show improved performance on human evaluation metrics. </li>
    <li>Cognitive science literature shows that humans process information more efficiently when salient elements are foregrounded and presented in familiar linguistic structures. </li>
    <li>Data-to-text NLG systems that use salience-based ordering produce more readable and preferred outputs. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> closely-related-to-existing</p>
            <p><strong>Explanation:</strong> The law extends cognitive principles from human annotation to LM training, which is a novel application.</p>            <p><strong>What Already Exists:</strong> Cognitive salience and natural ordering are known to improve human interpretability in data-to-text tasks.</p>            <p><strong>What is Novel:</strong> The law asserts that cognitive alignment is not just beneficial for interpretability, but also for model learning efficiency and generalization.</p>
            <p><strong>References:</strong> <ul>
    <li>Gatt & Krahmer (2018) Survey of the State of the Art in Natural Language Generation [cognitive salience in NLG]</li>
    <li>Reiter & Dale (2000) Building Natural Language Generation Systems [ordering and salience in NLG]</li>
    <li>van Dijk & Kintsch (1983) Strategies of Discourse Comprehension [cognitive salience in text processing]</li>
</ul>
            <h3>Statement 1: Narrative Structure Law (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; graph_representation &#8594; encodes &#8594; narrative_paths_or_subgraphs<span style="color: #888888;">, and</span></div>
        <div>&#8226; graph_representation &#8594; maps &#8594; graph_traversals_to_textual_sequences</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; language_model &#8594; can_generate &#8594; coherent_and_contextualized_text</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Narrative-ordered graph encodings improve coherence and context in generated text. </li>
    <li>Traversal-based encodings (e.g., BFS, DFS) have been shown to help LMs learn graph-to-text mappings. </li>
    <li>AMR-to-text and semantic graph-to-text systems that use narrative or event-based ordering produce more fluent and contextually appropriate outputs. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> closely-related-to-existing</p>
            <p><strong>Explanation:</strong> The law is closely related to existing NLG practices but extends them to a general theory for graph-to-text LM training.</p>            <p><strong>What Already Exists:</strong> Narrative structure and traversal-based encodings are used in some data-to-text systems.</p>            <p><strong>What is Novel:</strong> The law generalizes the principle to all graph-to-text tasks and claims it is necessary for optimal LM training.</p>
            <p><strong>References:</strong> <ul>
    <li>Konstas et al. (2017) Neural AMR: Sequence-to-Sequence Models for Parsing and Generation [narrative order in AMR-to-text]</li>
    <li>Gatt & Krahmer (2018) Survey of the State of the Art in Natural Language Generation [narrative structure in NLG]</li>
    <li>Moryossef et al. (2019) Step-by-Step: Separating Planning from Realization in Neural Data-to-Text Generation [narrative planning in NLG]</li>
</ul>
            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>If graph-to-text representations are reordered to match human narrative preferences, LMs will produce more coherent and human-like text.</li>
                <li>Cognitively-aligned representations will improve both automatic and human evaluation scores for graph-to-text generation tasks.</li>
                <li>Salience-based ordering will reduce the number of training epochs required for convergence in LM training.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>Cognitive alignment may enable LMs to learn implicit graph abstractions or analogies, improving transfer to novel graph types.</li>
                <li>Narrative-structured representations may allow LMs to generate multi-step reasoning chains from complex graphs, even in zero-shot settings.</li>
                <li>Highly cognitively-aligned representations may improve LM robustness to noisy or incomplete graph inputs.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>If cognitively-aligned representations do not improve LM performance or interpretability, the theory is challenged.</li>
                <li>If random or non-narrative orderings yield equal or better results, the necessity of cognitive alignment is called into question.</li>
                <li>If LMs trained on cognitively-aligned representations overfit or generalize poorly, the theory's generalization claim is weakened.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>The theory does not address the trade-off between cognitive alignment and representation compactness for very large graphs. </li>
    <li>The theory does not specify how to handle graphs with no clear narrative or salience (e.g., random or highly technical graphs). </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> closely-related-to-existing</p>
            <p><strong>Explanation:</strong> The theory generalizes cognitive principles to a new context, making it closely related but not identical to existing work.</p>
            <p><strong>References:</strong> <ul>
    <li>Gatt & Krahmer (2018) Survey of the State of the Art in Natural Language Generation [cognitive salience, narrative order]</li>
    <li>Reiter & Dale (2000) Building Natural Language Generation Systems [ordering and salience in NLG]</li>
    <li>Konstas et al. (2017) Neural AMR: Sequence-to-Sequence Models for Parsing and Generation [narrative order in AMR-to-text]</li>
    <li>van Dijk & Kintsch (1983) Strategies of Discourse Comprehension [cognitive salience in text processing]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Cognitive Alignment Theory of Graph-to-Text Representation",
    "theory_description": "This theory posits that the ideal representation for converting graphs into text for language model (LM) training is one that aligns with human cognitive strategies for understanding and describing graphs. Such representations should leverage natural language patterns, narrative orderings, and salient substructures to facilitate both model learning and human interpretability, thereby improving both model performance and explainability.",
    "theory_statements": [
        {
            "law": {
                "law_name": "Cognitive Salience Law",
                "if": [
                    {
                        "subject": "graph_representation",
                        "relation": "orders",
                        "object": "elements_by_cognitive_salience"
                    },
                    {
                        "subject": "graph_representation",
                        "relation": "uses",
                        "object": "natural_language_patterns"
                    }
                ],
                "then": [
                    {
                        "subject": "language_model",
                        "relation": "learns",
                        "object": "graph-to-text_mappings_more_efficiently"
                    },
                    {
                        "subject": "generated_text",
                        "relation": "is_more_interpretable",
                        "object": "to_humans"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Human annotators prefer graph-to-text outputs that follow natural narrative order and highlight salient nodes/edges.",
                        "uuids": []
                    },
                    {
                        "text": "LMs trained on cognitively-aligned representations show improved performance on human evaluation metrics.",
                        "uuids": []
                    },
                    {
                        "text": "Cognitive science literature shows that humans process information more efficiently when salient elements are foregrounded and presented in familiar linguistic structures.",
                        "uuids": []
                    },
                    {
                        "text": "Data-to-text NLG systems that use salience-based ordering produce more readable and preferred outputs.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Cognitive salience and natural ordering are known to improve human interpretability in data-to-text tasks.",
                    "what_is_novel": "The law asserts that cognitive alignment is not just beneficial for interpretability, but also for model learning efficiency and generalization.",
                    "classification_explanation": "The law extends cognitive principles from human annotation to LM training, which is a novel application.",
                    "likely_classification": "closely-related-to-existing",
                    "references": [
                        "Gatt & Krahmer (2018) Survey of the State of the Art in Natural Language Generation [cognitive salience in NLG]",
                        "Reiter & Dale (2000) Building Natural Language Generation Systems [ordering and salience in NLG]",
                        "van Dijk & Kintsch (1983) Strategies of Discourse Comprehension [cognitive salience in text processing]"
                    ]
                }
            }
        },
        {
            "law": {
                "law_name": "Narrative Structure Law",
                "if": [
                    {
                        "subject": "graph_representation",
                        "relation": "encodes",
                        "object": "narrative_paths_or_subgraphs"
                    },
                    {
                        "subject": "graph_representation",
                        "relation": "maps",
                        "object": "graph_traversals_to_textual_sequences"
                    }
                ],
                "then": [
                    {
                        "subject": "language_model",
                        "relation": "can_generate",
                        "object": "coherent_and_contextualized_text"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Narrative-ordered graph encodings improve coherence and context in generated text.",
                        "uuids": []
                    },
                    {
                        "text": "Traversal-based encodings (e.g., BFS, DFS) have been shown to help LMs learn graph-to-text mappings.",
                        "uuids": []
                    },
                    {
                        "text": "AMR-to-text and semantic graph-to-text systems that use narrative or event-based ordering produce more fluent and contextually appropriate outputs.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Narrative structure and traversal-based encodings are used in some data-to-text systems.",
                    "what_is_novel": "The law generalizes the principle to all graph-to-text tasks and claims it is necessary for optimal LM training.",
                    "classification_explanation": "The law is closely related to existing NLG practices but extends them to a general theory for graph-to-text LM training.",
                    "likely_classification": "closely-related-to-existing",
                    "references": [
                        "Konstas et al. (2017) Neural AMR: Sequence-to-Sequence Models for Parsing and Generation [narrative order in AMR-to-text]",
                        "Gatt & Krahmer (2018) Survey of the State of the Art in Natural Language Generation [narrative structure in NLG]",
                        "Moryossef et al. (2019) Step-by-Step: Separating Planning from Realization in Neural Data-to-Text Generation [narrative planning in NLG]"
                    ]
                }
            }
        }
    ],
    "new_predictions_likely": [
        "If graph-to-text representations are reordered to match human narrative preferences, LMs will produce more coherent and human-like text.",
        "Cognitively-aligned representations will improve both automatic and human evaluation scores for graph-to-text generation tasks.",
        "Salience-based ordering will reduce the number of training epochs required for convergence in LM training."
    ],
    "new_predictions_unknown": [
        "Cognitive alignment may enable LMs to learn implicit graph abstractions or analogies, improving transfer to novel graph types.",
        "Narrative-structured representations may allow LMs to generate multi-step reasoning chains from complex graphs, even in zero-shot settings.",
        "Highly cognitively-aligned representations may improve LM robustness to noisy or incomplete graph inputs."
    ],
    "negative_experiments": [
        "If cognitively-aligned representations do not improve LM performance or interpretability, the theory is challenged.",
        "If random or non-narrative orderings yield equal or better results, the necessity of cognitive alignment is called into question.",
        "If LMs trained on cognitively-aligned representations overfit or generalize poorly, the theory's generalization claim is weakened."
    ],
    "unaccounted_for": [
        {
            "text": "The theory does not address the trade-off between cognitive alignment and representation compactness for very large graphs.",
            "uuids": []
        },
        {
            "text": "The theory does not specify how to handle graphs with no clear narrative or salience (e.g., random or highly technical graphs).",
            "uuids": []
        }
    ],
    "conflicting_evidence": [
        {
            "text": "Some LMs can learn to generate coherent text from non-narrative, purely structural representations, especially with large-scale pretraining.",
            "uuids": []
        }
    ],
    "special_cases": [
        "Graphs with no clear narrative or salience (e.g., random graphs) may not benefit from cognitive alignment.",
        "For highly technical or domain-specific graphs, expert-driven orderings may outperform general cognitive strategies."
    ],
    "existing_theory": {
        "what_already_exists": "Cognitive alignment and narrative structure are established in NLG and human annotation.",
        "what_is_novel": "The explicit claim that cognitive alignment is necessary for ideal LM training on graph-to-text is new.",
        "classification_explanation": "The theory generalizes cognitive principles to a new context, making it closely related but not identical to existing work.",
        "likely_classification": "closely-related-to-existing",
        "references": [
            "Gatt & Krahmer (2018) Survey of the State of the Art in Natural Language Generation [cognitive salience, narrative order]",
            "Reiter & Dale (2000) Building Natural Language Generation Systems [ordering and salience in NLG]",
            "Konstas et al. (2017) Neural AMR: Sequence-to-Sequence Models for Parsing and Generation [narrative order in AMR-to-text]",
            "van Dijk & Kintsch (1983) Strategies of Discourse Comprehension [cognitive salience in text processing]"
        ]
    },
    "reflected_from_theory_index": 1,
    "type": "general",
    "version": "built-theory-from-results-single-theory-reflection2-nov14-2025-LLM-BASELINE-no-evidence-without-matched-control-theory-name",
    "theory_query": "Build a theory of ideal representations for converting graphs into text for language model training.",
    "original_theory_id": "theory-613",
    "original_theory_name": "Structural Faithfulness and Inductive Bias Preservation Theory",
    "provide_matched_control_thery_name": false,
    "matched_control_theory_name": null,
    "model_str": "openai/gpt-4.1-2025-04-14"
}</code></pre>
        </div>
    </div>
</body>
</html>