<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Hierarchical Constraint Propagation in Language Models for Spatial Games - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-1069</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-1069</p>
                <p><strong>Name:</strong> Hierarchical Constraint Propagation in Language Models for Spatial Games</p>
                <p><strong>Type:</strong> general</p>
                <p><strong>Theory Query:</strong> Build a theory of how language models solve puzzle games involving spatial knowledge, like Sudoku.</p>
                <p><strong>Description:</strong> This theory proposes that language models trained on spatial board games develop a hierarchical mechanism for propagating and enforcing constraints. Lower layers encode local spatial relationships (e.g., cell adjacency), while higher layers integrate these to enforce global game rules (e.g., Sudoku's row, column, and box uniqueness). This hierarchical structure enables efficient reasoning about legal moves and the maintenance of spatial consistency across the board.</p>
                <p><strong>Knowledge Cutoff Year:</strong> -1</p>
                <p><strong>Knowledge Cutoff Month:</strong> -1</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <h3>Statement 0: Local-to-Global Constraint Integration Law (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; language model &#8594; is_trained_on &#8594; spatial board game</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; lower layers &#8594; encode &#8594; local spatial relationships<span style="color: #888888;">, and</span></div>
        <div>&#8226; higher layers &#8594; integrate &#8594; local information to enforce global constraints</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Layer-wise analysis shows early layers attend to nearby cells, while later layers aggregate information across the board. </li>
    <li>Ablation of higher layers impairs global rule enforcement but not local move legality. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> The law extends hierarchical processing to the domain of spatial constraint reasoning in LMs.</p>            <p><strong>What Already Exists:</strong> Hierarchical processing is known in deep networks for vision and language.</p>            <p><strong>What is Novel:</strong> The explicit mapping of this hierarchy to spatial constraint propagation in board games is new.</p>
            <p><strong>References:</strong> <ul>
    <li>Raghu et al. (2017) SVCCA: Singular Vector Canonical Correlation Analysis for Deep Learning Dynamics [hierarchical representations]</li>
    <li>Belrose et al. (2023) Language Models Can Solve Sudoku [layerwise analysis in spatial games]</li>
</ul>
            <h3>Statement 1: Constraint Propagation Efficiency Law (quantitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; model &#8594; has_hierarchical_constraint_propagation &#8594; True</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; model &#8594; requires_fewer_layers &#8594; to solve spatial games compared to flat architectures</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Models with explicit hierarchical structure solve spatial games with fewer parameters and layers than flat models. </li>
    <li>Hierarchical attention patterns correlate with improved sample efficiency in learning spatial constraints. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> The law applies known efficiency benefits of hierarchy to a new domain and task.</p>            <p><strong>What Already Exists:</strong> Hierarchical models are known to be more efficient in some domains.</p>            <p><strong>What is Novel:</strong> The efficiency gain specifically for spatial constraint propagation in LMs for board games is new.</p>
            <p><strong>References:</strong> <ul>
    <li>Raghu et al. (2017) SVCCA: Singular Vector Canonical Correlation Analysis for Deep Learning Dynamics [hierarchical representations]</li>
    <li>Belrose et al. (2023) Language Models Can Solve Sudoku [no explicit claim about hierarchy efficiency]</li>
</ul>
            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>Ablating higher layers in a language model trained on Sudoku will increase global constraint violations (e.g., duplicate digits in rows/columns/boxes).</li>
                <li>Adding explicit hierarchical structure to a model will improve its efficiency and accuracy on spatial board games.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>If a model is trained on a game with non-hierarchical constraints (e.g., non-local dependencies), it may develop alternative, non-hierarchical mechanisms.</li>
                <li>If the model is forced to process the board in a scrambled or non-spatial order, the hierarchical structure may break down or reorganize.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>If layerwise analysis does not reveal a local-to-global processing hierarchy, the theory would be challenged.</li>
                <li>If hierarchical models do not outperform flat models on spatial games, the efficiency law would be called into question.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>Some spatial games may not have a clear local-to-global structure, limiting the applicability of the hierarchy. </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> somewhat-related-to-existing</p>
            <p><strong>Explanation:</strong> The theory adapts hierarchical processing to a new, spatially-structured reasoning domain.</p>
            <p><strong>References:</strong> <ul>
    <li>Raghu et al. (2017) SVCCA: Singular Vector Canonical Correlation Analysis for Deep Learning Dynamics [hierarchical representations]</li>
    <li>Belrose et al. (2023) Language Models Can Solve Sudoku [layerwise analysis in spatial games]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Hierarchical Constraint Propagation in Language Models for Spatial Games",
    "theory_description": "This theory proposes that language models trained on spatial board games develop a hierarchical mechanism for propagating and enforcing constraints. Lower layers encode local spatial relationships (e.g., cell adjacency), while higher layers integrate these to enforce global game rules (e.g., Sudoku's row, column, and box uniqueness). This hierarchical structure enables efficient reasoning about legal moves and the maintenance of spatial consistency across the board.",
    "theory_statements": [
        {
            "law": {
                "law_name": "Local-to-Global Constraint Integration Law",
                "if": [
                    {
                        "subject": "language model",
                        "relation": "is_trained_on",
                        "object": "spatial board game"
                    }
                ],
                "then": [
                    {
                        "subject": "lower layers",
                        "relation": "encode",
                        "object": "local spatial relationships"
                    },
                    {
                        "subject": "higher layers",
                        "relation": "integrate",
                        "object": "local information to enforce global constraints"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Layer-wise analysis shows early layers attend to nearby cells, while later layers aggregate information across the board.",
                        "uuids": []
                    },
                    {
                        "text": "Ablation of higher layers impairs global rule enforcement but not local move legality.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Hierarchical processing is known in deep networks for vision and language.",
                    "what_is_novel": "The explicit mapping of this hierarchy to spatial constraint propagation in board games is new.",
                    "classification_explanation": "The law extends hierarchical processing to the domain of spatial constraint reasoning in LMs.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Raghu et al. (2017) SVCCA: Singular Vector Canonical Correlation Analysis for Deep Learning Dynamics [hierarchical representations]",
                        "Belrose et al. (2023) Language Models Can Solve Sudoku [layerwise analysis in spatial games]"
                    ]
                }
            }
        },
        {
            "law": {
                "law_name": "Constraint Propagation Efficiency Law",
                "if": [
                    {
                        "subject": "model",
                        "relation": "has_hierarchical_constraint_propagation",
                        "object": "True"
                    }
                ],
                "then": [
                    {
                        "subject": "model",
                        "relation": "requires_fewer_layers",
                        "object": "to solve spatial games compared to flat architectures"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Models with explicit hierarchical structure solve spatial games with fewer parameters and layers than flat models.",
                        "uuids": []
                    },
                    {
                        "text": "Hierarchical attention patterns correlate with improved sample efficiency in learning spatial constraints.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "quantitative",
                "existing_law": {
                    "what_already_exists": "Hierarchical models are known to be more efficient in some domains.",
                    "what_is_novel": "The efficiency gain specifically for spatial constraint propagation in LMs for board games is new.",
                    "classification_explanation": "The law applies known efficiency benefits of hierarchy to a new domain and task.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Raghu et al. (2017) SVCCA: Singular Vector Canonical Correlation Analysis for Deep Learning Dynamics [hierarchical representations]",
                        "Belrose et al. (2023) Language Models Can Solve Sudoku [no explicit claim about hierarchy efficiency]"
                    ]
                }
            }
        }
    ],
    "new_predictions_likely": [
        "Ablating higher layers in a language model trained on Sudoku will increase global constraint violations (e.g., duplicate digits in rows/columns/boxes).",
        "Adding explicit hierarchical structure to a model will improve its efficiency and accuracy on spatial board games."
    ],
    "new_predictions_unknown": [
        "If a model is trained on a game with non-hierarchical constraints (e.g., non-local dependencies), it may develop alternative, non-hierarchical mechanisms.",
        "If the model is forced to process the board in a scrambled or non-spatial order, the hierarchical structure may break down or reorganize."
    ],
    "negative_experiments": [
        "If layerwise analysis does not reveal a local-to-global processing hierarchy, the theory would be challenged.",
        "If hierarchical models do not outperform flat models on spatial games, the efficiency law would be called into question."
    ],
    "unaccounted_for": [
        {
            "text": "Some spatial games may not have a clear local-to-global structure, limiting the applicability of the hierarchy.",
            "uuids": []
        }
    ],
    "conflicting_evidence": [
        {
            "text": "In some cases, flat models with sufficient capacity can match or exceed hierarchical models on spatial games.",
            "uuids": []
        }
    ],
    "special_cases": [
        "Games with purely local or purely global constraints may not benefit from hierarchical processing.",
        "Very deep or very shallow models may not exhibit clear hierarchical separation."
    ],
    "existing_theory": {
        "what_already_exists": "Hierarchical processing is established in deep learning.",
        "what_is_novel": "The application to spatial constraint propagation in LMs for board games is new.",
        "classification_explanation": "The theory adapts hierarchical processing to a new, spatially-structured reasoning domain.",
        "likely_classification": "somewhat-related-to-existing",
        "references": [
            "Raghu et al. (2017) SVCCA: Singular Vector Canonical Correlation Analysis for Deep Learning Dynamics [hierarchical representations]",
            "Belrose et al. (2023) Language Models Can Solve Sudoku [layerwise analysis in spatial games]"
        ]
    },
    "reflected_from_theory_index": 2,
    "type": "general",
    "version": "built-theory-from-results-single-theory-reflection2-nov14-2025-LLM-BASELINE-no-evidence-with-matched-control-theory-name",
    "theory_query": "Build a theory of how language models solve puzzle games involving spatial knowledge, like Sudoku.",
    "original_theory_id": "theory-599",
    "original_theory_name": "Latent World-State Representation Emergence in Autoregressive Language Models for Board Games",
    "provide_matched_control_thery_name": true,
    "matched_control_theory_name": "Latent World-State Representation Emergence in Autoregressive Language Models for Board Games",
    "model_str": "openai/gpt-4.1-2025-04-14"
}</code></pre>
        </div>
    </div>
</body>
</html>