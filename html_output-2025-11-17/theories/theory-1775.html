<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Probabilistic Expectation Violation Theory - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-1775</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-1775</p>
                <p><strong>Name:</strong> Probabilistic Expectation Violation Theory</p>
                <p><strong>Type:</strong> general</p>
                <p><strong>Theory Query:</strong> Build a theory of how language models can be used for detecting anomalies in lists of data.</p>
                <p><strong>Description:</strong> Language models assign probabilities to items in a list based on learned statistical and semantic patterns. Anomalies are detected as items whose assigned probabilities are significantly lower than those of other items, indicating a violation of the model's learned expectations. This theory posits that anomaly detection is fundamentally a process of identifying expectation violations, whether due to statistical rarity, semantic incongruity, or both.</p>
                <p><strong>Knowledge Cutoff Year:</strong> -1</p>
                <p><strong>Knowledge Cutoff Month:</strong> -1</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <h3>Statement 0: Probability Threshold Anomaly Law (quantitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; item_i &#8594; is_in &#8594; data_list<span style="color: #888888;">, and</span></div>
        <div>&#8226; LM &#8594; assigns_probability &#8594; p_i<span style="color: #888888;">, and</span></div>
        <div>&#8226; p_i &#8594; is_significantly_lower_than &#8594; mean_probability_of_other_items</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; item_i &#8594; is_flagged_as &#8594; anomaly</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>LMs assign lower probabilities to out-of-distribution or contextually implausible items. </li>
    <li>Anomaly detection in time series and text often uses probability thresholds to flag rare events. </li>
    <li>LMs' output probabilities reflect their learned expectations from training data. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> This law is somewhat-related-to-existing work in anomaly detection, but its application to LM-based list anomaly detection is new.</p>            <p><strong>What Already Exists:</strong> Probability-based anomaly detection is established in statistics and machine learning.</p>            <p><strong>What is Novel:</strong> Application of LM-assigned probabilities to arbitrary list anomaly detection is novel.</p>
            <p><strong>References:</strong> <ul>
    <li>Chandola et al. (2009) Anomaly Detection: A Survey [Probability-based anomaly detection]</li>
    <li>Goldstein & Uchida (2016) A Comparative Evaluation of Unsupervised Anomaly Detection Algorithms for Multivariate Data [Thresholding in anomaly detection]</li>
    <li>Radford et al. (2019) Language Models are Unsupervised Multitask Learners [LMs assign probabilities to tokens]</li>
</ul>
            <h3>Statement 1: Expectation Violation Generalization (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; item_i &#8594; is_in &#8594; data_list<span style="color: #888888;">, and</span></div>
        <div>&#8226; item_i &#8594; violates_learned_pattern &#8594; LM_expectation</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; LM &#8594; assigns_low_probability &#8594; item_i<span style="color: #888888;">, and</span></div>
        <div>&#8226; item_i &#8594; is_flagged_as &#8594; anomaly</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>LMs can detect both statistical and semantic anomalies by assigning low probabilities to unexpected items. </li>
    <li>Expectation violation is a general principle in anomaly detection across domains. </li>
    <li>LMs' performance in cloze and masked language modeling tasks demonstrates sensitivity to expectation violations. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> This law is somewhat-related-to-existing work, but its application to LMs and arbitrary lists is new.</p>            <p><strong>What Already Exists:</strong> Expectation violation is a general principle in anomaly detection and cognitive science.</p>            <p><strong>What is Novel:</strong> Generalization of this principle to LM-based anomaly detection in arbitrary lists is novel.</p>
            <p><strong>References:</strong> <ul>
    <li>Chandola et al. (2009) Anomaly Detection: A Survey [Expectation violation in anomaly detection]</li>
    <li>Kutas & Hillyard (1980) Reading senseless sentences: Brain potentials reflect semantic incongruity [Expectation violation in cognitive science]</li>
    <li>Radford et al. (2019) Language Models are Unsupervised Multitask Learners [LMs and expectation violation]</li>
</ul>
            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>If a language model is applied to a list of common English words with a single rare or invented word, the rare word will be flagged as an anomaly.</li>
                <li>If a language model is applied to a list of numbers with a single string of letters, the string will be flagged as an anomaly.</li>
                <li>If a language model is applied to a list of U.S. state names with a single non-state name, the non-state will be flagged as an anomaly.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>If a language model is applied to a list of rare but contextually appropriate items, it is unknown whether it will flag them as anomalies.</li>
                <li>If a language model is applied to a list of items with subtle statistical patterns (e.g., prime numbers among integers), it is unclear if it can detect anomalies.</li>
                <li>If a language model is applied to a list of items from a language or domain not present in its training data, its anomaly detection performance is unknown.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>If a language model assigns high probabilities to items that violate learned patterns, the theory would be challenged.</li>
                <li>If a language model fails to flag items with low assigned probabilities as anomalies, the theory would be undermined.</li>
                <li>If a language model cannot distinguish between statistical rarity and semantic incongruity, the theory would be called into question.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>Lists where all items are equally rare or unknown to the LM, such as lists of newly coined terms. </li>
    <li>Lists with items that violate patterns not present in the LM's training data. </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> somewhat-related-to-existing</p>
            <p><strong>Explanation:</strong> This theory is somewhat-related-to-existing work, but its application to LMs and arbitrary lists is new.</p>
            <p><strong>References:</strong> <ul>
    <li>Chandola et al. (2009) Anomaly Detection: A Survey [Expectation violation and probability-based anomaly detection]</li>
    <li>Kutas & Hillyard (1980) Reading senseless sentences: Brain potentials reflect semantic incongruity [Expectation violation in cognitive science]</li>
    <li>Radford et al. (2019) Language Models are Unsupervised Multitask Learners [LMs and expectation violation]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Probabilistic Expectation Violation Theory",
    "theory_description": "Language models assign probabilities to items in a list based on learned statistical and semantic patterns. Anomalies are detected as items whose assigned probabilities are significantly lower than those of other items, indicating a violation of the model's learned expectations. This theory posits that anomaly detection is fundamentally a process of identifying expectation violations, whether due to statistical rarity, semantic incongruity, or both.",
    "theory_statements": [
        {
            "law": {
                "law_name": "Probability Threshold Anomaly Law",
                "if": [
                    {
                        "subject": "item_i",
                        "relation": "is_in",
                        "object": "data_list"
                    },
                    {
                        "subject": "LM",
                        "relation": "assigns_probability",
                        "object": "p_i"
                    },
                    {
                        "subject": "p_i",
                        "relation": "is_significantly_lower_than",
                        "object": "mean_probability_of_other_items"
                    }
                ],
                "then": [
                    {
                        "subject": "item_i",
                        "relation": "is_flagged_as",
                        "object": "anomaly"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "LMs assign lower probabilities to out-of-distribution or contextually implausible items.",
                        "uuids": []
                    },
                    {
                        "text": "Anomaly detection in time series and text often uses probability thresholds to flag rare events.",
                        "uuids": []
                    },
                    {
                        "text": "LMs' output probabilities reflect their learned expectations from training data.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "quantitative",
                "existing_law": {
                    "what_already_exists": "Probability-based anomaly detection is established in statistics and machine learning.",
                    "what_is_novel": "Application of LM-assigned probabilities to arbitrary list anomaly detection is novel.",
                    "classification_explanation": "This law is somewhat-related-to-existing work in anomaly detection, but its application to LM-based list anomaly detection is new.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Chandola et al. (2009) Anomaly Detection: A Survey [Probability-based anomaly detection]",
                        "Goldstein & Uchida (2016) A Comparative Evaluation of Unsupervised Anomaly Detection Algorithms for Multivariate Data [Thresholding in anomaly detection]",
                        "Radford et al. (2019) Language Models are Unsupervised Multitask Learners [LMs assign probabilities to tokens]"
                    ]
                }
            }
        },
        {
            "law": {
                "law_name": "Expectation Violation Generalization",
                "if": [
                    {
                        "subject": "item_i",
                        "relation": "is_in",
                        "object": "data_list"
                    },
                    {
                        "subject": "item_i",
                        "relation": "violates_learned_pattern",
                        "object": "LM_expectation"
                    }
                ],
                "then": [
                    {
                        "subject": "LM",
                        "relation": "assigns_low_probability",
                        "object": "item_i"
                    },
                    {
                        "subject": "item_i",
                        "relation": "is_flagged_as",
                        "object": "anomaly"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "LMs can detect both statistical and semantic anomalies by assigning low probabilities to unexpected items.",
                        "uuids": []
                    },
                    {
                        "text": "Expectation violation is a general principle in anomaly detection across domains.",
                        "uuids": []
                    },
                    {
                        "text": "LMs' performance in cloze and masked language modeling tasks demonstrates sensitivity to expectation violations.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Expectation violation is a general principle in anomaly detection and cognitive science.",
                    "what_is_novel": "Generalization of this principle to LM-based anomaly detection in arbitrary lists is novel.",
                    "classification_explanation": "This law is somewhat-related-to-existing work, but its application to LMs and arbitrary lists is new.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Chandola et al. (2009) Anomaly Detection: A Survey [Expectation violation in anomaly detection]",
                        "Kutas & Hillyard (1980) Reading senseless sentences: Brain potentials reflect semantic incongruity [Expectation violation in cognitive science]",
                        "Radford et al. (2019) Language Models are Unsupervised Multitask Learners [LMs and expectation violation]"
                    ]
                }
            }
        }
    ],
    "new_predictions_likely": [
        "If a language model is applied to a list of common English words with a single rare or invented word, the rare word will be flagged as an anomaly.",
        "If a language model is applied to a list of numbers with a single string of letters, the string will be flagged as an anomaly.",
        "If a language model is applied to a list of U.S. state names with a single non-state name, the non-state will be flagged as an anomaly."
    ],
    "new_predictions_unknown": [
        "If a language model is applied to a list of rare but contextually appropriate items, it is unknown whether it will flag them as anomalies.",
        "If a language model is applied to a list of items with subtle statistical patterns (e.g., prime numbers among integers), it is unclear if it can detect anomalies.",
        "If a language model is applied to a list of items from a language or domain not present in its training data, its anomaly detection performance is unknown."
    ],
    "negative_experiments": [
        "If a language model assigns high probabilities to items that violate learned patterns, the theory would be challenged.",
        "If a language model fails to flag items with low assigned probabilities as anomalies, the theory would be undermined.",
        "If a language model cannot distinguish between statistical rarity and semantic incongruity, the theory would be called into question."
    ],
    "unaccounted_for": [
        {
            "text": "Lists where all items are equally rare or unknown to the LM, such as lists of newly coined terms.",
            "uuids": []
        },
        {
            "text": "Lists with items that violate patterns not present in the LM's training data.",
            "uuids": []
        }
    ],
    "conflicting_evidence": [
        {
            "text": "LMs may assign low probabilities to rare but contextually appropriate items, leading to false positives.",
            "uuids": []
        },
        {
            "text": "LMs sometimes fail to detect anomalies in highly technical or domain-specific lists outside their training data.",
            "uuids": []
        }
    ],
    "special_cases": [
        "Lists with items that are all equally unfamiliar to the LM may not yield meaningful anomaly detection.",
        "Lists with subtle statistical patterns may not be detected as anomalous if the LM has not learned those patterns.",
        "Lists with items from multiple languages or scripts may confound the LM's probability assignments."
    ],
    "existing_theory": {
        "what_already_exists": "Probability-based and expectation-violation-based anomaly detection are established in statistics, machine learning, and cognitive science.",
        "what_is_novel": "Application of these principles to LM-based anomaly detection in arbitrary lists is novel.",
        "classification_explanation": "This theory is somewhat-related-to-existing work, but its application to LMs and arbitrary lists is new.",
        "likely_classification": "somewhat-related-to-existing",
        "references": [
            "Chandola et al. (2009) Anomaly Detection: A Survey [Expectation violation and probability-based anomaly detection]",
            "Kutas & Hillyard (1980) Reading senseless sentences: Brain potentials reflect semantic incongruity [Expectation violation in cognitive science]",
            "Radford et al. (2019) Language Models are Unsupervised Multitask Learners [LMs and expectation violation]"
        ]
    },
    "reflected_from_theory_index": 1,
    "type": "general",
    "version": "built-theory-from-results-single-theory-reflection2-nov14-2025-LLM-BASELINE-no-evidence-without-matched-control-theory-name",
    "theory_query": "Build a theory of how language models can be used for detecting anomalies in lists of data.",
    "original_theory_id": "theory-645",
    "original_theory_name": "Chain-of-Thought and Domain-Knowledge Prompting Enhances LLM Interpretability and Anomaly-Type Classification",
    "provide_matched_control_thery_name": false,
    "matched_control_theory_name": null,
    "model_str": "openai/gpt-4.1-2025-04-14"
}</code></pre>
        </div>
    </div>
</body>
</html>