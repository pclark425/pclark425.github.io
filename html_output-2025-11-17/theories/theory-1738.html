<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Probabilistic and Semantic Consistency Theory for LLM-Based Anomaly Detection - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-1738</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-1738</p>
                <p><strong>Name:</strong> Probabilistic and Semantic Consistency Theory for LLM-Based Anomaly Detection</p>
                <p><strong>Type:</strong> general</p>
                <p><strong>Theory Query:</strong> Build a theory of how language models can be used for detecting anomalies in lists of data.</p>
                <p><strong>Description:</strong> This theory asserts that LLMs detect anomalies in lists and tabular data by evaluating both the probabilistic likelihood of items (token-level and sequence-level) and their semantic consistency with the inferred structure and meaning of the list. Anomalies are identified as items that are either statistically improbable or semantically incoherent with the rest of the data, leveraging the LLM's dual capacity for statistical modeling and semantic understanding.</p>
                <p><strong>Knowledge Cutoff Year:</strong> -1</p>
                <p><strong>Knowledge Cutoff Month:</strong> -1</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <h3>Statement 0: Probabilistic Incongruity Law (quantitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; item &#8594; has_low_likelihood &#8594; under_LLM_given_list_context</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; item &#8594; is_flagged_as_anomalous &#8594; True</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Likelihood-based anomaly detection is a standard approach in NLP and has been shown effective with LLMs. </li>
    <li>LLMs assign token and sequence probabilities that can be used to identify out-of-distribution items. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> closely-related-to-existing</p>
            <p><strong>Explanation:</strong> This law is a direct extension of existing methods to a new data modality.</p>            <p><strong>What Already Exists:</strong> Likelihood-based anomaly detection is established in NLP.</p>            <p><strong>What is Novel:</strong> The explicit application to structured lists/tables and the combination with semantic consistency is novel.</p>
            <p><strong>References:</strong> <ul>
    <li>Hendrycks et al. (2020) Pretrained Transformers Improve Out-of-Distribution Detection [Likelihood-based OOD detection]</li>
    <li>Zhang et al. (2023) Language Models are Anomaly Detectors [LLMs for anomaly detection]</li>
</ul>
            <h3>Statement 1: Semantic Incoherence Law (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; item &#8594; is_semantically_incoherent_with &#8594; list_context</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; item &#8594; is_flagged_as_anomalous &#8594; True</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>LLMs can detect semantic anomalies, such as a fruit in a list of animals, even when token probabilities are not extreme. </li>
    <li>Semantic similarity and coherence are measurable by LLMs and have been used for anomaly detection. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> This law extends semantic anomaly detection to structured list/tabular contexts.</p>            <p><strong>What Already Exists:</strong> Semantic similarity and coherence are used in NLP for various tasks.</p>            <p><strong>What is Novel:</strong> The formalization of semantic incoherence as a law for anomaly detection in structured data is novel.</p>
            <p><strong>References:</strong> <ul>
    <li>Reif et al. (2019) Visualizing and Measuring the Geometry of BERT [Semantic similarity in LLMs]</li>
    <li>Zhang et al. (2023) Language Models are Anomaly Detectors [LLMs for anomaly detection]</li>
</ul>
            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>LLMs will flag as anomalous items that are semantically inconsistent with the rest of a list, even if their token probability is not extremely low.</li>
                <li>Combining probabilistic and semantic measures will improve anomaly detection performance over either method alone.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>LLMs may detect subtle semantic anomalies in highly technical or domain-specific lists where explicit probabilities are less informative.</li>
                <li>The theory predicts that LLMs could be tuned to detect anomalies in lists with complex, multi-level semantic structures (e.g., nested categories).</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>If LLMs fail to flag semantically incoherent items as anomalies, the semantic incoherence law is challenged.</li>
                <li>If probabilistic and semantic measures are uncorrelated or do not improve detection when combined, the theory is weakened.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>The theory does not address anomalies that are both statistically and semantically plausible but violate hidden or latent rules. </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> closely-related-to-existing</p>
            <p><strong>Explanation:</strong> This theory synthesizes two established approaches for a new application domain.</p>
            <p><strong>References:</strong> <ul>
    <li>Hendrycks et al. (2020) Pretrained Transformers Improve Out-of-Distribution Detection [Likelihood-based OOD detection]</li>
    <li>Reif et al. (2019) Visualizing and Measuring the Geometry of BERT [Semantic similarity in LLMs]</li>
    <li>Zhang et al. (2023) Language Models are Anomaly Detectors [LLMs for anomaly detection]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Probabilistic and Semantic Consistency Theory for LLM-Based Anomaly Detection",
    "theory_description": "This theory asserts that LLMs detect anomalies in lists and tabular data by evaluating both the probabilistic likelihood of items (token-level and sequence-level) and their semantic consistency with the inferred structure and meaning of the list. Anomalies are identified as items that are either statistically improbable or semantically incoherent with the rest of the data, leveraging the LLM's dual capacity for statistical modeling and semantic understanding.",
    "theory_statements": [
        {
            "law": {
                "law_name": "Probabilistic Incongruity Law",
                "if": [
                    {
                        "subject": "item",
                        "relation": "has_low_likelihood",
                        "object": "under_LLM_given_list_context"
                    }
                ],
                "then": [
                    {
                        "subject": "item",
                        "relation": "is_flagged_as_anomalous",
                        "object": "True"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Likelihood-based anomaly detection is a standard approach in NLP and has been shown effective with LLMs.",
                        "uuids": []
                    },
                    {
                        "text": "LLMs assign token and sequence probabilities that can be used to identify out-of-distribution items.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "quantitative",
                "existing_law": {
                    "what_already_exists": "Likelihood-based anomaly detection is established in NLP.",
                    "what_is_novel": "The explicit application to structured lists/tables and the combination with semantic consistency is novel.",
                    "classification_explanation": "This law is a direct extension of existing methods to a new data modality.",
                    "likely_classification": "closely-related-to-existing",
                    "references": [
                        "Hendrycks et al. (2020) Pretrained Transformers Improve Out-of-Distribution Detection [Likelihood-based OOD detection]",
                        "Zhang et al. (2023) Language Models are Anomaly Detectors [LLMs for anomaly detection]"
                    ]
                }
            }
        },
        {
            "law": {
                "law_name": "Semantic Incoherence Law",
                "if": [
                    {
                        "subject": "item",
                        "relation": "is_semantically_incoherent_with",
                        "object": "list_context"
                    }
                ],
                "then": [
                    {
                        "subject": "item",
                        "relation": "is_flagged_as_anomalous",
                        "object": "True"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "LLMs can detect semantic anomalies, such as a fruit in a list of animals, even when token probabilities are not extreme.",
                        "uuids": []
                    },
                    {
                        "text": "Semantic similarity and coherence are measurable by LLMs and have been used for anomaly detection.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Semantic similarity and coherence are used in NLP for various tasks.",
                    "what_is_novel": "The formalization of semantic incoherence as a law for anomaly detection in structured data is novel.",
                    "classification_explanation": "This law extends semantic anomaly detection to structured list/tabular contexts.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Reif et al. (2019) Visualizing and Measuring the Geometry of BERT [Semantic similarity in LLMs]",
                        "Zhang et al. (2023) Language Models are Anomaly Detectors [LLMs for anomaly detection]"
                    ]
                }
            }
        }
    ],
    "new_predictions_likely": [
        "LLMs will flag as anomalous items that are semantically inconsistent with the rest of a list, even if their token probability is not extremely low.",
        "Combining probabilistic and semantic measures will improve anomaly detection performance over either method alone."
    ],
    "new_predictions_unknown": [
        "LLMs may detect subtle semantic anomalies in highly technical or domain-specific lists where explicit probabilities are less informative.",
        "The theory predicts that LLMs could be tuned to detect anomalies in lists with complex, multi-level semantic structures (e.g., nested categories)."
    ],
    "negative_experiments": [
        "If LLMs fail to flag semantically incoherent items as anomalies, the semantic incoherence law is challenged.",
        "If probabilistic and semantic measures are uncorrelated or do not improve detection when combined, the theory is weakened."
    ],
    "unaccounted_for": [
        {
            "text": "The theory does not address anomalies that are both statistically and semantically plausible but violate hidden or latent rules.",
            "uuids": []
        }
    ],
    "conflicting_evidence": [
        {
            "text": "Some adversarial examples can fool both probabilistic and semantic measures, leading to missed anomalies.",
            "uuids": []
        }
    ],
    "special_cases": [
        "Lists with high semantic diversity may reduce the effectiveness of semantic coherence measures.",
        "Highly repetitive or formulaic lists may yield low anomaly detection sensitivity for subtle semantic deviations."
    ],
    "existing_theory": {
        "what_already_exists": "Probabilistic and semantic anomaly detection are established in NLP.",
        "what_is_novel": "The explicit combination and formalization for structured list/tabular data is new.",
        "classification_explanation": "This theory synthesizes two established approaches for a new application domain.",
        "likely_classification": "closely-related-to-existing",
        "references": [
            "Hendrycks et al. (2020) Pretrained Transformers Improve Out-of-Distribution Detection [Likelihood-based OOD detection]",
            "Reif et al. (2019) Visualizing and Measuring the Geometry of BERT [Semantic similarity in LLMs]",
            "Zhang et al. (2023) Language Models are Anomaly Detectors [LLMs for anomaly detection]"
        ]
    },
    "reflected_from_theory_index": 2,
    "type": "general",
    "version": "built-theory-from-results-single-theory-reflection2-nov14-2025-LLM-BASELINE-no-evidence-with-matched-control-theory-name",
    "theory_query": "Build a theory of how language models can be used for detecting anomalies in lists of data.",
    "original_theory_id": "theory-642",
    "original_theory_name": "Generalized Language Model Representation and Adaptation Theory for Anomaly Detection in Lists and Tabular Data",
    "provide_matched_control_thery_name": true,
    "matched_control_theory_name": "Generalized Language Model Representation and Adaptation Theory for Anomaly Detection in Lists and Tabular Data",
    "model_str": "openai/gpt-4.1-2025-04-14"
}</code></pre>
        </div>
    </div>
</body>
</html>