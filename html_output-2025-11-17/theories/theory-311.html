<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Hierarchical Landmark-Based Navigation Efficiency Theory - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-311</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-311</p>
                <p><strong>Name:</strong> Hierarchical Landmark-Based Navigation Efficiency Theory</p>
                <p><strong>Type:</strong> specific</p>
                <p><strong>Theory Query:</strong> Build a theory about navigation complexity in text worlds that relates graph-topology features (diameter, clustering, dead-ends, door constraints) to exploration efficiency and optimal policy structure.. Please focus on creating new theories that have not been proposed before in the literature.</p>
                <p><strong>Description:</strong> This theory proposes that navigation efficiency in complex graph topologies can be dramatically improved through hierarchical policies that identify and utilize 'landmark' nodes - nodes with high betweenness centrality, strategic positions relative to door constraints, or that serve as bridges between high-clustering regions. The theory posits that optimal navigation policies naturally decompose into two levels: (1) a high-level policy that navigates between landmarks, and (2) local policies that navigate within landmark-defined regions. Landmarks emerge from graph topology: nodes with high betweenness centrality (lying on many shortest paths), nodes adjacent to door constraints (controlling access to regions), and nodes at the boundaries of high-clustering communities. The theory predicts that: (a) learning efficiency scales with the number of landmarks rather than total nodes (reducing sample complexity from O(N²) to O(L²) where L << N is the number of landmarks), (b) the optimal number of landmarks L* is approximately sqrt(N) × (D/D_max) where D is graph diameter and D_max is maximum possible diameter for N nodes, (c) policies structured around landmarks are more robust to local topology changes that don't affect landmark connectivity, and (d) transfer learning between graphs is effective when landmark structures are preserved even if local topology differs. The theory further predicts that in graphs with door constraints, nodes adjacent to doors naturally emerge as landmarks, and that dead-ends reduce navigation efficiency proportionally to their distance from the nearest landmark.</p>
                <p><strong>Knowledge Cutoff Year:</strong> -1</p>
                <p><strong>Knowledge Cutoff Month:</strong> -1</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <ol>
                <li>The sample complexity of learning optimal navigation policies in a graph with N nodes and L landmarks scales as O(L² + N×L) rather than O(N²), where L is the number of landmark nodes.</li>
                <li>The optimal number of landmarks L* for a graph with N nodes and diameter D is approximately: L* ≈ sqrt(N) × (D/D_max) × (1 + α×C_var), where D_max is the maximum possible diameter for N nodes, C_var is the variance in clustering coefficients across the graph, and α ≈ 0.3-0.5.</li>
                <li>Nodes with betweenness centrality in the top 10-20% of the distribution naturally emerge as effective landmarks, and policies that explicitly use these nodes as subgoals achieve 40-60% faster convergence than flat policies.</li>
                <li>In graphs with door constraints (edges that require specific conditions to traverse), nodes adjacent to doors have betweenness centrality elevated by a factor of (1 + k×R), where k is the number of doors adjacent to the node and R is the ratio of nodes on opposite sides of the door to total nodes.</li>
                <li>Navigation policies structured hierarchically around landmarks maintain >80% of their performance when up to 30% of non-landmark edges are modified, compared to <50% performance retention for flat policies.</li>
                <li>Transfer learning between graphs G1 and G2 achieves efficiency proportional to: transfer_eff = (1 - |L1 - L2|/max(L1,L2)) × (overlap of landmark positions), where landmark position overlap is measured by graph edit distance between landmark-induced subgraphs.</li>
                <li>Dead-ends at distance d from the nearest landmark increase average navigation time by approximately d × (1 + 1/L), where L is the total number of landmarks, because they require backtracking to the landmark before proceeding.</li>
                <li>In graphs with heterogeneous clustering, optimal landmarks are positioned at the boundaries between high-clustering communities, with density proportional to the difference in clustering coefficients: landmark_density ∝ |C1 - C2|.</li>
            </ol>
            <h3>Supporting Evidence</h3>
<ol>
    <li>Betweenness centrality measures how often a node lies on shortest paths between other nodes, identifying strategic positions in networks. </li>
    <li>Hierarchical reinforcement learning decomposes complex tasks into subtasks, improving learning efficiency and transfer. </li>
    <li>Options framework in RL enables learning of reusable sub-policies that can be composed hierarchically. </li>
    <li>Community structure in networks creates natural hierarchical organization with bridge nodes connecting communities. </li>
    <li>Humans use landmark-based navigation strategies in spatial environments, organizing knowledge hierarchically. </li>
    <li>Graph diameter affects the complexity of navigation and planning in networks. </li>
</ol>            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>In a grid-world with 100 nodes and 4 strategically placed landmarks (at quartile positions), an agent will learn optimal navigation 3-4x faster than without explicit landmark identification.</li>
                <li>When training navigation agents on graphs with door constraints, agents that learn to identify and navigate via door-adjacent nodes as landmarks will achieve >90% success rate 2-3x faster than agents using flat policies.</li>
                <li>In a graph where 20% of edges are randomly modified after training, hierarchical policies using landmarks will maintain 75-85% of original performance, while flat policies will drop to 40-50% performance.</li>
                <li>Agents trained on a graph with 5 landmarks will successfully transfer to a topologically different graph with the same number of landmarks in similar positions with >60% initial performance, compared to <20% for flat policy transfer.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>Whether landmark-based hierarchical policies scale efficiently to very large graphs (>10,000 nodes) where even O(L²) complexity might be prohibitive is unknown, but would determine the practical applicability of this approach to large-scale navigation problems.</li>
                <li>In dynamic environments where graph topology changes over time, whether landmarks should be fixed or adaptive, and at what rate they should be updated, is unclear but critical for real-world applications.</li>
                <li>Whether there exists a universal algorithm for landmark selection that works across all graph types, or whether landmark selection must be tailored to specific topology features (clustering, diameter, door constraints), is unknown but would significantly impact the generality of the theory.</li>
                <li>In adversarial settings where an opponent can modify the graph to disrupt navigation, whether protecting landmark connectivity is sufficient to maintain navigation efficiency, or whether additional robustness mechanisms are needed, is unclear.</li>
                <li>Whether the hierarchical decomposition should be strictly two-level (landmarks and local) or whether deeper hierarchies (landmarks, sub-landmarks, local) provide additional benefits for very large or complex graphs is unknown.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>If learning time does NOT scale with O(L²) but continues to scale with O(N²) even when using landmark-based hierarchical policies, this would fundamentally challenge the theory's efficiency claims.</li>
                <li>If randomly selected nodes work as well as high-betweenness nodes for landmarks, this would contradict the theory's prediction that topological position matters for landmark effectiveness.</li>
                <li>If hierarchical policies do NOT show better robustness to edge modifications compared to flat policies, this would challenge the theory's claims about structural robustness.</li>
                <li>If transfer learning between graphs does NOT correlate with landmark structure preservation, this would undermine the theory's predictions about what enables effective transfer.</li>
                <li>If dead-ends do NOT increase navigation time proportionally to their distance from landmarks, this would challenge the theory's model of how landmarks mitigate dead-end costs.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>The computational cost of identifying landmarks (computing betweenness centrality) is O(N×E) which may be prohibitive for very large graphs, but the theory does not address approximate landmark selection methods. </li>
    <li>The theory does not specify how to handle graphs with multiple disconnected components, where landmark-based navigation between components is impossible. </li>
    <li>The interaction between landmark-based policies and exploration strategies (epsilon-greedy, UCB, etc.) is not fully specified - it's unclear whether exploration should be landmark-aware. </li>
    <li>The theory does not address how partial observability (where the agent cannot see the full graph structure) affects landmark identification and utilization. </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> new</p>
            <p><strong>Explanation:</strong> No explanation provided.</p>
            <p><strong>References:</strong> <ul>
    <li>Sutton et al. (1999) Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning [Introduces options framework for hierarchical RL but does not propose landmark-based selection or relate to graph topology]</li>
    <li>Dietterich (2000) Hierarchical Reinforcement Learning with the MAXQ Value Function Decomposition [Proposes hierarchical RL decomposition but does not use graph-theoretic properties for hierarchy design]</li>
    <li>Simonyan & Zisserman (2014) Very Deep Convolutional Networks for Large-Scale Image Recognition [In computer vision context, not navigation or graph theory]</li>
    <li>Freeman (1977) A Set of Measures of Centrality Based on Betweenness [Introduces betweenness centrality but does not apply it to navigation policy learning]</li>
    <li>Girvan & Newman (2002) Community structure in social and biological networks [Analyzes community structure but does not propose navigation policies based on community boundaries]</li>
    <li>Bacon et al. (2017) The Option-Critic Architecture [Learns options end-to-end but does not explicitly use graph topology or landmarks]</li>
    <li>Kulkarni et al. (2016) Hierarchical Deep Reinforcement Learning: Integrating Temporal Abstraction and Intrinsic Motivation [Proposes hierarchical deep RL but does not specifically address landmark-based navigation in graph structures]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Hierarchical Landmark-Based Navigation Efficiency Theory",
    "theory_description": "This theory proposes that navigation efficiency in complex graph topologies can be dramatically improved through hierarchical policies that identify and utilize 'landmark' nodes - nodes with high betweenness centrality, strategic positions relative to door constraints, or that serve as bridges between high-clustering regions. The theory posits that optimal navigation policies naturally decompose into two levels: (1) a high-level policy that navigates between landmarks, and (2) local policies that navigate within landmark-defined regions. Landmarks emerge from graph topology: nodes with high betweenness centrality (lying on many shortest paths), nodes adjacent to door constraints (controlling access to regions), and nodes at the boundaries of high-clustering communities. The theory predicts that: (a) learning efficiency scales with the number of landmarks rather than total nodes (reducing sample complexity from O(N²) to O(L²) where L &lt;&lt; N is the number of landmarks), (b) the optimal number of landmarks L* is approximately sqrt(N) × (D/D_max) where D is graph diameter and D_max is maximum possible diameter for N nodes, (c) policies structured around landmarks are more robust to local topology changes that don't affect landmark connectivity, and (d) transfer learning between graphs is effective when landmark structures are preserved even if local topology differs. The theory further predicts that in graphs with door constraints, nodes adjacent to doors naturally emerge as landmarks, and that dead-ends reduce navigation efficiency proportionally to their distance from the nearest landmark.",
    "supporting_evidence": [
        {
            "text": "Betweenness centrality measures how often a node lies on shortest paths between other nodes, identifying strategic positions in networks.",
            "citations": [
                "Freeman (1977) A Set of Measures of Centrality Based on Betweenness",
                "Brandes (2001) A faster algorithm for betweenness centrality"
            ]
        },
        {
            "text": "Hierarchical reinforcement learning decomposes complex tasks into subtasks, improving learning efficiency and transfer.",
            "citations": [
                "Sutton et al. (1999) Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning",
                "Dietterich (2000) Hierarchical Reinforcement Learning with the MAXQ Value Function Decomposition",
                "Barto & Mahadevan (2003) Recent Advances in Hierarchical Reinforcement Learning"
            ]
        },
        {
            "text": "Options framework in RL enables learning of reusable sub-policies that can be composed hierarchically.",
            "citations": [
                "Sutton et al. (1999) Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning",
                "Precup (2000) Temporal Abstraction in Reinforcement Learning"
            ]
        },
        {
            "text": "Community structure in networks creates natural hierarchical organization with bridge nodes connecting communities.",
            "citations": [
                "Girvan & Newman (2002) Community structure in social and biological networks",
                "Newman & Girvan (2004) Finding and evaluating community structure in networks"
            ]
        },
        {
            "text": "Humans use landmark-based navigation strategies in spatial environments, organizing knowledge hierarchically.",
            "citations": [
                "Siegel & White (1975) The development of spatial representations of large-scale environments",
                "Wiener et al. (2009) Mazes, maps, and memory: The influence of environmental structure on spatial learning"
            ]
        },
        {
            "text": "Graph diameter affects the complexity of navigation and planning in networks.",
            "citations": [
                "Albert & Barabási (2002) Statistical mechanics of complex networks"
            ]
        }
    ],
    "theory_statements": [
        "The sample complexity of learning optimal navigation policies in a graph with N nodes and L landmarks scales as O(L² + N×L) rather than O(N²), where L is the number of landmark nodes.",
        "The optimal number of landmarks L* for a graph with N nodes and diameter D is approximately: L* ≈ sqrt(N) × (D/D_max) × (1 + α×C_var), where D_max is the maximum possible diameter for N nodes, C_var is the variance in clustering coefficients across the graph, and α ≈ 0.3-0.5.",
        "Nodes with betweenness centrality in the top 10-20% of the distribution naturally emerge as effective landmarks, and policies that explicitly use these nodes as subgoals achieve 40-60% faster convergence than flat policies.",
        "In graphs with door constraints (edges that require specific conditions to traverse), nodes adjacent to doors have betweenness centrality elevated by a factor of (1 + k×R), where k is the number of doors adjacent to the node and R is the ratio of nodes on opposite sides of the door to total nodes.",
        "Navigation policies structured hierarchically around landmarks maintain &gt;80% of their performance when up to 30% of non-landmark edges are modified, compared to &lt;50% performance retention for flat policies.",
        "Transfer learning between graphs G1 and G2 achieves efficiency proportional to: transfer_eff = (1 - |L1 - L2|/max(L1,L2)) × (overlap of landmark positions), where landmark position overlap is measured by graph edit distance between landmark-induced subgraphs.",
        "Dead-ends at distance d from the nearest landmark increase average navigation time by approximately d × (1 + 1/L), where L is the total number of landmarks, because they require backtracking to the landmark before proceeding.",
        "In graphs with heterogeneous clustering, optimal landmarks are positioned at the boundaries between high-clustering communities, with density proportional to the difference in clustering coefficients: landmark_density ∝ |C1 - C2|."
    ],
    "new_predictions_likely": [
        "In a grid-world with 100 nodes and 4 strategically placed landmarks (at quartile positions), an agent will learn optimal navigation 3-4x faster than without explicit landmark identification.",
        "When training navigation agents on graphs with door constraints, agents that learn to identify and navigate via door-adjacent nodes as landmarks will achieve &gt;90% success rate 2-3x faster than agents using flat policies.",
        "In a graph where 20% of edges are randomly modified after training, hierarchical policies using landmarks will maintain 75-85% of original performance, while flat policies will drop to 40-50% performance.",
        "Agents trained on a graph with 5 landmarks will successfully transfer to a topologically different graph with the same number of landmarks in similar positions with &gt;60% initial performance, compared to &lt;20% for flat policy transfer."
    ],
    "new_predictions_unknown": [
        "Whether landmark-based hierarchical policies scale efficiently to very large graphs (&gt;10,000 nodes) where even O(L²) complexity might be prohibitive is unknown, but would determine the practical applicability of this approach to large-scale navigation problems.",
        "In dynamic environments where graph topology changes over time, whether landmarks should be fixed or adaptive, and at what rate they should be updated, is unclear but critical for real-world applications.",
        "Whether there exists a universal algorithm for landmark selection that works across all graph types, or whether landmark selection must be tailored to specific topology features (clustering, diameter, door constraints), is unknown but would significantly impact the generality of the theory.",
        "In adversarial settings where an opponent can modify the graph to disrupt navigation, whether protecting landmark connectivity is sufficient to maintain navigation efficiency, or whether additional robustness mechanisms are needed, is unclear.",
        "Whether the hierarchical decomposition should be strictly two-level (landmarks and local) or whether deeper hierarchies (landmarks, sub-landmarks, local) provide additional benefits for very large or complex graphs is unknown."
    ],
    "negative_experiments": [
        "If learning time does NOT scale with O(L²) but continues to scale with O(N²) even when using landmark-based hierarchical policies, this would fundamentally challenge the theory's efficiency claims.",
        "If randomly selected nodes work as well as high-betweenness nodes for landmarks, this would contradict the theory's prediction that topological position matters for landmark effectiveness.",
        "If hierarchical policies do NOT show better robustness to edge modifications compared to flat policies, this would challenge the theory's claims about structural robustness.",
        "If transfer learning between graphs does NOT correlate with landmark structure preservation, this would undermine the theory's predictions about what enables effective transfer.",
        "If dead-ends do NOT increase navigation time proportionally to their distance from landmarks, this would challenge the theory's model of how landmarks mitigate dead-end costs."
    ],
    "unaccounted_for": [
        {
            "text": "The computational cost of identifying landmarks (computing betweenness centrality) is O(N×E) which may be prohibitive for very large graphs, but the theory does not address approximate landmark selection methods.",
            "citations": [
                "Brandes (2001) A faster algorithm for betweenness centrality"
            ]
        },
        {
            "text": "The theory does not specify how to handle graphs with multiple disconnected components, where landmark-based navigation between components is impossible.",
            "citations": []
        },
        {
            "text": "The interaction between landmark-based policies and exploration strategies (epsilon-greedy, UCB, etc.) is not fully specified - it's unclear whether exploration should be landmark-aware.",
            "citations": []
        },
        {
            "text": "The theory does not address how partial observability (where the agent cannot see the full graph structure) affects landmark identification and utilization.",
            "citations": []
        }
    ],
    "conflicting_evidence": [],
    "special_cases": [
        "In complete graphs (where all nodes are connected to all others), every node has equal betweenness centrality, so the theory's landmark selection mechanism breaks down. In this case, any subset of nodes can serve as landmarks.",
        "In tree structures, the theory predicts that branch points (nodes with degree &gt;2) serve as natural landmarks, but since trees have unique paths, the hierarchical decomposition provides less benefit than in graphs with cycles.",
        "In graphs with uniform topology (regular lattices), betweenness centrality may be uniform or nearly uniform, requiring alternative landmark selection criteria such as spatial distribution or distance-based selection.",
        "When the number of door constraints is very high (&gt;50% of edges are doors), nearly all nodes become high-betweenness landmarks, potentially negating the efficiency benefits of hierarchical decomposition.",
        "In very small graphs (N &lt; 20), the overhead of hierarchical policy structure may exceed the benefits, making flat policies more efficient."
    ],
    "existing_theory": {
        "likely_classification": "new",
        "references": [
            "Sutton et al. (1999) Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning [Introduces options framework for hierarchical RL but does not propose landmark-based selection or relate to graph topology]",
            "Dietterich (2000) Hierarchical Reinforcement Learning with the MAXQ Value Function Decomposition [Proposes hierarchical RL decomposition but does not use graph-theoretic properties for hierarchy design]",
            "Simonyan & Zisserman (2014) Very Deep Convolutional Networks for Large-Scale Image Recognition [In computer vision context, not navigation or graph theory]",
            "Freeman (1977) A Set of Measures of Centrality Based on Betweenness [Introduces betweenness centrality but does not apply it to navigation policy learning]",
            "Girvan & Newman (2002) Community structure in social and biological networks [Analyzes community structure but does not propose navigation policies based on community boundaries]",
            "Bacon et al. (2017) The Option-Critic Architecture [Learns options end-to-end but does not explicitly use graph topology or landmarks]",
            "Kulkarni et al. (2016) Hierarchical Deep Reinforcement Learning: Integrating Temporal Abstraction and Intrinsic Motivation [Proposes hierarchical deep RL but does not specifically address landmark-based navigation in graph structures]"
        ]
    },
    "theory_type_general_specific": "specific",
    "reflected_from_theory_index": 3,
    "theory_query": "Build a theory about navigation complexity in text worlds that relates graph-topology features (diameter, clustering, dead-ends, door constraints) to exploration efficiency and optimal policy structure.. Please focus on creating new theories that have not been proposed before in the literature.",
    "generation_mode": "llm_baseline_no_evidence",
    "original_theory_id": "theory-146",
    "original_theory_name": "Hierarchical Landmark-Based Navigation Efficiency Theory",
    "model_str": "claude-sonnet-4-5-20250929"
}</code></pre>
        </div>
    </div>
</body>
</html>