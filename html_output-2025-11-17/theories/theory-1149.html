<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Hierarchical Prompt Decomposition Law - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-1149</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-1149</p>
                <p><strong>Name:</strong> Hierarchical Prompt Decomposition Law</p>
                <p><strong>Type:</strong> general</p>
                <p><strong>Theory Query:</strong> Build a theory of how language models can best perform strict logical reasoning.</p>
                <p><strong>Description:</strong> This theory asserts that strict logical reasoning in language models is best achieved through hierarchical prompt decomposition, where complex problems are recursively broken down into subproblems at multiple levels of abstraction. Each subproblem is solved at the appropriate level, and solutions are composed bottom-up, ensuring that logical dependencies are respected and that the reasoning process mirrors human hierarchical problem-solving.</p>
                <p><strong>Knowledge Cutoff Year:</strong> -1</p>
                <p><strong>Knowledge Cutoff Month:</strong> -1</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <h3>Statement 0: Recursive Decomposition Law (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; complex_prompt &#8594; is_recursively_decomposed &#8594; hierarchical_subproblems<span style="color: #888888;">, and</span></div>
        <div>&#8226; subproblems &#8594; are_solved_at_appropriate_level &#8594; True</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; language_model &#8594; achieves &#8594; hierarchical_logical_reasoning</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Human problem-solving often involves hierarchical decomposition; LMs benefit from similar approaches. </li>
    <li>Hierarchical task decomposition is used in program synthesis and planning, improving logical accuracy. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> This law extends hierarchical decomposition from planning/program synthesis to LM logical reasoning.</p>            <p><strong>What Already Exists:</strong> Hierarchical decomposition is used in planning and program synthesis, but not formalized for LM logical reasoning.</p>            <p><strong>What is Novel:</strong> The explicit law that recursive, hierarchical decomposition is necessary for strict logical reasoning in LMs is novel.</p>
            <p><strong>References:</strong> <ul>
    <li>Aho et al. (1974) The Design and Analysis of Computer Algorithms [hierarchical decomposition in algorithms]</li>
    <li>Scholkopf et al. (2021) Toward Causal Representation Learning [hierarchical causal reasoning, not LM-specific]</li>
</ul>
            <h3>Statement 1: Bottom-Up Composition Law (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; solutions_to_leaf_subproblems &#8594; are_composed_upwards &#8594; parent_subproblems<span style="color: #888888;">, and</span></div>
        <div>&#8226; composition &#8594; respects_logical_dependencies &#8594; True</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; final_solution &#8594; is_logically_consistent &#8594; True</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Bottom-up composition in hierarchical planning ensures logical consistency. </li>
    <li>LMs that compose solutions from subproblems in a bottom-up manner show improved logical accuracy. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> This law adapts bottom-up composition from other domains to LM logical reasoning.</p>            <p><strong>What Already Exists:</strong> Bottom-up composition is used in planning and program synthesis.</p>            <p><strong>What is Novel:</strong> The explicit law that bottom-up composition is necessary for logical consistency in LM reasoning is novel.</p>
            <p><strong>References:</strong> <ul>
    <li>Aho et al. (1974) The Design and Analysis of Computer Algorithms [bottom-up composition in algorithms]</li>
    <li>Scholkopf et al. (2021) Toward Causal Representation Learning [hierarchical reasoning, not LM-specific]</li>
</ul>
            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>If LMs are prompted to decompose problems hierarchically and compose solutions bottom-up, logical accuracy will increase.</li>
                <li>If logical dependencies are violated during composition, logical consistency will decrease.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>If LMs are trained with explicit hierarchical decomposition, they may develop emergent hierarchical representations.</li>
                <li>If hierarchical decomposition is applied to very deep reasoning chains, LMs may solve problems previously unsolvable by flat decomposition.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>If LMs perform equally well without hierarchical decomposition, the theory would be challenged.</li>
                <li>If bottom-up composition does not improve logical consistency, the law would be called into question.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>Some problems may not naturally decompose hierarchically, limiting the law's applicability. </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> somewhat-related-to-existing</p>
            <p><strong>Explanation:</strong> This theory adapts and formalizes hierarchical decomposition and composition for LM logical reasoning.</p>
            <p><strong>References:</strong> <ul>
    <li>Aho et al. (1974) The Design and Analysis of Computer Algorithms [hierarchical decomposition, bottom-up composition]</li>
    <li>Scholkopf et al. (2021) Toward Causal Representation Learning [hierarchical reasoning, not LM-specific]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Hierarchical Prompt Decomposition Law",
    "theory_description": "This theory asserts that strict logical reasoning in language models is best achieved through hierarchical prompt decomposition, where complex problems are recursively broken down into subproblems at multiple levels of abstraction. Each subproblem is solved at the appropriate level, and solutions are composed bottom-up, ensuring that logical dependencies are respected and that the reasoning process mirrors human hierarchical problem-solving.",
    "theory_statements": [
        {
            "law": {
                "law_name": "Recursive Decomposition Law",
                "if": [
                    {
                        "subject": "complex_prompt",
                        "relation": "is_recursively_decomposed",
                        "object": "hierarchical_subproblems"
                    },
                    {
                        "subject": "subproblems",
                        "relation": "are_solved_at_appropriate_level",
                        "object": "True"
                    }
                ],
                "then": [
                    {
                        "subject": "language_model",
                        "relation": "achieves",
                        "object": "hierarchical_logical_reasoning"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Human problem-solving often involves hierarchical decomposition; LMs benefit from similar approaches.",
                        "uuids": []
                    },
                    {
                        "text": "Hierarchical task decomposition is used in program synthesis and planning, improving logical accuracy.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Hierarchical decomposition is used in planning and program synthesis, but not formalized for LM logical reasoning.",
                    "what_is_novel": "The explicit law that recursive, hierarchical decomposition is necessary for strict logical reasoning in LMs is novel.",
                    "classification_explanation": "This law extends hierarchical decomposition from planning/program synthesis to LM logical reasoning.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Aho et al. (1974) The Design and Analysis of Computer Algorithms [hierarchical decomposition in algorithms]",
                        "Scholkopf et al. (2021) Toward Causal Representation Learning [hierarchical causal reasoning, not LM-specific]"
                    ]
                }
            }
        },
        {
            "law": {
                "law_name": "Bottom-Up Composition Law",
                "if": [
                    {
                        "subject": "solutions_to_leaf_subproblems",
                        "relation": "are_composed_upwards",
                        "object": "parent_subproblems"
                    },
                    {
                        "subject": "composition",
                        "relation": "respects_logical_dependencies",
                        "object": "True"
                    }
                ],
                "then": [
                    {
                        "subject": "final_solution",
                        "relation": "is_logically_consistent",
                        "object": "True"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Bottom-up composition in hierarchical planning ensures logical consistency.",
                        "uuids": []
                    },
                    {
                        "text": "LMs that compose solutions from subproblems in a bottom-up manner show improved logical accuracy.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Bottom-up composition is used in planning and program synthesis.",
                    "what_is_novel": "The explicit law that bottom-up composition is necessary for logical consistency in LM reasoning is novel.",
                    "classification_explanation": "This law adapts bottom-up composition from other domains to LM logical reasoning.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Aho et al. (1974) The Design and Analysis of Computer Algorithms [bottom-up composition in algorithms]",
                        "Scholkopf et al. (2021) Toward Causal Representation Learning [hierarchical reasoning, not LM-specific]"
                    ]
                }
            }
        }
    ],
    "new_predictions_likely": [
        "If LMs are prompted to decompose problems hierarchically and compose solutions bottom-up, logical accuracy will increase.",
        "If logical dependencies are violated during composition, logical consistency will decrease."
    ],
    "new_predictions_unknown": [
        "If LMs are trained with explicit hierarchical decomposition, they may develop emergent hierarchical representations.",
        "If hierarchical decomposition is applied to very deep reasoning chains, LMs may solve problems previously unsolvable by flat decomposition."
    ],
    "negative_experiments": [
        "If LMs perform equally well without hierarchical decomposition, the theory would be challenged.",
        "If bottom-up composition does not improve logical consistency, the law would be called into question."
    ],
    "unaccounted_for": [
        {
            "text": "Some problems may not naturally decompose hierarchically, limiting the law's applicability.",
            "uuids": []
        }
    ],
    "conflicting_evidence": [
        {
            "text": "There are cases where LMs solve problems with flat decomposition, suggesting hierarchy is not always necessary.",
            "uuids": []
        }
    ],
    "special_cases": [
        "For problems that are atomic or have no natural hierarchy, the law may not apply.",
        "For LMs with strong flat reasoning capabilities, hierarchical decomposition may be unnecessary."
    ],
    "existing_theory": {
        "what_already_exists": "Hierarchical decomposition and bottom-up composition are known in planning and algorithms.",
        "what_is_novel": "The explicit application and formalization of these principles for strict logical reasoning in LMs is novel.",
        "classification_explanation": "This theory adapts and formalizes hierarchical decomposition and composition for LM logical reasoning.",
        "likely_classification": "somewhat-related-to-existing",
        "references": [
            "Aho et al. (1974) The Design and Analysis of Computer Algorithms [hierarchical decomposition, bottom-up composition]",
            "Scholkopf et al. (2021) Toward Causal Representation Learning [hierarchical reasoning, not LM-specific]"
        ]
    },
    "reflected_from_theory_index": 2,
    "type": "general",
    "version": "built-theory-from-results-single-theory-reflection2-nov14-2025-LLM-BASELINE-no-evidence-with-matched-control-theory-name",
    "theory_query": "Build a theory of how language models can best perform strict logical reasoning.",
    "original_theory_id": "theory-604",
    "original_theory_name": "Prompt Decomposition and Iterative Composition Law",
    "provide_matched_control_thery_name": true,
    "matched_control_theory_name": "Prompt Decomposition and Iterative Composition Law",
    "model_str": "openai/gpt-4.1-2025-04-14"
}</code></pre>
        </div>
    </div>
</body>
</html>