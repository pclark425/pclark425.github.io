<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Hierarchical Dual-Process Theory of Arithmetic in LLMs - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-737</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-737</p>
                <p><strong>Name:</strong> Hierarchical Dual-Process Theory of Arithmetic in LLMs</p>
                <p><strong>Type:</strong> general</p>
                <p><strong>Theory Query:</strong> Build a theory of how language models perform arithmetic.</p>
                <p><strong>Description:</strong> This theory proposes that LLMs use a hierarchical dual-process system for arithmetic: a fast, pattern-matching process for frequent or simple cases, and a slower, latent algorithmic process for more complex or unfamiliar cases. The interaction between these processes determines both accuracy and characteristic error types.</p>
                <p><strong>Knowledge Cutoff Year:</strong> -1</p>
                <p><strong>Knowledge Cutoff Month:</strong> -1</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <h3>Statement 0: Fast Pattern-Matching Process (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; arithmetic query &#8594; matches &#8594; frequent pattern in training data</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; LLM &#8594; uses &#8594; pattern-matching process<span style="color: #888888;">, and</span></div>
        <div>&#8226; LLM &#8594; produces &#8594; output with high speed and moderate accuracy</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>LLMs are faster and more accurate on arithmetic queries that match frequent training patterns. </li>
    <li>Surface-level copying and memorization are observed for simple or common arithmetic problems. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> Pattern-matching is known, but its explicit role as a fast process in arithmetic is novel.</p>            <p><strong>What Already Exists:</strong> Pattern-matching and memorization in LLMs are well-documented.</p>            <p><strong>What is Novel:</strong> This law formalizes the process as a distinct, fast pathway in arithmetic reasoning.</p>
            <p><strong>References:</strong> <ul>
    <li>Turpin et al. (2023) Language Models Don't Always Say What They Think [Pattern bias in LLMs]</li>
    <li>Zhou et al. (2022) Least-to-Most Prompting Enables Complex Reasoning in Large Language Models [Surface-level bias in LLMs]</li>
</ul>
            <h3>Statement 1: Slow Algorithmic Process for Complex Cases (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; arithmetic query &#8594; does_not_match &#8594; frequent pattern in training data</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; LLM &#8594; activates &#8594; latent algorithmic process<span style="color: #888888;">, and</span></div>
        <div>&#8226; LLM &#8594; produces &#8594; output with higher computational cost and variable accuracy</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>LLMs are slower and less accurate on rare or complex arithmetic queries, suggesting a fallback to algorithmic computation. </li>
    <li>Mechanistic interpretability reveals sub-networks corresponding to algorithmic steps in complex arithmetic. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> Algorithmic reasoning is known, but its hierarchical relationship to pattern-matching in arithmetic is novel.</p>            <p><strong>What Already Exists:</strong> Algorithmic reasoning in neural networks is established.</p>            <p><strong>What is Novel:</strong> This law posits a hierarchical fallback to algorithmic computation in arithmetic.</p>
            <p><strong>References:</strong> <ul>
    <li>Nanda et al. (2023) Progress Measures for Grokking via Mechanistic Interpretability [Algorithmic circuits in neural networks]</li>
    <li>Weiss et al. (2021) Thinking Like Transformers: Neural Algorithmic Reasoning [Algorithmic reasoning in transformers]</li>
</ul>
            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>LLMs will be faster and more accurate on arithmetic queries that match frequent training patterns, and slower/less accurate on rare or complex queries.</li>
                <li>If the frequency of certain arithmetic patterns is increased in training, LLMs will shift to using the fast process for those patterns.</li>
                <li>Introducing novel arithmetic formats will increase reliance on the slow, algorithmic process, with increased error rates.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>If both processes are disrupted (e.g., by adversarial input), LLMs may fail entirely or develop new error types.</li>
                <li>If LLMs are trained with explicit process supervision, the balance between fast and slow processes may shift in unpredictable ways.</li>
                <li>If LLMs are scaled up, the boundary between fast and slow processes may blur or shift.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>If LLMs show no difference in speed or accuracy between frequent and rare arithmetic patterns, the dual-process theory would be challenged.</li>
                <li>If LLMs do not fall back to algorithmic computation on complex queries, the hierarchical structure is called into question.</li>
                <li>If process-specific interventions (e.g., disrupting pattern-matching) do not affect performance as predicted, the theory is falsified.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>Some LLMs can generalize to novel arithmetic formats with little loss in speed or accuracy, not fully explained by the dual-process model. </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> somewhat-related-to-existing</p>
            <p><strong>Explanation:</strong> The dual-process structure is inspired by cognitive science, but its application to LLM arithmetic is novel.</p>
            <p><strong>References:</strong> <ul>
    <li>Evans (2008) Dual-processing accounts of reasoning, judgment, and social cognition [Dual-process theory in cognitive science]</li>
    <li>Nanda et al. (2023) Progress Measures for Grokking via Mechanistic Interpretability [Algorithmic circuits in neural networks]</li>
    <li>Turpin et al. (2023) Language Models Don't Always Say What They Think [Pattern bias in LLMs]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Hierarchical Dual-Process Theory of Arithmetic in LLMs",
    "theory_description": "This theory proposes that LLMs use a hierarchical dual-process system for arithmetic: a fast, pattern-matching process for frequent or simple cases, and a slower, latent algorithmic process for more complex or unfamiliar cases. The interaction between these processes determines both accuracy and characteristic error types.",
    "theory_statements": [
        {
            "law": {
                "law_name": "Fast Pattern-Matching Process",
                "if": [
                    {
                        "subject": "arithmetic query",
                        "relation": "matches",
                        "object": "frequent pattern in training data"
                    }
                ],
                "then": [
                    {
                        "subject": "LLM",
                        "relation": "uses",
                        "object": "pattern-matching process"
                    },
                    {
                        "subject": "LLM",
                        "relation": "produces",
                        "object": "output with high speed and moderate accuracy"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "LLMs are faster and more accurate on arithmetic queries that match frequent training patterns.",
                        "uuids": []
                    },
                    {
                        "text": "Surface-level copying and memorization are observed for simple or common arithmetic problems.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Pattern-matching and memorization in LLMs are well-documented.",
                    "what_is_novel": "This law formalizes the process as a distinct, fast pathway in arithmetic reasoning.",
                    "classification_explanation": "Pattern-matching is known, but its explicit role as a fast process in arithmetic is novel.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Turpin et al. (2023) Language Models Don't Always Say What They Think [Pattern bias in LLMs]",
                        "Zhou et al. (2022) Least-to-Most Prompting Enables Complex Reasoning in Large Language Models [Surface-level bias in LLMs]"
                    ]
                }
            }
        },
        {
            "law": {
                "law_name": "Slow Algorithmic Process for Complex Cases",
                "if": [
                    {
                        "subject": "arithmetic query",
                        "relation": "does_not_match",
                        "object": "frequent pattern in training data"
                    }
                ],
                "then": [
                    {
                        "subject": "LLM",
                        "relation": "activates",
                        "object": "latent algorithmic process"
                    },
                    {
                        "subject": "LLM",
                        "relation": "produces",
                        "object": "output with higher computational cost and variable accuracy"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "LLMs are slower and less accurate on rare or complex arithmetic queries, suggesting a fallback to algorithmic computation.",
                        "uuids": []
                    },
                    {
                        "text": "Mechanistic interpretability reveals sub-networks corresponding to algorithmic steps in complex arithmetic.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Algorithmic reasoning in neural networks is established.",
                    "what_is_novel": "This law posits a hierarchical fallback to algorithmic computation in arithmetic.",
                    "classification_explanation": "Algorithmic reasoning is known, but its hierarchical relationship to pattern-matching in arithmetic is novel.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Nanda et al. (2023) Progress Measures for Grokking via Mechanistic Interpretability [Algorithmic circuits in neural networks]",
                        "Weiss et al. (2021) Thinking Like Transformers: Neural Algorithmic Reasoning [Algorithmic reasoning in transformers]"
                    ]
                }
            }
        }
    ],
    "new_predictions_likely": [
        "LLMs will be faster and more accurate on arithmetic queries that match frequent training patterns, and slower/less accurate on rare or complex queries.",
        "If the frequency of certain arithmetic patterns is increased in training, LLMs will shift to using the fast process for those patterns.",
        "Introducing novel arithmetic formats will increase reliance on the slow, algorithmic process, with increased error rates."
    ],
    "new_predictions_unknown": [
        "If both processes are disrupted (e.g., by adversarial input), LLMs may fail entirely or develop new error types.",
        "If LLMs are trained with explicit process supervision, the balance between fast and slow processes may shift in unpredictable ways.",
        "If LLMs are scaled up, the boundary between fast and slow processes may blur or shift."
    ],
    "negative_experiments": [
        "If LLMs show no difference in speed or accuracy between frequent and rare arithmetic patterns, the dual-process theory would be challenged.",
        "If LLMs do not fall back to algorithmic computation on complex queries, the hierarchical structure is called into question.",
        "If process-specific interventions (e.g., disrupting pattern-matching) do not affect performance as predicted, the theory is falsified."
    ],
    "unaccounted_for": [
        {
            "text": "Some LLMs can generalize to novel arithmetic formats with little loss in speed or accuracy, not fully explained by the dual-process model.",
            "uuids": []
        }
    ],
    "conflicting_evidence": [
        {
            "text": "Abrupt improvements in arithmetic after scaling may not fit a gradual dual-process development.",
            "uuids": []
        }
    ],
    "special_cases": [
        "Very small arithmetic problems may be solved by direct memorization, bypassing both processes.",
        "Chain-of-thought prompting may engage both processes in sequence or in parallel.",
        "Highly adversarial or ambiguous queries may disrupt the hierarchy and produce unpredictable outputs."
    ],
    "existing_theory": {
        "what_already_exists": "Dual-process theories are common in cognitive science, and pattern-matching/algorithmic reasoning are known in LLMs.",
        "what_is_novel": "This theory applies a hierarchical dual-process framework specifically to arithmetic in LLMs.",
        "classification_explanation": "The dual-process structure is inspired by cognitive science, but its application to LLM arithmetic is novel.",
        "likely_classification": "somewhat-related-to-existing",
        "references": [
            "Evans (2008) Dual-processing accounts of reasoning, judgment, and social cognition [Dual-process theory in cognitive science]",
            "Nanda et al. (2023) Progress Measures for Grokking via Mechanistic Interpretability [Algorithmic circuits in neural networks]",
            "Turpin et al. (2023) Language Models Don't Always Say What They Think [Pattern bias in LLMs]"
        ]
    },
    "reflected_from_theory_index": 2,
    "type": "general",
    "version": "built-theory-from-results-single-theory-reflection2-nov14-2025-LLM-BASELINE-no-evidence-with-matched-control-theory-name",
    "theory_query": "Build a theory of how language models perform arithmetic.",
    "original_theory_id": "theory-578",
    "original_theory_name": "Latent Algorithm Activation and Superficial Alignment Theory",
    "provide_matched_control_thery_name": true,
    "matched_control_theory_name": "Latent Algorithm Activation and Superficial Alignment Theory",
    "model_str": "openai/gpt-4.1-2025-04-14"
}</code></pre>
        </div>
    </div>
</body>
</html>