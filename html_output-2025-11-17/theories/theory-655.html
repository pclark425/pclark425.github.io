<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Prompt Formatting Induces Degeneration and Output Validity Collapse - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-655</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-655</p>
                <p><strong>Name:</strong> Prompt Formatting Induces Degeneration and Output Validity Collapse</p>
                <p><strong>Type:</strong> specific</p>
                <p><strong>Theory Query:</strong> Build a theory of how problem presentation format affects LLM performance, based on the following results.</p>
                <p><strong>Description:</strong> This theory posits that prompt formatting choices—such as separators, casing, enumeration style, and explicit output constraints—can systematically induce degeneration, where the model fails to produce any valid output, and that the probability of degeneration is strongly correlated with prompt format. The theory further asserts that the spread in accuracy across prompt formats is largely explained by the probability of producing any valid output (centered mass), rather than by differences in the model's ability to select the correct answer among valid outputs.</p>
                <p><strong>Knowledge Cutoff Year:</strong> 2024</p>
                <p><strong>Knowledge Cutoff Month:</strong> 6</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <h3>Statement 0: Prompt Formatting Strongly Modulates Degeneration Rate (quantitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; prompt_format &#8594; is_varied &#8594; across plausible, semantically-equivalent forms</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; probability_of_valid_output &#8594; varies &#8594; substantially (centered mass spread up to 0.96 correlation with accuracy)</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Formatting can increase degeneration (no valid output) and is strongly correlated with accuracy (r up to 0.96); observed spreads up to 76 percentage points in accuracy across formats for the same model and task. <a href="../results/extraction-result-5671.html#e5671.9" class="evidence-link">[e5671.9]</a> <a href="../results/extraction-result-5671.html#e5671.0" class="evidence-link">[e5671.0]</a> </li>
    <li>Observed that prompt formatting choices (separators, casing, enumeration, etc.) can cause large swings in accuracy and degeneration rates, with median spread of 7.5 percentage points and maximum up to 76 points across formats. <a href="../results/extraction-result-5671.html#e5671.0" class="evidence-link">[e5671.0]</a> </li>
    <li>Classifier trained on prompt embeddings can identify format with >=0.98 accuracy, and separability correlates with performance spread, indicating that formatting deterministically transforms internal representations and output distributions. <a href="../results/extraction-result-5671.html#e5671.5" class="evidence-link">[e5671.5]</a> </li>
    <li>Formatting interacts with the model's decoding behavior so that some formats induce degeneration (no valid output), explaining larger spreads when using exact prefix matching vs ranking metrics. <a href="../results/extraction-result-5671.html#e5671.9" class="evidence-link">[e5671.9]</a> </li>
    <li>Formatting choices act as spurious, meaning-preserving features that systematically alter model internal representations and output distributions; effects are unpredictable and can introduce biases, degeneration, or make formats appear 'good' for one model but not another. <a href="../results/extraction-result-5671.html#e5671.0" class="evidence-link">[e5671.0]</a> </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: green; font-weight: bold;">new</span></p>
            <p><strong>Explanation:</strong> This is a new, empirically supported law that extends prior work on prompt sensitivity by quantifying the relationship between degeneration and accuracy spread.</p>            <p><strong>What Already Exists:</strong> Prompt formatting is known to affect output, and degeneration is a recognized failure mode.</p>            <p><strong>What is Novel:</strong> The explicit quantitative link between formatting, degeneration rate, and accuracy spread, and the identification of centered mass as the main driver of accuracy variation, is novel.</p>
            <p><strong>References:</strong> <ul>
    <li>Zhou et al. (2023) Quantifying Language Models' Sensitivity to Spurious Features in Prompt Design [formatting sensitivity, degeneration]</li>
</ul>
            <h3>Statement 1: Degeneration Rate Explains Most Accuracy Spread Across Formats (quantitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; prompt_format &#8594; induces &#8594; variation in probability_of_valid_output (centered mass)</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; accuracy_spread_across_formats &#8594; is_explained_by &#8594; variation in probability_of_valid_output</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Very strong correlations (up to r~0.96) show that formatting can dramatically change whether the model produces any valid answer at all; associated spread for exact prefix matching is substantially larger than for ranking accuracy. <a href="../results/extraction-result-5671.html#e5671.9" class="evidence-link">[e5671.9]</a> </li>
    <li>Observed that the spread in accuracy across prompt formats is largely explained by the probability of producing any valid output (centered mass), rather than by differences in the model's ability to select the correct answer among valid outputs. <a href="../results/extraction-result-5671.html#e5671.9" class="evidence-link">[e5671.9]</a> <a href="../results/extraction-result-5671.html#e5671.0" class="evidence-link">[e5671.0]</a> </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: green; font-weight: bold;">new</span></p>
            <p><strong>Explanation:</strong> This law is new in its quantitative focus on degeneration as the main driver of accuracy spread.</p>            <p><strong>What Already Exists:</strong> It is known that prompt format can affect accuracy, and that degeneration is a failure mode.</p>            <p><strong>What is Novel:</strong> The explicit demonstration that accuracy spread is explained by degeneration rate (centered mass), not just answer selection, is novel.</p>
            <p><strong>References:</strong> <ul>
    <li>Zhou et al. (2023) Quantifying Language Models' Sensitivity to Spurious Features in Prompt Design [formatting sensitivity, degeneration]</li>
</ul>
            <h3>Statement 2: Strict Output Constraints Can Increase Degeneration (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; prompt_format &#8594; includes &#8594; strict output formatting requirements</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; degeneration_rate &#8594; increases &#8594; especially for models not robust to format</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Strict answer-format enforcement can artifactually reduce measured accuracy if models produce valid answers in a different surface form; Llama 2 7B's high rate of misformatted answers illustrates how presentation/formatting constraints can affect evaluation results independent of underlying problem-solving capability. <a href="../results/extraction-result-5702.html#e5702.6" class="evidence-link">[e5702.6]</a> </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> This law is somewhat-related-to-existing, but the focus on degeneration as the mechanism is new.</p>            <p><strong>What Already Exists:</strong> Strict output constraints are known to affect evaluation.</p>            <p><strong>What is Novel:</strong> The explicit link to increased degeneration and its impact on measured accuracy is novel.</p>
            <p><strong>References:</strong> <ul>
    <li>Zhou et al. (2023) Quantifying Language Models' Sensitivity to Spurious Features in Prompt Design [formatting sensitivity, degeneration]</li>
</ul>
            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>If a new set of prompt formats is constructed with varying separators, casing, and enumeration, the degeneration rate (probability of producing any valid output) will vary substantially, and this will explain most of the accuracy spread.</li>
                <li>If a model is evaluated on a task with strict output constraints, formats that are less natural or more ambiguous will have higher degeneration rates.</li>
                <li>If prompt formats are optimized to maximize centered mass (valid output probability), accuracy will increase across tasks with strict answer requirements.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>If a model is trained with explicit anti-degeneration objectives (e.g., penalizing invalid outputs), the spread in accuracy across formats may decrease, but the model may become less flexible or more verbose.</li>
                <li>If a model is evaluated on a task with a very large or open-ended output space, the link between formatting and degeneration may weaken, or new forms of degeneration may emerge.</li>
                <li>If future LLMs are trained with adversarial format perturbations, they may develop invariance to formatting, reducing degeneration but possibly at the cost of other forms of robustness.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>If accuracy spread across prompt formats is not explained by the probability of producing any valid output, this would falsify the theory.</li>
                <li>If formatting changes do not affect degeneration rates, or if degeneration is uncorrelated with accuracy, the theory would be called into question.</li>
                <li>If models consistently produce valid outputs regardless of prompt formatting, the theory would be falsified.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>Some tasks and models may be robust to formatting changes, especially for open-ended or generative tasks. <a href="../results/extraction-result-5816.html#e5816.0" class="evidence-link">[e5816.0]</a> <a href="../results/extraction-result-5816.html#e5816.5" class="evidence-link">[e5816.5]</a> <a href="../results/extraction-result-5813.html#e5813.7" class="evidence-link">[e5813.7]</a> </li>
    <li>Null/minimal prompts can sometimes be competitive, indicating that degeneration is not universal. <a href="../results/extraction-result-5813.html#e5813.7" class="evidence-link">[e5813.7]</a> </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> new</p>
            <p><strong>Explanation:</strong> This is a new, empirically supported theory that extends prior work on prompt sensitivity by quantifying the relationship between degeneration and accuracy spread.</p>
            <p><strong>References:</strong> <ul>
    <li>Zhou et al. (2023) Quantifying Language Models' Sensitivity to Spurious Features in Prompt Design [formatting sensitivity, degeneration]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Prompt Formatting Induces Degeneration and Output Validity Collapse",
    "theory_description": "This theory posits that prompt formatting choices—such as separators, casing, enumeration style, and explicit output constraints—can systematically induce degeneration, where the model fails to produce any valid output, and that the probability of degeneration is strongly correlated with prompt format. The theory further asserts that the spread in accuracy across prompt formats is largely explained by the probability of producing any valid output (centered mass), rather than by differences in the model's ability to select the correct answer among valid outputs.",
    "theory_statements": [
        {
            "law": {
                "law_name": "Prompt Formatting Strongly Modulates Degeneration Rate",
                "if": [
                    {
                        "subject": "prompt_format",
                        "relation": "is_varied",
                        "object": "across plausible, semantically-equivalent forms"
                    }
                ],
                "then": [
                    {
                        "subject": "probability_of_valid_output",
                        "relation": "varies",
                        "object": "substantially (centered mass spread up to 0.96 correlation with accuracy)"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Formatting can increase degeneration (no valid output) and is strongly correlated with accuracy (r up to 0.96); observed spreads up to 76 percentage points in accuracy across formats for the same model and task.",
                        "uuids": [
                            "e5671.9",
                            "e5671.0"
                        ]
                    },
                    {
                        "text": "Observed that prompt formatting choices (separators, casing, enumeration, etc.) can cause large swings in accuracy and degeneration rates, with median spread of 7.5 percentage points and maximum up to 76 points across formats.",
                        "uuids": [
                            "e5671.0"
                        ]
                    },
                    {
                        "text": "Classifier trained on prompt embeddings can identify format with &gt;=0.98 accuracy, and separability correlates with performance spread, indicating that formatting deterministically transforms internal representations and output distributions.",
                        "uuids": [
                            "e5671.5"
                        ]
                    },
                    {
                        "text": "Formatting interacts with the model's decoding behavior so that some formats induce degeneration (no valid output), explaining larger spreads when using exact prefix matching vs ranking metrics.",
                        "uuids": [
                            "e5671.9"
                        ]
                    },
                    {
                        "text": "Formatting choices act as spurious, meaning-preserving features that systematically alter model internal representations and output distributions; effects are unpredictable and can introduce biases, degeneration, or make formats appear 'good' for one model but not another.",
                        "uuids": [
                            "e5671.0"
                        ]
                    }
                ],
                "qual_or_quant": "quantitative",
                "existing_law": {
                    "what_already_exists": "Prompt formatting is known to affect output, and degeneration is a recognized failure mode.",
                    "what_is_novel": "The explicit quantitative link between formatting, degeneration rate, and accuracy spread, and the identification of centered mass as the main driver of accuracy variation, is novel.",
                    "classification_explanation": "This is a new, empirically supported law that extends prior work on prompt sensitivity by quantifying the relationship between degeneration and accuracy spread.",
                    "likely_classification": "new",
                    "references": [
                        "Zhou et al. (2023) Quantifying Language Models' Sensitivity to Spurious Features in Prompt Design [formatting sensitivity, degeneration]"
                    ]
                }
            }
        },
        {
            "law": {
                "law_name": "Degeneration Rate Explains Most Accuracy Spread Across Formats",
                "if": [
                    {
                        "subject": "prompt_format",
                        "relation": "induces",
                        "object": "variation in probability_of_valid_output (centered mass)"
                    }
                ],
                "then": [
                    {
                        "subject": "accuracy_spread_across_formats",
                        "relation": "is_explained_by",
                        "object": "variation in probability_of_valid_output"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Very strong correlations (up to r~0.96) show that formatting can dramatically change whether the model produces any valid answer at all; associated spread for exact prefix matching is substantially larger than for ranking accuracy.",
                        "uuids": [
                            "e5671.9"
                        ]
                    },
                    {
                        "text": "Observed that the spread in accuracy across prompt formats is largely explained by the probability of producing any valid output (centered mass), rather than by differences in the model's ability to select the correct answer among valid outputs.",
                        "uuids": [
                            "e5671.9",
                            "e5671.0"
                        ]
                    }
                ],
                "qual_or_quant": "quantitative",
                "existing_law": {
                    "what_already_exists": "It is known that prompt format can affect accuracy, and that degeneration is a failure mode.",
                    "what_is_novel": "The explicit demonstration that accuracy spread is explained by degeneration rate (centered mass), not just answer selection, is novel.",
                    "classification_explanation": "This law is new in its quantitative focus on degeneration as the main driver of accuracy spread.",
                    "likely_classification": "new",
                    "references": [
                        "Zhou et al. (2023) Quantifying Language Models' Sensitivity to Spurious Features in Prompt Design [formatting sensitivity, degeneration]"
                    ]
                }
            }
        },
        {
            "law": {
                "law_name": "Strict Output Constraints Can Increase Degeneration",
                "if": [
                    {
                        "subject": "prompt_format",
                        "relation": "includes",
                        "object": "strict output formatting requirements"
                    }
                ],
                "then": [
                    {
                        "subject": "degeneration_rate",
                        "relation": "increases",
                        "object": "especially for models not robust to format"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Strict answer-format enforcement can artifactually reduce measured accuracy if models produce valid answers in a different surface form; Llama 2 7B's high rate of misformatted answers illustrates how presentation/formatting constraints can affect evaluation results independent of underlying problem-solving capability.",
                        "uuids": [
                            "e5702.6"
                        ]
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Strict output constraints are known to affect evaluation.",
                    "what_is_novel": "The explicit link to increased degeneration and its impact on measured accuracy is novel.",
                    "classification_explanation": "This law is somewhat-related-to-existing, but the focus on degeneration as the mechanism is new.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Zhou et al. (2023) Quantifying Language Models' Sensitivity to Spurious Features in Prompt Design [formatting sensitivity, degeneration]"
                    ]
                }
            }
        }
    ],
    "new_predictions_likely": [
        "If a new set of prompt formats is constructed with varying separators, casing, and enumeration, the degeneration rate (probability of producing any valid output) will vary substantially, and this will explain most of the accuracy spread.",
        "If a model is evaluated on a task with strict output constraints, formats that are less natural or more ambiguous will have higher degeneration rates.",
        "If prompt formats are optimized to maximize centered mass (valid output probability), accuracy will increase across tasks with strict answer requirements."
    ],
    "new_predictions_unknown": [
        "If a model is trained with explicit anti-degeneration objectives (e.g., penalizing invalid outputs), the spread in accuracy across formats may decrease, but the model may become less flexible or more verbose.",
        "If a model is evaluated on a task with a very large or open-ended output space, the link between formatting and degeneration may weaken, or new forms of degeneration may emerge.",
        "If future LLMs are trained with adversarial format perturbations, they may develop invariance to formatting, reducing degeneration but possibly at the cost of other forms of robustness."
    ],
    "negative_experiments": [
        "If accuracy spread across prompt formats is not explained by the probability of producing any valid output, this would falsify the theory.",
        "If formatting changes do not affect degeneration rates, or if degeneration is uncorrelated with accuracy, the theory would be called into question.",
        "If models consistently produce valid outputs regardless of prompt formatting, the theory would be falsified."
    ],
    "unaccounted_for": [
        {
            "text": "Some tasks and models may be robust to formatting changes, especially for open-ended or generative tasks.",
            "uuids": [
                "e5816.0",
                "e5816.5",
                "e5813.7"
            ]
        },
        {
            "text": "Null/minimal prompts can sometimes be competitive, indicating that degeneration is not universal.",
            "uuids": [
                "e5813.7"
            ]
        }
    ],
    "conflicting_evidence": [
        {
            "text": "Null/minimal prompts can sometimes be competitive, indicating that degeneration is not universal.",
            "uuids": [
                "e5813.7"
            ]
        }
    ],
    "special_cases": [
        "For tasks with very large or open-ended output spaces, degeneration may manifest differently or be less correlated with formatting.",
        "Instruction-tuned or robustly trained models may exhibit reduced degeneration rates across formats.",
        "Some models may have built-in format invariance due to training on diverse prompt styles."
    ],
    "existing_theory": {
        "what_already_exists": "Prompt formatting is known to affect output, and degeneration is a recognized failure mode.",
        "what_is_novel": "The explicit quantitative link between formatting, degeneration rate, and accuracy spread, and the identification of centered mass as the main driver of accuracy variation, is novel.",
        "classification_explanation": "This is a new, empirically supported theory that extends prior work on prompt sensitivity by quantifying the relationship between degeneration and accuracy spread.",
        "likely_classification": "new",
        "references": [
            "Zhou et al. (2023) Quantifying Language Models' Sensitivity to Spurious Features in Prompt Design [formatting sensitivity, degeneration]"
        ]
    },
    "theory_type_general_specific": "specific",
    "reflected_from_theory_index": 3,
    "version": "built-theory-from-results-single-theory-reflection2-nov14-2025",
    "type": "specific"
}</code></pre>
        </div>
    </div>
</body>
</html>