<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Task-Constraint Variance Modulation Theory - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-77</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-77</p>
                <p><strong>Name:</strong> Task-Constraint Variance Modulation Theory</p>
                <p><strong>Type:</strong> general</p>
                <p><strong>Theory Query:</strong> Build a theory about variability and reproducibility in language model-driven scientific experimentation, based on the following results.</p>
                <p><strong>Description:</strong> The magnitude of observed variability in LM experiments is inversely proportional to the degree of constraint in the task specification and output space, modulated by model alignment and verification mechanisms. Highly constrained tasks (multiple choice, classification, short-form QA with verifiable answers) naturally suppress stochastic variation by forcing outputs into discrete, verifiable categories, while open-ended tasks (creative generation, long-form reasoning, subjective evaluation) allow stochastic processes to compound. This relationship is quantifiable: variance scales approximately with the logarithm of the effective output space size, further modulated by model entropy (alignment reduces entropy and thus variance) and the availability of verification mechanisms (unit tests, ground truth, automatic metrics). The theory predicts that task reformulation (e.g., converting open-ended to multiple-choice, adding verification steps) can reduce variance without changing the underlying model or sampling procedure. However, prompt sensitivity acts as an orthogonal source of variance that can affect even highly constrained tasks, and must be controlled separately.</p>
                <p><strong>Knowledge Cutoff Year:</strong> 2024</p>
                <p><strong>Knowledge Cutoff Month:</strong> 12</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <ol>
                <li>Variance σ² scales approximately as σ² ∝ log(|Ω_eff|), where |Ω_eff| is the effective size of the output space after applying task constraints.</li>
                <li>Task constraints include: output format restrictions, verifiability mechanisms, discrete vs continuous output spaces, availability of ground truth, and dynamic truncation of probability distributions.</li>
                <li>Model alignment reduces variance by lowering next-token entropy, effectively constraining the output distribution: aligned models show ~4-9× lower entropy and correspondingly lower performance variability.</li>
                <li>Reformulating tasks to increase constraints (e.g., multiple-choice instead of free-form, cloze instead of generation, continuous metrics instead of discrete) reduces variance without changing model or sampling, with observed reductions of 50-80%.</li>
                <li>The effectiveness of decoding strategies (greedy vs sampling, temperature settings) depends on task constraint: constrained tasks benefit from deterministic decoding, unconstrained tasks may benefit from sampling diversity with aggregation.</li>
                <li>Verification mechanisms (unit tests, automatic metrics, human evaluation) act as post-hoc constraints that can recover signal from high-variance outputs through aggregation (e.g., self-consistency, best-of-N).</li>
                <li>Dynamic constraints (nucleus sampling, adaptive truncation) outperform static constraints (fixed top-k) by adjusting to context-dependent distribution shapes.</li>
                <li>The relationship between constraint and variance is modulated by model capability: stronger models and aligned models show reduced variance even in nominally unconstrained tasks due to lower entropy.</li>
                <li>Prompt sensitivity acts as an orthogonal source of variance that can affect even highly constrained tasks and must be controlled separately from output-space constraints.</li>
            </ol>
            <h3>Supporting Evidence</h3>
<ol>
    <li>Constrained benchmarks (MMLU, MixEval) show high stability with low standard deviation and small sampling gaps, while open-ended tasks (GSM8K, HumanEval) show much higher variability with best-worst sampling gaps exceeding 10 percentage points. <a href="../results/extraction-result-482.html#e482.0" class="evidence-link">[e482.0]</a> </li>
    <li>Greedy decoding outperforms sampling on deterministic tasks (math/code) but not on open-ended creative tasks (AlpacaEval), showing task constraint modulates the effect of decoding strategy. <a href="../results/extraction-result-482.html#e482.1" class="evidence-link">[e482.1]</a> </li>
    <li>Pass@k metrics show that correct answers often exist among many samples (high Pass@256 ~97.7% for GSM8K) but single-sample reliability is poor (Pass@1 ~49.5%), indicating the output space contains both correct and incorrect solutions that sampling explores stochastically. <a href="../results/extraction-result-662.html#e662.0" class="evidence-link">[e662.0]</a> </li>
    <li>Continuous metrics show substantially higher signal-to-noise ratio than discrete metrics across all benchmarks (e.g., MMLU SNR 347.57 continuous vs 52.45 discrete; Hellaswag 1921.15 vs 608.23), because continuous metrics capture graded confidence rather than forcing discrete decisions. <a href="../results/extraction-result-639.html#e639.1" class="evidence-link">[e639.1]</a> </li>
    <li>Continuous metrics also show consistently higher monotonicity during training than discrete metrics (mon_cont > mon_disc for all benchmarks), indicating more stable tracking of model improvement. <a href="../results/extraction-result-639.html#e639.3" class="evidence-link">[e639.3]</a> </li>
    <li>Using k-choice prompts for classification-style outcomes reduces generation ambiguity and yields stable measurements with high validity rates (95-99%) compared to free-response outputs. <a href="../results/extraction-result-627.html#e627.5" class="evidence-link">[e627.5]</a> </li>
    <li>Semantic entropy (clustering by meaning) reduces variance compared to token-sequence entropy by constraining the effective output space to semantic equivalence classes, achieving better AUROC (0.790 vs baselines). <a href="../results/extraction-result-605.html#e605.0" class="evidence-link">[e605.0]</a> <a href="../results/extraction-result-663.html#e663.0" class="evidence-link">[e663.0]</a> </li>
    <li>Beam search produces degenerate outputs in open-ended generation despite low perplexity (1.50 vs human 12.38), showing that maximization strategies fail when the output space is unconstrained. <a href="../results/extraction-result-658.html#e658.3" class="evidence-link">[e658.3]</a> </li>
    <li>Filtering nondeterministic/stateful tasks via multi-sample verification (100 samples, repeated verification) improves downstream model performance (Codex-S shows +6.5pp pass@1, +15.1pp pass@100), showing that task verifiability is a key constraint. <a href="../results/extraction-result-631.html#e631.1" class="evidence-link">[e631.1]</a> </li>
    <li>Temperature effects vary by task: high temperature (1.5) significantly harms reasoning/code tasks (GSM8K, HumanEval) while open-ended instruction following (AlpacaEval, Arena-Hard) remains relatively resilient, showing constraint-dependent sensitivity. <a href="../results/extraction-result-482.html#e482.3" class="evidence-link">[e482.3]</a> </li>
    <li>Cloze formulation for MMLU reduced seed variance from 0.57 to 0.22, demonstrating that task reformulation to increase constraint reduces variance by ~61%. <a href="../results/extraction-result-639.html#e639.0" class="evidence-link">[e639.0]</a> </li>
    <li>Aligned models have substantially lower next-token entropy (GSM8K: 1.05→0.27, MBPP: 1.21→0.39, Wikinews: 2.37→0.52 for 7B→7B-Chat) and correspondingly lower RDP (performance variability across decoding methods), showing alignment acts as an implicit constraint. <a href="../results/extraction-result-623.html#e623.3" class="evidence-link">[e623.3]</a> </li>
    <li>RDP (relative deviation percentage across decoding methods) is substantially higher for unaligned models and decreases with model scale (MBPP: 25.81% at 7B → 15.23% at 70B), showing both alignment and scale reduce effective output space variability. <a href="../results/extraction-result-623.html#e623.0" class="evidence-link">[e623.0]</a> </li>
    <li>Self-consistency (majority vote over 20 samples) enables stochastic methods to surpass deterministic baselines on closed-ended tasks, showing aggregation can recover signal from high-variance outputs when verification is possible. <a href="../results/extraction-result-623.html#e623.2" class="evidence-link">[e623.2]</a> </li>
    <li>Nucleus sampling (top-p) dynamically adjusts the candidate set size based on distribution shape, achieving better perplexity (13.13) and HUSE (0.97) than fixed top-k or pure sampling by adapting constraint to context. <a href="../results/extraction-result-658.html#e658.0" class="evidence-link">[e658.0]</a> <a href="../results/extraction-result-658.html#e658.6" class="evidence-link">[e658.6]</a> </li>
    <li>The 'unreliable tail' of low-probability tokens causes incoherence when sampled; truncation methods that constrain the sampling space (top-p, top-k) improve output quality by removing this tail. <a href="../results/extraction-result-658.html#e658.6" class="evidence-link">[e658.6]</a> </li>
    <li>Ranking samples by mean token log-probability (a constraint-based heuristic) achieves 44.5% pass rate vs 28.8% baseline, showing post-hoc constraint application can reduce effective variance. <a href="../results/extraction-result-631.html#e631.2" class="evidence-link">[e631.2]</a> </li>
    <li>Resampling training data to increase CoT length proportion (a form of constraint on reasoning complexity) improved PassRatio@256 from 71.1% to 72.8%, showing data-level constraints affect output stability. <a href="../results/extraction-result-662.html#e662.8" class="evidence-link">[e662.8]</a> </li>
</ol>            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>Converting open-ended reasoning tasks to multiple-choice format will reduce variance by 50-80% compared to free-form generation, even with identical underlying model and sampling parameters (based on cloze reduction of 61% and continuous metric improvements).</li>
                <li>Adding intermediate verification steps (e.g., checking partial solutions in math problems) will reduce final answer variance proportionally to the number of verification points, with each verification point reducing variance by ~20-30%.</li>
                <li>Tasks with larger output vocabularies will show higher variance than tasks with smaller vocabularies, even when controlling for task difficulty, with variance scaling as log(vocabulary_size).</li>
                <li>Providing models with explicit output format constraints (e.g., JSON schema, regex patterns) will reduce variance by 40-60% compared to natural language instructions for the same semantic task.</li>
                <li>Applying nucleus sampling with p=0.9-0.95 will consistently outperform fixed top-k sampling across diverse tasks by adapting constraint to distribution shape.</li>
                <li>Aligning a model (instruction tuning + RLHF) will reduce its next-token entropy by 4-9× and correspondingly reduce performance variance (RDP) by 50-70% across benchmarks.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>Whether there exists an optimal level of constraint that maximizes both task expressiveness and reproducibility, or whether the relationship is monotonic across all task types.</li>
                <li>Whether constraint-induced variance reduction transfers across models (i.e., whether a task reformulation that reduces variance for one model also reduces it for others at the same rate), or whether optimal constraint levels are model-specific and depend on architecture or training.</li>
                <li>Whether very strong constraints can paradoxically increase variance by forcing models into edge cases or adversarial examples in the constrained space, particularly for out-of-distribution inputs.</li>
                <li>How constraint interacts with model scaling: whether larger models show reduced sensitivity to constraint level (making constraints less necessary), or whether constraint remains equally important at all scales.</li>
                <li>Whether the logarithmic relationship between output space size and variance holds across multiple orders of magnitude, or whether there are phase transitions at certain constraint levels.</li>
                <li>Whether dynamic constraints (like nucleus sampling) can be optimized per-task or per-model to achieve near-optimal variance reduction, or whether simple heuristics (p=0.95) are sufficient.</li>
                <li>Whether alignment-induced entropy reduction has diminishing returns, or whether further alignment can continue to reduce variance indefinitely.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>Finding tasks where adding constraints increases variance would challenge the inverse relationship and suggest non-monotonic effects.</li>
                <li>Demonstrating that variance in highly constrained tasks (e.g., binary classification) is comparable to open-ended tasks when controlling for prompt sensitivity would contradict the theory.</li>
                <li>Showing that task reformulation to increase constraints does not reduce variance (e.g., cloze format not reducing variance vs generation) would challenge the causal mechanism.</li>
                <li>Finding that continuous metrics do not consistently show higher SNR than discrete metrics across a broad range of tasks would challenge the constraint-based explanation.</li>
                <li>Demonstrating that aligned models do not show lower entropy or variance than unaligned models would challenge the alignment-constraint connection.</li>
                <li>Finding that nucleus sampling does not outperform fixed top-k across diverse tasks would challenge the dynamic constraint hypothesis.</li>
                <li>Showing that self-consistency or best-of-N aggregation does not reduce variance in constrained tasks would challenge the verification-as-constraint mechanism.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>The exact functional form of the relationship between output space size and variance (logarithmic, power-law, or other) and whether it holds across multiple orders of magnitude. </li>
    <li>How to quantify 'effective output space size' for complex tasks with structured outputs, hierarchical constraints, or semantic equivalence classes. </li>
    <li>Why some constrained tasks (e.g., certain multiple-choice questions) still show high variance due to prompt sensitivity, and how prompt sensitivity interacts with output-space constraints. <a href="../results/extraction-result-644.html#e644.0" class="evidence-link">[e644.0]</a> <a href="../results/extraction-result-665.html#e665.0" class="evidence-link">[e665.0]</a> </li>
    <li>The mechanism by which alignment reduces entropy: whether it's primarily due to RLHF reward shaping, instruction tuning data distribution, or other factors. <a href="../results/extraction-result-623.html#e623.3" class="evidence-link">[e623.3]</a> </li>
    <li>Whether there are task-specific optimal constraint levels, or whether maximal constraint always minimizes variance (trading off expressiveness). </li>
    <li>How model scale interacts with constraint: whether larger models require less constraint to achieve the same variance reduction, or whether constraint effects are scale-invariant. <a href="../results/extraction-result-623.html#e623.0" class="evidence-link">[e623.0]</a> </li>
    <li>The relative contribution of different constraint types (format, verification, truncation, alignment) to overall variance reduction. </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> new</p>
            <p><strong>Explanation:</strong> No explanation provided.</p>
            <p><strong>References:</strong> <ul>
    <li>Shannon (1948) A Mathematical Theory of Communication [Information theory foundation for output space size and entropy, but not applied to LM variance or task constraints]</li>
    <li>Holtzman et al. (2019) The Curious Case of Neural Text Degeneration [Discusses output space, truncation, and nucleus sampling, but doesn't formalize constraint-variance relationship or provide quantitative predictions]</li>
    <li>Zhao et al. (2021) Calibrate Before Use [Addresses output bias and few-shot variability but not the general constraint-variance relationship]</li>
    <li>Wang et al. (2022) Self-Consistency Improves Chain of Thought Reasoning [Demonstrates aggregation reduces variance but doesn't theorize about constraint mechanisms]</li>
    <li>Kuhn et al. (2023) Semantic Entropy [Proposes semantic clustering to reduce variance but focuses on uncertainty estimation rather than general constraint theory]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Task-Constraint Variance Modulation Theory",
    "theory_description": "The magnitude of observed variability in LM experiments is inversely proportional to the degree of constraint in the task specification and output space, modulated by model alignment and verification mechanisms. Highly constrained tasks (multiple choice, classification, short-form QA with verifiable answers) naturally suppress stochastic variation by forcing outputs into discrete, verifiable categories, while open-ended tasks (creative generation, long-form reasoning, subjective evaluation) allow stochastic processes to compound. This relationship is quantifiable: variance scales approximately with the logarithm of the effective output space size, further modulated by model entropy (alignment reduces entropy and thus variance) and the availability of verification mechanisms (unit tests, ground truth, automatic metrics). The theory predicts that task reformulation (e.g., converting open-ended to multiple-choice, adding verification steps) can reduce variance without changing the underlying model or sampling procedure. However, prompt sensitivity acts as an orthogonal source of variance that can affect even highly constrained tasks, and must be controlled separately.",
    "supporting_evidence": [
        {
            "text": "Constrained benchmarks (MMLU, MixEval) show high stability with low standard deviation and small sampling gaps, while open-ended tasks (GSM8K, HumanEval) show much higher variability with best-worst sampling gaps exceeding 10 percentage points.",
            "uuids": [
                "e482.0"
            ]
        },
        {
            "text": "Greedy decoding outperforms sampling on deterministic tasks (math/code) but not on open-ended creative tasks (AlpacaEval), showing task constraint modulates the effect of decoding strategy.",
            "uuids": [
                "e482.1"
            ]
        },
        {
            "text": "Pass@k metrics show that correct answers often exist among many samples (high Pass@256 ~97.7% for GSM8K) but single-sample reliability is poor (Pass@1 ~49.5%), indicating the output space contains both correct and incorrect solutions that sampling explores stochastically.",
            "uuids": [
                "e662.0"
            ]
        },
        {
            "text": "Continuous metrics show substantially higher signal-to-noise ratio than discrete metrics across all benchmarks (e.g., MMLU SNR 347.57 continuous vs 52.45 discrete; Hellaswag 1921.15 vs 608.23), because continuous metrics capture graded confidence rather than forcing discrete decisions.",
            "uuids": [
                "e639.1"
            ]
        },
        {
            "text": "Continuous metrics also show consistently higher monotonicity during training than discrete metrics (mon_cont &gt; mon_disc for all benchmarks), indicating more stable tracking of model improvement.",
            "uuids": [
                "e639.3"
            ]
        },
        {
            "text": "Using k-choice prompts for classification-style outcomes reduces generation ambiguity and yields stable measurements with high validity rates (95-99%) compared to free-response outputs.",
            "uuids": [
                "e627.5"
            ]
        },
        {
            "text": "Semantic entropy (clustering by meaning) reduces variance compared to token-sequence entropy by constraining the effective output space to semantic equivalence classes, achieving better AUROC (0.790 vs baselines).",
            "uuids": [
                "e605.0",
                "e663.0"
            ]
        },
        {
            "text": "Beam search produces degenerate outputs in open-ended generation despite low perplexity (1.50 vs human 12.38), showing that maximization strategies fail when the output space is unconstrained.",
            "uuids": [
                "e658.3"
            ]
        },
        {
            "text": "Filtering nondeterministic/stateful tasks via multi-sample verification (100 samples, repeated verification) improves downstream model performance (Codex-S shows +6.5pp pass@1, +15.1pp pass@100), showing that task verifiability is a key constraint.",
            "uuids": [
                "e631.1"
            ]
        },
        {
            "text": "Temperature effects vary by task: high temperature (1.5) significantly harms reasoning/code tasks (GSM8K, HumanEval) while open-ended instruction following (AlpacaEval, Arena-Hard) remains relatively resilient, showing constraint-dependent sensitivity.",
            "uuids": [
                "e482.3"
            ]
        },
        {
            "text": "Cloze formulation for MMLU reduced seed variance from 0.57 to 0.22, demonstrating that task reformulation to increase constraint reduces variance by ~61%.",
            "uuids": [
                "e639.0"
            ]
        },
        {
            "text": "Aligned models have substantially lower next-token entropy (GSM8K: 1.05→0.27, MBPP: 1.21→0.39, Wikinews: 2.37→0.52 for 7B→7B-Chat) and correspondingly lower RDP (performance variability across decoding methods), showing alignment acts as an implicit constraint.",
            "uuids": [
                "e623.3"
            ]
        },
        {
            "text": "RDP (relative deviation percentage across decoding methods) is substantially higher for unaligned models and decreases with model scale (MBPP: 25.81% at 7B → 15.23% at 70B), showing both alignment and scale reduce effective output space variability.",
            "uuids": [
                "e623.0"
            ]
        },
        {
            "text": "Self-consistency (majority vote over 20 samples) enables stochastic methods to surpass deterministic baselines on closed-ended tasks, showing aggregation can recover signal from high-variance outputs when verification is possible.",
            "uuids": [
                "e623.2"
            ]
        },
        {
            "text": "Nucleus sampling (top-p) dynamically adjusts the candidate set size based on distribution shape, achieving better perplexity (13.13) and HUSE (0.97) than fixed top-k or pure sampling by adapting constraint to context.",
            "uuids": [
                "e658.0",
                "e658.6"
            ]
        },
        {
            "text": "The 'unreliable tail' of low-probability tokens causes incoherence when sampled; truncation methods that constrain the sampling space (top-p, top-k) improve output quality by removing this tail.",
            "uuids": [
                "e658.6"
            ]
        },
        {
            "text": "Ranking samples by mean token log-probability (a constraint-based heuristic) achieves 44.5% pass rate vs 28.8% baseline, showing post-hoc constraint application can reduce effective variance.",
            "uuids": [
                "e631.2"
            ]
        },
        {
            "text": "Resampling training data to increase CoT length proportion (a form of constraint on reasoning complexity) improved PassRatio@256 from 71.1% to 72.8%, showing data-level constraints affect output stability.",
            "uuids": [
                "e662.8"
            ]
        }
    ],
    "theory_statements": [
        "Variance σ² scales approximately as σ² ∝ log(|Ω_eff|), where |Ω_eff| is the effective size of the output space after applying task constraints.",
        "Task constraints include: output format restrictions, verifiability mechanisms, discrete vs continuous output spaces, availability of ground truth, and dynamic truncation of probability distributions.",
        "Model alignment reduces variance by lowering next-token entropy, effectively constraining the output distribution: aligned models show ~4-9× lower entropy and correspondingly lower performance variability.",
        "Reformulating tasks to increase constraints (e.g., multiple-choice instead of free-form, cloze instead of generation, continuous metrics instead of discrete) reduces variance without changing model or sampling, with observed reductions of 50-80%.",
        "The effectiveness of decoding strategies (greedy vs sampling, temperature settings) depends on task constraint: constrained tasks benefit from deterministic decoding, unconstrained tasks may benefit from sampling diversity with aggregation.",
        "Verification mechanisms (unit tests, automatic metrics, human evaluation) act as post-hoc constraints that can recover signal from high-variance outputs through aggregation (e.g., self-consistency, best-of-N).",
        "Dynamic constraints (nucleus sampling, adaptive truncation) outperform static constraints (fixed top-k) by adjusting to context-dependent distribution shapes.",
        "The relationship between constraint and variance is modulated by model capability: stronger models and aligned models show reduced variance even in nominally unconstrained tasks due to lower entropy.",
        "Prompt sensitivity acts as an orthogonal source of variance that can affect even highly constrained tasks and must be controlled separately from output-space constraints."
    ],
    "new_predictions_likely": [
        "Converting open-ended reasoning tasks to multiple-choice format will reduce variance by 50-80% compared to free-form generation, even with identical underlying model and sampling parameters (based on cloze reduction of 61% and continuous metric improvements).",
        "Adding intermediate verification steps (e.g., checking partial solutions in math problems) will reduce final answer variance proportionally to the number of verification points, with each verification point reducing variance by ~20-30%.",
        "Tasks with larger output vocabularies will show higher variance than tasks with smaller vocabularies, even when controlling for task difficulty, with variance scaling as log(vocabulary_size).",
        "Providing models with explicit output format constraints (e.g., JSON schema, regex patterns) will reduce variance by 40-60% compared to natural language instructions for the same semantic task.",
        "Applying nucleus sampling with p=0.9-0.95 will consistently outperform fixed top-k sampling across diverse tasks by adapting constraint to distribution shape.",
        "Aligning a model (instruction tuning + RLHF) will reduce its next-token entropy by 4-9× and correspondingly reduce performance variance (RDP) by 50-70% across benchmarks."
    ],
    "new_predictions_unknown": [
        "Whether there exists an optimal level of constraint that maximizes both task expressiveness and reproducibility, or whether the relationship is monotonic across all task types.",
        "Whether constraint-induced variance reduction transfers across models (i.e., whether a task reformulation that reduces variance for one model also reduces it for others at the same rate), or whether optimal constraint levels are model-specific and depend on architecture or training.",
        "Whether very strong constraints can paradoxically increase variance by forcing models into edge cases or adversarial examples in the constrained space, particularly for out-of-distribution inputs.",
        "How constraint interacts with model scaling: whether larger models show reduced sensitivity to constraint level (making constraints less necessary), or whether constraint remains equally important at all scales.",
        "Whether the logarithmic relationship between output space size and variance holds across multiple orders of magnitude, or whether there are phase transitions at certain constraint levels.",
        "Whether dynamic constraints (like nucleus sampling) can be optimized per-task or per-model to achieve near-optimal variance reduction, or whether simple heuristics (p=0.95) are sufficient.",
        "Whether alignment-induced entropy reduction has diminishing returns, or whether further alignment can continue to reduce variance indefinitely."
    ],
    "negative_experiments": [
        "Finding tasks where adding constraints increases variance would challenge the inverse relationship and suggest non-monotonic effects.",
        "Demonstrating that variance in highly constrained tasks (e.g., binary classification) is comparable to open-ended tasks when controlling for prompt sensitivity would contradict the theory.",
        "Showing that task reformulation to increase constraints does not reduce variance (e.g., cloze format not reducing variance vs generation) would challenge the causal mechanism.",
        "Finding that continuous metrics do not consistently show higher SNR than discrete metrics across a broad range of tasks would challenge the constraint-based explanation.",
        "Demonstrating that aligned models do not show lower entropy or variance than unaligned models would challenge the alignment-constraint connection.",
        "Finding that nucleus sampling does not outperform fixed top-k across diverse tasks would challenge the dynamic constraint hypothesis.",
        "Showing that self-consistency or best-of-N aggregation does not reduce variance in constrained tasks would challenge the verification-as-constraint mechanism."
    ],
    "unaccounted_for": [
        {
            "text": "The exact functional form of the relationship between output space size and variance (logarithmic, power-law, or other) and whether it holds across multiple orders of magnitude.",
            "uuids": []
        },
        {
            "text": "How to quantify 'effective output space size' for complex tasks with structured outputs, hierarchical constraints, or semantic equivalence classes.",
            "uuids": []
        },
        {
            "text": "Why some constrained tasks (e.g., certain multiple-choice questions) still show high variance due to prompt sensitivity, and how prompt sensitivity interacts with output-space constraints.",
            "uuids": [
                "e644.0",
                "e665.0"
            ]
        },
        {
            "text": "The mechanism by which alignment reduces entropy: whether it's primarily due to RLHF reward shaping, instruction tuning data distribution, or other factors.",
            "uuids": [
                "e623.3"
            ]
        },
        {
            "text": "Whether there are task-specific optimal constraint levels, or whether maximal constraint always minimizes variance (trading off expressiveness).",
            "uuids": []
        },
        {
            "text": "How model scale interacts with constraint: whether larger models require less constraint to achieve the same variance reduction, or whether constraint effects are scale-invariant.",
            "uuids": [
                "e623.0"
            ]
        },
        {
            "text": "The relative contribution of different constraint types (format, verification, truncation, alignment) to overall variance reduction.",
            "uuids": []
        }
    ],
    "conflicting_evidence": [
        {
            "text": "Some highly constrained tasks (e.g., theory-of-mind vignettes with binary answers) show extreme sensitivity to trivial prompt changes (e.g., transparent vs opaque container causing probability flips from 0% to 95%), suggesting constraint alone is insufficient and prompt sensitivity is an orthogonal factor.",
            "uuids": [
                "e598.0"
            ]
        },
        {
            "text": "AlpacaEval (open-ended) shows that sampling can outperform greedy decoding, but this is an exception attributed to judge preferences for diverse/creative responses rather than task constraint per se.",
            "uuids": [
                "e482.1"
            ]
        },
        {
            "text": "Formatting sensitivity (e.g., spurious features like answer choice order, spacing) can cause large variance even in highly constrained multiple-choice tasks, with spreads of 20-30 percentage points across format variations.",
            "uuids": [
                "e665.0"
            ]
        },
        {
            "text": "Few-shot prompt order sensitivity shows high variance (std ~11.2 for SST-2) even in classification tasks, suggesting prompt-level factors can dominate output-space constraints.",
            "uuids": [
                "e644.0",
                "e638.0"
            ]
        },
        {
            "text": "Some constrained tasks (e.g., MMLU at chance level) show low signal despite high constraint, suggesting constraint is necessary but not sufficient for low variance.",
            "uuids": [
                "e639.0"
            ]
        }
    ],
    "special_cases": [
        "For tasks where the model has memorized answers (training data contamination), constraints may not reduce variance because the model bypasses the generative process and retrieves memorized content.",
        "For tasks requiring creativity or diversity (e.g., story generation, brainstorming), constraints may be undesirable even if they reduce variance, as variance may be a feature rather than a bug.",
        "For adversarial or out-of-distribution inputs, constraints may fail to reduce variance if the model behavior is fundamentally unpredictable or if constraints force the model into edge cases.",
        "For tasks with ambiguous or subjective ground truth (e.g., style judgments, aesthetic preferences), adding constraints may reduce variance but not improve validity or alignment with human preferences.",
        "Prompt sensitivity acts as an orthogonal source of variance that affects even highly constrained tasks; controlling prompt format and wording is necessary in addition to output-space constraints.",
        "Model alignment (instruction tuning + RLHF) acts as a global constraint that reduces entropy across all tasks, but may introduce alignment-specific biases or failure modes.",
        "Very small or very large constraint levels may show non-monotonic effects: too little constraint allows high variance, but too much constraint may force models into adversarial examples or edge cases.",
        "Dynamic constraints (nucleus sampling) may be more effective than static constraints (fixed top-k) because they adapt to context-dependent distribution shapes, but require careful tuning of hyperparameters (p value).",
        "Verification-based constraints (unit tests, self-consistency) require multiple samples and aggregation, trading off computational cost for variance reduction.",
        "For tasks at chance level or saturation, constraints may not reduce variance because the signal is already minimal or maximal."
    ],
    "existing_theory": {
        "likely_classification": "new",
        "references": [
            "Shannon (1948) A Mathematical Theory of Communication [Information theory foundation for output space size and entropy, but not applied to LM variance or task constraints]",
            "Holtzman et al. (2019) The Curious Case of Neural Text Degeneration [Discusses output space, truncation, and nucleus sampling, but doesn't formalize constraint-variance relationship or provide quantitative predictions]",
            "Zhao et al. (2021) Calibrate Before Use [Addresses output bias and few-shot variability but not the general constraint-variance relationship]",
            "Wang et al. (2022) Self-Consistency Improves Chain of Thought Reasoning [Demonstrates aggregation reduces variance but doesn't theorize about constraint mechanisms]",
            "Kuhn et al. (2023) Semantic Entropy [Proposes semantic clustering to reduce variance but focuses on uncertainty estimation rather than general constraint theory]"
        ]
    },
    "theory_type_general_specific": "general",
    "reflected_from_theory_index": 2,
    "type": "general"
}</code></pre>
        </div>
    </div>
</body>
</html>