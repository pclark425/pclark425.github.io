<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Contextual Compression-Expansion Memory Theory for LLM Agents in Text Games - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-950</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-950</p>
                <p><strong>Name:</strong> Contextual Compression-Expansion Memory Theory for LLM Agents in Text Games</p>
                <p><strong>Type:</strong> general</p>
                <p><strong>Theory Query:</strong> Build a theory of how LLM agents for text games can best use memory to solve text game tasks.</p>
                <p><strong>Description:</strong> This theory proposes that LLM agents optimally use memory in text games by dynamically compressing past experiences into compact, context-sensitive representations during routine play, and expanding these representations into detailed traces when encountering uncertainty, ambiguity, or the need for planning, thus balancing efficiency and flexibility.</p>
                <p><strong>Knowledge Cutoff Year:</strong> -1</p>
                <p><strong>Knowledge Cutoff Month:</strong> -1</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <h3>Statement 0: Contextual Memory Compression (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; LLM agent &#8594; is_in &#8594; routine or familiar game state</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; LLM agent &#8594; compresses &#8594; past experiences into compact representations (e.g., summaries, embeddings, schemas)</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Human memory is known to compress routine experiences into schemas or scripts, reducing cognitive load. </li>
    <li>LLM agents with memory bottlenecks (e.g., limited context window) benefit from summarization or embedding-based memory. </li>
    <li>Empirical studies show that LLMs using memory summarization or schema-based memory outperform those using raw transcripts in long-horizon text games. </li>
    <li>Cognitive architectures (e.g., Soar, ACT-R) use chunking and schema abstraction to manage memory efficiently in sequential decision tasks. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> Compression is known, but its dynamic, context-driven application in LLM agents for text games is new.</p>            <p><strong>What Already Exists:</strong> Memory compression and schema formation are established in cognitive science; memory summarization is used in LLMs.</p>            <p><strong>What is Novel:</strong> The dynamic, context-sensitive switching between compression and expansion in LLM agents for text games is novel.</p>
            <p><strong>References:</strong> <ul>
    <li>Bartlett (1932) Remembering: A Study in Experimental and Social Psychology [schema theory in human memory]</li>
    <li>Liu et al. (2023) Lost in the Middle: How Language Models Use Long Contexts [context window limitations and summarization in LLMs]</li>
    <li>Laird et al. (1987) Soar: An architecture for general intelligence [chunking and abstraction in cognitive architectures]</li>
</ul>
            <h3>Statement 1: Contextual Memory Expansion for Uncertainty Resolution (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; LLM agent &#8594; encounters &#8594; uncertainty, ambiguity, or planning need<span style="color: #888888;">, and</span></div>
        <div>&#8226; LLM agent &#8594; has &#8594; compressed memory representations</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; LLM agent &#8594; expands &#8594; compressed representations into detailed episodic traces<span style="color: #888888;">, and</span></div>
        <div>&#8226; LLM agent &#8594; uses &#8594; expanded traces for reasoning, disambiguation, or planning</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Humans recall detailed memories when facing uncertainty or novel problems, expanding from compressed schemas. </li>
    <li>LLM agents with retrieval-augmented or expandable memory modules show improved performance in tasks requiring detailed recall. </li>
    <li>Script theory in cognitive science posits that detailed episodic recall is triggered by schema violations or ambiguity. </li>
    <li>Experiments with LLM agents in text games show that retrieval of detailed past events improves performance in puzzles and planning tasks. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> Expansion is known in humans, but its operationalization in LLM agents for text games is new.</p>            <p><strong>What Already Exists:</strong> Memory expansion and detailed recall in response to uncertainty are known in cognitive science.</p>            <p><strong>What is Novel:</strong> The explicit, dynamic expansion of compressed memory in LLM agents for text games, triggered by uncertainty or planning needs, is novel.</p>
            <p><strong>References:</strong> <ul>
    <li>Schank & Abelson (1977) Scripts, Plans, Goals, and Understanding [script theory, expansion in novel situations]</li>
    <li>Khandelwal et al. (2019) Generalization through Memorization: Nearest Neighbor Language Models [retrieval-augmented LMs, but not dynamic expansion]</li>
    <li>Madotto et al. (2020) Memory Grounded Conversational Reasoning [retrieval and expansion in LLMs]</li>
</ul>
            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>LLM agents that compress memory during routine play and expand it during uncertainty will use less memory and compute while maintaining or improving performance compared to agents with static memory usage.</li>
                <li>Agents with dynamic compression-expansion memory will be more robust to context window limitations and catastrophic forgetting.</li>
                <li>In text games with frequent ambiguity, agents with expansion mechanisms will outperform those with only compressed memory.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>If compression-expansion mechanisms are made recursive (i.e., compressing expanded traces after resolution), agents may develop emergent meta-memory strategies.</li>
                <li>In highly non-stationary or adversarial games, the optimal compression-expansion schedule may become adaptive or self-modifying.</li>
                <li>The balance between compression and expansion may lead to emergent behaviors such as selective forgetting or creative problem solving.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>If static memory (no compression or expansion) performs as well as dynamic memory, the theory's core claim is undermined.</li>
                <li>If expansion of compressed memory does not improve uncertainty resolution or planning, the theory is challenged.</li>
                <li>If agents with dynamic memory mechanisms are more prone to error or hallucination than those with static memory, the theory is weakened.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>The impact of memory compression on the agent's ability to learn new, rare, or out-of-distribution events is not fully addressed. </li>
    <li>The theory does not specify how to optimally detect uncertainty or ambiguity in all text game contexts. </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> somewhat-related-to-existing</p>
            <p><strong>Explanation:</strong> The theory builds on known memory processes but introduces a novel, operational mechanism for LLM agents in text games.</p>
            <p><strong>References:</strong> <ul>
    <li>Bartlett (1932) Remembering: A Study in Experimental and Social Psychology [schema theory]</li>
    <li>Schank & Abelson (1977) Scripts, Plans, Goals, and Understanding [script expansion]</li>
    <li>Liu et al. (2023) Lost in the Middle: How Language Models Use Long Contexts [context window and summarization in LLMs]</li>
    <li>Laird et al. (1987) Soar: An architecture for general intelligence [chunking and abstraction in cognitive architectures]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Contextual Compression-Expansion Memory Theory for LLM Agents in Text Games",
    "theory_description": "This theory proposes that LLM agents optimally use memory in text games by dynamically compressing past experiences into compact, context-sensitive representations during routine play, and expanding these representations into detailed traces when encountering uncertainty, ambiguity, or the need for planning, thus balancing efficiency and flexibility.",
    "theory_statements": [
        {
            "law": {
                "law_name": "Contextual Memory Compression",
                "if": [
                    {
                        "subject": "LLM agent",
                        "relation": "is_in",
                        "object": "routine or familiar game state"
                    }
                ],
                "then": [
                    {
                        "subject": "LLM agent",
                        "relation": "compresses",
                        "object": "past experiences into compact representations (e.g., summaries, embeddings, schemas)"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Human memory is known to compress routine experiences into schemas or scripts, reducing cognitive load.",
                        "uuids": []
                    },
                    {
                        "text": "LLM agents with memory bottlenecks (e.g., limited context window) benefit from summarization or embedding-based memory.",
                        "uuids": []
                    },
                    {
                        "text": "Empirical studies show that LLMs using memory summarization or schema-based memory outperform those using raw transcripts in long-horizon text games.",
                        "uuids": []
                    },
                    {
                        "text": "Cognitive architectures (e.g., Soar, ACT-R) use chunking and schema abstraction to manage memory efficiently in sequential decision tasks.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Memory compression and schema formation are established in cognitive science; memory summarization is used in LLMs.",
                    "what_is_novel": "The dynamic, context-sensitive switching between compression and expansion in LLM agents for text games is novel.",
                    "classification_explanation": "Compression is known, but its dynamic, context-driven application in LLM agents for text games is new.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Bartlett (1932) Remembering: A Study in Experimental and Social Psychology [schema theory in human memory]",
                        "Liu et al. (2023) Lost in the Middle: How Language Models Use Long Contexts [context window limitations and summarization in LLMs]",
                        "Laird et al. (1987) Soar: An architecture for general intelligence [chunking and abstraction in cognitive architectures]"
                    ]
                }
            }
        },
        {
            "law": {
                "law_name": "Contextual Memory Expansion for Uncertainty Resolution",
                "if": [
                    {
                        "subject": "LLM agent",
                        "relation": "encounters",
                        "object": "uncertainty, ambiguity, or planning need"
                    },
                    {
                        "subject": "LLM agent",
                        "relation": "has",
                        "object": "compressed memory representations"
                    }
                ],
                "then": [
                    {
                        "subject": "LLM agent",
                        "relation": "expands",
                        "object": "compressed representations into detailed episodic traces"
                    },
                    {
                        "subject": "LLM agent",
                        "relation": "uses",
                        "object": "expanded traces for reasoning, disambiguation, or planning"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Humans recall detailed memories when facing uncertainty or novel problems, expanding from compressed schemas.",
                        "uuids": []
                    },
                    {
                        "text": "LLM agents with retrieval-augmented or expandable memory modules show improved performance in tasks requiring detailed recall.",
                        "uuids": []
                    },
                    {
                        "text": "Script theory in cognitive science posits that detailed episodic recall is triggered by schema violations or ambiguity.",
                        "uuids": []
                    },
                    {
                        "text": "Experiments with LLM agents in text games show that retrieval of detailed past events improves performance in puzzles and planning tasks.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Memory expansion and detailed recall in response to uncertainty are known in cognitive science.",
                    "what_is_novel": "The explicit, dynamic expansion of compressed memory in LLM agents for text games, triggered by uncertainty or planning needs, is novel.",
                    "classification_explanation": "Expansion is known in humans, but its operationalization in LLM agents for text games is new.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Schank & Abelson (1977) Scripts, Plans, Goals, and Understanding [script theory, expansion in novel situations]",
                        "Khandelwal et al. (2019) Generalization through Memorization: Nearest Neighbor Language Models [retrieval-augmented LMs, but not dynamic expansion]",
                        "Madotto et al. (2020) Memory Grounded Conversational Reasoning [retrieval and expansion in LLMs]"
                    ]
                }
            }
        }
    ],
    "new_predictions_likely": [
        "LLM agents that compress memory during routine play and expand it during uncertainty will use less memory and compute while maintaining or improving performance compared to agents with static memory usage.",
        "Agents with dynamic compression-expansion memory will be more robust to context window limitations and catastrophic forgetting.",
        "In text games with frequent ambiguity, agents with expansion mechanisms will outperform those with only compressed memory."
    ],
    "new_predictions_unknown": [
        "If compression-expansion mechanisms are made recursive (i.e., compressing expanded traces after resolution), agents may develop emergent meta-memory strategies.",
        "In highly non-stationary or adversarial games, the optimal compression-expansion schedule may become adaptive or self-modifying.",
        "The balance between compression and expansion may lead to emergent behaviors such as selective forgetting or creative problem solving."
    ],
    "negative_experiments": [
        "If static memory (no compression or expansion) performs as well as dynamic memory, the theory's core claim is undermined.",
        "If expansion of compressed memory does not improve uncertainty resolution or planning, the theory is challenged.",
        "If agents with dynamic memory mechanisms are more prone to error or hallucination than those with static memory, the theory is weakened."
    ],
    "unaccounted_for": [
        {
            "text": "The impact of memory compression on the agent's ability to learn new, rare, or out-of-distribution events is not fully addressed.",
            "uuids": []
        },
        {
            "text": "The theory does not specify how to optimally detect uncertainty or ambiguity in all text game contexts.",
            "uuids": []
        }
    ],
    "conflicting_evidence": [
        {
            "text": "Some LLM agents with large, uncompressed memory buffers have shown strong performance in certain text games, suggesting compression may not always be necessary.",
            "uuids": []
        },
        {
            "text": "In some cases, over-compression can lead to loss of critical details, harming performance.",
            "uuids": []
        }
    ],
    "special_cases": [
        "In games with very short episodes or minimal memory demands, compression-expansion may be unnecessary.",
        "In games with highly repetitive structure, over-compression may lead to loss of critical details.",
        "In games with highly dynamic or adversarial environments, the triggers for expansion may need to be more sensitive or adaptive."
    ],
    "existing_theory": {
        "what_already_exists": "Memory compression and expansion are known in cognitive science and some AI work.",
        "what_is_novel": "The explicit, context-driven, dynamic compression-expansion mechanism for LLM agents in text games is new.",
        "classification_explanation": "The theory builds on known memory processes but introduces a novel, operational mechanism for LLM agents in text games.",
        "likely_classification": "somewhat-related-to-existing",
        "references": [
            "Bartlett (1932) Remembering: A Study in Experimental and Social Psychology [schema theory]",
            "Schank & Abelson (1977) Scripts, Plans, Goals, and Understanding [script expansion]",
            "Liu et al. (2023) Lost in the Middle: How Language Models Use Long Contexts [context window and summarization in LLMs]",
            "Laird et al. (1987) Soar: An architecture for general intelligence [chunking and abstraction in cognitive architectures]"
        ]
    },
    "reflected_from_theory_index": 1,
    "type": "general",
    "version": "built-theory-from-results-single-theory-reflection2-nov14-2025-LLM-BASELINE-no-evidence-without-matched-control-theory-name",
    "theory_query": "Build a theory of how LLM agents for text games can best use memory to solve text game tasks.",
    "original_theory_id": "theory-592",
    "original_theory_name": "Hybrid Memory Architecture Principle for LLM Agents",
    "provide_matched_control_thery_name": false,
    "matched_control_theory_name": null,
    "model_str": "openai/gpt-4.1-2025-04-14"
}</code></pre>
        </div>
    </div>
</body>
</html>