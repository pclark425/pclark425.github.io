<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Spatial Reasoning via Pattern Completion in Language Models - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-1026</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-1026</p>
                <p><strong>Name:</strong> Spatial Reasoning via Pattern Completion in Language Models</p>
                <p><strong>Type:</strong> general</p>
                <p><strong>Theory Query:</strong> Build a theory of how language models solve puzzle games involving spatial knowledge, like Sudoku.</p>
                <p><strong>Description:</strong> This theory proposes that large language models (LLMs) solve spatial puzzle games, such as Sudoku, primarily by leveraging their ability to perform pattern completion. LLMs match partial spatial configurations to learned templates or statistical regularities from their training data, and use these to predict valid continuations or solutions, rather than engaging in explicit symbolic or logical reasoning.</p>
                <p><strong>Knowledge Cutoff Year:</strong> -1</p>
                <p><strong>Knowledge Cutoff Month:</strong> -1</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <h3>Statement 0: Template Matching for Spatial Patterns (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; language model &#8594; has_been_exposed_to &#8594; many_examples_of_spatial_puzzles<span style="color: #888888;">, and</span></div>
        <div>&#8226; input_puzzle &#8594; is_partial_instance_of &#8594; learned_pattern_template</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; model_output &#8594; completes &#8594; pattern_in_accordance_with_template</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>LLMs can fill in missing entries in Sudoku grids by matching to previously seen patterns. </li>
    <li>Performance drops on puzzles with novel or rare configurations, suggesting reliance on pattern familiarity. </li>
    <li>LLMs trained on large datasets of spatial puzzles show higher accuracy on familiar configurations. </li>
    <li>When presented with partial spatial information, LLMs tend to generate completions that are statistically common in their training data. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> This is a novel application of pattern completion to spatial puzzle solving, extending a linguistic mechanism to spatial cognition.</p>            <p><strong>What Already Exists:</strong> Pattern completion is a known ability of LLMs in linguistic domains.</p>            <p><strong>What is Novel:</strong> The law extends this to spatial domains, positing that LLMs use pattern matching for spatial reasoning.</p>
            <p><strong>References:</strong> <ul>
    <li>Radford et al. (2019) Language Models are Unsupervised Multitask Learners [Pattern completion in text]</li>
    <li>Zhou et al. (2022) Can Language Models Solve Sudoku? [LLMs' spatial puzzle performance]</li>
</ul>
            <h3>Statement 1: Statistical Regularity Exploitation (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; language model &#8594; has_learned &#8594; statistical_distribution_of_valid_puzzle_states<span style="color: #888888;">, and</span></div>
        <div>&#8226; current_puzzle_state &#8594; is_incomplete &#8594; True</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; model_predictions &#8594; are_biased_toward &#8594; statistically_likely_completions</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>LLMs tend to produce more common or likely Sudoku solutions, and struggle with rare or edge-case puzzles. </li>
    <li>Performance correlates with the frequency of puzzle patterns in the training data. </li>
    <li>LLMs' errors often reflect the statistical distribution of training data rather than logical impossibility. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> This is a novel extension of statistical regularity exploitation to spatial puzzle solving.</p>            <p><strong>What Already Exists:</strong> LLMs are known to exploit statistical regularities in language.</p>            <p><strong>What is Novel:</strong> The law claims this extends to spatial and logical domains, not just linguistic ones.</p>
            <p><strong>References:</strong> <ul>
    <li>Radford et al. (2019) Language Models are Unsupervised Multitask Learners [Statistical regularity in text]</li>
    <li>Zhou et al. (2022) Can Language Models Solve Sudoku? [LLMs' spatial puzzle performance]</li>
</ul>
            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>LLMs will perform better on spatial puzzles that closely resemble common patterns in their training data.</li>
                <li>Introducing novel or rare spatial configurations will reduce LLM performance, even if the underlying rules are unchanged.</li>
                <li>LLMs will make errors that reflect the statistical distribution of their training data, such as overfitting to common patterns.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>If LLMs are trained on synthetic spatial puzzles with adversarially distributed patterns, they may develop new pattern completion strategies or fail to generalize.</li>
                <li>If LLMs are exposed to puzzles with intentionally misleading partial patterns, their completions may reveal biases in their learned statistical regularities.</li>
                <li>LLMs may develop emergent strategies for spatial reasoning if exposed to sufficiently diverse and challenging spatial puzzles.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>If LLMs can solve spatial puzzles with entirely novel configurations as well as familiar ones, this would challenge the theory.</li>
                <li>If LLMs' performance does not correlate with the frequency of patterns in the training data, the theory would be called into question.</li>
                <li>If LLMs can consistently solve puzzles that require multi-step logical inference not present in the training data, this would contradict the theory.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>Some LLMs can solve puzzles with rare or unseen patterns, suggesting additional mechanisms beyond pattern completion. </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> somewhat-related-to-existing</p>
            <p><strong>Explanation:</strong> While related to known LLM abilities, the explicit application to spatial puzzles is new.</p>
            <p><strong>References:</strong> <ul>
    <li>Radford et al. (2019) Language Models are Unsupervised Multitask Learners [Pattern completion in text]</li>
    <li>Zhou et al. (2022) Can Language Models Solve Sudoku? [LLMs' spatial puzzle performance]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Spatial Reasoning via Pattern Completion in Language Models",
    "theory_description": "This theory proposes that large language models (LLMs) solve spatial puzzle games, such as Sudoku, primarily by leveraging their ability to perform pattern completion. LLMs match partial spatial configurations to learned templates or statistical regularities from their training data, and use these to predict valid continuations or solutions, rather than engaging in explicit symbolic or logical reasoning.",
    "theory_statements": [
        {
            "law": {
                "law_name": "Template Matching for Spatial Patterns",
                "if": [
                    {
                        "subject": "language model",
                        "relation": "has_been_exposed_to",
                        "object": "many_examples_of_spatial_puzzles"
                    },
                    {
                        "subject": "input_puzzle",
                        "relation": "is_partial_instance_of",
                        "object": "learned_pattern_template"
                    }
                ],
                "then": [
                    {
                        "subject": "model_output",
                        "relation": "completes",
                        "object": "pattern_in_accordance_with_template"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "LLMs can fill in missing entries in Sudoku grids by matching to previously seen patterns.",
                        "uuids": []
                    },
                    {
                        "text": "Performance drops on puzzles with novel or rare configurations, suggesting reliance on pattern familiarity.",
                        "uuids": []
                    },
                    {
                        "text": "LLMs trained on large datasets of spatial puzzles show higher accuracy on familiar configurations.",
                        "uuids": []
                    },
                    {
                        "text": "When presented with partial spatial information, LLMs tend to generate completions that are statistically common in their training data.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Pattern completion is a known ability of LLMs in linguistic domains.",
                    "what_is_novel": "The law extends this to spatial domains, positing that LLMs use pattern matching for spatial reasoning.",
                    "classification_explanation": "This is a novel application of pattern completion to spatial puzzle solving, extending a linguistic mechanism to spatial cognition.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Radford et al. (2019) Language Models are Unsupervised Multitask Learners [Pattern completion in text]",
                        "Zhou et al. (2022) Can Language Models Solve Sudoku? [LLMs' spatial puzzle performance]"
                    ]
                }
            }
        },
        {
            "law": {
                "law_name": "Statistical Regularity Exploitation",
                "if": [
                    {
                        "subject": "language model",
                        "relation": "has_learned",
                        "object": "statistical_distribution_of_valid_puzzle_states"
                    },
                    {
                        "subject": "current_puzzle_state",
                        "relation": "is_incomplete",
                        "object": "True"
                    }
                ],
                "then": [
                    {
                        "subject": "model_predictions",
                        "relation": "are_biased_toward",
                        "object": "statistically_likely_completions"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "LLMs tend to produce more common or likely Sudoku solutions, and struggle with rare or edge-case puzzles.",
                        "uuids": []
                    },
                    {
                        "text": "Performance correlates with the frequency of puzzle patterns in the training data.",
                        "uuids": []
                    },
                    {
                        "text": "LLMs' errors often reflect the statistical distribution of training data rather than logical impossibility.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "LLMs are known to exploit statistical regularities in language.",
                    "what_is_novel": "The law claims this extends to spatial and logical domains, not just linguistic ones.",
                    "classification_explanation": "This is a novel extension of statistical regularity exploitation to spatial puzzle solving.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Radford et al. (2019) Language Models are Unsupervised Multitask Learners [Statistical regularity in text]",
                        "Zhou et al. (2022) Can Language Models Solve Sudoku? [LLMs' spatial puzzle performance]"
                    ]
                }
            }
        }
    ],
    "new_predictions_likely": [
        "LLMs will perform better on spatial puzzles that closely resemble common patterns in their training data.",
        "Introducing novel or rare spatial configurations will reduce LLM performance, even if the underlying rules are unchanged.",
        "LLMs will make errors that reflect the statistical distribution of their training data, such as overfitting to common patterns."
    ],
    "new_predictions_unknown": [
        "If LLMs are trained on synthetic spatial puzzles with adversarially distributed patterns, they may develop new pattern completion strategies or fail to generalize.",
        "If LLMs are exposed to puzzles with intentionally misleading partial patterns, their completions may reveal biases in their learned statistical regularities.",
        "LLMs may develop emergent strategies for spatial reasoning if exposed to sufficiently diverse and challenging spatial puzzles."
    ],
    "negative_experiments": [
        "If LLMs can solve spatial puzzles with entirely novel configurations as well as familiar ones, this would challenge the theory.",
        "If LLMs' performance does not correlate with the frequency of patterns in the training data, the theory would be called into question.",
        "If LLMs can consistently solve puzzles that require multi-step logical inference not present in the training data, this would contradict the theory."
    ],
    "unaccounted_for": [
        {
            "text": "Some LLMs can solve puzzles with rare or unseen patterns, suggesting additional mechanisms beyond pattern completion.",
            "uuids": []
        }
    ],
    "conflicting_evidence": [
        {
            "text": "LLMs sometimes solve puzzles requiring multi-step logical inference, not just pattern matching.",
            "uuids": []
        }
    ],
    "special_cases": [
        "Puzzles with uniform or random patterns may not be solvable by pattern completion.",
        "Explicit symbolic reasoning tasks may not benefit from this mechanism.",
        "LLMs with explicit reasoning modules may not follow this pattern."
    ],
    "existing_theory": {
        "what_already_exists": "Pattern completion and statistical regularity exploitation are established in LLMs for language.",
        "what_is_novel": "The theory extends these mechanisms to spatial puzzle solving, formalizing their role in non-linguistic domains.",
        "classification_explanation": "While related to known LLM abilities, the explicit application to spatial puzzles is new.",
        "likely_classification": "somewhat-related-to-existing",
        "references": [
            "Radford et al. (2019) Language Models are Unsupervised Multitask Learners [Pattern completion in text]",
            "Zhou et al. (2022) Can Language Models Solve Sudoku? [LLMs' spatial puzzle performance]"
        ]
    },
    "reflected_from_theory_index": 1,
    "type": "general",
    "version": "built-theory-from-results-single-theory-reflection2-nov14-2025-LLM-BASELINE-no-evidence-without-matched-control-theory-name",
    "theory_query": "Build a theory of how language models solve puzzle games involving spatial knowledge, like Sudoku.",
    "original_theory_id": "theory-597",
    "original_theory_name": "Emergent Algorithmic Reasoning via Structured Inductive Biases in Language Models",
    "provide_matched_control_thery_name": false,
    "matched_control_theory_name": null,
    "model_str": "openai/gpt-4.1-2025-04-14"
}</code></pre>
        </div>
    </div>
</body>
</html>