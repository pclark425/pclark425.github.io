<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Order-Invariance Robustness Law for Graph Linearization in LLMs - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-615</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-615</p>
                <p><strong>Name:</strong> Order-Invariance Robustness Law for Graph Linearization in LLMs</p>
                <p><strong>Type:</strong> specific</p>
                <p><strong>Theory Query:</strong> Build a theory of ideal representations for converting graphs into text for language model training, based on the following results.</p>
                <p><strong>Description:</strong> This theory asserts that exposing LLMs to multiple, adversarially permuted linearizations of the same graph during training (e.g., via adversarial linearization, SMILES enumeration, or randomization) is necessary to achieve order-invariant graph-to-text representations. The theory claims that such training reduces overfitting to arbitrary token orderings, increases robustness to input variations, and enables better generalization to unseen graph orderings, especially in tasks where the graph structure is more important than the specific serialization.</p>
                <p><strong>Knowledge Cutoff Year:</strong> 2024</p>
                <p><strong>Knowledge Cutoff Month:</strong> 6</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <h3>Statement 0: Adversarial Linearization Robustness Law (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; graph-to-text model &#8594; is trained with &#8594; multiple, adversarially permuted linearizations of each graph</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; model &#8594; achieves &#8594; higher robustness and less overfitting to canonical orderings, with comparable or improved BLEU and structural accuracy</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Adversarial linearization training improves robustness with only minor reduction in canonical performance; final BLEU is comparable to canonical training, but models are less sensitive to input order. <a href="../results/extraction-result-5246.html#e5246.4" class="evidence-link">[e5246.4]</a> </li>
    <li>SMILES enumeration increases invariance and improves molecular property prediction by reducing bias from a single canonical SMILES. <a href="../results/extraction-result-5369.html#e5369.1" class="evidence-link">[e5369.1]</a> </li>
    <li>Partition-and-TSP approach for AMR linearization (Song et al., 2016) shows that different linearizations can affect downstream generation quality, motivating the need for order-invariant representations. <a href="../results/extraction-result-5362.html#e5362.2" class="evidence-link">[e5362.2]</a> </li>
    <li>BFS and DFS linearization strategies are used in various works to test the effect of order; models trained on a single order can overfit to that order, while exposure to multiple orders increases generalization. <a href="../results/extraction-result-5251.html#e5251.5" class="evidence-link">[e5251.5]</a> <a href="../results/extraction-result-5355.html#e5355.0" class="evidence-link">[e5355.0]</a> </li>
    <li>Linearization baseline models (e.g., for AMR and KG-to-text) are sensitive to the order of serialization, and adversarial or randomized orderings during training reduce this sensitivity. <a href="../results/extraction-result-5390.html#e5390.2" class="evidence-link">[e5390.2]</a> <a href="../results/extraction-result-5239.html#e5239.2" class="evidence-link">[e5239.2]</a> </li>
    <li>In molecular graph modeling, SMILES enumeration (randomized linearizations) is used as data augmentation to reduce overfitting to a single canonical order and improve downstream property prediction. <a href="../results/extraction-result-5369.html#e5369.1" class="evidence-link">[e5369.1]</a> </li>
    <li>In the context of graph-to-text generation, adversarial linearization exposure (randomized/canonical/reconfigured) increases the number of epochs needed to reach a given BLEU, but final BLEU is comparable and robustness to input order is improved. <a href="../results/extraction-result-5246.html#e5246.4" class="evidence-link">[e5246.4]</a> </li>
    <li>In the context of graph-to-sequence learning, models trained on a single linearization can overfit to annotator-induced order, while adversarial linearization reduces this overfitting. <a href="../results/extraction-result-5246.html#e5246.4" class="evidence-link">[e5246.4]</a> </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: green; font-weight: bold;">new</span></p>
            <p><strong>Explanation:</strong> While order-invariance is established in GNNs, its operationalization via adversarial linearization in LLM-based graph-to-text conversion is a new, empirically supported theory, especially as applied to LLMs and graph-to-text tasks.</p>            <p><strong>What Already Exists:</strong> Order-invariance is a known goal in GNNs and some graph learning, and data augmentation via randomization is used in some domains (e.g., SMILES enumeration in chemistry).</p>            <p><strong>What is Novel:</strong> The explicit use of adversarial linearization or enumeration as a necessary training strategy for order-invariant LLM-based graph-to-text representations, and the empirical demonstration that this increases robustness and generalization in LLMs, is novel.</p>
            <p><strong>References:</strong> <ul>
    <li>Ribeiro et al. (2020) Promoting Graph Awareness in Linearized Graph-to-Text Generation [adversarial linearization]</li>
    <li>Bjerrum (2017) SMILES enumeration as data augmentation for neural network modeling of molecules [SMILES enumeration]</li>
    <li>Song et al. (2016) AMR-to-text generation as a traveling salesman problem [linearization order effects]</li>
    <li>Konstas et al. (2017) Neural AMR: Sequence-to-sequence models for parsing and generation [linearization order]</li>
    <li>Guo et al. (2019) Densely Connected Graph Convolutional Networks for Graph-to-Sequence Learning [linearization vs. graph encoders]</li>
</ul>
            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>Training LLMs on multiple random or adversarial linearizations of graphs will reduce performance drops when evaluated on non-canonical or unseen orderings.</li>
                <li>Order-invariant training will improve generalization to new graph types or domains where serialization order is not standardized.</li>
                <li>Models trained with adversarial linearization will show less variance in BLEU or accuracy when evaluated on different input orderings compared to models trained on a single canonical order.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>Order-invariant training will enable LLMs to generalize to entirely new graph serialization schemes (e.g., from bracketed to XML or DOT) without additional fine-tuning.</li>
                <li>Combining adversarial linearization with structure-aware attention or graph encoders will yield synergistic gains in robustness and generalization, but the magnitude is unknown.</li>
                <li>Order-invariant training may improve LLMs' ability to handle graphs with complex reentrancies or cycles, but the extent of this effect is not yet established.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>If models trained with adversarial linearization do not outperform or match canonical-order-trained models on non-canonical inputs, the theory would be challenged.</li>
                <li>If adversarial linearization leads to significant drops in BLEU or structural accuracy, the law would be called into question.</li>
                <li>If models trained with adversarial linearization still show strong order sensitivity or overfitting to specific serializations, the theory would be weakened.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>Some structure-aware encodings (e.g., motif or Levi graph, or graph encoders that do not rely on linearization) may be less sensitive to order, making adversarial linearization less critical. <a href="../results/extraction-result-5357.html#e5357.1" class="evidence-link">[e5357.1]</a> <a href="../results/extraction-result-5390.html#e5390.1" class="evidence-link">[e5390.1]</a> <a href="../results/extraction-result-5374.html#e5374.4" class="evidence-link">[e5374.4]</a> <a href="../results/extraction-result-5371.html#e5371.1" class="evidence-link">[e5371.1]</a> </li>
    <li>Certain graph-to-sequence models that use explicit graph encoders (e.g., GNNs, graph transformers) may already be order-invariant by design, reducing the need for adversarial linearization. <a href="../results/extraction-result-5374.html#e5374.4" class="evidence-link">[e5374.4]</a> <a href="../results/extraction-result-5371.html#e5371.1" class="evidence-link">[e5371.1]</a> <a href="../results/extraction-result-5387.html#e5387.7" class="evidence-link">[e5387.7]</a> </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> new</p>
            <p><strong>Explanation:</strong> This is a new, empirically supported theory specific to LLM-based graph-to-text conversion, building on but distinct from prior work in GNNs and data augmentation.</p>
            <p><strong>References:</strong> <ul>
    <li>Ribeiro et al. (2020) Promoting Graph Awareness in Linearized Graph-to-Text Generation [adversarial linearization]</li>
    <li>Bjerrum (2017) SMILES enumeration as data augmentation for neural network modeling of molecules [SMILES enumeration]</li>
    <li>Song et al. (2016) AMR-to-text generation as a traveling salesman problem [linearization order effects]</li>
    <li>Konstas et al. (2017) Neural AMR: Sequence-to-sequence models for parsing and generation [linearization order]</li>
    <li>Guo et al. (2019) Densely Connected Graph Convolutional Networks for Graph-to-Sequence Learning [linearization vs. graph encoders]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Order-Invariance Robustness Law for Graph Linearization in LLMs",
    "theory_description": "This theory asserts that exposing LLMs to multiple, adversarially permuted linearizations of the same graph during training (e.g., via adversarial linearization, SMILES enumeration, or randomization) is necessary to achieve order-invariant graph-to-text representations. The theory claims that such training reduces overfitting to arbitrary token orderings, increases robustness to input variations, and enables better generalization to unseen graph orderings, especially in tasks where the graph structure is more important than the specific serialization.",
    "theory_statements": [
        {
            "law": {
                "law_name": "Adversarial Linearization Robustness Law",
                "if": [
                    {
                        "subject": "graph-to-text model",
                        "relation": "is trained with",
                        "object": "multiple, adversarially permuted linearizations of each graph"
                    }
                ],
                "then": [
                    {
                        "subject": "model",
                        "relation": "achieves",
                        "object": "higher robustness and less overfitting to canonical orderings, with comparable or improved BLEU and structural accuracy"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Adversarial linearization training improves robustness with only minor reduction in canonical performance; final BLEU is comparable to canonical training, but models are less sensitive to input order.",
                        "uuids": [
                            "e5246.4"
                        ]
                    },
                    {
                        "text": "SMILES enumeration increases invariance and improves molecular property prediction by reducing bias from a single canonical SMILES.",
                        "uuids": [
                            "e5369.1"
                        ]
                    },
                    {
                        "text": "Partition-and-TSP approach for AMR linearization (Song et al., 2016) shows that different linearizations can affect downstream generation quality, motivating the need for order-invariant representations.",
                        "uuids": [
                            "e5362.2"
                        ]
                    },
                    {
                        "text": "BFS and DFS linearization strategies are used in various works to test the effect of order; models trained on a single order can overfit to that order, while exposure to multiple orders increases generalization.",
                        "uuids": [
                            "e5251.5",
                            "e5355.0"
                        ]
                    },
                    {
                        "text": "Linearization baseline models (e.g., for AMR and KG-to-text) are sensitive to the order of serialization, and adversarial or randomized orderings during training reduce this sensitivity.",
                        "uuids": [
                            "e5390.2",
                            "e5239.2"
                        ]
                    },
                    {
                        "text": "In molecular graph modeling, SMILES enumeration (randomized linearizations) is used as data augmentation to reduce overfitting to a single canonical order and improve downstream property prediction.",
                        "uuids": [
                            "e5369.1"
                        ]
                    },
                    {
                        "text": "In the context of graph-to-text generation, adversarial linearization exposure (randomized/canonical/reconfigured) increases the number of epochs needed to reach a given BLEU, but final BLEU is comparable and robustness to input order is improved.",
                        "uuids": [
                            "e5246.4"
                        ]
                    },
                    {
                        "text": "In the context of graph-to-sequence learning, models trained on a single linearization can overfit to annotator-induced order, while adversarial linearization reduces this overfitting.",
                        "uuids": [
                            "e5246.4"
                        ]
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Order-invariance is a known goal in GNNs and some graph learning, and data augmentation via randomization is used in some domains (e.g., SMILES enumeration in chemistry).",
                    "what_is_novel": "The explicit use of adversarial linearization or enumeration as a necessary training strategy for order-invariant LLM-based graph-to-text representations, and the empirical demonstration that this increases robustness and generalization in LLMs, is novel.",
                    "classification_explanation": "While order-invariance is established in GNNs, its operationalization via adversarial linearization in LLM-based graph-to-text conversion is a new, empirically supported theory, especially as applied to LLMs and graph-to-text tasks.",
                    "likely_classification": "new",
                    "references": [
                        "Ribeiro et al. (2020) Promoting Graph Awareness in Linearized Graph-to-Text Generation [adversarial linearization]",
                        "Bjerrum (2017) SMILES enumeration as data augmentation for neural network modeling of molecules [SMILES enumeration]",
                        "Song et al. (2016) AMR-to-text generation as a traveling salesman problem [linearization order effects]",
                        "Konstas et al. (2017) Neural AMR: Sequence-to-sequence models for parsing and generation [linearization order]",
                        "Guo et al. (2019) Densely Connected Graph Convolutional Networks for Graph-to-Sequence Learning [linearization vs. graph encoders]"
                    ]
                }
            }
        }
    ],
    "new_predictions_likely": [
        "Training LLMs on multiple random or adversarial linearizations of graphs will reduce performance drops when evaluated on non-canonical or unseen orderings.",
        "Order-invariant training will improve generalization to new graph types or domains where serialization order is not standardized.",
        "Models trained with adversarial linearization will show less variance in BLEU or accuracy when evaluated on different input orderings compared to models trained on a single canonical order."
    ],
    "new_predictions_unknown": [
        "Order-invariant training will enable LLMs to generalize to entirely new graph serialization schemes (e.g., from bracketed to XML or DOT) without additional fine-tuning.",
        "Combining adversarial linearization with structure-aware attention or graph encoders will yield synergistic gains in robustness and generalization, but the magnitude is unknown.",
        "Order-invariant training may improve LLMs' ability to handle graphs with complex reentrancies or cycles, but the extent of this effect is not yet established."
    ],
    "negative_experiments": [
        "If models trained with adversarial linearization do not outperform or match canonical-order-trained models on non-canonical inputs, the theory would be challenged.",
        "If adversarial linearization leads to significant drops in BLEU or structural accuracy, the law would be called into question.",
        "If models trained with adversarial linearization still show strong order sensitivity or overfitting to specific serializations, the theory would be weakened."
    ],
    "unaccounted_for": [
        {
            "text": "Some structure-aware encodings (e.g., motif or Levi graph, or graph encoders that do not rely on linearization) may be less sensitive to order, making adversarial linearization less critical.",
            "uuids": [
                "e5357.1",
                "e5390.1",
                "e5374.4",
                "e5371.1"
            ]
        },
        {
            "text": "Certain graph-to-sequence models that use explicit graph encoders (e.g., GNNs, graph transformers) may already be order-invariant by design, reducing the need for adversarial linearization.",
            "uuids": [
                "e5374.4",
                "e5371.1",
                "e5387.7"
            ]
        }
    ],
    "conflicting_evidence": [
        {
            "text": "In some cases, models still perform best on canonical orderings even after adversarial training, indicating incomplete order-invariance.",
            "uuids": [
                "e5246.4"
            ]
        },
        {
            "text": "For some tasks, especially those where serialization order encodes semantic information (e.g., temporal graphs), adversarial linearization may harm performance.",
            "uuids": [
                "e5373.1"
            ]
        }
    ],
    "special_cases": [
        "For very small graphs or graphs with unique canonical orderings, adversarial linearization may provide little benefit.",
        "In domains where serialization order encodes semantic information (e.g., temporal graphs, event orderings), adversarial linearization may harm performance.",
        "For structure-aware encodings or models with explicit graph inductive bias, adversarial linearization may be unnecessary or redundant."
    ],
    "existing_theory": {
        "what_already_exists": "Order-invariance is a known goal in graph learning, and data augmentation via randomization is used in some domains (e.g., SMILES enumeration in chemistry).",
        "what_is_novel": "The explicit operationalization of order-invariance via adversarial linearization or enumeration in LLM-based graph-to-text training, and the demonstration that this increases robustness and generalization in LLMs, is novel.",
        "classification_explanation": "This is a new, empirically supported theory specific to LLM-based graph-to-text conversion, building on but distinct from prior work in GNNs and data augmentation.",
        "likely_classification": "new",
        "references": [
            "Ribeiro et al. (2020) Promoting Graph Awareness in Linearized Graph-to-Text Generation [adversarial linearization]",
            "Bjerrum (2017) SMILES enumeration as data augmentation for neural network modeling of molecules [SMILES enumeration]",
            "Song et al. (2016) AMR-to-text generation as a traveling salesman problem [linearization order effects]",
            "Konstas et al. (2017) Neural AMR: Sequence-to-sequence models for parsing and generation [linearization order]",
            "Guo et al. (2019) Densely Connected Graph Convolutional Networks for Graph-to-Sequence Learning [linearization vs. graph encoders]"
        ]
    },
    "theory_type_general_specific": "specific",
    "reflected_from_theory_index": 3,
    "version": "built-theory-from-results-single-theory-reflection2-nov14-2025",
    "type": "specific"
}</code></pre>
        </div>
    </div>
</body>
</html>