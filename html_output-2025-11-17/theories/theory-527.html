<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Iterative LLM-Driven Symbolic Regression with Complexity Penalization - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-527</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-527</p>
                <p><strong>Name:</strong> Iterative LLM-Driven Symbolic Regression with Complexity Penalization</p>
                <p><strong>Type:</strong> specific</p>
                <p><strong>Theory Query:</strong> Build a theory of how large language models (LLMs) can be used to distill quantitative laws from large numbers of scholarly input papers, based on the following results.</p>
                <p><strong>Description:</strong> An iterative pipeline using large language models (LLMs) to generate symbolic function skeletons from numeric data, combined with external numerical optimization for coefficients and explicit complexity penalization, leads to the discovery of accurate, low-complexity, and generalizable equations. The LLM's in-context learning and meta-prompting enable rapid convergence to human-like solutions, and the explicit complexity penalty ensures parsimony and interpretability. This theory is primarily instantiated in the ICSR framework, but is supported by related evidence from OPRO and other LLM-SR approaches.</p>
                <p><strong>Knowledge Cutoff Year:</strong> 2024</p>
                <p><strong>Knowledge Cutoff Month:</strong> 6</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <h3>Statement 0: Optimization-by-Prompting with Complexity Penalty Law (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; LLM &#8594; is_prompted_with &#8594; numeric_data_points_and_prior_candidate_fitness<span style="color: #888888;">, and</span></div>
        <div>&#8226; pipeline &#8594; applies &#8594; complexity_penalized_fitness_function</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; pipeline &#8594; discovers &#8594; low-complexity_and_accurate_symbolic_equations</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>ICSR demonstrates that iterative meta-prompting with complexity-penalized fitness leads to simpler and more accurate equations than classical SR baselines (gplearn, DSR, uDSR, NeSymReS, E2E, TPSR), with lower-complexity expressions and improved out-of-distribution generalization. <a href="../results/extraction-result-3647.html#e3647.0" class="evidence-link">[e3647.0]</a> </li>
    <li>ICSR's ablation studies show that removing the complexity penalty leads to more complex, less interpretable solutions. <a href="../results/extraction-result-3647.html#e3647.0" class="evidence-link">[e3647.0]</a> </li>
    <li>ICSR outperforms or matches state-of-the-art symbolic regression baselines on standard benchmarks (Nguyen, Constant, R, Keijzer) while producing lower-complexity expressions. <a href="../results/extraction-result-3647.html#e3647.0" class="evidence-link">[e3647.0]</a> </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p class="empty-note">No existing law comparison provided.</p>
            <h3>Statement 1: LLM In-Context Learning Accelerates Convergence Law (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; LLM &#8594; receives &#8594; prior_candidate_solutions_and_scores_in_prompt</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; LLM &#8594; proposes &#8594; improved_candidates_more_rapidly_than_random_search</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>ICSR and OPRO show that LLMs can leverage in-context examples to accelerate optimization and symbolic regression, with ICSR's iterative meta-prompting leading to rapid improvement in candidate quality. <a href="../results/extraction-result-3647.html#e3647.0" class="evidence-link">[e3647.0]</a> <a href="../results/extraction-result-3647.html#e3647.2" class="evidence-link">[e3647.2]</a> </li>
    <li>OPRO demonstrates that meta-prompting LLMs with previous attempts and their scores enables iterative improvement on classical optimization tasks, motivating its use in symbolic regression. <a href="../results/extraction-result-3647.html#e3647.2" class="evidence-link">[e3647.2]</a> </li>
    <li>ICSR's ablation studies show that removing the iterative refinement loop or in-context prior candidates degrades performance and slows convergence. <a href="../results/extraction-result-3647.html#e3647.0" class="evidence-link">[e3647.0]</a> </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p class="empty-note">No existing law comparison provided.</p>
            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>Applying ICSR to a new synthetic benchmark will yield lower-complexity and more accurate equations than GP or DSR.</li>
                <li>Increasing the number of in-context prior candidates in the prompt (up to the context window limit) will further accelerate convergence and improve solution quality.</li>
                <li>ICSR will outperform random LLM generation (no data in prompt) and non-iterative LLM baselines on symbolic regression tasks.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>ICSR applied to real-world, noisy experimental data (e.g., biological growth curves, physical measurements) will discover interpretable laws that generalize to new experimental conditions.</li>
                <li>Combining ICSR with vision-language models (ICSR-V) will enable symbolic law discovery from plots or images, not just numeric data, provided future VLMs are sufficiently capable.</li>
                <li>ICSR with larger LLMs or improved prompt engineering will scale to higher-dimensional symbolic regression tasks (d > 5) with competitive performance.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>If ICSR fails to outperform classical SR on a new benchmark, or produces more complex equations, the theory would be challenged.</li>
                <li>If increasing the number of in-context examples in the prompt does not improve convergence or solution quality, the in-context learning law would be questioned.</li>
                <li>If ICSR fails to generalize to out-of-distribution test ranges (e.g., extrapolation), the claim of improved generalization would be weakened.</li>
                <li>If ablation of the complexity penalty does not increase solution complexity, the necessity of explicit complexity penalization would be questioned.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>ICSR-V (vision-language extension) did not improve performance with current VLMs, suggesting limitations in multi-modal symbolic regression. <a href="../results/extraction-result-3647.html#e3647.0" class="evidence-link">[e3647.0]</a> </li>
    <li>Some LLM-based SR methods (e.g., Llm-SR, Shojaee et al. 2024) leverage natural-language variable descriptions to improve equation discovery, which is not directly addressed by ICSR's numeric-only prompts. <a href="../results/extraction-result-3647.html#e3647.1" class="evidence-link">[e3647.1]</a> </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> closely-related-to-existing</p>
            <p><strong>Explanation:</strong> No explanation provided.</p>
            <p><strong>References:</strong> <ul>
    <li>Biggio et al. (2024) In-Context Symbolic Regression: Leveraging Large Language Models for Function Discovery [ICSR, main instantiation of this theory]</li>
    <li>OPRO (2023) Large language models as optimizers [meta-prompting for optimization, but not specialized to symbolic regression]</li>
    <li>Shojaee et al. (2024) Scientific equation discovery via programming with large language models [LLM-SR, similar iterative refinement but different implementation]</li>
    <li>SymbolicGPT (Valipour et al., 2021) Symbolicgpt: A generative transformer model for symbolic regression [uses LLMs for symbolic regression, but with different architecture and training]</li>
    <li>DSR (Petersen et al., 2021) Deep symbolic regression: Recovering mathematical expressions from data via risk-seeking policy gradients [non-LLM deep learning approach, but similar symbolic regression goal]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Iterative LLM-Driven Symbolic Regression with Complexity Penalization",
    "theory_description": "An iterative pipeline using large language models (LLMs) to generate symbolic function skeletons from numeric data, combined with external numerical optimization for coefficients and explicit complexity penalization, leads to the discovery of accurate, low-complexity, and generalizable equations. The LLM's in-context learning and meta-prompting enable rapid convergence to human-like solutions, and the explicit complexity penalty ensures parsimony and interpretability. This theory is primarily instantiated in the ICSR framework, but is supported by related evidence from OPRO and other LLM-SR approaches.",
    "theory_statements": [
        {
            "law": {
                "law_name": "Optimization-by-Prompting with Complexity Penalty Law",
                "if": [
                    {
                        "subject": "LLM",
                        "relation": "is_prompted_with",
                        "object": "numeric_data_points_and_prior_candidate_fitness"
                    },
                    {
                        "subject": "pipeline",
                        "relation": "applies",
                        "object": "complexity_penalized_fitness_function"
                    }
                ],
                "then": [
                    {
                        "subject": "pipeline",
                        "relation": "discovers",
                        "object": "low-complexity_and_accurate_symbolic_equations"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "ICSR demonstrates that iterative meta-prompting with complexity-penalized fitness leads to simpler and more accurate equations than classical SR baselines (gplearn, DSR, uDSR, NeSymReS, E2E, TPSR), with lower-complexity expressions and improved out-of-distribution generalization.",
                        "uuids": [
                            "e3647.0"
                        ]
                    },
                    {
                        "text": "ICSR's ablation studies show that removing the complexity penalty leads to more complex, less interpretable solutions.",
                        "uuids": [
                            "e3647.0"
                        ]
                    },
                    {
                        "text": "ICSR outperforms or matches state-of-the-art symbolic regression baselines on standard benchmarks (Nguyen, Constant, R, Keijzer) while producing lower-complexity expressions.",
                        "uuids": [
                            "e3647.0"
                        ]
                    }
                ],
                "qual_or_quant": "qualitative"
            }
        },
        {
            "law": {
                "law_name": "LLM In-Context Learning Accelerates Convergence Law",
                "if": [
                    {
                        "subject": "LLM",
                        "relation": "receives",
                        "object": "prior_candidate_solutions_and_scores_in_prompt"
                    }
                ],
                "then": [
                    {
                        "subject": "LLM",
                        "relation": "proposes",
                        "object": "improved_candidates_more_rapidly_than_random_search"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "ICSR and OPRO show that LLMs can leverage in-context examples to accelerate optimization and symbolic regression, with ICSR's iterative meta-prompting leading to rapid improvement in candidate quality.",
                        "uuids": [
                            "e3647.0",
                            "e3647.2"
                        ]
                    },
                    {
                        "text": "OPRO demonstrates that meta-prompting LLMs with previous attempts and their scores enables iterative improvement on classical optimization tasks, motivating its use in symbolic regression.",
                        "uuids": [
                            "e3647.2"
                        ]
                    },
                    {
                        "text": "ICSR's ablation studies show that removing the iterative refinement loop or in-context prior candidates degrades performance and slows convergence.",
                        "uuids": [
                            "e3647.0"
                        ]
                    }
                ],
                "qual_or_quant": "qualitative"
            }
        }
    ],
    "new_predictions_likely": [
        "Applying ICSR to a new synthetic benchmark will yield lower-complexity and more accurate equations than GP or DSR.",
        "Increasing the number of in-context prior candidates in the prompt (up to the context window limit) will further accelerate convergence and improve solution quality.",
        "ICSR will outperform random LLM generation (no data in prompt) and non-iterative LLM baselines on symbolic regression tasks."
    ],
    "new_predictions_unknown": [
        "ICSR applied to real-world, noisy experimental data (e.g., biological growth curves, physical measurements) will discover interpretable laws that generalize to new experimental conditions.",
        "Combining ICSR with vision-language models (ICSR-V) will enable symbolic law discovery from plots or images, not just numeric data, provided future VLMs are sufficiently capable.",
        "ICSR with larger LLMs or improved prompt engineering will scale to higher-dimensional symbolic regression tasks (d &gt; 5) with competitive performance."
    ],
    "negative_experiments": [
        "If ICSR fails to outperform classical SR on a new benchmark, or produces more complex equations, the theory would be challenged.",
        "If increasing the number of in-context examples in the prompt does not improve convergence or solution quality, the in-context learning law would be questioned.",
        "If ICSR fails to generalize to out-of-distribution test ranges (e.g., extrapolation), the claim of improved generalization would be weakened.",
        "If ablation of the complexity penalty does not increase solution complexity, the necessity of explicit complexity penalization would be questioned."
    ],
    "unaccounted_for": [
        {
            "text": "ICSR-V (vision-language extension) did not improve performance with current VLMs, suggesting limitations in multi-modal symbolic regression.",
            "uuids": [
                "e3647.0"
            ]
        },
        {
            "text": "Some LLM-based SR methods (e.g., Llm-SR, Shojaee et al. 2024) leverage natural-language variable descriptions to improve equation discovery, which is not directly addressed by ICSR's numeric-only prompts.",
            "uuids": [
                "e3647.1"
            ]
        }
    ],
    "conflicting_evidence": [
        {
            "text": "Some failures on harder benchmarks (e.g., parts of Keijzer and R) where sparse sampling or low-density regions lead to incorrect extrapolation, indicating that ICSR's generalization is not universal.",
            "uuids": [
                "e3647.0"
            ]
        },
        {
            "text": "ICSR's scalability to higher-dimensional inputs is limited by prompt context size and LLM capacity, which may prevent success on very high-dimensional SR tasks.",
            "uuids": [
                "e3647.0"
            ]
        }
    ],
    "special_cases": [
        "Scalability to high-dimensional inputs is limited by prompt context size and LLM ability to exploit structure.",
        "Performance depends on LLM pretraining and may degrade if the LLM is not exposed to relevant symbolic forms.",
        "ICSR's success is contingent on the LLM's ability to parse and generate valid symbolic expressions; poor LLMs or insufficient pretraining may yield invalid or low-quality outputs.",
        "ICSR's complexity penalty must be tuned appropriately; excessive penalization may prevent recovery of correct but complex ground-truth equations."
    ],
    "existing_theory": {
        "likely_classification": "closely-related-to-existing",
        "references": [
            "Biggio et al. (2024) In-Context Symbolic Regression: Leveraging Large Language Models for Function Discovery [ICSR, main instantiation of this theory]",
            "OPRO (2023) Large language models as optimizers [meta-prompting for optimization, but not specialized to symbolic regression]",
            "Shojaee et al. (2024) Scientific equation discovery via programming with large language models [LLM-SR, similar iterative refinement but different implementation]",
            "SymbolicGPT (Valipour et al., 2021) Symbolicgpt: A generative transformer model for symbolic regression [uses LLMs for symbolic regression, but with different architecture and training]",
            "DSR (Petersen et al., 2021) Deep symbolic regression: Recovering mathematical expressions from data via risk-seeking policy gradients [non-LLM deep learning approach, but similar symbolic regression goal]"
        ]
    },
    "reflected_from_theory_index": 2,
    "version": "built-theory-from-results-single-theory-reflection2-nov13-2025",
    "type": "specific"
}</code></pre>
        </div>
    </div>
</body>
</html>