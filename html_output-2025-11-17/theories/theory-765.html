<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Hierarchical Representation and Compositionality in LLM Arithmetic - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-765</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-765</p>
                <p><strong>Name:</strong> Hierarchical Representation and Compositionality in LLM Arithmetic</p>
                <p><strong>Type:</strong> general</p>
                <p><strong>Theory Query:</strong> Build a theory of how language models perform arithmetic.</p>
                <p><strong>Description:</strong> This theory proposes that LLMs develop hierarchical, compositional representations of numbers and arithmetic operations, enabling them to decompose complex arithmetic tasks into simpler subproblems. These representations are learned through exposure to diverse arithmetic data and are activated via chain-of-thought prompting, allowing the model to recursively apply learned subroutines (e.g., single-digit addition) to solve multi-digit or multi-step problems. The theory further posits that the depth and flexibility of these hierarchical representations are a function of model scale and training diversity.</p>
                <p><strong>Knowledge Cutoff Year:</strong> -1</p>
                <p><strong>Knowledge Cutoff Month:</strong> -1</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <h3>Statement 0: Hierarchical Decomposition of Arithmetic Tasks (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; LLM &#8594; has_learned &#8594; compositional_number_representations<span style="color: #888888;">, and</span></div>
        <div>&#8226; LLM &#8594; receives_prompt &#8594; multi-digit_arithmetic_problem</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; LLM &#8594; decomposes &#8594; problem_into_subproblems<span style="color: #888888;">, and</span></div>
        <div>&#8226; LLM &#8594; solves &#8594; subproblems_recursively</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>LLMs can perform multi-digit addition and multiplication by generating stepwise solutions that mirror human decomposition (e.g., column-wise addition). </li>
    <li>Analysis of LLM outputs shows recursive application of single-digit operations in multi-digit arithmetic. </li>
    <li>LLMs can generalize to longer arithmetic problems than seen in training, indicating compositionality. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> The law extends compositionality to a mechanistic, recursive process for arithmetic in LLMs.</p>            <p><strong>What Already Exists:</strong> Compositionality and hierarchical representations are known in neural networks, and LLMs show stepwise arithmetic reasoning.</p>            <p><strong>What is Novel:</strong> This law formalizes the recursive, hierarchical decomposition as a core mechanism for LLM arithmetic.</p>
            <p><strong>References:</strong> <ul>
    <li>Lake & Baroni (2018) Generalization without Systematicity: On the Compositional Skills of Sequence-to-Sequence Recurrent Networks [Compositionality in neural nets]</li>
    <li>Wei et al. (2022) Chain-of-Thought Prompting Elicits Reasoning in Large Language Models [Stepwise reasoning]</li>
</ul>
            <h3>Statement 1: Scale-Dependent Depth of Hierarchical Reasoning (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; LLM &#8594; has_parameter_count &#8594; N<span style="color: #888888;">, and</span></div>
        <div>&#8226; N &#8594; greater_than &#8594; hierarchical_threshold</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; LLM &#8594; can_perform &#8594; deeper_recursive_arithmetic<span style="color: #888888;">, and</span></div>
        <div>&#8226; LLM &#8594; generalizes &#8594; to_longer_or_more_complex_arithmetic_sequences</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Larger LLMs can solve longer and more complex arithmetic problems than smaller models. </li>
    <li>Empirical scaling laws show that arithmetic accuracy and generalization improve sharply at certain model sizes. </li>
    <li>LLMs with more parameters can maintain longer chain-of-thought sequences without error. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> The law synthesizes scaling and compositionality into a new, predictive relationship for arithmetic.</p>            <p><strong>What Already Exists:</strong> Scaling laws for LLMs are well-studied, and larger models show better reasoning.</p>            <p><strong>What is Novel:</strong> This law links scale specifically to the depth of hierarchical, recursive arithmetic reasoning.</p>
            <p><strong>References:</strong> <ul>
    <li>Kaplan et al. (2020) Scaling Laws for Neural Language Models [Scaling laws]</li>
    <li>Wei et al. (2022) Chain-of-Thought Prompting Elicits Reasoning in Large Language Models [Stepwise reasoning]</li>
</ul>
            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>Larger LLMs will outperform smaller ones on multi-step arithmetic tasks requiring deeper recursion.</li>
                <li>LLMs will show error patterns in multi-digit arithmetic that reflect failures in hierarchical decomposition (e.g., carry errors).</li>
                <li>Providing explicit subproblem structure in prompts will improve LLM arithmetic accuracy.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>LLMs may be able to learn and apply novel hierarchical decompositions for arithmetic operations not present in training data.</li>
                <li>LLMs may transfer hierarchical reasoning to other algorithmic domains (e.g., sorting, symbolic manipulation).</li>
                <li>LLMs may develop internal representations isomorphic to tree-like data structures for arithmetic.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>If LLMs do not show improved performance on deeper recursive arithmetic with scale, the theory is challenged.</li>
                <li>If LLMs cannot decompose arithmetic problems into subproblems, the hierarchical mechanism is called into question.</li>
                <li>If LLMs' error patterns do not reflect hierarchical decomposition, the theory's mechanistic claim is weakened.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>Some arithmetic errors in LLMs may arise from tokenization artifacts rather than hierarchical reasoning failures. </li>
    <li>LLMs may memorize frequent arithmetic facts, bypassing hierarchical reasoning for those cases. </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> somewhat-related-to-existing</p>
            <p><strong>Explanation:</strong> The theory synthesizes compositionality and scaling into a new, mechanistic account for arithmetic in LLMs.</p>
            <p><strong>References:</strong> <ul>
    <li>Lake & Baroni (2018) Generalization without Systematicity [Compositionality in neural nets]</li>
    <li>Kaplan et al. (2020) Scaling Laws for Neural Language Models [Scaling laws]</li>
    <li>Wei et al. (2022) Chain-of-Thought Prompting Elicits Reasoning in Large Language Models [Stepwise reasoning]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Hierarchical Representation and Compositionality in LLM Arithmetic",
    "theory_description": "This theory proposes that LLMs develop hierarchical, compositional representations of numbers and arithmetic operations, enabling them to decompose complex arithmetic tasks into simpler subproblems. These representations are learned through exposure to diverse arithmetic data and are activated via chain-of-thought prompting, allowing the model to recursively apply learned subroutines (e.g., single-digit addition) to solve multi-digit or multi-step problems. The theory further posits that the depth and flexibility of these hierarchical representations are a function of model scale and training diversity.",
    "theory_statements": [
        {
            "law": {
                "law_name": "Hierarchical Decomposition of Arithmetic Tasks",
                "if": [
                    {
                        "subject": "LLM",
                        "relation": "has_learned",
                        "object": "compositional_number_representations"
                    },
                    {
                        "subject": "LLM",
                        "relation": "receives_prompt",
                        "object": "multi-digit_arithmetic_problem"
                    }
                ],
                "then": [
                    {
                        "subject": "LLM",
                        "relation": "decomposes",
                        "object": "problem_into_subproblems"
                    },
                    {
                        "subject": "LLM",
                        "relation": "solves",
                        "object": "subproblems_recursively"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "LLMs can perform multi-digit addition and multiplication by generating stepwise solutions that mirror human decomposition (e.g., column-wise addition).",
                        "uuids": []
                    },
                    {
                        "text": "Analysis of LLM outputs shows recursive application of single-digit operations in multi-digit arithmetic.",
                        "uuids": []
                    },
                    {
                        "text": "LLMs can generalize to longer arithmetic problems than seen in training, indicating compositionality.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Compositionality and hierarchical representations are known in neural networks, and LLMs show stepwise arithmetic reasoning.",
                    "what_is_novel": "This law formalizes the recursive, hierarchical decomposition as a core mechanism for LLM arithmetic.",
                    "classification_explanation": "The law extends compositionality to a mechanistic, recursive process for arithmetic in LLMs.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Lake & Baroni (2018) Generalization without Systematicity: On the Compositional Skills of Sequence-to-Sequence Recurrent Networks [Compositionality in neural nets]",
                        "Wei et al. (2022) Chain-of-Thought Prompting Elicits Reasoning in Large Language Models [Stepwise reasoning]"
                    ]
                }
            }
        },
        {
            "law": {
                "law_name": "Scale-Dependent Depth of Hierarchical Reasoning",
                "if": [
                    {
                        "subject": "LLM",
                        "relation": "has_parameter_count",
                        "object": "N"
                    },
                    {
                        "subject": "N",
                        "relation": "greater_than",
                        "object": "hierarchical_threshold"
                    }
                ],
                "then": [
                    {
                        "subject": "LLM",
                        "relation": "can_perform",
                        "object": "deeper_recursive_arithmetic"
                    },
                    {
                        "subject": "LLM",
                        "relation": "generalizes",
                        "object": "to_longer_or_more_complex_arithmetic_sequences"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Larger LLMs can solve longer and more complex arithmetic problems than smaller models.",
                        "uuids": []
                    },
                    {
                        "text": "Empirical scaling laws show that arithmetic accuracy and generalization improve sharply at certain model sizes.",
                        "uuids": []
                    },
                    {
                        "text": "LLMs with more parameters can maintain longer chain-of-thought sequences without error.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Scaling laws for LLMs are well-studied, and larger models show better reasoning.",
                    "what_is_novel": "This law links scale specifically to the depth of hierarchical, recursive arithmetic reasoning.",
                    "classification_explanation": "The law synthesizes scaling and compositionality into a new, predictive relationship for arithmetic.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Kaplan et al. (2020) Scaling Laws for Neural Language Models [Scaling laws]",
                        "Wei et al. (2022) Chain-of-Thought Prompting Elicits Reasoning in Large Language Models [Stepwise reasoning]"
                    ]
                }
            }
        }
    ],
    "new_predictions_likely": [
        "Larger LLMs will outperform smaller ones on multi-step arithmetic tasks requiring deeper recursion.",
        "LLMs will show error patterns in multi-digit arithmetic that reflect failures in hierarchical decomposition (e.g., carry errors).",
        "Providing explicit subproblem structure in prompts will improve LLM arithmetic accuracy."
    ],
    "new_predictions_unknown": [
        "LLMs may be able to learn and apply novel hierarchical decompositions for arithmetic operations not present in training data.",
        "LLMs may transfer hierarchical reasoning to other algorithmic domains (e.g., sorting, symbolic manipulation).",
        "LLMs may develop internal representations isomorphic to tree-like data structures for arithmetic."
    ],
    "negative_experiments": [
        "If LLMs do not show improved performance on deeper recursive arithmetic with scale, the theory is challenged.",
        "If LLMs cannot decompose arithmetic problems into subproblems, the hierarchical mechanism is called into question.",
        "If LLMs' error patterns do not reflect hierarchical decomposition, the theory's mechanistic claim is weakened."
    ],
    "unaccounted_for": [
        {
            "text": "Some arithmetic errors in LLMs may arise from tokenization artifacts rather than hierarchical reasoning failures.",
            "uuids": []
        },
        {
            "text": "LLMs may memorize frequent arithmetic facts, bypassing hierarchical reasoning for those cases.",
            "uuids": []
        }
    ],
    "conflicting_evidence": [
        {
            "text": "LLMs sometimes make non-hierarchical errors (e.g., digit transpositions) inconsistent with recursive decomposition.",
            "uuids": []
        }
    ],
    "special_cases": [
        "Arithmetic with non-standard number formats or encodings may not trigger hierarchical decomposition.",
        "Very long arithmetic problems may exceed the model's context window, limiting recursion."
    ],
    "existing_theory": {
        "what_already_exists": "Compositionality and scaling laws are established in neural networks and LLMs.",
        "what_is_novel": "This theory unifies hierarchical, recursive decomposition and scale as the core mechanism for LLM arithmetic.",
        "classification_explanation": "The theory synthesizes compositionality and scaling into a new, mechanistic account for arithmetic in LLMs.",
        "likely_classification": "somewhat-related-to-existing",
        "references": [
            "Lake & Baroni (2018) Generalization without Systematicity [Compositionality in neural nets]",
            "Kaplan et al. (2020) Scaling Laws for Neural Language Models [Scaling laws]",
            "Wei et al. (2022) Chain-of-Thought Prompting Elicits Reasoning in Large Language Models [Stepwise reasoning]"
        ]
    },
    "reflected_from_theory_index": 0,
    "type": "general",
    "version": "built-theory-from-results-single-theory-reflection2-nov14-2025-LLM-BASELINE-no-evidence-with-matched-control-theory-name",
    "theory_query": "Build a theory of how language models perform arithmetic.",
    "original_theory_id": "theory-580",
    "original_theory_name": "Emergent Algorithmic Reasoning via Chain-of-Thought and Program Synthesis in Large Language Models",
    "provide_matched_control_thery_name": true,
    "matched_control_theory_name": "Emergent Algorithmic Reasoning via Chain-of-Thought and Program Synthesis in Large Language Models",
    "model_str": "openai/gpt-4.1-2025-04-14"
}</code></pre>
        </div>
    </div>
</body>
</html>