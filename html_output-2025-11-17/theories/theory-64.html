<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Procedural Knowledge as Executable Artifacts Theory - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-64</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-64</p>
                <p><strong>Name:</strong> Procedural Knowledge as Executable Artifacts Theory</p>
                <p><strong>Type:</strong> general</p>
                <p><strong>Theory Query:</strong> Build a theory of how language models encode and utilize spatial, procedural, and object-relational knowledge for embodied planning tasks without direct sensory input, based on the following results.</p>
                <p><strong>Description:</strong> Language models encode procedural knowledge for embodied tasks most effectively when they generate executable artifacts (code, skill sequences, symbolic programs, pseudocode) that externalize and operationalize procedures. This approach transforms procedural reasoning from a pattern-completion problem into a program synthesis problem, where the model's role is to map from natural language task descriptions to structured executable representations interpretable by downstream execution systems. Effectiveness depends on: (1) the model's ability to generate syntactically and semantically correct artifacts, (2) the expressiveness and precision of the artifact language, (3) the availability of execution infrastructure (interpreters, skill libraries, planners, symbolic reasoners), (4) mechanisms for multi-stage verification and refinement, and (5) the design of skill APIs that balance expressiveness with learnability. This theory explains why code-generation approaches often outperform natural language planning, why explicit skill libraries reduce hallucination, and why symbolic program representations enable capabilities (formal verification, compositional reuse, deterministic execution) that are difficult or impossible with natural language alone.</p>
                <p><strong>Knowledge Cutoff Year:</strong> 2024</p>
                <p><strong>Knowledge Cutoff Month:</strong> 12</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <ol>
                <li>Procedural knowledge in language models is most effectively utilized when externalized as executable artifacts (code, skill sequences, symbolic programs) rather than implicit sequential patterns or natural language descriptions</li>
                <li>The quality of procedural reasoning is determined by: (1) artifact generation accuracy (syntax and semantics), (2) artifact language expressiveness and precision, (3) execution infrastructure quality (interpreters, skill libraries, symbolic reasoners), (4) verification mechanisms (syntax checking, semantic validation, simulation), and (5) API design that balances expressiveness with learnability</li>
                <li>Code-based procedural representations enable capabilities that natural language cannot reliably provide: precise composition, hierarchical abstraction, deterministic execution, formal verification, and exact numeric/geometric computation</li>
                <li>Models can learn to generate executable artifacts through: (1) pretraining on code and structured data, (2) fine-tuning on paired (instruction, artifact) data, (3) prompting with examples and API documentation, (4) iterative refinement with execution feedback, and (5) training on synthetic intermediate representations</li>
                <li>Explicit skill libraries and APIs reduce hallucination by constraining the output space, providing clear semantics for each action, and enabling verification against defined schemas</li>
                <li>Hierarchical procedural abstraction (functions calling functions, skills composed into plans, sub-goals decomposed into actions) emerges naturally in code-based representations but is difficult to maintain consistently in natural language</li>
                <li>Verification and refinement of executable artifacts is more tractable than verifying natural language plans due to formal properties of code (syntax rules, type systems, deterministic execution)</li>
                <li>Multi-stage verification (internal code checking, external outcome validation) provides complementary error detection that substantially improves reliability</li>
                <li>The effectiveness of executable artifacts depends critically on the design of skill APIs: too restrictive limits expressiveness, too permissive increases learning difficulty and hallucination</li>
                <li>Symbolic program representations (ASP, logic programs) enable reasoning capabilities (constraint satisfaction, proof search, multi-hop inference) that are difficult for neural sequence models alone</li>
            </ol>
            <h3>Supporting Evidence</h3>
<ol>
    <li>LLMs generating executable code (Python, MJCF, TikZ/SVG) for robotic control and spatial reasoning achieve higher success rates and precision than generating natural language plans <a href="../results/extraction-result-367.html#e367.0" class="evidence-link">[e367.0]</a> <a href="../results/extraction-result-392.html#e392.0" class="evidence-link">[e392.0]</a> <a href="../results/extraction-result-392.html#e392.3" class="evidence-link">[e392.3]</a> <a href="../results/extraction-result-532.html#e532.1" class="evidence-link">[e532.1]</a> </li>
    <li>Fine-tuning models to output structured skill sequences (API calls) dramatically reduces hallucination and improves executability compared to freeform text generation <a href="../results/extraction-result-395.html#e395.0" class="evidence-link">[e395.0]</a> <a href="../results/extraction-result-395.html#e395.1" class="evidence-link">[e395.1]</a> <a href="../results/extraction-result-395.html#e395.5" class="evidence-link">[e395.5]</a> </li>
    <li>Systems that convert natural language to symbolic programs (ASP, PDDL, logic programs) enable precise multi-step reasoning and formal verification that language-only approaches cannot achieve <a href="../results/extraction-result-535.html#e535.2" class="evidence-link">[e535.2]</a> <a href="../results/extraction-result-518.html#e518.0" class="evidence-link">[e518.0]</a> <a href="../results/extraction-result-518.html#e518.2" class="evidence-link">[e518.2]</a> <a href="../results/extraction-result-520.html#e520.3" class="evidence-link">[e520.3]</a> </li>
    <li>Code-based representations enable compositional reuse: generated functions can be called by later code, enabling hierarchical procedural abstraction and sub-goal decomposition <a href="../results/extraction-result-367.html#e367.0" class="evidence-link">[e367.0]</a> <a href="../results/extraction-result-367.html#e367.4" class="evidence-link">[e367.4]</a> <a href="../results/extraction-result-392.html#e392.0" class="evidence-link">[e392.0]</a> <a href="../results/extraction-result-509.html#e509.1" class="evidence-link">[e509.1]</a> </li>
    <li>Executable artifacts enable multi-stage verification: code can be syntax-checked, semantically validated, simulated, and tested before execution, reducing failures substantially <a href="../results/extraction-result-354.html#e354.0" class="evidence-link">[e354.0]</a> <a href="../results/extraction-result-354.html#e354.2" class="evidence-link">[e354.2]</a> <a href="../results/extraction-result-395.html#e395.0" class="evidence-link">[e395.0]</a> <a href="../results/extraction-result-535.html#e535.2" class="evidence-link">[e535.2]</a> </li>
    <li>Models trained on code show better procedural reasoning than models trained only on natural language, suggesting code exposure teaches procedural structure and compositional thinking <a href="../results/extraction-result-532.html#e532.1" class="evidence-link">[e532.1]</a> <a href="../results/extraction-result-358.html#e358.2" class="evidence-link">[e358.2]</a> <a href="../results/extraction-result-367.html#e367.0" class="evidence-link">[e367.0]</a> </li>
    <li>Explicit skill libraries with defined APIs outperform open-vocabulary action generation by constraining the output space, providing clear semantics, and reducing ambiguity <a href="../results/extraction-result-395.html#e395.0" class="evidence-link">[e395.0]</a> <a href="../results/extraction-result-395.html#e395.1" class="evidence-link">[e395.1]</a> <a href="../results/extraction-result-351.html#e351.0" class="evidence-link">[e351.0]</a> <a href="../results/extraction-result-350.html#e350.0" class="evidence-link">[e350.0]</a> </li>
    <li>Iterative refinement of executable artifacts through generate-verify-refine loops improves success rates substantially, with verification catching errors before execution <a href="../results/extraction-result-354.html#e354.0" class="evidence-link">[e354.0]</a> <a href="../results/extraction-result-354.html#e354.2" class="evidence-link">[e354.2]</a> <a href="../results/extraction-result-511.html#e511.0" class="evidence-link">[e511.0]</a> <a href="../results/extraction-result-368.html#e368.4" class="evidence-link">[e368.4]</a> </li>
    <li>Synthetic subgoal languages (PDDL-like representations) serve as effective intermediate representations that improve both training efficiency and downstream task performance <a href="../results/extraction-result-509.html#e509.1" class="evidence-link">[e509.1]</a> </li>
    <li>Parametric geometric priors and functions enable precise spatial reasoning when embedded in executable code, outperforming natural language spatial descriptions <a href="../results/extraction-result-548.html#e548.2" class="evidence-link">[e548.2]</a> </li>
    <li>Language planning modules that output symbolic sub-goals enable better integration with downstream symbolic reasoning and execution systems <a href="../results/extraction-result-365.html#e365.0" class="evidence-link">[e365.0]</a> <a href="../results/extraction-result-365.html#e365.3" class="evidence-link">[e365.3]</a> </li>
    <li>Mapping natural language plans to executable programs (VirtualHome, simulator code) enables quantitative evaluation and execution that natural language plans cannot support <a href="../results/extraction-result-361.html#e361.4" class="evidence-link">[e361.4]</a> </li>
    <li>Cross-modal translation between language and action sequences benefits from explicit binding losses that enforce correspondence between linguistic descriptions and executable action representations <a href="../results/extraction-result-513.html#e513.2" class="evidence-link">[e513.2]</a> </li>
    <li>Code generation enables precise numeric and geometric computations (coordinate arithmetic, distance calculations) that are error-prone in natural language <a href="../results/extraction-result-367.html#e367.1" class="evidence-link">[e367.1]</a> <a href="../results/extraction-result-532.html#e532.1" class="evidence-link">[e532.1]</a> </li>
    <li>Hierarchical sub-agents for on-demand function synthesis enable compositional code generation that reuses and abstracts procedures <a href="../results/extraction-result-392.html#e392.0" class="evidence-link">[e392.0]</a> </li>
</ol>            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>Training LLMs with more code (especially robotics/simulation code, geometric algorithms, and planning domain definitions) will improve their embodied planning capabilities even on natural language tasks</li>
                <li>Providing LLMs with richer skill libraries and APIs will improve performance more than scaling model size alone, particularly for complex multi-step tasks</li>
                <li>Systems that generate code with explicit multi-stage verification (syntax, semantics, simulation) will outperform those that generate code without verification</li>
                <li>Fine-tuning on (natural language, code) pairs will transfer better to novel tasks than fine-tuning on (natural language, natural language plan) pairs</li>
                <li>Models that generate intermediate symbolic representations (PDDL, ASP) before final code will show better compositional generalization than end-to-end code generation</li>
                <li>Hierarchical code generation (high-level functions first, then implementation details) will outperform flat code generation for complex tasks</li>
                <li>Skill libraries designed with clear compositional structure will be learned more efficiently than flat skill sets of equal size</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>Whether there exists an optimal level of abstraction for skill APIs that balances expressiveness and learnability across diverse embodied domains, or whether optimal abstraction is domain-specific</li>
                <li>Whether models can learn to design their own skill APIs and execution infrastructure rather than relying on human-designed ones, and whether such learned APIs would be interpretable</li>
                <li>Whether code-based procedural representations will remain superior as natural language models scale to much larger sizes (e.g., 1T+ parameters) with more sophisticated reasoning capabilities</li>
                <li>Whether the benefits of executable artifacts extend to domains beyond robotics and planning (e.g., social interaction, creative tasks, scientific reasoning) or are specific to procedural/spatial domains</li>
                <li>Whether hybrid representations (code + natural language annotations) could combine the precision of code with the flexibility of natural language</li>
                <li>Whether models can learn to automatically select the appropriate level of abstraction (natural language vs. pseudocode vs. executable code) based on task requirements</li>
                <li>Whether formal verification of generated code can be automated sufficiently to enable safe deployment without human oversight</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>Demonstrating that natural language plan generation consistently outperforms code generation when both have equal training data and execution infrastructure would challenge the superiority of executable artifacts</li>
                <li>Finding that models cannot learn to generate correct code even with extensive training on code-generation tasks would question the learnability assumption</li>
                <li>Showing that verification mechanisms provide no benefit over unverified generation (or that verification costs outweigh benefits) would challenge the importance of formal properties</li>
                <li>Demonstrating that skill libraries constrain performance more than they help (by limiting expressiveness or requiring excessive training) would question the API-based approach</li>
                <li>Finding that end-to-end learned policies consistently outperform code-based planning across diverse tasks would challenge the need for explicit procedural artifacts</li>
                <li>Showing that the overhead of code generation (computational cost, latency) makes it impractical for real-time embodied tasks would limit applicability</li>
                <li>Demonstrating that natural language plans are more robust to distribution shift than code-based plans would challenge the generalization claims</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>The theory does not explain how to design optimal skill APIs for novel domains without extensive domain knowledge or trial-and-error </li>
    <li>Trade-offs between API expressiveness and learnability are not fully characterized - when does adding more skills help vs. hurt? </li>
    <li>How models handle situations requiring skills outside their predefined library is not fully addressed - can they compose existing skills creatively or do they fail? <a href="../results/extraction-result-395.html#e395.0" class="evidence-link">[e395.0]</a> <a href="../results/extraction-result-395.html#e395.10" class="evidence-link">[e395.10]</a> </li>
    <li>The cognitive/computational costs of code generation versus natural language generation are not systematically compared </li>
    <li>The theory doesn't explain why some tasks (simple, short-horizon) don't benefit from code generation </li>
    <li>How to handle partial observability and dynamic environments where pre-generated code may become invalid is not addressed </li>
    <li>The role of natural language annotations and comments in generated code is not characterized </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> closely-related-to-existing</p>
            <p><strong>Explanation:</strong> No explanation provided.</p>
            <p><strong>References:</strong> <ul>
    <li>Liang et al. (2022) Code as Policies: Language Model Programs for Embodied Control [Directly proposes using code generation for robot control, very closely related, foundational work for this theory]</li>
    <li>Jiang et al. (2019) Program Synthesis [General framework for learning to generate programs from specifications, related approach]</li>
    <li>Nye et al. (2021) Show Your Work: Scratchpads for Intermediate Computation with Language Models [Proposes using intermediate computational artifacts for reasoning, related mechanism]</li>
    <li>Austin et al. (2021) Program Synthesis with Large Language Models [Demonstrates LLM code generation capabilities, foundational work]</li>
    <li>Singh et al. (2023) ProgPrompt: Generating Situated Robot Task Plans using Large Language Models [Uses program synthesis for robot planning, closely related]</li>
    <li>Huang et al. (2022) Language Models as Zero-Shot Planners [Explores LLMs for planning, related but focuses more on natural language]</li>
    <li>Ahn et al. (2022) Do As I Can, Not As I Say: Grounding Language in Robotic Affordances [Combines language models with affordances, related approach to grounding]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Procedural Knowledge as Executable Artifacts Theory",
    "theory_description": "Language models encode procedural knowledge for embodied tasks most effectively when they generate executable artifacts (code, skill sequences, symbolic programs, pseudocode) that externalize and operationalize procedures. This approach transforms procedural reasoning from a pattern-completion problem into a program synthesis problem, where the model's role is to map from natural language task descriptions to structured executable representations interpretable by downstream execution systems. Effectiveness depends on: (1) the model's ability to generate syntactically and semantically correct artifacts, (2) the expressiveness and precision of the artifact language, (3) the availability of execution infrastructure (interpreters, skill libraries, planners, symbolic reasoners), (4) mechanisms for multi-stage verification and refinement, and (5) the design of skill APIs that balance expressiveness with learnability. This theory explains why code-generation approaches often outperform natural language planning, why explicit skill libraries reduce hallucination, and why symbolic program representations enable capabilities (formal verification, compositional reuse, deterministic execution) that are difficult or impossible with natural language alone.",
    "supporting_evidence": [
        {
            "text": "LLMs generating executable code (Python, MJCF, TikZ/SVG) for robotic control and spatial reasoning achieve higher success rates and precision than generating natural language plans",
            "uuids": [
                "e367.0",
                "e392.0",
                "e392.3",
                "e532.1"
            ]
        },
        {
            "text": "Fine-tuning models to output structured skill sequences (API calls) dramatically reduces hallucination and improves executability compared to freeform text generation",
            "uuids": [
                "e395.0",
                "e395.1",
                "e395.5"
            ]
        },
        {
            "text": "Systems that convert natural language to symbolic programs (ASP, PDDL, logic programs) enable precise multi-step reasoning and formal verification that language-only approaches cannot achieve",
            "uuids": [
                "e535.2",
                "e518.0",
                "e518.2",
                "e520.3"
            ]
        },
        {
            "text": "Code-based representations enable compositional reuse: generated functions can be called by later code, enabling hierarchical procedural abstraction and sub-goal decomposition",
            "uuids": [
                "e367.0",
                "e367.4",
                "e392.0",
                "e509.1"
            ]
        },
        {
            "text": "Executable artifacts enable multi-stage verification: code can be syntax-checked, semantically validated, simulated, and tested before execution, reducing failures substantially",
            "uuids": [
                "e354.0",
                "e354.2",
                "e395.0",
                "e535.2"
            ]
        },
        {
            "text": "Models trained on code show better procedural reasoning than models trained only on natural language, suggesting code exposure teaches procedural structure and compositional thinking",
            "uuids": [
                "e532.1",
                "e358.2",
                "e367.0"
            ]
        },
        {
            "text": "Explicit skill libraries with defined APIs outperform open-vocabulary action generation by constraining the output space, providing clear semantics, and reducing ambiguity",
            "uuids": [
                "e395.0",
                "e395.1",
                "e351.0",
                "e350.0"
            ]
        },
        {
            "text": "Iterative refinement of executable artifacts through generate-verify-refine loops improves success rates substantially, with verification catching errors before execution",
            "uuids": [
                "e354.0",
                "e354.2",
                "e511.0",
                "e368.4"
            ]
        },
        {
            "text": "Synthetic subgoal languages (PDDL-like representations) serve as effective intermediate representations that improve both training efficiency and downstream task performance",
            "uuids": [
                "e509.1"
            ]
        },
        {
            "text": "Parametric geometric priors and functions enable precise spatial reasoning when embedded in executable code, outperforming natural language spatial descriptions",
            "uuids": [
                "e548.2"
            ]
        },
        {
            "text": "Language planning modules that output symbolic sub-goals enable better integration with downstream symbolic reasoning and execution systems",
            "uuids": [
                "e365.0",
                "e365.3"
            ]
        },
        {
            "text": "Mapping natural language plans to executable programs (VirtualHome, simulator code) enables quantitative evaluation and execution that natural language plans cannot support",
            "uuids": [
                "e361.4"
            ]
        },
        {
            "text": "Cross-modal translation between language and action sequences benefits from explicit binding losses that enforce correspondence between linguistic descriptions and executable action representations",
            "uuids": [
                "e513.2"
            ]
        },
        {
            "text": "Code generation enables precise numeric and geometric computations (coordinate arithmetic, distance calculations) that are error-prone in natural language",
            "uuids": [
                "e367.1",
                "e532.1"
            ]
        },
        {
            "text": "Hierarchical sub-agents for on-demand function synthesis enable compositional code generation that reuses and abstracts procedures",
            "uuids": [
                "e392.0"
            ]
        }
    ],
    "theory_statements": [
        "Procedural knowledge in language models is most effectively utilized when externalized as executable artifacts (code, skill sequences, symbolic programs) rather than implicit sequential patterns or natural language descriptions",
        "The quality of procedural reasoning is determined by: (1) artifact generation accuracy (syntax and semantics), (2) artifact language expressiveness and precision, (3) execution infrastructure quality (interpreters, skill libraries, symbolic reasoners), (4) verification mechanisms (syntax checking, semantic validation, simulation), and (5) API design that balances expressiveness with learnability",
        "Code-based procedural representations enable capabilities that natural language cannot reliably provide: precise composition, hierarchical abstraction, deterministic execution, formal verification, and exact numeric/geometric computation",
        "Models can learn to generate executable artifacts through: (1) pretraining on code and structured data, (2) fine-tuning on paired (instruction, artifact) data, (3) prompting with examples and API documentation, (4) iterative refinement with execution feedback, and (5) training on synthetic intermediate representations",
        "Explicit skill libraries and APIs reduce hallucination by constraining the output space, providing clear semantics for each action, and enabling verification against defined schemas",
        "Hierarchical procedural abstraction (functions calling functions, skills composed into plans, sub-goals decomposed into actions) emerges naturally in code-based representations but is difficult to maintain consistently in natural language",
        "Verification and refinement of executable artifacts is more tractable than verifying natural language plans due to formal properties of code (syntax rules, type systems, deterministic execution)",
        "Multi-stage verification (internal code checking, external outcome validation) provides complementary error detection that substantially improves reliability",
        "The effectiveness of executable artifacts depends critically on the design of skill APIs: too restrictive limits expressiveness, too permissive increases learning difficulty and hallucination",
        "Symbolic program representations (ASP, logic programs) enable reasoning capabilities (constraint satisfaction, proof search, multi-hop inference) that are difficult for neural sequence models alone"
    ],
    "new_predictions_likely": [
        "Training LLMs with more code (especially robotics/simulation code, geometric algorithms, and planning domain definitions) will improve their embodied planning capabilities even on natural language tasks",
        "Providing LLMs with richer skill libraries and APIs will improve performance more than scaling model size alone, particularly for complex multi-step tasks",
        "Systems that generate code with explicit multi-stage verification (syntax, semantics, simulation) will outperform those that generate code without verification",
        "Fine-tuning on (natural language, code) pairs will transfer better to novel tasks than fine-tuning on (natural language, natural language plan) pairs",
        "Models that generate intermediate symbolic representations (PDDL, ASP) before final code will show better compositional generalization than end-to-end code generation",
        "Hierarchical code generation (high-level functions first, then implementation details) will outperform flat code generation for complex tasks",
        "Skill libraries designed with clear compositional structure will be learned more efficiently than flat skill sets of equal size"
    ],
    "new_predictions_unknown": [
        "Whether there exists an optimal level of abstraction for skill APIs that balances expressiveness and learnability across diverse embodied domains, or whether optimal abstraction is domain-specific",
        "Whether models can learn to design their own skill APIs and execution infrastructure rather than relying on human-designed ones, and whether such learned APIs would be interpretable",
        "Whether code-based procedural representations will remain superior as natural language models scale to much larger sizes (e.g., 1T+ parameters) with more sophisticated reasoning capabilities",
        "Whether the benefits of executable artifacts extend to domains beyond robotics and planning (e.g., social interaction, creative tasks, scientific reasoning) or are specific to procedural/spatial domains",
        "Whether hybrid representations (code + natural language annotations) could combine the precision of code with the flexibility of natural language",
        "Whether models can learn to automatically select the appropriate level of abstraction (natural language vs. pseudocode vs. executable code) based on task requirements",
        "Whether formal verification of generated code can be automated sufficiently to enable safe deployment without human oversight"
    ],
    "negative_experiments": [
        "Demonstrating that natural language plan generation consistently outperforms code generation when both have equal training data and execution infrastructure would challenge the superiority of executable artifacts",
        "Finding that models cannot learn to generate correct code even with extensive training on code-generation tasks would question the learnability assumption",
        "Showing that verification mechanisms provide no benefit over unverified generation (or that verification costs outweigh benefits) would challenge the importance of formal properties",
        "Demonstrating that skill libraries constrain performance more than they help (by limiting expressiveness or requiring excessive training) would question the API-based approach",
        "Finding that end-to-end learned policies consistently outperform code-based planning across diverse tasks would challenge the need for explicit procedural artifacts",
        "Showing that the overhead of code generation (computational cost, latency) makes it impractical for real-time embodied tasks would limit applicability",
        "Demonstrating that natural language plans are more robust to distribution shift than code-based plans would challenge the generalization claims"
    ],
    "unaccounted_for": [
        {
            "text": "The theory does not explain how to design optimal skill APIs for novel domains without extensive domain knowledge or trial-and-error",
            "uuids": []
        },
        {
            "text": "Trade-offs between API expressiveness and learnability are not fully characterized - when does adding more skills help vs. hurt?",
            "uuids": []
        },
        {
            "text": "How models handle situations requiring skills outside their predefined library is not fully addressed - can they compose existing skills creatively or do they fail?",
            "uuids": [
                "e395.0",
                "e395.10"
            ]
        },
        {
            "text": "The cognitive/computational costs of code generation versus natural language generation are not systematically compared",
            "uuids": []
        },
        {
            "text": "The theory doesn't explain why some tasks (simple, short-horizon) don't benefit from code generation",
            "uuids": []
        },
        {
            "text": "How to handle partial observability and dynamic environments where pre-generated code may become invalid is not addressed",
            "uuids": []
        },
        {
            "text": "The role of natural language annotations and comments in generated code is not characterized",
            "uuids": []
        }
    ],
    "conflicting_evidence": [
        {
            "text": "Some natural language planning systems (Inner Monologue, LFG) achieve competitive performance with code-based systems on certain benchmarks, suggesting code may not always be necessary",
            "uuids": [
                "e352.0",
                "e341.0"
            ]
        },
        {
            "text": "End-to-end learned policies sometimes outperform code-based planning systems, questioning whether explicit procedural artifacts are always optimal",
            "uuids": [
                "e533.0",
                "e530.3"
            ]
        },
        {
            "text": "Natural language plans can be more flexible and adaptable to unexpected situations than rigid code, suggesting trade-offs rather than clear superiority",
            "uuids": [
                "e352.0"
            ]
        },
        {
            "text": "Code generation requires substantial infrastructure (interpreters, skill implementations, execution environments) that may not be available in all domains",
            "uuids": [
                "e392.3",
                "e367.0"
            ]
        },
        {
            "text": "Some models achieve high performance on procedural tasks without explicit code generation, using implicit procedural knowledge in weights",
            "uuids": [
                "e511.0",
                "e514.0"
            ]
        }
    ],
    "special_cases": [
        "For very simple tasks (1-2 steps), the overhead of code generation may not be justified compared to direct action prediction or natural language planning",
        "In domains without well-defined execution infrastructure or skill libraries, natural language plans may be more practical than code",
        "For tasks requiring real-time adaptation to dynamic environments, compiled code may be less flexible than learned policies or natural language plans",
        "In safety-critical domains, formally verified code may be essential regardless of performance trade-offs",
        "For tasks with high uncertainty or partial observability, probabilistic planning may be more appropriate than deterministic code",
        "When human interpretability is critical, natural language plans may be preferred over code despite lower precision",
        "For creative or open-ended tasks, natural language may provide more flexibility than structured code representations",
        "In resource-constrained settings (limited compute, memory), lightweight natural language planning may be more practical than code generation and execution"
    ],
    "existing_theory": {
        "likely_classification": "closely-related-to-existing",
        "references": [
            "Liang et al. (2022) Code as Policies: Language Model Programs for Embodied Control [Directly proposes using code generation for robot control, very closely related, foundational work for this theory]",
            "Jiang et al. (2019) Program Synthesis [General framework for learning to generate programs from specifications, related approach]",
            "Nye et al. (2021) Show Your Work: Scratchpads for Intermediate Computation with Language Models [Proposes using intermediate computational artifacts for reasoning, related mechanism]",
            "Austin et al. (2021) Program Synthesis with Large Language Models [Demonstrates LLM code generation capabilities, foundational work]",
            "Singh et al. (2023) ProgPrompt: Generating Situated Robot Task Plans using Large Language Models [Uses program synthesis for robot planning, closely related]",
            "Huang et al. (2022) Language Models as Zero-Shot Planners [Explores LLMs for planning, related but focuses more on natural language]",
            "Ahn et al. (2022) Do As I Can, Not As I Say: Grounding Language in Robotic Affordances [Combines language models with affordances, related approach to grounding]"
        ]
    },
    "theory_type_general_specific": "general",
    "reflected_from_theory_index": 2,
    "type": "general"
}</code></pre>
        </div>
    </div>
</body>
</html>