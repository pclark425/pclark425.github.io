<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Motif-Driven Locality Enhancement Theory for Hard Graph Problems - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-614</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-614</p>
                <p><strong>Name:</strong> Motif-Driven Locality Enhancement Theory for Hard Graph Problems</p>
                <p><strong>Type:</strong> specific</p>
                <p><strong>Theory Query:</strong> Build a theory of ideal representations for converting graphs into text for language model training, based on the following results.</p>
                <p><strong>Description:</strong> This theory posits that for graph tasks characterized by low homophily and high motif complexity (i.e., 'hard' node classification problems), representations that explicitly encode motif attachment information—specifically, which motifs (e.g., triangles, stars, cliques) a node participates in—provide a unique, discriminative local structural signal. This enables LLMs to outperform both global motif counts and plain adjacency or attribute-based encodings. Motif attachment lists act as a local structural fingerprint, allowing LLMs to distinguish nodes in structurally ambiguous or heterophilous regions of the graph, especially where traditional homophily-based cues are weak.</p>
                <p><strong>Knowledge Cutoff Year:</strong> 2024</p>
                <p><strong>Knowledge Cutoff Month:</strong> 6</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <h3>Statement 0: Motif Attachment Superiority Law (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; graph task &#8594; is &#8594; hard (low homophily, high motif count)<span style="color: #888888;">, and</span></div>
        <div>&#8226; representation &#8594; includes &#8594; explicit motif attachment lists for the query node</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; LLM &#8594; achieves &#8594; higher accuracy and lower mismatch/denial rates than motif-count-only or adjacency-only encodings</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Motif modality with attached motif lists ('triangle and star attached to ? node') improves accuracy and lowers mismatch/denial on hard graph problems compared to counts-only or adjacency-only. <a href="../results/extraction-result-5357.html#e5357.1" class="evidence-link">[e5357.1]</a> </li>
    <li>Motif modality attains the highest accuracy on the 'hard' graph problems (high motif count / low homophily). <a href="../results/extraction-result-5357.html#e5357.1" class="evidence-link">[e5357.1]</a> </li>
    <li>Motif encoding (counts and attached-motif listings) outperformed text and image modalities on the hardest tasks where motif structure is discriminative. <a href="../results/extraction-result-5357.html#e5357.1" class="evidence-link">[e5357.1]</a> </li>
    <li>Providing motif attachment information (which nodes form the motif with the query node) improved performance more than counts alone. <a href="../results/extraction-result-5357.html#e5357.1" class="evidence-link">[e5357.1]</a> </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: green; font-weight: bold;">new</span></p>
            <p><strong>Explanation:</strong> While motif features are known in GNNs, their explicit use as attachment lists in LLM graph-to-text representations for hard tasks is a novel, empirically supported claim.</p>            <p><strong>What Already Exists:</strong> Motif-based features are used in GNNs and graph mining, but explicit motif attachment lists for LLMs are novel.</p>            <p><strong>What is Novel:</strong> The law that motif attachment lists specifically enable LLMs to outperform other encodings on hard, heterophilous graph tasks is new.</p>
            <p><strong>References:</strong> <ul>
    <li>Wang et al. (2023) Which Modality should I use - Text, Motif, or Image? [motif attachment]</li>
</ul>
            <h3>Statement 1: Motif Attachment-Attribute Synergy Law (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; representation &#8594; combines &#8594; motif attachment lists and node attribute text<span style="color: #888888;">, and</span></div>
        <div>&#8226; graph task &#8594; is &#8594; hard (low homophily, high motif count)</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; LLM &#8594; achieves &#8594; further improved accuracy and reduced mismatch/denial rates compared to using either motif attachment or attribute text alone</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Combining motif info with text/image can correct errors; motif attachment lists are more informative than counts alone, and combining modalities can correct misclassifications. <a href="../results/extraction-result-5357.html#e5357.1" class="evidence-link">[e5357.1]</a> </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: green; font-weight: bold;">new</span></p>
            <p><strong>Explanation:</strong> This law extends the motif attachment principle to multimodal fusion in LLM-based graph-to-text representations, which is not previously formalized.</p>            <p><strong>What Already Exists:</strong> Combining multiple modalities is a known strategy in multimodal learning, but the specific synergy of motif attachment lists and node attribute text for LLM-based graph tasks is not established.</p>            <p><strong>What is Novel:</strong> The explicit claim that motif attachment lists and node attribute text together yield superior performance for LLMs on hard graph problems is new.</p>
            <p><strong>References:</strong> <ul>
    <li>Wang et al. (2023) Which Modality should I use - Text, Motif, or Image? [motif attachment, multimodal fusion]</li>
</ul>
            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>On node classification benchmarks with low homophily and high motif density, LLMs using motif attachment encodings will outperform those using only motif counts or adjacency lists.</li>
                <li>Combining motif attachment lists with node attribute text will further improve performance on hard graph problems.</li>
                <li>Motif attachment encodings will yield lower denial and mismatch rates on hard tasks compared to text-only or adjacency-only encodings.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>Motif attachment encodings will enable LLMs to generalize to new, unseen motif types (e.g., higher-order cliques) in transfer learning settings.</li>
                <li>Motif attachment lists will improve LLM performance on link prediction tasks in heterophilous graphs, but the magnitude of improvement is unknown.</li>
                <li>Motif attachment encodings may enable LLMs to better handle adversarially perturbed graphs where global structure is ambiguous but local motifs are preserved.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>If motif attachment encodings do not outperform motif counts or adjacency lists on hard graph problems, the theory would be challenged.</li>
                <li>If adding motif attachment lists increases mismatch or denial rates, the law would be called into question.</li>
                <li>If combining motif attachment lists with node attribute text does not yield further improvements over either alone, the synergy law would be falsified.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>Image-based encodings sometimes outperform motif encodings on medium-difficulty tasks, which is not explained by the theory. <a href="../results/extraction-result-5252.html#e5252.8" class="evidence-link">[e5252.8]</a> </li>
    <li>Motif modality had higher mismatch rates than image or text in some settings, especially on certain datasets, which is not fully explained by the theory. <a href="../results/extraction-result-5357.html#e5357.1" class="evidence-link">[e5357.1]</a> </li>
    <li>Motif encoding is computationally expensive for large graphs, limiting scalability, which is not addressed by the theory. <a href="../results/extraction-result-5357.html#e5357.1" class="evidence-link">[e5357.1]</a> </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> new</p>
            <p><strong>Explanation:</strong> This is a new, empirically supported theory specific to LLM-based graph-to-text conversion for hard graph problems, not previously formalized in the literature.</p>
            <p><strong>References:</strong> <ul>
    <li>Wang et al. (2023) Which Modality should I use - Text, Motif, or Image? [motif attachment, LLM graph encoding]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Motif-Driven Locality Enhancement Theory for Hard Graph Problems",
    "theory_description": "This theory posits that for graph tasks characterized by low homophily and high motif complexity (i.e., 'hard' node classification problems), representations that explicitly encode motif attachment information—specifically, which motifs (e.g., triangles, stars, cliques) a node participates in—provide a unique, discriminative local structural signal. This enables LLMs to outperform both global motif counts and plain adjacency or attribute-based encodings. Motif attachment lists act as a local structural fingerprint, allowing LLMs to distinguish nodes in structurally ambiguous or heterophilous regions of the graph, especially where traditional homophily-based cues are weak.",
    "theory_statements": [
        {
            "law": {
                "law_name": "Motif Attachment Superiority Law",
                "if": [
                    {
                        "subject": "graph task",
                        "relation": "is",
                        "object": "hard (low homophily, high motif count)"
                    },
                    {
                        "subject": "representation",
                        "relation": "includes",
                        "object": "explicit motif attachment lists for the query node"
                    }
                ],
                "then": [
                    {
                        "subject": "LLM",
                        "relation": "achieves",
                        "object": "higher accuracy and lower mismatch/denial rates than motif-count-only or adjacency-only encodings"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Motif modality with attached motif lists ('triangle and star attached to ? node') improves accuracy and lowers mismatch/denial on hard graph problems compared to counts-only or adjacency-only.",
                        "uuids": [
                            "e5357.1"
                        ]
                    },
                    {
                        "text": "Motif modality attains the highest accuracy on the 'hard' graph problems (high motif count / low homophily).",
                        "uuids": [
                            "e5357.1"
                        ]
                    },
                    {
                        "text": "Motif encoding (counts and attached-motif listings) outperformed text and image modalities on the hardest tasks where motif structure is discriminative.",
                        "uuids": [
                            "e5357.1"
                        ]
                    },
                    {
                        "text": "Providing motif attachment information (which nodes form the motif with the query node) improved performance more than counts alone.",
                        "uuids": [
                            "e5357.1"
                        ]
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Motif-based features are used in GNNs and graph mining, but explicit motif attachment lists for LLMs are novel.",
                    "what_is_novel": "The law that motif attachment lists specifically enable LLMs to outperform other encodings on hard, heterophilous graph tasks is new.",
                    "classification_explanation": "While motif features are known in GNNs, their explicit use as attachment lists in LLM graph-to-text representations for hard tasks is a novel, empirically supported claim.",
                    "likely_classification": "new",
                    "references": [
                        "Wang et al. (2023) Which Modality should I use - Text, Motif, or Image? [motif attachment]"
                    ]
                }
            }
        },
        {
            "law": {
                "law_name": "Motif Attachment-Attribute Synergy Law",
                "if": [
                    {
                        "subject": "representation",
                        "relation": "combines",
                        "object": "motif attachment lists and node attribute text"
                    },
                    {
                        "subject": "graph task",
                        "relation": "is",
                        "object": "hard (low homophily, high motif count)"
                    }
                ],
                "then": [
                    {
                        "subject": "LLM",
                        "relation": "achieves",
                        "object": "further improved accuracy and reduced mismatch/denial rates compared to using either motif attachment or attribute text alone"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Combining motif info with text/image can correct errors; motif attachment lists are more informative than counts alone, and combining modalities can correct misclassifications.",
                        "uuids": [
                            "e5357.1"
                        ]
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Combining multiple modalities is a known strategy in multimodal learning, but the specific synergy of motif attachment lists and node attribute text for LLM-based graph tasks is not established.",
                    "what_is_novel": "The explicit claim that motif attachment lists and node attribute text together yield superior performance for LLMs on hard graph problems is new.",
                    "classification_explanation": "This law extends the motif attachment principle to multimodal fusion in LLM-based graph-to-text representations, which is not previously formalized.",
                    "likely_classification": "new",
                    "references": [
                        "Wang et al. (2023) Which Modality should I use - Text, Motif, or Image? [motif attachment, multimodal fusion]"
                    ]
                }
            }
        }
    ],
    "new_predictions_likely": [
        "On node classification benchmarks with low homophily and high motif density, LLMs using motif attachment encodings will outperform those using only motif counts or adjacency lists.",
        "Combining motif attachment lists with node attribute text will further improve performance on hard graph problems.",
        "Motif attachment encodings will yield lower denial and mismatch rates on hard tasks compared to text-only or adjacency-only encodings."
    ],
    "new_predictions_unknown": [
        "Motif attachment encodings will enable LLMs to generalize to new, unseen motif types (e.g., higher-order cliques) in transfer learning settings.",
        "Motif attachment lists will improve LLM performance on link prediction tasks in heterophilous graphs, but the magnitude of improvement is unknown.",
        "Motif attachment encodings may enable LLMs to better handle adversarially perturbed graphs where global structure is ambiguous but local motifs are preserved."
    ],
    "negative_experiments": [
        "If motif attachment encodings do not outperform motif counts or adjacency lists on hard graph problems, the theory would be challenged.",
        "If adding motif attachment lists increases mismatch or denial rates, the law would be called into question.",
        "If combining motif attachment lists with node attribute text does not yield further improvements over either alone, the synergy law would be falsified."
    ],
    "unaccounted_for": [
        {
            "text": "Image-based encodings sometimes outperform motif encodings on medium-difficulty tasks, which is not explained by the theory.",
            "uuids": [
                "e5252.8"
            ]
        },
        {
            "text": "Motif modality had higher mismatch rates than image or text in some settings, especially on certain datasets, which is not fully explained by the theory.",
            "uuids": [
                "e5357.1"
            ]
        },
        {
            "text": "Motif encoding is computationally expensive for large graphs, limiting scalability, which is not addressed by the theory.",
            "uuids": [
                "e5357.1"
            ]
        }
    ],
    "conflicting_evidence": [
        {
            "text": "Motif encodings have higher mismatch rates in some datasets, suggesting that motif attachment is not always beneficial.",
            "uuids": [
                "e5357.1"
            ]
        },
        {
            "text": "On easy/medium tasks, motif modality generally had lower mean accuracy than text or image modalities.",
            "uuids": [
                "e5357.1"
            ]
        }
    ],
    "special_cases": [
        "For graphs with low motif density or high homophily, motif attachment encodings may provide little or no benefit.",
        "In very large graphs, computing motif attachment lists may be computationally infeasible, limiting practical application.",
        "Motif attachment lists may be less effective when motifs are not discriminative for the target task (e.g., in graphs where all nodes participate in similar motifs)."
    ],
    "existing_theory": {
        "what_already_exists": "Motif features are used in GNNs and graph mining, but not as explicit attachment lists for LLMs.",
        "what_is_novel": "The use of motif attachment lists as a local structural fingerprint for LLM-based graph-to-text representations, and the explicit claim of their superiority for hard, heterophilous graph problems, is novel.",
        "classification_explanation": "This is a new, empirically supported theory specific to LLM-based graph-to-text conversion for hard graph problems, not previously formalized in the literature.",
        "likely_classification": "new",
        "references": [
            "Wang et al. (2023) Which Modality should I use - Text, Motif, or Image? [motif attachment, LLM graph encoding]"
        ]
    },
    "reflected_from_theory_index": 2,
    "version": "built-theory-from-results-single-theory-reflection2-nov14-2025",
    "type": "specific"
}</code></pre>
        </div>
    </div>
</body>
</html>