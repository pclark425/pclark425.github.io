<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LLM-Driven Extraction of Biomedical Gene–Disease Association Laws via Abstract Aggregation - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-659</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-659</p>
                <p><strong>Name:</strong> LLM-Driven Extraction of Biomedical Gene–Disease Association Laws via Abstract Aggregation</p>
                <p><strong>Type:</strong> specific</p>
                <p><strong>Theory Query:</strong> Build a theory of how large language models (LLMs) can be used to distill qualitative laws from large numbers of scholarly input papers, based on the following results.</p>
                <p><strong>Description:</strong> This theory posits that large language models (LLMs), when prompted with concatenated abstracts of top-retrieved papers for a given gene, can distill qualitative association laws between genes and diseases by leveraging both frequency and strength cues in the text. The accuracy of these distilled laws increases with the number of abstracts provided, and the process is robust to moderate prompt engineering. The approach is limited by the quality and coverage of the retrieved abstracts, the specificity of the literature, and is most effective for well-studied gene–disease pairs. The method is less reliable for rare genes, multi-topic abstracts, or when the LLM's pretraining knowledge contaminates the extraction.</p>
                <p><strong>Knowledge Cutoff Year:</strong> 2024</p>
                <p><strong>Knowledge Cutoff Month:</strong> 6</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <h3>Statement 0: Frequency-Strength Aggregation Law for Gene–Disease Association (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; LLM &#8594; is_prompted_with &#8594; concatenated_abstracts_about_gene_X<span style="color: #888888;">, and</span></div>
        <div>&#8226; disease_Y &#8594; is_frequently_and_strongly_described &#8594; in_abstracts_about_gene_X</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; LLM &#8594; will_rank &#8594; disease_Y_as_associated_with_gene_X</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>LLM-powered gene–disease distillation framework recovers known associations with increasing accuracy as more abstracts are provided; frequency and strength language in abstracts drive ranking. For example, GPT-4 summarized abstracts stating 'Mutations in the PSEN1 gene ... are the most common cause of familial Alzheimer's disease (fAD)' and 'around 20% of recorded PSEN1 mutations ... associated with epileptic seizures', and produced a ranked output with Alzheimer's disease top and genetic epilepsy syndrome second, demonstrating capture of both frequency and strength language ('most common', '20%') to form qualitative association judgments. <a href="../results/extraction-result-5749.html#e5749.0" class="evidence-link">[e5749.0]</a> </li>
    <li>The framework uses prompt-engineered queries to GPT-4 that (a) restrict the model to provided text, (b) instruct ranking rules (frequency and strength of reported association), (c) perform three independent queries and aggregate by frequency for a final ranking. <a href="../results/extraction-result-5749.html#e5749.0" class="evidence-link">[e5749.0]</a> </li>
    <li>Case studies (e.g., PSEN1) show GPT-4 extracting explicit association phrases and statistics and ranking Alzheimer's disease above other diseases. <a href="../results/extraction-result-5749.html#e5749.0" class="evidence-link">[e5749.0]</a> </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> Traditional methods use co-occurrence and statistical association, but LLMs' ability to synthesize context-sensitive associations from free text, including nuanced language cues, is new.</p>            <p><strong>What Already Exists:</strong> Frequency-based aggregation and co-occurrence analysis are used in traditional text mining for association extraction.</p>            <p><strong>What is Novel:</strong> The use of LLMs to synthesize and rank associations by combining nuanced frequency and strength cues in natural language across many abstracts, with explicit prompt restriction and ranking logic, is novel.</p>
            <p><strong>References:</strong> <ul>
    <li>Zheng et al. (2023) Large language models for scientific synthesis, inference and explanation [LLM-based synthesis, but not for gene–disease association]</li>
    <li>BioGPT (2022) [LLM for biomedical relation extraction, but not frequency-strength aggregation]</li>
</ul>
            <h3>Statement 1: Recall Increases with Number of Abstracts (quantitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; number_of_abstracts_N &#8594; is_increased &#8594; for_gene_X</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; LLM_recall_of_true_association &#8594; increases &#8594; with_N</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Hit ratio for correct gene–disease association increases from ~23% to ~54% as N increases from 10 to 20 abstracts. For N=10 top papers, HR values were low (e.g., HR@10 ≈ 23.3%), while for N=20 HR improved substantially (e.g., HR@10 ≈ 53.9%, HR@20 ≈ 59.55%). <a href="../results/extraction-result-5749.html#e5749.0" class="evidence-link">[e5749.0]</a> </li>
    <li>Overall, increasing N (more source abstracts) improves recall, demonstrating LLMs' ability to synthesize recurrent qualitative associations from many papers but with only moderate accuracy depending on retrieval breadth. <a href="../results/extraction-result-5749.html#e5749.0" class="evidence-link">[e5749.0]</a> </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> General principle is known, but its specific application and quantification in LLM-based gene–disease law distillation is new.</p>            <p><strong>What Already Exists:</strong> Recall increasing with more data is a general principle in information retrieval.</p>            <p><strong>What is Novel:</strong> The quantitative relationship between number of abstracts and LLM-based association recall in this biomedical context is new.</p>
            <p><strong>References:</strong> <ul>
    <li>Zheng et al. (2023) Large language models for scientific synthesis, inference and explanation [LLM-based synthesis, but not this quantitative law]</li>
</ul>
            <h3>Statement 2: Prompt Restriction Reduces Hallucination but Does Not Eliminate Pretraining Leakage (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; LLM &#8594; is_prompted_with &#8594; explicit instruction to use only provided abstracts</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; LLM &#8594; reduces &#8594; hallucinated associations<span style="color: #888888;">, and</span></div>
        <div>&#8226; LLM &#8594; may_still_use &#8594; internal pretraining knowledge</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>The framework uses prompt restrictions to instruct the LLM to only use provided text, but the paper notes the inability to fully rule out LLM reliance on internal pretraining knowledge despite prompt restrictions. <a href="../results/extraction-result-5749.html#e5749.0" class="evidence-link">[e5749.0]</a> </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> Prompt restriction is established, but the specific challenge of pretraining leakage in law extraction from concatenated abstracts is newly highlighted.</p>            <p><strong>What Already Exists:</strong> Prompt restriction is a known method to reduce hallucination in LLMs.</p>            <p><strong>What is Novel:</strong> Explicit demonstration that even with prompt restriction, LLMs may still draw on pretraining knowledge, affecting the purity of literature-derived law extraction.</p>
            <p><strong>References:</strong> <ul>
    <li>RAG+RLHF (e5765.3) [Prompting and retrieval-augmentation to reduce hallucination]</li>
    <li>LLMs-as-knowledge-bases (e5757.0) [LLMs encode knowledge from pretraining, which can leak into outputs]</li>
</ul>
            <h3>Statement 3: Association Extraction is Limited by Abstract Quality and Topic Specificity (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; abstracts_about_gene_X &#8594; are_sparse_or_multi-topic &#8594; True</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; LLM &#8594; may_incorrectly_attribute &#8594; diseases mentioned in abstracts to gene_X</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>The model can incorrectly attribute diseases mentioned in multi-topic papers to the target gene (false associations) when full context is not preserved. <a href="../results/extraction-result-5749.html#e5749.0" class="evidence-link">[e5749.0]</a> </li>
    <li>Dependence on retrieved literature quality and quantity—small N limits recall; using only abstracts may miss evidence in full text. <a href="../results/extraction-result-5749.html#e5749.0" class="evidence-link">[e5749.0]</a> </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> closely-related-to-existing</p>
            <p><strong>Explanation:</strong> Known in traditional methods, but the persistence of this limitation in LLM-based law extraction is newly confirmed.</p>            <p><strong>What Already Exists:</strong> Limitations of co-occurrence-based extraction in multi-topic or sparse literature are known in text mining.</p>            <p><strong>What is Novel:</strong> Demonstration that LLMs, even with advanced language understanding, are still subject to these limitations in the context of law extraction from biomedical abstracts.</p>
            <p><strong>References:</strong> <ul>
    <li>Traditional text mining literature on co-occurrence and topic drift</li>
    <li>LLM-powered gene–disease distillation (e5749.0) [explicitly discusses this limitation]</li>
</ul>
            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>If the number of abstracts per gene is increased to 30 or 40, recall of true gene–disease associations will further increase, up to a saturation point.</li>
                <li>For genes with sparse literature, the LLM will produce less accurate or more uncertain association rankings.</li>
                <li>If the abstracts are filtered for higher specificity (e.g., only disease-focused studies), the precision of the top-ranked associations will improve.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>Applying this method to rare or newly discovered genes may yield novel, previously unreported disease associations that could be validated experimentally.</li>
                <li>If the approach is extended to full-text articles (not just abstracts), the accuracy and depth of association laws may improve, but with increased risk of spurious associations due to context fragmentation.</li>
                <li>If LLMs are fine-tuned on domain-specific corpora with explicit negative examples, the false positive rate in association extraction may decrease.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>If increasing the number of abstracts does not improve recall, or if the LLM begins to hallucinate associations not present in the text, the theory would be challenged.</li>
                <li>If the LLM fails to rank well-established gene–disease associations highly even with many abstracts, the theory would be called into question.</li>
                <li>If prompt restriction fails to reduce hallucinated associations compared to unrestricted prompting, the theory's assumptions about LLM behavior would be undermined.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>The method may not generalize to associations that are only weakly or indirectly described in the literature, or to multi-gene/multi-disease relationships. <a href="../results/extraction-result-5749.html#e5749.0" class="evidence-link">[e5749.0]</a> </li>
    <li>The evaluation was limited to genes associated with a single disease family (Alzheimer's) and thus not yet shown broadly across domains. <a href="../results/extraction-result-5749.html#e5749.0" class="evidence-link">[e5749.0]</a> </li>
    <li>LLMs struggle with very long full-text documents (prompt length constraints) leading to slow performance and potential errors when processing whole papers. <a href="../results/extraction-result-5749.html#e5749.0" class="evidence-link">[e5749.0]</a> </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> somewhat-related-to-existing</p>
            <p><strong>Explanation:</strong> The approach builds on existing text mining but leverages LLMs' language understanding for more nuanced law extraction, and highlights new limitations and behaviors specific to LLMs.</p>
            <p><strong>References:</strong> <ul>
    <li>Zheng et al. (2023) Large language models for scientific synthesis, inference and explanation [LLM-based synthesis, but not for gene–disease association]</li>
    <li>BioGPT (2022) [LLM for biomedical relation extraction, but not frequency-strength aggregation]</li>
    <li>LLMs-as-knowledge-bases (e5757.0) [LLMs encode knowledge from pretraining, which can leak into outputs]</li>
    <li>RAG+RLHF (e5765.3) [Prompting and retrieval-augmentation to reduce hallucination]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "LLM-Driven Extraction of Biomedical Gene–Disease Association Laws via Abstract Aggregation",
    "theory_description": "This theory posits that large language models (LLMs), when prompted with concatenated abstracts of top-retrieved papers for a given gene, can distill qualitative association laws between genes and diseases by leveraging both frequency and strength cues in the text. The accuracy of these distilled laws increases with the number of abstracts provided, and the process is robust to moderate prompt engineering. The approach is limited by the quality and coverage of the retrieved abstracts, the specificity of the literature, and is most effective for well-studied gene–disease pairs. The method is less reliable for rare genes, multi-topic abstracts, or when the LLM's pretraining knowledge contaminates the extraction.",
    "theory_statements": [
        {
            "law": {
                "law_name": "Frequency-Strength Aggregation Law for Gene–Disease Association",
                "if": [
                    {
                        "subject": "LLM",
                        "relation": "is_prompted_with",
                        "object": "concatenated_abstracts_about_gene_X"
                    },
                    {
                        "subject": "disease_Y",
                        "relation": "is_frequently_and_strongly_described",
                        "object": "in_abstracts_about_gene_X"
                    }
                ],
                "then": [
                    {
                        "subject": "LLM",
                        "relation": "will_rank",
                        "object": "disease_Y_as_associated_with_gene_X"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "LLM-powered gene–disease distillation framework recovers known associations with increasing accuracy as more abstracts are provided; frequency and strength language in abstracts drive ranking. For example, GPT-4 summarized abstracts stating 'Mutations in the PSEN1 gene ... are the most common cause of familial Alzheimer's disease (fAD)' and 'around 20% of recorded PSEN1 mutations ... associated with epileptic seizures', and produced a ranked output with Alzheimer's disease top and genetic epilepsy syndrome second, demonstrating capture of both frequency and strength language ('most common', '20%') to form qualitative association judgments.",
                        "uuids": [
                            "e5749.0"
                        ]
                    },
                    {
                        "text": "The framework uses prompt-engineered queries to GPT-4 that (a) restrict the model to provided text, (b) instruct ranking rules (frequency and strength of reported association), (c) perform three independent queries and aggregate by frequency for a final ranking.",
                        "uuids": [
                            "e5749.0"
                        ]
                    },
                    {
                        "text": "Case studies (e.g., PSEN1) show GPT-4 extracting explicit association phrases and statistics and ranking Alzheimer's disease above other diseases.",
                        "uuids": [
                            "e5749.0"
                        ]
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Frequency-based aggregation and co-occurrence analysis are used in traditional text mining for association extraction.",
                    "what_is_novel": "The use of LLMs to synthesize and rank associations by combining nuanced frequency and strength cues in natural language across many abstracts, with explicit prompt restriction and ranking logic, is novel.",
                    "classification_explanation": "Traditional methods use co-occurrence and statistical association, but LLMs' ability to synthesize context-sensitive associations from free text, including nuanced language cues, is new.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Zheng et al. (2023) Large language models for scientific synthesis, inference and explanation [LLM-based synthesis, but not for gene–disease association]",
                        "BioGPT (2022) [LLM for biomedical relation extraction, but not frequency-strength aggregation]"
                    ]
                }
            }
        },
        {
            "law": {
                "law_name": "Recall Increases with Number of Abstracts",
                "if": [
                    {
                        "subject": "number_of_abstracts_N",
                        "relation": "is_increased",
                        "object": "for_gene_X"
                    }
                ],
                "then": [
                    {
                        "subject": "LLM_recall_of_true_association",
                        "relation": "increases",
                        "object": "with_N"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Hit ratio for correct gene–disease association increases from ~23% to ~54% as N increases from 10 to 20 abstracts. For N=10 top papers, HR values were low (e.g., HR@10 ≈ 23.3%), while for N=20 HR improved substantially (e.g., HR@10 ≈ 53.9%, HR@20 ≈ 59.55%).",
                        "uuids": [
                            "e5749.0"
                        ]
                    },
                    {
                        "text": "Overall, increasing N (more source abstracts) improves recall, demonstrating LLMs' ability to synthesize recurrent qualitative associations from many papers but with only moderate accuracy depending on retrieval breadth.",
                        "uuids": [
                            "e5749.0"
                        ]
                    }
                ],
                "qual_or_quant": "quantitative",
                "existing_law": {
                    "what_already_exists": "Recall increasing with more data is a general principle in information retrieval.",
                    "what_is_novel": "The quantitative relationship between number of abstracts and LLM-based association recall in this biomedical context is new.",
                    "classification_explanation": "General principle is known, but its specific application and quantification in LLM-based gene–disease law distillation is new.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Zheng et al. (2023) Large language models for scientific synthesis, inference and explanation [LLM-based synthesis, but not this quantitative law]"
                    ]
                }
            }
        },
        {
            "law": {
                "law_name": "Prompt Restriction Reduces Hallucination but Does Not Eliminate Pretraining Leakage",
                "if": [
                    {
                        "subject": "LLM",
                        "relation": "is_prompted_with",
                        "object": "explicit instruction to use only provided abstracts"
                    }
                ],
                "then": [
                    {
                        "subject": "LLM",
                        "relation": "reduces",
                        "object": "hallucinated associations"
                    },
                    {
                        "subject": "LLM",
                        "relation": "may_still_use",
                        "object": "internal pretraining knowledge"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "The framework uses prompt restrictions to instruct the LLM to only use provided text, but the paper notes the inability to fully rule out LLM reliance on internal pretraining knowledge despite prompt restrictions.",
                        "uuids": [
                            "e5749.0"
                        ]
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Prompt restriction is a known method to reduce hallucination in LLMs.",
                    "what_is_novel": "Explicit demonstration that even with prompt restriction, LLMs may still draw on pretraining knowledge, affecting the purity of literature-derived law extraction.",
                    "classification_explanation": "Prompt restriction is established, but the specific challenge of pretraining leakage in law extraction from concatenated abstracts is newly highlighted.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "RAG+RLHF (e5765.3) [Prompting and retrieval-augmentation to reduce hallucination]",
                        "LLMs-as-knowledge-bases (e5757.0) [LLMs encode knowledge from pretraining, which can leak into outputs]"
                    ]
                }
            }
        },
        {
            "law": {
                "law_name": "Association Extraction is Limited by Abstract Quality and Topic Specificity",
                "if": [
                    {
                        "subject": "abstracts_about_gene_X",
                        "relation": "are_sparse_or_multi-topic",
                        "object": "True"
                    }
                ],
                "then": [
                    {
                        "subject": "LLM",
                        "relation": "may_incorrectly_attribute",
                        "object": "diseases mentioned in abstracts to gene_X"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "The model can incorrectly attribute diseases mentioned in multi-topic papers to the target gene (false associations) when full context is not preserved.",
                        "uuids": [
                            "e5749.0"
                        ]
                    },
                    {
                        "text": "Dependence on retrieved literature quality and quantity—small N limits recall; using only abstracts may miss evidence in full text.",
                        "uuids": [
                            "e5749.0"
                        ]
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Limitations of co-occurrence-based extraction in multi-topic or sparse literature are known in text mining.",
                    "what_is_novel": "Demonstration that LLMs, even with advanced language understanding, are still subject to these limitations in the context of law extraction from biomedical abstracts.",
                    "classification_explanation": "Known in traditional methods, but the persistence of this limitation in LLM-based law extraction is newly confirmed.",
                    "likely_classification": "closely-related-to-existing",
                    "references": [
                        "Traditional text mining literature on co-occurrence and topic drift",
                        "LLM-powered gene–disease distillation (e5749.0) [explicitly discusses this limitation]"
                    ]
                }
            }
        }
    ],
    "new_predictions_likely": [
        "If the number of abstracts per gene is increased to 30 or 40, recall of true gene–disease associations will further increase, up to a saturation point.",
        "For genes with sparse literature, the LLM will produce less accurate or more uncertain association rankings.",
        "If the abstracts are filtered for higher specificity (e.g., only disease-focused studies), the precision of the top-ranked associations will improve."
    ],
    "new_predictions_unknown": [
        "Applying this method to rare or newly discovered genes may yield novel, previously unreported disease associations that could be validated experimentally.",
        "If the approach is extended to full-text articles (not just abstracts), the accuracy and depth of association laws may improve, but with increased risk of spurious associations due to context fragmentation.",
        "If LLMs are fine-tuned on domain-specific corpora with explicit negative examples, the false positive rate in association extraction may decrease."
    ],
    "negative_experiments": [
        "If increasing the number of abstracts does not improve recall, or if the LLM begins to hallucinate associations not present in the text, the theory would be challenged.",
        "If the LLM fails to rank well-established gene–disease associations highly even with many abstracts, the theory would be called into question.",
        "If prompt restriction fails to reduce hallucinated associations compared to unrestricted prompting, the theory's assumptions about LLM behavior would be undermined."
    ],
    "unaccounted_for": [
        {
            "text": "The method may not generalize to associations that are only weakly or indirectly described in the literature, or to multi-gene/multi-disease relationships.",
            "uuids": [
                "e5749.0"
            ]
        },
        {
            "text": "The evaluation was limited to genes associated with a single disease family (Alzheimer's) and thus not yet shown broadly across domains.",
            "uuids": [
                "e5749.0"
            ]
        },
        {
            "text": "LLMs struggle with very long full-text documents (prompt length constraints) leading to slow performance and potential errors when processing whole papers.",
            "uuids": [
                "e5749.0"
            ]
        }
    ],
    "conflicting_evidence": [],
    "special_cases": [
        "For genes with ambiguous or multi-topic abstracts, the LLM may incorrectly attribute diseases mentioned in the text to the target gene.",
        "If the LLM's pretraining corpus already contains the association, it may not be possible to distinguish between retrieval from prompt and internal knowledge.",
        "If the abstracts contain contradictory or outdated information, the LLM's ranking may reflect historical rather than current consensus."
    ],
    "existing_theory": {
        "what_already_exists": "Frequency-based association extraction and co-occurrence analysis are established in text mining and biomedical informatics.",
        "what_is_novel": "LLM-based synthesis and ranking using nuanced language cues across many abstracts, with explicit prompt restriction and aggregation logic, is new. The explicit demonstration of recall scaling with number of abstracts and the persistence of pretraining leakage are also novel in this context.",
        "classification_explanation": "The approach builds on existing text mining but leverages LLMs' language understanding for more nuanced law extraction, and highlights new limitations and behaviors specific to LLMs.",
        "likely_classification": "somewhat-related-to-existing",
        "references": [
            "Zheng et al. (2023) Large language models for scientific synthesis, inference and explanation [LLM-based synthesis, but not for gene–disease association]",
            "BioGPT (2022) [LLM for biomedical relation extraction, but not frequency-strength aggregation]",
            "LLMs-as-knowledge-bases (e5757.0) [LLMs encode knowledge from pretraining, which can leak into outputs]",
            "RAG+RLHF (e5765.3) [Prompting and retrieval-augmentation to reduce hallucination]"
        ]
    },
    "reflected_from_theory_index": 2,
    "version": "built-theory-from-results-single-theory-reflection2-nov14-2025",
    "type": "specific"
}</code></pre>
        </div>
    </div>
</body>
</html>