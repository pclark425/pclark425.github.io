<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Completeness-Dependence Law for LLM Revision in Spatial Planning - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-486</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-486</p>
                <p><strong>Name:</strong> Completeness-Dependence Law for LLM Revision in Spatial Planning</p>
                <p><strong>Type:</strong> specific</p>
                <p><strong>Theory Query:</strong> Build a theory of how language models solve puzzle games involving spatial knowledge, like Sudoku, based on the following results.</p>
                <p><strong>Description:</strong> The effectiveness of LLM-based revision in spatial planning tasks (such as XoT on Pocket Cube and 8-Puzzle) is highly sensitive to the completeness of the intermediate thought trajectory provided to the LLM. Incomplete or partial state sequences drastically reduce the LLM's ability to revise or correct solutions, indicating that LLMs rely on explicit, stepwise state information to perform spatial reasoning and cannot reliably 'imagine' or interpolate missing spatial transitions. This law is specific to spatial planning tasks that require multi-step state tracking, and is not necessarily generalizable to non-spatial or single-step tasks.</p>
                <p><strong>Knowledge Cutoff Year:</strong> 2024</p>
                <p><strong>Knowledge Cutoff Month:</strong> 6</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <h3>Statement 0: Completeness Sensitivity Law (quantitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; LLM &#8594; is_provided_with &#8594; incomplete or partial sequence of spatial states (thoughts)<span style="color: #888888;">, and</span></div>
        <div>&#8226; task &#8594; requires &#8594; multi-step spatial planning or revision</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; LLM &#8594; exhibits &#8594; drastically reduced revision accuracy (e.g., near-zero on Pocket Cube)</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Ablation in XoT: incomplete thoughts cause Pocket Cube accuracy to drop to ~6%, compared to >77% with complete thoughts. <a href="../results/extraction-result-3108.html#e3108.1" class="evidence-link">[e3108.1]</a> </li>
    <li>XOT+GPT-4 (Pocket Cube): Providing explicit, complete MCTS trajectories (stateful rotations) enables high revision accuracy; incomplete or missing steps cause large performance drops. <a href="../results/extraction-result-3108.html#e3108.1" class="evidence-link">[e3108.1]</a> </li>
    <li>XoT on 8-Puzzle: High accuracy (93.2%) is achieved when LLMs are provided with full, stepwise state sequences for revision. <a href="../results/extraction-result-3106.html#e3106.2" class="evidence-link">[e3106.2]</a> </li>
    <li>MCTS-only (no LLM): Without LLM revision, MCTS yields lower-quality or suboptimal trajectories, but the addition of a single LLM revision (with full state sequence) substantially raises accuracy. <a href="../results/extraction-result-3108.html#e3108.3" class="evidence-link">[e3108.3]</a> </li>
    <li>LLaMA-2-13B (finetuned): Finetuning on input-output pairs without explicit stepwise state information leads to near-zero accuracy on spatial planning tasks (0% on 8-Puzzle and Pocket Cube), indicating that the model cannot interpolate missing spatial transitions. <a href="../results/extraction-result-3108.html#e3108.4" class="evidence-link">[e3108.4]</a> </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p class="empty-note">No existing law comparison provided.</p>
            <h3>Statement 1: Explicit State Trajectory Law (quantitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; LLM &#8594; is_provided_with &#8594; complete, explicit, stepwise sequence of spatial states (thoughts)<span style="color: #888888;">, and</span></div>
        <div>&#8226; task &#8594; requires &#8594; multi-step spatial planning or revision</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; LLM &#8594; achieves &#8594; high revision accuracy (e.g., >77% on Pocket Cube, >93% on 8-Puzzle)</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>XOT+GPT-4 (Pocket Cube): With complete MCTS trajectories, GPT-4 achieves 77.6% (1 revision) and 83.6% (3 revisions) accuracy. <a href="../results/extraction-result-3108.html#e3108.1" class="evidence-link">[e3108.1]</a> </li>
    <li>XoT on 8-Puzzle: Providing full, stepwise state sequences enables 93.2% accuracy across 419 8-Puzzle instances. <a href="../results/extraction-result-3106.html#e3106.2" class="evidence-link">[e3106.2]</a> </li>
    <li>MCTS-only (no LLM): MCTS alone achieves 46.44% on Pocket Cube, but with LLM revision (using full state sequence), accuracy rises to 77.6%. <a href="../results/extraction-result-3108.html#e3108.3" class="evidence-link">[e3108.3]</a> </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p class="empty-note">No existing law comparison provided.</p>
            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>Providing LLMs with only partial move sequences or missing intermediate states in any spatial planning task (e.g., Rubik's Cube, sliding puzzles, Blocksworld) will result in near-chance or drastically reduced revision accuracy.</li>
                <li>Augmenting LLM prompts with complete, stepwise state transitions will restore or greatly improve revision accuracy in spatial planning tasks, even for complex puzzles.</li>
                <li>If a spatial planning task is reformulated to provide only the initial and final states (without intermediate steps), LLM-based revision will fail to reliably correct or improve solutions.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>If LLMs are trained with massive exposure to incomplete spatial trajectories and forced to interpolate missing states, they may develop some ability to 'imagine' or reconstruct missing spatial transitions, partially mitigating completeness sensitivity.</li>
                <li>Future LLMs with larger context windows, more advanced training, or explicit spatial world-model modules may become less sensitive to completeness, but this is currently unproven.</li>
                <li>If LLMs are provided with partial state sequences but also with external symbolic reasoning tools (e.g., search or simulation modules), they may be able to compensate for missing information.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>If an LLM is able to revise or correct spatial plans with high accuracy when given only partial or incomplete state sequences, this would falsify the completeness sensitivity law.</li>
                <li>If providing more complete state sequences does not improve revision accuracy in spatial planning tasks, the law would be challenged.</li>
                <li>If an LLM trained only on input-output pairs (without intermediate states) achieves high accuracy on spatial planning revision, the law would be called into question.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>Some non-spatial planning tasks (e.g., arithmetic or symbolic reasoning, such as Game of 24) may not show the same sensitivity to completeness of intermediate steps. <a href="../results/extraction-result-3374.html#e3374.1" class="evidence-link">[e3374.1]</a> </li>
    <li>Tasks with very short planning horizons (1-2 steps) may be less sensitive to completeness, as the LLM may be able to interpolate or guess missing transitions. </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> new</p>
            <p><strong>Explanation:</strong> No explanation provided.</p>
            <p><strong>References:</strong> <ul>
    <li>Ding et al. (2023) Everything of Thoughts: Defying the Law of Penrose Triangle for Thought Generation [Ablation on completeness, but no formal law stated]</li>
    <li>XOT+GPT-4 (Pocket Cube) and XoT on 8-Puzzle (Ding et al. 2023) [Empirical ablation, but not formalized as a general law]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Completeness-Dependence Law for LLM Revision in Spatial Planning",
    "theory_description": "The effectiveness of LLM-based revision in spatial planning tasks (such as XoT on Pocket Cube and 8-Puzzle) is highly sensitive to the completeness of the intermediate thought trajectory provided to the LLM. Incomplete or partial state sequences drastically reduce the LLM's ability to revise or correct solutions, indicating that LLMs rely on explicit, stepwise state information to perform spatial reasoning and cannot reliably 'imagine' or interpolate missing spatial transitions. This law is specific to spatial planning tasks that require multi-step state tracking, and is not necessarily generalizable to non-spatial or single-step tasks.",
    "theory_statements": [
        {
            "law": {
                "law_name": "Completeness Sensitivity Law",
                "if": [
                    {
                        "subject": "LLM",
                        "relation": "is_provided_with",
                        "object": "incomplete or partial sequence of spatial states (thoughts)"
                    },
                    {
                        "subject": "task",
                        "relation": "requires",
                        "object": "multi-step spatial planning or revision"
                    }
                ],
                "then": [
                    {
                        "subject": "LLM",
                        "relation": "exhibits",
                        "object": "drastically reduced revision accuracy (e.g., near-zero on Pocket Cube)"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Ablation in XoT: incomplete thoughts cause Pocket Cube accuracy to drop to ~6%, compared to &gt;77% with complete thoughts.",
                        "uuids": [
                            "e3108.1"
                        ]
                    },
                    {
                        "text": "XOT+GPT-4 (Pocket Cube): Providing explicit, complete MCTS trajectories (stateful rotations) enables high revision accuracy; incomplete or missing steps cause large performance drops.",
                        "uuids": [
                            "e3108.1"
                        ]
                    },
                    {
                        "text": "XoT on 8-Puzzle: High accuracy (93.2%) is achieved when LLMs are provided with full, stepwise state sequences for revision.",
                        "uuids": [
                            "e3106.2"
                        ]
                    },
                    {
                        "text": "MCTS-only (no LLM): Without LLM revision, MCTS yields lower-quality or suboptimal trajectories, but the addition of a single LLM revision (with full state sequence) substantially raises accuracy.",
                        "uuids": [
                            "e3108.3"
                        ]
                    },
                    {
                        "text": "LLaMA-2-13B (finetuned): Finetuning on input-output pairs without explicit stepwise state information leads to near-zero accuracy on spatial planning tasks (0% on 8-Puzzle and Pocket Cube), indicating that the model cannot interpolate missing spatial transitions.",
                        "uuids": [
                            "e3108.4"
                        ]
                    }
                ],
                "qual_or_quant": "quantitative"
            }
        },
        {
            "law": {
                "law_name": "Explicit State Trajectory Law",
                "if": [
                    {
                        "subject": "LLM",
                        "relation": "is_provided_with",
                        "object": "complete, explicit, stepwise sequence of spatial states (thoughts)"
                    },
                    {
                        "subject": "task",
                        "relation": "requires",
                        "object": "multi-step spatial planning or revision"
                    }
                ],
                "then": [
                    {
                        "subject": "LLM",
                        "relation": "achieves",
                        "object": "high revision accuracy (e.g., &gt;77% on Pocket Cube, &gt;93% on 8-Puzzle)"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "XOT+GPT-4 (Pocket Cube): With complete MCTS trajectories, GPT-4 achieves 77.6% (1 revision) and 83.6% (3 revisions) accuracy.",
                        "uuids": [
                            "e3108.1"
                        ]
                    },
                    {
                        "text": "XoT on 8-Puzzle: Providing full, stepwise state sequences enables 93.2% accuracy across 419 8-Puzzle instances.",
                        "uuids": [
                            "e3106.2"
                        ]
                    },
                    {
                        "text": "MCTS-only (no LLM): MCTS alone achieves 46.44% on Pocket Cube, but with LLM revision (using full state sequence), accuracy rises to 77.6%.",
                        "uuids": [
                            "e3108.3"
                        ]
                    }
                ],
                "qual_or_quant": "quantitative"
            }
        }
    ],
    "new_predictions_likely": [
        "Providing LLMs with only partial move sequences or missing intermediate states in any spatial planning task (e.g., Rubik's Cube, sliding puzzles, Blocksworld) will result in near-chance or drastically reduced revision accuracy.",
        "Augmenting LLM prompts with complete, stepwise state transitions will restore or greatly improve revision accuracy in spatial planning tasks, even for complex puzzles.",
        "If a spatial planning task is reformulated to provide only the initial and final states (without intermediate steps), LLM-based revision will fail to reliably correct or improve solutions."
    ],
    "new_predictions_unknown": [
        "If LLMs are trained with massive exposure to incomplete spatial trajectories and forced to interpolate missing states, they may develop some ability to 'imagine' or reconstruct missing spatial transitions, partially mitigating completeness sensitivity.",
        "Future LLMs with larger context windows, more advanced training, or explicit spatial world-model modules may become less sensitive to completeness, but this is currently unproven.",
        "If LLMs are provided with partial state sequences but also with external symbolic reasoning tools (e.g., search or simulation modules), they may be able to compensate for missing information."
    ],
    "negative_experiments": [
        "If an LLM is able to revise or correct spatial plans with high accuracy when given only partial or incomplete state sequences, this would falsify the completeness sensitivity law.",
        "If providing more complete state sequences does not improve revision accuracy in spatial planning tasks, the law would be challenged.",
        "If an LLM trained only on input-output pairs (without intermediate states) achieves high accuracy on spatial planning revision, the law would be called into question."
    ],
    "unaccounted_for": [
        {
            "text": "Some non-spatial planning tasks (e.g., arithmetic or symbolic reasoning, such as Game of 24) may not show the same sensitivity to completeness of intermediate steps.",
            "uuids": [
                "e3374.1"
            ]
        },
        {
            "text": "Tasks with very short planning horizons (1-2 steps) may be less sensitive to completeness, as the LLM may be able to interpolate or guess missing transitions.",
            "uuids": []
        }
    ],
    "conflicting_evidence": [],
    "special_cases": [
        "Tasks with very short planning horizons (1-2 steps) may be less sensitive to completeness.",
        "If the LLM is fine-tuned specifically for interpolation or state reconstruction, the law may not hold.",
        "Non-spatial or purely symbolic tasks may not exhibit completeness sensitivity.",
        "If the LLM is provided with an external world model or simulation tool, it may be able to reconstruct missing states."
    ],
    "existing_theory": {
        "likely_classification": "new",
        "references": [
            "Ding et al. (2023) Everything of Thoughts: Defying the Law of Penrose Triangle for Thought Generation [Ablation on completeness, but no formal law stated]",
            "XOT+GPT-4 (Pocket Cube) and XoT on 8-Puzzle (Ding et al. 2023) [Empirical ablation, but not formalized as a general law]"
        ]
    },
    "reflected_from_theory_index": 2,
    "version": "built-theory-from-results-single-theory-reflection2-nov13-2025",
    "type": "specific"
}</code></pre>
        </div>
    </div>
</body>
</html>