<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Multi-Axial Evaluation Theory for LLM-Generated Scientific Theories - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-2245</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-2245</p>
                <p><strong>Name:</strong> Multi-Axial Evaluation Theory for LLM-Generated Scientific Theories</p>
                <p><strong>Type:</strong> general</p>
                <p><strong>Theory Query:</strong> Build a theory of how to evaluate LLM-generated scientific theories.</p>
                <p><strong>Description:</strong> This theory posits that the evaluation of LLM-generated scientific theories should be conducted along multiple, orthogonal axes: internal logical coherence, empirical adequacy, novelty, and epistemic utility. Each axis is necessary but not sufficient for overall theory acceptance, and the interplay between these axes determines the overall scientific value of an LLM-generated theory.</p>
                <p><strong>Knowledge Cutoff Year:</strong> -1</p>
                <p><strong>Knowledge Cutoff Month:</strong> -1</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <h3>Statement 0: Orthogonality of Evaluation Axes (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; LLM-generated theory &#8594; is_evaluated_on &#8594; logical coherence<span style="color: #888888;">, and</span></div>
        <div>&#8226; LLM-generated theory &#8594; is_evaluated_on &#8594; empirical adequacy<span style="color: #888888;">, and</span></div>
        <div>&#8226; LLM-generated theory &#8594; is_evaluated_on &#8594; novelty<span style="color: #888888;">, and</span></div>
        <div>&#8226; LLM-generated theory &#8594; is_evaluated_on &#8594; epistemic utility</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; evaluation axes &#8594; are_orthogonal &#8594; true</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Scientific theory evaluation in philosophy of science (e.g., Kuhn, Lakatos) emphasizes multiple, sometimes independent, criteria for theory choice. </li>
    <li>LLMs can generate theories that are internally coherent but empirically false, or empirically adequate but not novel. </li>
    <li>Empirical adequacy, logical coherence, novelty, and utility are often considered separately in peer review and scientific assessment. </li>
    <li>Orthogonality implies that a theory can score high on one axis and low on another, as observed in LLM outputs and human theory evaluation. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> While the axes themselves are known, their explicit orthogonality and necessity in the context of LLM-generated science is novel.</p>            <p><strong>What Already Exists:</strong> Multi-criteria theory evaluation is discussed in philosophy of science, but not formalized for LLM-generated theories.</p>            <p><strong>What is Novel:</strong> Explicitly formalizes the orthogonality and necessity of these four axes for LLM-generated theory evaluation.</p>
            <p><strong>References:</strong> <ul>
    <li>Kuhn (1962) The Structure of Scientific Revolutions [criteria for theory choice]</li>
    <li>Lakatos (1970) Falsification and the Methodology of Scientific Research Programmes [multiple criteria for theory evaluation]</li>
    <li>Longino (1990) Science as Social Knowledge [plurality of criteria in scientific evaluation]</li>
</ul>
            <h3>Statement 1: Interdependence and Threshold Law (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; LLM-generated theory &#8594; fails &#8594; any single evaluation axis</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; LLM-generated theory &#8594; is_rejected &#8594; as a scientific theory</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Scientific theories that are internally inconsistent, empirically inadequate, or lack utility are typically rejected. </li>
    <li>LLM-generated outputs can be plausible but fail on one or more axes, leading to rejection by human evaluators. </li>
    <li>Peer review processes often use threshold criteria for acceptance, such as logical consistency and empirical support. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> The threshold idea is known, but its application to LLM-generated science is new.</p>            <p><strong>What Already Exists:</strong> Threshold criteria for theory acceptance are discussed in philosophy of science.</p>            <p><strong>What is Novel:</strong> Applies a strict threshold model to LLM-generated theories, emphasizing the necessity of passing all axes.</p>
            <p><strong>References:</strong> <ul>
    <li>Popper (1959) The Logic of Scientific Discovery [falsifiability as a threshold]</li>
    <li>Thagard (1978) Why Astrology is a Pseudoscience [criteria for theory demarcation]</li>
    <li>Laudan (1983) The Demise of the Demarcation Problem [discussion of necessary criteria for science]</li>
</ul>
            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>If an LLM-generated theory is empirically adequate but internally inconsistent, it will be rejected by expert evaluators.</li>
                <li>If a theory is novel but lacks empirical support, it will not be accepted as a scientific contribution.</li>
                <li>If a theory is both novel and empirically adequate, it will be rated higher than a theory that is only empirically adequate.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>If a theory is highly novel and internally coherent but only partially empirically adequate, it may be provisionally accepted in fields with high uncertainty.</li>
                <li>If LLMs are trained on evaluation rubrics that weight axes differently, the relative importance of each axis may shift in future scientific practice.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>If a theory that fails on one axis (e.g., logical coherence) is nevertheless accepted by experts, this would challenge the threshold law.</li>
                <li>If empirical adequacy is not necessary for acceptance in some domains, the orthogonality and necessity of axes would be questioned.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>The role of social or institutional factors in theory acceptance is not addressed. </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> somewhat-related-to-existing</p>
            <p><strong>Explanation:</strong> The axes are known, but their formalization and application to LLM-generated science is new.</p>
            <p><strong>References:</strong> <ul>
    <li>Kuhn (1962) The Structure of Scientific Revolutions [criteria for theory choice]</li>
    <li>Popper (1959) The Logic of Scientific Discovery [falsifiability as a threshold]</li>
    <li>Thagard (1978) Why Astrology is a Pseudoscience [criteria for theory demarcation]</li>
    <li>Longino (1990) Science as Social Knowledge [plurality of criteria in scientific evaluation]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Multi-Axial Evaluation Theory for LLM-Generated Scientific Theories",
    "theory_description": "This theory posits that the evaluation of LLM-generated scientific theories should be conducted along multiple, orthogonal axes: internal logical coherence, empirical adequacy, novelty, and epistemic utility. Each axis is necessary but not sufficient for overall theory acceptance, and the interplay between these axes determines the overall scientific value of an LLM-generated theory.",
    "theory_statements": [
        {
            "law": {
                "law_name": "Orthogonality of Evaluation Axes",
                "if": [
                    {
                        "subject": "LLM-generated theory",
                        "relation": "is_evaluated_on",
                        "object": "logical coherence"
                    },
                    {
                        "subject": "LLM-generated theory",
                        "relation": "is_evaluated_on",
                        "object": "empirical adequacy"
                    },
                    {
                        "subject": "LLM-generated theory",
                        "relation": "is_evaluated_on",
                        "object": "novelty"
                    },
                    {
                        "subject": "LLM-generated theory",
                        "relation": "is_evaluated_on",
                        "object": "epistemic utility"
                    }
                ],
                "then": [
                    {
                        "subject": "evaluation axes",
                        "relation": "are_orthogonal",
                        "object": "true"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Scientific theory evaluation in philosophy of science (e.g., Kuhn, Lakatos) emphasizes multiple, sometimes independent, criteria for theory choice.",
                        "uuids": []
                    },
                    {
                        "text": "LLMs can generate theories that are internally coherent but empirically false, or empirically adequate but not novel.",
                        "uuids": []
                    },
                    {
                        "text": "Empirical adequacy, logical coherence, novelty, and utility are often considered separately in peer review and scientific assessment.",
                        "uuids": []
                    },
                    {
                        "text": "Orthogonality implies that a theory can score high on one axis and low on another, as observed in LLM outputs and human theory evaluation.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Multi-criteria theory evaluation is discussed in philosophy of science, but not formalized for LLM-generated theories.",
                    "what_is_novel": "Explicitly formalizes the orthogonality and necessity of these four axes for LLM-generated theory evaluation.",
                    "classification_explanation": "While the axes themselves are known, their explicit orthogonality and necessity in the context of LLM-generated science is novel.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Kuhn (1962) The Structure of Scientific Revolutions [criteria for theory choice]",
                        "Lakatos (1970) Falsification and the Methodology of Scientific Research Programmes [multiple criteria for theory evaluation]",
                        "Longino (1990) Science as Social Knowledge [plurality of criteria in scientific evaluation]"
                    ]
                }
            }
        },
        {
            "law": {
                "law_name": "Interdependence and Threshold Law",
                "if": [
                    {
                        "subject": "LLM-generated theory",
                        "relation": "fails",
                        "object": "any single evaluation axis"
                    }
                ],
                "then": [
                    {
                        "subject": "LLM-generated theory",
                        "relation": "is_rejected",
                        "object": "as a scientific theory"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Scientific theories that are internally inconsistent, empirically inadequate, or lack utility are typically rejected.",
                        "uuids": []
                    },
                    {
                        "text": "LLM-generated outputs can be plausible but fail on one or more axes, leading to rejection by human evaluators.",
                        "uuids": []
                    },
                    {
                        "text": "Peer review processes often use threshold criteria for acceptance, such as logical consistency and empirical support.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Threshold criteria for theory acceptance are discussed in philosophy of science.",
                    "what_is_novel": "Applies a strict threshold model to LLM-generated theories, emphasizing the necessity of passing all axes.",
                    "classification_explanation": "The threshold idea is known, but its application to LLM-generated science is new.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Popper (1959) The Logic of Scientific Discovery [falsifiability as a threshold]",
                        "Thagard (1978) Why Astrology is a Pseudoscience [criteria for theory demarcation]",
                        "Laudan (1983) The Demise of the Demarcation Problem [discussion of necessary criteria for science]"
                    ]
                }
            }
        }
    ],
    "new_predictions_likely": [
        "If an LLM-generated theory is empirically adequate but internally inconsistent, it will be rejected by expert evaluators.",
        "If a theory is novel but lacks empirical support, it will not be accepted as a scientific contribution.",
        "If a theory is both novel and empirically adequate, it will be rated higher than a theory that is only empirically adequate."
    ],
    "new_predictions_unknown": [
        "If a theory is highly novel and internally coherent but only partially empirically adequate, it may be provisionally accepted in fields with high uncertainty.",
        "If LLMs are trained on evaluation rubrics that weight axes differently, the relative importance of each axis may shift in future scientific practice."
    ],
    "negative_experiments": [
        "If a theory that fails on one axis (e.g., logical coherence) is nevertheless accepted by experts, this would challenge the threshold law.",
        "If empirical adequacy is not necessary for acceptance in some domains, the orthogonality and necessity of axes would be questioned."
    ],
    "unaccounted_for": [
        {
            "text": "The role of social or institutional factors in theory acceptance is not addressed.",
            "uuids": []
        }
    ],
    "conflicting_evidence": [
        {
            "text": "Some historical scientific theories were accepted despite lacking empirical adequacy at the time (e.g., string theory).",
            "uuids": []
        }
    ],
    "special_cases": [
        "In highly speculative or theoretical domains, the threshold for empirical adequacy may be relaxed.",
        "In interdisciplinary science, the axes may be weighted differently."
    ],
    "existing_theory": {
        "what_already_exists": "Multi-criteria evaluation is discussed in philosophy of science, but not formalized for LLM-generated theories.",
        "what_is_novel": "Explicit, orthogonal, and threshold-based evaluation axes for LLM-generated scientific theories.",
        "classification_explanation": "The axes are known, but their formalization and application to LLM-generated science is new.",
        "likely_classification": "somewhat-related-to-existing",
        "references": [
            "Kuhn (1962) The Structure of Scientific Revolutions [criteria for theory choice]",
            "Popper (1959) The Logic of Scientific Discovery [falsifiability as a threshold]",
            "Thagard (1978) Why Astrology is a Pseudoscience [criteria for theory demarcation]",
            "Longino (1990) Science as Social Knowledge [plurality of criteria in scientific evaluation]"
        ]
    },
    "reflected_from_theory_index": 0,
    "type": "general",
    "version": "built-theory-from-results-single-theory-reflection2-nov14-2025-LLM-BASELINE-no-evidence-without-matched-control-theory-name",
    "theory_query": "Build a theory of how to evaluate LLM-generated scientific theories.",
    "original_theory_id": "theory-676",
    "original_theory_name": "Multidimensional Evaluation Alignment Theory",
    "provide_matched_control_thery_name": false,
    "matched_control_theory_name": null,
    "model_str": "openai/gpt-4.1-2025-04-14"
}</code></pre>
        </div>
    </div>
</body>
</html>