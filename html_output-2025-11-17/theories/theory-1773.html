<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Contextual Consistency Theory of LM-based Anomaly Detection - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-1773</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-1773</p>
                <p><strong>Name:</strong> Contextual Consistency Theory of LM-based Anomaly Detection</p>
                <p><strong>Type:</strong> general</p>
                <p><strong>Theory Query:</strong> Build a theory of how language models can be used for detecting anomalies in lists of data.</p>
                <p><strong>Description:</strong> This theory posits that language models detect anomalies in lists by evaluating the contextual consistency of each item with respect to its surrounding items. Anomalies are identified as items whose presence disrupts the local or global coherence as modeled by the LM, regardless of their absolute frequency or probability. The theory emphasizes the role of context and relational structure, not just statistical rarity.</p>
                <p><strong>Knowledge Cutoff Year:</strong> -1</p>
                <p><strong>Knowledge Cutoff Month:</strong> -1</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <h3>Statement 0: Contextual Inconsistency Signals Anomaly (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; item_i &#8594; is_in &#8594; data_list<span style="color: #888888;">, and</span></div>
        <div>&#8226; context_window &#8594; surrounds &#8594; item_i<span style="color: #888888;">, and</span></div>
        <div>&#8226; LM &#8594; assigns_low_coherence_score &#8594; item_i_given_context_window</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; item_i &#8594; is_likely &#8594; anomaly</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>LMs are sensitive to local context and can detect disruptions in sequence coherence. </li>
    <li>Anomalies often manifest as contextually inconsistent items, even if their global frequency is not low. </li>
    <li>Studies in NLP show that LMs can detect grammatical or semantic errors based on context. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> closely-related-to-existing</p>
            <p><strong>Explanation:</strong> This law is closely-related-to-existing work in NLP, but its generalization to arbitrary lists is new.</p>            <p><strong>What Already Exists:</strong> LMs are known to model context and coherence in language and code.</p>            <p><strong>What is Novel:</strong> Applying contextual coherence as a general anomaly detection principle in arbitrary lists is novel.</p>
            <p><strong>References:</strong> <ul>
    <li>Devlin et al. (2018) BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding [Contextual modeling in LMs]</li>
    <li>Goldstein & Uchida (2016) A comparative evaluation of unsupervised anomaly detection algorithms for multivariate data [General anomaly detection]</li>
</ul>
            <h3>Statement 1: Relational Anomalies Can Be Detected Without Rarity (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; item_i &#8594; is_in &#8594; data_list<span style="color: #888888;">, and</span></div>
        <div>&#8226; item_i &#8594; is_frequent_in &#8594; training_data<span style="color: #888888;">, and</span></div>
        <div>&#8226; item_i &#8594; is_inconsistent_with &#8594; context_window</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; item_i &#8594; is_likely &#8594; anomaly</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Anomalies can be context-dependent, not just globally rare; e.g., a common value in an unusual position. </li>
    <li>LMs can flag contextually misplaced but frequent items as anomalous. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> This law is somewhat-related-to-existing, as it extends contextual anomaly detection to new domains.</p>            <p><strong>What Already Exists:</strong> Contextual anomaly detection is known in time series and NLP.</p>            <p><strong>What is Novel:</strong> Generalizing this to arbitrary lists and using LMs as the context model is novel.</p>
            <p><strong>References:</strong> <ul>
    <li>Chandola et al. (2012) Anomaly detection for discrete sequences: A survey [Contextual anomaly detection]</li>
    <li>Devlin et al. (2018) BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding [Contextual modeling in LMs]</li>
</ul>
            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>If a frequent item is inserted into a list at an unusual position (e.g., a header in the middle of a data table), the LM will flag it as anomalous.</li>
                <li>If a list of dates contains a date in the wrong format, even if the date itself is common, the LM will detect it as an anomaly.</li>
                <li>If a list of function calls in code contains a syntactically valid but contextually misplaced call, the LM will assign it low coherence.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>If a list contains subtle context-dependent anomalies (e.g., values that are only anomalous given a long-range dependency), it is unknown whether the LM can detect them without explicit training.</li>
                <li>If the LM is applied to lists with highly non-local dependencies (e.g., checksums), its ability to detect relational anomalies is uncertain.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>If the LM fails to flag contextually inconsistent but frequent items as anomalies, the theory would be challenged.</li>
                <li>If the LM only detects globally rare items and not contextually inconsistent ones, the theory would be undermined.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>Anomalies that do not disrupt local or global context (e.g., silent data corruption with no contextual effect) may not be detected. </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> closely-related-to-existing</p>
            <p><strong>Explanation:</strong> This theory is closely-related-to-existing work, but its generalization to arbitrary lists is new.</p>
            <p><strong>References:</strong> <ul>
    <li>Chandola et al. (2012) Anomaly detection for discrete sequences: A survey [Contextual anomaly detection]</li>
    <li>Devlin et al. (2018) BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding [Contextual modeling in LMs]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Contextual Consistency Theory of LM-based Anomaly Detection",
    "theory_description": "This theory posits that language models detect anomalies in lists by evaluating the contextual consistency of each item with respect to its surrounding items. Anomalies are identified as items whose presence disrupts the local or global coherence as modeled by the LM, regardless of their absolute frequency or probability. The theory emphasizes the role of context and relational structure, not just statistical rarity.",
    "theory_statements": [
        {
            "law": {
                "law_name": "Contextual Inconsistency Signals Anomaly",
                "if": [
                    {
                        "subject": "item_i",
                        "relation": "is_in",
                        "object": "data_list"
                    },
                    {
                        "subject": "context_window",
                        "relation": "surrounds",
                        "object": "item_i"
                    },
                    {
                        "subject": "LM",
                        "relation": "assigns_low_coherence_score",
                        "object": "item_i_given_context_window"
                    }
                ],
                "then": [
                    {
                        "subject": "item_i",
                        "relation": "is_likely",
                        "object": "anomaly"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "LMs are sensitive to local context and can detect disruptions in sequence coherence.",
                        "uuids": []
                    },
                    {
                        "text": "Anomalies often manifest as contextually inconsistent items, even if their global frequency is not low.",
                        "uuids": []
                    },
                    {
                        "text": "Studies in NLP show that LMs can detect grammatical or semantic errors based on context.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "LMs are known to model context and coherence in language and code.",
                    "what_is_novel": "Applying contextual coherence as a general anomaly detection principle in arbitrary lists is novel.",
                    "classification_explanation": "This law is closely-related-to-existing work in NLP, but its generalization to arbitrary lists is new.",
                    "likely_classification": "closely-related-to-existing",
                    "references": [
                        "Devlin et al. (2018) BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding [Contextual modeling in LMs]",
                        "Goldstein & Uchida (2016) A comparative evaluation of unsupervised anomaly detection algorithms for multivariate data [General anomaly detection]"
                    ]
                }
            }
        },
        {
            "law": {
                "law_name": "Relational Anomalies Can Be Detected Without Rarity",
                "if": [
                    {
                        "subject": "item_i",
                        "relation": "is_in",
                        "object": "data_list"
                    },
                    {
                        "subject": "item_i",
                        "relation": "is_frequent_in",
                        "object": "training_data"
                    },
                    {
                        "subject": "item_i",
                        "relation": "is_inconsistent_with",
                        "object": "context_window"
                    }
                ],
                "then": [
                    {
                        "subject": "item_i",
                        "relation": "is_likely",
                        "object": "anomaly"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Anomalies can be context-dependent, not just globally rare; e.g., a common value in an unusual position.",
                        "uuids": []
                    },
                    {
                        "text": "LMs can flag contextually misplaced but frequent items as anomalous.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Contextual anomaly detection is known in time series and NLP.",
                    "what_is_novel": "Generalizing this to arbitrary lists and using LMs as the context model is novel.",
                    "classification_explanation": "This law is somewhat-related-to-existing, as it extends contextual anomaly detection to new domains.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Chandola et al. (2012) Anomaly detection for discrete sequences: A survey [Contextual anomaly detection]",
                        "Devlin et al. (2018) BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding [Contextual modeling in LMs]"
                    ]
                }
            }
        }
    ],
    "new_predictions_likely": [
        "If a frequent item is inserted into a list at an unusual position (e.g., a header in the middle of a data table), the LM will flag it as anomalous.",
        "If a list of dates contains a date in the wrong format, even if the date itself is common, the LM will detect it as an anomaly.",
        "If a list of function calls in code contains a syntactically valid but contextually misplaced call, the LM will assign it low coherence."
    ],
    "new_predictions_unknown": [
        "If a list contains subtle context-dependent anomalies (e.g., values that are only anomalous given a long-range dependency), it is unknown whether the LM can detect them without explicit training.",
        "If the LM is applied to lists with highly non-local dependencies (e.g., checksums), its ability to detect relational anomalies is uncertain."
    ],
    "negative_experiments": [
        "If the LM fails to flag contextually inconsistent but frequent items as anomalies, the theory would be challenged.",
        "If the LM only detects globally rare items and not contextually inconsistent ones, the theory would be undermined."
    ],
    "unaccounted_for": [
        {
            "text": "Anomalies that do not disrupt local or global context (e.g., silent data corruption with no contextual effect) may not be detected.",
            "uuids": []
        }
    ],
    "conflicting_evidence": [
        {
            "text": "Some LMs may fail to capture long-range dependencies, missing context-dependent anomalies.",
            "uuids": []
        }
    ],
    "special_cases": [
        "Lists with weak or no contextual structure may not benefit from this approach.",
        "If the LM's context window is too small, it may miss anomalies that depend on long-range relationships."
    ],
    "existing_theory": {
        "what_already_exists": "Contextual anomaly detection is established in time series and NLP; LMs are known to model context.",
        "what_is_novel": "The explicit use of LMs for context-based anomaly detection in arbitrary lists is novel.",
        "classification_explanation": "This theory is closely-related-to-existing work, but its generalization to arbitrary lists is new.",
        "likely_classification": "closely-related-to-existing",
        "references": [
            "Chandola et al. (2012) Anomaly detection for discrete sequences: A survey [Contextual anomaly detection]",
            "Devlin et al. (2018) BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding [Contextual modeling in LMs]"
        ]
    },
    "reflected_from_theory_index": 0,
    "type": "general",
    "version": "built-theory-from-results-single-theory-reflection2-nov14-2025-LLM-BASELINE-no-evidence-without-matched-control-theory-name",
    "theory_query": "Build a theory of how language models can be used for detecting anomalies in lists of data.",
    "original_theory_id": "theory-645",
    "original_theory_name": "Chain-of-Thought and Domain-Knowledge Prompting Enhances LLM Interpretability and Anomaly-Type Classification",
    "provide_matched_control_thery_name": false,
    "matched_control_theory_name": null,
    "model_str": "openai/gpt-4.1-2025-04-14"
}</code></pre>
        </div>
    </div>
</body>
</html>