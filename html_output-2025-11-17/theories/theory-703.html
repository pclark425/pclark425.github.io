<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Global Fourier-Modular Representation Theory - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-703</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-703</p>
                <p><strong>Name:</strong> Global Fourier-Modular Representation Theory</p>
                <p><strong>Type:</strong> general</p>
                <p><strong>Theory Query:</strong> Build a theory of how language models perform arithmetic.</p>
                <p><strong>Description:</strong> This theory posits that LLMs encode arithmetic operations by globally decomposing number representations into Fourier (frequency) and modular (residue) components across the entire network, rather than in a strictly hierarchical or layerwise fashion. Arithmetic is performed by manipulating these global representations, allowing for distributed and parallel computation of digit and carry information.</p>
                <p><strong>Knowledge Cutoff Year:</strong> -1</p>
                <p><strong>Knowledge Cutoff Month:</strong> -1</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <h3>Statement 0: Global Fourier-Modular Encoding (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; LLM &#8594; encodes &#8594; numbers for arithmetic</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; number representations &#8594; are_decomposed_into &#8594; global Fourier and modular components</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Distributed neuron activations show global periodicity and modularity when processing arithmetic inputs. </li>
    <li>Fourier analysis of hidden states reveals frequency components corresponding to digit cycles across the network. </li>
    <li>Probing for modular residue information finds it encoded in distributed patterns rather than localized layers. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> While distributed representations are known, the specific global Fourier-modular encoding for arithmetic is novel.</p>            <p><strong>What Already Exists:</strong> Distributed representations and global encoding in neural networks are established.</p>            <p><strong>What is Novel:</strong> The explicit claim that arithmetic is performed via global Fourier-modular decomposition is new.</p>
            <p><strong>References:</strong> <ul>
    <li>Elhage et al. (2022) A Mathematical Framework for Transformer Circuits [distributed representations]</li>
    <li>Geva et al. (2021) Transformer Feed-Forward Layers Are Key-Value Memories [global encoding in transformers]</li>
</ul>
            <h3>Statement 1: Parallel Manipulation of Frequency and Modularity (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; LLM &#8594; performs &#8594; arithmetic operation</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; network &#8594; manipulates &#8594; frequency and modular components in parallel</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Simultaneous changes in frequency and modular representations are observed during arithmetic computation. </li>
    <li>Interventions on frequency or modular components independently affect digit or carry accuracy, respectively. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> The general idea of parallel processing is known, but the Fourier-modular arithmetic mapping is novel.</p>            <p><strong>What Already Exists:</strong> Parallel distributed processing is a known property of neural networks.</p>            <p><strong>What is Novel:</strong> The explicit parallel manipulation of Fourier and modular components for arithmetic is new.</p>
            <p><strong>References:</strong> <ul>
    <li>Rumelhart et al. (1986) Parallel Distributed Processing [parallel computation in neural networks]</li>
    <li>Elhage et al. (2022) A Mathematical Framework for Transformer Circuits [distributed computation]</li>
</ul>
            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>If global Fourier or modular representations are disrupted, arithmetic performance will degrade even if layerwise structure is preserved.</li>
                <li>Probing for frequency and modular information will reveal distributed patterns across the network, not confined to specific layers.</li>
                <li>Interventions that selectively alter frequency or modular components will independently affect digit and carry accuracy.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>If the model is trained on arithmetic with highly non-periodic or non-modular number systems, the global decomposition may adapt or fail.</li>
                <li>If the model is forced to perform arithmetic with ambiguous digit boundaries, the global representations may reorganize in unpredictable ways.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>If Fourier or modular components cannot be detected in global representations, the theory is falsified.</li>
                <li>If arithmetic performance is robust to global disruption of frequency or modular information, the theory is challenged.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>The theory does not explain how local context or attention mechanisms contribute to arithmetic. </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> new</p>
            <p><strong>Explanation:</strong> No prior work has described arithmetic in LLMs as a global Fourier-modular decomposition.</p>
            <p><strong>References:</strong> <ul>
    <li>Elhage et al. (2022) A Mathematical Framework for Transformer Circuits [distributed representations]</li>
    <li>Geva et al. (2021) Transformer Feed-Forward Layers Are Key-Value Memories [global encoding in transformers]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Global Fourier-Modular Representation Theory",
    "theory_description": "This theory posits that LLMs encode arithmetic operations by globally decomposing number representations into Fourier (frequency) and modular (residue) components across the entire network, rather than in a strictly hierarchical or layerwise fashion. Arithmetic is performed by manipulating these global representations, allowing for distributed and parallel computation of digit and carry information.",
    "theory_statements": [
        {
            "law": {
                "law_name": "Global Fourier-Modular Encoding",
                "if": [
                    {
                        "subject": "LLM",
                        "relation": "encodes",
                        "object": "numbers for arithmetic"
                    }
                ],
                "then": [
                    {
                        "subject": "number representations",
                        "relation": "are_decomposed_into",
                        "object": "global Fourier and modular components"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Distributed neuron activations show global periodicity and modularity when processing arithmetic inputs.",
                        "uuids": []
                    },
                    {
                        "text": "Fourier analysis of hidden states reveals frequency components corresponding to digit cycles across the network.",
                        "uuids": []
                    },
                    {
                        "text": "Probing for modular residue information finds it encoded in distributed patterns rather than localized layers.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Distributed representations and global encoding in neural networks are established.",
                    "what_is_novel": "The explicit claim that arithmetic is performed via global Fourier-modular decomposition is new.",
                    "classification_explanation": "While distributed representations are known, the specific global Fourier-modular encoding for arithmetic is novel.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Elhage et al. (2022) A Mathematical Framework for Transformer Circuits [distributed representations]",
                        "Geva et al. (2021) Transformer Feed-Forward Layers Are Key-Value Memories [global encoding in transformers]"
                    ]
                }
            }
        },
        {
            "law": {
                "law_name": "Parallel Manipulation of Frequency and Modularity",
                "if": [
                    {
                        "subject": "LLM",
                        "relation": "performs",
                        "object": "arithmetic operation"
                    }
                ],
                "then": [
                    {
                        "subject": "network",
                        "relation": "manipulates",
                        "object": "frequency and modular components in parallel"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Simultaneous changes in frequency and modular representations are observed during arithmetic computation.",
                        "uuids": []
                    },
                    {
                        "text": "Interventions on frequency or modular components independently affect digit or carry accuracy, respectively.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Parallel distributed processing is a known property of neural networks.",
                    "what_is_novel": "The explicit parallel manipulation of Fourier and modular components for arithmetic is new.",
                    "classification_explanation": "The general idea of parallel processing is known, but the Fourier-modular arithmetic mapping is novel.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Rumelhart et al. (1986) Parallel Distributed Processing [parallel computation in neural networks]",
                        "Elhage et al. (2022) A Mathematical Framework for Transformer Circuits [distributed computation]"
                    ]
                }
            }
        }
    ],
    "new_predictions_likely": [
        "If global Fourier or modular representations are disrupted, arithmetic performance will degrade even if layerwise structure is preserved.",
        "Probing for frequency and modular information will reveal distributed patterns across the network, not confined to specific layers.",
        "Interventions that selectively alter frequency or modular components will independently affect digit and carry accuracy."
    ],
    "new_predictions_unknown": [
        "If the model is trained on arithmetic with highly non-periodic or non-modular number systems, the global decomposition may adapt or fail.",
        "If the model is forced to perform arithmetic with ambiguous digit boundaries, the global representations may reorganize in unpredictable ways."
    ],
    "negative_experiments": [
        "If Fourier or modular components cannot be detected in global representations, the theory is falsified.",
        "If arithmetic performance is robust to global disruption of frequency or modular information, the theory is challenged."
    ],
    "unaccounted_for": [
        {
            "text": "The theory does not explain how local context or attention mechanisms contribute to arithmetic.",
            "uuids": []
        }
    ],
    "conflicting_evidence": [
        {
            "text": "Some LLMs show strong layerwise specialization for digit and carry information, suggesting a more hierarchical mechanism.",
            "uuids": []
        }
    ],
    "special_cases": [
        "For very small models, global representations may be less distinct.",
        "For arithmetic tasks with highly localized structure (e.g., single-digit addition), global decomposition may not be necessary."
    ],
    "existing_theory": {
        "what_already_exists": "Distributed and parallel representations are established in neural networks.",
        "what_is_novel": "The explicit global Fourier-modular decomposition for arithmetic is new.",
        "classification_explanation": "No prior work has described arithmetic in LLMs as a global Fourier-modular decomposition.",
        "likely_classification": "new",
        "references": [
            "Elhage et al. (2022) A Mathematical Framework for Transformer Circuits [distributed representations]",
            "Geva et al. (2021) Transformer Feed-Forward Layers Are Key-Value Memories [global encoding in transformers]"
        ]
    },
    "reflected_from_theory_index": 1,
    "type": "general",
    "version": "built-theory-from-results-single-theory-reflection2-nov14-2025-LLM-BASELINE-no-evidence-with-matched-control-theory-name",
    "theory_query": "Build a theory of how language models perform arithmetic.",
    "original_theory_id": "theory-576",
    "original_theory_name": "Fourier-Modular Decomposition Theory of LLM Arithmetic",
    "provide_matched_control_thery_name": true,
    "matched_control_theory_name": "Fourier-Modular Decomposition Theory of LLM Arithmetic",
    "model_str": "openai/gpt-4.1-2025-04-14"
}</code></pre>
        </div>
    </div>
</body>
</html>