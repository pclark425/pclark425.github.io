<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Active Interventional Experimental Design Theory - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-120</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-120</p>
                <p><strong>Name:</strong> Active Interventional Experimental Design Theory</p>
                <p><strong>Type:</strong> general</p>
                <p><strong>Theory Query:</strong> Build a theory of distractor-robust causal discovery in open-ended virtual labs, including methods to detect, downweight, and refute spurious signals during inquiry, based on the following results.</p>
                <p><strong>Description:</strong> Spurious causal hypotheses can be efficiently refuted through strategic selection of interventions that maximize information gain about causal structure. The optimal intervention strategy integrates four key components: (1) target selection where hypothesis graphs disagree most in their predictions (high between-graph variance relative to within-graph variance), (2) continuous value optimization that maximizes discriminative power while accounting for uncertainty, (3) posterior approximation methods that tractably represent uncertainty over graph structures, and (4) sample selection strategies that focus computational resources on informative data. This theory synthesizes Bayesian experimental design, mutual information maximization, submodular optimization, and active learning principles for causal discovery in interactive virtual laboratories and experimental environments.</p>
                <p><strong>Knowledge Cutoff Year:</strong> 2024</p>
                <p><strong>Knowledge Cutoff Month:</strong> 12</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <ol>
                <li>The expected mutual information I(f(G); Y | ξ, D) between a target graph functional f(G) and interventional outcome Y given intervention ξ and data D quantifies the expected reduction in uncertainty about causal structure</li>
                <li>Optimal intervention selection is a submodular optimization problem under certain conditions (DR-submodularity), enabling (1-1/e) approximation guarantees via greedy selection</li>
                <li>The discrepancy score D_k = VBG_k / VWG_k for intervention target k provides a practical approximation to mutual information under Gaussian outcome assumptions, where VBG is between-graph variance and VWG is within-graph variance</li>
                <li>For graphs with at most τ p-colliders per pair, O(n τ log n + n log n) randomized interventions suffice to recover the full causal structure including latent confounders with probability ≥ 1 - O(1/n²)</li>
                <li>Continuous intervention value selection via Bayesian optimization (e.g., GP-UCB) can improve sample efficiency by 2-4x compared to random value selection in nonlinear SCMs</li>
                <li>Batched intervention design with soft selection (allowing repeated interventions) outperforms hard constraints requiring unique interventions per batch, particularly when some interventions are much more informative</li>
                <li>Importance-weighted empirical-Bayes posterior approximation using MLE parameters enables tractable mutual-information computation while downweighting spurious DAGs via likelihood of interventional data</li>
                <li>Autoregressive variational posteriors (e.g., LSTM-based) better capture multimodal uncertainty over DAGs than factorized posteriors, improving intervention selection in non-identifiable settings</li>
                <li>Sample selection via gradient-based similarity and diversity metrics can reduce computational cost of CI-based causal discovery while maintaining or improving accuracy</li>
                <li>Unknown intervention targets can be predicted with 71-95% accuracy (depending on graph size) using likelihood deterioration heuristics, enabling intervention design without known targets</li>
            </ol>
            <h3>Supporting Evidence</h3>
<ol>
    <li>ABCD-Strategy uses mutual information to select batched interventions that maximally reduce posterior entropy about target graph functionals, with importance-weighted empirical-Bayes reweighting to downweight spurious DAGs <a href="../results/extraction-result-742.html#e742.0" class="evidence-link">[e742.0]</a> <a href="../results/extraction-result-742.html#e742.2" class="evidence-link">[e742.2]</a> <a href="../results/extraction-result-742.html#e742.3" class="evidence-link">[e742.3]</a> <a href="../results/extraction-result-984.html#e984.0" class="evidence-link">[e984.0]</a> <a href="../results/extraction-result-984.html#e984.1" class="evidence-link">[e984.1]</a> <a href="../results/extraction-result-984.html#e984.2" class="evidence-link">[e984.2]</a> </li>
    <li>AIT selects intervention targets by maximizing between-graph variance relative to within-graph variance (VBG/VWG ratio), which approximates mutual information under Gaussian assumptions <a href="../results/extraction-result-718.html#e718.0" class="evidence-link">[e718.0]</a> <a href="../results/extraction-result-718.html#e718.1" class="evidence-link">[e718.1]</a> </li>
    <li>CBED combines target selection via mutual information with continuous value optimization using GP-UCB, achieving 2-4x sample efficiency gains <a href="../results/extraction-result-750.html#e750.0" class="evidence-link">[e750.0]</a> <a href="../results/extraction-result-750.html#e750.1" class="evidence-link">[e750.1]</a> <a href="../results/extraction-result-750.html#e750.4" class="evidence-link">[e750.4]</a> <a href="../results/extraction-result-750.html#e750.5" class="evidence-link">[e750.5]</a> </li>
    <li>Greedy-CBED and Soft-CBED provide batched intervention strategies with (1-1/e) approximation guarantees via submodular optimization <a href="../results/extraction-result-750.html#e750.1" class="evidence-link">[e750.1]</a> </li>
    <li>Separating systems provide combinatorial intervention designs that guarantee coverage of critical collider sets with O((p/q) log p) interventions <a href="../results/extraction-result-981.html#e981.5" class="evidence-link">[e981.5]</a> <a href="../results/extraction-result-985.html#e985.3" class="evidence-link">[e985.3]</a> <a href="../results/extraction-result-985.html#e985.8" class="evidence-link">[e985.8]</a> </li>
    <li>Randomized intervention sampling probabilistically covers p-colliders to enable latent confounder detection with O(n τ log n) interventions <a href="../results/extraction-result-985.html#e985.6" class="evidence-link">[e985.6]</a> <a href="../results/extraction-result-985.html#e985.8" class="evidence-link">[e985.8]</a> </li>
    <li>LatentsWEdges uses distribution-comparison (do-see) tests under interventions to detect latent confounders between adjacent pairs <a href="../results/extraction-result-985.html#e985.6" class="evidence-link">[e985.6]</a> </li>
    <li>Online selective causal discovery uses gradient-based similarity and diversity metrics to select representative samples, reducing computational cost while maintaining accuracy <a href="../results/extraction-result-699.html#e699.0" class="evidence-link">[e699.0]</a> <a href="../results/extraction-result-699.html#e699.1" class="evidence-link">[e699.1]</a> </li>
    <li>VCN uses autoregressive variational posteriors over DAGs to capture multimodal uncertainty, enabling better intervention selection <a href="../results/extraction-result-987.html#e987.0" class="evidence-link">[e987.0]</a> <a href="../results/extraction-result-987.html#e987.1" class="evidence-link">[e987.1]</a> </li>
    <li>DiBS provides scalable variational posterior approximation using SVGD for nonlinear SCMs up to 50 dimensions <a href="../results/extraction-result-750.html#e750.7" class="evidence-link">[e750.7]</a> </li>
    <li>DAG-bootstrap provides tractable posterior approximation by resampling and running structure learning algorithms multiple times <a href="../results/extraction-result-742.html#e742.3" class="evidence-link">[e742.3]</a> <a href="../results/extraction-result-750.html#e750.8" class="evidence-link">[e750.8]</a> <a href="../results/extraction-result-987.html#e987.3" class="evidence-link">[e987.3]</a> </li>
    <li>DCDI leverages interventional data with differentiable optimization and expressive density estimators to recover causal structure <a href="../results/extraction-result-993.html#e993.0" class="evidence-link">[e993.0]</a> </li>
    <li>CIV and CIV-OW use causal information value to select interventions that maximize expected reduction in optimality gap <a href="../results/extraction-result-712.html#e712.6" class="evidence-link">[e712.6]</a> </li>
    <li>Active sampling reduces causal confusion by targeting uncertain transitions in RL environments <a href="../results/extraction-result-735.html#e735.6" class="evidence-link">[e735.6]</a> </li>
    <li>Causal curiosity provides intrinsic rewards for experiments that reveal causal structure, reducing data requirements by ~2.5x <a href="../results/extraction-result-701.html#e701.1" class="evidence-link">[e701.1]</a> </li>
    <li>Intervention prediction heuristics based on likelihood deterioration can identify unknown intervention targets with 71-95% accuracy <a href="../results/extraction-result-1005.html#e1005.1" class="evidence-link">[e1005.1]</a> </li>
    <li>Masking intervened variables and blocking gradients prevents spurious attribution of intervention effects <a href="../results/extraction-result-1005.html#e1005.2" class="evidence-link">[e1005.2]</a> </li>
    <li>AIT with noise robustness (masking intervened variables, VWG normalization) maintains performance under measurement noise up to η=0.05 <a href="../results/extraction-result-718.html#e718.0" class="evidence-link">[e718.0]</a> </li>
</ol>            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>In a 20-node causal graph with 3 p-colliders per pair, approximately 60 log(20) ≈ 180 randomized interventions should suffice for full recovery with latent confounders</li>
                <li>Combining CBED's mutual information target selection with GP-UCB value optimization should reduce required interventions by 30-50% compared to random targeting on nonlinear SCMs with 10-50 nodes</li>
                <li>Active intervention targeting should show largest gains over random selection in the 'elbow' region after observational equivalence class is identified but before full orientation</li>
                <li>Using gradient-based sample selection (similarity + diversity) should reduce computational time for PC+KCI by 50-80% while maintaining edge recovery accuracy within 5% of full-data performance</li>
                <li>Combining VCN or DiBS posterior approximation with CBED should scale to 100+ node graphs while maintaining near-optimal intervention selection</li>
                <li>Intervention prediction heuristics should maintain >80% accuracy for graphs up to 10 nodes, degrading gracefully to ~70% for larger graphs</li>
                <li>Soft batching with batch size B=5-10 should achieve 80-90% of the performance of fully sequential design while enabling parallel execution</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>Whether mutual information-based selection remains optimal when intervention costs vary significantly across targets (e.g., some interventions are 10-100x more expensive)</li>
                <li>The effectiveness of active intervention design when the true causal graph has feedback loops or time-varying structure not captured by static DAG assumptions</li>
                <li>Whether batch size optimization (trading off parallel execution vs. sequential adaptation) follows predictable scaling laws as a function of graph properties (density, size, p-collider count)</li>
                <li>The robustness of GP-UCB value selection when the true intervention response surface is highly non-smooth, discontinuous, or has multiple local optima</li>
                <li>Whether combining multiple posterior approximation methods (ensemble of VCN, DiBS, DAG-bootstrap) improves intervention selection beyond single-method approaches</li>
                <li>The extent to which online/streaming intervention design can approach the performance of batch design when data arrives sequentially</li>
                <li>Whether active intervention design can effectively handle mixed discrete-continuous intervention spaces with complex constraints</li>
                <li>The performance of mutual information-based selection when the true causal model violates assumptions (e.g., non-additive noise, context-dependent mechanisms)</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>Finding cases where random intervention selection consistently outperforms mutual information-based selection (beyond small-sample noise) would challenge the information-theoretic foundation</li>
                <li>Demonstrating that the VBG/VWG discrepancy score is uncorrelated with actual information gain in realistic settings would undermine AIT's theoretical justification</li>
                <li>Showing that greedy submodular optimization performs significantly worse than (1-1/e) approximation in practice (e.g., <0.5 approximation ratio) would question the optimization approach</li>
                <li>Finding that batched designs with soft selection consistently perform worse than hard-constrained unique interventions would contradict current theory</li>
                <li>Demonstrating that importance-weighted empirical-Bayes approximation produces systematically biased intervention selection compared to full Bayesian inference would challenge the approximation</li>
                <li>Finding that autoregressive posteriors provide no benefit over factorized posteriors in intervention selection would question the value of capturing posterior dependencies</li>
                <li>Showing that sample selection strategies consistently degrade causal discovery accuracy compared to using all available data would undermine the efficiency claims</li>
                <li>Demonstrating that intervention prediction heuristics perform at chance level (<50% accuracy) in realistic settings would invalidate the unknown-target approach</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>The theory does not fully address how to handle intervention costs or constraints on which variables can be intervened upon, though CIV methods partially address optimality-gap-focused design <a href="../results/extraction-result-742.html#e742.0" class="evidence-link">[e742.0]</a> <a href="../results/extraction-result-750.html#e750.0" class="evidence-link">[e750.0]</a> <a href="../results/extraction-result-712.html#e712.6" class="evidence-link">[e712.6]</a> </li>
    <li>Optimal strategies for sequential vs. batched intervention design under different computational budgets are not fully characterized beyond the (1-1/e) approximation <a href="../results/extraction-result-750.html#e750.1" class="evidence-link">[e750.1]</a> <a href="../results/extraction-result-984.html#e984.0" class="evidence-link">[e984.0]</a> </li>
    <li>The relationship between sample size per intervention and number of interventions is not optimized jointly in current methods <a href="../results/extraction-result-742.html#e742.0" class="evidence-link">[e742.0]</a> <a href="../results/extraction-result-984.html#e984.0" class="evidence-link">[e984.0]</a> </li>
    <li>How to handle continuous vs discrete intervention spaces with complex constraints is not fully addressed <a href="../results/extraction-result-750.html#e750.0" class="evidence-link">[e750.0]</a> </li>
    <li>The theory does not fully account for computational complexity trade-offs between different posterior approximation methods (MCMC vs variational vs bootstrap) <a href="../results/extraction-result-987.html#e987.0" class="evidence-link">[e987.0]</a> <a href="../results/extraction-result-987.html#e987.3" class="evidence-link">[e987.3]</a> <a href="../results/extraction-result-750.html#e750.7" class="evidence-link">[e750.7]</a> </li>
    <li>Integration with online/streaming data where interventions must be selected in real-time is not fully developed <a href="../results/extraction-result-699.html#e699.0" class="evidence-link">[e699.0]</a> <a href="../results/extraction-result-699.html#e699.1" class="evidence-link">[e699.1]</a> </li>
    <li>How to combine multiple sources of uncertainty (posterior over graphs, parameter uncertainty, measurement noise) in intervention selection is not fully specified <a href="../results/extraction-result-718.html#e718.0" class="evidence-link">[e718.0]</a> <a href="../results/extraction-result-987.html#e987.0" class="evidence-link">[e987.0]</a> </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> closely-related-to-existing</p>
            <p><strong>Explanation:</strong> No explanation provided.</p>
            <p><strong>References:</strong> <ul>
    <li>Hauser & Bühlmann (2012) Characterization and greedy learning of interventional Markov equivalence classes [GIES and interventional equivalence classes]</li>
    <li>Eberhardt (2008) Almost optimal intervention sets for causal discovery [Theoretical foundations for intervention complexity bounds]</li>
    <li>Lindgren et al. (2018) Experimental design for causal discovery [Separating systems and graph-sensitive intervention design]</li>
    <li>Shanmugam et al. (2015) Learning causal graphs with small interventions [Intervention complexity and multi-perturbation bounds]</li>
    <li>Chalupka et al. (2015) A framework for evaluating approximation methods for Gaussian process regression [GP-UCB for Bayesian optimization]</li>
    <li>Tong & Koller (2001) Active learning for structure in Bayesian networks [Mutual information for experimental design in causal discovery]</li>
    <li>Ghassami et al. (2018) Budgeted experiment design for causal structure learning [Budgeted experimental design and consistency properties]</li>
    <li>Addanki et al. (2020) Efficient intervention design for causal discovery with latents [Intervention design with latent confounders and p-colliders]</li>
    <li>Brouillard et al. (2020) Differentiable causal discovery from interventional data [DCDI and differentiable approaches to interventional discovery]</li>
    <li>Ke et al. (2019) Learning neural causal models from unknown interventions [SDI and handling unknown intervention targets]</li>
    <li>Tigas et al. (2022) Interventions, where and how? Experimental design for causal models at scale [CBED combining target and value selection]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Active Interventional Experimental Design Theory",
    "theory_description": "Spurious causal hypotheses can be efficiently refuted through strategic selection of interventions that maximize information gain about causal structure. The optimal intervention strategy integrates four key components: (1) target selection where hypothesis graphs disagree most in their predictions (high between-graph variance relative to within-graph variance), (2) continuous value optimization that maximizes discriminative power while accounting for uncertainty, (3) posterior approximation methods that tractably represent uncertainty over graph structures, and (4) sample selection strategies that focus computational resources on informative data. This theory synthesizes Bayesian experimental design, mutual information maximization, submodular optimization, and active learning principles for causal discovery in interactive virtual laboratories and experimental environments.",
    "supporting_evidence": [
        {
            "text": "ABCD-Strategy uses mutual information to select batched interventions that maximally reduce posterior entropy about target graph functionals, with importance-weighted empirical-Bayes reweighting to downweight spurious DAGs",
            "uuids": [
                "e742.0",
                "e742.2",
                "e742.3",
                "e984.0",
                "e984.1",
                "e984.2"
            ]
        },
        {
            "text": "AIT selects intervention targets by maximizing between-graph variance relative to within-graph variance (VBG/VWG ratio), which approximates mutual information under Gaussian assumptions",
            "uuids": [
                "e718.0",
                "e718.1"
            ]
        },
        {
            "text": "CBED combines target selection via mutual information with continuous value optimization using GP-UCB, achieving 2-4x sample efficiency gains",
            "uuids": [
                "e750.0",
                "e750.1",
                "e750.4",
                "e750.5"
            ]
        },
        {
            "text": "Greedy-CBED and Soft-CBED provide batched intervention strategies with (1-1/e) approximation guarantees via submodular optimization",
            "uuids": [
                "e750.1"
            ]
        },
        {
            "text": "Separating systems provide combinatorial intervention designs that guarantee coverage of critical collider sets with O((p/q) log p) interventions",
            "uuids": [
                "e981.5",
                "e985.3",
                "e985.8"
            ]
        },
        {
            "text": "Randomized intervention sampling probabilistically covers p-colliders to enable latent confounder detection with O(n τ log n) interventions",
            "uuids": [
                "e985.6",
                "e985.8"
            ]
        },
        {
            "text": "LatentsWEdges uses distribution-comparison (do-see) tests under interventions to detect latent confounders between adjacent pairs",
            "uuids": [
                "e985.6"
            ]
        },
        {
            "text": "Online selective causal discovery uses gradient-based similarity and diversity metrics to select representative samples, reducing computational cost while maintaining accuracy",
            "uuids": [
                "e699.0",
                "e699.1"
            ]
        },
        {
            "text": "VCN uses autoregressive variational posteriors over DAGs to capture multimodal uncertainty, enabling better intervention selection",
            "uuids": [
                "e987.0",
                "e987.1"
            ]
        },
        {
            "text": "DiBS provides scalable variational posterior approximation using SVGD for nonlinear SCMs up to 50 dimensions",
            "uuids": [
                "e750.7"
            ]
        },
        {
            "text": "DAG-bootstrap provides tractable posterior approximation by resampling and running structure learning algorithms multiple times",
            "uuids": [
                "e742.3",
                "e750.8",
                "e987.3"
            ]
        },
        {
            "text": "DCDI leverages interventional data with differentiable optimization and expressive density estimators to recover causal structure",
            "uuids": [
                "e993.0"
            ]
        },
        {
            "text": "CIV and CIV-OW use causal information value to select interventions that maximize expected reduction in optimality gap",
            "uuids": [
                "e712.6"
            ]
        },
        {
            "text": "Active sampling reduces causal confusion by targeting uncertain transitions in RL environments",
            "uuids": [
                "e735.6"
            ]
        },
        {
            "text": "Causal curiosity provides intrinsic rewards for experiments that reveal causal structure, reducing data requirements by ~2.5x",
            "uuids": [
                "e701.1"
            ]
        },
        {
            "text": "Intervention prediction heuristics based on likelihood deterioration can identify unknown intervention targets with 71-95% accuracy",
            "uuids": [
                "e1005.1"
            ]
        },
        {
            "text": "Masking intervened variables and blocking gradients prevents spurious attribution of intervention effects",
            "uuids": [
                "e1005.2"
            ]
        },
        {
            "text": "AIT with noise robustness (masking intervened variables, VWG normalization) maintains performance under measurement noise up to η=0.05",
            "uuids": [
                "e718.0"
            ]
        }
    ],
    "theory_statements": [
        "The expected mutual information I(f(G); Y | ξ, D) between a target graph functional f(G) and interventional outcome Y given intervention ξ and data D quantifies the expected reduction in uncertainty about causal structure",
        "Optimal intervention selection is a submodular optimization problem under certain conditions (DR-submodularity), enabling (1-1/e) approximation guarantees via greedy selection",
        "The discrepancy score D_k = VBG_k / VWG_k for intervention target k provides a practical approximation to mutual information under Gaussian outcome assumptions, where VBG is between-graph variance and VWG is within-graph variance",
        "For graphs with at most τ p-colliders per pair, O(n τ log n + n log n) randomized interventions suffice to recover the full causal structure including latent confounders with probability ≥ 1 - O(1/n²)",
        "Continuous intervention value selection via Bayesian optimization (e.g., GP-UCB) can improve sample efficiency by 2-4x compared to random value selection in nonlinear SCMs",
        "Batched intervention design with soft selection (allowing repeated interventions) outperforms hard constraints requiring unique interventions per batch, particularly when some interventions are much more informative",
        "Importance-weighted empirical-Bayes posterior approximation using MLE parameters enables tractable mutual-information computation while downweighting spurious DAGs via likelihood of interventional data",
        "Autoregressive variational posteriors (e.g., LSTM-based) better capture multimodal uncertainty over DAGs than factorized posteriors, improving intervention selection in non-identifiable settings",
        "Sample selection via gradient-based similarity and diversity metrics can reduce computational cost of CI-based causal discovery while maintaining or improving accuracy",
        "Unknown intervention targets can be predicted with 71-95% accuracy (depending on graph size) using likelihood deterioration heuristics, enabling intervention design without known targets"
    ],
    "new_predictions_likely": [
        "In a 20-node causal graph with 3 p-colliders per pair, approximately 60 log(20) ≈ 180 randomized interventions should suffice for full recovery with latent confounders",
        "Combining CBED's mutual information target selection with GP-UCB value optimization should reduce required interventions by 30-50% compared to random targeting on nonlinear SCMs with 10-50 nodes",
        "Active intervention targeting should show largest gains over random selection in the 'elbow' region after observational equivalence class is identified but before full orientation",
        "Using gradient-based sample selection (similarity + diversity) should reduce computational time for PC+KCI by 50-80% while maintaining edge recovery accuracy within 5% of full-data performance",
        "Combining VCN or DiBS posterior approximation with CBED should scale to 100+ node graphs while maintaining near-optimal intervention selection",
        "Intervention prediction heuristics should maintain &gt;80% accuracy for graphs up to 10 nodes, degrading gracefully to ~70% for larger graphs",
        "Soft batching with batch size B=5-10 should achieve 80-90% of the performance of fully sequential design while enabling parallel execution"
    ],
    "new_predictions_unknown": [
        "Whether mutual information-based selection remains optimal when intervention costs vary significantly across targets (e.g., some interventions are 10-100x more expensive)",
        "The effectiveness of active intervention design when the true causal graph has feedback loops or time-varying structure not captured by static DAG assumptions",
        "Whether batch size optimization (trading off parallel execution vs. sequential adaptation) follows predictable scaling laws as a function of graph properties (density, size, p-collider count)",
        "The robustness of GP-UCB value selection when the true intervention response surface is highly non-smooth, discontinuous, or has multiple local optima",
        "Whether combining multiple posterior approximation methods (ensemble of VCN, DiBS, DAG-bootstrap) improves intervention selection beyond single-method approaches",
        "The extent to which online/streaming intervention design can approach the performance of batch design when data arrives sequentially",
        "Whether active intervention design can effectively handle mixed discrete-continuous intervention spaces with complex constraints",
        "The performance of mutual information-based selection when the true causal model violates assumptions (e.g., non-additive noise, context-dependent mechanisms)"
    ],
    "negative_experiments": [
        "Finding cases where random intervention selection consistently outperforms mutual information-based selection (beyond small-sample noise) would challenge the information-theoretic foundation",
        "Demonstrating that the VBG/VWG discrepancy score is uncorrelated with actual information gain in realistic settings would undermine AIT's theoretical justification",
        "Showing that greedy submodular optimization performs significantly worse than (1-1/e) approximation in practice (e.g., &lt;0.5 approximation ratio) would question the optimization approach",
        "Finding that batched designs with soft selection consistently perform worse than hard-constrained unique interventions would contradict current theory",
        "Demonstrating that importance-weighted empirical-Bayes approximation produces systematically biased intervention selection compared to full Bayesian inference would challenge the approximation",
        "Finding that autoregressive posteriors provide no benefit over factorized posteriors in intervention selection would question the value of capturing posterior dependencies",
        "Showing that sample selection strategies consistently degrade causal discovery accuracy compared to using all available data would undermine the efficiency claims",
        "Demonstrating that intervention prediction heuristics perform at chance level (&lt;50% accuracy) in realistic settings would invalidate the unknown-target approach"
    ],
    "unaccounted_for": [
        {
            "text": "The theory does not fully address how to handle intervention costs or constraints on which variables can be intervened upon, though CIV methods partially address optimality-gap-focused design",
            "uuids": [
                "e742.0",
                "e750.0",
                "e712.6"
            ]
        },
        {
            "text": "Optimal strategies for sequential vs. batched intervention design under different computational budgets are not fully characterized beyond the (1-1/e) approximation",
            "uuids": [
                "e750.1",
                "e984.0"
            ]
        },
        {
            "text": "The relationship between sample size per intervention and number of interventions is not optimized jointly in current methods",
            "uuids": [
                "e742.0",
                "e984.0"
            ]
        },
        {
            "text": "How to handle continuous vs discrete intervention spaces with complex constraints is not fully addressed",
            "uuids": [
                "e750.0"
            ]
        },
        {
            "text": "The theory does not fully account for computational complexity trade-offs between different posterior approximation methods (MCMC vs variational vs bootstrap)",
            "uuids": [
                "e987.0",
                "e987.3",
                "e750.7"
            ]
        },
        {
            "text": "Integration with online/streaming data where interventions must be selected in real-time is not fully developed",
            "uuids": [
                "e699.0",
                "e699.1"
            ]
        },
        {
            "text": "How to combine multiple sources of uncertainty (posterior over graphs, parameter uncertainty, measurement noise) in intervention selection is not fully specified",
            "uuids": [
                "e718.0",
                "e987.0"
            ]
        }
    ],
    "conflicting_evidence": [
        {
            "text": "Some previously proposed utilities (e.g., Ness et al. 2018) can be inconsistent in budgeted settings, repeatedly selecting the same intervention",
            "uuids": [
                "e984.4"
            ]
        },
        {
            "text": "DAG bootstrap posterior approximation may have limited support compared to true posterior, restricting coverage to graphs discovered during bootstrap",
            "uuids": [
                "e987.3"
            ]
        },
        {
            "text": "GP-based approaches (von Kügelgen et al.) may not scale beyond small bivariate systems due to dimensionality of multi-output GPs",
            "uuids": [
                "e750.10"
            ]
        },
        {
            "text": "Factorized variational posteriors perform worse than autoregressive posteriors, suggesting that independence assumptions in posterior approximation can harm intervention selection",
            "uuids": [
                "e987.1"
            ]
        },
        {
            "text": "MaxV baseline (parameter-variance minimization) performs worse than causally-targeted acquisition (CIV), suggesting that global uncertainty reduction is insufficient",
            "uuids": [
                "e712.6"
            ]
        },
        {
            "text": "Active sampling for causal confusion shows mixed results across tasks, indicating that uncertainty-based selection alone may be insufficient without explicit causal modeling",
            "uuids": [
                "e735.6"
            ]
        }
    ],
    "special_cases": [
        "When intervention targets are unknown, heuristics based on likelihood deterioration can predict targets with 95% accuracy for 3-variable graphs, degrading to 71% for 8-variable graphs",
        "For linear Gaussian models, closed-form BGe scores enable efficient posterior updates without MCMC, making ABCD-Strategy particularly efficient",
        "In the presence of latent confounders with at most τ p-colliders per pair, interventions must include p-collider sets to break inducing paths, requiring O(n τ log n) interventions",
        "Soft batching (allowing repeated interventions) is particularly beneficial when some interventions are much more informative than others, as it enables sample reallocation",
        "For dense graphs or graphs with many p-colliders, graph-sensitive separating systems (Lindgren et al.) substantially outperform graph-agnostic constructions",
        "When measurement noise is present (up to η=0.05 flip probability), masking intervened variables and normalizing by within-graph variance maintains AIT performance",
        "In nonlinear SCMs with complex conditional densities, expressive models (normalizing flows in DCDI) combined with interventional data substantially improve recovery over simpler density models",
        "For graphs up to ~50 nodes, DiBS with SVGD provides tractable posterior approximation for nonlinear models, while larger graphs may require bootstrap or other approximations",
        "When computational budget is limited, gradient-based sample selection can reduce CI test computation by 50-80% while maintaining accuracy, making online causal discovery feasible",
        "In RL settings with task-agnostic exploration, combining causal discovery with intrinsic rewards (causal curiosity) can reduce data requirements by ~2.5x"
    ],
    "existing_theory": {
        "likely_classification": "closely-related-to-existing",
        "references": [
            "Hauser & Bühlmann (2012) Characterization and greedy learning of interventional Markov equivalence classes [GIES and interventional equivalence classes]",
            "Eberhardt (2008) Almost optimal intervention sets for causal discovery [Theoretical foundations for intervention complexity bounds]",
            "Lindgren et al. (2018) Experimental design for causal discovery [Separating systems and graph-sensitive intervention design]",
            "Shanmugam et al. (2015) Learning causal graphs with small interventions [Intervention complexity and multi-perturbation bounds]",
            "Chalupka et al. (2015) A framework for evaluating approximation methods for Gaussian process regression [GP-UCB for Bayesian optimization]",
            "Tong & Koller (2001) Active learning for structure in Bayesian networks [Mutual information for experimental design in causal discovery]",
            "Ghassami et al. (2018) Budgeted experiment design for causal structure learning [Budgeted experimental design and consistency properties]",
            "Addanki et al. (2020) Efficient intervention design for causal discovery with latents [Intervention design with latent confounders and p-colliders]",
            "Brouillard et al. (2020) Differentiable causal discovery from interventional data [DCDI and differentiable approaches to interventional discovery]",
            "Ke et al. (2019) Learning neural causal models from unknown interventions [SDI and handling unknown intervention targets]",
            "Tigas et al. (2022) Interventions, where and how? Experimental design for causal models at scale [CBED combining target and value selection]"
        ]
    },
    "theory_type_general_specific": "general",
    "reflected_from_theory_index": 1,
    "type": "general"
}</code></pre>
        </div>
    </div>
</body>
</html>