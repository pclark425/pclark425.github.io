<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Probabilistic Expectation Violation Theory - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-1743</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-1743</p>
                <p><strong>Name:</strong> Probabilistic Expectation Violation Theory</p>
                <p><strong>Type:</strong> general</p>
                <p><strong>Theory Query:</strong> Build a theory of how language models can be used for detecting anomalies in lists of data.</p>
                <p><strong>Description:</strong> Language models assign probabilities to sequences and items based on learned distributions. Anomalies in lists are detected as items with low conditional probability given the context of the list. This theory formalizes anomaly detection as the identification of items that violate the probabilistic expectations of the LM, integrating both local (item-level) and global (list-level) context.</p>
                <p><strong>Knowledge Cutoff Year:</strong> -1</p>
                <p><strong>Knowledge Cutoff Month:</strong> -1</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <h3>Statement 0: Low Conditional Probability Anomaly (quantitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; language_model &#8594; assigns_conditional_probability &#8594; P(item|list_context)<span style="color: #888888;">, and</span></div>
        <div>&#8226; P(item|list_context) &#8594; is_much_lower_than &#8594; P(typical_item|list_context)</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; language_model &#8594; flags &#8594; item_as_anomalous</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>LMs assign lower probabilities to out-of-context or rare items in a given list context. </li>
    <li>Perplexity-based anomaly detection methods use low-probability events as anomaly signals. </li>
    <li>Empirical studies show LMs can identify low-probability items as outliers in text and structured data. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> closely-related-to-existing</p>
            <p><strong>Explanation:</strong> Closely related to existing work, but the application to arbitrary list anomaly detection is a novel extension.</p>            <p><strong>What Already Exists:</strong> Probabilistic anomaly detection is well-established in statistics and NLP.</p>            <p><strong>What is Novel:</strong> This law applies it to arbitrary list contexts using LMs' learned conditional distributions.</p>
            <p><strong>References:</strong> <ul>
    <li>Goldstein & Uchida (2016) A Comparative Evaluation of Unsupervised Anomaly Detection Algorithms for Multivariate Data [probabilistic anomaly detection]</li>
    <li>Radford et al. (2019) Language Models are Unsupervised Multitask Learners [LMs assign probabilities to sequences]</li>
</ul>
            <h3>Statement 1: Contextual Probability Aggregation (quantitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; language_model &#8594; computes &#8594; joint_probability_of_list<span style="color: #888888;">, and</span></div>
        <div>&#8226; item &#8594; reduces &#8594; joint_probability_of_list</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; language_model &#8594; identifies &#8594; item_as_global_anomaly</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>LMs can compute the probability of an entire list and identify which item most reduces the overall likelihood. </li>
    <li>Global context can reveal anomalies not apparent from local context alone. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> Somewhat related to existing work, but the extension to arbitrary lists and LM-based joint modeling is new.</p>            <p><strong>What Already Exists:</strong> Global likelihood-based anomaly detection is used in time series and sequence modeling.</p>            <p><strong>What is Novel:</strong> Application to arbitrary lists and leveraging LMs' joint probability modeling is novel.</p>
            <p><strong>References:</strong> <ul>
    <li>Chandola et al. (2009) Anomaly Detection: A Survey [sequence anomaly detection]</li>
    <li>Radford et al. (2019) Language Models are Unsupervised Multitask Learners [LMs model joint probabilities]</li>
</ul>
            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>LMs will flag items with low conditional probability in a list as anomalies, even if they are common in the general corpus.</li>
                <li>LMs will identify global anomalies in lists where a single item disrupts the overall probability of the sequence.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>LMs can detect anomalies in lists with complex, non-local dependencies (e.g., palindromic or mathematical patterns).</li>
                <li>LMs can generalize probabilistic anomaly detection to lists in non-linguistic domains (e.g., code, tabular data).</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>If LMs fail to flag low-probability items as anomalies, the theory would be challenged.</li>
                <li>If LMs cannot identify global anomalies in lists with subtle dependencies, the theory would be called into question.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>Lists where all items are equally rare or the LM has not seen similar contexts in training. </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> somewhat-related-to-existing</p>
            <p><strong>Explanation:</strong> The theory extends existing probabilistic anomaly detection to the context of LMs and arbitrary lists.</p>
            <p><strong>References:</strong> <ul>
    <li>Goldstein & Uchida (2016) A Comparative Evaluation of Unsupervised Anomaly Detection Algorithms for Multivariate Data [probabilistic anomaly detection]</li>
    <li>Radford et al. (2019) Language Models are Unsupervised Multitask Learners [LMs assign probabilities to sequences]</li>
    <li>Chandola et al. (2009) Anomaly Detection: A Survey [sequence anomaly detection]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Probabilistic Expectation Violation Theory",
    "theory_description": "Language models assign probabilities to sequences and items based on learned distributions. Anomalies in lists are detected as items with low conditional probability given the context of the list. This theory formalizes anomaly detection as the identification of items that violate the probabilistic expectations of the LM, integrating both local (item-level) and global (list-level) context.",
    "theory_statements": [
        {
            "law": {
                "law_name": "Low Conditional Probability Anomaly",
                "if": [
                    {
                        "subject": "language_model",
                        "relation": "assigns_conditional_probability",
                        "object": "P(item|list_context)"
                    },
                    {
                        "subject": "P(item|list_context)",
                        "relation": "is_much_lower_than",
                        "object": "P(typical_item|list_context)"
                    }
                ],
                "then": [
                    {
                        "subject": "language_model",
                        "relation": "flags",
                        "object": "item_as_anomalous"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "LMs assign lower probabilities to out-of-context or rare items in a given list context.",
                        "uuids": []
                    },
                    {
                        "text": "Perplexity-based anomaly detection methods use low-probability events as anomaly signals.",
                        "uuids": []
                    },
                    {
                        "text": "Empirical studies show LMs can identify low-probability items as outliers in text and structured data.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "quantitative",
                "existing_law": {
                    "what_already_exists": "Probabilistic anomaly detection is well-established in statistics and NLP.",
                    "what_is_novel": "This law applies it to arbitrary list contexts using LMs' learned conditional distributions.",
                    "classification_explanation": "Closely related to existing work, but the application to arbitrary list anomaly detection is a novel extension.",
                    "likely_classification": "closely-related-to-existing",
                    "references": [
                        "Goldstein & Uchida (2016) A Comparative Evaluation of Unsupervised Anomaly Detection Algorithms for Multivariate Data [probabilistic anomaly detection]",
                        "Radford et al. (2019) Language Models are Unsupervised Multitask Learners [LMs assign probabilities to sequences]"
                    ]
                }
            }
        },
        {
            "law": {
                "law_name": "Contextual Probability Aggregation",
                "if": [
                    {
                        "subject": "language_model",
                        "relation": "computes",
                        "object": "joint_probability_of_list"
                    },
                    {
                        "subject": "item",
                        "relation": "reduces",
                        "object": "joint_probability_of_list"
                    }
                ],
                "then": [
                    {
                        "subject": "language_model",
                        "relation": "identifies",
                        "object": "item_as_global_anomaly"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "LMs can compute the probability of an entire list and identify which item most reduces the overall likelihood.",
                        "uuids": []
                    },
                    {
                        "text": "Global context can reveal anomalies not apparent from local context alone.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "quantitative",
                "existing_law": {
                    "what_already_exists": "Global likelihood-based anomaly detection is used in time series and sequence modeling.",
                    "what_is_novel": "Application to arbitrary lists and leveraging LMs' joint probability modeling is novel.",
                    "classification_explanation": "Somewhat related to existing work, but the extension to arbitrary lists and LM-based joint modeling is new.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Chandola et al. (2009) Anomaly Detection: A Survey [sequence anomaly detection]",
                        "Radford et al. (2019) Language Models are Unsupervised Multitask Learners [LMs model joint probabilities]"
                    ]
                }
            }
        }
    ],
    "new_predictions_likely": [
        "LMs will flag items with low conditional probability in a list as anomalies, even if they are common in the general corpus.",
        "LMs will identify global anomalies in lists where a single item disrupts the overall probability of the sequence."
    ],
    "new_predictions_unknown": [
        "LMs can detect anomalies in lists with complex, non-local dependencies (e.g., palindromic or mathematical patterns).",
        "LMs can generalize probabilistic anomaly detection to lists in non-linguistic domains (e.g., code, tabular data)."
    ],
    "negative_experiments": [
        "If LMs fail to flag low-probability items as anomalies, the theory would be challenged.",
        "If LMs cannot identify global anomalies in lists with subtle dependencies, the theory would be called into question."
    ],
    "unaccounted_for": [
        {
            "text": "Lists where all items are equally rare or the LM has not seen similar contexts in training.",
            "uuids": []
        }
    ],
    "conflicting_evidence": [
        {
            "text": "LMs may assign high probability to frequent but contextually anomalous items, missing true anomalies.",
            "uuids": []
        }
    ],
    "special_cases": [
        "Lists with adversarially constructed items to exploit LM biases.",
        "Lists from domains with distributional shift relative to LM training data."
    ],
    "existing_theory": {
        "what_already_exists": "Probabilistic anomaly detection is established, and LMs are known to assign probabilities to sequences.",
        "what_is_novel": "The explicit use of LMs' conditional and joint probabilities for unsupervised anomaly detection in arbitrary lists is novel.",
        "classification_explanation": "The theory extends existing probabilistic anomaly detection to the context of LMs and arbitrary lists.",
        "likely_classification": "somewhat-related-to-existing",
        "references": [
            "Goldstein & Uchida (2016) A Comparative Evaluation of Unsupervised Anomaly Detection Algorithms for Multivariate Data [probabilistic anomaly detection]",
            "Radford et al. (2019) Language Models are Unsupervised Multitask Learners [LMs assign probabilities to sequences]",
            "Chandola et al. (2009) Anomaly Detection: A Survey [sequence anomaly detection]"
        ]
    },
    "reflected_from_theory_index": 1,
    "type": "general",
    "version": "built-theory-from-results-single-theory-reflection2-nov14-2025-LLM-BASELINE-no-evidence-without-matched-control-theory-name",
    "theory_query": "Build a theory of how language models can be used for detecting anomalies in lists of data.",
    "original_theory_id": "theory-643",
    "original_theory_name": "Contextual and Semantic Reasoning Law for LLM-Based Anomaly Detection in Lists",
    "provide_matched_control_thery_name": false,
    "matched_control_theory_name": null,
    "model_str": "openai/gpt-4.1-2025-04-14"
}</code></pre>
        </div>
    </div>
</body>
</html>