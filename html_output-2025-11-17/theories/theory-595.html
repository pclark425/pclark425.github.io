<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Hybrid Memory Architectures Enable Robust Long-Horizon Reasoning and Generalization in LLM Agents for Text Games - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-595</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-595</p>
                <p><strong>Name:</strong> Hybrid Memory Architectures Enable Robust Long-Horizon Reasoning and Generalization in LLM Agents for Text Games</p>
                <p><strong>Type:</strong> general</p>
                <p><strong>Theory Query:</strong> Build a theory of how LLM agents for text games can best use memory to solve text game tasks, based on the following results.</p>
                <p><strong>Description:</strong> LLM agents for text games achieve robust long-horizon reasoning, behavioral coherence, and generalization when equipped with hybrid memory architectures that combine short-term (prompt/context window or working memory) and long-term (external, retrieval-augmented, or structured) memory. The hybrid approach enables agents to overcome context window limitations, maintain consistency across extended interactions, and transfer knowledge or skills across tasks and environments. The effectiveness of hybrid memory is maximized when memory is actively managed via summarization, prioritization, and retrieval strategies that balance recency, relevance, and importance.</p>
                <p><strong>Knowledge Cutoff Year:</strong> 2024</p>
                <p><strong>Knowledge Cutoff Month:</strong> 6</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <h3>Statement 0: Hybrid Memory Enables Long-Horizon Coherence and Generalization (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; agent &#8594; uses &#8594; hybrid memory (short-term + long-term)<span style="color: #888888;">, and</span></div>
        <div>&#8226; memory &#8594; is_managed_by &#8594; summarization and retrieval strategies</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; agent &#8594; achieves &#8594; robust long-horizon reasoning and behavioral coherence<span style="color: #888888;">, and</span></div>
        <div>&#8226; agent &#8594; generalizes &#8594; across tasks and environments</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Generative Agents, AgentSims, and RecurrentGPT all use hybrid memory (prompt-based short-term + vector DB/episodic long-term) to maintain behavioral consistency and long-form coherence in interactive fiction and social simulations. <a href="../results/extraction-result-4915.html#e4915.0" class="evidence-link">[e4915.0]</a> <a href="../results/extraction-result-4900.html#e4900.4" class="evidence-link">[e4900.4]</a> <a href="../results/extraction-result-4876.html#e4876.4" class="evidence-link">[e4876.4]</a> <a href="../results/extraction-result-4919.html#e4919.4" class="evidence-link">[e4919.4]</a> <a href="../results/extraction-result-4900.html#e4900.1" class="evidence-link">[e4900.1]</a> <a href="../results/extraction-result-4660.html#e4660.0" class="evidence-link">[e4660.0]</a> <a href="../results/extraction-result-4685.html#e4685.3" class="evidence-link">[e4685.3]</a> </li>
    <li>Voyager's skill library (vector DB of executable programs) combined with curriculum history enables open-ended exploration and zero-shot generalization in Minecraft, outperforming baselines without such memory. <a href="../results/extraction-result-4919.html#e4919.0" class="evidence-link">[e4919.0]</a> <a href="../results/extraction-result-4919.html#e4919.3" class="evidence-link">[e4919.3]</a> </li>
    <li>CoELA, AGENTS, and LLM-Agent (LLM-Coordination) frameworks use explicit modular memory (semantic, episodic, procedural) to support multi-agent collaboration, planning, and ToM reasoning, with ablations showing severe degradation when memory is removed. <a href="../results/extraction-result-4864.html#e4864.0" class="evidence-link">[e4864.0]</a> <a href="../results/extraction-result-4915.html#e4915.0" class="evidence-link">[e4915.0]</a> <a href="../results/extraction-result-4659.html#e4659.0" class="evidence-link">[e4659.0]</a> </li>
    <li>RecurrentGPT ablations show that removing either short-term or long-term memory causes large drops in coherence and interestingness in long text generation. <a href="../results/extraction-result-4876.html#e4876.2" class="evidence-link">[e4876.2]</a> <a href="../results/extraction-result-4876.html#e4876.3" class="evidence-link">[e4876.3]</a> <a href="../results/extraction-result-4876.html#e4876.4" class="evidence-link">[e4876.4]</a> </li>
    <li>Generative Agents and AgentSims use retrieval-augmented long-term memory to recall relevant experiences, with memory management (summarization, importance ranking) to fit within prompt limits. <a href="../results/extraction-result-4915.html#e4915.0" class="evidence-link">[e4915.0]</a> <a href="../results/extraction-result-4900.html#e4900.4" class="evidence-link">[e4900.4]</a> <a href="../results/extraction-result-4919.html#e4919.4" class="evidence-link">[e4919.4]</a> <a href="../results/extraction-result-4900.html#e4900.1" class="evidence-link">[e4900.1]</a> <a href="../results/extraction-result-4660.html#e4660.0" class="evidence-link">[e4660.0]</a> <a href="../results/extraction-result-4685.html#e4685.3" class="evidence-link">[e4685.3]</a> </li>
    <li>Surveys and architectural proposals (e.g., Episodic Buffer, Working Memory Hub, Memory Management Agent) recommend hybrid memory and active management for LLM agents. <a href="../results/extraction-result-4663.html#e4663.1" class="evidence-link">[e4663.1]</a> <a href="../results/extraction-result-4663.html#e4663.2" class="evidence-link">[e4663.2]</a> <a href="../results/extraction-result-4663.html#e4663.3" class="evidence-link">[e4663.3]</a> <a href="../results/extraction-result-4660.html#e4660.1" class="evidence-link">[e4660.1]</a> </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> While hybrid memory is discussed in cognitive architectures, this law synthesizes empirical evidence from diverse LLM agent systems and formalizes the conditions and outcomes for text game agents.</p>            <p><strong>What Already Exists:</strong> Hybrid memory architectures are discussed in cognitive architectures and some LLM agent frameworks, but their necessity and empirical impact for long-horizon text game reasoning and generalization is not formalized.</p>            <p><strong>What is Novel:</strong> This law formalizes the necessity and empirical benefit of hybrid memory (short-term + long-term) with active management for robust long-horizon reasoning and generalization in LLM agents for text games.</p>
            <p><strong>References:</strong> <ul>
    <li>Park et al. (2023) Generative agents: Interactive simulacra of human behavior [hybrid memory in social simulation]</li>
    <li>Zhou et al. (2023) RecurrentGPT: Interactive generation of (arbitrarily) long text [hybrid memory for long-form generation]</li>
    <li>Wang et al. (2023) Agents: An Open-source Framework for Autonomous Language Agents [modular memory in LLM agents]</li>
    <li>Li et al. (2023) Empowering Working Memory for Large Language Model Agents [memory management and hybrid memory proposal]</li>
</ul>
            <h3>Statement 1: Active Memory Management (Summarization, Prioritization, Retrieval) is Required for Scalability and Relevance (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; agent &#8594; has &#8594; growing long-term memory<span style="color: #888888;">, and</span></div>
        <div>&#8226; memory &#8594; is_managed_by &#8594; summarization, prioritization, and retrieval</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; agent &#8594; maintains &#8594; scalable and relevant memory for decision-making</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Generative Agents, AgentSims, and RecurrentGPT all use summarization and importance/relevance ranking to condense and retrieve salient memories, enabling agents to avoid unbounded context growth and maintain relevant information. <a href="../results/extraction-result-4915.html#e4915.0" class="evidence-link">[e4915.0]</a> <a href="../results/extraction-result-4900.html#e4900.4" class="evidence-link">[e4900.4]</a> <a href="../results/extraction-result-4876.html#e4876.4" class="evidence-link">[e4876.4]</a> <a href="../results/extraction-result-4919.html#e4919.4" class="evidence-link">[e4919.4]</a> <a href="../results/extraction-result-4900.html#e4900.1" class="evidence-link">[e4900.1]</a> <a href="../results/extraction-result-4660.html#e4660.0" class="evidence-link">[e4660.0]</a> <a href="../results/extraction-result-4685.html#e4685.3" class="evidence-link">[e4685.3]</a> </li>
    <li>Voyager condenses successful trajectories into abstract skills and uses embedding-based retrieval to select relevant skills for new tasks. <a href="../results/extraction-result-4919.html#e4919.0" class="evidence-link">[e4919.0]</a> <a href="../results/extraction-result-4919.html#e4919.3" class="evidence-link">[e4919.3]</a> </li>
    <li>PsychoGAT uses explicit summarization-based narrative memory, with controller and critic agents enforcing concise, justified memory updates and size limits. <a href="../results/extraction-result-4661.html#e4661.0" class="evidence-link">[e4661.0]</a> </li>
    <li>Surveys and architectural proposals (e.g., Memory Management Agent, Episodic Buffer, Working Memory Hub) emphasize the need for summarization, prioritization, and retrieval to manage memory growth and relevance. <a href="../results/extraction-result-4663.html#e4663.1" class="evidence-link">[e4663.1]</a> <a href="../results/extraction-result-4663.html#e4663.2" class="evidence-link">[e4663.2]</a> <a href="../results/extraction-result-4663.html#e4663.3" class="evidence-link">[e4663.3]</a> <a href="../results/extraction-result-4660.html#e4660.1" class="evidence-link">[e4660.1]</a> </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> While summarization and retrieval are known, this law synthesizes their necessity and empirical impact in the context of LLM agents for text games.</p>            <p><strong>What Already Exists:</strong> Summarization and retrieval are known in information retrieval and cognitive architectures, but their necessity for scalable, relevant memory in LLM agents for text games is not formalized.</p>            <p><strong>What is Novel:</strong> This law formalizes the requirement for active memory management (summarization, prioritization, retrieval) to maintain scalable and relevant memory in LLM agents for text games.</p>
            <p><strong>References:</strong> <ul>
    <li>Park et al. (2023) Generative agents: Interactive simulacra of human behavior [summarization and retrieval in agent memory]</li>
    <li>Li et al. (2023) Empowering Working Memory for Large Language Model Agents [memory management proposal]</li>
    <li>Zhou et al. (2023) RecurrentGPT: Interactive generation of (arbitrarily) long text [summarization and retrieval in long-form generation]</li>
</ul>
            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>An LLM agent for a long-horizon text game equipped with both short-term (prompt) and long-term (retrieval-augmented) memory, with active summarization and prioritization, will maintain behavioral coherence and outperform agents with only prompt-based memory on tasks requiring recall of distant events.</li>
                <li>In a multi-agent simulation, agents with hybrid memory and active management will exhibit more consistent, human-like social behaviors and better recall of past interactions than agents with only short-term memory.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>If hybrid memory is extended to support collaborative memory sharing among agents, emergent group-level planning or social phenomena may arise.</li>
                <li>In highly dynamic or adversarial environments, hybrid memory with adaptive summarization may enable agents to develop new forms of strategic deception or alliance formation.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>If an agent with only prompt-based memory (no long-term retrieval) matches or exceeds the performance and coherence of a hybrid-memory agent on long-horizon or multi-session tasks, the theory would be challenged.</li>
                <li>If active memory management (summarization, prioritization) fails to improve or even degrades performance compared to naive full-history concatenation, the theory would be undermined.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>Some tasks (e.g., short, single-turn games or tasks with minimal long-term dependencies) may not benefit from hybrid memory, and prompt-only agents may suffice. <a href="../results/extraction-result-4899.html#e4899.1" class="evidence-link">[e4899.1]</a> <a href="../results/extraction-result-4899.html#e4899.0" class="evidence-link">[e4899.0]</a> <a href="../results/extraction-result-4899.html#e4899.2" class="evidence-link">[e4899.2]</a> <a href="../results/extraction-result-4882.html#e4882.2" class="evidence-link">[e4882.2]</a> <a href="../results/extraction-result-4882.html#e4882.1" class="evidence-link">[e4882.1]</a> <a href="../results/extraction-result-4882.html#e4882.0" class="evidence-link">[e4882.0]</a> </li>
    <li>In certain RL or symbolic agents (e.g., BabyAI bot, NAIL), hand-crafted or structured memory may outperform learned hybrid memory in specific domains. <a href="../results/extraction-result-4891.html#e4891.1" class="evidence-link">[e4891.1]</a> <a href="../results/extraction-result-4673.html#e4673.0" class="evidence-link">[e4673.0]</a> <a href="../results/extraction-result-4923.html#e4923.1" class="evidence-link">[e4923.1]</a> </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> somewhat-related-to-existing</p>
            <p><strong>Explanation:</strong> While hybrid memory is discussed in cognitive architectures, this theory synthesizes empirical evidence from diverse LLM agent systems and formalizes the conditions and outcomes for text game agents.</p>
            <p><strong>References:</strong> <ul>
    <li>Park et al. (2023) Generative agents: Interactive simulacra of human behavior [hybrid memory in social simulation]</li>
    <li>Zhou et al. (2023) RecurrentGPT: Interactive generation of (arbitrarily) long text [hybrid memory for long-form generation]</li>
    <li>Wang et al. (2023) Agents: An Open-source Framework for Autonomous Language Agents [modular memory in LLM agents]</li>
    <li>Li et al. (2023) Empowering Working Memory for Large Language Model Agents [memory management and hybrid memory proposal]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Hybrid Memory Architectures Enable Robust Long-Horizon Reasoning and Generalization in LLM Agents for Text Games",
    "theory_description": "LLM agents for text games achieve robust long-horizon reasoning, behavioral coherence, and generalization when equipped with hybrid memory architectures that combine short-term (prompt/context window or working memory) and long-term (external, retrieval-augmented, or structured) memory. The hybrid approach enables agents to overcome context window limitations, maintain consistency across extended interactions, and transfer knowledge or skills across tasks and environments. The effectiveness of hybrid memory is maximized when memory is actively managed via summarization, prioritization, and retrieval strategies that balance recency, relevance, and importance.",
    "theory_statements": [
        {
            "law": {
                "law_name": "Hybrid Memory Enables Long-Horizon Coherence and Generalization",
                "if": [
                    {
                        "subject": "agent",
                        "relation": "uses",
                        "object": "hybrid memory (short-term + long-term)"
                    },
                    {
                        "subject": "memory",
                        "relation": "is_managed_by",
                        "object": "summarization and retrieval strategies"
                    }
                ],
                "then": [
                    {
                        "subject": "agent",
                        "relation": "achieves",
                        "object": "robust long-horizon reasoning and behavioral coherence"
                    },
                    {
                        "subject": "agent",
                        "relation": "generalizes",
                        "object": "across tasks and environments"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Generative Agents, AgentSims, and RecurrentGPT all use hybrid memory (prompt-based short-term + vector DB/episodic long-term) to maintain behavioral consistency and long-form coherence in interactive fiction and social simulations.",
                        "uuids": [
                            "e4915.0",
                            "e4900.4",
                            "e4876.4",
                            "e4919.4",
                            "e4900.1",
                            "e4660.0",
                            "e4685.3"
                        ]
                    },
                    {
                        "text": "Voyager's skill library (vector DB of executable programs) combined with curriculum history enables open-ended exploration and zero-shot generalization in Minecraft, outperforming baselines without such memory.",
                        "uuids": [
                            "e4919.0",
                            "e4919.3"
                        ]
                    },
                    {
                        "text": "CoELA, AGENTS, and LLM-Agent (LLM-Coordination) frameworks use explicit modular memory (semantic, episodic, procedural) to support multi-agent collaboration, planning, and ToM reasoning, with ablations showing severe degradation when memory is removed.",
                        "uuids": [
                            "e4864.0",
                            "e4915.0",
                            "e4659.0"
                        ]
                    },
                    {
                        "text": "RecurrentGPT ablations show that removing either short-term or long-term memory causes large drops in coherence and interestingness in long text generation.",
                        "uuids": [
                            "e4876.2",
                            "e4876.3",
                            "e4876.4"
                        ]
                    },
                    {
                        "text": "Generative Agents and AgentSims use retrieval-augmented long-term memory to recall relevant experiences, with memory management (summarization, importance ranking) to fit within prompt limits.",
                        "uuids": [
                            "e4915.0",
                            "e4900.4",
                            "e4919.4",
                            "e4900.1",
                            "e4660.0",
                            "e4685.3"
                        ]
                    },
                    {
                        "text": "Surveys and architectural proposals (e.g., Episodic Buffer, Working Memory Hub, Memory Management Agent) recommend hybrid memory and active management for LLM agents.",
                        "uuids": [
                            "e4663.1",
                            "e4663.2",
                            "e4663.3",
                            "e4660.1"
                        ]
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Hybrid memory architectures are discussed in cognitive architectures and some LLM agent frameworks, but their necessity and empirical impact for long-horizon text game reasoning and generalization is not formalized.",
                    "what_is_novel": "This law formalizes the necessity and empirical benefit of hybrid memory (short-term + long-term) with active management for robust long-horizon reasoning and generalization in LLM agents for text games.",
                    "classification_explanation": "While hybrid memory is discussed in cognitive architectures, this law synthesizes empirical evidence from diverse LLM agent systems and formalizes the conditions and outcomes for text game agents.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Park et al. (2023) Generative agents: Interactive simulacra of human behavior [hybrid memory in social simulation]",
                        "Zhou et al. (2023) RecurrentGPT: Interactive generation of (arbitrarily) long text [hybrid memory for long-form generation]",
                        "Wang et al. (2023) Agents: An Open-source Framework for Autonomous Language Agents [modular memory in LLM agents]",
                        "Li et al. (2023) Empowering Working Memory for Large Language Model Agents [memory management and hybrid memory proposal]"
                    ]
                }
            }
        },
        {
            "law": {
                "law_name": "Active Memory Management (Summarization, Prioritization, Retrieval) is Required for Scalability and Relevance",
                "if": [
                    {
                        "subject": "agent",
                        "relation": "has",
                        "object": "growing long-term memory"
                    },
                    {
                        "subject": "memory",
                        "relation": "is_managed_by",
                        "object": "summarization, prioritization, and retrieval"
                    }
                ],
                "then": [
                    {
                        "subject": "agent",
                        "relation": "maintains",
                        "object": "scalable and relevant memory for decision-making"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Generative Agents, AgentSims, and RecurrentGPT all use summarization and importance/relevance ranking to condense and retrieve salient memories, enabling agents to avoid unbounded context growth and maintain relevant information.",
                        "uuids": [
                            "e4915.0",
                            "e4900.4",
                            "e4876.4",
                            "e4919.4",
                            "e4900.1",
                            "e4660.0",
                            "e4685.3"
                        ]
                    },
                    {
                        "text": "Voyager condenses successful trajectories into abstract skills and uses embedding-based retrieval to select relevant skills for new tasks.",
                        "uuids": [
                            "e4919.0",
                            "e4919.3"
                        ]
                    },
                    {
                        "text": "PsychoGAT uses explicit summarization-based narrative memory, with controller and critic agents enforcing concise, justified memory updates and size limits.",
                        "uuids": [
                            "e4661.0"
                        ]
                    },
                    {
                        "text": "Surveys and architectural proposals (e.g., Memory Management Agent, Episodic Buffer, Working Memory Hub) emphasize the need for summarization, prioritization, and retrieval to manage memory growth and relevance.",
                        "uuids": [
                            "e4663.1",
                            "e4663.2",
                            "e4663.3",
                            "e4660.1"
                        ]
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Summarization and retrieval are known in information retrieval and cognitive architectures, but their necessity for scalable, relevant memory in LLM agents for text games is not formalized.",
                    "what_is_novel": "This law formalizes the requirement for active memory management (summarization, prioritization, retrieval) to maintain scalable and relevant memory in LLM agents for text games.",
                    "classification_explanation": "While summarization and retrieval are known, this law synthesizes their necessity and empirical impact in the context of LLM agents for text games.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Park et al. (2023) Generative agents: Interactive simulacra of human behavior [summarization and retrieval in agent memory]",
                        "Li et al. (2023) Empowering Working Memory for Large Language Model Agents [memory management proposal]",
                        "Zhou et al. (2023) RecurrentGPT: Interactive generation of (arbitrarily) long text [summarization and retrieval in long-form generation]"
                    ]
                }
            }
        }
    ],
    "new_predictions_likely": [
        "An LLM agent for a long-horizon text game equipped with both short-term (prompt) and long-term (retrieval-augmented) memory, with active summarization and prioritization, will maintain behavioral coherence and outperform agents with only prompt-based memory on tasks requiring recall of distant events.",
        "In a multi-agent simulation, agents with hybrid memory and active management will exhibit more consistent, human-like social behaviors and better recall of past interactions than agents with only short-term memory."
    ],
    "new_predictions_unknown": [
        "If hybrid memory is extended to support collaborative memory sharing among agents, emergent group-level planning or social phenomena may arise.",
        "In highly dynamic or adversarial environments, hybrid memory with adaptive summarization may enable agents to develop new forms of strategic deception or alliance formation."
    ],
    "negative_experiments": [
        "If an agent with only prompt-based memory (no long-term retrieval) matches or exceeds the performance and coherence of a hybrid-memory agent on long-horizon or multi-session tasks, the theory would be challenged.",
        "If active memory management (summarization, prioritization) fails to improve or even degrades performance compared to naive full-history concatenation, the theory would be undermined."
    ],
    "unaccounted_for": [
        {
            "text": "Some tasks (e.g., short, single-turn games or tasks with minimal long-term dependencies) may not benefit from hybrid memory, and prompt-only agents may suffice.",
            "uuids": [
                "e4899.1",
                "e4899.0",
                "e4899.2",
                "e4882.2",
                "e4882.1",
                "e4882.0"
            ]
        },
        {
            "text": "In certain RL or symbolic agents (e.g., BabyAI bot, NAIL), hand-crafted or structured memory may outperform learned hybrid memory in specific domains.",
            "uuids": [
                "e4891.1",
                "e4673.0",
                "e4923.1"
            ]
        }
    ],
    "conflicting_evidence": [
        {
            "text": "In some cases, naive inclusion of action history or memory (e.g., Swift agent with 10-action history) degraded performance, indicating that memory must be carefully managed and tailored to the architecture.",
            "uuids": [
                "e4652.1"
            ]
        },
        {
            "text": "WebShop IL agent's naive history concatenation degraded performance, suggesting that not all memory augmentation is beneficial without proper design.",
            "uuids": [
                "e4875.0"
            ]
        }
    ],
    "special_cases": [
        "Tasks with extremely short horizons or where all relevant information is present in the immediate observation may not benefit from long-term memory.",
        "If memory management (summarization, prioritization) is poorly designed, it may remove critical information and harm performance."
    ],
    "existing_theory": {
        "what_already_exists": "Hybrid memory and memory management are discussed in cognitive architectures and some LLM agent frameworks, but their necessity and empirical impact for long-horizon text game reasoning and generalization is not formalized.",
        "what_is_novel": "This theory formalizes the necessity and empirical benefit of hybrid memory (short-term + long-term) with active management for robust long-horizon reasoning and generalization in LLM agents for text games.",
        "classification_explanation": "While hybrid memory is discussed in cognitive architectures, this theory synthesizes empirical evidence from diverse LLM agent systems and formalizes the conditions and outcomes for text game agents.",
        "likely_classification": "somewhat-related-to-existing",
        "references": [
            "Park et al. (2023) Generative agents: Interactive simulacra of human behavior [hybrid memory in social simulation]",
            "Zhou et al. (2023) RecurrentGPT: Interactive generation of (arbitrarily) long text [hybrid memory for long-form generation]",
            "Wang et al. (2023) Agents: An Open-source Framework for Autonomous Language Agents [modular memory in LLM agents]",
            "Li et al. (2023) Empowering Working Memory for Large Language Model Agents [memory management and hybrid memory proposal]"
        ]
    },
    "reflected_from_theory_index": 3,
    "version": "built-theory-from-results-single-theory-reflection2-nov14-2025",
    "type": "general"
}</code></pre>
        </div>
    </div>
</body>
</html>