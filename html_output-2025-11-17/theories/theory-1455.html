<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Unified Hierarchical Predictive Hybridism (UHPH) – Predictive Coding Extension - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-1455</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-1455</p>
                <p><strong>Name:</strong> Unified Hierarchical Predictive Hybridism (UHPH) – Predictive Coding Extension</p>
                <p><strong>Type:</strong> general</p>
                <p><strong>Theory Query:</strong> Build a theory of the representational format of conceptual knowledge in brains at a functional (not neural) level.</p>
                <p><strong>Description:</strong> This extension of UHPH asserts that the primary function of the hierarchical, hybrid representational system is to generate and update predictions about sensory, motor, and conceptual states. Prediction errors at each level drive learning and inference, and the hybrid format allows for flexible integration of distributed, symbolic, and sensorimotor information to minimize uncertainty and optimize behavior.</p>
                <p><strong>Knowledge Cutoff Year:</strong> -1</p>
                <p><strong>Knowledge Cutoff Month:</strong> -1</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <h3>Statement 0: Prediction-Driven Representation Update (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; current state &#8594; is_represented_as &#8594; hybrid hierarchical code<span style="color: #888888;">, and</span></div>
        <div>&#8226; incoming information &#8594; is_received &#8594; sensory/motor/conceptual</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; prediction error &#8594; is_computed_at &#8594; each hierarchical level<span style="color: #888888;">, and</span></div>
        <div>&#8226; representational code &#8594; is_updated_to_minimize &#8594; prediction error</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Predictive coding models and empirical data show that brains compute prediction errors at multiple levels and update representations accordingly. </li>
    <li>Neural responses to unexpected stimuli are larger and drive representational change. </li>
    <li>Hierarchical Bayesian models in cognitive science support multi-level error-driven updating. </li>
    <li>Learning in deep neural networks is driven by error backpropagation, analogous to prediction error minimization. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> closely-related-to-existing</p>
            <p><strong>Explanation:</strong> Predictive coding is established, but its extension to hybrid representational formats is novel.</p>            <p><strong>What Already Exists:</strong> Predictive coding and error-driven learning are established in neuroscience.</p>            <p><strong>What is Novel:</strong> The claim that prediction error minimization operates over hybrid, multi-format representations at all hierarchical levels, not just distributed codes.</p>
            <p><strong>References:</strong> <ul>
    <li>Friston (2010) The free-energy principle [Predictive coding]</li>
    <li>Clark (2013) Whatever next? Predictive brains, situated agents, and the future of cognitive science [Predictive processing]</li>
    <li>Hinton (2007) Learning multiple layers of representation [Error-driven learning in distributed codes]</li>
</ul>
            <h3>Statement 1: Format-Specific Prediction Error Integration (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; prediction error &#8594; is_generated_in &#8594; one representational format (e.g., sensorimotor)<span style="color: #888888;">, and</span></div>
        <div>&#8226; conceptual knowledge &#8594; is_encoded_in &#8594; hybrid format</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; prediction error &#8594; is_integrated_across &#8594; all representational formats<span style="color: #888888;">, and</span></div>
        <div>&#8226; learning and inference &#8594; are_optimized_by &#8594; cross-format integration</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Cross-modal prediction errors (e.g., visual-auditory mismatch) lead to representational updating in both modalities and in higher-level conceptual areas. </li>
    <li>Hybrid models in AI (e.g., neuro-symbolic systems) show improved learning when integrating errors across formats. </li>
    <li>Neuroimaging studies show that prediction errors in one modality can modulate activity in other, non-matching modalities. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> Cross-modal error integration is established, but cross-format (symbolic/distributed/sensorimotor) integration in conceptual knowledge is novel.</p>            <p><strong>What Already Exists:</strong> Prediction error integration across sensory modalities is known.</p>            <p><strong>What is Novel:</strong> The claim that prediction errors are integrated across distributed, symbolic, and sensorimotor codes within conceptual knowledge, not just across sensory modalities.</p>
            <p><strong>References:</strong> <ul>
    <li>Clark (2013) Whatever next? [Predictive processing, cross-modal integration]</li>
    <li>Marcus et al. (2014) The atoms of neural computation [Neuro-symbolic integration]</li>
    <li>Binder & Desai (2011) The neurobiology of semantic memory [Multi-format conceptual representations]</li>
</ul>
            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>Prediction errors in one representational format (e.g., sensorimotor) will induce representational updating in other formats (e.g., symbolic) during conceptual learning.</li>
                <li>Neuroimaging will reveal coordinated error signals across distributed, symbolic, and sensorimotor networks during conceptual change.</li>
                <li>Hybrid AI models that integrate prediction errors across formats will learn new concepts more efficiently than single-format models.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>Direct manipulation of prediction errors in symbolic representations (e.g., via language priming) will induce measurable changes in distributed and sensorimotor codes.</li>
                <li>In neurodevelopmental disorders, specific deficits in cross-format prediction error integration will correlate with conceptual learning impairments.</li>
                <li>Real-time neural decoding will reveal format-specific prediction error signals converging in higher-order conceptual hubs.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>If prediction errors in one format do not influence representations in other formats, the theory would be challenged.</li>
                <li>If conceptual learning can occur without any evidence of prediction error signals, the theory would be called into question.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>The precise mechanisms by which prediction errors are communicated and integrated across representational formats are not fully specified. </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> closely-related-to-existing</p>
            <p><strong>Explanation:</strong> The theory extends predictive coding to a new domain (hybrid conceptual representations), making it closely related but novel in scope.</p>
            <p><strong>References:</strong> <ul>
    <li>Friston (2010) The free-energy principle [Predictive coding]</li>
    <li>Clark (2013) Whatever next? [Predictive processing]</li>
    <li>Marcus et al. (2014) The atoms of neural computation [Neuro-symbolic integration]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Unified Hierarchical Predictive Hybridism (UHPH) – Predictive Coding Extension",
    "theory_description": "This extension of UHPH asserts that the primary function of the hierarchical, hybrid representational system is to generate and update predictions about sensory, motor, and conceptual states. Prediction errors at each level drive learning and inference, and the hybrid format allows for flexible integration of distributed, symbolic, and sensorimotor information to minimize uncertainty and optimize behavior.",
    "theory_statements": [
        {
            "law": {
                "law_name": "Prediction-Driven Representation Update",
                "if": [
                    {
                        "subject": "current state",
                        "relation": "is_represented_as",
                        "object": "hybrid hierarchical code"
                    },
                    {
                        "subject": "incoming information",
                        "relation": "is_received",
                        "object": "sensory/motor/conceptual"
                    }
                ],
                "then": [
                    {
                        "subject": "prediction error",
                        "relation": "is_computed_at",
                        "object": "each hierarchical level"
                    },
                    {
                        "subject": "representational code",
                        "relation": "is_updated_to_minimize",
                        "object": "prediction error"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Predictive coding models and empirical data show that brains compute prediction errors at multiple levels and update representations accordingly.",
                        "uuids": []
                    },
                    {
                        "text": "Neural responses to unexpected stimuli are larger and drive representational change.",
                        "uuids": []
                    },
                    {
                        "text": "Hierarchical Bayesian models in cognitive science support multi-level error-driven updating.",
                        "uuids": []
                    },
                    {
                        "text": "Learning in deep neural networks is driven by error backpropagation, analogous to prediction error minimization.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Predictive coding and error-driven learning are established in neuroscience.",
                    "what_is_novel": "The claim that prediction error minimization operates over hybrid, multi-format representations at all hierarchical levels, not just distributed codes.",
                    "classification_explanation": "Predictive coding is established, but its extension to hybrid representational formats is novel.",
                    "likely_classification": "closely-related-to-existing",
                    "references": [
                        "Friston (2010) The free-energy principle [Predictive coding]",
                        "Clark (2013) Whatever next? Predictive brains, situated agents, and the future of cognitive science [Predictive processing]",
                        "Hinton (2007) Learning multiple layers of representation [Error-driven learning in distributed codes]"
                    ]
                }
            }
        },
        {
            "law": {
                "law_name": "Format-Specific Prediction Error Integration",
                "if": [
                    {
                        "subject": "prediction error",
                        "relation": "is_generated_in",
                        "object": "one representational format (e.g., sensorimotor)"
                    },
                    {
                        "subject": "conceptual knowledge",
                        "relation": "is_encoded_in",
                        "object": "hybrid format"
                    }
                ],
                "then": [
                    {
                        "subject": "prediction error",
                        "relation": "is_integrated_across",
                        "object": "all representational formats"
                    },
                    {
                        "subject": "learning and inference",
                        "relation": "are_optimized_by",
                        "object": "cross-format integration"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Cross-modal prediction errors (e.g., visual-auditory mismatch) lead to representational updating in both modalities and in higher-level conceptual areas.",
                        "uuids": []
                    },
                    {
                        "text": "Hybrid models in AI (e.g., neuro-symbolic systems) show improved learning when integrating errors across formats.",
                        "uuids": []
                    },
                    {
                        "text": "Neuroimaging studies show that prediction errors in one modality can modulate activity in other, non-matching modalities.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Prediction error integration across sensory modalities is known.",
                    "what_is_novel": "The claim that prediction errors are integrated across distributed, symbolic, and sensorimotor codes within conceptual knowledge, not just across sensory modalities.",
                    "classification_explanation": "Cross-modal error integration is established, but cross-format (symbolic/distributed/sensorimotor) integration in conceptual knowledge is novel.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Clark (2013) Whatever next? [Predictive processing, cross-modal integration]",
                        "Marcus et al. (2014) The atoms of neural computation [Neuro-symbolic integration]",
                        "Binder & Desai (2011) The neurobiology of semantic memory [Multi-format conceptual representations]"
                    ]
                }
            }
        }
    ],
    "new_predictions_likely": [
        "Prediction errors in one representational format (e.g., sensorimotor) will induce representational updating in other formats (e.g., symbolic) during conceptual learning.",
        "Neuroimaging will reveal coordinated error signals across distributed, symbolic, and sensorimotor networks during conceptual change.",
        "Hybrid AI models that integrate prediction errors across formats will learn new concepts more efficiently than single-format models."
    ],
    "new_predictions_unknown": [
        "Direct manipulation of prediction errors in symbolic representations (e.g., via language priming) will induce measurable changes in distributed and sensorimotor codes.",
        "In neurodevelopmental disorders, specific deficits in cross-format prediction error integration will correlate with conceptual learning impairments.",
        "Real-time neural decoding will reveal format-specific prediction error signals converging in higher-order conceptual hubs."
    ],
    "negative_experiments": [
        "If prediction errors in one format do not influence representations in other formats, the theory would be challenged.",
        "If conceptual learning can occur without any evidence of prediction error signals, the theory would be called into question."
    ],
    "unaccounted_for": [
        {
            "text": "The precise mechanisms by which prediction errors are communicated and integrated across representational formats are not fully specified.",
            "uuids": []
        }
    ],
    "conflicting_evidence": [
        {
            "text": "Some studies suggest that certain forms of conceptual learning can occur without explicit prediction error signals.",
            "uuids": []
        }
    ],
    "special_cases": [
        "Highly familiar or overlearned concepts may generate minimal prediction errors and thus show little cross-format updating.",
        "In cases of brain injury, prediction error integration may be disrupted, leading to selective conceptual deficits."
    ],
    "existing_theory": {
        "what_already_exists": "Predictive coding and cross-modal error integration are established.",
        "what_is_novel": "The extension of prediction error minimization and integration to hybrid, multi-format conceptual representations.",
        "classification_explanation": "The theory extends predictive coding to a new domain (hybrid conceptual representations), making it closely related but novel in scope.",
        "likely_classification": "closely-related-to-existing",
        "references": [
            "Friston (2010) The free-energy principle [Predictive coding]",
            "Clark (2013) Whatever next? [Predictive processing]",
            "Marcus et al. (2014) The atoms of neural computation [Neuro-symbolic integration]"
        ]
    },
    "reflected_from_theory_index": 1,
    "type": "general",
    "version": "built-theory-from-results-single-theory-reflection2-nov14-2025-LLM-BASELINE-no-evidence-with-matched-control-theory-name",
    "theory_query": "Build a theory of the representational format of conceptual knowledge in brains at a functional (not neural) level.",
    "original_theory_id": "theory-624",
    "original_theory_name": "Unified Hierarchical Predictive Hybridism (UHPH)",
    "provide_matched_control_thery_name": true,
    "matched_control_theory_name": "Unified Hierarchical Predictive Hybridism (UHPH)",
    "model_str": "openai/gpt-4.1-2025-04-14"
}</code></pre>
        </div>
    </div>
</body>
</html>