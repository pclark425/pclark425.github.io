<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Dual-Process Reasoning Theory for Language Models - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-1158</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-1158</p>
                <p><strong>Name:</strong> Dual-Process Reasoning Theory for Language Models</p>
                <p><strong>Type:</strong> general</p>
                <p><strong>Theory Query:</strong> Build a theory of how language models can best perform strict logical reasoning.</p>
                <p><strong>Description:</strong> This theory posits that language models (LMs) can best perform strict logical reasoning when they integrate two distinct but interacting reasoning processes: (1) a fast, heuristic-driven process for initial response generation, and (2) a slow, rule-based process for explicit logical verification and correction. The theory asserts that optimal logical performance arises from the dynamic interplay between these processes, with the rule-based process monitoring and, if necessary, overriding the heuristic process to ensure logical fidelity.</p>
                <p><strong>Knowledge Cutoff Year:</strong> -1</p>
                <p><strong>Knowledge Cutoff Month:</strong> -1</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <h3>Statement 0: Heuristic-Rule Duality Law (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; language model &#8594; is_engaged_in &#8594; logical reasoning task</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; language model &#8594; activates &#8594; heuristic reasoning process<span style="color: #888888;">, and</span></div>
        <div>&#8226; language model &#8594; activates &#8594; rule-based reasoning process</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Human reasoning is often modeled as dual-process (Kahneman, 2011), and LMs show both fast, intuitive and slow, deliberative behaviors. </li>
    <li>LMs can generate quick, plausible answers but benefit from explicit logical verification steps. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> closely-related-to-existing</p>
            <p><strong>Explanation:</strong> The law adapts dual-process theory from cognitive science to LMs, formalizing the need for both processes and their interaction.</p>            <p><strong>What Already Exists:</strong> Dual-process theories are well-established in cognitive science for human reasoning; LMs have been observed to benefit from both fast and slow reasoning modes.</p>            <p><strong>What is Novel:</strong> Explicitly formalizing the interaction and monitoring between heuristic and rule-based processes within LMs for strict logical reasoning.</p>
            <p><strong>References:</strong> <ul>
    <li>Kahneman (2011) Thinking, Fast and Slow [dual-process theory in humans]</li>
    <li>Wei et al. (2022) Chain-of-thought prompting elicits reasoning in LMs [slow, deliberative reasoning in LMs]</li>
</ul>
            <h3>Statement 1: Rule-Based Override Law (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; heuristic reasoning process &#8594; produces &#8594; output<span style="color: #888888;">, and</span></div>
        <div>&#8226; rule-based reasoning process &#8594; detects &#8594; logical inconsistency in output</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; rule-based reasoning process &#8594; overrides &#8594; heuristic output<span style="color: #888888;">, and</span></div>
        <div>&#8226; language model &#8594; outputs &#8594; logically consistent answer</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>LMs can self-correct or be prompted to verify and revise initial outputs, improving logical accuracy. </li>
    <li>Explicit logical verification steps catch and correct errors from initial, heuristic outputs. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> The law extends existing self-correction by embedding it in a dual-process framework for LMs.</p>            <p><strong>What Already Exists:</strong> Self-correction and verification in LMs are known, as is the benefit of explicit logical steps.</p>            <p><strong>What is Novel:</strong> The formalization of a rule-based process that can override heuristic outputs within a dual-process LM architecture.</p>
            <p><strong>References:</strong> <ul>
    <li>Madaan et al. (2023) Self-refine: Iterative refinement with self-feedback [self-correction in LMs]</li>
    <li>Wang et al. (2022) Self-consistency improves chain of thought reasoning in language models [verification in LMs]</li>
</ul>
            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>LMs with explicit dual-process architectures will outperform those with only heuristic or only rule-based reasoning on strict logical tasks.</li>
                <li>Introducing a rule-based verification step after initial output will reduce logical errors in LM responses.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>The dual-process approach may enable LMs to generalize logical reasoning to domains with novel or ambiguous rules.</li>
                <li>Dynamic weighting between heuristic and rule-based processes may optimize both speed and accuracy in logical reasoning.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>If LMs with dual-process architectures do not outperform single-process LMs on logical reasoning tasks, the theory is undermined.</li>
                <li>If rule-based overrides do not improve logical consistency, the theory's assumptions are challenged.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>Some logical errors may arise from limitations in the rule-based process itself, not just the heuristic process. </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> somewhat-related-to-existing</p>
            <p><strong>Explanation:</strong> The theory adapts and extends dual-process theory to LMs, introducing explicit interaction and override mechanisms.</p>
            <p><strong>References:</strong> <ul>
    <li>Kahneman (2011) Thinking, Fast and Slow [dual-process theory in humans]</li>
    <li>Wei et al. (2022) Chain-of-thought prompting elicits reasoning in LMs [deliberative reasoning in LMs]</li>
    <li>Madaan et al. (2023) Self-refine: Iterative refinement with self-feedback [self-correction in LMs]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Dual-Process Reasoning Theory for Language Models",
    "theory_description": "This theory posits that language models (LMs) can best perform strict logical reasoning when they integrate two distinct but interacting reasoning processes: (1) a fast, heuristic-driven process for initial response generation, and (2) a slow, rule-based process for explicit logical verification and correction. The theory asserts that optimal logical performance arises from the dynamic interplay between these processes, with the rule-based process monitoring and, if necessary, overriding the heuristic process to ensure logical fidelity.",
    "theory_statements": [
        {
            "law": {
                "law_name": "Heuristic-Rule Duality Law",
                "if": [
                    {
                        "subject": "language model",
                        "relation": "is_engaged_in",
                        "object": "logical reasoning task"
                    }
                ],
                "then": [
                    {
                        "subject": "language model",
                        "relation": "activates",
                        "object": "heuristic reasoning process"
                    },
                    {
                        "subject": "language model",
                        "relation": "activates",
                        "object": "rule-based reasoning process"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Human reasoning is often modeled as dual-process (Kahneman, 2011), and LMs show both fast, intuitive and slow, deliberative behaviors.",
                        "uuids": []
                    },
                    {
                        "text": "LMs can generate quick, plausible answers but benefit from explicit logical verification steps.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Dual-process theories are well-established in cognitive science for human reasoning; LMs have been observed to benefit from both fast and slow reasoning modes.",
                    "what_is_novel": "Explicitly formalizing the interaction and monitoring between heuristic and rule-based processes within LMs for strict logical reasoning.",
                    "classification_explanation": "The law adapts dual-process theory from cognitive science to LMs, formalizing the need for both processes and their interaction.",
                    "likely_classification": "closely-related-to-existing",
                    "references": [
                        "Kahneman (2011) Thinking, Fast and Slow [dual-process theory in humans]",
                        "Wei et al. (2022) Chain-of-thought prompting elicits reasoning in LMs [slow, deliberative reasoning in LMs]"
                    ]
                }
            }
        },
        {
            "law": {
                "law_name": "Rule-Based Override Law",
                "if": [
                    {
                        "subject": "heuristic reasoning process",
                        "relation": "produces",
                        "object": "output"
                    },
                    {
                        "subject": "rule-based reasoning process",
                        "relation": "detects",
                        "object": "logical inconsistency in output"
                    }
                ],
                "then": [
                    {
                        "subject": "rule-based reasoning process",
                        "relation": "overrides",
                        "object": "heuristic output"
                    },
                    {
                        "subject": "language model",
                        "relation": "outputs",
                        "object": "logically consistent answer"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "LMs can self-correct or be prompted to verify and revise initial outputs, improving logical accuracy.",
                        "uuids": []
                    },
                    {
                        "text": "Explicit logical verification steps catch and correct errors from initial, heuristic outputs.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Self-correction and verification in LMs are known, as is the benefit of explicit logical steps.",
                    "what_is_novel": "The formalization of a rule-based process that can override heuristic outputs within a dual-process LM architecture.",
                    "classification_explanation": "The law extends existing self-correction by embedding it in a dual-process framework for LMs.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Madaan et al. (2023) Self-refine: Iterative refinement with self-feedback [self-correction in LMs]",
                        "Wang et al. (2022) Self-consistency improves chain of thought reasoning in language models [verification in LMs]"
                    ]
                }
            }
        }
    ],
    "new_predictions_likely": [
        "LMs with explicit dual-process architectures will outperform those with only heuristic or only rule-based reasoning on strict logical tasks.",
        "Introducing a rule-based verification step after initial output will reduce logical errors in LM responses."
    ],
    "new_predictions_unknown": [
        "The dual-process approach may enable LMs to generalize logical reasoning to domains with novel or ambiguous rules.",
        "Dynamic weighting between heuristic and rule-based processes may optimize both speed and accuracy in logical reasoning."
    ],
    "negative_experiments": [
        "If LMs with dual-process architectures do not outperform single-process LMs on logical reasoning tasks, the theory is undermined.",
        "If rule-based overrides do not improve logical consistency, the theory's assumptions are challenged."
    ],
    "unaccounted_for": [
        {
            "text": "Some logical errors may arise from limitations in the rule-based process itself, not just the heuristic process.",
            "uuids": []
        }
    ],
    "conflicting_evidence": [
        {
            "text": "Some LMs achieve high logical accuracy without explicit dual-process mechanisms.",
            "uuids": []
        }
    ],
    "special_cases": [
        "Tasks with ill-defined or non-classical logic may not benefit from rule-based overrides.",
        "Resource constraints may limit the feasibility of dual-process architectures in practice."
    ],
    "existing_theory": {
        "what_already_exists": "Dual-process theory in human cognition; self-correction and verification in LMs.",
        "what_is_novel": "Formalizing dual-process reasoning and explicit override mechanisms within LMs for strict logical reasoning.",
        "classification_explanation": "The theory adapts and extends dual-process theory to LMs, introducing explicit interaction and override mechanisms.",
        "likely_classification": "somewhat-related-to-existing",
        "references": [
            "Kahneman (2011) Thinking, Fast and Slow [dual-process theory in humans]",
            "Wei et al. (2022) Chain-of-thought prompting elicits reasoning in LMs [deliberative reasoning in LMs]",
            "Madaan et al. (2023) Self-refine: Iterative refinement with self-feedback [self-correction in LMs]"
        ]
    },
    "reflected_from_theory_index": 3,
    "type": "general",
    "version": "built-theory-from-results-single-theory-reflection2-nov14-2025-LLM-BASELINE-no-evidence-without-matched-control-theory-name",
    "theory_query": "Build a theory of how language models can best perform strict logical reasoning.",
    "original_theory_id": "theory-605",
    "original_theory_name": "Preference Optimization and Hard Negative Sampling for Robust Multi-Step Reasoning",
    "provide_matched_control_thery_name": false,
    "matched_control_theory_name": null,
    "model_str": "openai/gpt-4.1-2025-04-14"
}</code></pre>
        </div>
    </div>
</body>
</html>