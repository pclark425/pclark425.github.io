<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LLM-Inductive Bias and Human-Like Law Discovery Theory - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-523</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-523</p>
                <p><strong>Name:</strong> LLM-Inductive Bias and Human-Like Law Discovery Theory</p>
                <p><strong>Type:</strong> general</p>
                <p><strong>Theory Query:</strong> Build a theory of how large language models (LLMs) can be used to distill quantitative laws from large numbers of scholarly input papers, based on the following results.</p>
                <p><strong>Description:</strong> Large language models (LLMs) pretrained on extensive scientific corpora containing equations, code, and human-authored explanations develop strong inductive biases toward human-like, interpretable, and compact symbolic forms. When these LLMs are used as candidate generators in symbolic regression or scientific law discovery pipelines—especially when paired with external evaluators, optimization, or evolutionary search—they tend to propose candidate laws and models that are more interpretable, simpler, and often more generalizable than those produced by classical search-based symbolic regression. This inductive bias is particularly beneficial in domains where human intuition and prior scientific conventions are effective, but may be limiting in domains with non-intuitive or non-human-like laws.</p>
                <p><strong>Knowledge Cutoff Year:</strong> 2024</p>
                <p><strong>Knowledge Cutoff Month:</strong> 6</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <h3>Statement 0: Human-Like Inductive Bias Law (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; LLM &#8594; is_pretrained_on &#8594; large_scientific_corpus_with_equations_and_programs</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; LLM &#8594; has_inductive_bias_toward &#8594; human-authored_symbolic_forms</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>LMX-SR (Galactica), ICSR, and FunSearch all report that LLM-generated expressions are more compact and interpretable than those from classical GP or search-based SR, and that LLMs favor human-like forms due to pretraining. <a href="../results/extraction-result-3809.html#e3809.0" class="evidence-link">[e3809.0]</a> <a href="../results/extraction-result-3647.html#e3647.0" class="evidence-link">[e3647.0]</a> <a href="../results/extraction-result-3653.html#e3653.0" class="evidence-link">[e3653.0]</a> </li>
    <li>SymbolicGPT leverages a GPT-style transformer trained on parse-tree-generated equations and produces compact, human-like expressions, outperforming GP and DSR in expression size and interpretability. <a href="../results/extraction-result-3812.html#e3812.0" class="evidence-link">[e3812.0]</a> </li>
    <li>LaTeX Equation Probe and Galactica's domain probes show that LLMs can recall and generate canonical human-authored equations, indicating strong bias toward human-like forms. <a href="../results/extraction-result-3821.html#e3821.0" class="evidence-link">[e3821.0]</a> <a href="../results/extraction-result-3821.html#e3821.3" class="evidence-link">[e3821.3]</a> </li>
    <li>FunSearch and related evolutionary LLM pipelines report that LLM-generated code/programs are concise and interpretable, facilitating human analysis and further mathematical insight. <a href="../results/extraction-result-3653.html#e3653.0" class="evidence-link">[e3653.0]</a> <a href="../results/extraction-result-3653.html#e3653.3" class="evidence-link">[e3653.3]</a> <a href="../results/extraction-result-3654.html#e3654.1" class="evidence-link">[e3654.1]</a> <a href="../results/extraction-result-3652.html#e3652.1" class="evidence-link">[e3652.1]</a> <a href="../results/extraction-result-3655.html#e3655.2" class="evidence-link">[e3655.2]</a> </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p class="empty-note">No existing law comparison provided.</p>
            <h3>Statement 1: Inductive Bias Enables Simpler Law Discovery Law (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; LLM &#8594; has_human-like_inductive_bias &#8594; True<span style="color: #888888;">, and</span></div>
        <div>&#8226; pipeline &#8594; uses &#8594; LLM_for_candidate_generation</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; pipeline &#8594; discovers &#8594; simpler_and_more_interpretable_laws_than_classical_SR</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>ICSR and LLM-SR report that LLM-based pipelines produce lower-complexity expressions with better out-of-distribution generalization than classical SR baselines. <a href="../results/extraction-result-3647.html#e3647.0" class="evidence-link">[e3647.0]</a> <a href="../results/extraction-result-3652.html#e3652.0" class="evidence-link">[e3652.0]</a> </li>
    <li>LMX-SR (Galactica) and SymbolicGPT both show that LLM-based symbolic regression produces more compact and interpretable expressions than GP, DSR, and other search-based methods. <a href="../results/extraction-result-3809.html#e3809.0" class="evidence-link">[e3809.0]</a> <a href="../results/extraction-result-3812.html#e3812.0" class="evidence-link">[e3812.0]</a> </li>
    <li>FunSearch's evolutionary LLM pipeline discovers new mathematical constructions and heuristics that are both novel and interpretable, outperforming classical program search and genetic programming in terms of solution simplicity and human readability. <a href="../results/extraction-result-3653.html#e3653.0" class="evidence-link">[e3653.0]</a> <a href="../results/extraction-result-3653.html#e3653.2" class="evidence-link">[e3653.2]</a> <a href="../results/extraction-result-3653.html#e3653.3" class="evidence-link">[e3653.3]</a> </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p class="empty-note">No existing law comparison provided.</p>
            <h3>Statement 2: Inductive Bias Generalization Law (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; LLM &#8594; is_applied_to &#8594; novel_symbolic_regression_tasks</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; LLM &#8594; generalizes_better &#8594; to_out-of-distribution_data_than_classical_SR</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>LLM-SR and ICSR show improved OOD generalization compared to GP, DSR, and other SR baselines, attributed to LLM priors. <a href="../results/extraction-result-3652.html#e3652.0" class="evidence-link">[e3652.0]</a> <a href="../results/extraction-result-3647.html#e3647.0" class="evidence-link">[e3647.0]</a> </li>
    <li>SymbolicGPT demonstrates greater data efficiency and better generalization to test cases with limited data compared to GP and DSR. <a href="../results/extraction-result-3812.html#e3812.0" class="evidence-link">[e3812.0]</a> </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p class="empty-note">No existing law comparison provided.</p>
            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>If a new LLM is pretrained on a larger, more diverse scientific corpus, its proposals in symbolic regression tasks will be even more human-like and interpretable than current models.</li>
                <li>LLM-based symbolic regression will outperform classical GP in terms of expression simplicity and OOD generalization on new synthetic or real-world benchmarks.</li>
                <li>In domains with well-established human conventions (e.g., classical physics), LLM-based pipelines will more reliably rediscover canonical laws than search-based SR.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>LLMs with strong human-like priors may be able to discover new, previously unknown physical laws that are both simple and interpretable, potentially leading to new scientific paradigms.</li>
                <li>In domains where human intuition is misleading (e.g., highly non-intuitive quantum systems or chaotic systems), LLM inductive bias may hinder discovery or lead to systematic errors.</li>
                <li>If LLMs are pretrained on corpora with systematic errors or biases, their inductive bias may propagate these errors into discovered laws.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>If LLM-based pipelines consistently produce more complex or less interpretable expressions than classical SR on new tasks, this would challenge the inductive bias theory.</li>
                <li>If LLMs trained on non-scientific corpora (e.g., fiction) perform equally well at symbolic regression, the human-like bias explanation would be undermined.</li>
                <li>If LLM-based pipelines fail to generalize to OOD data or produce overfit, non-interpretable expressions, the theory would be called into question.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>Cases where LLMs hallucinate or produce invalid outputs, or where domain-specific knowledge is required beyond human-like priors (e.g., chemistry reaction mechanisms, or tasks requiring mechanistic simulation). <a href="../results/extraction-result-3821.html#e3821.1" class="evidence-link">[e3821.1]</a> <a href="../results/extraction-result-3648.html#e3648.0" class="evidence-link">[e3648.0]</a> <a href="../results/extraction-result-3805.html#e3805.0" class="evidence-link">[e3805.0]</a> <a href="../results/extraction-result-3821.html#e3821.3" class="evidence-link">[e3821.3]</a> <a href="../results/extraction-result-3823.html#e3823.3" class="evidence-link">[e3823.3]</a> <a href="../results/extraction-result-3817.html#e3817.0" class="evidence-link">[e3817.0]</a> <a href="../results/extraction-result-3817.html#e3817.3" class="evidence-link">[e3817.3]</a> </li>
    <li>LLMs' performance in domains with highly non-intuitive or non-human-like laws (e.g., quantum field theory, certain biological systems) is not fully explained by this theory. <a href="../results/extraction-result-3811.html#e3811.0" class="evidence-link">[e3811.0]</a> <a href="../results/extraction-result-3655.html#e3655.1" class="evidence-link">[e3655.1]</a> </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> closely-related-to-existing</p>
            <p><strong>Explanation:</strong> No explanation provided.</p>
            <p><strong>References:</strong> <ul>
    <li>Meyerson et al. (2023) Language model crossover: Variation through few-shot prompting [LLM as crossover/mutation operator, but not explicit on inductive bias]</li>
    <li>Shojaee et al. (2024) Scientific equation discovery via programming with large language models [LLM-SR, but does not formalize the inductive bias theory]</li>
    <li>Valipour et al. (2021) SymbolicGPT: A generative transformer model for symbolic regression [LLM-based symbolic regression, but not explicit on inductive bias toward human-like forms]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "LLM-Inductive Bias and Human-Like Law Discovery Theory",
    "theory_description": "Large language models (LLMs) pretrained on extensive scientific corpora containing equations, code, and human-authored explanations develop strong inductive biases toward human-like, interpretable, and compact symbolic forms. When these LLMs are used as candidate generators in symbolic regression or scientific law discovery pipelines—especially when paired with external evaluators, optimization, or evolutionary search—they tend to propose candidate laws and models that are more interpretable, simpler, and often more generalizable than those produced by classical search-based symbolic regression. This inductive bias is particularly beneficial in domains where human intuition and prior scientific conventions are effective, but may be limiting in domains with non-intuitive or non-human-like laws.",
    "theory_statements": [
        {
            "law": {
                "law_name": "Human-Like Inductive Bias Law",
                "if": [
                    {
                        "subject": "LLM",
                        "relation": "is_pretrained_on",
                        "object": "large_scientific_corpus_with_equations_and_programs"
                    }
                ],
                "then": [
                    {
                        "subject": "LLM",
                        "relation": "has_inductive_bias_toward",
                        "object": "human-authored_symbolic_forms"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "LMX-SR (Galactica), ICSR, and FunSearch all report that LLM-generated expressions are more compact and interpretable than those from classical GP or search-based SR, and that LLMs favor human-like forms due to pretraining.",
                        "uuids": [
                            "e3809.0",
                            "e3647.0",
                            "e3653.0"
                        ]
                    },
                    {
                        "text": "SymbolicGPT leverages a GPT-style transformer trained on parse-tree-generated equations and produces compact, human-like expressions, outperforming GP and DSR in expression size and interpretability.",
                        "uuids": [
                            "e3812.0"
                        ]
                    },
                    {
                        "text": "LaTeX Equation Probe and Galactica's domain probes show that LLMs can recall and generate canonical human-authored equations, indicating strong bias toward human-like forms.",
                        "uuids": [
                            "e3821.0",
                            "e3821.3"
                        ]
                    },
                    {
                        "text": "FunSearch and related evolutionary LLM pipelines report that LLM-generated code/programs are concise and interpretable, facilitating human analysis and further mathematical insight.",
                        "uuids": [
                            "e3653.0",
                            "e3653.3",
                            "e3654.1",
                            "e3652.1",
                            "e3655.2"
                        ]
                    }
                ],
                "qual_or_quant": "qualitative"
            }
        },
        {
            "law": {
                "law_name": "Inductive Bias Enables Simpler Law Discovery Law",
                "if": [
                    {
                        "subject": "LLM",
                        "relation": "has_human-like_inductive_bias",
                        "object": "True"
                    },
                    {
                        "subject": "pipeline",
                        "relation": "uses",
                        "object": "LLM_for_candidate_generation"
                    }
                ],
                "then": [
                    {
                        "subject": "pipeline",
                        "relation": "discovers",
                        "object": "simpler_and_more_interpretable_laws_than_classical_SR"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "ICSR and LLM-SR report that LLM-based pipelines produce lower-complexity expressions with better out-of-distribution generalization than classical SR baselines.",
                        "uuids": [
                            "e3647.0",
                            "e3652.0"
                        ]
                    },
                    {
                        "text": "LMX-SR (Galactica) and SymbolicGPT both show that LLM-based symbolic regression produces more compact and interpretable expressions than GP, DSR, and other search-based methods.",
                        "uuids": [
                            "e3809.0",
                            "e3812.0"
                        ]
                    },
                    {
                        "text": "FunSearch's evolutionary LLM pipeline discovers new mathematical constructions and heuristics that are both novel and interpretable, outperforming classical program search and genetic programming in terms of solution simplicity and human readability.",
                        "uuids": [
                            "e3653.0",
                            "e3653.2",
                            "e3653.3"
                        ]
                    }
                ],
                "qual_or_quant": "qualitative"
            }
        },
        {
            "law": {
                "law_name": "Inductive Bias Generalization Law",
                "if": [
                    {
                        "subject": "LLM",
                        "relation": "is_applied_to",
                        "object": "novel_symbolic_regression_tasks"
                    }
                ],
                "then": [
                    {
                        "subject": "LLM",
                        "relation": "generalizes_better",
                        "object": "to_out-of-distribution_data_than_classical_SR"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "LLM-SR and ICSR show improved OOD generalization compared to GP, DSR, and other SR baselines, attributed to LLM priors.",
                        "uuids": [
                            "e3652.0",
                            "e3647.0"
                        ]
                    },
                    {
                        "text": "SymbolicGPT demonstrates greater data efficiency and better generalization to test cases with limited data compared to GP and DSR.",
                        "uuids": [
                            "e3812.0"
                        ]
                    }
                ],
                "qual_or_quant": "qualitative"
            }
        }
    ],
    "new_predictions_likely": [
        "If a new LLM is pretrained on a larger, more diverse scientific corpus, its proposals in symbolic regression tasks will be even more human-like and interpretable than current models.",
        "LLM-based symbolic regression will outperform classical GP in terms of expression simplicity and OOD generalization on new synthetic or real-world benchmarks.",
        "In domains with well-established human conventions (e.g., classical physics), LLM-based pipelines will more reliably rediscover canonical laws than search-based SR."
    ],
    "new_predictions_unknown": [
        "LLMs with strong human-like priors may be able to discover new, previously unknown physical laws that are both simple and interpretable, potentially leading to new scientific paradigms.",
        "In domains where human intuition is misleading (e.g., highly non-intuitive quantum systems or chaotic systems), LLM inductive bias may hinder discovery or lead to systematic errors.",
        "If LLMs are pretrained on corpora with systematic errors or biases, their inductive bias may propagate these errors into discovered laws."
    ],
    "negative_experiments": [
        "If LLM-based pipelines consistently produce more complex or less interpretable expressions than classical SR on new tasks, this would challenge the inductive bias theory.",
        "If LLMs trained on non-scientific corpora (e.g., fiction) perform equally well at symbolic regression, the human-like bias explanation would be undermined.",
        "If LLM-based pipelines fail to generalize to OOD data or produce overfit, non-interpretable expressions, the theory would be called into question."
    ],
    "unaccounted_for": [
        {
            "text": "Cases where LLMs hallucinate or produce invalid outputs, or where domain-specific knowledge is required beyond human-like priors (e.g., chemistry reaction mechanisms, or tasks requiring mechanistic simulation).",
            "uuids": [
                "e3821.1",
                "e3648.0",
                "e3805.0",
                "e3821.3",
                "e3823.3",
                "e3817.0",
                "e3817.3"
            ]
        },
        {
            "text": "LLMs' performance in domains with highly non-intuitive or non-human-like laws (e.g., quantum field theory, certain biological systems) is not fully explained by this theory.",
            "uuids": [
                "e3811.0",
                "e3655.1"
            ]
        }
    ],
    "conflicting_evidence": [
        {
            "text": "SymbolicGPT and some other LLM-based SR models underperform on certain benchmarks, suggesting that inductive bias alone is not sufficient for all tasks; performance can depend on model architecture, pretraining data, and task domain.",
            "uuids": [
                "e3654.2",
                "e3812.0"
            ]
        },
        {
            "text": "In some cases, LLMs memorize or recite known equations from training data (e.g., Feynman benchmark in LLM-SR), which may not reflect genuine law discovery or generalization.",
            "uuids": [
                "e3652.0",
                "e3821.0"
            ]
        }
    ],
    "special_cases": [
        "Domains with non-human-like or highly non-intuitive laws may not benefit from LLM inductive bias.",
        "If the LLM's pretraining corpus is biased, incomplete, or contains systematic errors, the inductive bias may mislead discovery.",
        "Tasks requiring mechanistic simulation, high-precision numeric computation, or domain-specific symbolic manipulation may require tool augmentation or hybrid approaches."
    ],
    "existing_theory": {
        "likely_classification": "closely-related-to-existing",
        "references": [
            "Meyerson et al. (2023) Language model crossover: Variation through few-shot prompting [LLM as crossover/mutation operator, but not explicit on inductive bias]",
            "Shojaee et al. (2024) Scientific equation discovery via programming with large language models [LLM-SR, but does not formalize the inductive bias theory]",
            "Valipour et al. (2021) SymbolicGPT: A generative transformer model for symbolic regression [LLM-based symbolic regression, but not explicit on inductive bias toward human-like forms]"
        ]
    },
    "theory_type_general_specific": "general",
    "reflected_from_theory_index": 1,
    "version": "built-theory-from-results-single-theory-reflection2-nov13-2025",
    "type": "general"
}</code></pre>
        </div>
    </div>
</body>
</html>