<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Domain Randomization Sufficiency Theory - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-187</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-187</p>
                <p><strong>Name:</strong> Domain Randomization Sufficiency Theory</p>
                <p><strong>Type:</strong> general</p>
                <p><strong>Theory Query:</strong> Build a theory about sim-to-real transfer for scientific discovery agents that specifies environment fidelity requirements and skill-transfer conditions from virtual labs to real robotics labs, based on the following results.</p>
                <p><strong>Description:</strong> Domain randomization enables sim-to-real transfer when three conditions are met: (1) the randomization distribution covers the real-world parameter values with sufficient probability mass, (2) the policy can learn invariant features or robust behaviors across the randomized distribution, and (3) the task success is not critically dependent on precise parameter values. However, domain randomization has fundamental limitations: its effectiveness decreases exponentially with the dimensionality of the parameter space in continuous domains, it cannot compensate for structural model errors (only parametric errors), and it may be insufficient for contact-rich or precision tasks without additional techniques. The effectiveness varies significantly between visual randomization (which can compensate for approximate physics) and physics randomization (which requires more careful tuning).</p>
                <p><strong>Knowledge Cutoff Year:</strong> 2024</p>
                <p><strong>Knowledge Cutoff Month:</strong> 12</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <ol>
                <li>Domain randomization is necessary when the true parameter values are unknown or when the policy must be robust to parameter variations</li>
                <li>Domain randomization is sufficient for transfer when: (a) the randomization distribution includes the real parameters with non-negligible probability, (b) the policy has sufficient capacity and training data to learn invariant features, and (c) the task does not require precise parameter-dependent control</li>
                <li>The sample complexity of learning with domain randomization scales exponentially with the number of randomized dimensions in continuous domains unless parameters are independent or the policy can learn hierarchical abstractions</li>
                <li>Adaptive domain randomization (ADR) converges to effective ranges faster than fixed randomization by using policy performance as feedback, but may converge to alternate high-performing parameter regions rather than ground truth</li>
                <li>Domain randomization is most effective for parameters that affect high-level task success rather than low-level control precision</li>
                <li>Combining domain randomization with system identification, online adaptation, or posterior estimation is more sample-efficient than domain randomization alone</li>
                <li>Visual domain randomization (textures, lighting) is more effective than physics randomization for vision-based policies when physics is approximately correct, and can compensate for 20-30% physics misspecification</li>
                <li>Domain randomization cannot compensate for structural model errors (missing degrees of freedom, incorrect contact models), only parametric errors within the correct model structure</li>
                <li>Domain randomization effectiveness depends on observation space: compact spaces (IMU-only) transfer better than high-dimensional spaces (raw images) due to reduced overfitting</li>
                <li>Memory-augmented policies (LSTM) combined with domain randomization enable online implicit system identification and improve transfer for contact-rich tasks</li>
                <li>Domain randomization as pretraining is valuable even when zero-shot transfer fails, as it provides a robust initialization for fine-tuning with small amounts of real data</li>
            </ol>
            <h3>Supporting Evidence</h3>
<ol>
    <li>Heavy domain randomization (physics, visual, dynamics) enabled successful transfer for dexterous manipulation without real-world fine-tuning <a href="../results/extraction-result-1651.html#e1651.0" class="evidence-link">[e1651.0]</a> <a href="../results/extraction-result-1791.html#e1791.0" class="evidence-link">[e1791.0]</a> </li>
    <li>Domain randomization over camera parameters, friction, and visual appearance enabled autonomous driving transfer <a href="../results/extraction-result-1802.html#e1802.0" class="evidence-link">[e1802.0]</a> <a href="../results/extraction-result-1680.html#e1680.1" class="evidence-link">[e1680.1]</a> <a href="../results/extraction-result-1680.html#e1680.5" class="evidence-link">[e1680.5]</a> <a href="../results/extraction-result-1682.html#e1682.1" class="evidence-link">[e1682.1]</a> </li>
    <li>Adaptive domain randomization (ADR/VADR) that expands ranges based on policy performance outperforms fixed randomization <a href="../results/extraction-result-1791.html#e1791.0" class="evidence-link">[e1791.0]</a> <a href="../results/extraction-result-1791.html#e1791.1" class="evidence-link">[e1791.1]</a> <a href="../results/extraction-result-1678.html#e1678.0" class="evidence-link">[e1678.0]</a> </li>
    <li>Domain randomization alone was insufficient for some tasks and required system identification or online adaptation <a href="../results/extraction-result-1654.html#e1654.0" class="evidence-link">[e1654.0]</a> <a href="../results/extraction-result-1650.html#e1650.0" class="evidence-link">[e1650.0]</a> <a href="../results/extraction-result-1657.html#e1657.2" class="evidence-link">[e1657.2]</a> <a href="../results/extraction-result-1672.html#e1672.0" class="evidence-link">[e1672.0]</a> </li>
    <li>Excessive randomization can harm learning by diluting task-relevant signal or creating infeasible scenarios <a href="../results/extraction-result-1657.html#e1657.2" class="evidence-link">[e1657.2]</a> <a href="../results/extraction-result-1680.html#e1680.1" class="evidence-link">[e1680.1]</a> </li>
    <li>Domain randomization with compact observation spaces (IMU-only) transfers better than with large observation spaces <a href="../results/extraction-result-1780.html#e1780.0" class="evidence-link">[e1780.0]</a> </li>
    <li>Randomization of task-irrelevant parameters does not improve transfer and may slow learning <a href="../results/extraction-result-1785.html#e1785.1" class="evidence-link">[e1785.1]</a> <a href="../results/extraction-result-1785.html#e1785.2" class="evidence-link">[e1785.2]</a> </li>
    <li>Domain randomization treats parameters independently and may miss correlated real-world effects <a href="../results/extraction-result-1791.html#e1791.1" class="evidence-link">[e1791.1]</a> <a href="../results/extraction-result-1798.html#e1798.0" class="evidence-link">[e1798.0]</a> </li>
    <li>Visual domain randomization can enable transfer even when physics parameters are misspecified <a href="../results/extraction-result-1674.html#e1674.0" class="evidence-link">[e1674.0]</a> <a href="../results/extraction-result-1802.html#e1802.0" class="evidence-link">[e1802.0]</a> </li>
    <li>Domain randomization combined with memory-augmented policies (LSTM) improves transfer for contact-rich tasks <a href="../results/extraction-result-1651.html#e1651.0" class="evidence-link">[e1651.0]</a> </li>
    <li>Ensemble-based training on varied dynamics models improves robustness to modeling error <a href="../results/extraction-result-1798.html#e1798.0" class="evidence-link">[e1798.0]</a> <a href="../results/extraction-result-1682.html#e1682.2" class="evidence-link">[e1682.2]</a> <a href="../results/extraction-result-1682.html#e1682.3" class="evidence-link">[e1682.3]</a> </li>
    <li>Domain randomization has weak theoretical guarantees in continuous partial-observation domains <a href="../results/extraction-result-1670.html#e1670.4" class="evidence-link">[e1670.4]</a> </li>
    <li>Posterior-guided domain randomization outperforms uniform randomization by concentrating on likely parameter values <a href="../results/extraction-result-1785.html#e1785.1" class="evidence-link">[e1785.1]</a> <a href="../results/extraction-result-1785.html#e1785.2" class="evidence-link">[e1785.2]</a> </li>
    <li>Domain randomization as pretraining is effective even when zero-shot transfer fails <a href="../results/extraction-result-1828.html#e1828.1" class="evidence-link">[e1828.1]</a> </li>
    <li>Realistic rendering with randomization reduces real-world label requirements <a href="../results/extraction-result-1682.html#e1682.6" class="evidence-link">[e1682.6]</a> </li>
    <li>Domain randomization effectiveness depends on task structure (open-loop vs closed-loop) <a href="../results/extraction-result-1785.html#e1785.1" class="evidence-link">[e1785.1]</a> </li>
</ol>            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>A manipulation task with 3-5 independent randomized parameters will transfer successfully with domain randomization alone, while a task with >10 correlated parameters will require posterior estimation or adaptive DR</li>
                <li>Adaptive domain randomization will converge to effective parameter ranges in 5-10 iterations for tasks where policy performance provides clear feedback on parameter appropriateness</li>
                <li>Domain randomization over visual parameters will enable transfer for navigation tasks even when physics parameters are misspecified by 20-30%</li>
                <li>Policies trained with domain randomization will be more robust to deployment-time parameter variations than policies trained with system identification alone</li>
                <li>LSTM policies trained with domain randomization will outperform feedforward policies on contact-rich tasks by 20-40% in real-world success rate</li>
                <li>Visual domain randomization will enable transfer for bin-picking with commodity depth sensors where depth-only approaches fail</li>
                <li>Domain randomization combined with 5k real samples will match the performance of policies trained on 100k+ real samples for grasping tasks</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>Whether domain randomization can enable transfer for tasks with >20 randomized dimensions without exponential sample complexity growth, even with hierarchical or learned randomization strategies</li>
                <li>Whether learned meta-parameters or hierarchical randomization strategies can overcome the curse of dimensionality in high-dimensional parameter spaces</li>
                <li>Whether domain randomization can compensate for structural model errors (e.g., missing degrees of freedom, incorrect contact models) or only parametric errors</li>
                <li>Whether there exists an optimal randomization distribution shape (uniform, Gaussian, learned posterior) that generalizes across task types</li>
                <li>Whether the effectiveness of domain randomization depends fundamentally on policy architecture (LSTM vs transformer vs feedforward) or is architecture-agnostic</li>
                <li>Whether domain randomization can enable transfer for tasks requiring sub-millimeter precision or whether such tasks fundamentally require system identification</li>
                <li>Whether visual domain randomization can compensate for arbitrarily large physics misspecification or whether there is a fundamental limit</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>Finding a task where narrow randomization around true parameters outperforms wide randomization would challenge the coverage requirement and suggest that exploration-exploitation tradeoffs matter</li>
                <li>Demonstrating successful transfer with randomization that explicitly excludes the true parameter values would challenge the sufficiency condition and support the alternate-modes hypothesis from BayRnTune</li>
                <li>Finding that domain randomization with independent parameter sampling works as well as correlated sampling would challenge the dimensionality curse and suggest parameters are more independent than expected</li>
                <li>Showing that domain randomization improves transfer for tasks with precise parameter dependencies (e.g., sub-millimeter assembly) would challenge the high-level success principle</li>
                <li>Finding that domain randomization enables transfer despite structural model errors (e.g., missing contact modes) would challenge the parametric-only limitation</li>
                <li>Demonstrating that feedforward policies with domain randomization match LSTM performance on contact-rich tasks would challenge the memory-augmentation requirement</li>
                <li>Finding that domain randomization over >20 dimensions achieves sample complexity similar to 5 dimensions would challenge the exponential scaling prediction</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>How to determine optimal randomization ranges without real-world data or extensive trial-and-error, beyond adaptive methods like ADR <a href="../results/extraction-result-1791.html#e1791.0" class="evidence-link">[e1791.0]</a> <a href="../results/extraction-result-1791.html#e1791.1" class="evidence-link">[e1791.1]</a> <a href="../results/extraction-result-1678.html#e1678.0" class="evidence-link">[e1678.0]</a> </li>
    <li>Whether domain randomization effectiveness depends on policy architecture (LSTM vs feedforward vs transformer) or learning algorithm (PPO vs SAC vs offline RL) <a href="../results/extraction-result-1651.html#e1651.0" class="evidence-link">[e1651.0]</a> <a href="../results/extraction-result-1780.html#e1780.0" class="evidence-link">[e1780.0]</a> <a href="../results/extraction-result-1791.html#e1791.0" class="evidence-link">[e1791.0]</a> </li>
    <li>How domain randomization interacts with other transfer techniques like system identification, online adaptation, and observation abstraction <a href="../results/extraction-result-1654.html#e1654.0" class="evidence-link">[e1654.0]</a> <a href="../results/extraction-result-1650.html#e1650.0" class="evidence-link">[e1650.0]</a> <a href="../results/extraction-result-1672.html#e1672.0" class="evidence-link">[e1672.0]</a> <a href="../results/extraction-result-1790.html#e1790.0" class="evidence-link">[e1790.0]</a> </li>
    <li>Why some tasks (grasping, navigation) succeed with domain randomization while others (assembly, wiping) require additional techniques <a href="../results/extraction-result-1828.html#e1828.1" class="evidence-link">[e1828.1]</a> <a href="../results/extraction-result-1650.html#e1650.0" class="evidence-link">[e1650.0]</a> <a href="../results/extraction-result-1681.html#e1681.0" class="evidence-link">[e1681.0]</a> </li>
    <li>The role of observation abstraction (feature tracks, segmentation) in reducing the need for domain randomization <a href="../results/extraction-result-1790.html#e1790.0" class="evidence-link">[e1790.0]</a> <a href="../results/extraction-result-1802.html#e1802.0" class="evidence-link">[e1802.0]</a> </li>
    <li>How action space choice (joint vs end-effector vs impedance) interacts with domain randomization effectiveness <a href="../results/extraction-result-1788.html#e1788.0" class="evidence-link">[e1788.0]</a> <a href="../results/extraction-result-1788.html#e1788.1" class="evidence-link">[e1788.1]</a> <a href="../results/extraction-result-1672.html#e1672.1" class="evidence-link">[e1672.1]</a> </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> closely-related-to-existing</p>
            <p><strong>Explanation:</strong> No explanation provided.</p>
            <p><strong>References:</strong> <ul>
    <li>Tobin et al. (2017) Domain randomization for transferring deep neural networks from simulation to the real world [Original domain randomization paper, foundational work]</li>
    <li>Peng et al. (2018) Sim-to-real transfer of robotic control with dynamics randomization [Dynamics randomization, extension to physics parameters]</li>
    <li>OpenAI et al. (2019) Solving Rubik's Cube with a Robot Hand [Automatic domain randomization (ADR), adaptive range expansion]</li>
    <li>Muratore et al. (2021) Robot Learning from Randomized Simulations: A Review [Comprehensive review of domain randomization approaches]</li>
    <li>Rajeswaran et al. (2016) EPOpt: Learning Robust Neural Network Policies Using Model Ensembles [Ensemble-based training with adversarial objectives]</li>
    <li>Chebotar et al. (2019) Closing the Sim-to-Real Loop: Adapting Simulation Randomization with Real World Experience [SimOpt, adapting randomization with real data]</li>
    <li>Muratore et al. (2022) BayesSim: adaptive domain randomization via probabilistic inference for robotics simulators [Posterior-guided domain randomization]</li>
    <li>Chen et al. (2021) Provable Sim-to-real Transfer in Continuous Domain with Partial Observations [Theoretical analysis showing limitations of DR in continuous domains]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Domain Randomization Sufficiency Theory",
    "theory_description": "Domain randomization enables sim-to-real transfer when three conditions are met: (1) the randomization distribution covers the real-world parameter values with sufficient probability mass, (2) the policy can learn invariant features or robust behaviors across the randomized distribution, and (3) the task success is not critically dependent on precise parameter values. However, domain randomization has fundamental limitations: its effectiveness decreases exponentially with the dimensionality of the parameter space in continuous domains, it cannot compensate for structural model errors (only parametric errors), and it may be insufficient for contact-rich or precision tasks without additional techniques. The effectiveness varies significantly between visual randomization (which can compensate for approximate physics) and physics randomization (which requires more careful tuning).",
    "supporting_evidence": [
        {
            "text": "Heavy domain randomization (physics, visual, dynamics) enabled successful transfer for dexterous manipulation without real-world fine-tuning",
            "uuids": [
                "e1651.0",
                "e1791.0"
            ]
        },
        {
            "text": "Domain randomization over camera parameters, friction, and visual appearance enabled autonomous driving transfer",
            "uuids": [
                "e1802.0",
                "e1680.1",
                "e1680.5",
                "e1682.1"
            ]
        },
        {
            "text": "Adaptive domain randomization (ADR/VADR) that expands ranges based on policy performance outperforms fixed randomization",
            "uuids": [
                "e1791.0",
                "e1791.1",
                "e1678.0"
            ]
        },
        {
            "text": "Domain randomization alone was insufficient for some tasks and required system identification or online adaptation",
            "uuids": [
                "e1654.0",
                "e1650.0",
                "e1657.2",
                "e1672.0"
            ]
        },
        {
            "text": "Excessive randomization can harm learning by diluting task-relevant signal or creating infeasible scenarios",
            "uuids": [
                "e1657.2",
                "e1680.1"
            ]
        },
        {
            "text": "Domain randomization with compact observation spaces (IMU-only) transfers better than with large observation spaces",
            "uuids": [
                "e1780.0"
            ]
        },
        {
            "text": "Randomization of task-irrelevant parameters does not improve transfer and may slow learning",
            "uuids": [
                "e1785.1",
                "e1785.2"
            ]
        },
        {
            "text": "Domain randomization treats parameters independently and may miss correlated real-world effects",
            "uuids": [
                "e1791.1",
                "e1798.0"
            ]
        },
        {
            "text": "Visual domain randomization can enable transfer even when physics parameters are misspecified",
            "uuids": [
                "e1674.0",
                "e1802.0"
            ]
        },
        {
            "text": "Domain randomization combined with memory-augmented policies (LSTM) improves transfer for contact-rich tasks",
            "uuids": [
                "e1651.0"
            ]
        },
        {
            "text": "Ensemble-based training on varied dynamics models improves robustness to modeling error",
            "uuids": [
                "e1798.0",
                "e1682.2",
                "e1682.3"
            ]
        },
        {
            "text": "Domain randomization has weak theoretical guarantees in continuous partial-observation domains",
            "uuids": [
                "e1670.4"
            ]
        },
        {
            "text": "Posterior-guided domain randomization outperforms uniform randomization by concentrating on likely parameter values",
            "uuids": [
                "e1785.1",
                "e1785.2"
            ]
        },
        {
            "text": "Domain randomization as pretraining is effective even when zero-shot transfer fails",
            "uuids": [
                "e1828.1"
            ]
        },
        {
            "text": "Realistic rendering with randomization reduces real-world label requirements",
            "uuids": [
                "e1682.6"
            ]
        },
        {
            "text": "Domain randomization effectiveness depends on task structure (open-loop vs closed-loop)",
            "uuids": [
                "e1785.1"
            ]
        }
    ],
    "theory_statements": [
        "Domain randomization is necessary when the true parameter values are unknown or when the policy must be robust to parameter variations",
        "Domain randomization is sufficient for transfer when: (a) the randomization distribution includes the real parameters with non-negligible probability, (b) the policy has sufficient capacity and training data to learn invariant features, and (c) the task does not require precise parameter-dependent control",
        "The sample complexity of learning with domain randomization scales exponentially with the number of randomized dimensions in continuous domains unless parameters are independent or the policy can learn hierarchical abstractions",
        "Adaptive domain randomization (ADR) converges to effective ranges faster than fixed randomization by using policy performance as feedback, but may converge to alternate high-performing parameter regions rather than ground truth",
        "Domain randomization is most effective for parameters that affect high-level task success rather than low-level control precision",
        "Combining domain randomization with system identification, online adaptation, or posterior estimation is more sample-efficient than domain randomization alone",
        "Visual domain randomization (textures, lighting) is more effective than physics randomization for vision-based policies when physics is approximately correct, and can compensate for 20-30% physics misspecification",
        "Domain randomization cannot compensate for structural model errors (missing degrees of freedom, incorrect contact models), only parametric errors within the correct model structure",
        "Domain randomization effectiveness depends on observation space: compact spaces (IMU-only) transfer better than high-dimensional spaces (raw images) due to reduced overfitting",
        "Memory-augmented policies (LSTM) combined with domain randomization enable online implicit system identification and improve transfer for contact-rich tasks",
        "Domain randomization as pretraining is valuable even when zero-shot transfer fails, as it provides a robust initialization for fine-tuning with small amounts of real data"
    ],
    "new_predictions_likely": [
        "A manipulation task with 3-5 independent randomized parameters will transfer successfully with domain randomization alone, while a task with &gt;10 correlated parameters will require posterior estimation or adaptive DR",
        "Adaptive domain randomization will converge to effective parameter ranges in 5-10 iterations for tasks where policy performance provides clear feedback on parameter appropriateness",
        "Domain randomization over visual parameters will enable transfer for navigation tasks even when physics parameters are misspecified by 20-30%",
        "Policies trained with domain randomization will be more robust to deployment-time parameter variations than policies trained with system identification alone",
        "LSTM policies trained with domain randomization will outperform feedforward policies on contact-rich tasks by 20-40% in real-world success rate",
        "Visual domain randomization will enable transfer for bin-picking with commodity depth sensors where depth-only approaches fail",
        "Domain randomization combined with 5k real samples will match the performance of policies trained on 100k+ real samples for grasping tasks"
    ],
    "new_predictions_unknown": [
        "Whether domain randomization can enable transfer for tasks with &gt;20 randomized dimensions without exponential sample complexity growth, even with hierarchical or learned randomization strategies",
        "Whether learned meta-parameters or hierarchical randomization strategies can overcome the curse of dimensionality in high-dimensional parameter spaces",
        "Whether domain randomization can compensate for structural model errors (e.g., missing degrees of freedom, incorrect contact models) or only parametric errors",
        "Whether there exists an optimal randomization distribution shape (uniform, Gaussian, learned posterior) that generalizes across task types",
        "Whether the effectiveness of domain randomization depends fundamentally on policy architecture (LSTM vs transformer vs feedforward) or is architecture-agnostic",
        "Whether domain randomization can enable transfer for tasks requiring sub-millimeter precision or whether such tasks fundamentally require system identification",
        "Whether visual domain randomization can compensate for arbitrarily large physics misspecification or whether there is a fundamental limit"
    ],
    "negative_experiments": [
        "Finding a task where narrow randomization around true parameters outperforms wide randomization would challenge the coverage requirement and suggest that exploration-exploitation tradeoffs matter",
        "Demonstrating successful transfer with randomization that explicitly excludes the true parameter values would challenge the sufficiency condition and support the alternate-modes hypothesis from BayRnTune",
        "Finding that domain randomization with independent parameter sampling works as well as correlated sampling would challenge the dimensionality curse and suggest parameters are more independent than expected",
        "Showing that domain randomization improves transfer for tasks with precise parameter dependencies (e.g., sub-millimeter assembly) would challenge the high-level success principle",
        "Finding that domain randomization enables transfer despite structural model errors (e.g., missing contact modes) would challenge the parametric-only limitation",
        "Demonstrating that feedforward policies with domain randomization match LSTM performance on contact-rich tasks would challenge the memory-augmentation requirement",
        "Finding that domain randomization over &gt;20 dimensions achieves sample complexity similar to 5 dimensions would challenge the exponential scaling prediction"
    ],
    "unaccounted_for": [
        {
            "text": "How to determine optimal randomization ranges without real-world data or extensive trial-and-error, beyond adaptive methods like ADR",
            "uuids": [
                "e1791.0",
                "e1791.1",
                "e1678.0"
            ]
        },
        {
            "text": "Whether domain randomization effectiveness depends on policy architecture (LSTM vs feedforward vs transformer) or learning algorithm (PPO vs SAC vs offline RL)",
            "uuids": [
                "e1651.0",
                "e1780.0",
                "e1791.0"
            ]
        },
        {
            "text": "How domain randomization interacts with other transfer techniques like system identification, online adaptation, and observation abstraction",
            "uuids": [
                "e1654.0",
                "e1650.0",
                "e1672.0",
                "e1790.0"
            ]
        },
        {
            "text": "Why some tasks (grasping, navigation) succeed with domain randomization while others (assembly, wiping) require additional techniques",
            "uuids": [
                "e1828.1",
                "e1650.0",
                "e1681.0"
            ]
        },
        {
            "text": "The role of observation abstraction (feature tracks, segmentation) in reducing the need for domain randomization",
            "uuids": [
                "e1790.0",
                "e1802.0"
            ]
        },
        {
            "text": "How action space choice (joint vs end-effector vs impedance) interacts with domain randomization effectiveness",
            "uuids": [
                "e1788.0",
                "e1788.1",
                "e1672.1"
            ]
        }
    ],
    "conflicting_evidence": [
        {
            "text": "Some papers report that domain randomization is essential for transfer, while others achieve better results without it using system identification",
            "uuids": [
                "e1654.0",
                "e1651.0"
            ]
        },
        {
            "text": "ADR sometimes converges to parameter values far from ground truth but still achieves good performance, suggesting coverage may not be necessary",
            "uuids": [
                "e1678.0",
                "e1678.1"
            ]
        },
        {
            "text": "Domain randomization has weak theoretical guarantees in continuous domains, yet empirically works well for many continuous control tasks",
            "uuids": [
                "e1670.4",
                "e1651.0",
                "e1791.0"
            ]
        },
        {
            "text": "Posterior-guided randomization outperforms uniform randomization, suggesting that coverage alone is insufficient and concentration around likely values matters",
            "uuids": [
                "e1785.1",
                "e1785.2"
            ]
        },
        {
            "text": "Domain randomization achieved poor zero-shot transfer (33-37%) but was effective for pretraining, suggesting its value may be in initialization rather than direct transfer",
            "uuids": [
                "e1828.1"
            ]
        },
        {
            "text": "Some tasks succeed with domain randomization alone while similar tasks require additional techniques, without clear distinguishing features",
            "uuids": [
                "e1674.0",
                "e1650.0",
                "e1681.0"
            ]
        }
    ],
    "special_cases": [
        "For unstable systems (bipedal robots, buoyancy-assisted robots), some parameters (mass, buoyancy) cannot be randomized without causing catastrophic failures during training",
        "Visual domain randomization may require photorealistic base rendering for some tasks (manipulation) but can work with non-photorealistic rendering for others (navigation)",
        "Temporal aspects (delays, frequencies) may need explicit modeling rather than randomization for high-frequency control tasks",
        "Contact-rich tasks (assembly, wiping) often require domain randomization combined with other techniques (system identification, online adaptation, impedance control) rather than domain randomization alone",
        "Open-loop tasks (sliding, throwing) are more sensitive to parameter accuracy and may require posterior-guided randomization rather than uniform randomization",
        "Tasks with commodity sensors (noisy depth cameras) may benefit more from visual domain randomization than from accurate physics simulation",
        "Observation space dimensionality interacts with domain randomization: compact spaces (IMU) transfer better than high-dimensional spaces (raw images) even with the same physics randomization",
        "Memory-augmented policies (LSTM) may be necessary for domain randomization to work on contact-rich tasks, as they enable online implicit system identification"
    ],
    "existing_theory": {
        "likely_classification": "closely-related-to-existing",
        "references": [
            "Tobin et al. (2017) Domain randomization for transferring deep neural networks from simulation to the real world [Original domain randomization paper, foundational work]",
            "Peng et al. (2018) Sim-to-real transfer of robotic control with dynamics randomization [Dynamics randomization, extension to physics parameters]",
            "OpenAI et al. (2019) Solving Rubik's Cube with a Robot Hand [Automatic domain randomization (ADR), adaptive range expansion]",
            "Muratore et al. (2021) Robot Learning from Randomized Simulations: A Review [Comprehensive review of domain randomization approaches]",
            "Rajeswaran et al. (2016) EPOpt: Learning Robust Neural Network Policies Using Model Ensembles [Ensemble-based training with adversarial objectives]",
            "Chebotar et al. (2019) Closing the Sim-to-Real Loop: Adapting Simulation Randomization with Real World Experience [SimOpt, adapting randomization with real data]",
            "Muratore et al. (2022) BayesSim: adaptive domain randomization via probabilistic inference for robotics simulators [Posterior-guided domain randomization]",
            "Chen et al. (2021) Provable Sim-to-real Transfer in Continuous Domain with Partial Observations [Theoretical analysis showing limitations of DR in continuous domains]"
        ]
    },
    "theory_type_general_specific": "general",
    "reflected_from_theory_index": 1,
    "type": "general"
}</code></pre>
        </div>
    </div>
</body>
</html>