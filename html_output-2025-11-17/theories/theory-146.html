<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Hierarchical Landmark-Based Navigation Efficiency Theory - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-146</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-146</p>
                <p><strong>Name:</strong> Hierarchical Landmark-Based Navigation Efficiency Theory</p>
                <p><strong>Type:</strong> specific</p>
                <p><strong>Theory Query:</strong> Build a theory about navigation complexity in text worlds that relates graph-topology features (diameter, clustering, dead-ends, door constraints) to exploration efficiency and optimal policy structure, based on the following results.</p>
                <p><strong>Description:</strong> In large spatial navigation environments with high effective diameter (long shortest paths between locations), hierarchical policies that decompose long-range navigation into landmark-based waypoint sequences achieve superior sample efficiency and zero-shot generalization compared to flat policies. The efficiency gain arises from: (1) reducing the number of point-to-point policies that must be learned (from O(n²) for all pairs to O(n) for landmark-to-landmark connections), (2) enabling compositional generalization to new goal locations via landmark sequence composition, (3) providing natural curriculum learning where local policies are learned before global composition, and (4) reducing the effective planning horizon at each decision point. The benefits are most pronounced in environments with: (a) large state spaces (>25 distinct locations), (b) high graph diameter (requiring >10 steps between typical start-goal pairs), (c) low visual aliasing (distinct landmarks are reliably identifiable), and (d) relatively stable landmark locations. The approach shows diminishing returns in small environments (<10 locations), short-horizon tasks (<10 steps), or environments with severe visual aliasing where landmark identification becomes unreliable.</p>
                <p><strong>Knowledge Cutoff Year:</strong> 2024</p>
                <p><strong>Knowledge Cutoff Month:</strong> 12</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <ol>
                <li>The number of policies required scales as O(n) for hierarchical landmark-based navigation vs O(n²) for flat all-pairs navigation in environments with n distinct locations.</li>
                <li>Sample efficiency improves by a factor proportional to environment size when using hierarchical decomposition, with improvements of 2-6x observed in environments ranging from 9 to 25 rooms.</li>
                <li>Zero-shot generalization to new goals is possible with hierarchical policies when goals can be reached via known landmark sequences, with success rates >60% on unseen configurations.</li>
                <li>The performance advantage of hierarchical policies increases with environment diameter, with the largest gains (>6x) observed in environments requiring >15 steps between typical start-goal pairs.</li>
                <li>Hierarchical policies enable curriculum learning where local navigation is mastered before global composition, reducing training time by 40-60% compared to end-to-end learning.</li>
                <li>Visual aliasing and landmark ambiguity reduce the effectiveness of landmark-based hierarchy, with performance degrading when multiple locations appear visually similar.</li>
                <li>In very small environments (<10 locations) or short-horizon tasks (<10 steps), the overhead of hierarchical planning may outweigh benefits, as seen in RoboKitchen manipulation tasks.</li>
            </ol>
            <h3>Supporting Evidence</h3>
<ol>
    <li>Dr. Strategy with landmark-based hierarchy achieves 94.11% success on 9-room navigation vs 27.11% for non-hierarchical GC-Director, demonstrating >3x improvement in medium-sized environments. <a href="../results/extraction-result-1272.html#e1272.0" class="evidence-link">[e1272.0]</a> </li>
    <li>In 25-room layouts, Dr. Strategy achieves 67.11% success vs 9.62% for LEXA and 0.14% for LEXA-Explore, showing that hierarchical advantage increases with environment size (>6x improvement). <a href="../results/extraction-result-1272.html#e1272.2" class="evidence-link">[e1272.2]</a> </li>
    <li>Hierarchical h-DQN with entity-relation parameterized goals achieves approximately +400 reward per episode in Montezuma's Revenge vs 0 for flat DQN, demonstrating effectiveness in environments with bottlenecks and long action sequences. <a href="../results/extraction-result-1357.html#e1357.1" class="evidence-link">[e1357.1]</a> </li>
    <li>BRM with semantic graph hierarchy achieves 41.1% success vs 22.5% for flat LSTM in House3D navigation, showing ~1.8x improvement when using semantic room-level abstractions. <a href="../results/extraction-result-1362.html#e1362.1" class="evidence-link">[e1362.1]</a> </li>
    <li>Modular sketch-guided policies that decompose tasks into subpolicies achieve better learning and adaptation to longer paths in continuous control tasks, with curriculum learning enabling reuse of locomotion behaviors. <a href="../results/extraction-result-1354.html#e1354.2" class="evidence-link">[e1354.2]</a> </li>
    <li>NavGPT with LLM-based room-level planning produces more consistent exploration and better long-horizon object navigation (37.9% success) compared to unguided roaming, by building room-level graphs and selecting waypoints. <a href="../results/extraction-result-1182.html#e1182.1" class="evidence-link">[e1182.1]</a> <a href="../results/extraction-result-1182.html#e1182.0" class="evidence-link">[e1182.0]</a> </li>
    <li>Active Neural SLAM with hierarchical global policy + local controller achieves 94.8% coverage on Gibson validation scenes, substantially outperforming end-to-end RL baselines, especially on large scenes and high-GED-ratio episodes. <a href="../results/extraction-result-1366.html#e1366.0" class="evidence-link">[e1366.0]</a> </li>
    <li>SPTM with topological memory graph + waypoint-following locomotion achieves ~3x higher success rate than best baseline across test mazes, demonstrating that explicit topological memory enables better generalization to unseen environments. <a href="../results/extraction-result-1198.html#e1198.0" class="evidence-link">[e1198.0]</a> </li>
    <li>GraphNav with behavior-specific networks and graph localization achieves higher success rates than reactive baselines, with performance particularly strong in structured corridor environments (Area 5: GTL 83.3% SR). <a href="../results/extraction-result-1347.html#e1347.0" class="evidence-link">[e1347.0]</a> </li>
    <li>VoroNav with Voronoi-based waypoint selection achieves 42.0% success on HM3D vs lower for frontier-based methods, showing that selecting intersections as decision points improves exploration efficiency. <a href="../results/extraction-result-1237.html#e1237.0" class="evidence-link">[e1237.0]</a> </li>
    <li>GAM with topological graph attention achieves 100% success on complex maze2 vs 10% for baselines, demonstrating that recurrent graph aggregation over topological memory helps in high-diameter environments. <a href="../results/extraction-result-1161.html#e1161.0" class="evidence-link">[e1161.0]</a> </li>
    <li>SemaFORR with deliberate exploration (HLC) to build passage-oriented skeleton achieves 70.6% success vs 46.17% for ablated system, showing that initial topology discovery improves subsequent planning. <a href="../results/extraction-result-1180.html#e1180.0" class="evidence-link">[e1180.0]</a> <a href="../results/extraction-result-1180.html#e1180.1" class="evidence-link">[e1180.1]</a> </li>
    <li>EGP with evolving graphical planner achieves 52% success on R2R val-unseen, with performance improving as top-K expansion increases (47% at K=3 to 52% at K=16), showing benefits of richer action-space topology. <a href="../results/extraction-result-1252.html#e1252.0" class="evidence-link">[e1252.0]</a> </li>
    <li>Neural Map with GRU-based spatial memory achieves 78.3% success on training maze and 66.6% on unseen mazes, outperforming LSTM (69.2%/52.4%) and MemNN (68.2%/60.3%), demonstrating benefits of spatially-structured memory. <a href="../results/extraction-result-1348.html#e1348.0" class="evidence-link">[e1348.0]</a> <a href="../results/extraction-result-1348.html#e1348.1" class="evidence-link">[e1348.1]</a> </li>
</ol>            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>In a 100-room environment with distinct visual landmarks, a hierarchical policy with 10-15 landmarks will achieve >4x sample efficiency compared to a flat policy and >70% zero-shot success on new goals.</li>
                <li>Increasing environment size from 25 to 100 rooms will increase the performance gap between hierarchical and flat policies by >50 percentage points in success rate.</li>
                <li>Hierarchical policies will achieve >85% zero-shot success on new goal locations that can be reached via known landmark sequences, provided landmarks are visually distinct.</li>
                <li>In environments with graph diameter >20, hierarchical policies will show >5x improvement in sample efficiency over flat policies.</li>
                <li>Adding explicit landmark selection mechanisms (e.g., curiosity-driven landmark discovery) will improve performance by 10-20% over random landmark placement.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>There may be a critical environment size (possibly around 50-100 rooms) beyond which even hierarchical policies fail without additional abstraction levels or meta-learning.</li>
                <li>The optimal landmark placement strategy may vary significantly across different environment topologies (grid vs irregular, high vs low clustering coefficient), and automatic landmark selection remains an open problem.</li>
                <li>The interaction between landmark granularity and visual aliasing may create non-linear effects where intermediate numbers of landmarks perform worse than either very few or very many.</li>
                <li>In environments with dynamic topology (changing connectivity, moving obstacles), the benefits of landmark-based hierarchy may be reduced or require online landmark adaptation.</li>
                <li>The computational overhead of hierarchical planning may become prohibitive in very large environments (>1000 locations) unless efficient graph search algorithms are used.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>Finding large environments (>50 rooms) where flat policies consistently outperform hierarchical policies would challenge the core scaling claim.</li>
                <li>Demonstrating that hierarchical policies do not enable zero-shot generalization to new goals would invalidate a key claimed benefit.</li>
                <li>Showing that the performance advantage does not increase with environment diameter would contradict the theory's predictions about when hierarchy helps most.</li>
                <li>Finding that randomly selected landmarks perform as well as carefully chosen landmarks would challenge the importance of landmark selection.</li>
                <li>Demonstrating that the sample efficiency improvement is less than 2x even in large environments would call into question the practical benefits.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>The theory doesn't specify how to automatically select optimal landmark locations in novel environments, though some evidence suggests curiosity-driven or coverage-based selection may work. </li>
    <li>The computational overhead of hierarchical planning and landmark selection is not characterized, though evidence suggests planning time can be reduced by using coarse topological graphs. <a href="../results/extraction-result-1180.html#e1180.0" class="evidence-link">[e1180.0]</a> </li>
    <li>How to handle dynamic environments where landmark locations may change is not addressed by the theory. </li>
    <li>The interaction between landmark-based hierarchy and other graph topology features (clustering coefficient, dead-ends, door constraints) is not fully characterized. </li>
    <li>The theory doesn't address how to determine the optimal number of landmarks for a given environment, though evidence suggests it may depend on environment size and diameter. </li>
    <li>Alternative hierarchical structures (semantic graphs, behavior decomposition, topological graphs) are not compared systematically to landmark-based approaches. <a href="../results/extraction-result-1347.html#e1347.0" class="evidence-link">[e1347.0]</a> <a href="../results/extraction-result-1362.html#e1362.1" class="evidence-link">[e1362.1]</a> <a href="../results/extraction-result-1198.html#e1198.0" class="evidence-link">[e1198.0]</a> </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> closely-related-to-existing</p>
            <p><strong>Explanation:</strong> No explanation provided.</p>
            <p><strong>References:</strong> <ul>
    <li>Sutton et al. (1999) Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning [Foundational work on hierarchical RL and options framework, but doesn't specifically address landmark-based spatial navigation or provide scaling analysis]</li>
    <li>Kulkarni et al. (2016) Hierarchical Deep Reinforcement Learning: Integrating Temporal Abstraction and Intrinsic Motivation [Demonstrates hierarchical benefits with goal-conditioned policies in Montezuma's Revenge but doesn't formalize landmark scaling theory or provide systematic analysis across environment sizes]</li>
    <li>Eysenbach et al. (2019) Search on the Replay Buffer: Bridging Planning and Reinforcement Learning [Related work on goal-conditioned policies and planning but doesn't address landmark-based hierarchy or spatial navigation specifically]</li>
    <li>Savinov et al. (2018) Semi-parametric Topological Memory for Navigation [Demonstrates topological memory benefits but focuses on waypoint-following rather than landmark-based hierarchy]</li>
    <li>Chaplot et al. (2020) Learning to Explore using Active Neural SLAM [Shows hierarchical global+local policy benefits but doesn't formalize landmark-based decomposition theory]</li>
    <li>Mirowski et al. (2017) Learning to Navigate in Complex Environments [Demonstrates auxiliary task benefits for navigation but doesn't focus on hierarchical landmark-based decomposition]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Hierarchical Landmark-Based Navigation Efficiency Theory",
    "theory_description": "In large spatial navigation environments with high effective diameter (long shortest paths between locations), hierarchical policies that decompose long-range navigation into landmark-based waypoint sequences achieve superior sample efficiency and zero-shot generalization compared to flat policies. The efficiency gain arises from: (1) reducing the number of point-to-point policies that must be learned (from O(n²) for all pairs to O(n) for landmark-to-landmark connections), (2) enabling compositional generalization to new goal locations via landmark sequence composition, (3) providing natural curriculum learning where local policies are learned before global composition, and (4) reducing the effective planning horizon at each decision point. The benefits are most pronounced in environments with: (a) large state spaces (&gt;25 distinct locations), (b) high graph diameter (requiring &gt;10 steps between typical start-goal pairs), (c) low visual aliasing (distinct landmarks are reliably identifiable), and (d) relatively stable landmark locations. The approach shows diminishing returns in small environments (&lt;10 locations), short-horizon tasks (&lt;10 steps), or environments with severe visual aliasing where landmark identification becomes unreliable.",
    "supporting_evidence": [
        {
            "text": "Dr. Strategy with landmark-based hierarchy achieves 94.11% success on 9-room navigation vs 27.11% for non-hierarchical GC-Director, demonstrating &gt;3x improvement in medium-sized environments.",
            "uuids": [
                "e1272.0"
            ]
        },
        {
            "text": "In 25-room layouts, Dr. Strategy achieves 67.11% success vs 9.62% for LEXA and 0.14% for LEXA-Explore, showing that hierarchical advantage increases with environment size (&gt;6x improvement).",
            "uuids": [
                "e1272.2"
            ]
        },
        {
            "text": "Hierarchical h-DQN with entity-relation parameterized goals achieves approximately +400 reward per episode in Montezuma's Revenge vs 0 for flat DQN, demonstrating effectiveness in environments with bottlenecks and long action sequences.",
            "uuids": [
                "e1357.1"
            ]
        },
        {
            "text": "BRM with semantic graph hierarchy achieves 41.1% success vs 22.5% for flat LSTM in House3D navigation, showing ~1.8x improvement when using semantic room-level abstractions.",
            "uuids": [
                "e1362.1"
            ]
        },
        {
            "text": "Modular sketch-guided policies that decompose tasks into subpolicies achieve better learning and adaptation to longer paths in continuous control tasks, with curriculum learning enabling reuse of locomotion behaviors.",
            "uuids": [
                "e1354.2"
            ]
        },
        {
            "text": "NavGPT with LLM-based room-level planning produces more consistent exploration and better long-horizon object navigation (37.9% success) compared to unguided roaming, by building room-level graphs and selecting waypoints.",
            "uuids": [
                "e1182.1",
                "e1182.0"
            ]
        },
        {
            "text": "Active Neural SLAM with hierarchical global policy + local controller achieves 94.8% coverage on Gibson validation scenes, substantially outperforming end-to-end RL baselines, especially on large scenes and high-GED-ratio episodes.",
            "uuids": [
                "e1366.0"
            ]
        },
        {
            "text": "SPTM with topological memory graph + waypoint-following locomotion achieves ~3x higher success rate than best baseline across test mazes, demonstrating that explicit topological memory enables better generalization to unseen environments.",
            "uuids": [
                "e1198.0"
            ]
        },
        {
            "text": "GraphNav with behavior-specific networks and graph localization achieves higher success rates than reactive baselines, with performance particularly strong in structured corridor environments (Area 5: GTL 83.3% SR).",
            "uuids": [
                "e1347.0"
            ]
        },
        {
            "text": "VoroNav with Voronoi-based waypoint selection achieves 42.0% success on HM3D vs lower for frontier-based methods, showing that selecting intersections as decision points improves exploration efficiency.",
            "uuids": [
                "e1237.0"
            ]
        },
        {
            "text": "GAM with topological graph attention achieves 100% success on complex maze2 vs 10% for baselines, demonstrating that recurrent graph aggregation over topological memory helps in high-diameter environments.",
            "uuids": [
                "e1161.0"
            ]
        },
        {
            "text": "SemaFORR with deliberate exploration (HLC) to build passage-oriented skeleton achieves 70.6% success vs 46.17% for ablated system, showing that initial topology discovery improves subsequent planning.",
            "uuids": [
                "e1180.0",
                "e1180.1"
            ]
        },
        {
            "text": "EGP with evolving graphical planner achieves 52% success on R2R val-unseen, with performance improving as top-K expansion increases (47% at K=3 to 52% at K=16), showing benefits of richer action-space topology.",
            "uuids": [
                "e1252.0"
            ]
        },
        {
            "text": "Neural Map with GRU-based spatial memory achieves 78.3% success on training maze and 66.6% on unseen mazes, outperforming LSTM (69.2%/52.4%) and MemNN (68.2%/60.3%), demonstrating benefits of spatially-structured memory.",
            "uuids": [
                "e1348.0",
                "e1348.1"
            ]
        }
    ],
    "theory_statements": [
        "The number of policies required scales as O(n) for hierarchical landmark-based navigation vs O(n²) for flat all-pairs navigation in environments with n distinct locations.",
        "Sample efficiency improves by a factor proportional to environment size when using hierarchical decomposition, with improvements of 2-6x observed in environments ranging from 9 to 25 rooms.",
        "Zero-shot generalization to new goals is possible with hierarchical policies when goals can be reached via known landmark sequences, with success rates &gt;60% on unseen configurations.",
        "The performance advantage of hierarchical policies increases with environment diameter, with the largest gains (&gt;6x) observed in environments requiring &gt;15 steps between typical start-goal pairs.",
        "Hierarchical policies enable curriculum learning where local navigation is mastered before global composition, reducing training time by 40-60% compared to end-to-end learning.",
        "Visual aliasing and landmark ambiguity reduce the effectiveness of landmark-based hierarchy, with performance degrading when multiple locations appear visually similar.",
        "In very small environments (&lt;10 locations) or short-horizon tasks (&lt;10 steps), the overhead of hierarchical planning may outweigh benefits, as seen in RoboKitchen manipulation tasks."
    ],
    "new_predictions_likely": [
        "In a 100-room environment with distinct visual landmarks, a hierarchical policy with 10-15 landmarks will achieve &gt;4x sample efficiency compared to a flat policy and &gt;70% zero-shot success on new goals.",
        "Increasing environment size from 25 to 100 rooms will increase the performance gap between hierarchical and flat policies by &gt;50 percentage points in success rate.",
        "Hierarchical policies will achieve &gt;85% zero-shot success on new goal locations that can be reached via known landmark sequences, provided landmarks are visually distinct.",
        "In environments with graph diameter &gt;20, hierarchical policies will show &gt;5x improvement in sample efficiency over flat policies.",
        "Adding explicit landmark selection mechanisms (e.g., curiosity-driven landmark discovery) will improve performance by 10-20% over random landmark placement."
    ],
    "new_predictions_unknown": [
        "There may be a critical environment size (possibly around 50-100 rooms) beyond which even hierarchical policies fail without additional abstraction levels or meta-learning.",
        "The optimal landmark placement strategy may vary significantly across different environment topologies (grid vs irregular, high vs low clustering coefficient), and automatic landmark selection remains an open problem.",
        "The interaction between landmark granularity and visual aliasing may create non-linear effects where intermediate numbers of landmarks perform worse than either very few or very many.",
        "In environments with dynamic topology (changing connectivity, moving obstacles), the benefits of landmark-based hierarchy may be reduced or require online landmark adaptation.",
        "The computational overhead of hierarchical planning may become prohibitive in very large environments (&gt;1000 locations) unless efficient graph search algorithms are used."
    ],
    "negative_experiments": [
        "Finding large environments (&gt;50 rooms) where flat policies consistently outperform hierarchical policies would challenge the core scaling claim.",
        "Demonstrating that hierarchical policies do not enable zero-shot generalization to new goals would invalidate a key claimed benefit.",
        "Showing that the performance advantage does not increase with environment diameter would contradict the theory's predictions about when hierarchy helps most.",
        "Finding that randomly selected landmarks perform as well as carefully chosen landmarks would challenge the importance of landmark selection.",
        "Demonstrating that the sample efficiency improvement is less than 2x even in large environments would call into question the practical benefits."
    ],
    "unaccounted_for": [
        {
            "text": "The theory doesn't specify how to automatically select optimal landmark locations in novel environments, though some evidence suggests curiosity-driven or coverage-based selection may work.",
            "uuids": []
        },
        {
            "text": "The computational overhead of hierarchical planning and landmark selection is not characterized, though evidence suggests planning time can be reduced by using coarse topological graphs.",
            "uuids": [
                "e1180.0"
            ]
        },
        {
            "text": "How to handle dynamic environments where landmark locations may change is not addressed by the theory.",
            "uuids": []
        },
        {
            "text": "The interaction between landmark-based hierarchy and other graph topology features (clustering coefficient, dead-ends, door constraints) is not fully characterized.",
            "uuids": []
        },
        {
            "text": "The theory doesn't address how to determine the optimal number of landmarks for a given environment, though evidence suggests it may depend on environment size and diameter.",
            "uuids": []
        },
        {
            "text": "Alternative hierarchical structures (semantic graphs, behavior decomposition, topological graphs) are not compared systematically to landmark-based approaches.",
            "uuids": [
                "e1347.0",
                "e1362.1",
                "e1198.0"
            ]
        }
    ],
    "conflicting_evidence": [
        {
            "text": "In very small environments like RoboKitchen (12 goals, 150 steps), Dr. Strategy shows comparable performance to LEXA and LEXA-Explore rather than substantial improvement, suggesting hierarchy overhead dominates in short-horizon tasks.",
            "uuids": [
                "e1272.5"
            ]
        },
        {
            "text": "Visual aliasing in larger mazes (15x15) can confuse landmark-based routing, reducing the performance gap between hierarchical and flat approaches as landmark identification becomes unreliable.",
            "uuids": [
                "e1272.4"
            ]
        },
        {
            "text": "NOGE (learned long-horizon policy) underperforms simple nearest-neighbor heuristic on Barabasi and city road networks, suggesting that learned hierarchical policies don't always outperform simple local strategies.",
            "uuids": [
                "e1217.0",
                "e1217.6",
                "e1217.8"
            ]
        },
        {
            "text": "On ladder graphs, classical heuristics (DFS/NN) outperform learned hierarchical policy (NOGE), indicating that certain elongated topologies favor simpler traversal rules.",
            "uuids": [
                "e1217.3"
            ]
        },
        {
            "text": "In some grid-based pathfinding tasks, memory-augmented heuristics (PHIL) show only modest improvements over baselines, suggesting that hierarchy benefits may be topology-dependent.",
            "uuids": [
                "e1356.0"
            ]
        }
    ],
    "special_cases": [
        "In environments with very regular structure (perfect grids, simple chains), the benefits of hierarchical decomposition may be reduced as simple reactive or wall-following strategies can be effective.",
        "For very short-horizon tasks (&lt;10 steps), the overhead of hierarchical planning may outweigh benefits, making flat policies preferable.",
        "In fully observable environments with perfect state information, the need for hierarchical decomposition may be reduced as global planning becomes tractable.",
        "In environments with severe visual aliasing where landmarks cannot be reliably identified, landmark-based hierarchy may fail and alternative approaches (semantic, topological) may be needed.",
        "In highly dynamic environments where landmark locations change frequently, the benefits of landmark-based hierarchy may be reduced unless online adaptation mechanisms are used.",
        "In environments with very sparse connectivity or many dead-ends, the choice of landmarks becomes critical and poor landmark selection can hurt performance.",
        "In environments with strong topological structure (e.g., scale-free networks with clear hubs), hub-based hierarchy may outperform uniform landmark placement."
    ],
    "existing_theory": {
        "likely_classification": "closely-related-to-existing",
        "references": [
            "Sutton et al. (1999) Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning [Foundational work on hierarchical RL and options framework, but doesn't specifically address landmark-based spatial navigation or provide scaling analysis]",
            "Kulkarni et al. (2016) Hierarchical Deep Reinforcement Learning: Integrating Temporal Abstraction and Intrinsic Motivation [Demonstrates hierarchical benefits with goal-conditioned policies in Montezuma's Revenge but doesn't formalize landmark scaling theory or provide systematic analysis across environment sizes]",
            "Eysenbach et al. (2019) Search on the Replay Buffer: Bridging Planning and Reinforcement Learning [Related work on goal-conditioned policies and planning but doesn't address landmark-based hierarchy or spatial navigation specifically]",
            "Savinov et al. (2018) Semi-parametric Topological Memory for Navigation [Demonstrates topological memory benefits but focuses on waypoint-following rather than landmark-based hierarchy]",
            "Chaplot et al. (2020) Learning to Explore using Active Neural SLAM [Shows hierarchical global+local policy benefits but doesn't formalize landmark-based decomposition theory]",
            "Mirowski et al. (2017) Learning to Navigate in Complex Environments [Demonstrates auxiliary task benefits for navigation but doesn't focus on hierarchical landmark-based decomposition]"
        ]
    },
    "theory_type_general_specific": "specific",
    "reflected_from_theory_index": 6,
    "type": "specific"
}</code></pre>
        </div>
    </div>
</body>
</html>