<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Hierarchical Abstraction and Spatial Schema Induction - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-1073</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-1073</p>
                <p><strong>Name:</strong> Hierarchical Abstraction and Spatial Schema Induction</p>
                <p><strong>Type:</strong> general</p>
                <p><strong>Theory Query:</strong> Build a theory of how language models solve puzzle games involving spatial knowledge, like Sudoku.</p>
                <p><strong>Description:</strong> This theory proposes that LLMs solve spatial puzzle games by inducing hierarchical abstractions and spatial schemas from their training data, allowing them to chunk and manipulate puzzle elements at multiple levels of granularity. Through exposure to structured text and spatial reasoning problems, LLMs develop internal representations that capture both local (cell-level) and global (grid-level) patterns, enabling efficient reasoning and generalization to novel puzzles.</p>
                <p><strong>Knowledge Cutoff Year:</strong> -1</p>
                <p><strong>Knowledge Cutoff Month:</strong> -1</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <h3>Statement 0: Hierarchical Schema Formation (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; language model &#8594; is_trained_on &#8594; structured spatial reasoning data</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; language model &#8594; develops_internal_hierarchical_schemas &#8594; representing local and global spatial relationships</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>LLMs can generalize from small to large spatial puzzles, indicating abstraction beyond surface features. </li>
    <li>Analysis of LLM attention patterns reveals focus on both local cell neighborhoods and global grid structure. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> While related to hierarchical representations in neural networks, the specific application to spatial schema induction in LLMs is new.</p>            <p><strong>What Already Exists:</strong> Hierarchical abstraction is a known property of deep neural networks in vision and language.</p>            <p><strong>What is Novel:</strong> The application of hierarchical schema induction to spatial puzzle solving in LLMs is novel.</p>
            <p><strong>References:</strong> <ul>
    <li>Yamins & DiCarlo (2016) Using goal-driven deep learning models to understand sensory cortex [Hierarchical abstraction in vision]</li>
    <li>Tenney et al. (2019) BERT Rediscovers the Classical NLP Pipeline [Hierarchical linguistic abstraction]</li>
</ul>
            <h3>Statement 1: Schema-Guided Reasoning (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; language model &#8594; has_internal_hierarchical_schemas &#8594; for spatial puzzles<span style="color: #888888;">, and</span></div>
        <div>&#8226; language model &#8594; receives_input &#8594; partially-filled spatial puzzle</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; language model &#8594; applies_schema-guided_reasoning &#8594; to infer missing elements at multiple levels</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>LLMs can solve puzzles by filling in both individual cells and larger substructures (e.g., rows, boxes). </li>
    <li>LLMs' errors often reflect schema-level misgeneralizations rather than random mistakes. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: green; font-weight: bold;">new</span></p>
            <p><strong>Explanation:</strong> This law extends schema theory to LLMs' spatial reasoning, which is not previously established.</p>            <p><strong>What Already Exists:</strong> Schema-based reasoning is established in cognitive science and some neural models.</p>            <p><strong>What is Novel:</strong> The demonstration that LLMs use induced spatial schemas for multi-level reasoning in puzzles is novel.</p>
            <p><strong>References:</strong> <ul>
    <li>Rumelhart (1980) Schemata: The building blocks of cognition [Schema theory in cognitive science]</li>
    <li>Lake et al. (2017) Building machines that learn and think like people [Schema-based reasoning in AI]</li>
</ul>
            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>LLMs will show transfer learning effects, performing better on novel spatial puzzles that share hierarchical structure with training data.</li>
                <li>LLMs' attention maps will reveal simultaneous focus on local and global puzzle features during solution generation.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>If LLMs are trained on puzzles with novel hierarchical structures, they may develop new, compositional schemas enabling zero-shot generalization.</li>
                <li>LLMs may be able to explain their reasoning in terms of induced schemas if prompted appropriately.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>If LLMs fail to generalize to larger or structurally novel puzzles, this would challenge the hierarchical schema induction hypothesis.</li>
                <li>If LLMs' attention patterns do not reflect hierarchical abstraction, the theory would be called into question.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>The process by which LLMs select or compose schemas for novel puzzles is not directly observable. </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> new</p>
            <p><strong>Explanation:</strong> No prior work has directly demonstrated hierarchical schema induction in LLMs for spatial reasoning.</p>
            <p><strong>References:</strong> <ul>
    <li>Rumelhart (1980) Schemata: The building blocks of cognition [Schema theory in cognitive science]</li>
    <li>Tenney et al. (2019) BERT Rediscovers the Classical NLP Pipeline [Hierarchical abstraction in language models]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Hierarchical Abstraction and Spatial Schema Induction",
    "theory_description": "This theory proposes that LLMs solve spatial puzzle games by inducing hierarchical abstractions and spatial schemas from their training data, allowing them to chunk and manipulate puzzle elements at multiple levels of granularity. Through exposure to structured text and spatial reasoning problems, LLMs develop internal representations that capture both local (cell-level) and global (grid-level) patterns, enabling efficient reasoning and generalization to novel puzzles.",
    "theory_statements": [
        {
            "law": {
                "law_name": "Hierarchical Schema Formation",
                "if": [
                    {
                        "subject": "language model",
                        "relation": "is_trained_on",
                        "object": "structured spatial reasoning data"
                    }
                ],
                "then": [
                    {
                        "subject": "language model",
                        "relation": "develops_internal_hierarchical_schemas",
                        "object": "representing local and global spatial relationships"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "LLMs can generalize from small to large spatial puzzles, indicating abstraction beyond surface features.",
                        "uuids": []
                    },
                    {
                        "text": "Analysis of LLM attention patterns reveals focus on both local cell neighborhoods and global grid structure.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Hierarchical abstraction is a known property of deep neural networks in vision and language.",
                    "what_is_novel": "The application of hierarchical schema induction to spatial puzzle solving in LLMs is novel.",
                    "classification_explanation": "While related to hierarchical representations in neural networks, the specific application to spatial schema induction in LLMs is new.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Yamins & DiCarlo (2016) Using goal-driven deep learning models to understand sensory cortex [Hierarchical abstraction in vision]",
                        "Tenney et al. (2019) BERT Rediscovers the Classical NLP Pipeline [Hierarchical linguistic abstraction]"
                    ]
                }
            }
        },
        {
            "law": {
                "law_name": "Schema-Guided Reasoning",
                "if": [
                    {
                        "subject": "language model",
                        "relation": "has_internal_hierarchical_schemas",
                        "object": "for spatial puzzles"
                    },
                    {
                        "subject": "language model",
                        "relation": "receives_input",
                        "object": "partially-filled spatial puzzle"
                    }
                ],
                "then": [
                    {
                        "subject": "language model",
                        "relation": "applies_schema-guided_reasoning",
                        "object": "to infer missing elements at multiple levels"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "LLMs can solve puzzles by filling in both individual cells and larger substructures (e.g., rows, boxes).",
                        "uuids": []
                    },
                    {
                        "text": "LLMs' errors often reflect schema-level misgeneralizations rather than random mistakes.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Schema-based reasoning is established in cognitive science and some neural models.",
                    "what_is_novel": "The demonstration that LLMs use induced spatial schemas for multi-level reasoning in puzzles is novel.",
                    "classification_explanation": "This law extends schema theory to LLMs' spatial reasoning, which is not previously established.",
                    "likely_classification": "new",
                    "references": [
                        "Rumelhart (1980) Schemata: The building blocks of cognition [Schema theory in cognitive science]",
                        "Lake et al. (2017) Building machines that learn and think like people [Schema-based reasoning in AI]"
                    ]
                }
            }
        }
    ],
    "new_predictions_likely": [
        "LLMs will show transfer learning effects, performing better on novel spatial puzzles that share hierarchical structure with training data.",
        "LLMs' attention maps will reveal simultaneous focus on local and global puzzle features during solution generation."
    ],
    "new_predictions_unknown": [
        "If LLMs are trained on puzzles with novel hierarchical structures, they may develop new, compositional schemas enabling zero-shot generalization.",
        "LLMs may be able to explain their reasoning in terms of induced schemas if prompted appropriately."
    ],
    "negative_experiments": [
        "If LLMs fail to generalize to larger or structurally novel puzzles, this would challenge the hierarchical schema induction hypothesis.",
        "If LLMs' attention patterns do not reflect hierarchical abstraction, the theory would be called into question."
    ],
    "unaccounted_for": [
        {
            "text": "The process by which LLMs select or compose schemas for novel puzzles is not directly observable.",
            "uuids": []
        }
    ],
    "conflicting_evidence": [
        {
            "text": "LLMs sometimes make local errors that violate global constraints, suggesting incomplete schema integration.",
            "uuids": []
        }
    ],
    "special_cases": [
        "Puzzles with highly irregular or non-hierarchical structure may not be efficiently solved by LLMs.",
        "LLMs with limited depth or training data may not develop robust hierarchical schemas."
    ],
    "existing_theory": {
        "what_already_exists": "Hierarchical abstraction and schema theory are established in cognitive science and deep learning.",
        "what_is_novel": "The application of these concepts to LLMs' spatial puzzle solving and the explicit claim of induced spatial schemas is novel.",
        "classification_explanation": "No prior work has directly demonstrated hierarchical schema induction in LLMs for spatial reasoning.",
        "likely_classification": "new",
        "references": [
            "Rumelhart (1980) Schemata: The building blocks of cognition [Schema theory in cognitive science]",
            "Tenney et al. (2019) BERT Rediscovers the Classical NLP Pipeline [Hierarchical abstraction in language models]"
        ]
    },
    "reflected_from_theory_index": 0,
    "type": "general",
    "version": "built-theory-from-results-single-theory-reflection2-nov14-2025-LLM-BASELINE-no-evidence-without-matched-control-theory-name",
    "theory_query": "Build a theory of how language models solve puzzle games involving spatial knowledge, like Sudoku.",
    "original_theory_id": "theory-600",
    "original_theory_name": "Constraint-Driven Training Objectives Enable Neural Networks to Internalize Global Spatial Rules",
    "provide_matched_control_thery_name": false,
    "matched_control_theory_name": null,
    "model_str": "openai/gpt-4.1-2025-04-14"
}</code></pre>
        </div>
    </div>
</body>
</html>