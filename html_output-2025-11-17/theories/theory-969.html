<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Dynamic Episodic-Semantic Memory Integration for LLM Text Game Agents - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-969</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-969</p>
                <p><strong>Name:</strong> Dynamic Episodic-Semantic Memory Integration for LLM Text Game Agents</p>
                <p><strong>Type:</strong> general</p>
                <p><strong>Theory Query:</strong> Build a theory of how LLM agents for text games can best use memory to solve text game tasks.</p>
                <p><strong>Description:</strong> This theory posits that LLM agents achieve optimal performance in text games by dynamically integrating episodic (event-based) and semantic (fact-based) memory representations. The agent maintains a structured memory system that separates and interlinks episodic traces (specific game events, actions, and outcomes) with semantic abstractions (rules, object properties, and world knowledge). The agent adaptively queries and updates both memory types, using episodic memory for context-sensitive reasoning and semantic memory for generalization and planning.</p>
                <p><strong>Knowledge Cutoff Year:</strong> -1</p>
                <p><strong>Knowledge Cutoff Month:</strong> -1</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <h3>Statement 0: Episodic-Semantic Memory Separation and Linking (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; LLM agent &#8594; engages_in &#8594; text game task</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; LLM agent &#8594; stores &#8594; episodic memory traces of events and actions<span style="color: #888888;">, and</span></div>
        <div>&#8226; LLM agent &#8594; stores &#8594; semantic memory of rules, object properties, and world knowledge<span style="color: #888888;">, and</span></div>
        <div>&#8226; episodic memory &#8594; is_linked_to &#8594; semantic memory via abstraction and generalization</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Human memory is organized into episodic and semantic systems, which interact for flexible reasoning. </li>
    <li>Neural architectures with separate episodic and semantic modules show improved generalization and context sensitivity. </li>
    <li>Text games require both recall of specific events (e.g., which door was opened) and general knowledge (e.g., keys open doors). </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> The separation is known, but the explicit, dynamic linking and use in LLM text game agents is novel.</p>            <p><strong>What Already Exists:</strong> Episodic and semantic memory separation is well-established in cognitive science; some neural models use modular memory.</p>            <p><strong>What is Novel:</strong> Dynamic, explicit integration and linking of episodic and semantic memory in LLM agents for text games.</p>
            <p><strong>References:</strong> <ul>
    <li>Tulving (1972) Episodic and semantic memory [episodic/semantic distinction]</li>
    <li>Weston et al. (2015) Memory Networks [modular memory in neural networks]</li>
    <li>Urbanek et al. (2019) Learning to Speak and Act in a Fantasy Text Adventure Game [LLM agents in text games]</li>
</ul>
            <h3>Statement 1: Adaptive Memory Querying Based on Task Demands (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; LLM agent &#8594; faces &#8594; task requiring context-sensitive or general reasoning</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; LLM agent &#8594; queries &#8594; episodic memory for context-specific details<span style="color: #888888;">, and</span></div>
        <div>&#8226; LLM agent &#8594; queries &#8594; semantic memory for general rules or knowledge<span style="color: #888888;">, and</span></div>
        <div>&#8226; LLM agent &#8594; integrates &#8594; retrieved information for decision making</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Humans flexibly query episodic or semantic memory depending on task demands. </li>
    <li>Neural agents with adaptive memory querying outperform those with static recall. </li>
    <li>Text games often require both remembering past actions and applying general knowledge. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> The principle is known, but its explicit, dynamic application in LLM text game agents is new.</p>            <p><strong>What Already Exists:</strong> Adaptive memory querying is observed in human cognition and some neural models.</p>            <p><strong>What is Novel:</strong> Explicit, dynamic adaptation of memory querying in LLM agents for text games.</p>
            <p><strong>References:</strong> <ul>
    <li>Tulving (1985) Memory and consciousness [adaptive memory use in humans]</li>
    <li>Graves et al. (2016) Hybrid computing using a neural network with dynamic external memory [adaptive querying]</li>
    <li>Urbanek et al. (2019) Learning to Speak and Act in a Fantasy Text Adventure Game [LLM agents in text games]</li>
</ul>
            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>LLM agents with explicit episodic-semantic memory integration will outperform agents with monolithic or undifferentiated memory in tasks requiring both context recall and generalization.</li>
                <li>Agents that dynamically adapt their memory querying to the current task will solve multi-step puzzles and ambiguous scenarios more efficiently.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>Emergent memory linking strategies may arise, such as forming new semantic abstractions from repeated episodic experiences.</li>
                <li>Over-integration of episodic and semantic memory may lead to interference or confusion in highly complex games.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>If agents with undifferentiated memory perform as well as those with explicit episodic-semantic separation, the theory would be challenged.</li>
                <li>If dynamic memory querying does not improve performance over static recall, the theory's utility would be questioned.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>The impact of memory capacity limits and forgetting mechanisms is not addressed. </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> somewhat-related-to-existing</p>
            <p><strong>Explanation:</strong> The theory applies known memory principles in a new, explicit way to LLM agents in text games.</p>
            <p><strong>References:</strong> <ul>
    <li>Tulving (1972) Episodic and semantic memory [episodic/semantic distinction]</li>
    <li>Weston et al. (2015) Memory Networks [modular memory in neural networks]</li>
    <li>Urbanek et al. (2019) Learning to Speak and Act in a Fantasy Text Adventure Game [LLM agents in text games]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Dynamic Episodic-Semantic Memory Integration for LLM Text Game Agents",
    "theory_description": "This theory posits that LLM agents achieve optimal performance in text games by dynamically integrating episodic (event-based) and semantic (fact-based) memory representations. The agent maintains a structured memory system that separates and interlinks episodic traces (specific game events, actions, and outcomes) with semantic abstractions (rules, object properties, and world knowledge). The agent adaptively queries and updates both memory types, using episodic memory for context-sensitive reasoning and semantic memory for generalization and planning.",
    "theory_statements": [
        {
            "law": {
                "law_name": "Episodic-Semantic Memory Separation and Linking",
                "if": [
                    {
                        "subject": "LLM agent",
                        "relation": "engages_in",
                        "object": "text game task"
                    }
                ],
                "then": [
                    {
                        "subject": "LLM agent",
                        "relation": "stores",
                        "object": "episodic memory traces of events and actions"
                    },
                    {
                        "subject": "LLM agent",
                        "relation": "stores",
                        "object": "semantic memory of rules, object properties, and world knowledge"
                    },
                    {
                        "subject": "episodic memory",
                        "relation": "is_linked_to",
                        "object": "semantic memory via abstraction and generalization"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Human memory is organized into episodic and semantic systems, which interact for flexible reasoning.",
                        "uuids": []
                    },
                    {
                        "text": "Neural architectures with separate episodic and semantic modules show improved generalization and context sensitivity.",
                        "uuids": []
                    },
                    {
                        "text": "Text games require both recall of specific events (e.g., which door was opened) and general knowledge (e.g., keys open doors).",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Episodic and semantic memory separation is well-established in cognitive science; some neural models use modular memory.",
                    "what_is_novel": "Dynamic, explicit integration and linking of episodic and semantic memory in LLM agents for text games.",
                    "classification_explanation": "The separation is known, but the explicit, dynamic linking and use in LLM text game agents is novel.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Tulving (1972) Episodic and semantic memory [episodic/semantic distinction]",
                        "Weston et al. (2015) Memory Networks [modular memory in neural networks]",
                        "Urbanek et al. (2019) Learning to Speak and Act in a Fantasy Text Adventure Game [LLM agents in text games]"
                    ]
                }
            }
        },
        {
            "law": {
                "law_name": "Adaptive Memory Querying Based on Task Demands",
                "if": [
                    {
                        "subject": "LLM agent",
                        "relation": "faces",
                        "object": "task requiring context-sensitive or general reasoning"
                    }
                ],
                "then": [
                    {
                        "subject": "LLM agent",
                        "relation": "queries",
                        "object": "episodic memory for context-specific details"
                    },
                    {
                        "subject": "LLM agent",
                        "relation": "queries",
                        "object": "semantic memory for general rules or knowledge"
                    },
                    {
                        "subject": "LLM agent",
                        "relation": "integrates",
                        "object": "retrieved information for decision making"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Humans flexibly query episodic or semantic memory depending on task demands.",
                        "uuids": []
                    },
                    {
                        "text": "Neural agents with adaptive memory querying outperform those with static recall.",
                        "uuids": []
                    },
                    {
                        "text": "Text games often require both remembering past actions and applying general knowledge.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Adaptive memory querying is observed in human cognition and some neural models.",
                    "what_is_novel": "Explicit, dynamic adaptation of memory querying in LLM agents for text games.",
                    "classification_explanation": "The principle is known, but its explicit, dynamic application in LLM text game agents is new.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Tulving (1985) Memory and consciousness [adaptive memory use in humans]",
                        "Graves et al. (2016) Hybrid computing using a neural network with dynamic external memory [adaptive querying]",
                        "Urbanek et al. (2019) Learning to Speak and Act in a Fantasy Text Adventure Game [LLM agents in text games]"
                    ]
                }
            }
        }
    ],
    "new_predictions_likely": [
        "LLM agents with explicit episodic-semantic memory integration will outperform agents with monolithic or undifferentiated memory in tasks requiring both context recall and generalization.",
        "Agents that dynamically adapt their memory querying to the current task will solve multi-step puzzles and ambiguous scenarios more efficiently."
    ],
    "new_predictions_unknown": [
        "Emergent memory linking strategies may arise, such as forming new semantic abstractions from repeated episodic experiences.",
        "Over-integration of episodic and semantic memory may lead to interference or confusion in highly complex games."
    ],
    "negative_experiments": [
        "If agents with undifferentiated memory perform as well as those with explicit episodic-semantic separation, the theory would be challenged.",
        "If dynamic memory querying does not improve performance over static recall, the theory's utility would be questioned."
    ],
    "unaccounted_for": [
        {
            "text": "The impact of memory capacity limits and forgetting mechanisms is not addressed.",
            "uuids": []
        }
    ],
    "conflicting_evidence": [
        {
            "text": "Some simple text games can be solved with only short-term or working memory, without explicit episodic-semantic separation.",
            "uuids": []
        }
    ],
    "special_cases": [
        "In very simple or fully observable games, explicit memory separation may be unnecessary.",
        "If the agent's memory linking is poorly calibrated, it may misattribute events or rules."
    ],
    "existing_theory": {
        "what_already_exists": "Episodic and semantic memory separation and adaptive querying are known in cognitive science and some neural models.",
        "what_is_novel": "Dynamic, explicit integration and linking of episodic and semantic memory in LLM agents for text games.",
        "classification_explanation": "The theory applies known memory principles in a new, explicit way to LLM agents in text games.",
        "likely_classification": "somewhat-related-to-existing",
        "references": [
            "Tulving (1972) Episodic and semantic memory [episodic/semantic distinction]",
            "Weston et al. (2015) Memory Networks [modular memory in neural networks]",
            "Urbanek et al. (2019) Learning to Speak and Act in a Fantasy Text Adventure Game [LLM agents in text games]"
        ]
    },
    "reflected_from_theory_index": 3,
    "type": "general",
    "version": "built-theory-from-results-single-theory-reflection2-nov14-2025-LLM-BASELINE-no-evidence-without-matched-control-theory-name",
    "theory_query": "Build a theory of how LLM agents for text games can best use memory to solve text game tasks.",
    "original_theory_id": "theory-593",
    "original_theory_name": "Hybrid Memory Architectures Enable Robust Long-Horizon Reasoning and Generalization in LLM Agents for Text Games",
    "provide_matched_control_thery_name": false,
    "matched_control_theory_name": null,
    "model_str": "openai/gpt-4.1-2025-04-14"
}</code></pre>
        </div>
    </div>
</body>
</html>