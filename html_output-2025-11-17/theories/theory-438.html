<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Human-Aware AI Discovery Theory - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-438</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-438</p>
                <p><strong>Name:</strong> Human-Aware AI Discovery Theory</p>
                <p><strong>Type:</strong> specific</p>
                <p><strong>Theory Query:</strong> Build a theory of how AI systems can systematically generate and validate scientific hypotheses, balancing novelty with plausibility, quantifying hypothesis quality, ensuring reproducibility, preventing hallucinations, and integrating statistical rigor, based on the following results.</p>
                <p><strong>Description:</strong> AI systems can be designed to generate hypotheses that are explicitly complementary to human cognition by modeling human accessibility through co-authorship networks and literature patterns, combined with independent scientific plausibility assessment. The theory states that: (1) human cognitive accessibility can be quantified through graph-based metrics in research hypergraphs containing materials/concepts, properties, and disambiguated authors; (2) AI systems can be tuned via a mixing parameter to generate hypotheses ranging from human-mimetic (accessible) to human-complementary (alien); (3) optimal complementary hypotheses exist in a narrow parameter range (β ≈ 0.2-0.3) that balances human-inaccessibility with scientific plausibility as measured by independent theoretical validators; (4) human-aware AI substantially outperforms content-only AI for discovery acceleration (50-400% improvement); (5) the framework requires integration of both graph-based accessibility metrics and domain-specific plausibility scorers to achieve optimal performance.</p>
                <p><strong>Knowledge Cutoff Year:</strong> 2024</p>
                <p><strong>Knowledge Cutoff Month:</strong> 12</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <ol>
                <li>Human cognitive accessibility A can be quantified as A = f(SPD, Jaccard_coauthor, transition_probability) where SPD is shortest-path distance in research hypergraphs, Jaccard measures shared expert density, and transition probabilities capture random-walk accessibility.</li>
                <li>AI systems with explicit human-awareness (modeling co-authorship via hypergraph random walks) outperform content-only systems by 50-400% on discovery acceleration metrics, with larger improvements in domains with sparse relevant literature.</li>
                <li>Optimal complementary hypotheses exist at mixing parameter values β ∈ [0.2, 0.3] that maximize P(undiscoverable by humans AND scientifically plausible), where the mixing formula is: score = (1-β)/2 * plausibility_Z + (1+β)/2 * alienness_Z.</li>
                <li>The effectiveness of human-aware AI scales with: (1) quality of author disambiguation, (2) availability of theoretical plausibility scorers, and (3) density of co-authorship networks in the domain.</li>
                <li>Human-aware AI shows largest benefits (>100% improvement) in well-established fields with clear expertise boundaries and available theoretical validators, and smallest benefits (<30%) in emerging interdisciplinary areas or domains without theoretical scorers.</li>
                <li>Discoverability (human likelihood of finding a hypothesis) decreases monotonically with increasing β, while theoretical plausibility decays more slowly, creating an optimal complementary range.</li>
                <li>The framework requires ~45% of properties to have available theoretical scorers for full validation; performance in domains without scorers relies solely on embedding-based plausibility proxies.</li>
                <li>Random walks with alpha-weighted sampling (alpha=1 recommended) over mixed hypergraphs effectively simulate chains of human inference through author-author, author-material, and material-property steps.</li>
            </ol>
            <h3>Supporting Evidence</h3>
<ol>
    <li>Human-aware hypergraph with authors achieves ~100% average increase in precision over content-only baselines for materials discovery across thermoelectricity, ferroelectricity, and photovoltaics <a href="../results/extraction-result-2654.html#e2654.0" class="evidence-link">[e2654.0]</a> </li>
    <li>SPD+beta system identifies optimal beta range 0.2-0.3 where candidates are unlikely to be found by humans yet likely to yield strong theoretical scores <a href="../results/extraction-result-2655.html#e2655.2" class="evidence-link">[e2655.2]</a> </li>
    <li>Expert-aware random walks (250k walks, length 20, alpha-weighted sampling) simulate human-accessible inference paths through co-authorship networks <a href="../results/extraction-result-2654.html#e2654.0" class="evidence-link">[e2654.0]</a> </li>
    <li>Shortest-path distance (SPD) in hypergraph quantifies cognitive inaccessibility, with longer SPD indicating greater human-unavailability <a href="../results/extraction-result-2655.html#e2655.2" class="evidence-link">[e2655.2]</a> </li>
    <li>DeepWalk embeddings (dim=200, window=8) trained on author-material-property hypergraph sequences capture human accessibility patterns with ~36-38% precision for COVID-19 predictions vs ~10-12% for content-only <a href="../results/extraction-result-2655.html#e2655.0" class="evidence-link">[e2655.0]</a> <a href="../results/extraction-result-2654.html#e2654.0" class="evidence-link">[e2654.0]</a> </li>
    <li>Expectation gap analysis quantifies difference between expected beta under plausible vs discoverable conditionals, showing positive gaps for most properties <a href="../results/extraction-result-2655.html#e2655.6" class="evidence-link">[e2655.6]</a> </li>
    <li>COVID-19 therapy predictions using human-aware methods achieved 350-400% relative improvement over content-only baseline (36-38% vs ~10% precision at 12 months) <a href="../results/extraction-result-2654.html#e2654.0" class="evidence-link">[e2654.0]</a> </li>
    <li>GraphSAGE with authors outperforms author-less variant by 10-20 percentage points (e.g., thermoelectricity: 62% vs 48%) <a href="../results/extraction-result-2654.html#e2654.3" class="evidence-link">[e2654.3]</a> </li>
    <li>Drug repurposing with human-aware hypergraph yielded 43% higher precision than content-only model evaluated 19 years post-prediction <a href="../results/extraction-result-2654.html#e2654.0" class="evidence-link">[e2654.0]</a> </li>
    <li>Transition probability metrics from random walks provide probabilistic measures of accessibility, with Markov transition matrices used to rank candidates <a href="../results/extraction-result-2654.html#e2654.0" class="evidence-link">[e2654.0]</a> </li>
    <li>First-principles theoretical scorers (DFT power factor, spontaneous polarization, PPI proximity) validate that high-beta predictions maintain scientific plausibility <a href="../results/extraction-result-2655.html#e2655.5" class="evidence-link">[e2655.5]</a> </li>
    <li>Theoretical scores of predicted sets remain high into modestly positive beta values (up to ~0.4) and often exceed average scores of published discoveries <a href="../results/extraction-result-2655.html#e2655.5" class="evidence-link">[e2655.5]</a> </li>
    <li>Joint probability P(undiscoverable, plausible | beta) identifies optimal beta ranges for complementary hypothesis generation <a href="../results/extraction-result-2655.html#e2655.6" class="evidence-link">[e2655.6]</a> </li>
    <li>Correlation between prediction precision and drug literature occurrence: r=0.74, p<0.001, indicating method works better for frequently-mentioned entities <a href="../results/extraction-result-2654.html#e2654.0" class="evidence-link">[e2654.0]</a> </li>
    <li>Progesterone for COVID-19 was among true positives uniquely predicted by human-aware method and later entered clinical trials <a href="../results/extraction-result-2655.html#e2655.0" class="evidence-link">[e2655.0]</a> </li>
</ol>            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>AI systems that explicitly model human expertise networks will consistently outperform content-only systems by >50% on discovery acceleration tasks across scientific domains with established research communities and available theoretical validators.</li>
                <li>The optimal parameter for complementary discovery will fall in the range 0.15-0.35 across diverse scientific fields, with variation correlating with field maturity, collaboration density, and availability of first-principles validation methods.</li>
                <li>Human-aware AI will show largest benefits (>100% improvement) in fields like materials science, drug repurposing, and established chemistry domains, and smallest benefits (<30%) in emerging interdisciplinary areas like synthetic biology or quantum computing applications.</li>
                <li>Combining human-aware graph metrics with theoretical plausibility scoring will identify 2-3x more validated complementary hypotheses than either approach alone, particularly in the β=0.2-0.3 range.</li>
                <li>In domains where theoretical scorers are available for >60% of properties, human-aware AI will maintain high precision (>30%) even at β=0.4, while domains with <30% scorer coverage will show rapid precision decay beyond β=0.25.</li>
                <li>The correlation between prediction precision and entity frequency in literature will hold across domains, with r>0.6 expected for most scientific fields with sufficient publication data.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>Whether human-aware AI can adapt to rapidly changing research landscapes as new collaborations form and expertise evolves, or if models require retraining every 1-2 years to maintain performance.</li>
                <li>If there exist systematic 'blind spots' in human cognition that AI can reliably identify across multiple domains, or if human-inaccessible hypotheses are domain-specifically implausible.</li>
                <li>Whether human-aware AI can generalize across cultures and research systems with different collaboration patterns (e.g., Asian vs Western research networks, industry vs academic collaborations) without recalibration.</li>
                <li>If adversarial researchers could game human-aware AI systems by strategically forming collaborations to influence AI predictions, and whether such gaming would be detectable.</li>
                <li>Whether the optimal β range (0.2-0.3) is universal across all sciences or if it varies systematically by field characteristics (e.g., experimental cost, validation time, interdisciplinarity).</li>
                <li>If human-aware AI can identify breakthrough hypotheses that require paradigm shifts, or if it is inherently limited to incremental advances within existing frameworks.</li>
                <li>Whether combining human-aware AI with other AI approaches (e.g., causal reasoning, symbolic AI) would yield multiplicative or merely additive improvements in discovery acceleration.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>Finding that content-only AI performs as well as human-aware AI across multiple domains would invalidate the core premise of human-awareness value.</li>
                <li>Demonstrating that random parameter selection (random β) performs as well as optimized β=0.2-0.3 would question the existence of an optimal complementary range.</li>
                <li>Showing that shortest-path distance does not correlate with human discovery patterns (e.g., r<0.2) would challenge the accessibility quantification method.</li>
                <li>Evidence that human-aware AI predictions are no more likely to be validated than random predictions from the same candidate pool would contradict the theory's utility.</li>
                <li>Finding that removing author nodes from hypergraphs does not significantly decrease performance (<10% drop) would question the necessity of explicit human modeling.</li>
                <li>Demonstrating that theoretical plausibility scores do not correlate with eventual experimental validation would undermine the plausibility assessment component.</li>
                <li>Showing that the expectation gap is negative or near-zero for most properties would contradict the existence of a complementary discovery opportunity.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>The theory does not address how to handle fields where collaboration patterns are weak or non-existent (e.g., theoretical mathematics, some humanities) </li>
    <li>Mechanisms for incorporating non-publication-based expertise (industry knowledge, clinical practice, craft knowledge) are not specified </li>
    <li>The theory does not explain how to balance human-awareness with other discovery objectives (experimental cost, ethical constraints, feasibility, time-to-validation) </li>
    <li>Computational cost trade-offs between human-aware methods (250k random walks) and simpler approaches are not systematically analyzed <a href="../results/extraction-result-2654.html#e2654.0" class="evidence-link">[e2654.0]</a> </li>
    <li>The theory does not address how to handle temporal dynamics: how quickly do expertise networks change and how often must models be retrained </li>
    <li>Integration strategies when multiple types of plausibility scorers (DFT, PPI, symmetry analysis) give conflicting assessments are not specified <a href="../results/extraction-result-2655.html#e2655.5" class="evidence-link">[e2655.5]</a> </li>
    <li>The theory does not explain how to handle cases where high-impact discoveries come from unexpected cross-domain connections not captured in co-authorship networks </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> new</p>
            <p><strong>Explanation:</strong> No explanation provided.</p>
            <p><strong>References:</strong> <ul>
    <li>Rzhetsky et al. (2015) Choosing experiments to accelerate collective discovery [Related empirical work on scientific strategy and collaboration patterns, but does not formalize human-aware AI theory or provide algorithmic framework]</li>
    <li>Foster et al. (2015) Tradition and Innovation in Scientists' Research Strategies [Empirical study of human discovery patterns and cognitive constraints, but no AI system design or complementary discovery framework]</li>
    <li>Fortunato et al. (2018) Science of science [Broad review of science of science including collaboration networks, but does not address human-aware AI design or complementary hypothesis generation]</li>
    <li>Tshitoyan et al. (2019) Unsupervised word embeddings capture latent knowledge from materials science literature [Content-only materials discovery without human-awareness modeling, serves as baseline comparison]</li>
    <li>Swanson (1986) Undiscovered public knowledge [Foundational work on literature-based discovery, but predates modern AI and does not incorporate human accessibility modeling]</li>
    <li>Kitano (2016) Artificial Intelligence to Win the Nobel Prize and Beyond [Speculative vision of AI for scientific discovery, but does not provide concrete human-aware framework or validation]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Human-Aware AI Discovery Theory",
    "theory_description": "AI systems can be designed to generate hypotheses that are explicitly complementary to human cognition by modeling human accessibility through co-authorship networks and literature patterns, combined with independent scientific plausibility assessment. The theory states that: (1) human cognitive accessibility can be quantified through graph-based metrics in research hypergraphs containing materials/concepts, properties, and disambiguated authors; (2) AI systems can be tuned via a mixing parameter to generate hypotheses ranging from human-mimetic (accessible) to human-complementary (alien); (3) optimal complementary hypotheses exist in a narrow parameter range (β ≈ 0.2-0.3) that balances human-inaccessibility with scientific plausibility as measured by independent theoretical validators; (4) human-aware AI substantially outperforms content-only AI for discovery acceleration (50-400% improvement); (5) the framework requires integration of both graph-based accessibility metrics and domain-specific plausibility scorers to achieve optimal performance.",
    "supporting_evidence": [
        {
            "text": "Human-aware hypergraph with authors achieves ~100% average increase in precision over content-only baselines for materials discovery across thermoelectricity, ferroelectricity, and photovoltaics",
            "uuids": [
                "e2654.0"
            ]
        },
        {
            "text": "SPD+beta system identifies optimal beta range 0.2-0.3 where candidates are unlikely to be found by humans yet likely to yield strong theoretical scores",
            "uuids": [
                "e2655.2"
            ]
        },
        {
            "text": "Expert-aware random walks (250k walks, length 20, alpha-weighted sampling) simulate human-accessible inference paths through co-authorship networks",
            "uuids": [
                "e2654.0"
            ]
        },
        {
            "text": "Shortest-path distance (SPD) in hypergraph quantifies cognitive inaccessibility, with longer SPD indicating greater human-unavailability",
            "uuids": [
                "e2655.2"
            ]
        },
        {
            "text": "DeepWalk embeddings (dim=200, window=8) trained on author-material-property hypergraph sequences capture human accessibility patterns with ~36-38% precision for COVID-19 predictions vs ~10-12% for content-only",
            "uuids": [
                "e2655.0",
                "e2654.0"
            ]
        },
        {
            "text": "Expectation gap analysis quantifies difference between expected beta under plausible vs discoverable conditionals, showing positive gaps for most properties",
            "uuids": [
                "e2655.6"
            ]
        },
        {
            "text": "COVID-19 therapy predictions using human-aware methods achieved 350-400% relative improvement over content-only baseline (36-38% vs ~10% precision at 12 months)",
            "uuids": [
                "e2654.0"
            ]
        },
        {
            "text": "GraphSAGE with authors outperforms author-less variant by 10-20 percentage points (e.g., thermoelectricity: 62% vs 48%)",
            "uuids": [
                "e2654.3"
            ]
        },
        {
            "text": "Drug repurposing with human-aware hypergraph yielded 43% higher precision than content-only model evaluated 19 years post-prediction",
            "uuids": [
                "e2654.0"
            ]
        },
        {
            "text": "Transition probability metrics from random walks provide probabilistic measures of accessibility, with Markov transition matrices used to rank candidates",
            "uuids": [
                "e2654.0"
            ]
        },
        {
            "text": "First-principles theoretical scorers (DFT power factor, spontaneous polarization, PPI proximity) validate that high-beta predictions maintain scientific plausibility",
            "uuids": [
                "e2655.5"
            ]
        },
        {
            "text": "Theoretical scores of predicted sets remain high into modestly positive beta values (up to ~0.4) and often exceed average scores of published discoveries",
            "uuids": [
                "e2655.5"
            ]
        },
        {
            "text": "Joint probability P(undiscoverable, plausible | beta) identifies optimal beta ranges for complementary hypothesis generation",
            "uuids": [
                "e2655.6"
            ]
        },
        {
            "text": "Correlation between prediction precision and drug literature occurrence: r=0.74, p&lt;0.001, indicating method works better for frequently-mentioned entities",
            "uuids": [
                "e2654.0"
            ]
        },
        {
            "text": "Progesterone for COVID-19 was among true positives uniquely predicted by human-aware method and later entered clinical trials",
            "uuids": [
                "e2655.0"
            ]
        }
    ],
    "theory_statements": [
        "Human cognitive accessibility A can be quantified as A = f(SPD, Jaccard_coauthor, transition_probability) where SPD is shortest-path distance in research hypergraphs, Jaccard measures shared expert density, and transition probabilities capture random-walk accessibility.",
        "AI systems with explicit human-awareness (modeling co-authorship via hypergraph random walks) outperform content-only systems by 50-400% on discovery acceleration metrics, with larger improvements in domains with sparse relevant literature.",
        "Optimal complementary hypotheses exist at mixing parameter values β ∈ [0.2, 0.3] that maximize P(undiscoverable by humans AND scientifically plausible), where the mixing formula is: score = (1-β)/2 * plausibility_Z + (1+β)/2 * alienness_Z.",
        "The effectiveness of human-aware AI scales with: (1) quality of author disambiguation, (2) availability of theoretical plausibility scorers, and (3) density of co-authorship networks in the domain.",
        "Human-aware AI shows largest benefits (&gt;100% improvement) in well-established fields with clear expertise boundaries and available theoretical validators, and smallest benefits (&lt;30%) in emerging interdisciplinary areas or domains without theoretical scorers.",
        "Discoverability (human likelihood of finding a hypothesis) decreases monotonically with increasing β, while theoretical plausibility decays more slowly, creating an optimal complementary range.",
        "The framework requires ~45% of properties to have available theoretical scorers for full validation; performance in domains without scorers relies solely on embedding-based plausibility proxies.",
        "Random walks with alpha-weighted sampling (alpha=1 recommended) over mixed hypergraphs effectively simulate chains of human inference through author-author, author-material, and material-property steps."
    ],
    "new_predictions_likely": [
        "AI systems that explicitly model human expertise networks will consistently outperform content-only systems by &gt;50% on discovery acceleration tasks across scientific domains with established research communities and available theoretical validators.",
        "The optimal parameter for complementary discovery will fall in the range 0.15-0.35 across diverse scientific fields, with variation correlating with field maturity, collaboration density, and availability of first-principles validation methods.",
        "Human-aware AI will show largest benefits (&gt;100% improvement) in fields like materials science, drug repurposing, and established chemistry domains, and smallest benefits (&lt;30%) in emerging interdisciplinary areas like synthetic biology or quantum computing applications.",
        "Combining human-aware graph metrics with theoretical plausibility scoring will identify 2-3x more validated complementary hypotheses than either approach alone, particularly in the β=0.2-0.3 range.",
        "In domains where theoretical scorers are available for &gt;60% of properties, human-aware AI will maintain high precision (&gt;30%) even at β=0.4, while domains with &lt;30% scorer coverage will show rapid precision decay beyond β=0.25.",
        "The correlation between prediction precision and entity frequency in literature will hold across domains, with r&gt;0.6 expected for most scientific fields with sufficient publication data."
    ],
    "new_predictions_unknown": [
        "Whether human-aware AI can adapt to rapidly changing research landscapes as new collaborations form and expertise evolves, or if models require retraining every 1-2 years to maintain performance.",
        "If there exist systematic 'blind spots' in human cognition that AI can reliably identify across multiple domains, or if human-inaccessible hypotheses are domain-specifically implausible.",
        "Whether human-aware AI can generalize across cultures and research systems with different collaboration patterns (e.g., Asian vs Western research networks, industry vs academic collaborations) without recalibration.",
        "If adversarial researchers could game human-aware AI systems by strategically forming collaborations to influence AI predictions, and whether such gaming would be detectable.",
        "Whether the optimal β range (0.2-0.3) is universal across all sciences or if it varies systematically by field characteristics (e.g., experimental cost, validation time, interdisciplinarity).",
        "If human-aware AI can identify breakthrough hypotheses that require paradigm shifts, or if it is inherently limited to incremental advances within existing frameworks.",
        "Whether combining human-aware AI with other AI approaches (e.g., causal reasoning, symbolic AI) would yield multiplicative or merely additive improvements in discovery acceleration."
    ],
    "negative_experiments": [
        "Finding that content-only AI performs as well as human-aware AI across multiple domains would invalidate the core premise of human-awareness value.",
        "Demonstrating that random parameter selection (random β) performs as well as optimized β=0.2-0.3 would question the existence of an optimal complementary range.",
        "Showing that shortest-path distance does not correlate with human discovery patterns (e.g., r&lt;0.2) would challenge the accessibility quantification method.",
        "Evidence that human-aware AI predictions are no more likely to be validated than random predictions from the same candidate pool would contradict the theory's utility.",
        "Finding that removing author nodes from hypergraphs does not significantly decrease performance (&lt;10% drop) would question the necessity of explicit human modeling.",
        "Demonstrating that theoretical plausibility scores do not correlate with eventual experimental validation would undermine the plausibility assessment component.",
        "Showing that the expectation gap is negative or near-zero for most properties would contradict the existence of a complementary discovery opportunity."
    ],
    "unaccounted_for": [
        {
            "text": "The theory does not address how to handle fields where collaboration patterns are weak or non-existent (e.g., theoretical mathematics, some humanities)",
            "uuids": []
        },
        {
            "text": "Mechanisms for incorporating non-publication-based expertise (industry knowledge, clinical practice, craft knowledge) are not specified",
            "uuids": []
        },
        {
            "text": "The theory does not explain how to balance human-awareness with other discovery objectives (experimental cost, ethical constraints, feasibility, time-to-validation)",
            "uuids": []
        },
        {
            "text": "Computational cost trade-offs between human-aware methods (250k random walks) and simpler approaches are not systematically analyzed",
            "uuids": [
                "e2654.0"
            ]
        },
        {
            "text": "The theory does not address how to handle temporal dynamics: how quickly do expertise networks change and how often must models be retrained",
            "uuids": []
        },
        {
            "text": "Integration strategies when multiple types of plausibility scorers (DFT, PPI, symmetry analysis) give conflicting assessments are not specified",
            "uuids": [
                "e2655.5"
            ]
        },
        {
            "text": "The theory does not explain how to handle cases where high-impact discoveries come from unexpected cross-domain connections not captured in co-authorship networks",
            "uuids": []
        }
    ],
    "conflicting_evidence": [
        {
            "text": "Some highly novel discoveries are made by individual researchers without extensive collaboration networks, suggesting human-awareness may not capture all discovery modes",
            "uuids": []
        },
        {
            "text": "Content-only methods can sometimes identify novel hypotheses that human-aware methods miss, particularly in highly interdisciplinary connections",
            "uuids": [
                "e2655.0"
            ]
        },
        {
            "text": "Author-less GraphSAGE variants still achieve reasonable performance (48-58% precision), suggesting human-awareness provides incremental rather than transformative improvement in some cases",
            "uuids": [
                "e2654.3"
            ]
        },
        {
            "text": "Theoretical scorers are available for only ~45% of properties, limiting the applicability of the full framework to less than half of potential discovery targets",
            "uuids": [
                "e2655.5"
            ]
        },
        {
            "text": "Performance is correlated with entity frequency in literature (r=0.74), suggesting the method may be biased toward well-studied entities and miss truly novel concepts",
            "uuids": [
                "e2654.0"
            ]
        },
        {
            "text": "GraphSAGE using word2vec features may limit exploration due to content-based constraints, suggesting tension between human-awareness and true novelty",
            "uuids": [
                "e2654.3"
            ]
        }
    ],
    "special_cases": [
        "In highly interdisciplinary fields, expertise boundaries are blurred and co-authorship networks may not accurately reflect cognitive accessibility, requiring alternative accessibility metrics.",
        "For emerging fields with sparse publication records (&lt;1000 papers), human-aware metrics may be unreliable due to insufficient data for stable random walk statistics and author disambiguation.",
        "In fields with strong geographic or institutional clustering (e.g., particle physics, space science), human-aware AI may need to account for non-cognitive barriers to collaboration such as access to facilities.",
        "For properties without available theoretical scorers (&gt;55% of cases in materials science), the framework must rely solely on embedding-based plausibility proxies, reducing validation confidence.",
        "In domains where most discoveries are made by small teams or individuals (e.g., mathematics), co-authorship-based accessibility may be less predictive than citation-based or concept-based metrics.",
        "When β &gt; 0.4, theoretical plausibility scores begin to decay rapidly, suggesting an upper bound on useful alienness beyond which hypotheses become scientifically implausible.",
        "In fields with rapid paradigm shifts or technological disruptions, historical co-authorship patterns may poorly predict future discovery patterns, requiring temporal weighting or recency bias.",
        "For drug repurposing and COVID-19 applications, the framework shows particularly strong performance (350-400% improvement), suggesting domain-specific factors that enhance human-aware AI effectiveness."
    ],
    "existing_theory": {
        "likely_classification": "new",
        "references": [
            "Rzhetsky et al. (2015) Choosing experiments to accelerate collective discovery [Related empirical work on scientific strategy and collaboration patterns, but does not formalize human-aware AI theory or provide algorithmic framework]",
            "Foster et al. (2015) Tradition and Innovation in Scientists' Research Strategies [Empirical study of human discovery patterns and cognitive constraints, but no AI system design or complementary discovery framework]",
            "Fortunato et al. (2018) Science of science [Broad review of science of science including collaboration networks, but does not address human-aware AI design or complementary hypothesis generation]",
            "Tshitoyan et al. (2019) Unsupervised word embeddings capture latent knowledge from materials science literature [Content-only materials discovery without human-awareness modeling, serves as baseline comparison]",
            "Swanson (1986) Undiscovered public knowledge [Foundational work on literature-based discovery, but predates modern AI and does not incorporate human accessibility modeling]",
            "Kitano (2016) Artificial Intelligence to Win the Nobel Prize and Beyond [Speculative vision of AI for scientific discovery, but does not provide concrete human-aware framework or validation]"
        ]
    },
    "theory_type_general_specific": "specific",
    "reflected_from_theory_index": 5,
    "type": "specific"
}</code></pre>
        </div>
    </div>
</body>
</html>