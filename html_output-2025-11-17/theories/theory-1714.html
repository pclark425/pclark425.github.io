<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Contextual Probability-Based Anomaly Detection Theory - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-1714</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-1714</p>
                <p><strong>Name:</strong> Contextual Probability-Based Anomaly Detection Theory</p>
                <p><strong>Type:</strong> general</p>
                <p><strong>Theory Query:</strong> Build a theory of how language models can be used for detecting anomalies in lists of data.</p>
                <p><strong>Description:</strong> This theory proposes that language models can be used for anomaly detection in lists by computing the contextual probability of each item given the rest of the list. Items with significantly lower conditional probability are flagged as anomalies. This approach leverages the LLM's ability to estimate the likelihood of tokens or phrases in context, providing a quantitative anomaly score.</p>
                <p><strong>Knowledge Cutoff Year:</strong> -1</p>
                <p><strong>Knowledge Cutoff Month:</strong> -1</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <h3>Statement 0: Conditional Probability Law (quantitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; language model &#8594; is_given &#8594; list of items<span style="color: #888888;">, and</span></div>
        <div>&#8226; item &#8594; is_member_of &#8594; list</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; language model &#8594; computes &#8594; P(item | rest of list)</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>LLMs can assign probabilities to tokens or phrases in context, as shown in masked language modeling and perplexity estimation. </li>
    <li>Low-probability items in context are often out-of-distribution or anomalous. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> closely-related-to-existing</p>
            <p><strong>Explanation:</strong> Conditional probability estimation is established, but its use for list anomaly detection is a novel application.</p>            <p><strong>What Already Exists:</strong> Conditional probability estimation is core to language modeling.</p>            <p><strong>What is Novel:</strong> Application to anomaly detection in arbitrary lists is a new extension.</p>
            <p><strong>References:</strong> <ul>
    <li>Devlin et al. (2018) BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding [Masked language modeling]</li>
    <li>Hendrycks et al. (2020) Pretrained Transformers Improve Out-of-Distribution Robustness [OOD detection via probability estimation]</li>
</ul>
            <h3>Statement 1: Anomaly Threshold Law (quantitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; item &#8594; has_conditional_probability &#8594; P<span style="color: #888888;">, and</span></div>
        <div>&#8226; P &#8594; is_much_lower_than &#8594; average P of other items in list</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; item &#8594; is_flagged_as &#8594; anomaly</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Thresholding on conditional probability is a standard method in anomaly detection and OOD detection. </li>
    <li>Empirical studies show that LLMs assign lower probabilities to out-of-context or anomalous items. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> closely-related-to-existing</p>
            <p><strong>Explanation:</strong> Thresholding is known, but its application to LLM-based list anomaly detection is novel.</p>            <p><strong>What Already Exists:</strong> Threshold-based anomaly detection using probability scores is established.</p>            <p><strong>What is Novel:</strong> Direct use of LLM conditional probabilities for list anomaly detection is a new application.</p>
            <p><strong>References:</strong> <ul>
    <li>Chandola et al. (2009) Anomaly Detection: A Survey [Thresholding in anomaly detection]</li>
    <li>Hendrycks et al. (2020) Pretrained Transformers Improve Out-of-Distribution Robustness [LLMs and OOD detection]</li>
</ul>
            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>If a list of common English words contains a rare or invented word, the LLM will assign it a low probability and flag it as anomalous.</li>
                <li>If a list of U.S. states contains a non-state, the LLM will assign it a lower probability in context.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>If all items in a list are rare or invented, the LLM's probability distribution may not distinguish anomalies.</li>
                <li>If the anomaly is a subtle contextual mismatch (e.g., a state from a different country in a list of U.S. states), the LLM's probability assignment may be ambiguous.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>If the LLM assigns high probability to clear anomalies, the theory is challenged.</li>
                <li>If the LLM's probability distribution does not correlate with human judgments of anomaly, the theory's assumptions are undermined.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>Lists with items that are all equally improbable or out-of-distribution may not yield meaningful anomaly scores. </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> closely-related-to-existing</p>
            <p><strong>Explanation:</strong> The theory extends established probability-based anomaly detection to LLMs in the context of lists.</p>
            <p><strong>References:</strong> <ul>
    <li>Devlin et al. (2018) BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding [Masked language modeling]</li>
    <li>Chandola et al. (2009) Anomaly Detection: A Survey [Thresholding in anomaly detection]</li>
    <li>Hendrycks et al. (2020) Pretrained Transformers Improve Out-of-Distribution Robustness [LLMs and OOD detection]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Contextual Probability-Based Anomaly Detection Theory",
    "theory_description": "This theory proposes that language models can be used for anomaly detection in lists by computing the contextual probability of each item given the rest of the list. Items with significantly lower conditional probability are flagged as anomalies. This approach leverages the LLM's ability to estimate the likelihood of tokens or phrases in context, providing a quantitative anomaly score.",
    "theory_statements": [
        {
            "law": {
                "law_name": "Conditional Probability Law",
                "if": [
                    {
                        "subject": "language model",
                        "relation": "is_given",
                        "object": "list of items"
                    },
                    {
                        "subject": "item",
                        "relation": "is_member_of",
                        "object": "list"
                    }
                ],
                "then": [
                    {
                        "subject": "language model",
                        "relation": "computes",
                        "object": "P(item | rest of list)"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "LLMs can assign probabilities to tokens or phrases in context, as shown in masked language modeling and perplexity estimation.",
                        "uuids": []
                    },
                    {
                        "text": "Low-probability items in context are often out-of-distribution or anomalous.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "quantitative",
                "existing_law": {
                    "what_already_exists": "Conditional probability estimation is core to language modeling.",
                    "what_is_novel": "Application to anomaly detection in arbitrary lists is a new extension.",
                    "classification_explanation": "Conditional probability estimation is established, but its use for list anomaly detection is a novel application.",
                    "likely_classification": "closely-related-to-existing",
                    "references": [
                        "Devlin et al. (2018) BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding [Masked language modeling]",
                        "Hendrycks et al. (2020) Pretrained Transformers Improve Out-of-Distribution Robustness [OOD detection via probability estimation]"
                    ]
                }
            }
        },
        {
            "law": {
                "law_name": "Anomaly Threshold Law",
                "if": [
                    {
                        "subject": "item",
                        "relation": "has_conditional_probability",
                        "object": "P"
                    },
                    {
                        "subject": "P",
                        "relation": "is_much_lower_than",
                        "object": "average P of other items in list"
                    }
                ],
                "then": [
                    {
                        "subject": "item",
                        "relation": "is_flagged_as",
                        "object": "anomaly"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Thresholding on conditional probability is a standard method in anomaly detection and OOD detection.",
                        "uuids": []
                    },
                    {
                        "text": "Empirical studies show that LLMs assign lower probabilities to out-of-context or anomalous items.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "quantitative",
                "existing_law": {
                    "what_already_exists": "Threshold-based anomaly detection using probability scores is established.",
                    "what_is_novel": "Direct use of LLM conditional probabilities for list anomaly detection is a new application.",
                    "classification_explanation": "Thresholding is known, but its application to LLM-based list anomaly detection is novel.",
                    "likely_classification": "closely-related-to-existing",
                    "references": [
                        "Chandola et al. (2009) Anomaly Detection: A Survey [Thresholding in anomaly detection]",
                        "Hendrycks et al. (2020) Pretrained Transformers Improve Out-of-Distribution Robustness [LLMs and OOD detection]"
                    ]
                }
            }
        }
    ],
    "new_predictions_likely": [
        "If a list of common English words contains a rare or invented word, the LLM will assign it a low probability and flag it as anomalous.",
        "If a list of U.S. states contains a non-state, the LLM will assign it a lower probability in context."
    ],
    "new_predictions_unknown": [
        "If all items in a list are rare or invented, the LLM's probability distribution may not distinguish anomalies.",
        "If the anomaly is a subtle contextual mismatch (e.g., a state from a different country in a list of U.S. states), the LLM's probability assignment may be ambiguous."
    ],
    "negative_experiments": [
        "If the LLM assigns high probability to clear anomalies, the theory is challenged.",
        "If the LLM's probability distribution does not correlate with human judgments of anomaly, the theory's assumptions are undermined."
    ],
    "unaccounted_for": [
        {
            "text": "Lists with items that are all equally improbable or out-of-distribution may not yield meaningful anomaly scores.",
            "uuids": []
        }
    ],
    "conflicting_evidence": [
        {
            "text": "LLMs may assign high probability to plausible-sounding but incorrect or fabricated items, especially in adversarial settings.",
            "uuids": []
        }
    ],
    "special_cases": [
        "Lists with multiple low-probability items may result in ambiguous anomaly detection.",
        "If the list context is too short, probability estimation may be unreliable."
    ],
    "existing_theory": {
        "what_already_exists": "Conditional probability and thresholding are established in anomaly detection and language modeling.",
        "what_is_novel": "Direct application of LLM conditional probabilities to list anomaly detection is new.",
        "classification_explanation": "The theory extends established probability-based anomaly detection to LLMs in the context of lists.",
        "likely_classification": "closely-related-to-existing",
        "references": [
            "Devlin et al. (2018) BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding [Masked language modeling]",
            "Chandola et al. (2009) Anomaly Detection: A Survey [Thresholding in anomaly detection]",
            "Hendrycks et al. (2020) Pretrained Transformers Improve Out-of-Distribution Robustness [LLMs and OOD detection]"
        ]
    },
    "reflected_from_theory_index": 2,
    "type": "general",
    "version": "built-theory-from-results-single-theory-reflection2-nov14-2025-LLM-BASELINE-no-evidence-without-matched-control-theory-name",
    "theory_query": "Build a theory of how language models can be used for detecting anomalies in lists of data.",
    "original_theory_id": "theory-641",
    "original_theory_name": "Hybrid and Retrieval-Augmented LLM Anomaly Detection Theory",
    "provide_matched_control_thery_name": false,
    "matched_control_theory_name": null,
    "model_str": "openai/gpt-4.1-2025-04-14"
}</code></pre>
        </div>
    </div>
</body>
</html>