<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Active Inference and Expected Free Energy Theory for Hybrid Systems - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-87</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-87</p>
                <p><strong>Name:</strong> Active Inference and Expected Free Energy Theory for Hybrid Systems</p>
                <p><strong>Type:</strong> specific</p>
                <p><strong>Theory Query:</strong> Build a theory about hybrid declarative-imperative reasoning systems and their emergent properties, based on the following results.</p>
                <p><strong>Description:</strong> Hybrid systems that combine explicit probabilistic generative models (declarative) with amortized neural inference (imperative) and use expected free energy minimization for action selection exhibit emergent active exploration behavior that balances epistemic (information-seeking) and pragmatic (goal-directed) drives. This emerges from the mathematical decomposition of expected free energy G into preference satisfaction and expected information gain terms, enabling systems to actively reduce uncertainty when goals are ambiguous and exploit known information when goals are clear. The theory posits that this framework provides a principled, unified objective connecting perception (variational inference), learning (parameter updates), and action (policy selection) through the minimization of variational free energy and expected free energy.</p>
                <p><strong>Knowledge Cutoff Year:</strong> 2024</p>
                <p><strong>Knowledge Cutoff Month:</strong> 12</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <ol>
                <li>Systems that minimize expected free energy G (decomposed into preference satisfaction and expected information gain) exhibit emergent active exploration behavior without explicit exploration heuristics.</li>
                <li>The balance between epistemic (information-seeking) and pragmatic (goal-directed) behavior emerges naturally from the relative magnitudes of uncertainty and goal-directedness in the expected free energy decomposition.</li>
                <li>Combining explicit probabilistic generative models with amortized neural inference enables efficient active inference at scale while maintaining interpretability through inspectable belief distributions.</li>
                <li>Particle filter representations of beliefs over continuous variables enable non-parametric uncertainty quantification that drives information-seeking behavior through the expected information gain term.</li>
                <li>The variational free energy principle provides a unified objective that connects perception (variational inference), learning (parameter updates), and action (expected free energy minimization) in hybrid systems.</li>
                <li>Neural training losses (reconstruction MSE, KL regularizers, BCE for identity) can be derived as terms in variational free energy, enabling principled end-to-end training of hybrid active inference systems.</li>
                <li>Monte Carlo importance sampling over candidate actions scored by expected free energy provides a practical implementation of active inference for continuous action spaces.</li>
                <li>Explicit factorization of generative models into interpretable latent variables (identity, pose, position) enables targeted information-seeking actions that reduce uncertainty over specific factors.</li>
            </ol>
            <h3>Supporting Evidence</h3>
<ol>
    <li>SceneCCN + Active Inference achieves 69.0% success rate on 500-scene active search benchmark, substantially outperforming PoseCNN baseline (16.2%) through expected free energy-driven action selection <a href="../results/extraction-result-614.html#e614.0" class="evidence-link">[e614.0]</a> <a href="../results/extraction-result-614.html#e614.1" class="evidence-link">[e614.1]</a> </li>
    <li>SceneCCN demonstrates balanced epistemic-foraging and goal-directed behavior: actively explores when goal object is not seen and exploits goal-directed moves when confident, emerging from expected free energy decomposition <a href="../results/extraction-result-614.html#e614.0" class="evidence-link">[e614.0]</a> </li>
    <li>SceneCCN shows robustness to occlusions because the info-gain term causes active search rather than premature failure, with mean azimuth error 0.569±0.034 rad compared to PoseCNN's 1.277±0.042 rad <a href="../results/extraction-result-614.html#e614.0" class="evidence-link">[e614.0]</a> <a href="../results/extraction-result-614.html#e614.1" class="evidence-link">[e614.1]</a> </li>
    <li>PoseCNN + Infogain baseline (28.4% success) shows improvement over pure PoseCNN (16.2%) by adding information-gain-driven exploration, demonstrating that epistemic drive alone provides benefits <a href="../results/extraction-result-614.html#e614.1" class="evidence-link">[e614.1]</a> </li>
    <li>Active Inference with Amortized Inference paradigm yields principled trade-off between exploration and exploitation via expected free energy decomposition into preference term and expected information gain <a href="../results/extraction-result-614.html#e614.2" class="evidence-link">[e614.2]</a> </li>
    <li>SceneCCN's particle filter beliefs over object translations and expected free energy components (preference vs info-gain) provide interpretable policy objectives and belief dynamics <a href="../results/extraction-result-614.html#e614.0" class="evidence-link">[e614.0]</a> <a href="../results/extraction-result-614.html#e614.2" class="evidence-link">[e614.2]</a> </li>
    <li>Variational free energy principle provides theoretical grounding: explicit mapping of neural training losses (MSE, KL, BCE) to variational free energy terms shows how declarative probabilistic structure combined with neural amortized inference yields emergent active perception <a href="../results/extraction-result-614.html#e614.0" class="evidence-link">[e614.0]</a> <a href="../results/extraction-result-614.html#e614.2" class="evidence-link">[e614.2]</a> </li>
    <li>Monte Carlo sampling of candidate viewpoints scored by expected free energy G integrates neural-inferred factors (pose, identity, scale) and particle-filter beliefs, enabling practical action selection <a href="../results/extraction-result-614.html#e614.0" class="evidence-link">[e614.0]</a> </li>
    <li>SceneCCN's explicit probabilistic generative model factorizes scene into K object-entities with identity, allocentric translation, and object-centric pose, providing structured declarative representation <a href="../results/extraction-result-614.html#e614.0" class="evidence-link">[e614.0]</a> </li>
    <li>Amortized neural networks (CCNs for pose, fully-convolutional mask predictor, spatial-transformer crop extractor) implement likelihoods and posteriors, trained with losses corresponding to free-energy terms <a href="../results/extraction-result-614.html#e614.0" class="evidence-link">[e614.0]</a> <a href="../results/extraction-result-614.html#e614.2" class="evidence-link">[e614.2]</a> </li>
    <li>Particle filter provides non-parametric posterior for object positions that feeds into expected free energy computations, enabling uncertainty-driven exploration <a href="../results/extraction-result-614.html#e614.0" class="evidence-link">[e614.0]</a> <a href="../results/extraction-result-614.html#e614.2" class="evidence-link">[e614.2]</a> </li>
    <li>System demonstrates improved sample-efficiency for active search tasks compared to purely supervised pose regression or model-based RL baselines <a href="../results/extraction-result-614.html#e614.0" class="evidence-link">[e614.0]</a> </li>
    <li>On single LEXA environment, SceneCCN + AIF achieves 62% success rate with Δφ=1.050(±0.470), Δθ=0.187(±0.083), Δr=0.076(±0.039), demonstrating consistent performance <a href="../results/extraction-result-614.html#e614.0" class="evidence-link">[e614.0]</a> </li>
    <li>Loss-level correspondence between neural training objectives and variational free energy terms enables principled joint training of perception and action modules <a href="../results/extraction-result-614.html#e614.2" class="evidence-link">[e614.2]</a> </li>
</ol>            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>Hybrid active inference systems will outperform pure reinforcement learning on tasks requiring exploration under uncertainty with sparse rewards, particularly when the reward structure is ambiguous.</li>
                <li>Adding expected free energy-based action selection to existing hybrid perception systems will improve performance on active vision and robotics tasks by 20-50% over baseline exploration strategies.</li>
                <li>Systems with explicit uncertainty representations (particle filters, Bayesian posteriors) will show more efficient exploration than systems with implicit uncertainty, requiring fewer actions to achieve equivalent task performance.</li>
                <li>Active inference systems will show better sample efficiency on tasks requiring information gathering compared to reward-maximizing RL agents, particularly in the first 100-1000 episodes of training.</li>
                <li>The epistemic-pragmatic balance in active inference systems will automatically adapt to task difficulty: high epistemic drive when uncertainty is high, high pragmatic drive when goals are clear.</li>
                <li>Hybrid active inference systems will show graceful degradation under partial observability, maintaining reasonable performance even when key state variables are occluded.</li>
                <li>Active inference with particle filters will outperform parametric uncertainty representations (e.g., Gaussian posteriors) on tasks with multimodal or non-Gaussian uncertainty distributions.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>Whether active inference principles can scale to very high-dimensional action spaces (>100 dimensions) and complex environments without prohibitive computational cost from Monte Carlo sampling.</li>
                <li>Whether the expected free energy framework can be extended to multi-agent settings with emergent coordination behavior, where agents must model each other's beliefs and goals.</li>
                <li>Whether active inference can be combined with large-scale neural policies (e.g., LLMs or large vision transformers) while maintaining theoretical guarantees and computational tractability.</li>
                <li>Whether the epistemic-pragmatic balance can be automatically tuned for different task types without manual parameter adjustment of preference distributions and prior beliefs.</li>
                <li>Whether active inference systems can learn hierarchical generative models online during deployment, adapting to non-stationary environments without catastrophic forgetting.</li>
                <li>Whether the particle filter approach can be replaced with more scalable approximate inference methods (e.g., variational inference, normalizing flows) without losing the benefits of explicit uncertainty quantification.</li>
                <li>Whether active inference can handle tasks requiring long-horizon planning (>50 steps) where the computational cost of expected free energy calculation over future trajectories becomes prohibitive.</li>
                <li>Whether the framework can be extended to handle discrete and continuous action spaces simultaneously in a unified manner.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>Finding that simple exploration heuristics (e.g., epsilon-greedy, UCB, or random exploration) achieve equivalent performance to expected free energy minimization would challenge the theoretical advantage of the active inference framework.</li>
                <li>Demonstrating that pure neural policies can learn equivalent active exploration behavior without explicit uncertainty quantification or generative models would question the necessity of the probabilistic framework.</li>
                <li>Showing that the computational cost of expected free energy calculation (Monte Carlo sampling, particle filter updates) outweighs performance benefits in practical applications would limit applicability.</li>
                <li>Finding that the epistemic-pragmatic decomposition does not generalize to tasks outside active vision (e.g., manipulation, navigation in complex environments) would challenge the generality of the theory.</li>
                <li>Demonstrating that model-free RL with intrinsic motivation (e.g., curiosity-driven exploration) achieves better sample efficiency than active inference would question the value of explicit generative models.</li>
                <li>Finding that the particle filter representation is unnecessary and simpler uncertainty representations (e.g., single Gaussian) achieve equivalent performance would challenge the need for non-parametric beliefs.</li>
                <li>Showing that the loss-level correspondence between neural objectives and variational free energy terms does not improve training compared to standard supervised learning would question the theoretical framework's practical value.</li>
                <li>Demonstrating that systems without explicit preference distributions can learn equivalent goal-directed behavior through reward shaping would challenge the necessity of the pragmatic term in expected free energy.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>How to scale active inference to very large state and action spaces efficiently, particularly when Monte Carlo sampling becomes computationally prohibitive <a href="../results/extraction-result-614.html#e614.0" class="evidence-link">[e614.0]</a> <a href="../results/extraction-result-614.html#e614.2" class="evidence-link">[e614.2]</a> </li>
    <li>How to automatically set preference distributions and prior beliefs for new tasks without manual engineering or domain expertise <a href="../results/extraction-result-614.html#e614.0" class="evidence-link">[e614.0]</a> </li>
    <li>The relationship between active inference and other exploration strategies in RL (e.g., curiosity-driven exploration, empowerment, information gain in Bayesian RL) <a href="../results/extraction-result-614.html#e614.1" class="evidence-link">[e614.1]</a> </li>
    <li>How to handle non-stationary environments where generative models must adapt online without catastrophic forgetting or requiring full retraining <a href="../results/extraction-result-614.html#e614.0" class="evidence-link">[e614.0]</a> </li>
    <li>How to extend the framework to multi-agent settings where agents must model each other's beliefs and coordinate exploration <a href="../results/extraction-result-614.html#e614.0" class="evidence-link">[e614.0]</a> </li>
    <li>How to handle tasks requiring long-horizon planning where computing expected free energy over extended trajectories becomes intractable <a href="../results/extraction-result-614.html#e614.0" class="evidence-link">[e614.0]</a> </li>
    <li>How to integrate active inference with modern large-scale neural architectures (transformers, large vision models) while maintaining theoretical guarantees <a href="../results/extraction-result-614.html#e614.0" class="evidence-link">[e614.0]</a> </li>
    <li>The trade-offs between different approximate inference methods (particle filters vs. variational inference vs. normalizing flows) for maintaining uncertainty representations <a href="../results/extraction-result-614.html#e614.0" class="evidence-link">[e614.0]</a> <a href="../results/extraction-result-614.html#e614.2" class="evidence-link">[e614.2]</a> </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> closely-related-to-existing</p>
            <p><strong>Explanation:</strong> No explanation provided.</p>
            <p><strong>References:</strong> <ul>
    <li>Friston et al. (2015) Active inference and epistemic value [Theoretical foundation for active inference and expected free energy decomposition]</li>
    <li>Friston et al. (2017) Active Inference: A Process Theory [General active inference framework and free energy principle]</li>
    <li>Parr & Friston (2019) Generalised free energy and active inference [Mathematical formulation of expected free energy and its decomposition]</li>
    <li>Sajid et al. (2021) Active Inference: Demystified and Compared [Comparison of active inference with other frameworks including RL]</li>
    <li>Millidge et al. (2021) Whence the Expected Free Energy? [Analysis of expected free energy and its relationship to other objectives]</li>
    <li>Da Costa et al. (2020) Active inference on discrete state-spaces: A synthesis [Discrete-state formulation of active inference]</li>
    <li>Tschantz et al. (2020) Reinforcement Learning through Active Inference [Connections between active inference and RL]</li>
    <li>Ueltzhöffer (2018) Deep Active Inference [Neural network implementations of active inference]</li>
    <li>Çatal et al. (2021) Learning Perception and Planning with Deep Active Inference [Deep learning approaches to active inference with learned generative models]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Active Inference and Expected Free Energy Theory for Hybrid Systems",
    "theory_description": "Hybrid systems that combine explicit probabilistic generative models (declarative) with amortized neural inference (imperative) and use expected free energy minimization for action selection exhibit emergent active exploration behavior that balances epistemic (information-seeking) and pragmatic (goal-directed) drives. This emerges from the mathematical decomposition of expected free energy G into preference satisfaction and expected information gain terms, enabling systems to actively reduce uncertainty when goals are ambiguous and exploit known information when goals are clear. The theory posits that this framework provides a principled, unified objective connecting perception (variational inference), learning (parameter updates), and action (policy selection) through the minimization of variational free energy and expected free energy.",
    "supporting_evidence": [
        {
            "text": "SceneCCN + Active Inference achieves 69.0% success rate on 500-scene active search benchmark, substantially outperforming PoseCNN baseline (16.2%) through expected free energy-driven action selection",
            "uuids": [
                "e614.0",
                "e614.1"
            ]
        },
        {
            "text": "SceneCCN demonstrates balanced epistemic-foraging and goal-directed behavior: actively explores when goal object is not seen and exploits goal-directed moves when confident, emerging from expected free energy decomposition",
            "uuids": [
                "e614.0"
            ]
        },
        {
            "text": "SceneCCN shows robustness to occlusions because the info-gain term causes active search rather than premature failure, with mean azimuth error 0.569±0.034 rad compared to PoseCNN's 1.277±0.042 rad",
            "uuids": [
                "e614.0",
                "e614.1"
            ]
        },
        {
            "text": "PoseCNN + Infogain baseline (28.4% success) shows improvement over pure PoseCNN (16.2%) by adding information-gain-driven exploration, demonstrating that epistemic drive alone provides benefits",
            "uuids": [
                "e614.1"
            ]
        },
        {
            "text": "Active Inference with Amortized Inference paradigm yields principled trade-off between exploration and exploitation via expected free energy decomposition into preference term and expected information gain",
            "uuids": [
                "e614.2"
            ]
        },
        {
            "text": "SceneCCN's particle filter beliefs over object translations and expected free energy components (preference vs info-gain) provide interpretable policy objectives and belief dynamics",
            "uuids": [
                "e614.0",
                "e614.2"
            ]
        },
        {
            "text": "Variational free energy principle provides theoretical grounding: explicit mapping of neural training losses (MSE, KL, BCE) to variational free energy terms shows how declarative probabilistic structure combined with neural amortized inference yields emergent active perception",
            "uuids": [
                "e614.0",
                "e614.2"
            ]
        },
        {
            "text": "Monte Carlo sampling of candidate viewpoints scored by expected free energy G integrates neural-inferred factors (pose, identity, scale) and particle-filter beliefs, enabling practical action selection",
            "uuids": [
                "e614.0"
            ]
        },
        {
            "text": "SceneCCN's explicit probabilistic generative model factorizes scene into K object-entities with identity, allocentric translation, and object-centric pose, providing structured declarative representation",
            "uuids": [
                "e614.0"
            ]
        },
        {
            "text": "Amortized neural networks (CCNs for pose, fully-convolutional mask predictor, spatial-transformer crop extractor) implement likelihoods and posteriors, trained with losses corresponding to free-energy terms",
            "uuids": [
                "e614.0",
                "e614.2"
            ]
        },
        {
            "text": "Particle filter provides non-parametric posterior for object positions that feeds into expected free energy computations, enabling uncertainty-driven exploration",
            "uuids": [
                "e614.0",
                "e614.2"
            ]
        },
        {
            "text": "System demonstrates improved sample-efficiency for active search tasks compared to purely supervised pose regression or model-based RL baselines",
            "uuids": [
                "e614.0"
            ]
        },
        {
            "text": "On single LEXA environment, SceneCCN + AIF achieves 62% success rate with Δφ=1.050(±0.470), Δθ=0.187(±0.083), Δr=0.076(±0.039), demonstrating consistent performance",
            "uuids": [
                "e614.0"
            ]
        },
        {
            "text": "Loss-level correspondence between neural training objectives and variational free energy terms enables principled joint training of perception and action modules",
            "uuids": [
                "e614.2"
            ]
        }
    ],
    "theory_statements": [
        "Systems that minimize expected free energy G (decomposed into preference satisfaction and expected information gain) exhibit emergent active exploration behavior without explicit exploration heuristics.",
        "The balance between epistemic (information-seeking) and pragmatic (goal-directed) behavior emerges naturally from the relative magnitudes of uncertainty and goal-directedness in the expected free energy decomposition.",
        "Combining explicit probabilistic generative models with amortized neural inference enables efficient active inference at scale while maintaining interpretability through inspectable belief distributions.",
        "Particle filter representations of beliefs over continuous variables enable non-parametric uncertainty quantification that drives information-seeking behavior through the expected information gain term.",
        "The variational free energy principle provides a unified objective that connects perception (variational inference), learning (parameter updates), and action (expected free energy minimization) in hybrid systems.",
        "Neural training losses (reconstruction MSE, KL regularizers, BCE for identity) can be derived as terms in variational free energy, enabling principled end-to-end training of hybrid active inference systems.",
        "Monte Carlo importance sampling over candidate actions scored by expected free energy provides a practical implementation of active inference for continuous action spaces.",
        "Explicit factorization of generative models into interpretable latent variables (identity, pose, position) enables targeted information-seeking actions that reduce uncertainty over specific factors."
    ],
    "new_predictions_likely": [
        "Hybrid active inference systems will outperform pure reinforcement learning on tasks requiring exploration under uncertainty with sparse rewards, particularly when the reward structure is ambiguous.",
        "Adding expected free energy-based action selection to existing hybrid perception systems will improve performance on active vision and robotics tasks by 20-50% over baseline exploration strategies.",
        "Systems with explicit uncertainty representations (particle filters, Bayesian posteriors) will show more efficient exploration than systems with implicit uncertainty, requiring fewer actions to achieve equivalent task performance.",
        "Active inference systems will show better sample efficiency on tasks requiring information gathering compared to reward-maximizing RL agents, particularly in the first 100-1000 episodes of training.",
        "The epistemic-pragmatic balance in active inference systems will automatically adapt to task difficulty: high epistemic drive when uncertainty is high, high pragmatic drive when goals are clear.",
        "Hybrid active inference systems will show graceful degradation under partial observability, maintaining reasonable performance even when key state variables are occluded.",
        "Active inference with particle filters will outperform parametric uncertainty representations (e.g., Gaussian posteriors) on tasks with multimodal or non-Gaussian uncertainty distributions."
    ],
    "new_predictions_unknown": [
        "Whether active inference principles can scale to very high-dimensional action spaces (&gt;100 dimensions) and complex environments without prohibitive computational cost from Monte Carlo sampling.",
        "Whether the expected free energy framework can be extended to multi-agent settings with emergent coordination behavior, where agents must model each other's beliefs and goals.",
        "Whether active inference can be combined with large-scale neural policies (e.g., LLMs or large vision transformers) while maintaining theoretical guarantees and computational tractability.",
        "Whether the epistemic-pragmatic balance can be automatically tuned for different task types without manual parameter adjustment of preference distributions and prior beliefs.",
        "Whether active inference systems can learn hierarchical generative models online during deployment, adapting to non-stationary environments without catastrophic forgetting.",
        "Whether the particle filter approach can be replaced with more scalable approximate inference methods (e.g., variational inference, normalizing flows) without losing the benefits of explicit uncertainty quantification.",
        "Whether active inference can handle tasks requiring long-horizon planning (&gt;50 steps) where the computational cost of expected free energy calculation over future trajectories becomes prohibitive.",
        "Whether the framework can be extended to handle discrete and continuous action spaces simultaneously in a unified manner."
    ],
    "negative_experiments": [
        "Finding that simple exploration heuristics (e.g., epsilon-greedy, UCB, or random exploration) achieve equivalent performance to expected free energy minimization would challenge the theoretical advantage of the active inference framework.",
        "Demonstrating that pure neural policies can learn equivalent active exploration behavior without explicit uncertainty quantification or generative models would question the necessity of the probabilistic framework.",
        "Showing that the computational cost of expected free energy calculation (Monte Carlo sampling, particle filter updates) outweighs performance benefits in practical applications would limit applicability.",
        "Finding that the epistemic-pragmatic decomposition does not generalize to tasks outside active vision (e.g., manipulation, navigation in complex environments) would challenge the generality of the theory.",
        "Demonstrating that model-free RL with intrinsic motivation (e.g., curiosity-driven exploration) achieves better sample efficiency than active inference would question the value of explicit generative models.",
        "Finding that the particle filter representation is unnecessary and simpler uncertainty representations (e.g., single Gaussian) achieve equivalent performance would challenge the need for non-parametric beliefs.",
        "Showing that the loss-level correspondence between neural objectives and variational free energy terms does not improve training compared to standard supervised learning would question the theoretical framework's practical value.",
        "Demonstrating that systems without explicit preference distributions can learn equivalent goal-directed behavior through reward shaping would challenge the necessity of the pragmatic term in expected free energy."
    ],
    "unaccounted_for": [
        {
            "text": "How to scale active inference to very large state and action spaces efficiently, particularly when Monte Carlo sampling becomes computationally prohibitive",
            "uuids": [
                "e614.0",
                "e614.2"
            ]
        },
        {
            "text": "How to automatically set preference distributions and prior beliefs for new tasks without manual engineering or domain expertise",
            "uuids": [
                "e614.0"
            ]
        },
        {
            "text": "The relationship between active inference and other exploration strategies in RL (e.g., curiosity-driven exploration, empowerment, information gain in Bayesian RL)",
            "uuids": [
                "e614.1"
            ]
        },
        {
            "text": "How to handle non-stationary environments where generative models must adapt online without catastrophic forgetting or requiring full retraining",
            "uuids": [
                "e614.0"
            ]
        },
        {
            "text": "How to extend the framework to multi-agent settings where agents must model each other's beliefs and coordinate exploration",
            "uuids": [
                "e614.0"
            ]
        },
        {
            "text": "How to handle tasks requiring long-horizon planning where computing expected free energy over extended trajectories becomes intractable",
            "uuids": [
                "e614.0"
            ]
        },
        {
            "text": "How to integrate active inference with modern large-scale neural architectures (transformers, large vision models) while maintaining theoretical guarantees",
            "uuids": [
                "e614.0"
            ]
        },
        {
            "text": "The trade-offs between different approximate inference methods (particle filters vs. variational inference vs. normalizing flows) for maintaining uncertainty representations",
            "uuids": [
                "e614.0",
                "e614.2"
            ]
        }
    ],
    "conflicting_evidence": [
        {
            "text": "PoseCNN + Infogain achieves only 28.4% success despite information-gain term, compared to SceneCCN's 69.0%, suggesting that epistemic drive alone is insufficient and generative model quality is equally or more important",
            "uuids": [
                "e614.1",
                "e614.0"
            ]
        },
        {
            "text": "SceneCCN requires one CCN per object category limiting generalization to novel categories, suggesting active inference alone is insufficient without good perception and that per-category training is a significant limitation",
            "uuids": [
                "e614.0"
            ]
        },
        {
            "text": "SceneCCN's integration is modular rather than end-to-end, with particle filter and neural modules trained separately, suggesting that joint optimization across all components may not be necessary or practical",
            "uuids": [
                "e614.0"
            ]
        },
        {
            "text": "Specific failure on tomato soup can attributed to smaller rendering scale and weaker CCN accuracy indicates that perception quality bottlenecks can dominate over action selection quality",
            "uuids": [
                "e614.0"
            ]
        },
        {
            "text": "System considers only static environments (no object dynamics beyond learned pose transitions), limiting applicability to dynamic real-world scenarios where active inference should theoretically excel",
            "uuids": [
                "e614.0"
            ]
        },
        {
            "text": "PoseCNN baseline uses depth input while SceneCCN does not, making direct comparison difficult and suggesting that sensor modality choices may confound active inference benefits",
            "uuids": [
                "e614.1"
            ]
        }
    ],
    "special_cases": [
        "When goals are fully specified and observable with low uncertainty, the epistemic term becomes negligible and behavior becomes purely goal-directed (pragmatic term dominates).",
        "When uncertainty is very high and goals are ambiguous, the epistemic term dominates and behavior becomes purely exploratory (information-seeking).",
        "For tasks with deterministic dynamics and full observability, particle filter representations may be unnecessary and simpler uncertainty representations (single Gaussian) may suffice.",
        "When computational resources are severely limited, approximate expected free energy calculations (e.g., single-sample Monte Carlo, greedy action selection) may be necessary, potentially degrading performance.",
        "For tasks with unimodal, Gaussian uncertainty distributions, parametric representations may be sufficient and more efficient than particle filters.",
        "When the generative model is highly accurate and well-calibrated, the system can achieve high performance with fewer particles or simpler inference methods.",
        "For tasks requiring only short-horizon planning (1-5 steps), the computational cost of expected free energy calculation is minimal and the framework is most practical.",
        "When object categories are known and fixed, per-category neural modules (CCNs) can be pre-trained, but this limits zero-shot generalization to novel categories.",
        "In static environments with no object dynamics, the framework simplifies as temporal prediction models are unnecessary.",
        "When preference distributions are well-specified and aligned with task goals, the pragmatic term provides strong goal-directed behavior, but misspecified preferences can lead to suboptimal exploration."
    ],
    "existing_theory": {
        "likely_classification": "closely-related-to-existing",
        "references": [
            "Friston et al. (2015) Active inference and epistemic value [Theoretical foundation for active inference and expected free energy decomposition]",
            "Friston et al. (2017) Active Inference: A Process Theory [General active inference framework and free energy principle]",
            "Parr & Friston (2019) Generalised free energy and active inference [Mathematical formulation of expected free energy and its decomposition]",
            "Sajid et al. (2021) Active Inference: Demystified and Compared [Comparison of active inference with other frameworks including RL]",
            "Millidge et al. (2021) Whence the Expected Free Energy? [Analysis of expected free energy and its relationship to other objectives]",
            "Da Costa et al. (2020) Active inference on discrete state-spaces: A synthesis [Discrete-state formulation of active inference]",
            "Tschantz et al. (2020) Reinforcement Learning through Active Inference [Connections between active inference and RL]",
            "Ueltzhöffer (2018) Deep Active Inference [Neural network implementations of active inference]",
            "Çatal et al. (2021) Learning Perception and Planning with Deep Active Inference [Deep learning approaches to active inference with learned generative models]"
        ]
    },
    "theory_type_general_specific": "specific",
    "reflected_from_theory_index": 4,
    "type": "specific"
}</code></pre>
        </div>
    </div>
</body>
</html>