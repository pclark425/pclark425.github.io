<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Hierarchical Spatial Reasoning via Compositional Inductive Biases in LLMs - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-1037</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-1037</p>
                <p><strong>Name:</strong> Hierarchical Spatial Reasoning via Compositional Inductive Biases in LLMs</p>
                <p><strong>Type:</strong> general</p>
                <p><strong>Theory Query:</strong> Build a theory of how language models solve puzzle games involving spatial knowledge, like Sudoku.</p>
                <p><strong>Description:</strong> This theory proposes that LLMs solve spatial puzzles like Sudoku by leveraging hierarchical and compositional inductive biases, enabling them to decompose complex puzzles into subproblems, reason about local and global constraints, and recursively integrate partial solutions. The model's architecture and training encourage the emergence of multi-level spatial reasoning, supporting both local cell-level and global grid-level inference.</p>
                <p><strong>Knowledge Cutoff Year:</strong> -1</p>
                <p><strong>Knowledge Cutoff Month:</strong> -1</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <h3>Statement 0: Hierarchical Decomposition of Spatial Puzzles (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; language model &#8594; is presented with &#8594; complex spatial puzzle<span style="color: #888888;">, and</span></div>
        <div>&#8226; language model &#8594; has &#8594; compositional inductive biases</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; language model &#8594; decomposes &#8594; puzzle into hierarchical subproblems<span style="color: #888888;">, and</span></div>
        <div>&#8226; language model &#8594; solves &#8594; subproblems recursively</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>LLMs often solve Sudoku by filling in certain rows, columns, or blocks before integrating the full solution. </li>
    <li>Compositional reasoning is observed in LLMs for multi-step tasks and nested logic. </li>
    <li>Hierarchical attention in transformers supports multi-level reasoning. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> This law extends compositional reasoning to the specific context of spatial puzzle solving in LLMs.</p>            <p><strong>What Already Exists:</strong> Compositional and hierarchical reasoning in neural networks is established.</p>            <p><strong>What is Novel:</strong> The application of these biases to spatial puzzle decomposition in LLMs is new.</p>
            <p><strong>References:</strong> <ul>
    <li>Lake & Baroni (2018) Generalization without Systematicity: Compositional Skills in Sequence-to-Sequence Recurrent Networks [Compositional reasoning]</li>
    <li>Vaswani et al. (2017) Attention is All You Need [Hierarchical attention in transformers]</li>
</ul>
            <h3>Statement 1: Recursive Integration of Local and Global Constraints (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; language model &#8594; has &#8594; partial solutions to subproblems<span style="color: #888888;">, and</span></div>
        <div>&#8226; puzzle &#8594; has &#8594; local and global constraints</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; language model &#8594; recursively integrates &#8594; local and global constraint information<span style="color: #888888;">, and</span></div>
        <div>&#8226; language model &#8594; updates &#8594; solution candidates based on integrated constraints</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>LLMs can revise earlier cell assignments in Sudoku as new constraints are integrated. </li>
    <li>Transformer models can propagate information globally via attention, supporting recursive updates. </li>
    <li>LLMs' performance improves when allowed to iteratively refine solutions. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> This law synthesizes recursive reasoning and constraint integration in the context of LLMs and spatial puzzles.</p>            <p><strong>What Already Exists:</strong> Recursive and iterative reasoning in neural networks is known.</p>            <p><strong>What is Novel:</strong> The explicit recursive integration of local and global constraints in LLM spatial puzzle solving is new.</p>
            <p><strong>References:</strong> <ul>
    <li>Graves et al. (2016) Hybrid computing using a neural network with dynamic external memory [Iterative and recursive reasoning]</li>
    <li>Nye et al. (2021) Show Your Work: Scratchpads for Intermediate Computation with Language Models [Iterative refinement in LLMs]</li>
</ul>
            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>LLMs will show improved performance on spatial puzzles when allowed to generate intermediate subproblem solutions.</li>
                <li>Probing LLMs during puzzle solving will reveal hierarchical representations corresponding to subproblems and global constraints.</li>
                <li>LLMs will be able to transfer hierarchical reasoning strategies to new spatial puzzle types.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>LLMs may develop novel forms of hierarchical decomposition not used by humans.</li>
                <li>Recursive integration may enable LLMs to solve puzzles with highly entangled constraints beyond human capability.</li>
                <li>There may be emergent meta-reasoning about which subproblems to prioritize for efficient solution.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>If LLMs cannot decompose puzzles or fail to integrate local and global constraints, the theory is challenged.</li>
                <li>If probing fails to reveal hierarchical or recursive representations, the theory's mechanistic claims are undermined.</li>
                <li>If LLMs do not improve with iterative refinement, the recursive integration law is weakened.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>The exact mechanisms for subproblem selection and integration in LLMs are not fully understood. </li>
    <li>The limits of hierarchical reasoning in very large or highly irregular puzzles are not explained. </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> somewhat-related-to-existing</p>
            <p><strong>Explanation:</strong> This theory synthesizes known reasoning mechanisms in neural networks and applies them to spatial puzzle solving in LLMs.</p>
            <p><strong>References:</strong> <ul>
    <li>Lake & Baroni (2018) Generalization without Systematicity: Compositional Skills in Sequence-to-Sequence Recurrent Networks [Compositional reasoning]</li>
    <li>Graves et al. (2016) Hybrid computing using a neural network with dynamic external memory [Iterative and recursive reasoning]</li>
    <li>Nye et al. (2021) Show Your Work: Scratchpads for Intermediate Computation with Language Models [Iterative refinement in LLMs]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Hierarchical Spatial Reasoning via Compositional Inductive Biases in LLMs",
    "theory_description": "This theory proposes that LLMs solve spatial puzzles like Sudoku by leveraging hierarchical and compositional inductive biases, enabling them to decompose complex puzzles into subproblems, reason about local and global constraints, and recursively integrate partial solutions. The model's architecture and training encourage the emergence of multi-level spatial reasoning, supporting both local cell-level and global grid-level inference.",
    "theory_statements": [
        {
            "law": {
                "law_name": "Hierarchical Decomposition of Spatial Puzzles",
                "if": [
                    {
                        "subject": "language model",
                        "relation": "is presented with",
                        "object": "complex spatial puzzle"
                    },
                    {
                        "subject": "language model",
                        "relation": "has",
                        "object": "compositional inductive biases"
                    }
                ],
                "then": [
                    {
                        "subject": "language model",
                        "relation": "decomposes",
                        "object": "puzzle into hierarchical subproblems"
                    },
                    {
                        "subject": "language model",
                        "relation": "solves",
                        "object": "subproblems recursively"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "LLMs often solve Sudoku by filling in certain rows, columns, or blocks before integrating the full solution.",
                        "uuids": []
                    },
                    {
                        "text": "Compositional reasoning is observed in LLMs for multi-step tasks and nested logic.",
                        "uuids": []
                    },
                    {
                        "text": "Hierarchical attention in transformers supports multi-level reasoning.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Compositional and hierarchical reasoning in neural networks is established.",
                    "what_is_novel": "The application of these biases to spatial puzzle decomposition in LLMs is new.",
                    "classification_explanation": "This law extends compositional reasoning to the specific context of spatial puzzle solving in LLMs.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Lake & Baroni (2018) Generalization without Systematicity: Compositional Skills in Sequence-to-Sequence Recurrent Networks [Compositional reasoning]",
                        "Vaswani et al. (2017) Attention is All You Need [Hierarchical attention in transformers]"
                    ]
                }
            }
        },
        {
            "law": {
                "law_name": "Recursive Integration of Local and Global Constraints",
                "if": [
                    {
                        "subject": "language model",
                        "relation": "has",
                        "object": "partial solutions to subproblems"
                    },
                    {
                        "subject": "puzzle",
                        "relation": "has",
                        "object": "local and global constraints"
                    }
                ],
                "then": [
                    {
                        "subject": "language model",
                        "relation": "recursively integrates",
                        "object": "local and global constraint information"
                    },
                    {
                        "subject": "language model",
                        "relation": "updates",
                        "object": "solution candidates based on integrated constraints"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "LLMs can revise earlier cell assignments in Sudoku as new constraints are integrated.",
                        "uuids": []
                    },
                    {
                        "text": "Transformer models can propagate information globally via attention, supporting recursive updates.",
                        "uuids": []
                    },
                    {
                        "text": "LLMs' performance improves when allowed to iteratively refine solutions.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Recursive and iterative reasoning in neural networks is known.",
                    "what_is_novel": "The explicit recursive integration of local and global constraints in LLM spatial puzzle solving is new.",
                    "classification_explanation": "This law synthesizes recursive reasoning and constraint integration in the context of LLMs and spatial puzzles.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Graves et al. (2016) Hybrid computing using a neural network with dynamic external memory [Iterative and recursive reasoning]",
                        "Nye et al. (2021) Show Your Work: Scratchpads for Intermediate Computation with Language Models [Iterative refinement in LLMs]"
                    ]
                }
            }
        }
    ],
    "new_predictions_likely": [
        "LLMs will show improved performance on spatial puzzles when allowed to generate intermediate subproblem solutions.",
        "Probing LLMs during puzzle solving will reveal hierarchical representations corresponding to subproblems and global constraints.",
        "LLMs will be able to transfer hierarchical reasoning strategies to new spatial puzzle types."
    ],
    "new_predictions_unknown": [
        "LLMs may develop novel forms of hierarchical decomposition not used by humans.",
        "Recursive integration may enable LLMs to solve puzzles with highly entangled constraints beyond human capability.",
        "There may be emergent meta-reasoning about which subproblems to prioritize for efficient solution."
    ],
    "negative_experiments": [
        "If LLMs cannot decompose puzzles or fail to integrate local and global constraints, the theory is challenged.",
        "If probing fails to reveal hierarchical or recursive representations, the theory's mechanistic claims are undermined.",
        "If LLMs do not improve with iterative refinement, the recursive integration law is weakened."
    ],
    "unaccounted_for": [
        {
            "text": "The exact mechanisms for subproblem selection and integration in LLMs are not fully understood.",
            "uuids": []
        },
        {
            "text": "The limits of hierarchical reasoning in very large or highly irregular puzzles are not explained.",
            "uuids": []
        }
    ],
    "conflicting_evidence": [
        {
            "text": "Some LLMs fail to solve puzzles requiring deep recursion or non-standard decompositions.",
            "uuids": []
        }
    ],
    "special_cases": [
        "Puzzles with flat or non-hierarchical structure may not benefit from hierarchical decomposition.",
        "Very small models may lack the capacity for multi-level reasoning."
    ],
    "existing_theory": {
        "what_already_exists": "Compositional and hierarchical reasoning in neural networks is established; iterative refinement in LLMs is known.",
        "what_is_novel": "The explicit application of hierarchical and recursive reasoning to spatial puzzle solving in LLMs is new.",
        "classification_explanation": "This theory synthesizes known reasoning mechanisms in neural networks and applies them to spatial puzzle solving in LLMs.",
        "likely_classification": "somewhat-related-to-existing",
        "references": [
            "Lake & Baroni (2018) Generalization without Systematicity: Compositional Skills in Sequence-to-Sequence Recurrent Networks [Compositional reasoning]",
            "Graves et al. (2016) Hybrid computing using a neural network with dynamic external memory [Iterative and recursive reasoning]",
            "Nye et al. (2021) Show Your Work: Scratchpads for Intermediate Computation with Language Models [Iterative refinement in LLMs]"
        ]
    },
    "reflected_from_theory_index": 2,
    "type": "general",
    "version": "built-theory-from-results-single-theory-reflection2-nov14-2025-LLM-BASELINE-no-evidence-with-matched-control-theory-name",
    "theory_query": "Build a theory of how language models solve puzzle games involving spatial knowledge, like Sudoku.",
    "original_theory_id": "theory-597",
    "original_theory_name": "Emergent Algorithmic Reasoning via Structured Inductive Biases in Language Models",
    "provide_matched_control_thery_name": true,
    "matched_control_theory_name": "Emergent Algorithmic Reasoning via Structured Inductive Biases in Language Models",
    "model_str": "openai/gpt-4.1-2025-04-14"
}</code></pre>
        </div>
    </div>
</body>
</html>