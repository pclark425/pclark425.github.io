<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Semantic Abstraction Hierarchy Transfer Theory - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-355</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-355</p>
                <p><strong>Name:</strong> Semantic Abstraction Hierarchy Transfer Theory</p>
                <p><strong>Type:</strong> general</p>
                <p><strong>Theory Query:</strong> Build a theory about when and how pretraining on text worlds transfers to 3D embodied tasks, including mappings between high-level action semantics and low-level perception and predicted sample complexity gains.. Please focus on creating new theories that have not been proposed before in the literature.</p>
                <p><strong>Description:</strong> Transfer from text-worlds to 3D embodied tasks occurs most effectively when text-world pretraining establishes hierarchical action representations at multiple levels of abstraction, where high-level semantic goals (e.g., 'obtain key') can be decomposed into mid-level action sequences (e.g., 'navigate to room', 'pick up object') that are sufficiently abstract to be re-grounded in 3D perceptual spaces. The theory posits that transfer success depends on three key factors: (1) the degree of semantic alignment between text-world action primitives and the compositional structure of 3D task affordances, (2) the depth and breadth of the learned action hierarchy during pretraining, and (3) the availability of a grounding mechanism that can map abstract semantic representations to perceptual features and motor primitives. Sample complexity gains arise because the agent can leverage learned high-level policies and planning strategies, requiring only the learning of perceptual grounding and low-level control, rather than learning the entire task from scratch.</p>
                <p><strong>Knowledge Cutoff Year:</strong> -1</p>
                <p><strong>Knowledge Cutoff Month:</strong> -1</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <ol>
                <li>Transfer effectiveness is proportional to the semantic overlap between text-world action vocabularies and the affordance structure of 3D environments, measured by the intersection of action concepts and their compositional relationships</li>
                <li>Sample complexity gains increase with the depth of the action hierarchy learned during text-world pretraining, with diminishing returns at very deep hierarchies due to increased grounding complexity</li>
                <li>High-level action semantics (goals, subgoals, plans) transfer more readily than low-level motor primitives, requiring a perception-action grounding phase that maps abstract actions to sensorimotor control</li>
                <li>Text-world pretraining that includes spatial language (directional terms, spatial relations) and relational reasoning (object interactions, causal chains) provides measurable sample efficiency improvements over training from scratch on 3D tasks, with the magnitude depending on task complexity and semantic alignment</li>
                <li>The mapping from text actions to 3D embodied actions requires an intermediate representation space where semantic action concepts are disentangled from modality-specific execution details, enabling flexible re-grounding across different embodiments</li>
                <li>Transfer succeeds when text-world tasks share causal structure with 3D tasks (e.g., 'key unlocks door' in both domains), even when perceptual modalities differ completely, because causal abstractions are modality-independent</li>
                <li>The effectiveness of transfer is modulated by the diversity and coverage of action sequences encountered during text-world pretraining, with broader coverage leading to more robust transfer</li>
                <li>Grounding quality is the primary bottleneck for transfer: even with perfect high-level policy transfer, poor perceptual grounding will limit overall performance</li>
            </ol>
            <h3>Supporting Evidence</h3>
<ol>
    <li>Language models pretrained on text demonstrate compositional understanding of action sequences that can generalize to novel combinations, suggesting that abstract action representations can be learned from text </li>
    <li>Hierarchical reinforcement learning demonstrates that abstract action representations and temporal abstractions improve sample efficiency in complex tasks by reducing the effective planning horizon </li>
    <li>Vision-language models demonstrate that semantic concepts learned from text can be grounded to visual perceptual features through contrastive learning and alignment objectives </li>
    <li>Text-based game playing agents learn goal-oriented behavior, multi-step planning, and causal reasoning about object interactions and spatial relationships </li>
    <li>Language can serve as an effective abstraction layer for hierarchical reinforcement learning, enabling compositional generalization and transfer </li>
    <li>Embodied agents can leverage language instructions and descriptions to improve learning efficiency on 3D tasks through grounded language understanding </li>
    <li>Transfer learning in reinforcement learning is most effective when source and target tasks share abstract structure, even when surface features differ </li>
    <li>Compositional generalization in language models enables understanding of novel combinations of known concepts, which is crucial for transfer to new environments </li>
</ol>            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>Agents pretrained on text-worlds with rich spatial language (e.g., 'north', 'adjacent', 'above', 'behind') will show 30-50% faster learning on 3D navigation tasks compared to agents pretrained on text-worlds with minimal spatial language, measured by episodes to reach criterion performance</li>
                <li>Fine-tuning only the perception module while freezing high-level policy networks from text-world pretraining will achieve 60-80% of full fine-tuning performance with 3-5x fewer samples on tasks with high semantic alignment</li>
                <li>Text-world pretraining on tasks requiring multi-step planning (3+ steps) will transfer better to 3D tasks requiring similar planning horizons than to tasks with different temporal structures, with transfer benefits decreasing as horizon mismatch increases</li>
                <li>Agents will show positive transfer for novel object combinations in 3D environments if they encountered similar compositional structures in text-world pretraining (e.g., 'use X on Y' patterns), even with completely different object names, demonstrating abstract relational transfer</li>
                <li>Increasing the diversity of text-world environments during pretraining (while holding total training time constant) will improve transfer robustness to novel 3D environments, even if it slightly reduces performance on any single text-world task</li>
                <li>Agents pretrained on text-worlds with explicit causal language (e.g., 'because', 'causes', 'enables') will show better transfer to 3D tasks requiring causal reasoning than agents pretrained on text-worlds with only implicit causal structure</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>Whether text-world pretraining can enable zero-shot transfer to 3D embodied tasks when combined with frozen vision-language models (like CLIP) that provide perceptual grounding, without any 3D environment interaction during training</li>
                <li>Whether the semantic hierarchy learned from text-worlds exhibits universal structure that transfers across radically different embodied domains (e.g., robotic manipulation vs. quadruped locomotion vs. social navigation), or whether domain-specific hierarchies are necessary</li>
                <li>Whether adversarial text-world pretraining (with deliberately misleading spatial or causal structures that contradict physical reality) could actually harm 3D task learning more than no pretraining at all, or whether agents can unlearn incorrect priors efficiently</li>
                <li>Whether text-world pretraining could enable sample-efficient learning of physical intuition and dynamics prediction in 3D environments, despite text-worlds having no physics simulation, through abstract causal reasoning</li>
                <li>Whether the optimal ratio of text-world pretraining to 3D fine-tuning follows a predictable scaling law, or whether it depends critically on task-specific factors that are difficult to characterize a priori</li>
                <li>Whether multi-task text-world pretraining (training on diverse text-world tasks simultaneously) produces more transferable representations than sequential pretraining or single-task pretraining, and whether there are interference effects</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>If agents pretrained on text-worlds with rich action hierarchies show no sample efficiency improvement over random initialization on 3D tasks with matched semantic structure, this would challenge the core hierarchical transfer mechanism</li>
                <li>If ablating high-level semantic representations while keeping low-level features shows equal or better transfer performance, this would contradict the hierarchical abstraction hypothesis and suggest that transfer occurs through different mechanisms</li>
                <li>If text-world pretraining on tasks with completely different causal structures (e.g., inverted causality) shows equal transfer to tasks with aligned causal structures, this would challenge the causal structure alignment requirement</li>
                <li>If transfer performance does not correlate with semantic overlap metrics between text and 3D action spaces (measured by embedding similarity or graph alignment), this would question the semantic alignment principle</li>
                <li>If providing explicit hierarchical structure during 3D training (e.g., through curriculum learning or hierarchical RL) eliminates the benefits of text-world pretraining, this would suggest that the hierarchy itself, not the text-based learning, is the key factor</li>
                <li>If text-world pretraining with abstract action descriptions transfers no better than pretraining with arbitrary symbol sequences (controlling for statistical structure), this would challenge the importance of semantic content</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>The exact computational mechanisms by which semantic representations are re-grounded from text to visual perception remain underspecified - the theory does not detail whether this occurs through gradient-based learning, explicit mapping functions, or emergent alignment </li>
    <li>The theory does not fully explain how temporal dynamics and action timing transfer between discrete text-world steps and continuous 3D control, particularly for tasks requiring precise timing or continuous control </li>
    <li>Individual differences in transfer based on specific text-world training curricula, task orderings, and difficulty progressions are not fully characterized </li>
    <li>The role of language model scale and architecture in determining transfer effectiveness is not addressed - whether larger models transfer better and why </li>
    <li>The theory does not specify how multi-modal pretraining (text + images, but not 3D interaction) would compare to pure text-world pretraining </li>
    <li>The interaction between text-world pretraining and other forms of pretraining (e.g., self-supervised visual pretraining) is not characterized </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> new</p>
            <p><strong>Explanation:</strong> No explanation provided.</p>
            <p><strong>References:</strong> <ul>
    <li>Jiang et al. (2019) Language as an Abstraction for Hierarchical Deep Reinforcement Learning, NeurIPS [Related work on language for hierarchical RL, but focuses on language as an interface for hierarchical policies rather than text-world pretraining transfer]</li>
    <li>Shridhar et al. (2020) ALFRED: A Benchmark for Interpreting Grounded Instructions for Everyday Tasks, CVPR [Related to language grounding in 3D, but focuses on instruction following rather than pretraining transfer theory]</li>
    <li>Mu et al. (2022) Improving Intrinsic Exploration with Language Abstractions, NeurIPS [Related to language abstractions in RL, but not about text-world pretraining transfer theory]</li>
    <li>Côté et al. (2018) TextWorld: A Learning Environment for Text-based Games, IJCAI [Provides text-world environments but does not propose transfer theory to 3D]</li>
    <li>Ammanabrolu & Riedl (2019) Playing Text-Adventure Games with Graph-Based Deep Reinforcement Learning, NAACL [Focuses on text-game playing, not transfer to embodied domains]</li>
    <li>Andreas et al. (2017) Modular Multitask Reinforcement Learning with Policy Sketches, ICML [Related to compositional policy learning with language, but not specifically about text-world to 3D transfer]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Semantic Abstraction Hierarchy Transfer Theory",
    "theory_description": "Transfer from text-worlds to 3D embodied tasks occurs most effectively when text-world pretraining establishes hierarchical action representations at multiple levels of abstraction, where high-level semantic goals (e.g., 'obtain key') can be decomposed into mid-level action sequences (e.g., 'navigate to room', 'pick up object') that are sufficiently abstract to be re-grounded in 3D perceptual spaces. The theory posits that transfer success depends on three key factors: (1) the degree of semantic alignment between text-world action primitives and the compositional structure of 3D task affordances, (2) the depth and breadth of the learned action hierarchy during pretraining, and (3) the availability of a grounding mechanism that can map abstract semantic representations to perceptual features and motor primitives. Sample complexity gains arise because the agent can leverage learned high-level policies and planning strategies, requiring only the learning of perceptual grounding and low-level control, rather than learning the entire task from scratch.",
    "supporting_evidence": [
        {
            "text": "Language models pretrained on text demonstrate compositional understanding of action sequences that can generalize to novel combinations, suggesting that abstract action representations can be learned from text",
            "citations": [
                "Brown et al. (2020) Language Models are Few-Shot Learners, NeurIPS",
                "Wei et al. (2022) Chain-of-Thought Prompting Elicits Reasoning in Large Language Models, NeurIPS"
            ]
        },
        {
            "text": "Hierarchical reinforcement learning demonstrates that abstract action representations and temporal abstractions improve sample efficiency in complex tasks by reducing the effective planning horizon",
            "citations": [
                "Sutton et al. (1999) Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning, Artificial Intelligence",
                "Bacon et al. (2017) The Option-Critic Architecture, AAAI",
                "Nachum et al. (2018) Data-Efficient Hierarchical Reinforcement Learning, NeurIPS"
            ]
        },
        {
            "text": "Vision-language models demonstrate that semantic concepts learned from text can be grounded to visual perceptual features through contrastive learning and alignment objectives",
            "citations": [
                "Radford et al. (2021) Learning Transferable Visual Models From Natural Language Supervision, ICML",
                "Jia et al. (2021) Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision, ICML"
            ]
        },
        {
            "text": "Text-based game playing agents learn goal-oriented behavior, multi-step planning, and causal reasoning about object interactions and spatial relationships",
            "citations": [
                "Hausknecht et al. (2020) Interactive Fiction Games: A Colossal Adventure, AAAI",
                "Ammanabrolu & Riedl (2019) Playing Text-Adventure Games with Graph-Based Deep Reinforcement Learning, NAACL",
                "Côté et al. (2018) TextWorld: A Learning Environment for Text-based Games, IJCAI"
            ]
        },
        {
            "text": "Language can serve as an effective abstraction layer for hierarchical reinforcement learning, enabling compositional generalization and transfer",
            "citations": [
                "Jiang et al. (2019) Language as an Abstraction for Hierarchical Deep Reinforcement Learning, NeurIPS",
                "Andreas et al. (2017) Modular Multitask Reinforcement Learning with Policy Sketches, ICML"
            ]
        },
        {
            "text": "Embodied agents can leverage language instructions and descriptions to improve learning efficiency on 3D tasks through grounded language understanding",
            "citations": [
                "Shridhar et al. (2020) ALFRED: A Benchmark for Interpreting Grounded Instructions for Everyday Tasks, CVPR",
                "Lynch & Sermanet (2020) Language Conditioned Imitation Learning Over Unstructured Data, RSS"
            ]
        },
        {
            "text": "Transfer learning in reinforcement learning is most effective when source and target tasks share abstract structure, even when surface features differ",
            "citations": [
                "Taylor & Stone (2009) Transfer Learning for Reinforcement Learning Domains: A Survey, JMLR",
                "Zhu et al. (2020) Transfer Learning in Deep Reinforcement Learning: A Survey, arXiv"
            ]
        },
        {
            "text": "Compositional generalization in language models enables understanding of novel combinations of known concepts, which is crucial for transfer to new environments",
            "citations": [
                "Lake & Baroni (2018) Generalization without Systematicity: On the Compositional Skills of Sequence-to-Sequence Recurrent Networks, ICML",
                "Keysers et al. (2020) Measuring Compositional Generalization: A Comprehensive Method on Realistic Data, ICLR"
            ]
        }
    ],
    "theory_statements": [
        "Transfer effectiveness is proportional to the semantic overlap between text-world action vocabularies and the affordance structure of 3D environments, measured by the intersection of action concepts and their compositional relationships",
        "Sample complexity gains increase with the depth of the action hierarchy learned during text-world pretraining, with diminishing returns at very deep hierarchies due to increased grounding complexity",
        "High-level action semantics (goals, subgoals, plans) transfer more readily than low-level motor primitives, requiring a perception-action grounding phase that maps abstract actions to sensorimotor control",
        "Text-world pretraining that includes spatial language (directional terms, spatial relations) and relational reasoning (object interactions, causal chains) provides measurable sample efficiency improvements over training from scratch on 3D tasks, with the magnitude depending on task complexity and semantic alignment",
        "The mapping from text actions to 3D embodied actions requires an intermediate representation space where semantic action concepts are disentangled from modality-specific execution details, enabling flexible re-grounding across different embodiments",
        "Transfer succeeds when text-world tasks share causal structure with 3D tasks (e.g., 'key unlocks door' in both domains), even when perceptual modalities differ completely, because causal abstractions are modality-independent",
        "The effectiveness of transfer is modulated by the diversity and coverage of action sequences encountered during text-world pretraining, with broader coverage leading to more robust transfer",
        "Grounding quality is the primary bottleneck for transfer: even with perfect high-level policy transfer, poor perceptual grounding will limit overall performance"
    ],
    "new_predictions_likely": [
        "Agents pretrained on text-worlds with rich spatial language (e.g., 'north', 'adjacent', 'above', 'behind') will show 30-50% faster learning on 3D navigation tasks compared to agents pretrained on text-worlds with minimal spatial language, measured by episodes to reach criterion performance",
        "Fine-tuning only the perception module while freezing high-level policy networks from text-world pretraining will achieve 60-80% of full fine-tuning performance with 3-5x fewer samples on tasks with high semantic alignment",
        "Text-world pretraining on tasks requiring multi-step planning (3+ steps) will transfer better to 3D tasks requiring similar planning horizons than to tasks with different temporal structures, with transfer benefits decreasing as horizon mismatch increases",
        "Agents will show positive transfer for novel object combinations in 3D environments if they encountered similar compositional structures in text-world pretraining (e.g., 'use X on Y' patterns), even with completely different object names, demonstrating abstract relational transfer",
        "Increasing the diversity of text-world environments during pretraining (while holding total training time constant) will improve transfer robustness to novel 3D environments, even if it slightly reduces performance on any single text-world task",
        "Agents pretrained on text-worlds with explicit causal language (e.g., 'because', 'causes', 'enables') will show better transfer to 3D tasks requiring causal reasoning than agents pretrained on text-worlds with only implicit causal structure"
    ],
    "new_predictions_unknown": [
        "Whether text-world pretraining can enable zero-shot transfer to 3D embodied tasks when combined with frozen vision-language models (like CLIP) that provide perceptual grounding, without any 3D environment interaction during training",
        "Whether the semantic hierarchy learned from text-worlds exhibits universal structure that transfers across radically different embodied domains (e.g., robotic manipulation vs. quadruped locomotion vs. social navigation), or whether domain-specific hierarchies are necessary",
        "Whether adversarial text-world pretraining (with deliberately misleading spatial or causal structures that contradict physical reality) could actually harm 3D task learning more than no pretraining at all, or whether agents can unlearn incorrect priors efficiently",
        "Whether text-world pretraining could enable sample-efficient learning of physical intuition and dynamics prediction in 3D environments, despite text-worlds having no physics simulation, through abstract causal reasoning",
        "Whether the optimal ratio of text-world pretraining to 3D fine-tuning follows a predictable scaling law, or whether it depends critically on task-specific factors that are difficult to characterize a priori",
        "Whether multi-task text-world pretraining (training on diverse text-world tasks simultaneously) produces more transferable representations than sequential pretraining or single-task pretraining, and whether there are interference effects"
    ],
    "negative_experiments": [
        "If agents pretrained on text-worlds with rich action hierarchies show no sample efficiency improvement over random initialization on 3D tasks with matched semantic structure, this would challenge the core hierarchical transfer mechanism",
        "If ablating high-level semantic representations while keeping low-level features shows equal or better transfer performance, this would contradict the hierarchical abstraction hypothesis and suggest that transfer occurs through different mechanisms",
        "If text-world pretraining on tasks with completely different causal structures (e.g., inverted causality) shows equal transfer to tasks with aligned causal structures, this would challenge the causal structure alignment requirement",
        "If transfer performance does not correlate with semantic overlap metrics between text and 3D action spaces (measured by embedding similarity or graph alignment), this would question the semantic alignment principle",
        "If providing explicit hierarchical structure during 3D training (e.g., through curriculum learning or hierarchical RL) eliminates the benefits of text-world pretraining, this would suggest that the hierarchy itself, not the text-based learning, is the key factor",
        "If text-world pretraining with abstract action descriptions transfers no better than pretraining with arbitrary symbol sequences (controlling for statistical structure), this would challenge the importance of semantic content"
    ],
    "unaccounted_for": [
        {
            "text": "The exact computational mechanisms by which semantic representations are re-grounded from text to visual perception remain underspecified - the theory does not detail whether this occurs through gradient-based learning, explicit mapping functions, or emergent alignment",
            "citations": []
        },
        {
            "text": "The theory does not fully explain how temporal dynamics and action timing transfer between discrete text-world steps and continuous 3D control, particularly for tasks requiring precise timing or continuous control",
            "citations": []
        },
        {
            "text": "Individual differences in transfer based on specific text-world training curricula, task orderings, and difficulty progressions are not fully characterized",
            "citations": []
        },
        {
            "text": "The role of language model scale and architecture in determining transfer effectiveness is not addressed - whether larger models transfer better and why",
            "citations": []
        },
        {
            "text": "The theory does not specify how multi-modal pretraining (text + images, but not 3D interaction) would compare to pure text-world pretraining",
            "citations": []
        },
        {
            "text": "The interaction between text-world pretraining and other forms of pretraining (e.g., self-supervised visual pretraining) is not characterized",
            "citations": []
        }
    ],
    "conflicting_evidence": [
        {
            "text": "Some studies show that language conditioning can sometimes hurt performance on embodied tasks when the language is not well-aligned with the task structure, suggesting that text-based representations may introduce harmful biases",
            "citations": [
                "Pashevich et al. (2021) Episodic Transformer for Vision-and-Language Navigation, ICCV"
            ]
        },
        {
            "text": "End-to-end learning approaches that jointly learn perception and control sometimes outperform hierarchical approaches on certain tasks, challenging the universal benefit of hierarchical abstraction",
            "citations": [
                "Levine et al. (2016) End-to-End Training of Deep Visuomotor Policies, JMLR"
            ]
        },
        {
            "text": "Some work suggests that visual pretraining alone can be more effective than language-based pretraining for certain embodied tasks, particularly those requiring fine-grained visual discrimination",
            "citations": [
                "Sermanet et al. (2018) Time-Contrastive Networks: Self-Supervised Learning from Video, ICRA"
            ]
        }
    ],
    "special_cases": [
        "Transfer may fail when 3D tasks require precise motor control or perception at granularities not representable in text (e.g., sub-millimeter manipulation, texture discrimination)",
        "When text-world and 3D task reward structures are misaligned (e.g., different notions of success or optimality), negative transfer may occur despite semantic similarity in action spaces",
        "Very simple 3D tasks that can be solved with reactive policies may not benefit from text-world pretraining due to the overhead of the abstraction hierarchy and grounding process",
        "Transfer effectiveness may depend critically on the quality and type of the perception-to-semantics grounding mechanism - poor grounding can negate benefits of good high-level representations",
        "Tasks requiring real-time reactive control or fast sensorimotor loops may not benefit from text-world pretraining, which typically involves deliberative, sequential decision-making",
        "When the 3D environment has significantly different physics or dynamics than implied by text-world training (e.g., slippery surfaces, momentum effects), transfer may be limited to high-level strategy only",
        "Transfer may be asymmetric: text-to-3D transfer may work differently than 3D-to-text transfer, with different bottlenecks and failure modes",
        "The theory may not apply to tasks where language is inherently ambiguous or underspecified relative to the 3D task requirements"
    ],
    "existing_theory": {
        "likely_classification": "new",
        "references": [
            "Jiang et al. (2019) Language as an Abstraction for Hierarchical Deep Reinforcement Learning, NeurIPS [Related work on language for hierarchical RL, but focuses on language as an interface for hierarchical policies rather than text-world pretraining transfer]",
            "Shridhar et al. (2020) ALFRED: A Benchmark for Interpreting Grounded Instructions for Everyday Tasks, CVPR [Related to language grounding in 3D, but focuses on instruction following rather than pretraining transfer theory]",
            "Mu et al. (2022) Improving Intrinsic Exploration with Language Abstractions, NeurIPS [Related to language abstractions in RL, but not about text-world pretraining transfer theory]",
            "Côté et al. (2018) TextWorld: A Learning Environment for Text-based Games, IJCAI [Provides text-world environments but does not propose transfer theory to 3D]",
            "Ammanabrolu & Riedl (2019) Playing Text-Adventure Games with Graph-Based Deep Reinforcement Learning, NAACL [Focuses on text-game playing, not transfer to embodied domains]",
            "Andreas et al. (2017) Modular Multitask Reinforcement Learning with Policy Sketches, ICML [Related to compositional policy learning with language, but not specifically about text-world to 3D transfer]"
        ]
    },
    "theory_type_general_specific": "general",
    "reflected_from_theory_index": 0,
    "theory_query": "Build a theory about when and how pretraining on text worlds transfers to 3D embodied tasks, including mappings between high-level action semantics and low-level perception and predicted sample complexity gains.. Please focus on creating new theories that have not been proposed before in the literature.",
    "generation_mode": "llm_baseline_no_evidence",
    "original_theory_id": "theory-200",
    "original_theory_name": "Text-World to 3D Transfer Conditions Theory",
    "model_str": "claude-sonnet-4-5-20250929"
}</code></pre>
        </div>
    </div>
</body>
</html>