<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Hierarchical Episodic-Semantic Memory Integration Principle - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-911</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-911</p>
                <p><strong>Name:</strong> Hierarchical Episodic-Semantic Memory Integration Principle</p>
                <p><strong>Type:</strong> general</p>
                <p><strong>Theory Query:</strong> Build a theory of how LLM agents for text games can best use memory to solve text game tasks.</p>
                <p><strong>Description:</strong> This theory posits that LLM agents in text games achieve optimal performance by integrating hierarchical episodic (event-based) and semantic (fact-based) memory representations. Episodic memory encodes temporally ordered sequences of actions and observations, while semantic memory encodes abstracted knowledge about the game world, rules, and object properties. The agent dynamically switches between these memory types based on task demands, enabling both detailed recall of past events and generalization across similar situations.</p>
                <p><strong>Knowledge Cutoff Year:</strong> -1</p>
                <p><strong>Knowledge Cutoff Month:</strong> -1</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <h3>Statement 0: Hierarchical Memory Encoding Law (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; LLM agent &#8594; encounters &#8594; sequences of actions and observations in text game</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; LLM agent &#8594; encodes &#8594; episodic memory (ordered events) and semantic memory (abstracted knowledge) in a hierarchical structure</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Human memory is organized into episodic and semantic systems, supporting both event recall and generalization. </li>
    <li>Hierarchical memory architectures in AI improve performance on tasks requiring both detailed recall and abstraction. </li>
    <li>Text games often require recalling specific past actions (episodic) and applying general knowledge (semantic). </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> The law builds on known memory systems but applies a new, hierarchical integration for LLM agents in text games.</p>            <p><strong>What Already Exists:</strong> Episodic and semantic memory distinction is well-established in cognitive science and some AI systems.</p>            <p><strong>What is Novel:</strong> The explicit hierarchical integration and dynamic switching for LLM agents in text games is novel.</p>
            <p><strong>References:</strong> <ul>
    <li>Tulving (1972) Episodic and semantic memory [Human memory systems]</li>
    <li>Khandelwal et al. (2023) Memory in Language Models: An Empirical Study [Memory in LLMs]</li>
    <li>Madotto et al. (2020) Episodic Memory in Lifelong Language Learning [Episodic memory in AI]</li>
</ul>
            <h3>Statement 1: Dynamic Memory Switching Law (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; LLM agent &#8594; faces &#8594; task requiring either detailed recall or generalization</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; LLM agent &#8594; dynamically switches &#8594; between episodic and semantic memory representations as needed</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Humans flexibly use episodic or semantic memory depending on task demands. </li>
    <li>AI agents with dynamic memory access outperform those with static memory on complex tasks. </li>
    <li>Text game agents benefit from recalling specific events for puzzles and using general knowledge for navigation. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> Dynamic switching is known, but its hierarchical, context-driven application in LLM text game agents is new.</p>            <p><strong>What Already Exists:</strong> Dynamic memory access is explored in some AI architectures.</p>            <p><strong>What is Novel:</strong> The explicit, context-driven switching between hierarchical episodic and semantic memory in LLM text game agents is novel.</p>
            <p><strong>References:</strong> <ul>
    <li>Tulving (1985) Memory and consciousness [Dynamic use of memory types]</li>
    <li>Khandelwal et al. (2023) Memory in Language Models: An Empirical Study [Memory in LLMs]</li>
    <li>Madotto et al. (2020) Episodic Memory in Lifelong Language Learning [Episodic memory in AI]</li>
</ul>
            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>Agents with hierarchical episodic-semantic memory will outperform those with only one memory type on tasks requiring both recall and generalization.</li>
                <li>Dynamic switching will improve performance on puzzles with delayed dependencies and on navigation tasks.</li>
                <li>Hierarchical memory will reduce redundant storage and improve memory efficiency.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>The optimal granularity of episodic versus semantic memory for different game genres is unknown.</li>
                <li>Hierarchical integration may enable emergent reasoning strategies not present in either memory type alone.</li>
                <li>Over-reliance on one memory type may lead to systematic errors in certain game scenarios.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>If agents with only episodic or only semantic memory perform as well as those with hierarchical integration, the theory is challenged.</li>
                <li>If dynamic switching does not improve performance over static memory access, the theory's assumptions are questioned.</li>
                <li>If hierarchical memory leads to increased confusion or memory interference, the theory's utility is undermined.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>The computational overhead of maintaining hierarchical memory is not addressed. </li>
    <li>The impact of memory interference between episodic and semantic layers is not fully explored. </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> somewhat-related-to-existing</p>
            <p><strong>Explanation:</strong> The theory extends known memory systems with a new, principled integration and switching mechanism for LLM agents in text games.</p>
            <p><strong>References:</strong> <ul>
    <li>Tulving (1972) Episodic and semantic memory [Human memory systems]</li>
    <li>Khandelwal et al. (2023) Memory in Language Models: An Empirical Study [Memory in LLMs]</li>
    <li>Madotto et al. (2020) Episodic Memory in Lifelong Language Learning [Episodic memory in AI]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Hierarchical Episodic-Semantic Memory Integration Principle",
    "theory_description": "This theory posits that LLM agents in text games achieve optimal performance by integrating hierarchical episodic (event-based) and semantic (fact-based) memory representations. Episodic memory encodes temporally ordered sequences of actions and observations, while semantic memory encodes abstracted knowledge about the game world, rules, and object properties. The agent dynamically switches between these memory types based on task demands, enabling both detailed recall of past events and generalization across similar situations.",
    "theory_statements": [
        {
            "law": {
                "law_name": "Hierarchical Memory Encoding Law",
                "if": [
                    {
                        "subject": "LLM agent",
                        "relation": "encounters",
                        "object": "sequences of actions and observations in text game"
                    }
                ],
                "then": [
                    {
                        "subject": "LLM agent",
                        "relation": "encodes",
                        "object": "episodic memory (ordered events) and semantic memory (abstracted knowledge) in a hierarchical structure"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Human memory is organized into episodic and semantic systems, supporting both event recall and generalization.",
                        "uuids": []
                    },
                    {
                        "text": "Hierarchical memory architectures in AI improve performance on tasks requiring both detailed recall and abstraction.",
                        "uuids": []
                    },
                    {
                        "text": "Text games often require recalling specific past actions (episodic) and applying general knowledge (semantic).",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Episodic and semantic memory distinction is well-established in cognitive science and some AI systems.",
                    "what_is_novel": "The explicit hierarchical integration and dynamic switching for LLM agents in text games is novel.",
                    "classification_explanation": "The law builds on known memory systems but applies a new, hierarchical integration for LLM agents in text games.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Tulving (1972) Episodic and semantic memory [Human memory systems]",
                        "Khandelwal et al. (2023) Memory in Language Models: An Empirical Study [Memory in LLMs]",
                        "Madotto et al. (2020) Episodic Memory in Lifelong Language Learning [Episodic memory in AI]"
                    ]
                }
            }
        },
        {
            "law": {
                "law_name": "Dynamic Memory Switching Law",
                "if": [
                    {
                        "subject": "LLM agent",
                        "relation": "faces",
                        "object": "task requiring either detailed recall or generalization"
                    }
                ],
                "then": [
                    {
                        "subject": "LLM agent",
                        "relation": "dynamically switches",
                        "object": "between episodic and semantic memory representations as needed"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Humans flexibly use episodic or semantic memory depending on task demands.",
                        "uuids": []
                    },
                    {
                        "text": "AI agents with dynamic memory access outperform those with static memory on complex tasks.",
                        "uuids": []
                    },
                    {
                        "text": "Text game agents benefit from recalling specific events for puzzles and using general knowledge for navigation.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Dynamic memory access is explored in some AI architectures.",
                    "what_is_novel": "The explicit, context-driven switching between hierarchical episodic and semantic memory in LLM text game agents is novel.",
                    "classification_explanation": "Dynamic switching is known, but its hierarchical, context-driven application in LLM text game agents is new.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Tulving (1985) Memory and consciousness [Dynamic use of memory types]",
                        "Khandelwal et al. (2023) Memory in Language Models: An Empirical Study [Memory in LLMs]",
                        "Madotto et al. (2020) Episodic Memory in Lifelong Language Learning [Episodic memory in AI]"
                    ]
                }
            }
        }
    ],
    "new_predictions_likely": [
        "Agents with hierarchical episodic-semantic memory will outperform those with only one memory type on tasks requiring both recall and generalization.",
        "Dynamic switching will improve performance on puzzles with delayed dependencies and on navigation tasks.",
        "Hierarchical memory will reduce redundant storage and improve memory efficiency."
    ],
    "new_predictions_unknown": [
        "The optimal granularity of episodic versus semantic memory for different game genres is unknown.",
        "Hierarchical integration may enable emergent reasoning strategies not present in either memory type alone.",
        "Over-reliance on one memory type may lead to systematic errors in certain game scenarios."
    ],
    "negative_experiments": [
        "If agents with only episodic or only semantic memory perform as well as those with hierarchical integration, the theory is challenged.",
        "If dynamic switching does not improve performance over static memory access, the theory's assumptions are questioned.",
        "If hierarchical memory leads to increased confusion or memory interference, the theory's utility is undermined."
    ],
    "unaccounted_for": [
        {
            "text": "The computational overhead of maintaining hierarchical memory is not addressed.",
            "uuids": []
        },
        {
            "text": "The impact of memory interference between episodic and semantic layers is not fully explored.",
            "uuids": []
        }
    ],
    "conflicting_evidence": [
        {
            "text": "Some simple text games may be solved with only semantic or only episodic memory.",
            "uuids": []
        }
    ],
    "special_cases": [
        "Games with highly repetitive or non-linear structures may challenge the effectiveness of hierarchical memory.",
        "Tasks requiring only rote recall or only generalization may not benefit from integration."
    ],
    "existing_theory": {
        "what_already_exists": "Episodic and semantic memory are well-studied in cognitive science and some AI systems.",
        "what_is_novel": "The hierarchical integration and dynamic switching for LLM agents in text games is novel.",
        "classification_explanation": "The theory extends known memory systems with a new, principled integration and switching mechanism for LLM agents in text games.",
        "likely_classification": "somewhat-related-to-existing",
        "references": [
            "Tulving (1972) Episodic and semantic memory [Human memory systems]",
            "Khandelwal et al. (2023) Memory in Language Models: An Empirical Study [Memory in LLMs]",
            "Madotto et al. (2020) Episodic Memory in Lifelong Language Learning [Episodic memory in AI]"
        ]
    },
    "reflected_from_theory_index": 1,
    "type": "general",
    "version": "built-theory-from-results-single-theory-reflection2-nov14-2025-LLM-BASELINE-no-evidence-with-matched-control-theory-name",
    "theory_query": "Build a theory of how LLM agents for text games can best use memory to solve text game tasks.",
    "original_theory_id": "theory-589",
    "original_theory_name": "Hybrid Memory Architecture Principle for LLM Agents in Text Games",
    "provide_matched_control_thery_name": true,
    "matched_control_theory_name": "Hybrid Memory Architecture Principle for LLM Agents in Text Games",
    "model_str": "openai/gpt-4.1-2025-04-14"
}</code></pre>
        </div>
    </div>
</body>
</html>