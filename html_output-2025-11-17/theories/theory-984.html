<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Hierarchical Episodic-Semantic Memory Integration for LLM Agents in Text Games - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-984</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-984</p>
                <p><strong>Name:</strong> Hierarchical Episodic-Semantic Memory Integration for LLM Agents in Text Games</p>
                <p><strong>Type:</strong> general</p>
                <p><strong>Theory Query:</strong> Build a theory of how LLM agents for text games can best use memory to solve text game tasks.</p>
                <p><strong>Description:</strong> This theory posits that LLM agents achieve optimal performance in text games by integrating two complementary memory systems: an episodic memory that encodes temporally ordered sequences of game events, and a semantic memory that abstracts persistent facts, rules, and world knowledge. The agent dynamically interleaves retrieval and consolidation between these systems, enabling both flexible adaptation to novel situations and robust long-term planning.</p>
                <p><strong>Knowledge Cutoff Year:</strong> -1</p>
                <p><strong>Knowledge Cutoff Month:</strong> -1</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <h3>Statement 0: Episodic-Semantic Memory Complementarity (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; LLM agent &#8594; encounters &#8594; text game environment</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; LLM agent &#8594; stores &#8594; event sequences in episodic memory<span style="color: #888888;">, and</span></div>
        <div>&#8226; LLM agent &#8594; extracts &#8594; persistent facts and rules into semantic memory</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Cognitive neuroscience distinguishes episodic and semantic memory as complementary systems for event and fact storage. </li>
    <li>AI agents with both event logs and fact databases outperform those with only one type of memory in complex environments. </li>
    <li>Text games require both remembering specific actions (episodic) and generalizing world rules (semantic). </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> While the memory types are known, their operational integration for LLM-based text game agents is new.</p>            <p><strong>What Already Exists:</strong> The distinction between episodic and semantic memory is well-established in cognitive science and some AI architectures.</p>            <p><strong>What is Novel:</strong> The explicit, dynamic integration and interleaving of these systems in LLM agents for text games is novel.</p>
            <p><strong>References:</strong> <ul>
    <li>Tulving (1972) Episodic and semantic memory [Foundational distinction in human memory]</li>
    <li>Weston et al. (2015) Memory Networks [Neural architectures with explicit memory modules]</li>
    <li>Ammanabrolu et al. (2020) Graph Constrained Reinforcement Learning for Text Games [Structured memory in text game agents]</li>
</ul>
            <h3>Statement 1: Dynamic Memory Consolidation and Retrieval (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; LLM agent &#8594; faces &#8594; novel or complex task in text game</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; LLM agent &#8594; retrieves &#8594; relevant episodic traces and semantic facts<span style="color: #888888;">, and</span></div>
        <div>&#8226; LLM agent &#8594; consolidates &#8594; new knowledge from episodic to semantic memory</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Human memory consolidation transfers information from episodic to semantic systems for long-term retention. </li>
    <li>AI agents that periodically consolidate event traces into structured knowledge show improved generalization. </li>
    <li>Text games often require learning new rules or facts from specific experiences. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> The process is inspired by biology but its application to LLM agent memory in text games is new.</p>            <p><strong>What Already Exists:</strong> Memory consolidation is a known process in neuroscience and some AI systems.</p>            <p><strong>What is Novel:</strong> The dynamic, task-driven consolidation and retrieval in LLM agents for text games is novel.</p>
            <p><strong>References:</strong> <ul>
    <li>McClelland et al. (1995) Why there are complementary learning systems in the hippocampus and neocortex [Memory consolidation in humans]</li>
    <li>Weston et al. (2015) Memory Networks [Neural memory retrieval and consolidation]</li>
    <li>Ammanabrolu et al. (2020) Graph Constrained Reinforcement Learning for Text Games [Structured memory in text game agents]</li>
</ul>
            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>LLM agents with both episodic and semantic memory modules will outperform those with only one type in tasks requiring both recall of specific events and generalization of rules.</li>
                <li>Agents that periodically consolidate episodic traces into semantic knowledge will adapt more quickly to new but structurally similar games.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>If episodic and semantic memory are tightly coupled, agents may develop emergent meta-reasoning abilities (e.g., inferring unspoken rules from event patterns).</li>
                <li>Dynamic consolidation may enable transfer learning across unrelated text games if abstracted semantic knowledge is sufficiently general.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>If agents with only episodic or only semantic memory perform equally well as those with both, the theory's necessity is undermined.</li>
                <li>If dynamic consolidation leads to catastrophic forgetting or loss of important episodic details, the theory's utility is challenged.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>The impact of memory interference or overload (e.g., too many episodic traces) is not fully addressed. </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> somewhat-related-to-existing</p>
            <p><strong>Explanation:</strong> The theory adapts known memory systems to a new context and proposes a novel integration mechanism for LLM agents.</p>
            <p><strong>References:</strong> <ul>
    <li>Tulving (1972) Episodic and semantic memory [Foundational distinction in human memory]</li>
    <li>Weston et al. (2015) Memory Networks [Neural architectures with explicit memory modules]</li>
    <li>Ammanabrolu et al. (2020) Graph Constrained Reinforcement Learning for Text Games [Structured memory in text game agents]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Hierarchical Episodic-Semantic Memory Integration for LLM Agents in Text Games",
    "theory_description": "This theory posits that LLM agents achieve optimal performance in text games by integrating two complementary memory systems: an episodic memory that encodes temporally ordered sequences of game events, and a semantic memory that abstracts persistent facts, rules, and world knowledge. The agent dynamically interleaves retrieval and consolidation between these systems, enabling both flexible adaptation to novel situations and robust long-term planning.",
    "theory_statements": [
        {
            "law": {
                "law_name": "Episodic-Semantic Memory Complementarity",
                "if": [
                    {
                        "subject": "LLM agent",
                        "relation": "encounters",
                        "object": "text game environment"
                    }
                ],
                "then": [
                    {
                        "subject": "LLM agent",
                        "relation": "stores",
                        "object": "event sequences in episodic memory"
                    },
                    {
                        "subject": "LLM agent",
                        "relation": "extracts",
                        "object": "persistent facts and rules into semantic memory"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Cognitive neuroscience distinguishes episodic and semantic memory as complementary systems for event and fact storage.",
                        "uuids": []
                    },
                    {
                        "text": "AI agents with both event logs and fact databases outperform those with only one type of memory in complex environments.",
                        "uuids": []
                    },
                    {
                        "text": "Text games require both remembering specific actions (episodic) and generalizing world rules (semantic).",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "The distinction between episodic and semantic memory is well-established in cognitive science and some AI architectures.",
                    "what_is_novel": "The explicit, dynamic integration and interleaving of these systems in LLM agents for text games is novel.",
                    "classification_explanation": "While the memory types are known, their operational integration for LLM-based text game agents is new.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Tulving (1972) Episodic and semantic memory [Foundational distinction in human memory]",
                        "Weston et al. (2015) Memory Networks [Neural architectures with explicit memory modules]",
                        "Ammanabrolu et al. (2020) Graph Constrained Reinforcement Learning for Text Games [Structured memory in text game agents]"
                    ]
                }
            }
        },
        {
            "law": {
                "law_name": "Dynamic Memory Consolidation and Retrieval",
                "if": [
                    {
                        "subject": "LLM agent",
                        "relation": "faces",
                        "object": "novel or complex task in text game"
                    }
                ],
                "then": [
                    {
                        "subject": "LLM agent",
                        "relation": "retrieves",
                        "object": "relevant episodic traces and semantic facts"
                    },
                    {
                        "subject": "LLM agent",
                        "relation": "consolidates",
                        "object": "new knowledge from episodic to semantic memory"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Human memory consolidation transfers information from episodic to semantic systems for long-term retention.",
                        "uuids": []
                    },
                    {
                        "text": "AI agents that periodically consolidate event traces into structured knowledge show improved generalization.",
                        "uuids": []
                    },
                    {
                        "text": "Text games often require learning new rules or facts from specific experiences.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Memory consolidation is a known process in neuroscience and some AI systems.",
                    "what_is_novel": "The dynamic, task-driven consolidation and retrieval in LLM agents for text games is novel.",
                    "classification_explanation": "The process is inspired by biology but its application to LLM agent memory in text games is new.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "McClelland et al. (1995) Why there are complementary learning systems in the hippocampus and neocortex [Memory consolidation in humans]",
                        "Weston et al. (2015) Memory Networks [Neural memory retrieval and consolidation]",
                        "Ammanabrolu et al. (2020) Graph Constrained Reinforcement Learning for Text Games [Structured memory in text game agents]"
                    ]
                }
            }
        }
    ],
    "new_predictions_likely": [
        "LLM agents with both episodic and semantic memory modules will outperform those with only one type in tasks requiring both recall of specific events and generalization of rules.",
        "Agents that periodically consolidate episodic traces into semantic knowledge will adapt more quickly to new but structurally similar games."
    ],
    "new_predictions_unknown": [
        "If episodic and semantic memory are tightly coupled, agents may develop emergent meta-reasoning abilities (e.g., inferring unspoken rules from event patterns).",
        "Dynamic consolidation may enable transfer learning across unrelated text games if abstracted semantic knowledge is sufficiently general."
    ],
    "negative_experiments": [
        "If agents with only episodic or only semantic memory perform equally well as those with both, the theory's necessity is undermined.",
        "If dynamic consolidation leads to catastrophic forgetting or loss of important episodic details, the theory's utility is challenged."
    ],
    "unaccounted_for": [
        {
            "text": "The impact of memory interference or overload (e.g., too many episodic traces) is not fully addressed.",
            "uuids": []
        }
    ],
    "conflicting_evidence": [
        {
            "text": "Some simple text games can be solved with only short-term memory, suggesting hierarchical memory may not always be required.",
            "uuids": []
        }
    ],
    "special_cases": [
        "In games with static environments and no need for generalization, semantic memory may provide little benefit.",
        "If the game world is highly stochastic, episodic memory may be less reliable for planning."
    ],
    "existing_theory": {
        "what_already_exists": "Episodic and semantic memory systems are well-established in cognitive science and some AI models.",
        "what_is_novel": "The explicit, dynamic integration and interleaving of these systems in LLM agents for text games is new.",
        "classification_explanation": "The theory adapts known memory systems to a new context and proposes a novel integration mechanism for LLM agents.",
        "likely_classification": "somewhat-related-to-existing",
        "references": [
            "Tulving (1972) Episodic and semantic memory [Foundational distinction in human memory]",
            "Weston et al. (2015) Memory Networks [Neural architectures with explicit memory modules]",
            "Ammanabrolu et al. (2020) Graph Constrained Reinforcement Learning for Text Games [Structured memory in text game agents]"
        ]
    },
    "reflected_from_theory_index": 3,
    "type": "general",
    "version": "built-theory-from-results-single-theory-reflection2-nov14-2025-LLM-BASELINE-no-evidence-without-matched-control-theory-name",
    "theory_query": "Build a theory of how LLM agents for text games can best use memory to solve text game tasks.",
    "original_theory_id": "theory-594",
    "original_theory_name": "Structured and Interpretable Memory Representations Enable Efficient Planning, Exploration, and Error Recovery in LLM Agents for Text Games",
    "provide_matched_control_thery_name": false,
    "matched_control_theory_name": null,
    "model_str": "openai/gpt-4.1-2025-04-14"
}</code></pre>
        </div>
    </div>
</body>
</html>