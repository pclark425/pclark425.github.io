<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Structured External Memory Augmentation Theory - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-97</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-97</p>
                <p><strong>Name:</strong> Structured External Memory Augmentation Theory</p>
                <p><strong>Type:</strong> general</p>
                <p><strong>Theory Query:</strong> Build a theory of how agents perform planning with external tools in partially observable text environments, including belief-state updates that incorporate tool outputs and guide shortest-path actions, based on the following results.</p>
                <p><strong>Description:</strong> Agents operating in partially observable text environments benefit from maintaining explicit structured representations (knowledge graphs, belief graphs, symbolic states, or procedural program states) that are incrementally updated using external tool outputs. These structured representations serve as persistent memory that mitigates partial observability by aggregating information across time steps. The optimal representation type (graph-based vs. procedural vs. textual) depends on the task structure, tool availability, and computational constraints. Graph-based representations excel at relational reasoning and multi-hop inference, while procedural representations (program variables, execution traces) excel at sequential reasoning and arithmetic operations.</p>
                <p><strong>Knowledge Cutoff Year:</strong> 2024</p>
                <p><strong>Knowledge Cutoff Month:</strong> 12</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <ol>
                <li>Explicit structured belief representations (graphs, symbolic states, or procedural program states) that aggregate tool outputs across time steps provide superior performance in partially observable environments compared to implicit neural memory alone, particularly for tasks requiring multi-hop reasoning or long-term memory.</li>
                <li>Incremental construction of structured beliefs (evolving graphs, growing program states) is more sample-efficient than providing complete structured information upfront, as it focuses learning on relevant information and avoids overwhelming the agent with noise.</li>
                <li>The quality and relevance of external tool outputs (e.g., QA-based extraction vs. OpenIE, COMET vs. ConceptNet) directly impacts the utility of structured belief representations, with more accurate extraction leading to better downstream performance.</li>
                <li>Structured beliefs enable explicit reasoning about relationships, prerequisites, spatial/temporal dependencies, and co-reference that are difficult to capture in distributed neural representations alone.</li>
                <li>Graph-based belief representations naturally support multi-hop reasoning and can be encoded with graph neural networks (GATs, R-GCNs, GINs) for integration with learned policies.</li>
                <li>The optimal structured representation type depends on task characteristics: graph-based for relational/spatial reasoning, procedural (program variables) for sequential/arithmetic reasoning, and textual summaries for high-level planning.</li>
                <li>Structured beliefs must be updated incrementally with mechanisms for handling uncertainty, contradictions, and temporal dynamics to remain useful across long horizons.</li>
                <li>The computational overhead of maintaining structured beliefs is justified when the task requires aggregating information across many time steps or performing complex relational reasoning.</li>
            </ol>
            <h3>Supporting Evidence</h3>
<ol>
    <li>Q*BERT uses ALBERT QA to extract structured triples from observations and maintains a knowledge graph that improves sample efficiency over OpenIE-based extraction, achieving better performance on Jericho games <a href="../results/extraction-result-797.html#e797.0" class="evidence-link">[e797.0]</a> <a href="../results/extraction-result-797.html#e797.3" class="evidence-link">[e797.3]</a> <a href="../results/extraction-result-772.html#e772.2" class="evidence-link">[e772.2]</a> </li>
    <li>DiffG-RL constructs Difference Graphs linking environment state and commonsense knowledge, achieving 0.35±0.02 normalized score on TWC OUT Hard, outperforming baselines <a href="../results/extraction-result-778.html#e778.0" class="evidence-link">[e778.0]</a> <a href="../results/extraction-result-778.html#e778.1" class="evidence-link">[e778.1]</a> <a href="../results/extraction-result-778.html#e778.2" class="evidence-link">[e778.2]</a> </li>
    <li>Text+Commonsense agents using ConceptNet subgraphs with GAT encoding outperform text-only baselines, with KG_Evolve (incremental) showing better efficiency than KG_Full (complete upfront) <a href="../results/extraction-result-782.html#e782.0" class="evidence-link">[e782.0]</a> <a href="../results/extraction-result-782.html#e782.1" class="evidence-link">[e782.1]</a> <a href="../results/extraction-result-782.html#e782.2" class="evidence-link">[e782.2]</a> <a href="../results/extraction-result-782.html#e782.3" class="evidence-link">[e782.3]</a> </li>
    <li>KG-MRC builds dynamic bipartite knowledge graphs using MRC to track entity states across procedural text, achieving state-of-the-art on ProPara with explicit co-reference resolution <a href="../results/extraction-result-891.html#e891.0" class="evidence-link">[e891.0]</a> <a href="../results/extraction-result-891.html#e891.1" class="evidence-link">[e891.1]</a> <a href="../results/extraction-result-891.html#e891.2" class="evidence-link">[e891.2]</a> </li>
    <li>GATA maintains dynamic belief graphs that improve generalization in text-based games, with ground-truth graphs (GATA-GTF) achieving up to 95% normalized scores, demonstrating the value of accurate structured state <a href="../results/extraction-result-777.html#e777.0" class="evidence-link">[e777.0]</a> <a href="../results/extraction-result-777.html#e777.1" class="evidence-link">[e777.1]</a> <a href="../results/extraction-result-777.html#e777.2" class="evidence-link">[e777.2]</a> <a href="../results/extraction-result-794.html#e794.1" class="evidence-link">[e794.1]</a> </li>
    <li>NAIL uses a shared knowledge graph across modules to track objects, locations, and interactions, achieving 2.56% completion with graph-based navigation and validity detection <a href="../results/extraction-result-883.html#e883.3" class="evidence-link">[e883.3]</a> <a href="../results/extraction-result-806.html#e806.2" class="evidence-link">[e806.2]</a> <a href="../results/extraction-result-806.html#e806.5" class="evidence-link">[e806.5]</a> </li>
    <li>Worldformer predicts graph differences (additions) to update belief states and valid actions, improving look-ahead capabilities through learned world models <a href="../results/extraction-result-880.html#e880.0" class="evidence-link">[e880.0]</a> <a href="../results/extraction-result-880.html#e880.2" class="evidence-link">[e880.2]</a> </li>
    <li>KG-A2C uses knowledge graphs constructed from OpenIE to constrain action generation and improve performance in text games <a href="../results/extraction-result-778.html#e778.1" class="evidence-link">[e778.1]</a> <a href="../results/extraction-result-871.html#e871.1" class="evidence-link">[e871.1]</a> <a href="../results/extraction-result-797.html#e797.3" class="evidence-link">[e797.3]</a> </li>
    <li>COMET-A2C augments KG with commonsense inferences (HasA relations) enabling completion of tasks when objects aren't explicitly mentioned, achieving reward ≥6 vs baseline reward=2 <a href="../results/extraction-result-772.html#e772.2" class="evidence-link">[e772.2]</a> </li>
    <li>Ammanabrolu & Riedl's graph-based RL agent constructs KG from OpenIE and game-specific rules to inform policy in text adventures <a href="../results/extraction-result-769.html#e769.1" class="evidence-link">[e769.1]</a> <a href="../results/extraction-result-769.html#e769.2" class="evidence-link">[e769.2]</a> </li>
    <li>MPRC-DQN uses object-centric retrieval to build multi-paragraph textual belief states, achieving 64-76% winning percentage on Jericho games <a href="../results/extraction-result-871.html#e871.2" class="evidence-link">[e871.2]</a> </li>
    <li>Golovin agent maintains a map graph of locations and movement commands, using graph-based routing to reach promising destinations <a href="../results/extraction-result-883.html#e883.1" class="evidence-link">[e883.1]</a> </li>
    <li>LTL-GATA uses structured LTL formulas as explicit temporal belief state, with progression monitoring achieving ~82% success rate vs baseline GATA <a href="../results/extraction-result-794.html#e794.0" class="evidence-link">[e794.0]</a> </li>
    <li>ConceptAgent maintains a language-aligned 3D scene graph updated in real-time from perception tools, achieving 35% success on moderate tasks and 15% on hard tasks <a href="../results/extraction-result-804.html#e804.0" class="evidence-link">[e804.0]</a> </li>
    <li>KGA2C with Story Shaping uses target KG from LLM dialogue to guide learning, converging to optimal policy in ~10,000 steps vs ~90,000 for baseline <a href="../results/extraction-result-776.html#e776.0" class="evidence-link">[e776.0]</a> </li>
    <li>Belief+KG agents combining dynamic belief graphs with ConceptNet knowledge outperform text-only baselines in TextWorld <a href="../results/extraction-result-761.html#e761.0" class="evidence-link">[e761.0]</a> <a href="../results/extraction-result-761.html#e761.1" class="evidence-link">[e761.1]</a> </li>
    <li>TDGU constructs temporal dynamic knowledge graphs with timestamped events for textual SLAM in interactive fiction <a href="../results/extraction-result-785.html#e785.3" class="evidence-link">[e785.3]</a> </li>
    <li>LangGround MARL maintains implicit belief via LSTM hidden states augmented with communication vectors aligned to LLM embeddings, achieving 4.3±1.20 steps in Predator-Prey <a href="../results/extraction-result-805.html#e805.1" class="evidence-link">[e805.1]</a> </li>
</ol>            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>An agent using a hybrid belief system with both a knowledge graph (for long-term relational facts) and a recurrent neural memory (for recent context and implicit patterns) will outperform agents using either alone in long-horizon partially observable tasks requiring both types of reasoning.</li>
                <li>Agents that use external tools to validate and correct their belief graphs (e.g., by querying consistency checkers, running logical inference, or cross-referencing multiple extraction tools) will show improved robustness to extraction errors compared to agents that blindly trust single-tool outputs.</li>
                <li>In multi-agent partially observable environments, agents that maintain explicit belief graphs about teammates' knowledge states (theory of mind graphs) will coordinate more effectively than agents with implicit teammate models, particularly when communication is limited.</li>
                <li>Agents that dynamically choose between graph-based and procedural belief representations based on the current subtask (e.g., graphs for navigation, program states for arithmetic) will outperform agents committed to a single representation type.</li>
                <li>Structured beliefs that explicitly represent uncertainty (e.g., probabilistic graphs, confidence-weighted edges) will be more robust to noisy tool outputs than deterministic structured beliefs.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>Whether structured belief representations remain beneficial when scaled to extremely large state spaces (millions of entities, thousands of relation types) or whether they become computationally intractable compared to learned compressed representations with sufficient capacity.</li>
                <li>Whether end-to-end learned graph construction (without external tools, using only learned extractors) can match or exceed the performance of tool-augmented graph construction in zero-shot transfer to new domains with different entity types and relations.</li>
                <li>Whether temporal knowledge graphs that explicitly model time-varying relations and event sequences provide significant advantages over static graphs with implicit temporal encoding in highly dynamic environments with frequent state changes.</li>
                <li>Whether the benefits of structured beliefs persist when agents have access to very large context windows (e.g., 100K+ tokens) that can hold extensive textual history, or whether explicit structure becomes less important with sufficient context capacity.</li>
                <li>Whether structured beliefs can be effectively learned and maintained in continuous, high-dimensional state spaces (e.g., robotics with raw sensor inputs) or whether they are primarily beneficial in discrete, symbolic domains.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>Finding environments where agents with explicit structured beliefs consistently underperform agents with only implicit neural memory (controlling for total parameter count and training time) would challenge the theory's generality and suggest the benefits are task-specific.</li>
                <li>Demonstrating that the performance gains from structured beliefs disappear when controlling for model capacity (e.g., giving implicit-memory agents proportionally more parameters to match the effective capacity of graph+encoder systems) would suggest the benefits are primarily from capacity rather than structure.</li>
                <li>Showing that randomly-structured or adversarially-constructed belief graphs (with incorrect edges, wrong entity types, or shuffled relations) perform as well as carefully-constructed ones would challenge the claim that structure itself is beneficial rather than just additional parameters.</li>
                <li>Finding that agents with structured beliefs fail to generalize to new domains while implicit-memory agents succeed would challenge the claim that structure aids generalization.</li>
                <li>Demonstrating that the computational overhead of maintaining and updating structured beliefs outweighs their benefits in real-time settings would challenge their practical utility.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>The optimal granularity and abstraction level for structured beliefs across different task types is not well characterized - when should beliefs be fine-grained vs. abstract? </li>
    <li>How to automatically determine which information should be stored in structured vs. implicit representations, and when to transition between them during task execution </li>
    <li>The computational trade-offs between graph complexity (number of nodes, edges, relation types) and planning efficiency in real-time settings with limited compute budgets </li>
    <li>How to handle contradictory information from multiple tools when updating structured beliefs, and when to trust vs. discard tool outputs </li>
    <li>The role of structured beliefs in few-shot vs. many-shot learning scenarios - do they provide more benefit when training data is limited? </li>
    <li>How structured beliefs interact with different exploration strategies and whether they enable more efficient exploration </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> closely-related-to-existing</p>
            <p><strong>Explanation:</strong> No explanation provided.</p>
            <p><strong>References:</strong> <ul>
    <li>Ammanabrolu & Riedl (2018) Playing text-adventure games with graph-based deep reinforcement learning [Early foundational work on KG-based RL for text games, establishing the core idea]</li>
    <li>Adhikari et al. (2020) Learning dynamic belief graphs to generalize on text-based games [GATA framework for dynamic belief graphs with learned updates]</li>
    <li>Xu et al. (2020) Graph constrained reinforcement learning for natural language action spaces [KG-A2C framework showing how graphs constrain action generation]</li>
    <li>Das et al. (2018) Building dynamic knowledge graphs from text using machine reading comprehension [KG-MRC approach using QA for graph construction]</li>
    <li>Murugesan et al. (2021) Text-based RL Agents with Commonsense Knowledge [Framework for integrating external commonsense KGs with learned policies]</li>
    <li>Xu et al. (2022) DiffG-RL: Leveraging Difference between State and Common Sense [Difference graph representation linking state and commonsense]</li>
    <li>Jansen et al. (2020) How to Avoid Being Eaten by a Grue [Structured exploration with KG-based beliefs and QA extraction]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Structured External Memory Augmentation Theory",
    "theory_description": "Agents operating in partially observable text environments benefit from maintaining explicit structured representations (knowledge graphs, belief graphs, symbolic states, or procedural program states) that are incrementally updated using external tool outputs. These structured representations serve as persistent memory that mitigates partial observability by aggregating information across time steps. The optimal representation type (graph-based vs. procedural vs. textual) depends on the task structure, tool availability, and computational constraints. Graph-based representations excel at relational reasoning and multi-hop inference, while procedural representations (program variables, execution traces) excel at sequential reasoning and arithmetic operations.",
    "supporting_evidence": [
        {
            "text": "Q*BERT uses ALBERT QA to extract structured triples from observations and maintains a knowledge graph that improves sample efficiency over OpenIE-based extraction, achieving better performance on Jericho games",
            "uuids": [
                "e797.0",
                "e797.3",
                "e772.2"
            ]
        },
        {
            "text": "DiffG-RL constructs Difference Graphs linking environment state and commonsense knowledge, achieving 0.35±0.02 normalized score on TWC OUT Hard, outperforming baselines",
            "uuids": [
                "e778.0",
                "e778.1",
                "e778.2"
            ]
        },
        {
            "text": "Text+Commonsense agents using ConceptNet subgraphs with GAT encoding outperform text-only baselines, with KG_Evolve (incremental) showing better efficiency than KG_Full (complete upfront)",
            "uuids": [
                "e782.0",
                "e782.1",
                "e782.2",
                "e782.3"
            ]
        },
        {
            "text": "KG-MRC builds dynamic bipartite knowledge graphs using MRC to track entity states across procedural text, achieving state-of-the-art on ProPara with explicit co-reference resolution",
            "uuids": [
                "e891.0",
                "e891.1",
                "e891.2"
            ]
        },
        {
            "text": "GATA maintains dynamic belief graphs that improve generalization in text-based games, with ground-truth graphs (GATA-GTF) achieving up to 95% normalized scores, demonstrating the value of accurate structured state",
            "uuids": [
                "e777.0",
                "e777.1",
                "e777.2",
                "e794.1"
            ]
        },
        {
            "text": "NAIL uses a shared knowledge graph across modules to track objects, locations, and interactions, achieving 2.56% completion with graph-based navigation and validity detection",
            "uuids": [
                "e883.3",
                "e806.2",
                "e806.5"
            ]
        },
        {
            "text": "Worldformer predicts graph differences (additions) to update belief states and valid actions, improving look-ahead capabilities through learned world models",
            "uuids": [
                "e880.0",
                "e880.2"
            ]
        },
        {
            "text": "KG-A2C uses knowledge graphs constructed from OpenIE to constrain action generation and improve performance in text games",
            "uuids": [
                "e778.1",
                "e871.1",
                "e797.3"
            ]
        },
        {
            "text": "COMET-A2C augments KG with commonsense inferences (HasA relations) enabling completion of tasks when objects aren't explicitly mentioned, achieving reward ≥6 vs baseline reward=2",
            "uuids": [
                "e772.2"
            ]
        },
        {
            "text": "Ammanabrolu & Riedl's graph-based RL agent constructs KG from OpenIE and game-specific rules to inform policy in text adventures",
            "uuids": [
                "e769.1",
                "e769.2"
            ]
        },
        {
            "text": "MPRC-DQN uses object-centric retrieval to build multi-paragraph textual belief states, achieving 64-76% winning percentage on Jericho games",
            "uuids": [
                "e871.2"
            ]
        },
        {
            "text": "Golovin agent maintains a map graph of locations and movement commands, using graph-based routing to reach promising destinations",
            "uuids": [
                "e883.1"
            ]
        },
        {
            "text": "LTL-GATA uses structured LTL formulas as explicit temporal belief state, with progression monitoring achieving ~82% success rate vs baseline GATA",
            "uuids": [
                "e794.0"
            ]
        },
        {
            "text": "ConceptAgent maintains a language-aligned 3D scene graph updated in real-time from perception tools, achieving 35% success on moderate tasks and 15% on hard tasks",
            "uuids": [
                "e804.0"
            ]
        },
        {
            "text": "KGA2C with Story Shaping uses target KG from LLM dialogue to guide learning, converging to optimal policy in ~10,000 steps vs ~90,000 for baseline",
            "uuids": [
                "e776.0"
            ]
        },
        {
            "text": "Belief+KG agents combining dynamic belief graphs with ConceptNet knowledge outperform text-only baselines in TextWorld",
            "uuids": [
                "e761.0",
                "e761.1"
            ]
        },
        {
            "text": "TDGU constructs temporal dynamic knowledge graphs with timestamped events for textual SLAM in interactive fiction",
            "uuids": [
                "e785.3"
            ]
        },
        {
            "text": "LangGround MARL maintains implicit belief via LSTM hidden states augmented with communication vectors aligned to LLM embeddings, achieving 4.3±1.20 steps in Predator-Prey",
            "uuids": [
                "e805.1"
            ]
        }
    ],
    "theory_statements": [
        "Explicit structured belief representations (graphs, symbolic states, or procedural program states) that aggregate tool outputs across time steps provide superior performance in partially observable environments compared to implicit neural memory alone, particularly for tasks requiring multi-hop reasoning or long-term memory.",
        "Incremental construction of structured beliefs (evolving graphs, growing program states) is more sample-efficient than providing complete structured information upfront, as it focuses learning on relevant information and avoids overwhelming the agent with noise.",
        "The quality and relevance of external tool outputs (e.g., QA-based extraction vs. OpenIE, COMET vs. ConceptNet) directly impacts the utility of structured belief representations, with more accurate extraction leading to better downstream performance.",
        "Structured beliefs enable explicit reasoning about relationships, prerequisites, spatial/temporal dependencies, and co-reference that are difficult to capture in distributed neural representations alone.",
        "Graph-based belief representations naturally support multi-hop reasoning and can be encoded with graph neural networks (GATs, R-GCNs, GINs) for integration with learned policies.",
        "The optimal structured representation type depends on task characteristics: graph-based for relational/spatial reasoning, procedural (program variables) for sequential/arithmetic reasoning, and textual summaries for high-level planning.",
        "Structured beliefs must be updated incrementally with mechanisms for handling uncertainty, contradictions, and temporal dynamics to remain useful across long horizons.",
        "The computational overhead of maintaining structured beliefs is justified when the task requires aggregating information across many time steps or performing complex relational reasoning."
    ],
    "new_predictions_likely": [
        "An agent using a hybrid belief system with both a knowledge graph (for long-term relational facts) and a recurrent neural memory (for recent context and implicit patterns) will outperform agents using either alone in long-horizon partially observable tasks requiring both types of reasoning.",
        "Agents that use external tools to validate and correct their belief graphs (e.g., by querying consistency checkers, running logical inference, or cross-referencing multiple extraction tools) will show improved robustness to extraction errors compared to agents that blindly trust single-tool outputs.",
        "In multi-agent partially observable environments, agents that maintain explicit belief graphs about teammates' knowledge states (theory of mind graphs) will coordinate more effectively than agents with implicit teammate models, particularly when communication is limited.",
        "Agents that dynamically choose between graph-based and procedural belief representations based on the current subtask (e.g., graphs for navigation, program states for arithmetic) will outperform agents committed to a single representation type.",
        "Structured beliefs that explicitly represent uncertainty (e.g., probabilistic graphs, confidence-weighted edges) will be more robust to noisy tool outputs than deterministic structured beliefs."
    ],
    "new_predictions_unknown": [
        "Whether structured belief representations remain beneficial when scaled to extremely large state spaces (millions of entities, thousands of relation types) or whether they become computationally intractable compared to learned compressed representations with sufficient capacity.",
        "Whether end-to-end learned graph construction (without external tools, using only learned extractors) can match or exceed the performance of tool-augmented graph construction in zero-shot transfer to new domains with different entity types and relations.",
        "Whether temporal knowledge graphs that explicitly model time-varying relations and event sequences provide significant advantages over static graphs with implicit temporal encoding in highly dynamic environments with frequent state changes.",
        "Whether the benefits of structured beliefs persist when agents have access to very large context windows (e.g., 100K+ tokens) that can hold extensive textual history, or whether explicit structure becomes less important with sufficient context capacity.",
        "Whether structured beliefs can be effectively learned and maintained in continuous, high-dimensional state spaces (e.g., robotics with raw sensor inputs) or whether they are primarily beneficial in discrete, symbolic domains."
    ],
    "negative_experiments": [
        "Finding environments where agents with explicit structured beliefs consistently underperform agents with only implicit neural memory (controlling for total parameter count and training time) would challenge the theory's generality and suggest the benefits are task-specific.",
        "Demonstrating that the performance gains from structured beliefs disappear when controlling for model capacity (e.g., giving implicit-memory agents proportionally more parameters to match the effective capacity of graph+encoder systems) would suggest the benefits are primarily from capacity rather than structure.",
        "Showing that randomly-structured or adversarially-constructed belief graphs (with incorrect edges, wrong entity types, or shuffled relations) perform as well as carefully-constructed ones would challenge the claim that structure itself is beneficial rather than just additional parameters.",
        "Finding that agents with structured beliefs fail to generalize to new domains while implicit-memory agents succeed would challenge the claim that structure aids generalization.",
        "Demonstrating that the computational overhead of maintaining and updating structured beliefs outweighs their benefits in real-time settings would challenge their practical utility."
    ],
    "unaccounted_for": [
        {
            "text": "The optimal granularity and abstraction level for structured beliefs across different task types is not well characterized - when should beliefs be fine-grained vs. abstract?",
            "uuids": []
        },
        {
            "text": "How to automatically determine which information should be stored in structured vs. implicit representations, and when to transition between them during task execution",
            "uuids": []
        },
        {
            "text": "The computational trade-offs between graph complexity (number of nodes, edges, relation types) and planning efficiency in real-time settings with limited compute budgets",
            "uuids": []
        },
        {
            "text": "How to handle contradictory information from multiple tools when updating structured beliefs, and when to trust vs. discard tool outputs",
            "uuids": []
        },
        {
            "text": "The role of structured beliefs in few-shot vs. many-shot learning scenarios - do they provide more benefit when training data is limited?",
            "uuids": []
        },
        {
            "text": "How structured beliefs interact with different exploration strategies and whether they enable more efficient exploration",
            "uuids": []
        }
    ],
    "conflicting_evidence": [
        {
            "text": "LLM-based agents (GPT-4 with explicit textual belief) achieve strong performance (team score=90, 12.3 rounds) without graph structures, suggesting textual summaries may suffice for some tasks",
            "uuids": [
                "e773.0",
                "e773.1"
            ]
        },
        {
            "text": "LSTM-DQN achieves near-optimal performance (~100% quest completion, reward≈-11.33) in MUD games using only implicit recurrent memory without explicit graphs",
            "uuids": [
                "e872.0"
            ]
        },
        {
            "text": "Swift (Flan-T5) achieves competitive performance (avg≈30.18 with affordances) using only textual input sequences without explicit graph construction",
            "uuids": [
                "e789.3"
            ]
        },
        {
            "text": "PAL achieves 72-80% solve rates on reasoning tasks using procedural program state (Python variables) rather than graph-based beliefs, suggesting procedural representations can be superior for certain task types",
            "uuids": [
                "e888.0"
            ]
        },
        {
            "text": "ViperGPT achieves strong performance (72% RefCOCO, 51.9% OK-VQA) using program-local state (ImagePatch objects, variables) rather than persistent graphs",
            "uuids": [
                "e866.0"
            ]
        },
        {
            "text": "Translated LM pipeline achieves 73-79% executability using only prompt-based action history (textual trajectory) without structured graphs",
            "uuids": [
                "e867.1",
                "e877.0"
            ]
        },
        {
            "text": "Inner Monologue achieves strong embodied task performance using textual feedback integration without explicit graph structures",
            "uuids": [
                "e875.1",
                "e875.2",
                "e875.3"
            ]
        }
    ],
    "special_cases": [
        "In fully observable or nearly-fully-observable environments, the benefits of explicit structured beliefs may be minimal as the current observation contains most necessary information, and the overhead of maintaining structures is not justified.",
        "For very short-horizon tasks (1-3 steps), the overhead of constructing and maintaining structured beliefs may outweigh benefits, as simple reactive policies or single-step reasoning suffice.",
        "When tool outputs are highly noisy or unreliable (e.g., low-quality extraction, adversarial inputs), structured beliefs may propagate errors more severely than implicit representations that can learn to ignore or downweight unreliable signals through training.",
        "For tasks requiring primarily sequential or arithmetic reasoning (e.g., math word problems, algorithmic tasks), procedural program state (variables, execution traces) may be more effective than graph-based beliefs.",
        "In domains with very large or unbounded entity sets (e.g., open-world web navigation), maintaining complete graphs becomes intractable and selective/compressed representations may be necessary.",
        "When agents have access to very large context windows (100K+ tokens), the benefits of explicit structure may diminish as extensive textual history can be maintained directly.",
        "For tasks requiring primarily perceptual reasoning (e.g., visual question answering on single images), structured beliefs about entities may be less important than visual feature representations.",
        "In real-time settings with strict computational constraints, the overhead of graph updates and encoding may make implicit representations more practical despite potential performance trade-offs."
    ],
    "existing_theory": {
        "likely_classification": "closely-related-to-existing",
        "references": [
            "Ammanabrolu & Riedl (2018) Playing text-adventure games with graph-based deep reinforcement learning [Early foundational work on KG-based RL for text games, establishing the core idea]",
            "Adhikari et al. (2020) Learning dynamic belief graphs to generalize on text-based games [GATA framework for dynamic belief graphs with learned updates]",
            "Xu et al. (2020) Graph constrained reinforcement learning for natural language action spaces [KG-A2C framework showing how graphs constrain action generation]",
            "Das et al. (2018) Building dynamic knowledge graphs from text using machine reading comprehension [KG-MRC approach using QA for graph construction]",
            "Murugesan et al. (2021) Text-based RL Agents with Commonsense Knowledge [Framework for integrating external commonsense KGs with learned policies]",
            "Xu et al. (2022) DiffG-RL: Leveraging Difference between State and Common Sense [Difference graph representation linking state and commonsense]",
            "Jansen et al. (2020) How to Avoid Being Eaten by a Grue [Structured exploration with KG-based beliefs and QA extraction]"
        ]
    },
    "theory_type_general_specific": "general",
    "reflected_from_theory_index": 0,
    "type": "general"
}</code></pre>
        </div>
    </div>
</body>
</html>