<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Hierarchical Abstraction in Memory Enables Transfer and Compositionality in LLM Agents for Text Games - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-993</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-993</p>
                <p><strong>Name:</strong> Hierarchical Abstraction in Memory Enables Transfer and Compositionality in LLM Agents for Text Games</p>
                <p><strong>Type:</strong> general</p>
                <p><strong>Theory Query:</strong> Build a theory of how LLM agents for text games can best use memory to solve text game tasks.</p>
                <p><strong>Description:</strong> This theory proposes that LLM agents equipped with hierarchical, abstracted memory representations—where low-level events are grouped into higher-level schemas or scripts—can transfer knowledge across tasks and compose novel solutions in text games. By organizing memory into multi-level abstractions, agents can recognize recurring patterns, reuse strategies, and adapt to new challenges with minimal retraining.</p>
                <p><strong>Knowledge Cutoff Year:</strong> -1</p>
                <p><strong>Knowledge Cutoff Month:</strong> -1</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <h3>Statement 0: Hierarchical Memory Supports Transfer Across Tasks (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; LLM agent &#8594; has_memory &#8594; hierarchical abstraction of events and actions<span style="color: #888888;">, and</span></div>
        <div>&#8226; text games &#8594; share &#8594; common subgoals or patterns</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; LLM agent &#8594; can_transfer &#8594; strategies and knowledge across games<span style="color: #888888;">, and</span></div>
        <div>&#8226; LLM agent &#8594; can_learn &#8594; new games with fewer examples</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Hierarchical memory and abstraction enable transfer learning in cognitive architectures and deep RL. </li>
    <li>LLMs with schema-based memory can generalize across related tasks. </li>
    <li>Abstraction reduces the need for retraining on similar subgoals. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> The principle is established, but its systematic application to LLMs for text games is new.</p>            <p><strong>What Already Exists:</strong> Hierarchical abstraction and transfer are established in cognitive science and deep RL.</p>            <p><strong>What is Novel:</strong> Application to LLM agents in text games, and the explicit link to hierarchical memory for transfer and compositionality.</p>
            <p><strong>References:</strong> <ul>
    <li>Botvinick et al. (2019) Hierarchical Reinforcement Learning and Abstraction [hierarchical memory and transfer]</li>
    <li>Mialon et al. (2023) Augmented Language Models: a Survey [memory and reasoning in LLMs]</li>
    <li>Yao et al. (2023) Tree of Thoughts: Deliberate Problem Solving with Large Language Models [structured reasoning in LLMs]</li>
</ul>
            <h3>Statement 1: Hierarchical Memory Enables Compositional Problem Solving (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; LLM agent &#8594; has_memory &#8594; multi-level abstraction of actions and outcomes<span style="color: #888888;">, and</span></div>
        <div>&#8226; text game &#8594; requires &#8594; novel composition of known subgoals</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; LLM agent &#8594; can_compose &#8594; new solutions from known subgoal schemas<span style="color: #888888;">, and</span></div>
        <div>&#8226; LLM agent &#8594; can_adapt &#8594; to novel challenges with minimal retraining</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Compositionality via hierarchical memory is a key mechanism in human and artificial problem solving. </li>
    <li>LLMs with access to abstracted memory can recombine known strategies to solve new tasks. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> The principle is known, but its application to LLMs in text games is new.</p>            <p><strong>What Already Exists:</strong> Compositionality and hierarchical memory are established in cognitive science and AI.</p>            <p><strong>What is Novel:</strong> Direct application to LLM agents in text games, and the link to compositional problem solving.</p>
            <p><strong>References:</strong> <ul>
    <li>Botvinick et al. (2019) Hierarchical Reinforcement Learning and Abstraction [compositionality and abstraction]</li>
    <li>Mialon et al. (2023) Augmented Language Models: a Survey [memory and reasoning in LLMs]</li>
</ul>
            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>LLM agents with hierarchical, abstracted memory will learn new text games with shared subgoals more quickly than agents with flat or unstructured memory.</li>
                <li>Agents with compositional memory will solve novel tasks by recombining known subgoal schemas.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>Hierarchical memory may enable LLM agents to autonomously discover new, reusable subgoal schemas not present in training data.</li>
                <li>Compositional memory may allow LLM agents to generate creative solutions that surpass human-designed strategies.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>If hierarchical, abstracted memory does not improve transfer or compositional problem solving, the theory is challenged.</li>
                <li>If agents with hierarchical memory do not outperform those with flat memory on tasks requiring transfer or composition, the theory is called into question.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>The impact of hierarchical memory on tasks with no recurring subgoals or patterns is not addressed. </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> somewhat-related-to-existing</p>
            <p><strong>Explanation:</strong> The theory adapts known principles to a new context (LLMs for text games) with new predictions and mechanisms.</p>
            <p><strong>References:</strong> <ul>
    <li>Botvinick et al. (2019) Hierarchical Reinforcement Learning and Abstraction [hierarchical memory and transfer]</li>
    <li>Mialon et al. (2023) Augmented Language Models: a Survey [memory and reasoning in LLMs]</li>
    <li>Yao et al. (2023) Tree of Thoughts: Deliberate Problem Solving with Large Language Models [structured reasoning in LLMs]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Hierarchical Abstraction in Memory Enables Transfer and Compositionality in LLM Agents for Text Games",
    "theory_description": "This theory proposes that LLM agents equipped with hierarchical, abstracted memory representations—where low-level events are grouped into higher-level schemas or scripts—can transfer knowledge across tasks and compose novel solutions in text games. By organizing memory into multi-level abstractions, agents can recognize recurring patterns, reuse strategies, and adapt to new challenges with minimal retraining.",
    "theory_statements": [
        {
            "law": {
                "law_name": "Hierarchical Memory Supports Transfer Across Tasks",
                "if": [
                    {
                        "subject": "LLM agent",
                        "relation": "has_memory",
                        "object": "hierarchical abstraction of events and actions"
                    },
                    {
                        "subject": "text games",
                        "relation": "share",
                        "object": "common subgoals or patterns"
                    }
                ],
                "then": [
                    {
                        "subject": "LLM agent",
                        "relation": "can_transfer",
                        "object": "strategies and knowledge across games"
                    },
                    {
                        "subject": "LLM agent",
                        "relation": "can_learn",
                        "object": "new games with fewer examples"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Hierarchical memory and abstraction enable transfer learning in cognitive architectures and deep RL.",
                        "uuids": []
                    },
                    {
                        "text": "LLMs with schema-based memory can generalize across related tasks.",
                        "uuids": []
                    },
                    {
                        "text": "Abstraction reduces the need for retraining on similar subgoals.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Hierarchical abstraction and transfer are established in cognitive science and deep RL.",
                    "what_is_novel": "Application to LLM agents in text games, and the explicit link to hierarchical memory for transfer and compositionality.",
                    "classification_explanation": "The principle is established, but its systematic application to LLMs for text games is new.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Botvinick et al. (2019) Hierarchical Reinforcement Learning and Abstraction [hierarchical memory and transfer]",
                        "Mialon et al. (2023) Augmented Language Models: a Survey [memory and reasoning in LLMs]",
                        "Yao et al. (2023) Tree of Thoughts: Deliberate Problem Solving with Large Language Models [structured reasoning in LLMs]"
                    ]
                }
            }
        },
        {
            "law": {
                "law_name": "Hierarchical Memory Enables Compositional Problem Solving",
                "if": [
                    {
                        "subject": "LLM agent",
                        "relation": "has_memory",
                        "object": "multi-level abstraction of actions and outcomes"
                    },
                    {
                        "subject": "text game",
                        "relation": "requires",
                        "object": "novel composition of known subgoals"
                    }
                ],
                "then": [
                    {
                        "subject": "LLM agent",
                        "relation": "can_compose",
                        "object": "new solutions from known subgoal schemas"
                    },
                    {
                        "subject": "LLM agent",
                        "relation": "can_adapt",
                        "object": "to novel challenges with minimal retraining"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Compositionality via hierarchical memory is a key mechanism in human and artificial problem solving.",
                        "uuids": []
                    },
                    {
                        "text": "LLMs with access to abstracted memory can recombine known strategies to solve new tasks.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Compositionality and hierarchical memory are established in cognitive science and AI.",
                    "what_is_novel": "Direct application to LLM agents in text games, and the link to compositional problem solving.",
                    "classification_explanation": "The principle is known, but its application to LLMs in text games is new.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Botvinick et al. (2019) Hierarchical Reinforcement Learning and Abstraction [compositionality and abstraction]",
                        "Mialon et al. (2023) Augmented Language Models: a Survey [memory and reasoning in LLMs]"
                    ]
                }
            }
        }
    ],
    "new_predictions_likely": [
        "LLM agents with hierarchical, abstracted memory will learn new text games with shared subgoals more quickly than agents with flat or unstructured memory.",
        "Agents with compositional memory will solve novel tasks by recombining known subgoal schemas."
    ],
    "new_predictions_unknown": [
        "Hierarchical memory may enable LLM agents to autonomously discover new, reusable subgoal schemas not present in training data.",
        "Compositional memory may allow LLM agents to generate creative solutions that surpass human-designed strategies."
    ],
    "negative_experiments": [
        "If hierarchical, abstracted memory does not improve transfer or compositional problem solving, the theory is challenged.",
        "If agents with hierarchical memory do not outperform those with flat memory on tasks requiring transfer or composition, the theory is called into question."
    ],
    "unaccounted_for": [
        {
            "text": "The impact of hierarchical memory on tasks with no recurring subgoals or patterns is not addressed.",
            "uuids": []
        }
    ],
    "conflicting_evidence": [
        {
            "text": "Some LLM agents can transfer knowledge or compose solutions in simple domains without explicit hierarchical memory, suggesting limited benefit in those cases.",
            "uuids": []
        }
    ],
    "special_cases": [
        "In games with no recurring subgoals or compositional structure, hierarchical memory may provide little benefit.",
        "If abstraction is too coarse or too fine, it may hinder rather than help transfer and composition."
    ],
    "existing_theory": {
        "what_already_exists": "Hierarchical abstraction and compositionality are established in cognitive science and AI.",
        "what_is_novel": "Explicit, systematic application to LLM agents in text games, and the mapping to transfer and compositional problem solving.",
        "classification_explanation": "The theory adapts known principles to a new context (LLMs for text games) with new predictions and mechanisms.",
        "likely_classification": "somewhat-related-to-existing",
        "references": [
            "Botvinick et al. (2019) Hierarchical Reinforcement Learning and Abstraction [hierarchical memory and transfer]",
            "Mialon et al. (2023) Augmented Language Models: a Survey [memory and reasoning in LLMs]",
            "Yao et al. (2023) Tree of Thoughts: Deliberate Problem Solving with Large Language Models [structured reasoning in LLMs]"
        ]
    },
    "reflected_from_theory_index": 3,
    "type": "general",
    "version": "built-theory-from-results-single-theory-reflection2-nov14-2025-LLM-BASELINE-no-evidence-with-matched-control-theory-name",
    "theory_query": "Build a theory of how LLM agents for text games can best use memory to solve text game tasks.",
    "original_theory_id": "theory-594",
    "original_theory_name": "Structured and Interpretable Memory Representations Enable Efficient Planning, Exploration, and Error Recovery in LLM Agents for Text Games",
    "provide_matched_control_thery_name": true,
    "matched_control_theory_name": "Structured and Interpretable Memory Representations Enable Efficient Planning, Exploration, and Error Recovery in LLM Agents for Text Games",
    "model_str": "openai/gpt-4.1-2025-04-14"
}</code></pre>
        </div>
    </div>
</body>
</html>