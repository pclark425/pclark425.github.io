<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Dual-Process Reasoning Theory for Language Models - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Details for theory-1142</h1>

        <div class="section">
            <h2>Theory (General Information)</h2>
            <div class="info-section">
                <p><strong>ID:</strong> theory-1142</p>
                <p><strong>Name:</strong> Dual-Process Reasoning Theory for Language Models</p>
                <p><strong>Type:</strong> general</p>
                <p><strong>Theory Query:</strong> Build a theory of how language models can best perform strict logical reasoning.</p>
                <p><strong>Description:</strong> This theory posits that language models (LMs) can best perform strict logical reasoning when they integrate two distinct but interacting processes: (1) a fast, pattern-matching, context-driven process (analogous to System 1 in human cognition) and (2) a slow, explicit, rule-based logical process (analogous to System 2). The LM must be able to recognize when a task requires strict logical reasoning and dynamically invoke the explicit logical process, possibly by leveraging internal representations or external modules.</p>
                <p><strong>Knowledge Cutoff Year:</strong> -1</p>
                <p><strong>Knowledge Cutoff Month:</strong> -1</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory (Derived From)</h2>
            <p><strong>Derived From:</strong> <span class="empty-note">None</span></p>
            <p><strong>Change Log:</strong> <span class="empty-note">No change log entries.</span></p>
        </div>

        <div class="section">
            <h2>Evaluations of this Theory</h2>
            <p class="empty-note">No evaluations of this theory.</p>
        </div>

        <div class="section">
            <h2>Theory (Details)</h2>

            <h3>Theory Statements</h3>
            <h3>Statement 0: Dynamic Process Selection Law (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; reasoning task &#8594; requires &#8594; strict logical consistency<span style="color: #888888;">, and</span></div>
        <div>&#8226; language model &#8594; has &#8594; dual-process architecture</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; language model &#8594; should invoke &#8594; explicit logical process</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>Human reasoning is best explained by dual-process theories, with System 2 invoked for strict logic. </li>
    <li>LMs often default to pattern-matching but can be prompted to perform explicit logical steps. </li>
    <li>Empirical studies show LMs perform better on logic tasks when forced to 'think step by step'. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> The law adapts dual-process theory to LMs and formalizes the need for dynamic process selection for logic.</p>            <p><strong>What Already Exists:</strong> Dual-process theories are well-established in cognitive science; some LM prompting strategies mimic this.</p>            <p><strong>What is Novel:</strong> Explicitly formalizing the invocation of a rule-based logical process within LMs as a necessary condition for strict logic.</p>
            <p><strong>References:</strong> <ul>
    <li>Evans & Stanovich (2013) Dual-Process Theories of Higher Cognition [dual-process in humans]</li>
    <li>Wei et al. (2022) Chain-of-Thought Prompting Elicits Reasoning in Large Language Models [stepwise reasoning in LMs]</li>
</ul>
            <h3>Statement 1: Process Interaction Law (qualitative)</h3>
<table>
<thead> 
<tr><th style="width: 10%;">Condition</th><th style="width: 90%;">Details</th></tr>
</thead>
<tbody>
<tr>
    <td><strong>IF</strong></td>
    <td>
        <div>&#8226; language model &#8594; has &#8594; dual-process architecture<span style="color: #888888;">, and</span></div>
        <div>&#8226; reasoning task &#8594; contains &#8594; ambiguous or context-dependent elements</div>
    </td>
</tr>
<tr>
    <td><strong>THEN</strong></td>
    <td>
        <div>&#8226; language model &#8594; should use &#8594; pattern-matching process for context disambiguation<span style="color: #888888;">, and</span></div>
        <div>&#8226; language model &#8594; should use &#8594; explicit logical process for formal reasoning</div>
    </td>
</tr>
</tbody>
</table>
            <h4>Supporting Evidence for this Law</h4>
<ol>
    <li>LMs excel at context-sensitive tasks but struggle with strict logic unless guided. </li>
    <li>Human reasoning often uses context to set up formal logic steps. </li>
</ol>            <h4>Existing Law Comparison</h4>
            <p><strong>Likely Classification:</strong> <span style="color: orange; font-weight: bold;">somewhat-related-to-existing</span></p>
            <p><strong>Explanation:</strong> The law extends dual-process theory to LMs and specifies the interaction for logic tasks.</p>            <p><strong>What Already Exists:</strong> Interaction between intuitive and logical processes is known in human cognition.</p>            <p><strong>What is Novel:</strong> Explicit division of labor in LMs for context disambiguation and logic, and the need for their interaction.</p>
            <p><strong>References:</strong> <ul>
    <li>Evans & Stanovich (2013) Dual-Process Theories of Higher Cognition [dual-process in humans]</li>
    <li>Brown et al. (2020) Language Models are Few-Shot Learners [contextual adaptation in LMs]</li>
</ul>
            <h3>New Predictions (Likely outcome)</h3>
            <ol>
                <li>LMs with explicit dual-process architectures or prompting will outperform standard LMs on strict logic tasks.</li>
                <li>Tasks that require both context disambiguation and formal logic will be solved more accurately by LMs that separate these processes.</li>
            </ol>
            <h3>New Predictions (Unknown outcome/high-entropy)</h3>
            <ol>
                <li>LMs may develop emergent internal mechanisms resembling dual-process reasoning even without explicit design.</li>
                <li>The optimal balance between pattern-matching and explicit logic in LMs may depend on task complexity and domain.</li>
            </ol>
            <h3>Negative Experiments</h3>
            <ol>
                <li>If LMs without any explicit dual-process mechanism can match or exceed the performance of dual-process LMs on strict logic tasks, the theory is undermined.</li>
                <li>If separating context and logic processes in LMs leads to worse performance, the theory is called into question.</li>
            </ol>
            <h3>Unaccounted for Evidence</h3>
<ol>
    <li>Some LMs show improved logical reasoning with scale alone, without explicit process separation. </li>
</ol>            <h3>Existing Theory Comparison</h3>
            <p><strong>Likely Classification:</strong> somewhat-related-to-existing</p>
            <p><strong>Explanation:</strong> The theory adapts and extends dual-process theory to LMs, formalizing its necessity for strict logic.</p>
            <p><strong>References:</strong> <ul>
    <li>Evans & Stanovich (2013) Dual-Process Theories of Higher Cognition [dual-process in humans]</li>
    <li>Wei et al. (2022) Chain-of-Thought Prompting Elicits Reasoning in Large Language Models [stepwise reasoning in LMs]</li>
</ul>
        </div>

        <div class="section">
            <h2>Theory Components (Debug)</h2>
            <pre><code>{
    "theory_name": "Dual-Process Reasoning Theory for Language Models",
    "theory_description": "This theory posits that language models (LMs) can best perform strict logical reasoning when they integrate two distinct but interacting processes: (1) a fast, pattern-matching, context-driven process (analogous to System 1 in human cognition) and (2) a slow, explicit, rule-based logical process (analogous to System 2). The LM must be able to recognize when a task requires strict logical reasoning and dynamically invoke the explicit logical process, possibly by leveraging internal representations or external modules.",
    "theory_statements": [
        {
            "law": {
                "law_name": "Dynamic Process Selection Law",
                "if": [
                    {
                        "subject": "reasoning task",
                        "relation": "requires",
                        "object": "strict logical consistency"
                    },
                    {
                        "subject": "language model",
                        "relation": "has",
                        "object": "dual-process architecture"
                    }
                ],
                "then": [
                    {
                        "subject": "language model",
                        "relation": "should invoke",
                        "object": "explicit logical process"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "Human reasoning is best explained by dual-process theories, with System 2 invoked for strict logic.",
                        "uuids": []
                    },
                    {
                        "text": "LMs often default to pattern-matching but can be prompted to perform explicit logical steps.",
                        "uuids": []
                    },
                    {
                        "text": "Empirical studies show LMs perform better on logic tasks when forced to 'think step by step'.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Dual-process theories are well-established in cognitive science; some LM prompting strategies mimic this.",
                    "what_is_novel": "Explicitly formalizing the invocation of a rule-based logical process within LMs as a necessary condition for strict logic.",
                    "classification_explanation": "The law adapts dual-process theory to LMs and formalizes the need for dynamic process selection for logic.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Evans & Stanovich (2013) Dual-Process Theories of Higher Cognition [dual-process in humans]",
                        "Wei et al. (2022) Chain-of-Thought Prompting Elicits Reasoning in Large Language Models [stepwise reasoning in LMs]"
                    ]
                }
            }
        },
        {
            "law": {
                "law_name": "Process Interaction Law",
                "if": [
                    {
                        "subject": "language model",
                        "relation": "has",
                        "object": "dual-process architecture"
                    },
                    {
                        "subject": "reasoning task",
                        "relation": "contains",
                        "object": "ambiguous or context-dependent elements"
                    }
                ],
                "then": [
                    {
                        "subject": "language model",
                        "relation": "should use",
                        "object": "pattern-matching process for context disambiguation"
                    },
                    {
                        "subject": "language model",
                        "relation": "should use",
                        "object": "explicit logical process for formal reasoning"
                    }
                ],
                "supporting_evidence": [
                    {
                        "text": "LMs excel at context-sensitive tasks but struggle with strict logic unless guided.",
                        "uuids": []
                    },
                    {
                        "text": "Human reasoning often uses context to set up formal logic steps.",
                        "uuids": []
                    }
                ],
                "qual_or_quant": "qualitative",
                "existing_law": {
                    "what_already_exists": "Interaction between intuitive and logical processes is known in human cognition.",
                    "what_is_novel": "Explicit division of labor in LMs for context disambiguation and logic, and the need for their interaction.",
                    "classification_explanation": "The law extends dual-process theory to LMs and specifies the interaction for logic tasks.",
                    "likely_classification": "somewhat-related-to-existing",
                    "references": [
                        "Evans & Stanovich (2013) Dual-Process Theories of Higher Cognition [dual-process in humans]",
                        "Brown et al. (2020) Language Models are Few-Shot Learners [contextual adaptation in LMs]"
                    ]
                }
            }
        }
    ],
    "new_predictions_likely": [
        "LMs with explicit dual-process architectures or prompting will outperform standard LMs on strict logic tasks.",
        "Tasks that require both context disambiguation and formal logic will be solved more accurately by LMs that separate these processes."
    ],
    "new_predictions_unknown": [
        "LMs may develop emergent internal mechanisms resembling dual-process reasoning even without explicit design.",
        "The optimal balance between pattern-matching and explicit logic in LMs may depend on task complexity and domain."
    ],
    "negative_experiments": [
        "If LMs without any explicit dual-process mechanism can match or exceed the performance of dual-process LMs on strict logic tasks, the theory is undermined.",
        "If separating context and logic processes in LMs leads to worse performance, the theory is called into question."
    ],
    "unaccounted_for": [
        {
            "text": "Some LMs show improved logical reasoning with scale alone, without explicit process separation.",
            "uuids": []
        }
    ],
    "conflicting_evidence": [
        {
            "text": "Certain logic tasks can be solved by LMs holistically, without clear evidence of process separation.",
            "uuids": []
        }
    ],
    "special_cases": [
        "Tasks that are purely formal and context-free may not benefit from dual-process separation.",
        "If the LM's pattern-matching process is sufficiently powerful, explicit logic may be redundant for some tasks."
    ],
    "existing_theory": {
        "what_already_exists": "Dual-process theory in human cognition; some prompting strategies in LMs.",
        "what_is_novel": "Formalization of dual-process architecture as necessary for strict logic in LMs.",
        "classification_explanation": "The theory adapts and extends dual-process theory to LMs, formalizing its necessity for strict logic.",
        "likely_classification": "somewhat-related-to-existing",
        "references": [
            "Evans & Stanovich (2013) Dual-Process Theories of Higher Cognition [dual-process in humans]",
            "Wei et al. (2022) Chain-of-Thought Prompting Elicits Reasoning in Large Language Models [stepwise reasoning in LMs]"
        ]
    },
    "reflected_from_theory_index": 3,
    "type": "general",
    "version": "built-theory-from-results-single-theory-reflection2-nov14-2025-LLM-BASELINE-no-evidence-without-matched-control-theory-name",
    "theory_query": "Build a theory of how language models can best perform strict logical reasoning.",
    "original_theory_id": "theory-604",
    "original_theory_name": "Prompt Decomposition and Iterative Composition Law",
    "provide_matched_control_thery_name": false,
    "matched_control_theory_name": null,
    "model_str": "openai/gpt-4.1-2025-04-14"
}</code></pre>
        </div>
    </div>
</body>
</html>