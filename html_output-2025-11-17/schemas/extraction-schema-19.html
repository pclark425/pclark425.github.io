<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction Schema extraction-schema-19 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extraction Schema Details for extraction-schema-19</h1>

        <div class="section">
            <h2>Extraction Schema (General Information)</h2>
            <div class="info-section">
                <p><strong>Schema ID:</strong> extraction-schema-19</p>
                <p><strong>Extraction Query:</strong> Extract any mentions of variability, reproducibility, or stochasticity in language model-driven scientific experiments, including sources of variability, reproducibility metrics, and methods to improve reproducibility.</p>
            </div>
        </div>

        <div class="section">
            <h2>Extraction Schema (Details)</h2>
            <table>
                <thead>
                    <tr>
                        <th style="width: 20%;">Field Name</th>
                        <th style="width: 15%;">Type</th>
                        <th style="width: 65%;">Description</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>model_name</strong></td>
                        <td>str</td>
                        <td>The name of the language model used in the scientific experiment (e.g., GPT-4, Claude, LLaMA-2-70B, etc.)</td>
                    </tr>
                    <tr>
                        <td><strong>model_size</strong></td>
                        <td>str</td>
                        <td>The size of the model in parameters (e.g., 7B, 13B, 70B, 175B, etc.). Null if not specified.</td>
                    </tr>
                    <tr>
                        <td><strong>scientific_domain</strong></td>
                        <td>str</td>
                        <td>The scientific domain or field where the LM is being applied (e.g., chemistry, biology, materials science, drug discovery, hypothesis generation, literature review, etc.)</td>
                    </tr>
                    <tr>
                        <td><strong>experimental_task</strong></td>
                        <td>str</td>
                        <td>A specific description of the scientific task or experiment being performed with the LM (e.g., 'generating molecular structures', 'predicting protein functions', 'designing experiments', 'analyzing scientific literature')</td>
                    </tr>
                    <tr>
                        <td><strong>variability_sources</strong></td>
                        <td>str</td>
                        <td>What sources of variability are identified or discussed? (e.g., temperature parameter, sampling methods, prompt variations, model version differences, random seeds, API changes, etc.). Be specific and list all mentioned sources.</td>
                    </tr>
                    <tr>
                        <td><strong>variability_measured</strong></td>
                        <td>bool</td>
                        <td>Does the paper quantitatively measure variability across multiple runs or conditions? (true, false, or null for no information)</td>
                    </tr>
                    <tr>
                        <td><strong>variability_metrics</strong></td>
                        <td>str</td>
                        <td>What metrics are used to measure variability? (e.g., standard deviation, variance, agreement rate, consistency score, etc.). Null if not measured.</td>
                    </tr>
                    <tr>
                        <td><strong>variability_results</strong></td>
                        <td>str</td>
                        <td>What are the quantitative results about variability? Be specific and include numbers with units (e.g., 'agreement rate of 73% across 10 runs', 'standard deviation of 0.15 on accuracy metric'). Null if not reported.</td>
                    </tr>
                    <tr>
                        <td><strong>reproducibility_assessed</strong></td>
                        <td>bool</td>
                        <td>Does the paper assess reproducibility of results (e.g., by attempting to replicate experiments, comparing results across different settings, etc.)? (true, false, or null for no information)</td>
                    </tr>
                    <tr>
                        <td><strong>reproducibility_metrics</strong></td>
                        <td>str</td>
                        <td>What metrics or methods are used to assess reproducibility? (e.g., replication success rate, correlation between runs, exact match rate, etc.). Null if not assessed.</td>
                    </tr>
                    <tr>
                        <td><strong>reproducibility_results</strong></td>
                        <td>str</td>
                        <td>What are the results regarding reproducibility? Be specific and quantitative where possible (e.g., 'only 45% of results could be reproduced', 'correlation of 0.82 between original and replicated runs'). Null if not reported.</td>
                    </tr>
                    <tr>
                        <td><strong>reproducibility_challenges</strong></td>
                        <td>str</td>
                        <td>What specific challenges to reproducibility are identified? (e.g., 'API version changes', 'lack of random seed control', 'prompt sensitivity', 'non-deterministic sampling'). Null if not discussed.</td>
                    </tr>
                    <tr>
                        <td><strong>mitigation_methods</strong></td>
                        <td>str</td>
                        <td>What methods or interventions are proposed or tested to reduce variability or improve reproducibility? (e.g., 'setting temperature to 0', 'using fixed random seeds', 'ensemble methods', 'prompt standardization', 'multiple runs with aggregation'). Null if not discussed.</td>
                    </tr>
                    <tr>
                        <td><strong>mitigation_effectiveness</strong></td>
                        <td>str</td>
                        <td>If mitigation methods are tested, what are the quantitative results showing their effectiveness? (e.g., 'reduced variance from 0.15 to 0.03', 'improved reproducibility from 45% to 89%'). Null if not tested or reported.</td>
                    </tr>
                    <tr>
                        <td><strong>comparison_with_without_controls</strong></td>
                        <td>bool</td>
                        <td>Does the paper compare results with and without reproducibility controls (e.g., with vs without fixed seeds, temperature 0 vs temperature 1, etc.)? (true, false, or null for no information)</td>
                    </tr>
                    <tr>
                        <td><strong>number_of_runs</strong></td>
                        <td>str</td>
                        <td>How many independent runs or replicates were performed in the experiments? (e.g., '10 runs', '100 samples', '5 replicates'). Null if not specified.</td>
                    </tr>
                    <tr>
                        <td><strong>key_findings</strong></td>
                        <td>str</td>
                        <td>What are the key findings or conclusions about variability and reproducibility in this work? Summarize in 1-2 concise sentences with the most important quantitative or qualitative insights.</td>
                    </tr>
                </tbody>
            </table>
        </div>

        <div class="section">
            <h2>Extraction Schema (Debug)</h2>
            <pre><code>{
    "id": "extraction-schema-19",
    "schema": [
        {
            "name": "model_name",
            "type": "str",
            "description": "The name of the language model used in the scientific experiment (e.g., GPT-4, Claude, LLaMA-2-70B, etc.)"
        },
        {
            "name": "model_size",
            "type": "str",
            "description": "The size of the model in parameters (e.g., 7B, 13B, 70B, 175B, etc.). Null if not specified."
        },
        {
            "name": "scientific_domain",
            "type": "str",
            "description": "The scientific domain or field where the LM is being applied (e.g., chemistry, biology, materials science, drug discovery, hypothesis generation, literature review, etc.)"
        },
        {
            "name": "experimental_task",
            "type": "str",
            "description": "A specific description of the scientific task or experiment being performed with the LM (e.g., 'generating molecular structures', 'predicting protein functions', 'designing experiments', 'analyzing scientific literature')"
        },
        {
            "name": "variability_sources",
            "type": "str",
            "description": "What sources of variability are identified or discussed? (e.g., temperature parameter, sampling methods, prompt variations, model version differences, random seeds, API changes, etc.). Be specific and list all mentioned sources."
        },
        {
            "name": "variability_measured",
            "type": "bool",
            "description": "Does the paper quantitatively measure variability across multiple runs or conditions? (true, false, or null for no information)"
        },
        {
            "name": "variability_metrics",
            "type": "str",
            "description": "What metrics are used to measure variability? (e.g., standard deviation, variance, agreement rate, consistency score, etc.). Null if not measured."
        },
        {
            "name": "variability_results",
            "type": "str",
            "description": "What are the quantitative results about variability? Be specific and include numbers with units (e.g., 'agreement rate of 73% across 10 runs', 'standard deviation of 0.15 on accuracy metric'). Null if not reported."
        },
        {
            "name": "reproducibility_assessed",
            "type": "bool",
            "description": "Does the paper assess reproducibility of results (e.g., by attempting to replicate experiments, comparing results across different settings, etc.)? (true, false, or null for no information)"
        },
        {
            "name": "reproducibility_metrics",
            "type": "str",
            "description": "What metrics or methods are used to assess reproducibility? (e.g., replication success rate, correlation between runs, exact match rate, etc.). Null if not assessed."
        },
        {
            "name": "reproducibility_results",
            "type": "str",
            "description": "What are the results regarding reproducibility? Be specific and quantitative where possible (e.g., 'only 45% of results could be reproduced', 'correlation of 0.82 between original and replicated runs'). Null if not reported."
        },
        {
            "name": "reproducibility_challenges",
            "type": "str",
            "description": "What specific challenges to reproducibility are identified? (e.g., 'API version changes', 'lack of random seed control', 'prompt sensitivity', 'non-deterministic sampling'). Null if not discussed."
        },
        {
            "name": "mitigation_methods",
            "type": "str",
            "description": "What methods or interventions are proposed or tested to reduce variability or improve reproducibility? (e.g., 'setting temperature to 0', 'using fixed random seeds', 'ensemble methods', 'prompt standardization', 'multiple runs with aggregation'). Null if not discussed."
        },
        {
            "name": "mitigation_effectiveness",
            "type": "str",
            "description": "If mitigation methods are tested, what are the quantitative results showing their effectiveness? (e.g., 'reduced variance from 0.15 to 0.03', 'improved reproducibility from 45% to 89%'). Null if not tested or reported."
        },
        {
            "name": "comparison_with_without_controls",
            "type": "bool",
            "description": "Does the paper compare results with and without reproducibility controls (e.g., with vs without fixed seeds, temperature 0 vs temperature 1, etc.)? (true, false, or null for no information)"
        },
        {
            "name": "number_of_runs",
            "type": "str",
            "description": "How many independent runs or replicates were performed in the experiments? (e.g., '10 runs', '100 samples', '5 replicates'). Null if not specified."
        },
        {
            "name": "key_findings",
            "type": "str",
            "description": "What are the key findings or conclusions about variability and reproducibility in this work? Summarize in 1-2 concise sentences with the most important quantitative or qualitative insights."
        }
    ],
    "extraction_query": "Extract any mentions of variability, reproducibility, or stochasticity in language model-driven scientific experiments, including sources of variability, reproducibility metrics, and methods to improve reproducibility.",
    "supporting_theory_ids": [],
    "model_str": "claude-sonnet-4-5-20250929"
}</code></pre>
        </div>
    </div>
</body>
</html>