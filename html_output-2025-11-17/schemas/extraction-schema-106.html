<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction Schema extraction-schema-106 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extraction Schema Details for extraction-schema-106</h1>

        <div class="section">
            <h2>Extraction Schema (General Information)</h2>
            <div class="info-section">
                <p><strong>Schema ID:</strong> extraction-schema-106</p>
                <p><strong>Extraction Query:</strong> Extract any mentions of language models (LLMs or neural language models) being used to solve puzzle games that require spatial knowledge (such as Sudoku or other spatial reasoning tasks). Include details about the models, the puzzles, the mechanisms or strategies used, performance metrics, evidence of spatial reasoning, limitations, and comparisons.</p>
            </div>
        </div>

        <div class="section">
            <h2>Extraction Schema (Details)</h2>
            <table>
                <thead>
                    <tr>
                        <th style="width: 20%;">Field Name</th>
                        <th style="width: 15%;">Type</th>
                        <th style="width: 65%;">Description</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>model_name</strong></td>
                        <td>str</td>
                        <td>The name of the language model or neural network used to solve the puzzle (e.g., GPT-4, PaLM, custom transformer, etc.).</td>
                    </tr>
                    <tr>
                        <td><strong>model_description</strong></td>
                        <td>str</td>
                        <td>A brief description of the model, including architecture, size (number of parameters), and any relevant training details.</td>
                    </tr>
                    <tr>
                        <td><strong>puzzle_name</strong></td>
                        <td>str</td>
                        <td>The name of the puzzle or game being solved (e.g., Sudoku, Rubik's Cube, spatial reasoning benchmark, etc.).</td>
                    </tr>
                    <tr>
                        <td><strong>puzzle_description</strong></td>
                        <td>str</td>
                        <td>A brief description of the puzzle/game, with emphasis on the spatial knowledge or reasoning required.</td>
                    </tr>
                    <tr>
                        <td><strong>mechanism_or_strategy</strong></td>
                        <td>str</td>
                        <td>Description of the mechanism, strategy, or approach used by the model to solve the puzzle (e.g., chain-of-thought prompting, external tools, explicit spatial representations, iterative reasoning, etc.).</td>
                    </tr>
                    <tr>
                        <td><strong>evidence_of_spatial_reasoning</strong></td>
                        <td>str</td>
                        <td>Any evidence or analysis showing that the model is using spatial reasoning (e.g., probing, ablation studies, qualitative analysis, visualization of internal representations, etc.).</td>
                    </tr>
                    <tr>
                        <td><strong>performance_metrics</strong></td>
                        <td>str</td>
                        <td>Performance of the model on the puzzle/game (e.g., accuracy, success rate, time to solve, etc.; include numerical values and units if available).</td>
                    </tr>
                    <tr>
                        <td><strong>limitations_or_failure_cases</strong></td>
                        <td>str</td>
                        <td>Any reported limitations, failure cases, or challenges faced by the model in solving spatial puzzles.</td>
                    </tr>
                    <tr>
                        <td><strong>comparison_baseline</strong></td>
                        <td>str</td>
                        <td>Any comparisons to other models, human performance, or non-spatial tasks (e.g., 'model outperforms humans', 'model performs worse than on non-spatial puzzles', etc.).</td>
                    </tr>
                </tbody>
            </table>
        </div>

        <div class="section">
            <h2>Extraction Schema (Debug)</h2>
            <pre><code>{
    "id": "extraction-schema-106",
    "schema": [
        {
            "name": "model_name",
            "type": "str",
            "description": "The name of the language model or neural network used to solve the puzzle (e.g., GPT-4, PaLM, custom transformer, etc.)."
        },
        {
            "name": "model_description",
            "type": "str",
            "description": "A brief description of the model, including architecture, size (number of parameters), and any relevant training details."
        },
        {
            "name": "puzzle_name",
            "type": "str",
            "description": "The name of the puzzle or game being solved (e.g., Sudoku, Rubik's Cube, spatial reasoning benchmark, etc.)."
        },
        {
            "name": "puzzle_description",
            "type": "str",
            "description": "A brief description of the puzzle/game, with emphasis on the spatial knowledge or reasoning required."
        },
        {
            "name": "mechanism_or_strategy",
            "type": "str",
            "description": "Description of the mechanism, strategy, or approach used by the model to solve the puzzle (e.g., chain-of-thought prompting, external tools, explicit spatial representations, iterative reasoning, etc.)."
        },
        {
            "name": "evidence_of_spatial_reasoning",
            "type": "str",
            "description": "Any evidence or analysis showing that the model is using spatial reasoning (e.g., probing, ablation studies, qualitative analysis, visualization of internal representations, etc.)."
        },
        {
            "name": "performance_metrics",
            "type": "str",
            "description": "Performance of the model on the puzzle/game (e.g., accuracy, success rate, time to solve, etc.; include numerical values and units if available)."
        },
        {
            "name": "limitations_or_failure_cases",
            "type": "str",
            "description": "Any reported limitations, failure cases, or challenges faced by the model in solving spatial puzzles."
        },
        {
            "name": "comparison_baseline",
            "type": "str",
            "description": "Any comparisons to other models, human performance, or non-spatial tasks (e.g., 'model outperforms humans', 'model performs worse than on non-spatial puzzles', etc.)."
        }
    ],
    "extraction_query": "Extract any mentions of language models (LLMs or neural language models) being used to solve puzzle games that require spatial knowledge (such as Sudoku or other spatial reasoning tasks). Include details about the models, the puzzles, the mechanisms or strategies used, performance metrics, evidence of spatial reasoning, limitations, and comparisons.",
    "supporting_theory_ids": [],
    "model_str": "openai/gpt-4.1-2025-04-14"
}</code></pre>
        </div>
    </div>
</body>
</html>