<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction Schema extraction-schema-119 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extraction Schema Details for extraction-schema-119</h1>

        <div class="section">
            <h2>Extraction Schema (General Information)</h2>
            <div class="info-section">
                <p><strong>Schema ID:</strong> extraction-schema-119</p>
                <p><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) or AI systems being used to extract, discover, or distill quantitative laws, mathematical relationships, or empirical equations from large collections of scientific or scholarly papers.</p>
            </div>
        </div>

        <div class="section">
            <h2>Extraction Schema (Details)</h2>
            <table>
                <thead>
                    <tr>
                        <th style="width: 20%;">Field Name</th>
                        <th style="width: 15%;">Type</th>
                        <th style="width: 65%;">Description</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>model_name</strong></td>
                        <td>str</td>
                        <td>The name of the LLM or AI system used for distilling quantitative laws (e.g., GPT-4, SciBERT, custom model, etc.).</td>
                    </tr>
                    <tr>
                        <td><strong>model_description</strong></td>
                        <td>str</td>
                        <td>A brief description of the LLM or AI system, including architecture, size, and any relevant modifications for the task.</td>
                    </tr>
                    <tr>
                        <td><strong>task_domain</strong></td>
                        <td>str</td>
                        <td>The scientific or scholarly domain(s) from which quantitative laws are being distilled (e.g., physics, biology, materials science, economics, etc.).</td>
                    </tr>
                    <tr>
                        <td><strong>input_corpus_description</strong></td>
                        <td>str</td>
                        <td>A description of the input corpus, including the number of papers, sources, and any relevant filtering or preprocessing steps.</td>
                    </tr>
                    <tr>
                        <td><strong>distillation_method</strong></td>
                        <td>str</td>
                        <td>A concise description of the method or approach used to distill quantitative laws (e.g., prompt engineering, retrieval-augmented generation, fine-tuning, chain-of-thought, symbolic regression, etc.).</td>
                    </tr>
                    <tr>
                        <td><strong>quantitative_law_type</strong></td>
                        <td>str</td>
                        <td>The type of quantitative law or relationship distilled (e.g., mathematical equation, empirical law, statistical correlation, regression model, etc.).</td>
                    </tr>
                    <tr>
                        <td><strong>example_law_extracted</strong></td>
                        <td>str</td>
                        <td>An example of a quantitative law or relationship extracted by the model, as reported in the paper (e.g., a specific equation or empirical relationship).</td>
                    </tr>
                    <tr>
                        <td><strong>evaluation_method</strong></td>
                        <td>str</td>
                        <td>How the extracted law(s) were evaluated or validated (e.g., human expert review, comparison to known laws, predictive accuracy, reproducibility, etc.).</td>
                    </tr>
                    <tr>
                        <td><strong>results_summary</strong></td>
                        <td>str</td>
                        <td>A concise summary of the results, including any quantitative performance metrics, success rates, or notable findings.</td>
                    </tr>
                    <tr>
                        <td><strong>limitations_challenges</strong></td>
                        <td>str</td>
                        <td>Any reported limitations, challenges, or failure cases encountered in using LLMs for this task.</td>
                    </tr>
                    <tr>
                        <td><strong>comparison_to_baselines</strong></td>
                        <td>str</td>
                        <td>Any comparisons to baseline methods (e.g., human experts, traditional data mining, other AI models), including performance differences.</td>
                    </tr>
                </tbody>
            </table>
        </div>

        <div class="section">
            <h2>Extraction Schema (Debug)</h2>
            <pre><code>{
    "id": "extraction-schema-119",
    "schema": [
        {
            "name": "model_name",
            "type": "str",
            "description": "The name of the LLM or AI system used for distilling quantitative laws (e.g., GPT-4, SciBERT, custom model, etc.)."
        },
        {
            "name": "model_description",
            "type": "str",
            "description": "A brief description of the LLM or AI system, including architecture, size, and any relevant modifications for the task."
        },
        {
            "name": "task_domain",
            "type": "str",
            "description": "The scientific or scholarly domain(s) from which quantitative laws are being distilled (e.g., physics, biology, materials science, economics, etc.)."
        },
        {
            "name": "input_corpus_description",
            "type": "str",
            "description": "A description of the input corpus, including the number of papers, sources, and any relevant filtering or preprocessing steps."
        },
        {
            "name": "distillation_method",
            "type": "str",
            "description": "A concise description of the method or approach used to distill quantitative laws (e.g., prompt engineering, retrieval-augmented generation, fine-tuning, chain-of-thought, symbolic regression, etc.)."
        },
        {
            "name": "quantitative_law_type",
            "type": "str",
            "description": "The type of quantitative law or relationship distilled (e.g., mathematical equation, empirical law, statistical correlation, regression model, etc.)."
        },
        {
            "name": "example_law_extracted",
            "type": "str",
            "description": "An example of a quantitative law or relationship extracted by the model, as reported in the paper (e.g., a specific equation or empirical relationship)."
        },
        {
            "name": "evaluation_method",
            "type": "str",
            "description": "How the extracted law(s) were evaluated or validated (e.g., human expert review, comparison to known laws, predictive accuracy, reproducibility, etc.)."
        },
        {
            "name": "results_summary",
            "type": "str",
            "description": "A concise summary of the results, including any quantitative performance metrics, success rates, or notable findings."
        },
        {
            "name": "limitations_challenges",
            "type": "str",
            "description": "Any reported limitations, challenges, or failure cases encountered in using LLMs for this task."
        },
        {
            "name": "comparison_to_baselines",
            "type": "str",
            "description": "Any comparisons to baseline methods (e.g., human experts, traditional data mining, other AI models), including performance differences."
        }
    ],
    "extraction_query": "Extract any mentions of large language models (LLMs) or AI systems being used to extract, discover, or distill quantitative laws, mathematical relationships, or empirical equations from large collections of scientific or scholarly papers.",
    "supporting_theory_ids": [],
    "model_str": "openai/gpt-4.1-2025-04-14"
}</code></pre>
        </div>
    </div>
</body>
</html>