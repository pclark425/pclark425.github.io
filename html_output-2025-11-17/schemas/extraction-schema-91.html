<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction Schema extraction-schema-91 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extraction Schema Details for extraction-schema-91</h1>

        <div class="section">
            <h2>Extraction Schema (General Information)</h2>
            <div class="info-section">
                <p><strong>Schema ID:</strong> extraction-schema-91</p>
                <p><strong>Extraction Query:</strong> Extract any mentions of methods, systems, or studies that use large language models (LLMs) to distill theories or synthesize knowledge from large collections of scholarly papers, including details about the method, input corpus, topic/query specification, output, evaluation, results, and limitations.</p>
            </div>
        </div>

        <div class="section">
            <h2>Extraction Schema (Details)</h2>
            <table>
                <thead>
                    <tr>
                        <th style="width: 20%;">Field Name</th>
                        <th style="width: 15%;">Type</th>
                        <th style="width: 65%;">Description</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>system_or_method_name</strong></td>
                        <td>str</td>
                        <td>The name of the LLM-based system, method, or approach used for theory distillation or literature synthesis (e.g. 'SciFact-GPT', 'LLM-based Literature Synthesizer').</td>
                    </tr>
                    <tr>
                        <td><strong>system_or_method_description</strong></td>
                        <td>str</td>
                        <td>A concise description of the system or method, including its main features and how it uses LLMs for theory distillation from scholarly papers.</td>
                    </tr>
                    <tr>
                        <td><strong>input_corpus_description</strong></td>
                        <td>str</td>
                        <td>A description of the input corpus used (e.g. number of papers, domains, sources, size, language, etc.).</td>
                    </tr>
                    <tr>
                        <td><strong>topic_or_query_specification</strong></td>
                        <td>str</td>
                        <td>How the specific topic or query is provided to the system (e.g. natural language prompt, keyword search, structured query, etc.).</td>
                    </tr>
                    <tr>
                        <td><strong>distillation_method</strong></td>
                        <td>str</td>
                        <td>A description of the method or algorithm used by the LLM to distill theories or synthesize knowledge (e.g. prompt engineering, retrieval-augmented generation, chain-of-thought, etc.).</td>
                    </tr>
                    <tr>
                        <td><strong>output_type_and_format</strong></td>
                        <td>str</td>
                        <td>The type and format of the output produced (e.g. theory statement, summary, hypothesis, structured knowledge, etc.).</td>
                    </tr>
                    <tr>
                        <td><strong>evaluation_or_validation_method</strong></td>
                        <td>str</td>
                        <td>How the output is evaluated or validated (e.g. human expert review, benchmark comparison, automated metrics, etc.).</td>
                    </tr>
                    <tr>
                        <td><strong>results_summary</strong></td>
                        <td>str</td>
                        <td>A brief summary of the results, including quantitative or qualitative findings, performance metrics, or notable outcomes.</td>
                    </tr>
                    <tr>
                        <td><strong>limitations_or_challenges</strong></td>
                        <td>str</td>
                        <td>Any reported limitations, challenges, or failure cases of the method (e.g. hallucinations, bias, scalability, domain transfer, etc.).</td>
                    </tr>
                    <tr>
                        <td><strong>comparison_to_baselines_or_humans</strong></td>
                        <td>str</td>
                        <td>Any comparisons to baseline methods or human performance, if reported.</td>
                    </tr>
                </tbody>
            </table>
        </div>

        <div class="section">
            <h2>Extraction Schema (Debug)</h2>
            <pre><code>{
    "id": "extraction-schema-91",
    "schema": [
        {
            "name": "system_or_method_name",
            "type": "str",
            "description": "The name of the LLM-based system, method, or approach used for theory distillation or literature synthesis (e.g. 'SciFact-GPT', 'LLM-based Literature Synthesizer')."
        },
        {
            "name": "system_or_method_description",
            "type": "str",
            "description": "A concise description of the system or method, including its main features and how it uses LLMs for theory distillation from scholarly papers."
        },
        {
            "name": "input_corpus_description",
            "type": "str",
            "description": "A description of the input corpus used (e.g. number of papers, domains, sources, size, language, etc.)."
        },
        {
            "name": "topic_or_query_specification",
            "type": "str",
            "description": "How the specific topic or query is provided to the system (e.g. natural language prompt, keyword search, structured query, etc.)."
        },
        {
            "name": "distillation_method",
            "type": "str",
            "description": "A description of the method or algorithm used by the LLM to distill theories or synthesize knowledge (e.g. prompt engineering, retrieval-augmented generation, chain-of-thought, etc.)."
        },
        {
            "name": "output_type_and_format",
            "type": "str",
            "description": "The type and format of the output produced (e.g. theory statement, summary, hypothesis, structured knowledge, etc.)."
        },
        {
            "name": "evaluation_or_validation_method",
            "type": "str",
            "description": "How the output is evaluated or validated (e.g. human expert review, benchmark comparison, automated metrics, etc.)."
        },
        {
            "name": "results_summary",
            "type": "str",
            "description": "A brief summary of the results, including quantitative or qualitative findings, performance metrics, or notable outcomes."
        },
        {
            "name": "limitations_or_challenges",
            "type": "str",
            "description": "Any reported limitations, challenges, or failure cases of the method (e.g. hallucinations, bias, scalability, domain transfer, etc.)."
        },
        {
            "name": "comparison_to_baselines_or_humans",
            "type": "str",
            "description": "Any comparisons to baseline methods or human performance, if reported."
        }
    ],
    "extraction_query": "Extract any mentions of methods, systems, or studies that use large language models (LLMs) to distill theories or synthesize knowledge from large collections of scholarly papers, including details about the method, input corpus, topic/query specification, output, evaluation, results, and limitations.",
    "supporting_theory_ids": [],
    "model_str": "openai/gpt-4.1-2025-04-14"
}</code></pre>
        </div>
    </div>
</body>
</html>