<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction Schema extraction-schema-3 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extraction Schema Details for extraction-schema-3</h1>

        <div class="section">
            <h2>Extraction Schema (General Information)</h2>
            <div class="info-section">
                <p><strong>Schema ID:</strong> extraction-schema-3</p>
                <p><strong>Extraction Query:</strong> Extract any mentions of how large language models perform arithmetic and mathematical tasks, including details about the models, types of math problems, methods used, and performance results.</p>
            </div>
        </div>

        <div class="section">
            <h2>Extraction Schema (Details)</h2>
            <table>
                <thead>
                    <tr>
                        <th style="width: 20%;">Field Name</th>
                        <th style="width: 15%;">Type</th>
                        <th style="width: 65%;">Description</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>model_name</strong></td>
                        <td>str</td>
                        <td>The name of the large language model evaluated (e.g., GPT-3, PaLM, LLaMA, etc.).</td>
                    </tr>
                    <tr>
                        <td><strong>model_description</strong></td>
                        <td>str</td>
                        <td>A brief description of the model architecture, training data, or unique features relevant to math/arithmetic performance.</td>
                    </tr>
                    <tr>
                        <td><strong>model_size</strong></td>
                        <td>str</td>
                        <td>The size of the model in parameters (e.g., 1B, 7B, 70B, 540B).</td>
                    </tr>
                    <tr>
                        <td><strong>math_task_type</strong></td>
                        <td>str</td>
                        <td>The specific type or category of math/arithmetic problem used for evaluation (e.g., addition, multiplication, algebra, calculus, symbolic integration, word problems, multi-step reasoning).</td>
                    </tr>
                    <tr>
                        <td><strong>evaluation_method</strong></td>
                        <td>str</td>
                        <td>The method or approach used to evaluate the model's math performance (e.g., direct prompting, chain-of-thought prompting, calculator augmentation, fine-tuning, probing).</td>
                    </tr>
                    <tr>
                        <td><strong>performance_metrics</strong></td>
                        <td>str</td>
                        <td>Quantitative or qualitative performance results on the math tasks, including accuracy, error rates, or other relevant metrics, ideally broken down by task type.</td>
                    </tr>
                    <tr>
                        <td><strong>failure_modes</strong></td>
                        <td>str</td>
                        <td>Descriptions of common errors or failure modes observed in the model's math performance (e.g., off-by-one errors, inability to handle long sequences, symbolic manipulation errors).</td>
                    </tr>
                    <tr>
                        <td><strong>mechanistic_insights</strong></td>
                        <td>str</td>
                        <td>Any proposed explanations or mechanistic insights into how the model performs arithmetic/mathematics internally (e.g., learned heuristics, implicit algorithmic structures, memorization vs. reasoning).</td>
                    </tr>
                    <tr>
                        <td><strong>comparison_to_baselines</strong></td>
                        <td>str</td>
                        <td>Comparisons of the model's math performance to other models, classical symbolic solvers, or human baselines.</td>
                    </tr>
                    <tr>
                        <td><strong>impact_of_model_size</strong></td>
                        <td>str</td>
                        <td>Information on how model size affects arithmetic/mathematical performance, if reported.</td>
                    </tr>
                    <tr>
                        <td><strong>impact_of_training_data</strong></td>
                        <td>str</td>
                        <td>Information on how the nature or amount of training data (e.g., inclusion of code, math textbooks, symbolic data) affects math performance.</td>
                    </tr>
                    <tr>
                        <td><strong>use_of_external_tools</strong></td>
                        <td>bool</td>
                        <td>Whether the model uses external tools (e.g., calculators, symbolic math engines) during math problem solving.</td>
                    </tr>
                    <tr>
                        <td><strong>tool_description</strong></td>
                        <td>str</td>
                        <td>If external tools are used, describe the type of tool and how it is integrated.</td>
                    </tr>
                    <tr>
                        <td><strong>role_of_prompting</strong></td>
                        <td>str</td>
                        <td>Descriptions of how different prompting strategies (e.g., chain-of-thought, few-shot examples) influence math performance.</td>
                    </tr>
                    <tr>
                        <td><strong>limitations_and_challenges</strong></td>
                        <td>str</td>
                        <td>Reported limitations or challenges in the model's ability to perform arithmetic/mathematics.</td>
                    </tr>
                </tbody>
            </table>
        </div>

        <div class="section">
            <h2>Extraction Schema (Debug)</h2>
            <pre><code>{
    "id": "extraction-schema-3",
    "schema": [
        {
            "name": "model_name",
            "type": "str",
            "description": "The name of the large language model evaluated (e.g., GPT-3, PaLM, LLaMA, etc.)."
        },
        {
            "name": "model_description",
            "type": "str",
            "description": "A brief description of the model architecture, training data, or unique features relevant to math/arithmetic performance."
        },
        {
            "name": "model_size",
            "type": "str",
            "description": "The size of the model in parameters (e.g., 1B, 7B, 70B, 540B)."
        },
        {
            "name": "math_task_type",
            "type": "str",
            "description": "The specific type or category of math/arithmetic problem used for evaluation (e.g., addition, multiplication, algebra, calculus, symbolic integration, word problems, multi-step reasoning)."
        },
        {
            "name": "evaluation_method",
            "type": "str",
            "description": "The method or approach used to evaluate the model's math performance (e.g., direct prompting, chain-of-thought prompting, calculator augmentation, fine-tuning, probing)."
        },
        {
            "name": "performance_metrics",
            "type": "str",
            "description": "Quantitative or qualitative performance results on the math tasks, including accuracy, error rates, or other relevant metrics, ideally broken down by task type."
        },
        {
            "name": "failure_modes",
            "type": "str",
            "description": "Descriptions of common errors or failure modes observed in the model's math performance (e.g., off-by-one errors, inability to handle long sequences, symbolic manipulation errors)."
        },
        {
            "name": "mechanistic_insights",
            "type": "str",
            "description": "Any proposed explanations or mechanistic insights into how the model performs arithmetic/mathematics internally (e.g., learned heuristics, implicit algorithmic structures, memorization vs. reasoning)."
        },
        {
            "name": "comparison_to_baselines",
            "type": "str",
            "description": "Comparisons of the model's math performance to other models, classical symbolic solvers, or human baselines."
        },
        {
            "name": "impact_of_model_size",
            "type": "str",
            "description": "Information on how model size affects arithmetic/mathematical performance, if reported."
        },
        {
            "name": "impact_of_training_data",
            "type": "str",
            "description": "Information on how the nature or amount of training data (e.g., inclusion of code, math textbooks, symbolic data) affects math performance."
        },
        {
            "name": "use_of_external_tools",
            "type": "bool",
            "description": "Whether the model uses external tools (e.g., calculators, symbolic math engines) during math problem solving."
        },
        {
            "name": "tool_description",
            "type": "str",
            "description": "If external tools are used, describe the type of tool and how it is integrated."
        },
        {
            "name": "role_of_prompting",
            "type": "str",
            "description": "Descriptions of how different prompting strategies (e.g., chain-of-thought, few-shot examples) influence math performance."
        },
        {
            "name": "limitations_and_challenges",
            "type": "str",
            "description": "Reported limitations or challenges in the model's ability to perform arithmetic/mathematics."
        }
    ],
    "extraction_query": "Extract any mentions of how large language models perform arithmetic and mathematical tasks, including details about the models, types of math problems, methods used, and performance results.",
    "supporting_theory_ids": [],
    "model_str": null
}</code></pre>
        </div>
    </div>
</body>
</html>