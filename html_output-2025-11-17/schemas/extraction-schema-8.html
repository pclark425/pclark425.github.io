<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction Schema extraction-schema-8 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extraction Schema Details for extraction-schema-8</h1>

        <div class="section">
            <h2>Extraction Schema (General Information)</h2>
            <div class="info-section">
                <p><strong>Schema ID:</strong> extraction-schema-8</p>
                <p><strong>Extraction Query:</strong> Extract any mentions of evaluations of LLMs on theory-of-mind tasks, focusing on model architecture, training data, task performance, explicit mental state and recursive belief representations, limitations, and proposed improvements.</p>
            </div>
        </div>

        <div class="section">
            <h2>Extraction Schema (Details)</h2>
            <table>
                <thead>
                    <tr>
                        <th style="width: 20%;">Field Name</th>
                        <th style="width: 15%;">Type</th>
                        <th style="width: 65%;">Description</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>model_name</strong></td>
                        <td>str</td>
                        <td>The name of the LLM (e.g., GPT-3, PaLM) evaluated for theory-of-mind capabilities.</td>
                    </tr>
                    <tr>
                        <td><strong>model_description</strong></td>
                        <td>str</td>
                        <td>A brief description of the model including its architecture (e.g., autoregressive transformer) and any modifications relevant to ToM tasks.</td>
                    </tr>
                    <tr>
                        <td><strong>model_size</strong></td>
                        <td>str</td>
                        <td>The size of the model in parameters (e.g., 1B, 7B, 70B) or scale indicator.</td>
                    </tr>
                    <tr>
                        <td><strong>training_data_nature</strong></td>
                        <td>str</td>
                        <td>Details about the training data (e.g., static text corpora, multimodal data) and its potential influence on ToM capabilities.</td>
                    </tr>
                    <tr>
                        <td><strong>task_name</strong></td>
                        <td>str</td>
                        <td>The name of the theory-of-mind task or benchmark used (e.g., false belief, social faux pas, deception detection).</td>
                    </tr>
                    <tr>
                        <td><strong>task_description</strong></td>
                        <td>str</td>
                        <td>A brief description of the ToM task, including which mental states or aspects of social reasoning it evaluates.</td>
                    </tr>
                    <tr>
                        <td><strong>task_type</strong></td>
                        <td>str</td>
                        <td>The type of ToM evaluation (e.g., first-order belief, second-order belief, recursive reasoning).</td>
                    </tr>
                    <tr>
                        <td><strong>performance</strong></td>
                        <td>str</td>
                        <td>Quantitative or qualitative performance results on the ToM task (e.g., accuracy, success rate, specific metrics).</td>
                    </tr>
                    <tr>
                        <td><strong>evaluation_method</strong></td>
                        <td>str</td>
                        <td>The method or protocol used for evaluation (e.g., zero-shot prompting, few-shot prompting, fine-tuning).</td>
                    </tr>
                    <tr>
                        <td><strong>limitations_reported</strong></td>
                        <td>str</td>
                        <td>Any reported limitations or failure modes in the model's ToM performance (e.g., brittleness, poor recursive reasoning, sensitivity to perturbations).</td>
                    </tr>
                    <tr>
                        <td><strong>evidence_of_mental_state_representation</strong></td>
                        <td>bool</td>
                        <td>Indicates whether the paper provides evidence of explicit mental state representations internally (true, false, or null if not mentioned).</td>
                    </tr>
                    <tr>
                        <td><strong>evidence_of_recursive_belief_modeling</strong></td>
                        <td>bool</td>
                        <td>Indicates whether there is evidence that the model performs recursive or higher-order belief reasoning (true, false, or null if not mentioned).</td>
                    </tr>
                    <tr>
                        <td><strong>multimodal_grounding_reported</strong></td>
                        <td>bool</td>
                        <td>Denotes if evaluations included multimodal or interactive contexts to ground social reasoning (true, false, or null if not mentioned).</td>
                    </tr>
                    <tr>
                        <td><strong>symbolic_hybrid_methods</strong></td>
                        <td>str</td>
                        <td>Descriptions of any symbolic reasoning or hybrid approaches applied to improve ToM performance.</td>
                    </tr>
                    <tr>
                        <td><strong>counter_evidence</strong></td>
                        <td>str</td>
                        <td>Evidence or arguments that challenge the theory, such as cases where LLMs perform well on ToM tasks despite structural limitations.</td>
                    </tr>
                    <tr>
                        <td><strong>proposed_improvements</strong></td>
                        <td>str</td>
                        <td>Any proposed methods or interventions to overcome current LLM limitations on ToM tasks (e.g., explicit belief state modules, multimodal training).</td>
                    </tr>
                    <tr>
                        <td><strong>impact_of_model_size</strong></td>
                        <td>str</td>
                        <td>Observations on how model size correlates with performance on theory-of-mind tasks.</td>
                    </tr>
                    <tr>
                        <td><strong>comparison_to_human_performance</strong></td>
                        <td>str</td>
                        <td>Comparisons between the LLM's performance and human-level performance on ToM tasks, if available.</td>
                    </tr>
                </tbody>
            </table>
        </div>

        <div class="section">
            <h2>Extraction Schema (Debug)</h2>
            <pre><code>{
    "id": "extraction-schema-8",
    "schema": [
        {
            "name": "model_name",
            "type": "str",
            "description": "The name of the LLM (e.g., GPT-3, PaLM) evaluated for theory-of-mind capabilities."
        },
        {
            "name": "model_description",
            "type": "str",
            "description": "A brief description of the model including its architecture (e.g., autoregressive transformer) and any modifications relevant to ToM tasks."
        },
        {
            "name": "model_size",
            "type": "str",
            "description": "The size of the model in parameters (e.g., 1B, 7B, 70B) or scale indicator."
        },
        {
            "name": "training_data_nature",
            "type": "str",
            "description": "Details about the training data (e.g., static text corpora, multimodal data) and its potential influence on ToM capabilities."
        },
        {
            "name": "task_name",
            "type": "str",
            "description": "The name of the theory-of-mind task or benchmark used (e.g., false belief, social faux pas, deception detection)."
        },
        {
            "name": "task_description",
            "type": "str",
            "description": "A brief description of the ToM task, including which mental states or aspects of social reasoning it evaluates."
        },
        {
            "name": "task_type",
            "type": "str",
            "description": "The type of ToM evaluation (e.g., first-order belief, second-order belief, recursive reasoning)."
        },
        {
            "name": "performance",
            "type": "str",
            "description": "Quantitative or qualitative performance results on the ToM task (e.g., accuracy, success rate, specific metrics)."
        },
        {
            "name": "evaluation_method",
            "type": "str",
            "description": "The method or protocol used for evaluation (e.g., zero-shot prompting, few-shot prompting, fine-tuning)."
        },
        {
            "name": "limitations_reported",
            "type": "str",
            "description": "Any reported limitations or failure modes in the model's ToM performance (e.g., brittleness, poor recursive reasoning, sensitivity to perturbations)."
        },
        {
            "name": "evidence_of_mental_state_representation",
            "type": "bool",
            "description": "Indicates whether the paper provides evidence of explicit mental state representations internally (true, false, or null if not mentioned)."
        },
        {
            "name": "evidence_of_recursive_belief_modeling",
            "type": "bool",
            "description": "Indicates whether there is evidence that the model performs recursive or higher-order belief reasoning (true, false, or null if not mentioned)."
        },
        {
            "name": "multimodal_grounding_reported",
            "type": "bool",
            "description": "Denotes if evaluations included multimodal or interactive contexts to ground social reasoning (true, false, or null if not mentioned)."
        },
        {
            "name": "symbolic_hybrid_methods",
            "type": "str",
            "description": "Descriptions of any symbolic reasoning or hybrid approaches applied to improve ToM performance."
        },
        {
            "name": "counter_evidence",
            "type": "str",
            "description": "Evidence or arguments that challenge the theory, such as cases where LLMs perform well on ToM tasks despite structural limitations."
        },
        {
            "name": "proposed_improvements",
            "type": "str",
            "description": "Any proposed methods or interventions to overcome current LLM limitations on ToM tasks (e.g., explicit belief state modules, multimodal training)."
        },
        {
            "name": "impact_of_model_size",
            "type": "str",
            "description": "Observations on how model size correlates with performance on theory-of-mind tasks."
        },
        {
            "name": "comparison_to_human_performance",
            "type": "str",
            "description": "Comparisons between the LLM's performance and human-level performance on ToM tasks, if available."
        }
    ],
    "extraction_query": "Extract any mentions of evaluations of LLMs on theory-of-mind tasks, focusing on model architecture, training data, task performance, explicit mental state and recursive belief representations, limitations, and proposed improvements.",
    "supporting_theory_ids": [],
    "model_str": null
}</code></pre>
        </div>
    </div>
</body>
</html>