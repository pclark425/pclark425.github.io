<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction Schema extraction-schema-18 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extraction Schema Details for extraction-schema-18</h1>

        <div class="section">
            <h2>Extraction Schema (General Information)</h2>
            <div class="info-section">
                <p><strong>Schema ID:</strong> extraction-schema-18</p>
                <p><strong>Extraction Query:</strong> Extract any mentions of discrepancies, gaps, or misalignments between natural language descriptions (such as paper descriptions, documentation, or specifications) and their corresponding code implementations in automated experimentation systems, including how these gaps are identified, measured, and their impacts.</p>
            </div>
        </div>

        <div class="section">
            <h2>Extraction Schema (Details)</h2>
            <table>
                <thead>
                    <tr>
                        <th style="width: 20%;">Field Name</th>
                        <th style="width: 15%;">Type</th>
                        <th style="width: 65%;">Description</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>system_name</strong></td>
                        <td>str</td>
                        <td>The name of the system, tool, framework, or experimental setup being discussed (e.g., 'AutoML system', 'experiment tracking platform', 'ML pipeline', etc.)</td>
                    </tr>
                    <tr>
                        <td><strong>system_description</strong></td>
                        <td>str</td>
                        <td>A brief description of the system or experimental context.</td>
                    </tr>
                    <tr>
                        <td><strong>nl_description_type</strong></td>
                        <td>str</td>
                        <td>What type of natural language description is being compared to code? (e.g., 'research paper methods section', 'API documentation', 'algorithm specification', 'experimental protocol', 'README file', etc.)</td>
                    </tr>
                    <tr>
                        <td><strong>code_implementation_type</strong></td>
                        <td>str</td>
                        <td>What type of code implementation is being compared? (e.g., 'Python implementation', 'experiment script', 'library code', 'notebook', etc.)</td>
                    </tr>
                    <tr>
                        <td><strong>gap_type</strong></td>
                        <td>str</td>
                        <td>What type of faithfulness gap or discrepancy was identified? Be specific (e.g., 'hyperparameter mismatch', 'missing preprocessing step', 'different algorithm variant', 'incomplete specification', 'ambiguous description', etc.)</td>
                    </tr>
                    <tr>
                        <td><strong>gap_description</strong></td>
                        <td>str</td>
                        <td>A detailed description of the specific gap or discrepancy found between the natural language description and the code implementation.</td>
                    </tr>
                    <tr>
                        <td><strong>gap_location</strong></td>
                        <td>str</td>
                        <td>Where in the experimental pipeline or system does this gap occur? (e.g., 'data preprocessing', 'model architecture', 'training procedure', 'evaluation metrics', 'hyperparameters', etc.)</td>
                    </tr>
                    <tr>
                        <td><strong>detection_method</strong></td>
                        <td>str</td>
                        <td>How was this faithfulness gap detected or identified? (e.g., 'manual code review', 'automated analysis tool', 'reproducibility study', 'comparison of results', etc.)</td>
                    </tr>
                    <tr>
                        <td><strong>measurement_method</strong></td>
                        <td>str</td>
                        <td>If the gap was quantified or measured, how was it measured? Include any metrics or evaluation approaches used.</td>
                    </tr>
                    <tr>
                        <td><strong>impact_on_results</strong></td>
                        <td>str</td>
                        <td>What was the impact of this faithfulness gap on experimental results or reproducibility? Include quantitative measures if available (e.g., 'performance difference of 5%', 'failed to reproduce results', etc.)</td>
                    </tr>
                    <tr>
                        <td><strong>frequency_or_prevalence</strong></td>
                        <td>str</td>
                        <td>How common or frequent is this type of gap? Include statistics if available (e.g., 'found in 30% of papers examined', 'most common type of discrepancy', etc.)</td>
                    </tr>
                    <tr>
                        <td><strong>root_cause</strong></td>
                        <td>str</td>
                        <td>What is identified as the root cause of this faithfulness gap? (e.g., 'ambiguous natural language', 'implementation details omitted from paper', 'version differences', 'implicit assumptions', etc.)</td>
                    </tr>
                    <tr>
                        <td><strong>mitigation_approach</strong></td>
                        <td>str</td>
                        <td>What approach, if any, is proposed or used to address, reduce, or prevent this type of faithfulness gap?</td>
                    </tr>
                    <tr>
                        <td><strong>mitigation_effectiveness</strong></td>
                        <td>str</td>
                        <td>If a mitigation approach was evaluated, what was its effectiveness? Include quantitative results if available.</td>
                    </tr>
                    <tr>
                        <td><strong>domain_or_field</strong></td>
                        <td>str</td>
                        <td>What domain or field is this study focused on? (e.g., 'machine learning', 'deep learning', 'scientific computing', 'bioinformatics', etc.)</td>
                    </tr>
                    <tr>
                        <td><strong>reproducibility_impact</strong></td>
                        <td>bool</td>
                        <td>Does the paper explicitly discuss how this faithfulness gap affects reproducibility? (true, false, or null for no information)</td>
                    </tr>
                </tbody>
            </table>
        </div>

        <div class="section">
            <h2>Extraction Schema (Debug)</h2>
            <pre><code>{
    "id": "extraction-schema-18",
    "schema": [
        {
            "name": "system_name",
            "type": "str",
            "description": "The name of the system, tool, framework, or experimental setup being discussed (e.g., 'AutoML system', 'experiment tracking platform', 'ML pipeline', etc.)"
        },
        {
            "name": "system_description",
            "type": "str",
            "description": "A brief description of the system or experimental context."
        },
        {
            "name": "nl_description_type",
            "type": "str",
            "description": "What type of natural language description is being compared to code? (e.g., 'research paper methods section', 'API documentation', 'algorithm specification', 'experimental protocol', 'README file', etc.)"
        },
        {
            "name": "code_implementation_type",
            "type": "str",
            "description": "What type of code implementation is being compared? (e.g., 'Python implementation', 'experiment script', 'library code', 'notebook', etc.)"
        },
        {
            "name": "gap_type",
            "type": "str",
            "description": "What type of faithfulness gap or discrepancy was identified? Be specific (e.g., 'hyperparameter mismatch', 'missing preprocessing step', 'different algorithm variant', 'incomplete specification', 'ambiguous description', etc.)"
        },
        {
            "name": "gap_description",
            "type": "str",
            "description": "A detailed description of the specific gap or discrepancy found between the natural language description and the code implementation."
        },
        {
            "name": "gap_location",
            "type": "str",
            "description": "Where in the experimental pipeline or system does this gap occur? (e.g., 'data preprocessing', 'model architecture', 'training procedure', 'evaluation metrics', 'hyperparameters', etc.)"
        },
        {
            "name": "detection_method",
            "type": "str",
            "description": "How was this faithfulness gap detected or identified? (e.g., 'manual code review', 'automated analysis tool', 'reproducibility study', 'comparison of results', etc.)"
        },
        {
            "name": "measurement_method",
            "type": "str",
            "description": "If the gap was quantified or measured, how was it measured? Include any metrics or evaluation approaches used."
        },
        {
            "name": "impact_on_results",
            "type": "str",
            "description": "What was the impact of this faithfulness gap on experimental results or reproducibility? Include quantitative measures if available (e.g., 'performance difference of 5%', 'failed to reproduce results', etc.)"
        },
        {
            "name": "frequency_or_prevalence",
            "type": "str",
            "description": "How common or frequent is this type of gap? Include statistics if available (e.g., 'found in 30% of papers examined', 'most common type of discrepancy', etc.)"
        },
        {
            "name": "root_cause",
            "type": "str",
            "description": "What is identified as the root cause of this faithfulness gap? (e.g., 'ambiguous natural language', 'implementation details omitted from paper', 'version differences', 'implicit assumptions', etc.)"
        },
        {
            "name": "mitigation_approach",
            "type": "str",
            "description": "What approach, if any, is proposed or used to address, reduce, or prevent this type of faithfulness gap?"
        },
        {
            "name": "mitigation_effectiveness",
            "type": "str",
            "description": "If a mitigation approach was evaluated, what was its effectiveness? Include quantitative results if available."
        },
        {
            "name": "domain_or_field",
            "type": "str",
            "description": "What domain or field is this study focused on? (e.g., 'machine learning', 'deep learning', 'scientific computing', 'bioinformatics', etc.)"
        },
        {
            "name": "reproducibility_impact",
            "type": "bool",
            "description": "Does the paper explicitly discuss how this faithfulness gap affects reproducibility? (true, false, or null for no information)"
        }
    ],
    "extraction_query": "Extract any mentions of discrepancies, gaps, or misalignments between natural language descriptions (such as paper descriptions, documentation, or specifications) and their corresponding code implementations in automated experimentation systems, including how these gaps are identified, measured, and their impacts.",
    "supporting_theory_ids": [],
    "model_str": "claude-sonnet-4-5-20250929"
}</code></pre>
        </div>
    </div>
</body>
</html>