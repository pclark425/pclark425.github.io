<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction Schema extraction-schema-120 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extraction Schema Details for extraction-schema-120</h1>

        <div class="section">
            <h2>Extraction Schema (General Information)</h2>
            <div class="info-section">
                <p><strong>Schema ID:</strong> extraction-schema-120</p>
                <p><strong>Extraction Query:</strong> Extract any mentions of LLM-based systems or methods for distilling theories or synthesizing knowledge from large numbers of scholarly papers, including details about the LLMs used, the distillation approach, input and output types, evaluation methods, results, datasets, challenges, and comparisons to other methods.</p>
            </div>
        </div>

        <div class="section">
            <h2>Extraction Schema (Details)</h2>
            <table>
                <thead>
                    <tr>
                        <th style="width: 20%;">Field Name</th>
                        <th style="width: 15%;">Type</th>
                        <th style="width: 65%;">Description</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>system_name</strong></td>
                        <td>str</td>
                        <td>The name of the LLM-based system or method used for theory distillation or knowledge synthesis from scholarly papers (e.g., 'Elicit', 'PaperQA', 'LLM-Reviewer').</td>
                    </tr>
                    <tr>
                        <td><strong>system_description</strong></td>
                        <td>str</td>
                        <td>A brief description of the system or method, including its main purpose and how it operates.</td>
                    </tr>
                    <tr>
                        <td><strong>llm_model_used</strong></td>
                        <td>str</td>
                        <td>The name and version of the large language model(s) used (e.g., 'GPT-4', 'Llama 2-70B', 'PaLM').</td>
                    </tr>
                    <tr>
                        <td><strong>input_type_and_size</strong></td>
                        <td>str</td>
                        <td>A description of the input to the system, including the number and type of scholarly papers processed, and how the topic or query is specified.</td>
                    </tr>
                    <tr>
                        <td><strong>distillation_approach</strong></td>
                        <td>str</td>
                        <td>A description of the approach or method used for distillation (e.g., summarization, argument mining, evidence extraction, knowledge graph construction, chain-of-thought synthesis, etc.).</td>
                    </tr>
                    <tr>
                        <td><strong>output_type</strong></td>
                        <td>str</td>
                        <td>A description of the output produced by the system (e.g., theory, structured summary, knowledge graph, list of claims, etc.).</td>
                    </tr>
                    <tr>
                        <td><strong>evaluation_methods</strong></td>
                        <td>str</td>
                        <td>A description of how the quality or effectiveness of the distilled theory or synthesis is evaluated (e.g., human evaluation, comparison to expert summaries, benchmark tasks, etc.).</td>
                    </tr>
                    <tr>
                        <td><strong>results</strong></td>
                        <td>str</td>
                        <td>A summary of the main results reported, including quantitative or qualitative findings, performance metrics, or user study outcomes.</td>
                    </tr>
                    <tr>
                        <td><strong>datasets_or_benchmarks</strong></td>
                        <td>str</td>
                        <td>The names or descriptions of any datasets or benchmarks used to evaluate the system (e.g., PubMed, S2ORC, custom corpora, etc.).</td>
                    </tr>
                    <tr>
                        <td><strong>challenges_or_limitations</strong></td>
                        <td>str</td>
                        <td>Any challenges, limitations, or failure modes reported for the system or approach.</td>
                    </tr>
                    <tr>
                        <td><strong>comparisons_to_other_methods</strong></td>
                        <td>str</td>
                        <td>Any comparisons made to other (LLM-based or non-LLM) methods for theory distillation or literature synthesis, including relative strengths or weaknesses.</td>
                    </tr>
                </tbody>
            </table>
        </div>

        <div class="section">
            <h2>Extraction Schema (Debug)</h2>
            <pre><code>{
    "id": "extraction-schema-120",
    "schema": [
        {
            "name": "system_name",
            "type": "str",
            "description": "The name of the LLM-based system or method used for theory distillation or knowledge synthesis from scholarly papers (e.g., 'Elicit', 'PaperQA', 'LLM-Reviewer')."
        },
        {
            "name": "system_description",
            "type": "str",
            "description": "A brief description of the system or method, including its main purpose and how it operates."
        },
        {
            "name": "llm_model_used",
            "type": "str",
            "description": "The name and version of the large language model(s) used (e.g., 'GPT-4', 'Llama 2-70B', 'PaLM')."
        },
        {
            "name": "input_type_and_size",
            "type": "str",
            "description": "A description of the input to the system, including the number and type of scholarly papers processed, and how the topic or query is specified."
        },
        {
            "name": "distillation_approach",
            "type": "str",
            "description": "A description of the approach or method used for distillation (e.g., summarization, argument mining, evidence extraction, knowledge graph construction, chain-of-thought synthesis, etc.)."
        },
        {
            "name": "output_type",
            "type": "str",
            "description": "A description of the output produced by the system (e.g., theory, structured summary, knowledge graph, list of claims, etc.)."
        },
        {
            "name": "evaluation_methods",
            "type": "str",
            "description": "A description of how the quality or effectiveness of the distilled theory or synthesis is evaluated (e.g., human evaluation, comparison to expert summaries, benchmark tasks, etc.)."
        },
        {
            "name": "results",
            "type": "str",
            "description": "A summary of the main results reported, including quantitative or qualitative findings, performance metrics, or user study outcomes."
        },
        {
            "name": "datasets_or_benchmarks",
            "type": "str",
            "description": "The names or descriptions of any datasets or benchmarks used to evaluate the system (e.g., PubMed, S2ORC, custom corpora, etc.)."
        },
        {
            "name": "challenges_or_limitations",
            "type": "str",
            "description": "Any challenges, limitations, or failure modes reported for the system or approach."
        },
        {
            "name": "comparisons_to_other_methods",
            "type": "str",
            "description": "Any comparisons made to other (LLM-based or non-LLM) methods for theory distillation or literature synthesis, including relative strengths or weaknesses."
        }
    ],
    "extraction_query": "Extract any mentions of LLM-based systems or methods for distilling theories or synthesizing knowledge from large numbers of scholarly papers, including details about the LLMs used, the distillation approach, input and output types, evaluation methods, results, datasets, challenges, and comparisons to other methods.",
    "supporting_theory_ids": [],
    "model_str": "openai/gpt-4.1-2025-04-14"
}</code></pre>
        </div>
    </div>
</body>
</html>