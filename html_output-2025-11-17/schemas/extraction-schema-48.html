<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction Schema extraction-schema-48 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extraction Schema Details for extraction-schema-48</h1>

        <div class="section">
            <h2>Extraction Schema (General Information)</h2>
            <div class="info-section">
                <p><strong>Schema ID:</strong> extraction-schema-48</p>
                <p><strong>Extraction Query:</strong> Extract any mentions of compositional generalization, systematic generalization, or out-of-distribution generalization experiments, including model architectures, task characteristics, performance metrics, and comparisons across different conditions.</p>
            </div>
        </div>

        <div class="section">
            <h2>Extraction Schema (Details)</h2>
            <table>
                <thead>
                    <tr>
                        <th style="width: 20%;">Field Name</th>
                        <th style="width: 15%;">Type</th>
                        <th style="width: 65%;">Description</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>model_name</strong></td>
                        <td>str</td>
                        <td>The name of the model or agent being evaluated (e.g., 'BERT', 'GPT-3', 'T5', 'Transformer', 'LSTM', 'Neural Module Network', etc.)</td>
                    </tr>
                    <tr>
                        <td><strong>model_description</strong></td>
                        <td>str</td>
                        <td>A brief description of the model architecture and key characteristics (e.g., 'standard Transformer encoder-decoder', 'modular neural network with separate reasoning modules', 'hierarchical reinforcement learning agent', etc.)</td>
                    </tr>
                    <tr>
                        <td><strong>model_size</strong></td>
                        <td>str</td>
                        <td>Size of the model in parameters if mentioned (e.g., '110M', '1.5B', '175B', 'small/base/large'). Null if not applicable or not mentioned.</td>
                    </tr>
                    <tr>
                        <td><strong>is_pretrained</strong></td>
                        <td>bool</td>
                        <td>Is the model pretrained on a large corpus before being evaluated/fine-tuned on the compositional task? (true, false, or null for no information)</td>
                    </tr>
                    <tr>
                        <td><strong>architectural_features</strong></td>
                        <td>str</td>
                        <td>What special architectural features does the model have that might be relevant to compositional generalization? (e.g., 'modular structure', 'explicit memory', 'attention mechanisms', 'hierarchical structure', 'symbolic components', 'none/standard architecture', etc.)</td>
                    </tr>
                    <tr>
                        <td><strong>task_domain</strong></td>
                        <td>str</td>
                        <td>What domain is the compositional task in? (e.g., 'linguistic/semantic', 'procedural/sequential', 'hierarchical planning', 'visual reasoning', 'mathematical reasoning', 'program synthesis', etc.)</td>
                    </tr>
                    <tr>
                        <td><strong>task_name</strong></td>
                        <td>str</td>
                        <td>The name of the benchmark or task (e.g., 'SCAN', 'CFQ', 'bAbI', 'COGS', 'gSCAN', 'TextWorld', 'Minecraft', etc.)</td>
                    </tr>
                    <tr>
                        <td><strong>task_description</strong></td>
                        <td>str</td>
                        <td>A detailed description of what the task involves and what makes it compositional.</td>
                    </tr>
                    <tr>
                        <td><strong>compositional_depth</strong></td>
                        <td>str</td>
                        <td>What is the compositional depth or complexity of the task? (e.g., 'n=1 to n=5 supporting facts', '2-step to 10-step procedures', 'nesting depth 1-4', etc.). Null if not specified.</td>
                    </tr>
                    <tr>
                        <td><strong>composition_type</strong></td>
                        <td>str</td>
                        <td>What type of composition is being tested? (e.g., 'novel word combinations', 'novel action sequences', 'hierarchical goal decomposition', 'nested logical operations', 'function composition', etc.)</td>
                    </tr>
                    <tr>
                        <td><strong>split_type</strong></td>
                        <td>str</td>
                        <td>How is the train/test split designed to test compositional generalization? (e.g., 'novel combinations of seen primitives', 'longer sequences than training', 'novel structural patterns', 'IID split', 'random split', etc.)</td>
                    </tr>
                    <tr>
                        <td><strong>training_strategy</strong></td>
                        <td>str</td>
                        <td>What training strategy is used? (e.g., 'standard supervised learning', 'curriculum learning', 'data augmentation', 'meta-learning', 'few-shot learning', 'inoculation with OOD examples', etc.)</td>
                    </tr>
                    <tr>
                        <td><strong>curriculum_details</strong></td>
                        <td>str</td>
                        <td>If curriculum learning is used, describe the curriculum strategy in detail. Null if no curriculum.</td>
                    </tr>
                    <tr>
                        <td><strong>inoculation_details</strong></td>
                        <td>str</td>
                        <td>If the model is exposed to out-of-distribution or compositional examples during training (inoculation), describe how many examples and what type. Null if not applicable.</td>
                    </tr>
                    <tr>
                        <td><strong>iid_performance</strong></td>
                        <td>str</td>
                        <td>What is the model's performance on in-distribution (IID) test data? Include metrics with units (e.g., '95% accuracy', '0.85 F1', etc.). Null if not reported.</td>
                    </tr>
                    <tr>
                        <td><strong>compositional_performance</strong></td>
                        <td>str</td>
                        <td>What is the model's performance on compositional generalization (novel combinations)? Include metrics and breakdowns by complexity if available (e.g., '60% accuracy overall, 80% for n=2, 40% for n=3', etc.). Null if not reported.</td>
                    </tr>
                    <tr>
                        <td><strong>generalization_gap</strong></td>
                        <td>str</td>
                        <td>What is the gap between IID and compositional generalization performance? Calculate or extract the difference (e.g., '35% gap', 'drops from 95% to 60%', etc.). Null if cannot be determined.</td>
                    </tr>
                    <tr>
                        <td><strong>performance_by_depth</strong></td>
                        <td>str</td>
                        <td>If reported, what is the performance breakdown by compositional depth or complexity level? (e.g., 'n=1: 90%, n=2: 75%, n=3: 45%, n=4: 20%', etc.). Null if not reported.</td>
                    </tr>
                    <tr>
                        <td><strong>performance_by_composition_type</strong></td>
                        <td>str</td>
                        <td>If reported, what is the performance breakdown by different types of compositions or phenomena? (e.g., 'simple conjunctions: 85%, nested clauses: 45%, specific relations: 30%', etc.). Null if not reported.</td>
                    </tr>
                    <tr>
                        <td><strong>has_baseline_comparison</strong></td>
                        <td>bool</td>
                        <td>Does the paper compare the main approach against baselines (e.g., standard architecture vs modular, with curriculum vs without, pretrained vs not pretrained)? (true, false, or null)</td>
                    </tr>
                    <tr>
                        <td><strong>baseline_comparisons</strong></td>
                        <td>str</td>
                        <td>If baselines are compared, describe each baseline and its compositional generalization performance. Be specific about what differs between conditions.</td>
                    </tr>
                    <tr>
                        <td><strong>architectural_comparison</strong></td>
                        <td>str</td>
                        <td>If different architectures are compared on the same task, describe the architectures and their relative compositional generalization performance. Null if not applicable.</td>
                    </tr>
                    <tr>
                        <td><strong>scale_effects</strong></td>
                        <td>str</td>
                        <td>If multiple model sizes are tested, describe how compositional generalization changes with scale (e.g., 'gap reduces from 40% to 25% when scaling from 110M to 1.5B parameters', etc.). Null if not reported.</td>
                    </tr>
                    <tr>
                        <td><strong>transfer_results</strong></td>
                        <td>str</td>
                        <td>If the paper studies transfer learning or pretraining effects on compositional generalization, describe the results (e.g., 'pretraining reduces gap by 15%', 'transfer from task A to task B improves sample efficiency 3x', etc.). Null if not reported.</td>
                    </tr>
                    <tr>
                        <td><strong>key_findings</strong></td>
                        <td>str</td>
                        <td>What are the key findings about compositional generalization in this work? Be specific, information-dense, and focus on quantitative results (e.g., 'modular architecture reduces gap from 45% to 20%', 'performance degrades exponentially with compositional depth', 'curriculum provides no benefit for simple compositions but 30% improvement for complex ones', etc.)</td>
                    </tr>
                    <tr>
                        <td><strong>failure_analysis</strong></td>
                        <td>str</td>
                        <td>If the paper analyzes what types of compositional generalizations fail, describe the findings (e.g., 'fails primarily on double negations and nested quantifiers', 'errors increase with sequence length', etc.). Null if not reported.</td>
                    </tr>
                    <tr>
                        <td><strong>success_conditions</strong></td>
                        <td>str</td>
                        <td>Under what conditions does the model successfully achieve compositional generalization? (e.g., 'succeeds when training includes diverse primitive combinations', 'requires explicit structural bias', 'only works for shallow compositions', etc.). Null if not discussed.</td>
                    </tr>
                </tbody>
            </table>
        </div>

        <div class="section">
            <h2>Extraction Schema (Debug)</h2>
            <pre><code>{
    "id": "extraction-schema-48",
    "schema": [
        {
            "name": "model_name",
            "type": "str",
            "description": "The name of the model or agent being evaluated (e.g., 'BERT', 'GPT-3', 'T5', 'Transformer', 'LSTM', 'Neural Module Network', etc.)"
        },
        {
            "name": "model_description",
            "type": "str",
            "description": "A brief description of the model architecture and key characteristics (e.g., 'standard Transformer encoder-decoder', 'modular neural network with separate reasoning modules', 'hierarchical reinforcement learning agent', etc.)"
        },
        {
            "name": "model_size",
            "type": "str",
            "description": "Size of the model in parameters if mentioned (e.g., '110M', '1.5B', '175B', 'small/base/large'). Null if not applicable or not mentioned."
        },
        {
            "name": "is_pretrained",
            "type": "bool",
            "description": "Is the model pretrained on a large corpus before being evaluated/fine-tuned on the compositional task? (true, false, or null for no information)"
        },
        {
            "name": "architectural_features",
            "type": "str",
            "description": "What special architectural features does the model have that might be relevant to compositional generalization? (e.g., 'modular structure', 'explicit memory', 'attention mechanisms', 'hierarchical structure', 'symbolic components', 'none/standard architecture', etc.)"
        },
        {
            "name": "task_domain",
            "type": "str",
            "description": "What domain is the compositional task in? (e.g., 'linguistic/semantic', 'procedural/sequential', 'hierarchical planning', 'visual reasoning', 'mathematical reasoning', 'program synthesis', etc.)"
        },
        {
            "name": "task_name",
            "type": "str",
            "description": "The name of the benchmark or task (e.g., 'SCAN', 'CFQ', 'bAbI', 'COGS', 'gSCAN', 'TextWorld', 'Minecraft', etc.)"
        },
        {
            "name": "task_description",
            "type": "str",
            "description": "A detailed description of what the task involves and what makes it compositional."
        },
        {
            "name": "compositional_depth",
            "type": "str",
            "description": "What is the compositional depth or complexity of the task? (e.g., 'n=1 to n=5 supporting facts', '2-step to 10-step procedures', 'nesting depth 1-4', etc.). Null if not specified."
        },
        {
            "name": "composition_type",
            "type": "str",
            "description": "What type of composition is being tested? (e.g., 'novel word combinations', 'novel action sequences', 'hierarchical goal decomposition', 'nested logical operations', 'function composition', etc.)"
        },
        {
            "name": "split_type",
            "type": "str",
            "description": "How is the train/test split designed to test compositional generalization? (e.g., 'novel combinations of seen primitives', 'longer sequences than training', 'novel structural patterns', 'IID split', 'random split', etc.)"
        },
        {
            "name": "training_strategy",
            "type": "str",
            "description": "What training strategy is used? (e.g., 'standard supervised learning', 'curriculum learning', 'data augmentation', 'meta-learning', 'few-shot learning', 'inoculation with OOD examples', etc.)"
        },
        {
            "name": "curriculum_details",
            "type": "str",
            "description": "If curriculum learning is used, describe the curriculum strategy in detail. Null if no curriculum."
        },
        {
            "name": "inoculation_details",
            "type": "str",
            "description": "If the model is exposed to out-of-distribution or compositional examples during training (inoculation), describe how many examples and what type. Null if not applicable."
        },
        {
            "name": "iid_performance",
            "type": "str",
            "description": "What is the model's performance on in-distribution (IID) test data? Include metrics with units (e.g., '95% accuracy', '0.85 F1', etc.). Null if not reported."
        },
        {
            "name": "compositional_performance",
            "type": "str",
            "description": "What is the model's performance on compositional generalization (novel combinations)? Include metrics and breakdowns by complexity if available (e.g., '60% accuracy overall, 80% for n=2, 40% for n=3', etc.). Null if not reported."
        },
        {
            "name": "generalization_gap",
            "type": "str",
            "description": "What is the gap between IID and compositional generalization performance? Calculate or extract the difference (e.g., '35% gap', 'drops from 95% to 60%', etc.). Null if cannot be determined."
        },
        {
            "name": "performance_by_depth",
            "type": "str",
            "description": "If reported, what is the performance breakdown by compositional depth or complexity level? (e.g., 'n=1: 90%, n=2: 75%, n=3: 45%, n=4: 20%', etc.). Null if not reported."
        },
        {
            "name": "performance_by_composition_type",
            "type": "str",
            "description": "If reported, what is the performance breakdown by different types of compositions or phenomena? (e.g., 'simple conjunctions: 85%, nested clauses: 45%, specific relations: 30%', etc.). Null if not reported."
        },
        {
            "name": "has_baseline_comparison",
            "type": "bool",
            "description": "Does the paper compare the main approach against baselines (e.g., standard architecture vs modular, with curriculum vs without, pretrained vs not pretrained)? (true, false, or null)"
        },
        {
            "name": "baseline_comparisons",
            "type": "str",
            "description": "If baselines are compared, describe each baseline and its compositional generalization performance. Be specific about what differs between conditions."
        },
        {
            "name": "architectural_comparison",
            "type": "str",
            "description": "If different architectures are compared on the same task, describe the architectures and their relative compositional generalization performance. Null if not applicable."
        },
        {
            "name": "scale_effects",
            "type": "str",
            "description": "If multiple model sizes are tested, describe how compositional generalization changes with scale (e.g., 'gap reduces from 40% to 25% when scaling from 110M to 1.5B parameters', etc.). Null if not reported."
        },
        {
            "name": "transfer_results",
            "type": "str",
            "description": "If the paper studies transfer learning or pretraining effects on compositional generalization, describe the results (e.g., 'pretraining reduces gap by 15%', 'transfer from task A to task B improves sample efficiency 3x', etc.). Null if not reported."
        },
        {
            "name": "key_findings",
            "type": "str",
            "description": "What are the key findings about compositional generalization in this work? Be specific, information-dense, and focus on quantitative results (e.g., 'modular architecture reduces gap from 45% to 20%', 'performance degrades exponentially with compositional depth', 'curriculum provides no benefit for simple compositions but 30% improvement for complex ones', etc.)"
        },
        {
            "name": "failure_analysis",
            "type": "str",
            "description": "If the paper analyzes what types of compositional generalizations fail, describe the findings (e.g., 'fails primarily on double negations and nested quantifiers', 'errors increase with sequence length', etc.). Null if not reported."
        },
        {
            "name": "success_conditions",
            "type": "str",
            "description": "Under what conditions does the model successfully achieve compositional generalization? (e.g., 'succeeds when training includes diverse primitive combinations', 'requires explicit structural bias', 'only works for shallow compositions', etc.). Null if not discussed."
        }
    ],
    "extraction_query": "Extract any mentions of compositional generalization, systematic generalization, or out-of-distribution generalization experiments, including model architectures, task characteristics, performance metrics, and comparisons across different conditions.",
    "supporting_theory_ids": [],
    "model_str": "claude-sonnet-4-5-20250929"
}</code></pre>
        </div>
    </div>
</body>
</html>