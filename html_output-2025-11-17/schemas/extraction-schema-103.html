<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction Schema extraction-schema-103 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extraction Schema Details for extraction-schema-103</h1>

        <div class="section">
            <h2>Extraction Schema (General Information)</h2>
            <div class="info-section">
                <p><strong>Schema ID:</strong> extraction-schema-103</p>
                <p><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details about the agent, the type of memory used, the tasks or benchmarks, performance with and without memory, comparisons, and any reported insights or limitations.</p>
            </div>
        </div>

        <div class="section">
            <h2>Extraction Schema (Details)</h2>
            <table>
                <thead>
                    <tr>
                        <th style="width: 20%;">Field Name</th>
                        <th style="width: 15%;">Type</th>
                        <th style="width: 65%;">Description</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>agent_name</strong></td>
                        <td>str</td>
                        <td>The name of the language model agent or system being evaluated (e.g., 'ReAct', 'MemGPT', 'Toolformer').</td>
                    </tr>
                    <tr>
                        <td><strong>agent_description</strong></td>
                        <td>str</td>
                        <td>A brief description of the agent, including its architecture, purpose, or unique features.</td>
                    </tr>
                    <tr>
                        <td><strong>memory_type</strong></td>
                        <td>str</td>
                        <td>The type of memory used by the agent (e.g., external memory, retrieval-augmented, episodic memory, scratchpad, vector database, etc.).</td>
                    </tr>
                    <tr>
                        <td><strong>memory_description</strong></td>
                        <td>str</td>
                        <td>A concise description of how the memory is implemented and used by the agent (e.g., 'retrieves relevant documents from a vector store', 'maintains a running scratchpad of previous steps', etc.).</td>
                    </tr>
                    <tr>
                        <td><strong>task_name</strong></td>
                        <td>str</td>
                        <td>The name of the task or problem the agent is solving (e.g., 'question answering', 'code generation', 'multi-step reasoning').</td>
                    </tr>
                    <tr>
                        <td><strong>task_description</strong></td>
                        <td>str</td>
                        <td>A brief description of the task or benchmark, including any relevant details about its structure or requirements.</td>
                    </tr>
                    <tr>
                        <td><strong>benchmark_name</strong></td>
                        <td>str</td>
                        <td>The name of the benchmark or dataset used to evaluate the agent (e.g., 'HotpotQA', 'ALFWorld', 'ARC', etc.).</td>
                    </tr>
                    <tr>
                        <td><strong>performance_with_memory</strong></td>
                        <td>str</td>
                        <td>The performance of the agent on the task when using memory (include numerical results and units if available; null if not reported).</td>
                    </tr>
                    <tr>
                        <td><strong>performance_without_memory</strong></td>
                        <td>str</td>
                        <td>The performance of the agent on the task without using memory (include numerical results and units if available; null if not reported).</td>
                    </tr>
                    <tr>
                        <td><strong>has_performance_with_without_memory</strong></td>
                        <td>bool</td>
                        <td>Does the paper report performance for both with and without memory? (true, false, or null if no information)</td>
                    </tr>
                    <tr>
                        <td><strong>memory_comparison_summary</strong></td>
                        <td>str</td>
                        <td>A brief summary of any comparisons, ablations, or findings about the effect of memory on agent performance (e.g., 'memory improves multi-step reasoning by 15%', 'no significant difference observed', etc.).</td>
                    </tr>
                    <tr>
                        <td><strong>limitations_or_challenges</strong></td>
                        <td>str</td>
                        <td>Any reported limitations, challenges, or failure cases related to the use of memory in the agent (e.g., 'memory retrieval errors', 'scaling issues', 'catastrophic forgetting').</td>
                    </tr>
                    <tr>
                        <td><strong>key_insights</strong></td>
                        <td>str</td>
                        <td>Any key insights, recommendations, or conclusions from the paper about how memory should be used by language model agents to solve tasks.</td>
                    </tr>
                </tbody>
            </table>
        </div>

        <div class="section">
            <h2>Extraction Schema (Debug)</h2>
            <pre><code>{
    "id": "extraction-schema-103",
    "schema": [
        {
            "name": "agent_name",
            "type": "str",
            "description": "The name of the language model agent or system being evaluated (e.g., 'ReAct', 'MemGPT', 'Toolformer')."
        },
        {
            "name": "agent_description",
            "type": "str",
            "description": "A brief description of the agent, including its architecture, purpose, or unique features."
        },
        {
            "name": "memory_type",
            "type": "str",
            "description": "The type of memory used by the agent (e.g., external memory, retrieval-augmented, episodic memory, scratchpad, vector database, etc.)."
        },
        {
            "name": "memory_description",
            "type": "str",
            "description": "A concise description of how the memory is implemented and used by the agent (e.g., 'retrieves relevant documents from a vector store', 'maintains a running scratchpad of previous steps', etc.)."
        },
        {
            "name": "task_name",
            "type": "str",
            "description": "The name of the task or problem the agent is solving (e.g., 'question answering', 'code generation', 'multi-step reasoning')."
        },
        {
            "name": "task_description",
            "type": "str",
            "description": "A brief description of the task or benchmark, including any relevant details about its structure or requirements."
        },
        {
            "name": "benchmark_name",
            "type": "str",
            "description": "The name of the benchmark or dataset used to evaluate the agent (e.g., 'HotpotQA', 'ALFWorld', 'ARC', etc.)."
        },
        {
            "name": "performance_with_memory",
            "type": "str",
            "description": "The performance of the agent on the task when using memory (include numerical results and units if available; null if not reported)."
        },
        {
            "name": "performance_without_memory",
            "type": "str",
            "description": "The performance of the agent on the task without using memory (include numerical results and units if available; null if not reported)."
        },
        {
            "name": "has_performance_with_without_memory",
            "type": "bool",
            "description": "Does the paper report performance for both with and without memory? (true, false, or null if no information)"
        },
        {
            "name": "memory_comparison_summary",
            "type": "str",
            "description": "A brief summary of any comparisons, ablations, or findings about the effect of memory on agent performance (e.g., 'memory improves multi-step reasoning by 15%', 'no significant difference observed', etc.)."
        },
        {
            "name": "limitations_or_challenges",
            "type": "str",
            "description": "Any reported limitations, challenges, or failure cases related to the use of memory in the agent (e.g., 'memory retrieval errors', 'scaling issues', 'catastrophic forgetting')."
        },
        {
            "name": "key_insights",
            "type": "str",
            "description": "Any key insights, recommendations, or conclusions from the paper about how memory should be used by language model agents to solve tasks."
        }
    ],
    "extraction_query": "Extract any mentions of language model agents using memory to solve tasks, including details about the agent, the type of memory used, the tasks or benchmarks, performance with and without memory, comparisons, and any reported insights or limitations.",
    "supporting_theory_ids": [],
    "model_str": "openai/gpt-4.1-2025-04-14"
}</code></pre>
        </div>
    </div>
</body>
</html>