<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Theory Evaluation theory-evaluation-20 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Evaluation Details for theory-evaluation-20</h1>

        <div class="section">
            <h2>Theory Evaluation (General Information)</h2>
            <div class="info-section">
                <p><strong>Evaluation ID:</strong> theory-evaluation-20</p>
                <p><strong>This evaluation is for theory ID:</strong> <a href="../theories/theory-177.html">theory-177</a></p>
                <p><strong>This evaluation resulted in these revised theories:</strong> <a href="../theories/theory-380.html">theory-380</a></p>
                <p><strong>Overall Support or Contradict:</strong> support</p>
                <p><strong>Overall Support or Contradict Explanation:</strong> The new evidence strongly supports the theory's core claims that compositional generalization gaps exist, vary systematically by depth and composition type, and can be reduced through curriculum strategies and architectural support. However, the evidence reveals the mechanisms are more nuanced than stated, requiring refinements to emphasize coverage principles, training regimes, and specific architectural recipes rather than fixed percentage gaps and domain-based categorization.</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory Evaluation (Components)</h2>

            <h3>Fully Supporting Evidence</h3>
<ol>
    <li>CompoST benchmark shows large compositional gaps in SPARQL generation: training macro F1 ~0.92-0.95 drops to 0.45 (easy), 0.26 (medium), 0.09 (hard) on novel structural combinations, with compositionality-adjusted F1 never exceeding 0.57. Performance approaches ~0.01 for depth=3 & breadth=3 patterns, confirming 30-50% gaps for deep linguistic/semantic compositions. <a href="../results/extraction-result-2015.html#e2015.0" class="evidence-link">[e2015.0]</a> <a href="../results/extraction-result-2015.html#e2015.1" class="evidence-link">[e2015.1]</a> <a href="../results/extraction-result-2015.html#e2015.2" class="evidence-link">[e2015.2]</a> </li>
    <li>ReCOGS_pos structural generalization shows ~88.6% IID accuracy dropping to 19.7% on obj_pp_to_subj_pp split (69pp gap) and 40-52% on recursion splits for baseline Transformers, confirming large gaps for linguistic compositions with specific structural phenomena and supporting the theory's claim about certain composition types showing 50-80% failure rates. <a href="../results/extraction-result-2025.html#e2025.1" class="evidence-link">[e2025.1]</a> <a href="../results/extraction-result-2025.html#e2025.2" class="evidence-link">[e2025.2]</a> <a href="../results/extraction-result-2025.html#e2025.3" class="evidence-link">[e2025.3]</a> <a href="../results/extraction-result-2025.html#e2025.4" class="evidence-link">[e2025.4]</a> </li>
    <li>Entropy experiments confirm training distribution diversity is critical: performance scales monotonically with entropy H of verb distributions, with near-ceiling at H≥2 but failure at low H (H=0, H=1). Permutation-equivariant model solves all H levels, supporting the theory's emphasis on training distribution diversity and architectural support. <a href="../results/extraction-result-2016.html#e2016.0" class="evidence-link">[e2016.0]</a> <a href="../results/extraction-result-2016.html#e2016.1" class="evidence-link">[e2016.1]</a> <a href="../results/extraction-result-2016.html#e2016.2" class="evidence-link">[e2016.2]</a> <a href="../results/extraction-result-2016.html#e2016.3" class="evidence-link">[e2016.3]</a> <a href="../results/extraction-result-2016.html#e2016.4" class="evidence-link">[e2016.4]</a> </li>
    <li>CompSub span-level augmentation dramatically improves compositional generalization: SCAN jump/around-right to ~100%, COGS from 55.4% to 91.8%, GeoQuery improvements, demonstrating that increasing training diversity through multi-grained recombinations substantially reduces gaps by 10-40%, supporting the theory's curriculum strategy claims. <a href="../results/extraction-result-2026.html#e2026.0" class="evidence-link">[e2026.0]</a> <a href="../results/extraction-result-2026.html#e2026.1" class="evidence-link">[e2026.1]</a> <a href="../results/extraction-result-2026.html#e2026.2" class="evidence-link">[e2026.2]</a> <a href="../results/extraction-result-2026.html#e2026.5" class="evidence-link">[e2026.5]</a> </li>
    <li>Model scaling (68M→1.5B parameters) does not reduce compositional data requirements: power-law exponent for required dataset size remains essentially invariant across model sizes, and NON-TREE task shows no improvement with 1.5B model, confirming that architectural/training innovations rather than scale are needed. <a href="../results/extraction-result-2023.html#e2023.3" class="evidence-link">[e2023.3]</a> <a href="../results/extraction-result-2023.html#e2023.6" class="evidence-link">[e2023.6]</a> </li>
    <li>Meta-learning Boolean concepts shows compositional depth robustness: Meta-SGD maintains performance across depths D={3,5,7} while SGD degrades substantially (+15.5% to +34.1% improvements), but featural complexity (high F) causes collapse for all methods, supporting depth-handling claims while revealing complexity-dependent limits. <a href="../results/extraction-result-2003.html#e2003.0" class="evidence-link">[e2003.0]</a> </li>
    <li>Length generalization transfer experiments show multitask training with structurally aligned auxiliary tasks enables main task extrapolation with 2-15× sample efficiency gains when competency is aligned, while misaligned pretraining hurts performance, directly supporting the theory's transfer success and competency alignment principles. <a href="../results/extraction-result-2018.html#e2018.0" class="evidence-link">[e2018.0]</a> <a href="../results/extraction-result-2018.html#e2018.1" class="evidence-link">[e2018.1]</a> <a href="../results/extraction-result-2018.html#e2018.2" class="evidence-link">[e2018.2]</a> <a href="../results/extraction-result-2018.html#e2018.3" class="evidence-link">[e2018.3]</a> <a href="../results/extraction-result-2018.html#e2018.4" class="evidence-link">[e2018.4]</a> <a href="../results/extraction-result-2018.html#e2018.5" class="evidence-link">[e2018.5]</a> </li>
    <li>Discrete Latent Space Supervision with Self-Correction achieves near-perfect OOD generalization on modular arithmetic graphs up to 4× training size (N≤32 train, N=128 test), supporting the theory's claim that hierarchical architectures with explicit structure enable <10% gaps and near-complete transfer in procedural domains. <a href="../results/extraction-result-2024.html#e2024.0" class="evidence-link">[e2024.0]</a> <a href="../results/extraction-result-2024.html#e2024.1" class="evidence-link">[e2024.1]</a> <a href="../results/extraction-result-2024.html#e2024.2" class="evidence-link">[e2024.2]</a> <a href="../results/extraction-result-2024.html#e2024.3" class="evidence-link">[e2024.3]</a> <a href="../results/extraction-result-2024.html#e2024.5" class="evidence-link">[e2024.5]</a> <a href="../results/extraction-result-2024.html#e2024.6" class="evidence-link">[e2024.6]</a> </li>
    <li>Propositional logic experiments show baseline Transformer achieves ~94% IID but fails on specific negation-of-operator patterns (P1-P3 near-zero on simplest cases), while tree encodings, GCN, and LSTM show improvements but gaps persist, supporting the theory's claim that certain composition types show systematically higher failure rates. <a href="../results/extraction-result-2010.html#e2010.0" class="evidence-link">[e2010.0]</a> <a href="../results/extraction-result-2010.html#e2010.1" class="evidence-link">[e2010.1]</a> <a href="../results/extraction-result-2010.html#e2010.2" class="evidence-link">[e2010.2]</a> <a href="../results/extraction-result-2010.html#e2010.3" class="evidence-link">[e2010.3]</a> </li>
    <li>Curriculum training with in-context subtask blocks enables zero-shot compositional inference on modular double-exponential task with linearly decodable intermediate representations and fewer errors, while vanilla training shows weaker zero-shot performance, supporting curriculum strategies that provide explicit compositional structure. <a href="../results/extraction-result-2004.html#e2004.0" class="evidence-link">[e2004.0]</a> <a href="../results/extraction-result-2004.html#e2004.1" class="evidence-link">[e2004.1]</a> </li>
</ol>            <h3>Partially Supporting Evidence</h3>
<ol>
    <li>LCS-ICL with learned demonstration selection improves few-shot compositional generalization on COGS-QL: LLaMA3-8B achieves up to 8.8% absolute improvement over best baseline at 18-shot (reaching 58.7%), showing targeted exposure helps reduce gaps but doesn't achieve the theory's claimed >90% with ~500 samples, suggesting the mechanism is more conditional than stated. <a href="../results/extraction-result-2026.html#e2026.3" class="evidence-link">[e2026.3]</a> </li>
    <li>ComposableCoT with model merging or multitask learning enables zero-shot compositional CoT generation for pairwise string/skill compositions, outperforming StandardCoT baselines, and RFT with ≤500 compositional examples further improves performance, partially supporting inoculation effects but showing the approach is specific to CoT-formatted training rather than general. <a href="../results/extraction-result-2021.html#e2021.0" class="evidence-link">[e2021.0]</a> <a href="../results/extraction-result-2021.html#e2021.1" class="evidence-link">[e2021.1]</a> <a href="../results/extraction-result-2021.html#e2021.2" class="evidence-link">[e2021.2]</a> <a href="../results/extraction-result-2021.html#e2021.3" class="evidence-link">[e2021.3]</a> <a href="../results/extraction-result-2021.html#e2021.4" class="evidence-link">[e2021.4]</a> </li>
    <li>MLC (Meta-Learning for Compositionality) with 5.7M parameters achieves 98.78% on 3-shot and 86.73% on systematicity (12pp gap) on Compositional-ARC through episodic training, while static training achieves 0% OOD. This shows gaps can be substantially reduced (to ~10-15%) with appropriate training, partially supporting the theory's claims about curriculum strategies but showing better results than predicted for some conditions. <a href="../results/extraction-result-2027.html#e2027.0" class="evidence-link">[e2027.0]</a> <a href="../results/extraction-result-2027.html#e2027.1" class="evidence-link">[e2027.1]</a> <a href="../results/extraction-result-2027.html#e2027.2" class="evidence-link">[e2027.2]</a> </li>
    <li>Hyperteacher experiments show standard MLPs and Transformers can achieve compositional generalization (R²>0.95 on held-out tasks) when training covers sufficient distinct tasks (sub-exponential scaling) and model capacity is adequate, with linear decodability of constituents correlating with success, supporting the theory's emphasis on training diversity and architectural capacity. <a href="../results/extraction-result-2009.html#e2009.0" class="evidence-link">[e2009.0]</a> <a href="../results/extraction-result-2009.html#e2009.1" class="evidence-link">[e2009.1]</a> <a href="../results/extraction-result-2009.html#e2009.2" class="evidence-link">[e2009.2]</a> <a href="../results/extraction-result-2009.html#e2009.3" class="evidence-link">[e2009.3]</a> <a href="../results/extraction-result-2009.html#e2009.4" class="evidence-link">[e2009.4]</a> </li>
    <li>Subnetwork probing on ReCOGS_pos reveals that standard Transformers contain subnetworks achieving >90% on PP-IOBJ generalization while preserving IID performance, but these rely on both syntactic features and non-compositional heuristics, showing models can learn partial compositional solutions but with mixed strategies. <a href="../results/extraction-result-2014.html#e2014.0" class="evidence-link">[e2014.0]</a> <a href="../results/extraction-result-2014.html#e2014.1" class="evidence-link">[e2014.1]</a> <a href="../results/extraction-result-2014.html#e2014.2" class="evidence-link">[e2014.2]</a> </li>
    <li>Domain-specific fine-tuning with test-time training (LoRA) on Compositional-ARC enables 8B models to approach MLC performance (78.20% systematicity), showing gaps can be reduced with specialized training but requiring heavy augmentation and per-episode adaptation, partially supporting curriculum strategies while revealing computational costs. <a href="../results/extraction-result-2027.html#e2027.6" class="evidence-link">[e2027.6]</a> <a href="../results/extraction-result-2027.html#e2027.7" class="evidence-link">[e2027.7]</a> </li>
</ol>            <h3>Fully Contradicting Evidence</h3>
<ol>
    <li>Inoculation with 328 modified training examples on ReCOGS_pos v_dat_p2 split did not produce reliable crossover improvement to obj_pp_to_subj_pp (22% ±6.7% vs baseline 19.7%), directly contradicting the theory's claim that ~500 OOD samples can rapidly close gaps to >90% - effectiveness depends critically on pattern alignment, not just sample count. <a href="../results/extraction-result-2025.html#e2025.3" class="evidence-link">[e2025.3]</a> </li>
    <li>Small 5.7M parameter MLC model significantly outperforms 70B parameter general-purpose LLMs (GPT-4o: 0.99% systematicity, Gemini: 2.66%, o3-mini: 0.53% vs MLC: 86.73%) on Compositional-ARC, contradicting implicit assumptions about scale and showing episodic training regime is far more important than model size. <a href="../results/extraction-result-2027.html#e2027.1" class="evidence-link">[e2027.1]</a> <a href="../results/extraction-result-2027.html#e2027.3" class="evidence-link">[e2027.3]</a> <a href="../results/extraction-result-2027.html#e2027.4" class="evidence-link">[e2027.4]</a> <a href="../results/extraction-result-2027.html#e2027.5" class="evidence-link">[e2027.5]</a> </li>
</ol>            <h3>Partially Contradicting Evidence</h3>
<ol>
    <li>RASP program (Transformer-equivalent) achieves 100% semantic exact match on ReCOGS_pos test and nearly all generalization splits (92.20% on hardest obj_pp_to_subj_pp, 100% on recursion to depth 12), proving by construction that Transformers CAN represent systematic compositional solutions. This contradicts claims about fundamental representational limitations but doesn't contradict claims about learning difficulty, since RASP is hand-constructed. <a href="../results/extraction-result-2025.html#e2025.0" class="evidence-link">[e2025.0]</a> </li>
    <li>Lake & Baroni meta-learning model re-evaluation shows specific episode failures (41-54% accuracy) with systematic confusion between operators and non-systematic parsing, and 179/200 validation episodes reused training combinations, suggesting meta-learning alone doesn't guarantee systematic generalization and challenging the strength of meta-learning claims. <a href="../results/extraction-result-2007.html#e2007.0" class="evidence-link">[e2007.0]</a> <a href="../results/extraction-result-2007.html#e2007.1" class="evidence-link">[e2007.1]</a> </li>
    <li>Parity experiments with Chain-of-Thought show near-perfect generalization (>95%) to unseen tasks when trained on Õ(d) tasks with CoT representation, while ICL without CoT remains near chance, suggesting the theory's gap magnitudes are representation-dependent rather than task-inherent, partially contradicting fixed percentage claims. <a href="../results/extraction-result-2022.html#e2022.0" class="evidence-link">[e2022.0]</a> <a href="../results/extraction-result-2022.html#e2022.1" class="evidence-link">[e2022.1]</a> <a href="../results/extraction-result-2022.html#e2022.2" class="evidence-link">[e2022.2]</a> </li>
</ol>            <h3>Potentially Modifying Evidence</h3>
<ol>
    <li>Coverage principle: Compositional generalization requires k-coverage (multiple shared contexts providing evidence of functional equivalence), with required dataset size scaling as power law |X|^c where c≈2.26 for 2-HOP, 2.43 for PARALLEL-2-HOP, 2.58 for 3-HOP. Chain-of-Thought reduces exponent (3-HOP: 2.58→1.76) but doesn't eliminate coverage requirements. This provides a precise mechanistic account that should replace or augment the theory's 'training distribution diversity' concept. <a href="../results/extraction-result-2023.html#e2023.0" class="evidence-link">[e2023.0]</a> <a href="../results/extraction-result-2023.html#e2023.1" class="evidence-link">[e2023.1]</a> <a href="../results/extraction-result-2023.html#e2023.2" class="evidence-link">[e2023.2]</a> <a href="../results/extraction-result-2023.html#e2023.4" class="evidence-link">[e2023.4]</a> <a href="../results/extraction-result-2023.html#e2023.5" class="evidence-link">[e2023.5]</a> </li>
    <li>Path ambiguity (NON-TREE task) prevents unified intermediate representations: when a variable affects output through multiple computational paths, models form context-dependent (b,x2)-conditioned clusters instead of unified b representations, requiring near-exhaustive combinations even with extensive training and large models. This represents a structural limitation beyond training distribution that should be added to the theory. <a href="../results/extraction-result-2023.html#e2023.3" class="evidence-link">[e2023.3]</a> </li>
    <li>ARC (AutoRegressive Compositional) framework: Tasks with autoregressive compositional structure (T subtasks, D choices per step) can generalize to D^T tasks from Õ(D) training tasks when per-component coverage is satisfied and identifiability conditions hold, with empirical validation on parity, arithmetic, and translation tasks. This provides positive theoretical bounds that should be incorporated. <a href="../results/extraction-result-2022.html#e2022.0" class="evidence-link">[e2022.0]</a> <a href="../results/extraction-result-2022.html#e2022.1" class="evidence-link">[e2022.1]</a> <a href="../results/extraction-result-2022.html#e2022.3" class="evidence-link">[e2022.3]</a> <a href="../results/extraction-result-2022.html#e2022.4" class="evidence-link">[e2022.4]</a> <a href="../results/extraction-result-2022.html#e2022.5" class="evidence-link">[e2022.5]</a> <a href="../results/extraction-result-2022.html#e2022.6" class="evidence-link">[e2022.6]</a> </li>
    <li>Meta-learning on episodic tasks with dynamically varying grammars enables systematic generalization where static training fails completely (0% OOD): MLC achieves 86.73% systematicity vs 0% for static seq2seq on same architecture. This suggests training regime (episodic vs static) is a primary factor that should be elevated in the theory's framework alongside architecture and curriculum. <a href="../results/extraction-result-2027.html#e2027.0" class="evidence-link">[e2027.0]</a> <a href="../results/extraction-result-2027.html#e2027.1" class="evidence-link">[e2027.1]</a> <a href="../results/extraction-result-2027.html#e2027.2" class="evidence-link">[e2027.2]</a> </li>
    <li>Linear decodability of task constituents from hidden activations correlates with compositional generalization success across domains (functional regression, image generation, visual reasoning), suggesting a unified mechanistic principle: models that form linearly separable constituent representations generalize better. This cross-domain principle should be added to the theory. <a href="../results/extraction-result-2009.html#e2009.0" class="evidence-link">[e2009.0]</a> <a href="../results/extraction-result-2009.html#e2009.1" class="evidence-link">[e2009.1]</a> <a href="../results/extraction-result-2009.html#e2009.4" class="evidence-link">[e2009.4]</a> </li>
    <li>Attraction errors in ReCOGS_pos: 99.74% of single-part agent errors assign the agent index to the nearest PP noun (96.73% of those), representing a systematic, quantified failure mode where models don't learn to ignore PP nouns when selecting verb arguments. This specific mechanism should be added to the theory's 'certain composition types' category. <a href="../results/extraction-result-2025.html#e2025.4" class="evidence-link">[e2025.4]</a> </li>
    <li>Recurrent architectures with input-adaptive computation time, latent algorithmic supervision, discrete factorized bottlenecks, and self-correction training achieve near-perfect depth-invariant algorithms in procedural domains. This specific architectural recipe should be detailed in the theory's architectural support section as a concrete instantiation of 'hierarchical architectures with explicit structure.' <a href="../results/extraction-result-2024.html#e2024.1" class="evidence-link">[e2024.1]</a> <a href="../results/extraction-result-2024.html#e2024.2" class="evidence-link">[e2024.2]</a> <a href="../results/extraction-result-2024.html#e2024.3" class="evidence-link">[e2024.3]</a> <a href="../results/extraction-result-2024.html#e2024.6" class="evidence-link">[e2024.6]</a> </li>
    <li>Training regime (episodic meta-learning, static supervised, curriculum with in-context subtasks) appears to be a primary factor determining gap magnitude, potentially more important than domain (linguistic vs procedural). Visual reasoning (Compositional-ARC) shows similar patterns to linguistic domains under similar training regimes, suggesting the theory's domain-based categorization should be refined to emphasize training regime. <a href="../results/extraction-result-2027.html#e2027.0" class="evidence-link">[e2027.0]</a> <a href="../results/extraction-result-2027.html#e2027.1" class="evidence-link">[e2027.1]</a> <a href="../results/extraction-result-2027.html#e2027.2" class="evidence-link">[e2027.2]</a> <a href="../results/extraction-result-2004.html#e2004.0" class="evidence-link">[e2004.0]</a> <a href="../results/extraction-result-2004.html#e2004.1" class="evidence-link">[e2004.1]</a> </li>
</ol>            <h3>Suggested Revisions</h3>
            <ol>
                <li>Replace fixed gap percentages (30-50%, 10-30%, <10%) with conditional statements based on training regime: gaps can be 10-15% with episodic meta-learning (MLC), near-zero with proper architectural supervision (discrete latent + self-correction), but remain 50-80% with standard supervised training on linguistic tasks.</li>
                <li>Add coverage principle as central mechanism: Replace or augment 'training distribution diversity' with precise coverage requirements - compositional generalization requires k-coverage (multiple shared contexts), with data requirements scaling as power law |X|^c (c≈2-3) with token-set size and compositional depth.</li>
                <li>Elevate training regime as primary factor: Add 'training regime' (episodic meta-learning, static supervised, curriculum with explicit structure) as a primary dimension alongside architecture and domain, potentially more important than domain for determining gap magnitude.</li>
                <li>Refine inoculation claims: Change '~500 OOD samples can rapidly close gaps to >90%' to 'targeted exposure to critical compositional patterns can reduce gaps, with effectiveness depending on pattern coverage and alignment rather than sample count alone.'</li>
                <li>Add path ambiguity as fundamental limitation: When variables participate in multiple computational paths, unified intermediate representations cannot form without near-exhaustive combinations or explicit variable-binding mechanisms, representing a structural limit beyond training distribution.</li>
                <li>Incorporate ARC framework as positive bound: For tasks with autoregressive compositional structure, exponential generalization (D^T from Õ(D) training) is achievable when per-component coverage and identifiability conditions are satisfied.</li>
                <li>Add linear decodability principle: Models that form linearly separable constituent representations in hidden activations show better compositional generalization across domains (functional, visual, linguistic), suggesting representation quality is a key mechanistic factor.</li>
                <li>Specify concrete architectural recipes: Detail specific combinations that achieve near-perfect transfer (e.g., recurrence + latent supervision + discretization + self-correction for procedural domains; episodic meta-learning for visual/linguistic domains).</li>
                <li>Add systematic failure modes: Include specific, quantified failure mechanisms like attraction errors (nearest-noun assignment in 96.73% of cases), path ambiguity (context-dependent representations), and coverage gaps (insufficient k-evidence).</li>
                <li>Refine domain categorization: De-emphasize linguistic vs procedural distinction in favor of training regime and task structure (autoregressive compositional, path-ambiguous, etc.), since visual reasoning shows similar patterns to linguistic under similar training.</li>
            </ol>
        </div>

        <div class="section">
            <h2>Theory Evaluation (Debug)</h2>
            <pre><code>{
    "id": "theory-evaluation-20",
    "theory_id": "theory-177",
    "fully_supporting_evidence": [
        {
            "text": "CompoST benchmark shows large compositional gaps in SPARQL generation: training macro F1 ~0.92-0.95 drops to 0.45 (easy), 0.26 (medium), 0.09 (hard) on novel structural combinations, with compositionality-adjusted F1 never exceeding 0.57. Performance approaches ~0.01 for depth=3 & breadth=3 patterns, confirming 30-50% gaps for deep linguistic/semantic compositions.",
            "uuids": [
                "e2015.0",
                "e2015.1",
                "e2015.2"
            ]
        },
        {
            "text": "ReCOGS_pos structural generalization shows ~88.6% IID accuracy dropping to 19.7% on obj_pp_to_subj_pp split (69pp gap) and 40-52% on recursion splits for baseline Transformers, confirming large gaps for linguistic compositions with specific structural phenomena and supporting the theory's claim about certain composition types showing 50-80% failure rates.",
            "uuids": [
                "e2025.1",
                "e2025.2",
                "e2025.3",
                "e2025.4"
            ]
        },
        {
            "text": "Entropy experiments confirm training distribution diversity is critical: performance scales monotonically with entropy H of verb distributions, with near-ceiling at H≥2 but failure at low H (H=0, H=1). Permutation-equivariant model solves all H levels, supporting the theory's emphasis on training distribution diversity and architectural support.",
            "uuids": [
                "e2016.0",
                "e2016.1",
                "e2016.2",
                "e2016.3",
                "e2016.4"
            ]
        },
        {
            "text": "CompSub span-level augmentation dramatically improves compositional generalization: SCAN jump/around-right to ~100%, COGS from 55.4% to 91.8%, GeoQuery improvements, demonstrating that increasing training diversity through multi-grained recombinations substantially reduces gaps by 10-40%, supporting the theory's curriculum strategy claims.",
            "uuids": [
                "e2026.0",
                "e2026.1",
                "e2026.2",
                "e2026.5"
            ]
        },
        {
            "text": "Model scaling (68M→1.5B parameters) does not reduce compositional data requirements: power-law exponent for required dataset size remains essentially invariant across model sizes, and NON-TREE task shows no improvement with 1.5B model, confirming that architectural/training innovations rather than scale are needed.",
            "uuids": [
                "e2023.3",
                "e2023.6"
            ]
        },
        {
            "text": "Meta-learning Boolean concepts shows compositional depth robustness: Meta-SGD maintains performance across depths D={3,5,7} while SGD degrades substantially (+15.5% to +34.1% improvements), but featural complexity (high F) causes collapse for all methods, supporting depth-handling claims while revealing complexity-dependent limits.",
            "uuids": [
                "e2003.0"
            ]
        },
        {
            "text": "Length generalization transfer experiments show multitask training with structurally aligned auxiliary tasks enables main task extrapolation with 2-15× sample efficiency gains when competency is aligned, while misaligned pretraining hurts performance, directly supporting the theory's transfer success and competency alignment principles.",
            "uuids": [
                "e2018.0",
                "e2018.1",
                "e2018.2",
                "e2018.3",
                "e2018.4",
                "e2018.5"
            ]
        },
        {
            "text": "Discrete Latent Space Supervision with Self-Correction achieves near-perfect OOD generalization on modular arithmetic graphs up to 4× training size (N≤32 train, N=128 test), supporting the theory's claim that hierarchical architectures with explicit structure enable &lt;10% gaps and near-complete transfer in procedural domains.",
            "uuids": [
                "e2024.0",
                "e2024.1",
                "e2024.2",
                "e2024.3",
                "e2024.5",
                "e2024.6"
            ]
        },
        {
            "text": "Propositional logic experiments show baseline Transformer achieves ~94% IID but fails on specific negation-of-operator patterns (P1-P3 near-zero on simplest cases), while tree encodings, GCN, and LSTM show improvements but gaps persist, supporting the theory's claim that certain composition types show systematically higher failure rates.",
            "uuids": [
                "e2010.0",
                "e2010.1",
                "e2010.2",
                "e2010.3"
            ]
        },
        {
            "text": "Curriculum training with in-context subtask blocks enables zero-shot compositional inference on modular double-exponential task with linearly decodable intermediate representations and fewer errors, while vanilla training shows weaker zero-shot performance, supporting curriculum strategies that provide explicit compositional structure.",
            "uuids": [
                "e2004.0",
                "e2004.1"
            ]
        }
    ],
    "partially_supporting_evidence": [
        {
            "text": "LCS-ICL with learned demonstration selection improves few-shot compositional generalization on COGS-QL: LLaMA3-8B achieves up to 8.8% absolute improvement over best baseline at 18-shot (reaching 58.7%), showing targeted exposure helps reduce gaps but doesn't achieve the theory's claimed &gt;90% with ~500 samples, suggesting the mechanism is more conditional than stated.",
            "uuids": [
                "e2026.3"
            ]
        },
        {
            "text": "ComposableCoT with model merging or multitask learning enables zero-shot compositional CoT generation for pairwise string/skill compositions, outperforming StandardCoT baselines, and RFT with ≤500 compositional examples further improves performance, partially supporting inoculation effects but showing the approach is specific to CoT-formatted training rather than general.",
            "uuids": [
                "e2021.0",
                "e2021.1",
                "e2021.2",
                "e2021.3",
                "e2021.4"
            ]
        },
        {
            "text": "MLC (Meta-Learning for Compositionality) with 5.7M parameters achieves 98.78% on 3-shot and 86.73% on systematicity (12pp gap) on Compositional-ARC through episodic training, while static training achieves 0% OOD. This shows gaps can be substantially reduced (to ~10-15%) with appropriate training, partially supporting the theory's claims about curriculum strategies but showing better results than predicted for some conditions.",
            "uuids": [
                "e2027.0",
                "e2027.1",
                "e2027.2"
            ]
        },
        {
            "text": "Hyperteacher experiments show standard MLPs and Transformers can achieve compositional generalization (R²&gt;0.95 on held-out tasks) when training covers sufficient distinct tasks (sub-exponential scaling) and model capacity is adequate, with linear decodability of constituents correlating with success, supporting the theory's emphasis on training diversity and architectural capacity.",
            "uuids": [
                "e2009.0",
                "e2009.1",
                "e2009.2",
                "e2009.3",
                "e2009.4"
            ]
        },
        {
            "text": "Subnetwork probing on ReCOGS_pos reveals that standard Transformers contain subnetworks achieving &gt;90% on PP-IOBJ generalization while preserving IID performance, but these rely on both syntactic features and non-compositional heuristics, showing models can learn partial compositional solutions but with mixed strategies.",
            "uuids": [
                "e2014.0",
                "e2014.1",
                "e2014.2"
            ]
        },
        {
            "text": "Domain-specific fine-tuning with test-time training (LoRA) on Compositional-ARC enables 8B models to approach MLC performance (78.20% systematicity), showing gaps can be reduced with specialized training but requiring heavy augmentation and per-episode adaptation, partially supporting curriculum strategies while revealing computational costs.",
            "uuids": [
                "e2027.6",
                "e2027.7"
            ]
        }
    ],
    "fully_contradicting_evidence": [
        {
            "text": "Inoculation with 328 modified training examples on ReCOGS_pos v_dat_p2 split did not produce reliable crossover improvement to obj_pp_to_subj_pp (22% ±6.7% vs baseline 19.7%), directly contradicting the theory's claim that ~500 OOD samples can rapidly close gaps to &gt;90% - effectiveness depends critically on pattern alignment, not just sample count.",
            "uuids": [
                "e2025.3"
            ]
        },
        {
            "text": "Small 5.7M parameter MLC model significantly outperforms 70B parameter general-purpose LLMs (GPT-4o: 0.99% systematicity, Gemini: 2.66%, o3-mini: 0.53% vs MLC: 86.73%) on Compositional-ARC, contradicting implicit assumptions about scale and showing episodic training regime is far more important than model size.",
            "uuids": [
                "e2027.1",
                "e2027.3",
                "e2027.4",
                "e2027.5"
            ]
        }
    ],
    "partially_contradicting_evidence": [
        {
            "text": "RASP program (Transformer-equivalent) achieves 100% semantic exact match on ReCOGS_pos test and nearly all generalization splits (92.20% on hardest obj_pp_to_subj_pp, 100% on recursion to depth 12), proving by construction that Transformers CAN represent systematic compositional solutions. This contradicts claims about fundamental representational limitations but doesn't contradict claims about learning difficulty, since RASP is hand-constructed.",
            "uuids": [
                "e2025.0"
            ]
        },
        {
            "text": "Lake & Baroni meta-learning model re-evaluation shows specific episode failures (41-54% accuracy) with systematic confusion between operators and non-systematic parsing, and 179/200 validation episodes reused training combinations, suggesting meta-learning alone doesn't guarantee systematic generalization and challenging the strength of meta-learning claims.",
            "uuids": [
                "e2007.0",
                "e2007.1"
            ]
        },
        {
            "text": "Parity experiments with Chain-of-Thought show near-perfect generalization (&gt;95%) to unseen tasks when trained on Õ(d) tasks with CoT representation, while ICL without CoT remains near chance, suggesting the theory's gap magnitudes are representation-dependent rather than task-inherent, partially contradicting fixed percentage claims.",
            "uuids": [
                "e2022.0",
                "e2022.1",
                "e2022.2"
            ]
        }
    ],
    "potentially_modifying_evidence": [
        {
            "text": "Coverage principle: Compositional generalization requires k-coverage (multiple shared contexts providing evidence of functional equivalence), with required dataset size scaling as power law |X|^c where c≈2.26 for 2-HOP, 2.43 for PARALLEL-2-HOP, 2.58 for 3-HOP. Chain-of-Thought reduces exponent (3-HOP: 2.58→1.76) but doesn't eliminate coverage requirements. This provides a precise mechanistic account that should replace or augment the theory's 'training distribution diversity' concept.",
            "uuids": [
                "e2023.0",
                "e2023.1",
                "e2023.2",
                "e2023.4",
                "e2023.5"
            ]
        },
        {
            "text": "Path ambiguity (NON-TREE task) prevents unified intermediate representations: when a variable affects output through multiple computational paths, models form context-dependent (b,x2)-conditioned clusters instead of unified b representations, requiring near-exhaustive combinations even with extensive training and large models. This represents a structural limitation beyond training distribution that should be added to the theory.",
            "uuids": [
                "e2023.3"
            ]
        },
        {
            "text": "ARC (AutoRegressive Compositional) framework: Tasks with autoregressive compositional structure (T subtasks, D choices per step) can generalize to D^T tasks from Õ(D) training tasks when per-component coverage is satisfied and identifiability conditions hold, with empirical validation on parity, arithmetic, and translation tasks. This provides positive theoretical bounds that should be incorporated.",
            "uuids": [
                "e2022.0",
                "e2022.1",
                "e2022.3",
                "e2022.4",
                "e2022.5",
                "e2022.6"
            ]
        },
        {
            "text": "Meta-learning on episodic tasks with dynamically varying grammars enables systematic generalization where static training fails completely (0% OOD): MLC achieves 86.73% systematicity vs 0% for static seq2seq on same architecture. This suggests training regime (episodic vs static) is a primary factor that should be elevated in the theory's framework alongside architecture and curriculum.",
            "uuids": [
                "e2027.0",
                "e2027.1",
                "e2027.2"
            ]
        },
        {
            "text": "Linear decodability of task constituents from hidden activations correlates with compositional generalization success across domains (functional regression, image generation, visual reasoning), suggesting a unified mechanistic principle: models that form linearly separable constituent representations generalize better. This cross-domain principle should be added to the theory.",
            "uuids": [
                "e2009.0",
                "e2009.1",
                "e2009.4"
            ]
        },
        {
            "text": "Attraction errors in ReCOGS_pos: 99.74% of single-part agent errors assign the agent index to the nearest PP noun (96.73% of those), representing a systematic, quantified failure mode where models don't learn to ignore PP nouns when selecting verb arguments. This specific mechanism should be added to the theory's 'certain composition types' category.",
            "uuids": [
                "e2025.4"
            ]
        },
        {
            "text": "Recurrent architectures with input-adaptive computation time, latent algorithmic supervision, discrete factorized bottlenecks, and self-correction training achieve near-perfect depth-invariant algorithms in procedural domains. This specific architectural recipe should be detailed in the theory's architectural support section as a concrete instantiation of 'hierarchical architectures with explicit structure.'",
            "uuids": [
                "e2024.1",
                "e2024.2",
                "e2024.3",
                "e2024.6"
            ]
        },
        {
            "text": "Training regime (episodic meta-learning, static supervised, curriculum with in-context subtasks) appears to be a primary factor determining gap magnitude, potentially more important than domain (linguistic vs procedural). Visual reasoning (Compositional-ARC) shows similar patterns to linguistic domains under similar training regimes, suggesting the theory's domain-based categorization should be refined to emphasize training regime.",
            "uuids": [
                "e2027.0",
                "e2027.1",
                "e2027.2",
                "e2004.0",
                "e2004.1"
            ]
        }
    ],
    "suggested_revisions": [
        "Replace fixed gap percentages (30-50%, 10-30%, &lt;10%) with conditional statements based on training regime: gaps can be 10-15% with episodic meta-learning (MLC), near-zero with proper architectural supervision (discrete latent + self-correction), but remain 50-80% with standard supervised training on linguistic tasks.",
        "Add coverage principle as central mechanism: Replace or augment 'training distribution diversity' with precise coverage requirements - compositional generalization requires k-coverage (multiple shared contexts), with data requirements scaling as power law |X|^c (c≈2-3) with token-set size and compositional depth.",
        "Elevate training regime as primary factor: Add 'training regime' (episodic meta-learning, static supervised, curriculum with explicit structure) as a primary dimension alongside architecture and domain, potentially more important than domain for determining gap magnitude.",
        "Refine inoculation claims: Change '~500 OOD samples can rapidly close gaps to &gt;90%' to 'targeted exposure to critical compositional patterns can reduce gaps, with effectiveness depending on pattern coverage and alignment rather than sample count alone.'",
        "Add path ambiguity as fundamental limitation: When variables participate in multiple computational paths, unified intermediate representations cannot form without near-exhaustive combinations or explicit variable-binding mechanisms, representing a structural limit beyond training distribution.",
        "Incorporate ARC framework as positive bound: For tasks with autoregressive compositional structure, exponential generalization (D^T from Õ(D) training) is achievable when per-component coverage and identifiability conditions are satisfied.",
        "Add linear decodability principle: Models that form linearly separable constituent representations in hidden activations show better compositional generalization across domains (functional, visual, linguistic), suggesting representation quality is a key mechanistic factor.",
        "Specify concrete architectural recipes: Detail specific combinations that achieve near-perfect transfer (e.g., recurrence + latent supervision + discretization + self-correction for procedural domains; episodic meta-learning for visual/linguistic domains).",
        "Add systematic failure modes: Include specific, quantified failure mechanisms like attraction errors (nearest-noun assignment in 96.73% of cases), path ambiguity (context-dependent representations), and coverage gaps (insufficient k-evidence).",
        "Refine domain categorization: De-emphasize linguistic vs procedural distinction in favor of training regime and task structure (autoregressive compositional, path-ambiguous, etc.), since visual reasoning shows similar patterns to linguistic under similar training."
    ],
    "overall_support_or_contradict": "support",
    "overall_support_or_contradict_explanation": "The new evidence strongly supports the theory's core claims that compositional generalization gaps exist, vary systematically by depth and composition type, and can be reduced through curriculum strategies and architectural support. However, the evidence reveals the mechanisms are more nuanced than stated, requiring refinements to emphasize coverage principles, training regimes, and specific architectural recipes rather than fixed percentage gaps and domain-based categorization.",
    "revised_theory_ids": [
        "theory-380"
    ],
    "model_str": "claude-sonnet-4-5-20250929"
}</code></pre>
        </div>
    </div>
</body>
</html>