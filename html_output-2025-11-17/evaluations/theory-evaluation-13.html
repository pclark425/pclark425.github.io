<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Theory Evaluation theory-evaluation-13 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Evaluation Details for theory-evaluation-13</h1>

        <div class="section">
            <h2>Theory Evaluation (General Information)</h2>
            <div class="info-section">
                <p><strong>Evaluation ID:</strong> theory-evaluation-13</p>
                <p><strong>This evaluation is for theory ID:</strong> <a href="../theories/theory-196.html">theory-196</a></p>
                <p><strong>This evaluation resulted in these revised theories:</strong> <a href="../theories/theory-373.html">theory-373</a></p>
                <p><strong>Overall Support or Contradict:</strong> support</p>
                <p><strong>Overall Support or Contradict Explanation:</strong> The new evidence strongly supports the core theory that perception-language grounding quality is critical for embodied AI transfer, with extensive evidence of perception bottlenecks, benefits of vision-language pretraining, importance of object-centric representations, and domain-shift challenges. However, the evidence reveals important scope expansions needed: grounding must extend to temporal/action/memory dimensions, explicit reasoning enhances grounding, and grounding alone doesn't guarantee execution success, suggesting the theory should be broadened rather than contradicted.</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory Evaluation (Components)</h2>

            <h3>Fully Supporting Evidence</h3>
<ol>
    <li>Multiple studies identify perception/grounding as dominant failure mode: EmbodiedVSR shows perception errors (segmentation, depth) are major bottleneck despite strong reasoning; OPEx analysis found perception and low-level execution >50% of errors; OpenVLA adversarial attacks exploit embedding-space grounding vulnerabilities causing near-100% failure rates; DenseGrounding identifies semantic loss from sparse sampling as primary bottleneck <a href="../results/extraction-result-1941.html#e1941.0" class="evidence-link">[e1941.0]</a> <a href="../results/extraction-result-1696.html#e1696.0" class="evidence-link">[e1696.0]</a> <a href="../results/extraction-result-1975.html#e1975.0" class="evidence-link">[e1975.0]</a> <a href="../results/extraction-result-1975.html#e1975.3" class="evidence-link">[e1975.3]</a> <a href="../results/extraction-result-1968.html#e1968.0" class="evidence-link">[e1968.0]</a> </li>
    <li>Vision-language pretraining scale and quality directly improve grounding: Vlaser finetuning of InternVL3 on embodied data yields +30 point gains on reasoning benchmarks; RoboVLMs study shows stronger VLM alignment correlates with better control; WMNav comparison shows larger VLMs (Gemini vs Qwen 3B→7B) yield 29.7%→58.1% SR improvements; CLIP vs SigLIP vs ViLT comparison shows richer embeddings (1152-d SigLIP) outperform smaller ones (512-d CLIP: 74% vs 62% SR) <a href="../results/extraction-result-1967.html#e1967.4" class="evidence-link">[e1967.4]</a> <a href="../results/extraction-result-1948.html#e1948.8" class="evidence-link">[e1948.8]</a> <a href="../results/extraction-result-1980.html#e1980.0" class="evidence-link">[e1980.0]</a> <a href="../results/extraction-result-1973.html#e1973.0" class="evidence-link">[e1973.0]</a> </li>
    <li>Object-centric and region-level representations improve grounding substantially: ProxyTransformation's cluster-level multimodal enhancement yields +7.49% AP on EmbodiedScan; MTU3D's object-centric spatial memory enables +13.7% SR gains; ROBOGROUND's pixel-level masks improve contact rates by +18-30% over no-grounding baseline; RoboMAP's adaptive heatmaps outperform point-based methods by +9-14% on grounding benchmarks <a href="../results/extraction-result-1936.html#e1936.0" class="evidence-link">[e1936.0]</a> <a href="../results/extraction-result-1977.html#e1977.0" class="evidence-link">[e1977.0]</a> <a href="../results/extraction-result-1943.html#e1943.0" class="evidence-link">[e1943.0]</a> <a href="../results/extraction-result-1978.html#e1978.1" class="evidence-link">[e1978.1]</a> <a href="../results/extraction-result-1978.html#e1978.2" class="evidence-link">[e1978.2]</a> <a href="../results/extraction-result-1978.html#e1978.3" class="evidence-link">[e1978.3]</a> </li>
    <li>Domain shift and distribution mismatch are critical bottlenecks: OneTwoVLA without synthetic VL co-training achieves only 8% open-world grounding vs 73% with co-training (+65%); OpenVLA shows catastrophic representation degradation under fine-tuning requiring dual-encoder preservation; π0's wrist-camera pretraining reduces adversarial vulnerability; RecBert pretrained on ALFRED shows negative transfer to R2R due to synthetic-to-real domain gap <a href="../results/extraction-result-1965.html#e1965.0" class="evidence-link">[e1965.0]</a> <a href="../results/extraction-result-1947.html#e1947.2" class="evidence-link">[e1947.2]</a> <a href="../results/extraction-result-1975.html#e1975.2" class="evidence-link">[e1975.2]</a> <a href="../results/extraction-result-1729.html#e1729.2" class="evidence-link">[e1729.2]</a> </li>
    <li>Explicit spatial representations and multi-scale grounding improve performance: DenseGrounding's hierarchical scene semantic enhancer yields +5.57% ACC@25; EmbodiedVSR's dynamic scene graphs with physics constraints improve spatial reasoning; ProxyTransformation's 3D cluster transforms outperform 2D-only by +4.2 AP; MTU3D's 3D spatial memory bank enables lifelong navigation gains; VEME's geometry-aware features (VGGT) are essential for spatio-temporal understanding (removal causes ~21 point drop) <a href="../results/extraction-result-1968.html#e1968.0" class="evidence-link">[e1968.0]</a> <a href="../results/extraction-result-1941.html#e1941.0" class="evidence-link">[e1941.0]</a> <a href="../results/extraction-result-1936.html#e1936.0" class="evidence-link">[e1936.0]</a> <a href="../results/extraction-result-1977.html#e1977.0" class="evidence-link">[e1977.0]</a> <a href="../results/extraction-result-1956.html#e1956.3" class="evidence-link">[e1956.3]</a> </li>
    <li>Perception bottlenecks dominate even with strong language models: modular VLM pipelines fail on implicit affordance tasks despite using GPT-4-class LLMs; GroundingDINO+SAM misses featureless objects causing downstream failures; GPT-4o shows weaker precise grounding (S1/S2) than grounding-specialized models despite strong reasoning; quantization (INT4) disproportionately harms relational/implicit grounding (14-17% drops) vs attribute recognition (4%) <a href="../results/extraction-result-1981.html#e1981.1" class="evidence-link">[e1981.1]</a> <a href="../results/extraction-result-1981.html#e1981.5" class="evidence-link">[e1981.5]</a> <a href="../results/extraction-result-1972.html#e1972.8" class="evidence-link">[e1972.8]</a> <a href="../results/extraction-result-1981.html#e1981.6" class="evidence-link">[e1981.6]</a> </li>
    <li>Multi-view and diverse visual pretraining improves grounding robustness: π0 with wrist-camera pretraining shows lower adversarial vulnerability than single-view OpenVLA; OpenVLA-OFT with multi-camera fine-tuning reduces EDPA-induced failures; multi-view inputs in Gondola substantially reduce occlusion-driven grounding errors; ProxyTransformation using multi-view features outperforms single-view approaches <a href="../results/extraction-result-1975.html#e1975.2" class="evidence-link">[e1975.2]</a> <a href="../results/extraction-result-1975.html#e1975.1" class="evidence-link">[e1975.1]</a> <a href="../results/extraction-result-1958.html#e1958.0" class="evidence-link">[e1958.0]</a> <a href="../results/extraction-result-1936.html#e1936.0" class="evidence-link">[e1936.0]</a> </li>
    <li>Frozen vs fine-tuned encoder comparison supports theory predictions: OpenVLA+ partially-frozen dual encoder (one frozen, one trainable) improves from 35.03% to 55.55% avg SR, outperforming naive full fine-tuning; EF-VLA using frozen CLIP encoders achieves +20% on compositional tasks and 85% success on unseen goals; however, full freezing can degrade performance, supporting theory's nuanced view on adaptation <a href="../results/extraction-result-1947.html#e1947.2" class="evidence-link">[e1947.2]</a> <a href="../results/extraction-result-1982.html#e1982.3" class="evidence-link">[e1982.3]</a> </li>
</ol>            <h3>Partially Supporting Evidence</h3>
<ol>
    <li>Frozen pretrained embeddings can provide effective grounding with appropriate mechanisms but show clear limitations: SigLIP-BC achieves 74% navigation success with frozen embeddings and simple BC policy, but with 3.2× efficiency gap vs expert and failures in spatial reasoning/planning; ViLT (VQA-finetuned) performs worst (40% SR), suggesting task-specific fine-tuning for non-embodied tasks doesn't transfer well <a href="../results/extraction-result-1973.html#e1973.0" class="evidence-link">[e1973.0]</a> <a href="../results/extraction-result-1973.html#e1973.2" class="evidence-link">[e1973.2]</a> </li>
    <li>Language-based representations can partially bypass perception issues in specific settings: LangNav using text captions shows better sim-to-real transfer than vision-based RecBert; WMNav's text-image memory baseline performs worse (62.0% SR) than quantitative curiosity maps (72.2% SR) due to hallucination, showing text-only memory is insufficient; these approaches are limited to specific task types <a href="../results/extraction-result-1729.html#e1729.0" class="evidence-link">[e1729.0]</a> <a href="../results/extraction-result-1980.html#e1980.3" class="evidence-link">[e1980.3]</a> </li>
    <li>Memory systems are critical for grounding but implementation matters: MTU3D's spatial memory bank contributes substantially to lifelong navigation; VEME's spatial semantic memory yields ~+9.8 SPL when included; ISR (implicit scene representation) reduces redundant geometric details that impede grounding; however, memory systems depend on clean inputs (point clouds, trajectories) and can fail under noise <a href="../results/extraction-result-1977.html#e1977.2" class="evidence-link">[e1977.2]</a> <a href="../results/extraction-result-1956.html#e1956.1" class="evidence-link">[e1956.1]</a> <a href="../results/extraction-result-1933.html#e1933.1" class="evidence-link">[e1933.1]</a> </li>
    <li>Heatmap-based grounding can be more efficient than point-based: RoboMAP's adaptive heatmaps achieve competitive accuracy with ~15× faster inference than iterative methods like Embodied-R1; however, point-based methods can achieve higher precision on some tasks, suggesting trade-offs between efficiency and accuracy <a href="../results/extraction-result-1978.html#e1978.1" class="evidence-link">[e1978.1]</a> <a href="../results/extraction-result-1978.html#e1978.10" class="evidence-link">[e1978.10]</a> </li>
</ol>            <h3>Fully Contradicting Evidence</h3>
<p class="empty-note">No evidence provided.</p>            <h3>Partially Contradicting Evidence</h3>
<ol>
    <li>Some text-only or language-abstraction approaches achieve reasonable performance without explicit visual grounding in limited settings: LangSuitE text-only approaches achieve 77-86% SR on high-level actions; Code-as-Policies and LMPs succeed by generating programs calling perception APIs; however, these are limited to coarse navigation or modular settings and don't address fine-grained spatial reasoning or manipulation <a href="../results/extraction-result-1730.html#e1730.0" class="evidence-link">[e1730.0]</a> <a href="../results/extraction-result-1847.html#e1847.0" class="evidence-link">[e1847.0]</a> </li>
</ol>            <h3>Potentially Modifying Evidence</h3>
<ol>
    <li>Grounding improvements don't guarantee execution success, suggesting grounding is necessary but insufficient: ROBOGROUND achieves 89% contact but only 43.3% success on pick-and-place, showing large gap between localization and manipulation; VLM-VLA misalignment causes execution failures despite correct high-level grounding; dual-system approaches face latency and coordination issues; this suggests theory should clarify grounding as one component in execution pipeline <a href="../results/extraction-result-1943.html#e1943.0" class="evidence-link">[e1943.0]</a> <a href="../results/extraction-result-1962.html#e1962.3" class="evidence-link">[e1962.3]</a> <a href="../results/extraction-result-1965.html#e1965.3" class="evidence-link">[e1965.3]</a> </li>
    <li>Temporal and multi-step grounding requires different mechanisms than single-step: PIO benchmark shows models excel at S1/S2 single-target grounding but fail at S3 trajectory prediction; OneTwoVLA's explicit textual reasoning substantially improves long-horizon tasks (+30% over π0 baseline); Gemini-2.5-Pro succeeds at S3 planning despite weaker S1/S2 precision; this suggests theory should distinguish instantaneous vs. temporal grounding requirements <a href="../results/extraction-result-1972.html#e1972.0" class="evidence-link">[e1972.0]</a> <a href="../results/extraction-result-1965.html#e1965.0" class="evidence-link">[e1965.0]</a> <a href="../results/extraction-result-1972.html#e1972.7" class="evidence-link">[e1972.7]</a> </li>
    <li>Action-space alignment and tokenization are critical for grounding transfer beyond visual grounding: OpenVLA+ string tokenizer yields +15-43 point improvements by aligning actions with language tokens; VLM-VLA misalignment causes failures despite correct visual grounding; FAST tokenization enables 15× faster inference and 200 Hz control; this suggests theory should include action-grounding as distinct from perception-grounding <a href="../results/extraction-result-1947.html#e1947.3" class="evidence-link">[e1947.3]</a> <a href="../results/extraction-result-1962.html#e1962.3" class="evidence-link">[e1962.3]</a> <a href="../results/extraction-result-1982.html#e1982.11" class="evidence-link">[e1982.11]</a> </li>
    <li>Hierarchical and dual-system architectures show promise but face coordination challenges: Groot N1 dual-system achieves +17% SR and -28% collisions but faces timing mismatches (~800ms LLM vs ~10ms control); OneTwoVLA's unified reasoning+acting outperforms separated systems (87% vs 63% on long-horizon tasks); this suggests theory should address multi-level grounding coordination and latency constraints <a href="../results/extraction-result-1982.html#e1982.4" class="evidence-link">[e1982.4]</a> <a href="../results/extraction-result-1965.html#e1965.0" class="evidence-link">[e1965.0]</a> <a href="../results/extraction-result-1965.html#e1965.3" class="evidence-link">[e1965.3]</a> </li>
    <li>Synthetic and procedural data generation can effectively scale grounding supervision: OneTwoVLA's synthetic VL pipeline (16K images with fisheye/gripper augmentation) yields +65% open-world grounding improvement; OXE-MAP procedural conversion of trajectories to heatmaps enables effective training; DenseGrounding's LLM-grounded text augmentation yields +3.48% ACC@25; this extends theory's data-scaling predictions to include synthetic/procedural sources <a href="../results/extraction-result-1965.html#e1965.4" class="evidence-link">[e1965.4]</a> <a href="../results/extraction-result-1978.html#e1978.4" class="evidence-link">[e1978.4]</a> <a href="../results/extraction-result-1968.html#e1968.4" class="evidence-link">[e1968.4]</a> </li>
    <li>Adversarial robustness reveals grounding vulnerabilities and should be considered a dimension of grounding quality: EDPA embedding-space attacks cause near-100% failure by disrupting image-instruction alignment; adversarial fine-tuning of encoders reduces vulnerability by ~34%; attacks transfer across models/datasets indicating systematic weaknesses; this suggests theory should address grounding robustness as a distinct dimension <a href="../results/extraction-result-1975.html#e1975.3" class="evidence-link">[e1975.3]</a> <a href="../results/extraction-result-1975.html#e1975.0" class="evidence-link">[e1975.0]</a> </li>
    <li>Explicit reasoning and chain-of-thought improve grounding in complex settings: EmbodiedVSR's physics-constrained CoT reduces geometric hallucinations; Robix's thought-action consistency training via RL improves grounding and reduces irrational steps; RFT with free-form CoT yields +28 points over SFT on grounding benchmarks; HEAL probing shows models struggle with scene-task contradictions even with feedback; this suggests grounding benefits from explicit reasoning scaffolding <a href="../results/extraction-result-1941.html#e1941.0" class="evidence-link">[e1941.0]</a> <a href="../results/extraction-result-1962.html#e1962.0" class="evidence-link">[e1962.0]</a> <a href="../results/extraction-result-1979.html#e1979.7" class="evidence-link">[e1979.7]</a> <a href="../results/extraction-result-1963.html#e1963.3" class="evidence-link">[e1963.3]</a> </li>
    <li>Grounding representation format matters: RoboMAP's adaptive heatmaps outperform fixed-shape heatmaps and point-based methods; Gondola's end-to-end mask generation outperforms box-based grounding by +20-25 IoU points; normalized IoU metric needed to fairly compare boxes vs points; this suggests theory should address representation-level choices for grounding outputs <a href="../results/extraction-result-1978.html#e1978.1" class="evidence-link">[e1978.1]</a> <a href="../results/extraction-result-1958.html#e1958.0" class="evidence-link">[e1958.0]</a> <a href="../results/extraction-result-1972.html#e1972.9" class="evidence-link">[e1972.9]</a> </li>
    <li>Real-time constraints and inference latency are practical grounding bottlenecks: OneTwoVLA reasoning mode causes >2s latency for ~100 tokens; Groot N1 faces jerkiness from System 2 latency; RoboMAP achieves competitive accuracy with 15× faster inference than iterative methods; this suggests theory should consider computational efficiency as a grounding quality dimension <a href="../results/extraction-result-1965.html#e1965.0" class="evidence-link">[e1965.0]</a> <a href="../results/extraction-result-1982.html#e1982.4" class="evidence-link">[e1982.4]</a> <a href="../results/extraction-result-1978.html#e1978.10" class="evidence-link">[e1978.10]</a> </li>
    <li>Precision and numerical representation affect grounding: quantization (INT4) disproportionately harms high-level grounding (14-17% drops on implicit/relational) vs simple attribute recognition (4% drop); string-based action tokenization preserves fine-grained spatial values while enabling language alignment; this suggests grounding quality depends on representation precision <a href="../results/extraction-result-1981.html#e1981.6" class="evidence-link">[e1981.6]</a> <a href="../results/extraction-result-1947.html#e1947.3" class="evidence-link">[e1947.3]</a> </li>
</ol>            <h3>Suggested Revisions</h3>
            <ol>
                <li>Distinguish between single-step/instantaneous grounding (S1/S2-type localization) and temporal/trajectory grounding (S3-type planning), as evidence shows these require different mechanisms and models excel at one but not the other</li>
                <li>Add action-space grounding as a distinct component: the mapping from grounded perceptions to executable actions is a separate bottleneck (VLM-VLA misalignment, action tokenization effects, FAST compression)</li>
                <li>Expand fusion mechanisms to include hierarchical/dual-system architectures and their coordination challenges, as evidence shows both promise (Groot N1, OneTwoVLA) and pitfalls (latency, misalignment)</li>
                <li>Include synthetic and procedural data generation as effective scaling strategies for grounding supervision, extending beyond just scale of real pretraining data (OneTwoVLA synthetic VL, OXE-MAP, LLM-grounded augmentation)</li>
                <li>Add adversarial robustness as a dimension of grounding quality, as embedding-space attacks reveal fundamental vulnerabilities in learned alignments that can be mitigated through diverse pretraining and adversarial fine-tuning</li>
                <li>Incorporate explicit reasoning and chain-of-thought as mechanisms that enhance grounding, particularly for complex spatial reasoning, long-horizon tasks, and handling scene-task contradictions</li>
                <li>Clarify that grounding is necessary but not sufficient for task success—execution, action precision, system coordination, and real-time constraints are additional critical factors (ROBOGROUND contact vs success gap)</li>
                <li>Add memory systems (spatial memory banks, episodic memory, implicit scene representations) as critical components for grounding in sequential and long-horizon tasks, with caveats about dependence on input quality</li>
                <li>Include grounding representation format (heatmaps vs points vs boxes vs masks) as an important design choice affecting both accuracy and efficiency trade-offs</li>
                <li>Add computational efficiency and real-time constraints as practical dimensions of grounding quality, as latency can be a bottleneck even when grounding accuracy is high</li>
                <li>Expand frozen vs fine-tuned discussion to include partially-frozen dual-encoder approaches as effective middle ground that preserves pretrained grounding while enabling task adaptation</li>
                <li>Note that quantization and numerical precision disproportionately affect high-level grounding (relational, implicit) compared to simple attribute recognition, suggesting grounding quality is precision-sensitive</li>
            </ol>
        </div>

        <div class="section">
            <h2>Theory Evaluation (Debug)</h2>
            <pre><code>{
    "id": "theory-evaluation-13",
    "theory_id": "theory-196",
    "fully_supporting_evidence": [
        {
            "text": "Multiple studies identify perception/grounding as dominant failure mode: EmbodiedVSR shows perception errors (segmentation, depth) are major bottleneck despite strong reasoning; OPEx analysis found perception and low-level execution &gt;50% of errors; OpenVLA adversarial attacks exploit embedding-space grounding vulnerabilities causing near-100% failure rates; DenseGrounding identifies semantic loss from sparse sampling as primary bottleneck",
            "uuids": [
                "e1941.0",
                "e1696.0",
                "e1975.0",
                "e1975.3",
                "e1968.0"
            ]
        },
        {
            "text": "Vision-language pretraining scale and quality directly improve grounding: Vlaser finetuning of InternVL3 on embodied data yields +30 point gains on reasoning benchmarks; RoboVLMs study shows stronger VLM alignment correlates with better control; WMNav comparison shows larger VLMs (Gemini vs Qwen 3B→7B) yield 29.7%→58.1% SR improvements; CLIP vs SigLIP vs ViLT comparison shows richer embeddings (1152-d SigLIP) outperform smaller ones (512-d CLIP: 74% vs 62% SR)",
            "uuids": [
                "e1967.4",
                "e1948.8",
                "e1980.0",
                "e1973.0"
            ]
        },
        {
            "text": "Object-centric and region-level representations improve grounding substantially: ProxyTransformation's cluster-level multimodal enhancement yields +7.49% AP on EmbodiedScan; MTU3D's object-centric spatial memory enables +13.7% SR gains; ROBOGROUND's pixel-level masks improve contact rates by +18-30% over no-grounding baseline; RoboMAP's adaptive heatmaps outperform point-based methods by +9-14% on grounding benchmarks",
            "uuids": [
                "e1936.0",
                "e1977.0",
                "e1943.0",
                "e1978.1",
                "e1978.2",
                "e1978.3"
            ]
        },
        {
            "text": "Domain shift and distribution mismatch are critical bottlenecks: OneTwoVLA without synthetic VL co-training achieves only 8% open-world grounding vs 73% with co-training (+65%); OpenVLA shows catastrophic representation degradation under fine-tuning requiring dual-encoder preservation; π0's wrist-camera pretraining reduces adversarial vulnerability; RecBert pretrained on ALFRED shows negative transfer to R2R due to synthetic-to-real domain gap",
            "uuids": [
                "e1965.0",
                "e1947.2",
                "e1975.2",
                "e1729.2"
            ]
        },
        {
            "text": "Explicit spatial representations and multi-scale grounding improve performance: DenseGrounding's hierarchical scene semantic enhancer yields +5.57% ACC@25; EmbodiedVSR's dynamic scene graphs with physics constraints improve spatial reasoning; ProxyTransformation's 3D cluster transforms outperform 2D-only by +4.2 AP; MTU3D's 3D spatial memory bank enables lifelong navigation gains; VEME's geometry-aware features (VGGT) are essential for spatio-temporal understanding (removal causes ~21 point drop)",
            "uuids": [
                "e1968.0",
                "e1941.0",
                "e1936.0",
                "e1977.0",
                "e1956.3"
            ]
        },
        {
            "text": "Perception bottlenecks dominate even with strong language models: modular VLM pipelines fail on implicit affordance tasks despite using GPT-4-class LLMs; GroundingDINO+SAM misses featureless objects causing downstream failures; GPT-4o shows weaker precise grounding (S1/S2) than grounding-specialized models despite strong reasoning; quantization (INT4) disproportionately harms relational/implicit grounding (14-17% drops) vs attribute recognition (4%)",
            "uuids": [
                "e1981.1",
                "e1981.5",
                "e1972.8",
                "e1981.6"
            ]
        },
        {
            "text": "Multi-view and diverse visual pretraining improves grounding robustness: π0 with wrist-camera pretraining shows lower adversarial vulnerability than single-view OpenVLA; OpenVLA-OFT with multi-camera fine-tuning reduces EDPA-induced failures; multi-view inputs in Gondola substantially reduce occlusion-driven grounding errors; ProxyTransformation using multi-view features outperforms single-view approaches",
            "uuids": [
                "e1975.2",
                "e1975.1",
                "e1958.0",
                "e1936.0"
            ]
        },
        {
            "text": "Frozen vs fine-tuned encoder comparison supports theory predictions: OpenVLA+ partially-frozen dual encoder (one frozen, one trainable) improves from 35.03% to 55.55% avg SR, outperforming naive full fine-tuning; EF-VLA using frozen CLIP encoders achieves +20% on compositional tasks and 85% success on unseen goals; however, full freezing can degrade performance, supporting theory's nuanced view on adaptation",
            "uuids": [
                "e1947.2",
                "e1982.3"
            ]
        }
    ],
    "partially_supporting_evidence": [
        {
            "text": "Frozen pretrained embeddings can provide effective grounding with appropriate mechanisms but show clear limitations: SigLIP-BC achieves 74% navigation success with frozen embeddings and simple BC policy, but with 3.2× efficiency gap vs expert and failures in spatial reasoning/planning; ViLT (VQA-finetuned) performs worst (40% SR), suggesting task-specific fine-tuning for non-embodied tasks doesn't transfer well",
            "uuids": [
                "e1973.0",
                "e1973.2"
            ]
        },
        {
            "text": "Language-based representations can partially bypass perception issues in specific settings: LangNav using text captions shows better sim-to-real transfer than vision-based RecBert; WMNav's text-image memory baseline performs worse (62.0% SR) than quantitative curiosity maps (72.2% SR) due to hallucination, showing text-only memory is insufficient; these approaches are limited to specific task types",
            "uuids": [
                "e1729.0",
                "e1980.3"
            ]
        },
        {
            "text": "Memory systems are critical for grounding but implementation matters: MTU3D's spatial memory bank contributes substantially to lifelong navigation; VEME's spatial semantic memory yields ~+9.8 SPL when included; ISR (implicit scene representation) reduces redundant geometric details that impede grounding; however, memory systems depend on clean inputs (point clouds, trajectories) and can fail under noise",
            "uuids": [
                "e1977.2",
                "e1956.1",
                "e1933.1"
            ]
        },
        {
            "text": "Heatmap-based grounding can be more efficient than point-based: RoboMAP's adaptive heatmaps achieve competitive accuracy with ~15× faster inference than iterative methods like Embodied-R1; however, point-based methods can achieve higher precision on some tasks, suggesting trade-offs between efficiency and accuracy",
            "uuids": [
                "e1978.1",
                "e1978.10"
            ]
        }
    ],
    "fully_contradicting_evidence": [],
    "partially_contradicting_evidence": [
        {
            "text": "Some text-only or language-abstraction approaches achieve reasonable performance without explicit visual grounding in limited settings: LangSuitE text-only approaches achieve 77-86% SR on high-level actions; Code-as-Policies and LMPs succeed by generating programs calling perception APIs; however, these are limited to coarse navigation or modular settings and don't address fine-grained spatial reasoning or manipulation",
            "uuids": [
                "e1730.0",
                "e1847.0"
            ]
        }
    ],
    "potentially_modifying_evidence": [
        {
            "text": "Grounding improvements don't guarantee execution success, suggesting grounding is necessary but insufficient: ROBOGROUND achieves 89% contact but only 43.3% success on pick-and-place, showing large gap between localization and manipulation; VLM-VLA misalignment causes execution failures despite correct high-level grounding; dual-system approaches face latency and coordination issues; this suggests theory should clarify grounding as one component in execution pipeline",
            "uuids": [
                "e1943.0",
                "e1962.3",
                "e1965.3"
            ]
        },
        {
            "text": "Temporal and multi-step grounding requires different mechanisms than single-step: PIO benchmark shows models excel at S1/S2 single-target grounding but fail at S3 trajectory prediction; OneTwoVLA's explicit textual reasoning substantially improves long-horizon tasks (+30% over π0 baseline); Gemini-2.5-Pro succeeds at S3 planning despite weaker S1/S2 precision; this suggests theory should distinguish instantaneous vs. temporal grounding requirements",
            "uuids": [
                "e1972.0",
                "e1965.0",
                "e1972.7"
            ]
        },
        {
            "text": "Action-space alignment and tokenization are critical for grounding transfer beyond visual grounding: OpenVLA+ string tokenizer yields +15-43 point improvements by aligning actions with language tokens; VLM-VLA misalignment causes failures despite correct visual grounding; FAST tokenization enables 15× faster inference and 200 Hz control; this suggests theory should include action-grounding as distinct from perception-grounding",
            "uuids": [
                "e1947.3",
                "e1962.3",
                "e1982.11"
            ]
        },
        {
            "text": "Hierarchical and dual-system architectures show promise but face coordination challenges: Groot N1 dual-system achieves +17% SR and -28% collisions but faces timing mismatches (~800ms LLM vs ~10ms control); OneTwoVLA's unified reasoning+acting outperforms separated systems (87% vs 63% on long-horizon tasks); this suggests theory should address multi-level grounding coordination and latency constraints",
            "uuids": [
                "e1982.4",
                "e1965.0",
                "e1965.3"
            ]
        },
        {
            "text": "Synthetic and procedural data generation can effectively scale grounding supervision: OneTwoVLA's synthetic VL pipeline (16K images with fisheye/gripper augmentation) yields +65% open-world grounding improvement; OXE-MAP procedural conversion of trajectories to heatmaps enables effective training; DenseGrounding's LLM-grounded text augmentation yields +3.48% ACC@25; this extends theory's data-scaling predictions to include synthetic/procedural sources",
            "uuids": [
                "e1965.4",
                "e1978.4",
                "e1968.4"
            ]
        },
        {
            "text": "Adversarial robustness reveals grounding vulnerabilities and should be considered a dimension of grounding quality: EDPA embedding-space attacks cause near-100% failure by disrupting image-instruction alignment; adversarial fine-tuning of encoders reduces vulnerability by ~34%; attacks transfer across models/datasets indicating systematic weaknesses; this suggests theory should address grounding robustness as a distinct dimension",
            "uuids": [
                "e1975.3",
                "e1975.0"
            ]
        },
        {
            "text": "Explicit reasoning and chain-of-thought improve grounding in complex settings: EmbodiedVSR's physics-constrained CoT reduces geometric hallucinations; Robix's thought-action consistency training via RL improves grounding and reduces irrational steps; RFT with free-form CoT yields +28 points over SFT on grounding benchmarks; HEAL probing shows models struggle with scene-task contradictions even with feedback; this suggests grounding benefits from explicit reasoning scaffolding",
            "uuids": [
                "e1941.0",
                "e1962.0",
                "e1979.7",
                "e1963.3"
            ]
        },
        {
            "text": "Grounding representation format matters: RoboMAP's adaptive heatmaps outperform fixed-shape heatmaps and point-based methods; Gondola's end-to-end mask generation outperforms box-based grounding by +20-25 IoU points; normalized IoU metric needed to fairly compare boxes vs points; this suggests theory should address representation-level choices for grounding outputs",
            "uuids": [
                "e1978.1",
                "e1958.0",
                "e1972.9"
            ]
        },
        {
            "text": "Real-time constraints and inference latency are practical grounding bottlenecks: OneTwoVLA reasoning mode causes &gt;2s latency for ~100 tokens; Groot N1 faces jerkiness from System 2 latency; RoboMAP achieves competitive accuracy with 15× faster inference than iterative methods; this suggests theory should consider computational efficiency as a grounding quality dimension",
            "uuids": [
                "e1965.0",
                "e1982.4",
                "e1978.10"
            ]
        },
        {
            "text": "Precision and numerical representation affect grounding: quantization (INT4) disproportionately harms high-level grounding (14-17% drops on implicit/relational) vs simple attribute recognition (4% drop); string-based action tokenization preserves fine-grained spatial values while enabling language alignment; this suggests grounding quality depends on representation precision",
            "uuids": [
                "e1981.6",
                "e1947.3"
            ]
        }
    ],
    "suggested_revisions": [
        "Distinguish between single-step/instantaneous grounding (S1/S2-type localization) and temporal/trajectory grounding (S3-type planning), as evidence shows these require different mechanisms and models excel at one but not the other",
        "Add action-space grounding as a distinct component: the mapping from grounded perceptions to executable actions is a separate bottleneck (VLM-VLA misalignment, action tokenization effects, FAST compression)",
        "Expand fusion mechanisms to include hierarchical/dual-system architectures and their coordination challenges, as evidence shows both promise (Groot N1, OneTwoVLA) and pitfalls (latency, misalignment)",
        "Include synthetic and procedural data generation as effective scaling strategies for grounding supervision, extending beyond just scale of real pretraining data (OneTwoVLA synthetic VL, OXE-MAP, LLM-grounded augmentation)",
        "Add adversarial robustness as a dimension of grounding quality, as embedding-space attacks reveal fundamental vulnerabilities in learned alignments that can be mitigated through diverse pretraining and adversarial fine-tuning",
        "Incorporate explicit reasoning and chain-of-thought as mechanisms that enhance grounding, particularly for complex spatial reasoning, long-horizon tasks, and handling scene-task contradictions",
        "Clarify that grounding is necessary but not sufficient for task success—execution, action precision, system coordination, and real-time constraints are additional critical factors (ROBOGROUND contact vs success gap)",
        "Add memory systems (spatial memory banks, episodic memory, implicit scene representations) as critical components for grounding in sequential and long-horizon tasks, with caveats about dependence on input quality",
        "Include grounding representation format (heatmaps vs points vs boxes vs masks) as an important design choice affecting both accuracy and efficiency trade-offs",
        "Add computational efficiency and real-time constraints as practical dimensions of grounding quality, as latency can be a bottleneck even when grounding accuracy is high",
        "Expand frozen vs fine-tuned discussion to include partially-frozen dual-encoder approaches as effective middle ground that preserves pretrained grounding while enabling task adaptation",
        "Note that quantization and numerical precision disproportionately affect high-level grounding (relational, implicit) compared to simple attribute recognition, suggesting grounding quality is precision-sensitive"
    ],
    "overall_support_or_contradict": "support",
    "overall_support_or_contradict_explanation": "The new evidence strongly supports the core theory that perception-language grounding quality is critical for embodied AI transfer, with extensive evidence of perception bottlenecks, benefits of vision-language pretraining, importance of object-centric representations, and domain-shift challenges. However, the evidence reveals important scope expansions needed: grounding must extend to temporal/action/memory dimensions, explicit reasoning enhances grounding, and grounding alone doesn't guarantee execution success, suggesting the theory should be broadened rather than contradicted.",
    "revised_theory_ids": [
        "theory-373"
    ],
    "model_str": "claude-sonnet-4-5-20250929"
}</code></pre>
        </div>
    </div>
</body>
</html>