<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-80 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-80</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-80</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-5.html">extraction-schema-5</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of synaptic plasticity rules, brain connectivity patterns, and how they support learning at different temporal scales (e.g., milliseconds to days).</div>
                <p><strong>Paper ID:</strong> paper-a414e0814994171e54cdb7087edbe67a3762066f</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/a414e0814994171e54cdb7087edbe67a3762066f" target="_blank">Learning and executing goal-directed choices by internally generated sequences in spiking neural circuits</a></p>
                <p><strong>Paper Venue:</strong> PLoS Comput. Biol.</p>
                <p><strong>Paper TL;DR:</strong> The results suggest that the combination of plasticity phenomena on different timescales provides a candidate mechanism for forming internally generated neural sequences and for implementing adaptive spatial decision making.</p>
                <p><strong>Paper Abstract:</strong> Recent neural ensemble recordings have established a link between goal-directed spatial decision making and internally generated neural sequences in the hippocampus of rats. To elucidate the synaptic mechanisms of these sequences underlying spatial decision making processes, we develop and investigate a spiking neural circuit model endowed with a combination of two synaptic plasticity mechanisms including spike-timing dependent plasticity (STDP) and synaptic scaling. In this model, the interplay of the combined synaptic plasticity mechanisms and network dynamics gives rise to neural sequences which propagate ahead of the animals’ decision point to reach goal locations. The dynamical properties of these forward-sweeping sequences and the rates of correct binary choices executed by these sequences are quantitatively consistent with experimental observations; this consistency, however, is lost in our model when only one of STDP or synaptic scaling is included. We further demonstrate that such sequence-based decision making in our network model can adaptively respond to time-varying and probabilistic associations of cues and goal locations, and that our model performs as well as an optimal Kalman filter model. Our results thus suggest that the combination of plasticity phenomena on different timescales provides a candidate mechanism for forming internally generated neural sequences and for implementing adaptive spatial decision making.</p>
                <p><strong>Cost:</strong> 0.016</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e80.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e80.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of synaptic plasticity rules, brain connectivity patterns, and how they support learning at different temporal scales (e.g., milliseconds to days).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>STDP</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Spike-Timing Dependent Plasticity</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A temporally asymmetric Hebbian plasticity rule in which synapses are potentiated when presynaptic spikes precede postsynaptic spikes within a short window and depressed for the reverse timing; implemented here with symmetric potentiation/depression amplitudes and ~20 ms time constants.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Learning and executing goal-directed choices by internally generated sequences in spiking neural circuits</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>synaptic_rule_name</strong></td>
                            <td>Spike-Timing Dependent Plasticity (STDP)</td>
                        </tr>
                        <tr>
                            <td><strong>synaptic_rule_description</strong></td>
                            <td>STDP is implemented as a pair-based timing rule H(Δt) where Δt = t_post - t_pre: potentiation if 0 < Δt ≤ 5τ with magnitude A_+ exp(-Δt/τ_+) and depression if -5τ ≤ Δt < 0 with magnitude -A_- exp(Δt/τ_-). In the model A_+ = A_- = 1.2×10^-9, τ_+ = τ_- = 20 ms, and the window is truncated for |Δt| > 5τ (i.e. ≈100 ms). STDP is applied to all synapses (excitatory and inhibitory in the model) and accumulates changes across repeated trials; a hard cap on absolute synaptic change (|W(t)| ≤ L|W(0)| with L=0.12) prevents runaway growth.</td>
                        </tr>
                        <tr>
                            <td><strong>temporal_scale</strong></td>
                            <td>Milliseconds for the core potentiation/depression window (τ_+ = τ_- = 20 ms; window truncated beyond ≈100 ms); changes accumulate across trials (tens to hundreds of ms per trial and across many trials producing persistent synaptic modifications).</td>
                        </tr>
                        <tr>
                            <td><strong>brain_region_circuit</strong></td>
                            <td>Modeled hippocampal-like spatial circuit (2D place-field network intended to capture CA3-like recurrent place-cell dynamics used to explain hippocampal forward-sweeping sequences).</td>
                        </tr>
                        <tr>
                            <td><strong>connectivity_pattern</strong></td>
                            <td>Operates on a locally recurrent distance-dependent excitatory-inhibitory network (Gaussian falloff of static weights within radius D=25 grid units) and on random cue→network projections; STDP sculpts directionality of recurrent connections along behavioral paths.</td>
                        </tr>
                        <tr>
                            <td><strong>learning_type</strong></td>
                            <td>Associative/spatial sequence learning underlying goal-directed choice (learning of paths and cue→goal associations; supports probabilistic inference over cue-goal associations).</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_or_model</strong></td>
                            <td>Computational/theoretical spiking neural circuit model (conductance-based integrate-and-fire neurons) with STDP implemented as above.</td>
                        </tr>
                        <tr>
                            <td><strong>multi_timescale_interaction</strong></td>
                            <td>STDP provides fast, trial-level encoding of sequence directionality and cue-to-path associations (via potentiation of forward-direction synapses). These fast changes are modulated over longer times by synaptic scaling (a slower homeostatic process) that partially resets accumulated STDP changes, making the effective synaptic trace depend more on recent trials; analytically captured by ΔW_n = A_+ g_n exp(-Δt/τ_+) + r ΔW_{n-1}.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>STDP alone learns paths: it increases synaptic strengths in the direction of propagation and decreases reverse-direction connections, producing directional sequences; however, STDP alone leads to saturation/unwanted splitting of sequences (propagation down multiple arms). When combined with slower synaptic scaling, STDP sculpts cue→path asymmetries that generate forward-sweeping internally generated sequences (IGS) which reliably sweep toward one goal and support correct cued choices (~80% success), matching experimental observations (~75%).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_measure</strong></td>
                            <td>Parameters and quantitative aspects reported: A_+ = A_- = 1.2×10^-9; τ_+ = τ_- = 20 ms; STDP window truncated at |Δt| > 5τ (~100 ms). Behavioral performance: model with STDP+scaling achieves ≈80% correct choice rate (comparable to 75% reported experimentally). Without scaling, accuracy declines and splitting behavior dominates after ~80 trials. Analytic/behavioral comparisons to Kalman filter: model estimates of cue-goal probability were within 3% on 50% of trials, within 5% on 80% of trials, within 6% on 90% of trials (when compared over a Gaussian random-walk task after linear rescaling).</td>
                        </tr>
                        <tr>
                            <td><strong>slow_vs_fast_learning</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>consolidation_mechanism</strong></td>
                            <td>No explicit multi-stage consolidation (e.g., hippocampus→neocortex) is modeled; instead, a slow homeostatic synaptic scaling acts as a long-timescale process that partially resets/forgets older STDP-induced changes, producing an effective weighting of trials by recency (recent trials have greater influence). This functionsally separates fast encoding (STDP) from slower decay/reset (scaling), enabling adaptive updating rather than permanent consolidation.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Learning and executing goal-directed choices by internally generated sequences in spiking neural circuits', 'publication_date_yy_mm': '2017-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e80.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e80.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of synaptic plasticity rules, brain connectivity patterns, and how they support learning at different temporal scales (e.g., milliseconds to days).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Synaptic scaling</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Homeostatic Synaptic Scaling</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A slow, multiplicative homeostatic rule that scales recent synaptic changes toward baseline, preventing runaway potentiation from STDP and providing a slow timescale that weights recent trials more strongly than older ones.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Learning and executing goal-directed choices by internally generated sequences in spiking neural circuits</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>synaptic_rule_name</strong></td>
                            <td>Homeostatic synaptic scaling (multiplicative)</td>
                        </tr>
                        <tr>
                            <td><strong>synaptic_rule_description</strong></td>
                            <td>Synaptic scaling is implemented as a multiplicative term S(ΔW) = C ΔW applied periodically (computed every 100 time steps) that drives dynamic synaptic deviations ΔW back toward zero with characteristic time constant ≈7 s. In the Methods the conventional firing-rate formulation ΔW = ε(f - f^*)W is referenced; the model instead applies scaling proportional to the current plasticity-induced change so that synapses are scaled up or down toward their initial values. A hard upper/lower bound on total synaptic change (L=0.12×|W(0)|) is also imposed to avoid pathological growth.</td>
                        </tr>
                        <tr>
                            <td><strong>temporal_scale</strong></td>
                            <td>Slow relative to STDP: characteristic resetting time ≈7 seconds (model choice), which is ≈350× longer than the STDP time constant (20 ms); thus acts over seconds and across many trials (trials separated by ~150 ms; learning and behavioral adaptation observed across tens to hundreds of trials, i.e., seconds-to-minutes aggregated effects).</td>
                        </tr>
                        <tr>
                            <td><strong>brain_region_circuit</strong></td>
                            <td>Applied globally in the modeled hippocampal-like 2D recurrent network (affecting all synapses including cue→network connections) to produce long-timescale normalization across the simulated circuit.</td>
                        </tr>
                        <tr>
                            <td><strong>connectivity_pattern</strong></td>
                            <td>Multiplicative scaling applied to dynamic component ΔW of locally recurrent distance-dependent synapses and cue→network synapses; prevents recurrent forward-strengthening from causing sequences to split and propagate down multiple paths.</td>
                        </tr>
                        <tr>
                            <td><strong>learning_type</strong></td>
                            <td>Implements slow homeostatic modulation of associative/spatial learning; supports adaptive, time-varying learning by weighting recent trials more heavily (helps probabilistic tracking of cue-goal associations).</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_or_model</strong></td>
                            <td>Computational/theoretical model implementation of synaptic scaling based on biologically observed phenomena (cited empirical evidence for synaptic scaling in Discussion).</td>
                        </tr>
                        <tr>
                            <td><strong>multi_timescale_interaction</strong></td>
                            <td>Synaptic scaling (slow) counteracts the cumulative potentiation from STDP (fast). This creates two explicit timescales: fast STDP encodes immediate sequence/path statistics; slow scaling gradually decays older STDP-produced traces, making the effective synaptic state reflect a recent history of trials (analogue to exponential memory). The paper formalizes this as a discrete update ΔW_n = A_+ g_n exp(-Δt/τ_+) + r ΔW_{n-1} and derives steady-state ΔW_ss ∝ ̅g_n (averaged recent cue-goal probability), enabling probabilistic inference.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Synaptic scaling is necessary to (i) prevent the positive-feedback saturation of recurrent weights produced by STDP that would otherwise cause sequences to split and lose selectivity, and (ii) impart recency sensitivity so the network can adapt to time-varying cue→goal probabilities; with scaling, the model maintains stable forward-sweeping sequences and achieves behavioral accuracy comparable to experiments and near-Kalman-filter performance for tracking changing associations.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_measure</strong></td>
                            <td>Characteristic scaling time constant ≈7 s (scaling computed every 100 time steps in the simulation); scaling is ≈350× slower than STDP (20 ms). With scaling enabled, final success rate ≈80% and stable single-path forward sweeps; without scaling, splitting behavior dominates after ~80 trials and accuracy declines. Analytic steady-state relation given: ΔW_ss = F · ̅g_n with F = (A_+ / τ_+)*exp(-Δt / τ_+) / (1 - r) (as provided in the paper).</td>
                        </tr>
                        <tr>
                            <td><strong>slow_vs_fast_learning</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>consolidation_mechanism</strong></td>
                            <td>Acts as a slow forgetting/resetting mechanism rather than classic consolidation; synaptic scaling causes earlier STDP modifications to decay so that more recent trials dominate the synaptic state (this functional separation of timescales supports adaptive updating but is not presented as permanent consolidation to another system).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Learning and executing goal-directed choices by internally generated sequences in spiking neural circuits', 'publication_date_yy_mm': '2017-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e80.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e80.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of synaptic plasticity rules, brain connectivity patterns, and how they support learning at different temporal scales (e.g., milliseconds to days).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Recurrent distance-dependent network + cue projections</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Locally recurrent distance-dependent excitatory-inhibitory network with random cue→network projections (place-field 2D grid)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A 2D grid of excitatory and inhibitory integrate-and-fire neurons with Gaussian distance-dependent recurrent connectivity and sparse random cue projections; spatially localized bumps represent place fields and recurrent connectivity plus plasticity generate propagating forward-sweeping sequences.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Learning and executing goal-directed choices by internally generated sequences in spiking neural circuits</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>synaptic_rule_name</strong></td>
                            <td>Distance-dependent recurrent connectivity (Gaussian kernel) with plastic dynamic component</td>
                        </tr>
                        <tr>
                            <td><strong>synaptic_rule_description</strong></td>
                            <td>Static connectivity W_ij,ℓf^λ is distance-dependent: W = C^λ exp(-(d^2)/(d^λ)^2) for d ≤ D (cutoff). Network has 200×200 integer grid positions, excitatory neurons at non-even coordinates (30,000) and inhibitory at even coordinates (10,000), 75% excitatory / 25% inhibitory; each neuron connects to neighbors within radius D=25 (≈1470 excitatory and 490 inhibitory afferents). External cue neurons project randomly (40,000 cue synapses; ~1 per neuron on average) with initial weights drawn from the same distribution and plasticity applied to these cue→network synapses as well.</td>
                        </tr>
                        <tr>
                            <td><strong>temporal_scale</strong></td>
                            <td>Fast neural dynamics: spike conductance kernels with τ_d^E = 2.0 ms, τ_r^E = 0.5 ms; network propagation frames shown at 2 ms resolution; behaviorally relevant trial durations ~100 ms and inter-trial separations ≈150 ms. Plasticity acts over these fast dynamics (STDP ms-scale) and accumulates across trials; scaling acts over seconds.</td>
                        </tr>
                        <tr>
                            <td><strong>brain_region_circuit</strong></td>
                            <td>Model of a hippocampal place-cell network (inspired by CA3/Cornu Ammonis recurrent circuitry) used to study forward-sweeping internally generated sequences observed in hippocampal ensemble recordings.</td>
                        </tr>
                        <tr>
                            <td><strong>connectivity_pattern</strong></td>
                            <td>Locally recurrent excitatory and inhibitory connectivity with Gaussian spatial footprint and periodic boundary conditions; symmetric center-stem→arm recurrent potentiation by STDP unless broken by asymmetric cue→network connections; cue neurons provide asymmetric drive via learned cue→path weights that break symmetry and bias sequence direction.</td>
                        </tr>
                        <tr>
                            <td><strong>learning_type</strong></td>
                            <td>Spatial/associative learning (learning of traveled paths and cue→goal associations), sequence learning to support goal-directed choices and probabilistic inference over cue-goal mappings.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_or_model</strong></td>
                            <td>Computational/theoretical spiking neural circuit model representing a hippocampal-like recurrent network with place-field mapping; motivated and compared to in vivo hippocampal ensemble data.</td>
                        </tr>
                        <tr>
                            <td><strong>multi_timescale_interaction</strong></td>
                            <td>Fast sequence propagation emerges from the recurrent connectivity and STDP (ms-scale spike timing → directional weight changes); slow scaling adjusts the baseline of recurrent/ cue→network weights (seconds) to prevent pathological multi-path propagation and to encode recent trial statistics. The interplay between recurrent wiring (architecture) and plasticity at different rates yields IGS that can be used as online samplers for probabilistic inference across trials.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>The particular recurrent, local Gaussian connectivity supports propagating wavefronts that, when sculpted by STDP and biased by learned cue→network synapses, produce forward-sweeping internally generated sequences that predict future trajectories; the network topology plus the two-timescale plasticity is necessary and sufficient in the model for stable single-path forward sweeps and adaptive tracking of time-varying cue-goal statistics.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_measure</strong></td>
                            <td>Network details: 200×200 grid, D = 25 connectivity radius, ≈1470 excitatory and 490 inhibitory afferents per neuron; conductance time constants τ_d^E = 2.0 ms, τ_r^E = 0.5 ms; trip through T-maze ≈100 ms, trial separation 150 ms. Behavioral metric: forward-sweep sequences produced by this architecture combined with plasticity yield ≈80% correct choices on trained cue→goal mapping, and model-based estimates of cue-goal probability match Kalman-filter-level performance (error statistics described in other entries).</td>
                        </tr>
                        <tr>
                            <td><strong>slow_vs_fast_learning</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>consolidation_mechanism</strong></td>
                            <td>No explicit separate-system consolidation modeled (e.g., hippocampus→cortex). The network topology supports rapid sequence generation and STDP encodes path statistics quickly; slow synaptic scaling acts in-network to gradually renormalize weights, yielding an in-network mechanism for gradual forgetting/recency-weighting rather than transfer to another memory store.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Learning and executing goal-directed choices by internally generated sequences in spiking neural circuits', 'publication_date_yy_mm': '2017-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Sequential structure of neocortical spontaneous activity in vivo <em>(Rating: 2)</em></li>
                <li>Choice-specific sequences in parietal cortex during a virtual-navigation decision task <em>(Rating: 2)</em></li>
                <li>Rapid sequences of population activity patterns dynamically encode task-critical spatial information in parietal cortex <em>(Rating: 1)</em></li>
                <li>Behavior-dependent short-term assembly dynamics in the medial prefrontal cortex <em>(Rating: 1)</em></li>
            </ol>
        </div>

        </div>

    </div>
</body>
</html>